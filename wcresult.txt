like it or not
web technologies can web
technologies can web services
can web services scale
web services scale up
web services are distributed
services are distributed objects
cornell university i n
university i n the
i n the past
cornell university within the
cloudifying source code repositories
university within the community
only major internet players
within the community developing
major internet players such
the community developing the
internet players such as
community developing the web
players such as amazon
developing the web services
enforcing fairness in a
how much does it
implementing high performance multicast
fairness in a live
the web services architecture
much does it cost
web services architecture and
high performance multicast in
services architecture and products
and google were interested
optimizing power consumption in
performance multicast in a
michael siegenthaler hakim weatherspoon
aware adaptation techniques for
google were interested in
an increasingly schizophrenic message
were interested in deploying
siegenthaler hakim weatherspoon dept
interested in deploying large
power consumption in large
adaptation techniques for mobile
streaming system maya haridasana
increasingly schizophrenic message is
multicast in a managed
schizophrenic message is emerging
building collaboration applications that
consumption in large scale
collaboration applications that mix
in large scale storage
in a managed environment
large scale storage systems
techniques for mobile file
marketing materials assure us
applications that mix web
for mobile file systems
materials assure us that
that mix web services
mobile file systems benjamin
assure us that web
portob and robbert van
us that web services
this is changing rapidly
that web services are
and robbert van renessea
web services are a
robbert van renessea a
services are a breakthrough
van renessea a dept
mix web services hosted
file systems benjamin atkin
web services hosted content
of computer science cornell
a managed environment krzysztof
computer science cornell university
is changing rapidly all
offering unparalleled interoperability and
services hosted content with
scale storage systems lakshmi
managed environment krzysztof ostrowski
science cornell university msiegen
systems benjamin atkin kenneth
an adaptive distributed file
unparalleled interoperability and comprehensive
changing rapidly all sorts
hosted content with p
transparent error correction for
environment krzysztof ostrowski cornell
benjamin atkin kenneth p
adaptive distributed file system
krzysztof ostrowski cornell university
new york b institute
distributed file system for
ostrowski cornell university ken
file system for mobile
cornell university ken birman
system for mobile hosts
university ken birman cornell
york b institute of
ken birman cornell university
b institute of informatics
storage systems lakshmi ganesh
birman cornell university abstract
rapidly all sorts of
cornell university abstract motes
error correction for communication
university abstract motes end
birman nec laboratories america
correction for communication between
federal university of rio
of computer science cornell
university of rio grande
for mobile hosts benjamin
of rio grande do
all sorts of companies
mobile hosts benjamin atkin
interoperability and comprehensive standards
hosts benjamin atkin and
nec laboratories america cornell
benjamin atkin and kenneth
for communication between data
user application development using
computer science cornell university
application development using c
rio grande do sul
laboratories america cornell university
grande do sul porto
sorts of companies and
do sul porto alegre
and comprehensive standards for
science cornell university hweather
comprehensive standards for associated
atkin and kenneth p
standards for associated technologies
communication between data centers
of companies and governmental
between data centers mahesh
america cornell university atkin
companies and governmental organizations
ken birman computer science
krzysztof ostrowski cornell university
birman computer science department
and governmental organizations are
data centers mahesh balakrishnan
the company s own
governmental organizations are suddenly
company s own products
birman department of computer
organizations are suddenly looking
department of computer science
edu abstract cloud computing
are suddenly looking towards
dept of computer science
abstract cloud computing provides
suddenly looking towards web
they portray web services
cloud computing provides us
looking towards web services
portray web services as
computing provides us with
towards web services as
web services as a
provides us with general
web services as a
s own products are
of computer science cornell
own products are still
computer science cornell university
services as a platform
services as a seamless
us with general purpose
products are still implemented
as a platform that
are still implemented primarily
with general purpose storage
still implemented primarily in
a platform that might
implemented primarily in unmanaged
general purpose storage and
primarily in unmanaged c
edu abstract therefore react
platform that might support
abstract therefore react to
purpose storage and server
therefore react to bandwidth
that might support a
react to bandwidth variations
storage and server hosting
to bandwidth variations in
might support a wide
bandwidth variations in a
and server hosting platforms
variations in a fine
support a wide range
as a seamless interconnection
a wide range of
server hosting platforms at
wide range of demanding
a seamless interconnection layer
range of demanding applications
hosting platforms at a
by building xyx in
edu abstract data centers
platforms at a reasonable
seamless interconnection layer that
at a reasonable price
abstract data centers are
edu abstract we describe
interconnection layer that will
abstract we describe a
edu abstract mfs using
building xyx in the
abstract mfs using file
xyx in the recommended
mfs using file access
in the recommended manner
layer that will propel
data centers are the
that will propel computer
examples of such systems
we explore the possibility
of such systems include
using file access traces
explore the possibility of
centers are the backend
we describe a practical
the possibility of tapping
life file system traffic
we found ourselves breaking
file system traffic featuring
such systems include big
system traffic featuring high
describe a practical auditing
traffic featuring high read
file access traces from
found ourselves breaking new
access traces from windows
ourselves breaking new ground
traces from windows nt
possibility of tapping these
from windows nt and
are the backend for
windows nt and unix
computer commerce to a
a practical auditing approach
commerce to a previously
systems include big banking
to a previously inaccessible
the backend for a
a previously inaccessible level
practical auditing approach designed
the multicast protocols employed
and a synthetic workload
include big banking and
of tapping these resources
big banking and brokerage
auditing approach designed to
banking and brokerage data
and they use language
a synthetic workload designed
backend for a large
tapping these resources for
for a large number
multicast protocols employed by
a large number of
and brokerage data centers
they use language evocative
synthetic workload designed to
use language evocative of
these resources for the
approach designed to encourage
protocols employed by qsm
designed to encourage fairness
write wireless networks present
to encourage fairness in
language evocative of marketing
encourage fairness in peer
large number of services
employed by qsm were
number of services that
by qsm were designed
of services that we
resources for the purpose
services that we take
online service centers for
for the purpose of
wireless networks present unusual
qsm were designed for
networks present unusual challenges
evocative of marketing for
present unusual challenges for
workload designed to emulate
unusual challenges for mobile
edu abstract the most
designed to emulate sharing
were designed for performance
that we take for
of marketing for distributed
we take for granted
the purpose of hosting
take for granted today
abstract the global network
purpose of hosting source
to emulate sharing patterns
the global network of
auditing is employed to
service centers for companies
marketing for distributed object
centers for companies that
abstract the most commonly
for companies that operate
of hosting source code
companies that operate on
global network of data
that operate on a
challenges for mobile file
operate on a global
designed for performance and
a significant fraction of
for performance and scalability
emulate sharing patterns seen
hosting source code repositories
is employed to ensure
network of data centers
for distributed object middleware
for mobile file contention
on a global scale
the most commonly deployed
significant fraction of the
most commonly deployed web
source code repositories for
commonly deployed web service
of data centers is
deployed web service applications
sharing patterns seen in
systems to operate critical
employed to ensure that
to operate critical infrastructures
technologists are sending a
operate critical infrastructures like
are sending a somewhat
data centers is emerging
sending a somewhat different
fraction of the total
centers is emerging as
code repositories for individual
to ensure that correct
incorporating a mixture of
mafs is able to
a mixture of new
is able to achieve
mixture of new ideas
patterns seen in mobility
of new ideas and
is emerging as an
new ideas and ideas
ensure that correct nodes
ideas and ideas drawn
web service applications employ
a somewhat different message
able to achieve improvements
of the total cost
seen in mobility is
the total cost of
emerging as an important
total cost of ownership
and ideas drawn from
cost of ownership of
service applications employ client
of ownership of these
repositories for individual projects
ownership of these large
critical infrastructures like electric
for individual projects as
that correct nodes are
individual projects as well
to achieve improvements in
correct nodes are able
as an important distributed
in an essay entitled
infrastructures like electric power
an essay entitled web
like electric power and
in mobility is a
with clients running remotely
nodes are able to
clients running remotely and
ideas drawn from prior
running remotely and services
drawn from prior systems
essay entitled web services
electric power and transportation
entitled web services are
mobility is a critical
web services are not
are able to receive
services are not distributed
scale storage systems is
are not distributed objects
achieve improvements in execusystem
an important distributed systems
and government and military
projects as well as
important distributed systems paradigm
government and military systems
as well as entire
the aspects on which
and military systems responsible
well as entire open
aspects on which we
storage systems is the
on which we focus
distributed systems paradigm commodity
which we focus here
able to receive streams
we focus here reflect
remotely and services hosted
focus here reflect architectural
and services hosted in
improvements in execusystem clients
services hosted in data
is a critical feature
hosted in data centers
systems paradigm commodity clusters
a critical feature of
paradigm commodity clusters running
critical feature of computer
commodity clusters running high
feature of computer systems
systems is the cost
werner vogels argues that
is the cost of
military systems responsible for
the cost of keeping
here reflect architectural responses
cost of keeping hundreds
to receive streams even
we make the case
as entire open source
make the case for
since they are characterised
the case for service
of keeping hundreds of
vogels argues that web
keeping hundreds of thousands
receive streams even in
hundreds of thousands of
entire open source communities
of thousands of disks
they are characterised by
thousands of disks spinning
argues that web services
systems responsible for everything
streams even in the
reflect architectural responses to
and while collaborative engineering
an analysis of storage
are characterised by unpredictable
analysis of storage costs
responsible for everything from
of storage costs is
architectural responses to scheduling
storage costs is presented
while collaborative engineering systems
that web services will
we present a simple
characterised by unpredictable tion
even in the presence
by unpredictable tion time
applications that combine service
unpredictable tion time of
responses to scheduling delays
tion time of up
present a simple idea
for everything from intelligence
in the presence of
and a complete hosting
the presence of nodes
wireless networks are common
web services will work
time of up to
services will work well
everything from intelligence gathering
will work well for
a complete hosting solution
work well for important
presence of nodes that
well for important classes
most applications that run
speed lambda networks across
from intelligence gathering to
lambda networks across hundreds
complete hosting solution is
networks across hundreds of
a simple idea that
across hundreds of milliseconds
for important classes of
hundreds of milliseconds of
important classes of applications
of milliseconds of network
overheads associated with threads
milliseconds of network latency
of nodes that do
simple idea that allows
nodes that do not
hosted data with collaboration
that do not upload
hosting solution is built
do not upload enough
solution is built and
packet loss on long
is built and evaluated
data with collaboration features
built and evaluated as
idea that allows the
and evaluated as a
not upload enough data
evaluated as a proof
but he also cites
applications that run on
he also cites significant
and costs arising in
also cites significant limits
intelligence gathering to issuing
at both low and
gathering to issuing social
both low and high
to issuing social security
low and high bandwidths
issuing social security checks
with collaboration features implemented
haul networks can cripple
collaboration features implemented using
that allows the storage
networks can cripple the
allows the storage system
that run on existing
the storage system to
costs arising in the
run on existing work
can cripple the performance
this emerging trend presents
features implemented using peerto
emerging trend presents developers
storage system to turn
trend presents developers with
system to turn off
presents developers with a
cripple the performance of
developers with a new
and scales well when
as vogels sees it
scales well when compared
on existing work in
well when compared to
to turn off a
existing work in cache
the performance of applications
collaboration features are awkward
work in cache management
performance of applications and
when compared to previous
i ntroduction the advent
compared to previous solutions
with a new challenge
to previous solutions that
the traditional approach to
previous solutions that rely
features are awkward to
traditional approach to adapting
of applications and protocols
turn off a large
applications and protocols a
building web services solutions
the architecture is so
web services solutions that
in cache management for
services solutions that scale
approach to adapting network
cache management for mobile
off a large fraction
to adapting network communication
management for mobile file
a large fraction of
architecture is so centered
large fraction of its
ntroduction the advent of
fraction of its disks
and protocols a loss
the advent of cloud
adapting network communication to
for mobile file systems
advent of cloud computing
network communication to these
a scalable system is
solutions that rely on
communication to these conditions
are awkward to support
is so centered on
awkward to support solely
so centered on document
of cloud computing has
centered on document exchange
scalable system is one
that rely on tit
system is one that
to these conditions is
is one that can
arising in the memory
one that can flexibly
and at its core
cloud computing has brought
at its core is
mobile file systems mobile
its core is so
computing has brought us
protocols a loss rate
in the memory management
a loss rate as
tat style of data
loss rate as low
style of data exchange
rate as low as
file systems mobile hosts
has brought us a
that can flexibly accommodate
without incurring unacceptable performance
can flexibly accommodate growth
incurring unacceptable performance penalties
to support solely based
core is so simple
support solely based on
brought us a dazzling
solely based on the
auditing involves two roles
based on the existing
flexibly accommodate growth in
on the existing web
the memory management subsystem
that many features taken
these conditions is to
many features taken for
systems mobile hosts lack
conditions is to write
us a dazzling array
is to write back
of particular appeal is
to write back file
accommodate growth in its
write back file updates
growth in its client
a dazzling array of
in its client base
over the period during
dazzling array of public
the period during which
mobile hosts lack flexible
period during which qsm
the existing web services
during which qsm was
features taken for granted
which qsm was developed
is sufficient to reduce
array of public computing
sufficient to reduce tcp
hosts lack flexible mechanisms
of public computing services
existing web services technologies
particular appeal is the
taken for granted in
appeal is the fact
for granted in object
back file updates asynchronously
lack flexible mechanisms for
file updates asynchronously when
such systems typically run
updates asynchronously when bandwidth
is the fact that
asynchronously when bandwidth is
public computing services that
flexible mechanisms for data
untrusted local auditors run
indirection through the data
ip throughput by an
through the data center
throughput by an order
the data center introduces
by an order of
computing services that can
an order of magnitude
local auditors run on
order of magnitude on
the fact that our
of magnitude on a
these had pervasive consequences
data center introduces high
mechanisms for data access
center introduces high latencies
for data access in
auditors run on all
data access in an
run on all nodes
access in an en
this can lead to
introduces high latencies and
can lead to underutilisation
high latencies and limits
services that can be
latencies and limits scalability
on all nodes in
forcing us to redesign
all nodes in the
fact that our solution
nodes in the system
systems typically run on
that can be instantly
oriented systems are fundamentally
typically run on a
lead to underutilisation of
that our solution is
run on a clustered
us to redesign and
and precludes collaboration between
on a clustered computer
to underutilisation of bandwidth
our solution is not
a clustered computer or
can be instantly tapped
and are responsible for
clustered computer or in
precludes collaboration between clients
are responsible for collecting
computer or in a
solution is not application
responsible for collecting and
or in a large
to redesign and recode
for collecting and maintaining
in a large data
redesign and recode one
collecting and maintaining accountable
a large data center
underutilisation of bandwidth and
systems are fundamentally lacking
of bandwidth and inconsistencies
maelstrom is an edge
bandwidth and inconsistencies between
be instantly tapped by
is an edge appliance
large data center and
collaboration between clients connected
an edge appliance that
between clients connected to
and maintaining accountable information
instantly tapped by anyone
savings for a very
tapped by anyone with
for a very generic
by anyone with a
a very generic data
anyone with a credit
very generic data center
with a credit card
generic data center model
a credit card number
and inconsistencies between clients
clients connected to one
edge appliance that masks
and recode one layer
appliance that masks packet
recode one layer of
examples include dynamic object
one layer of the
data center and must
layer of the system
we describe a new
center and must be
that masks packet loss
we describe our solution
and must be able
masks packet loss transparently
of the system after
include dynamic object creation
the system after another
another but lacking connectivity
maintaining accountable information regarding
identify the parameters that
must be able to
the parameters that determine
describe a new mobile
parameters that determine its
incorporates mechanisms for making
a new mobile access
accountable information regarding data
packet loss transparently and
information regarding data sent
loss transparently and quickly
regarding data sent and
transparently and quickly from
data sent and received
and quickly from inter
new mobile access to
be able to handle
the original system was
but lacking connectivity to
original system was multithreaded
users are spared from
mechanisms for making efficient
sent and received by
dynamic object creation and
and received by each
able to handle high
received by each node
lacking connectivity to the
are spared from having
connectivity to the data
mobile access to shared
to the data center
that determine its cost
access to shared data
for making efficient vironment
o calls and was
spared from having to
calls and was rather
to handle high loads
and was rather casual
to shared data is
was rather casual about
object creation and garbage
one or more trusted
aggregating traffic for high
or more trusted global
cornell s live distributed
making efficient vironment with
shared data is complicated
efficient vironment with large
from having to invest
vironment with large and
handle high loads or
speed encoding and using
and present a simulator
s live distributed objects
present a simulator that
live distributed objects platform
a simulator that allows
having to invest in
simulator that allows us
more trusted global auditors
that allows us to
encoding and using a
trusted global auditors periodically
data is complicated by
global auditors periodically sample
distributed objects platform combines
auditors periodically sample the
objects platform combines web
periodically sample the state
platform combines web services
sample the state of
combines web services with
the state of participating
web services with direct
state of participating nodes
services with direct peerto
high loads or sudden
allows us to explore
loads or sudden demand
us to explore this
or sudden demand bursts
to explore this parameter
with large and frequent
explore this parameter space
peer communication to eliminate
and using a new
communication to eliminate these
is complicated by an
to eliminate these issues
estimate whether the streaming
to invest in expensive
whether the streaming quality
large and frequent variations
the streaming quality is
using a new forward
streaming quality is satisfactory
complicated by an unpredictable
rather casual about buffering
by an unpredictable mobile
we also present some
an unpredictable mobile file
and frequent variations in
unpredictable mobile file system
a new forward error
and decide whether any
casual about buffering and
decide whether any actions
also present some initial
whether any actions are
frequent variations in network
any actions are required
new forward error correction
creation and garbage collection
forward error correction scheme
sudden demand bursts and
error correction scheme to
demand bursts and a
correction scheme to handle
bursts and a vast
scheme to handle bursty
we demonstrate through simulation
to handle bursty loss
invest in expensive infrastructure
demonstrate through simulation that
that supports graceful degradation
about buffering and caching
supports graceful degradation computing
introduction there is a
graceful degradation computing environment
variations in network connec
in expensive infrastructure such
through simulation that our
expensive infrastructure such as
dynamically created object references
infrastructure such as servers
there is a growing
and a vast number
is a growing opportunity
use of available bandwidth
a growing opportunity to
the network or a
growing opportunity to use
the current system is
opportunity to use service
present some initial simulation
simulation that our approach
and a variety of
some initial simulation results
a variety of reliability
current system is single
and cooling equipment because
that our approach can
a vast number of
initial simulation results that
vast number of users
network or a particular
simulation results that add
it has mostly focused
results that add weight
has mostly focused on
cooling equipment because the
or a particular destination
our approach can successfully
applications in ways that
they must reliably respond
approach can successfully detect
equipment because the service
variety of reliability and
a particular destination of
of reliability and transactional
in ways that can
reliability and transactional mechanisms
ways that can slash
can successfully detect and
that can slash health
that add weight to
successfully detect and react
and obsessively minimizes memory
must reliably respond even
obsessively minimizes memory consumption
particular destination of file
mostly focused on tivity
destination of file system
detect and react to
of file system performance
and react to the
file system performance as
because the service provider
system performance as bandwidth
add weight to our
performance as bandwidth is
reliably respond even in
as bandwidth is reduced
react to the presence
weight to our claim
to the presence of
respond even in the
the presence of opportunistic
even in the event
to our claim that
in the event of
permit more effective search
the event of failures
the service provider takes
both perspectives can t
our claim that our
service provider takes care
performs well and is
provider takes care of
well and is stable
event of failures or
and is stable at
perspectives can t be
is stable at high
can t be correct
stable at high data
in collaborative work adapting
at high data rates
takes care of these
as well as may
care of these and
well as may be
more effective search and
as may be unavailable
it s easy to
effective search and rescue
large scale and under
search and rescue after
scale and under stress
and rescue after a
i ntroduction t a
collaborative work adapting existing
or the throughput may
s easy to see
the throughput may be
of these and amortizes
throughput may be substandard
rescue after a disaster
of failures or reconfiguration
ntroduction t a conference
work adapting existing systems
t a conference version
easy to see how
a conference version of
to see how this
these and amortizes the
see how this situation
adapting existing systems to
how this situation arose
as rapid propagation of
the finished system achieves
rapid propagation of essential
conference version of this
propagation of essential file
and amortizes the cost
of essential file updates
existing systems to cope
enable a more nimble
systems to cope with
a more nimble information
to cope with periods
claim that our solution
amortizes the cost across
that our solution represents
the cost across many
presence of opportunistic nodes
cost across many clients
managed and automate as
cope with periods of
mafs is able to
with periods of low
finished system achieves extremely
periods of low bandwidth
version of this paper
system achieves extremely high
and automate as many
web services are the
automate as many routine
our solution represents a
or make possible a
solution represents a new
achieving efficiency through economies
represents a new powersaving
achieves extremely high performance
a new powersaving opportunity
services are the most
new powersaving opportunity for
of opportunistic nodes in
powersaving opportunity for large
particularly when wireless and
efficiency through economies of
is able to shown
through economies of scale
able to shown in
are the most recent
to shown in figure
of this paper appeared
opportunistic nodes in streaming
this paper appeared in
nodes in streaming sessions
paper appeared in nsdi
make possible a world
companies are realizing that
when wireless and wired
extremely high performance with
as many routine services
high performance with relatively
possible a world of
performance with relatively modest
wireless and wired users
this graph shows results
many routine services such
graph shows results from
a world of professional
shows results from packet
the most recent in
introduction the declining costs
most recent in a
are realizing that it
recent in a long
with relatively modest cpu
in a long series
relatively modest cpu and
a long series of
modest cpu and memory
routine services such as
cpu and memory loads
it incurs low network
world of professional dialog
incurs low network and
the declining costs of
low network and computational
realizing that it no
network and computational overheads
fifth usenix symposium on
that it no longer
long series of object
declining costs of commodity
series of object oriented
and wired users share
of object oriented interoperability
wired users share in
which remain fixed as
it no longer makes
remain fixed as the
costs of commodity disk
no longer makes sense
although our paper is
usenix symposium on networked
object oriented interoperability platforms
symposium on networked systems
services such as backups
on networked systems design
such as backups and
networked systems design and
longer makes sense to
systems design and implementation
users share in a
fixed as the system
share in a style
as the system scales
as backups and component
our paper is not
backups and component upgrades
and mixes ideas from
and component upgrades as
mixes ideas from corba
component upgrades as possible
in a style which
makes sense to build
a style which we
of professional dialog and
style which we will
of commodity disk drives
which we will refer
sense to build and
we will refer to
professional dialog and collaboration
will refer to as
commodity disk drives has
refer to as modal
many settings also require
to as modal adaptation
introduction video and audio
settings also require security
improvements in execution time
also require security against
in execution time for
paper is not about
execution time for real
video and audio streaming
is not about setting
when files or databases
not about setting performance
dialog and collaboration without
disk drives has made
and collaboration without travel
and audio streaming account
life measurements of available
while exploiting xml and
about setting performance records
exploiting xml and other
drives has made online
require security against attempted
has made online data
soc applications will need
made online data storage
applications will need to
online data storage a
will need to combine
data storage a way
measurements of available bandwidth
storage a way of
to build and manage
a way of life
we describe some techniques
xml and other web
describe some techniques bandwidth
audio streaming account for
some techniques bandwidth is
security against attempted intrusions
techniques bandwidth is high
setting performance records the
build and manage all
performance records the absolute
and manage all of
records the absolute numbers
manage all of their
the absolute numbers are
all of their own
absolute numbers are good
of their own infrastructure
developers using popular middleware
of available bandwidth between
using popular middleware platforms
so much so that
the application communicates normally
ms index terms data
need to combine two
streaming account for a
to combine two types
available bandwidth between a
combine two types of
much so that companies
two types of content
when for adapting data
so that companies like
against attempted intrusions and
for adapting data access
that companies like google
attempted intrusions and distributed
adapting data access to
intrusions and distributed denial
and services in the
account for a large
services in the cloud
bandwidth between a mobile
in the cloud are
companies like google and
the cloud are quickly
data access to network
cloud are quickly becoming
popular middleware platforms can
are quickly becoming popular
qsm outperforms the multicast
between a mobile host
index terms data centers
a mobile host on
traditional web service hosted
mobile host on a
web service hosted content
middleware platforms can transform
outperforms the multicast platforms
platforms can transform a
access to network variability
can transform a program
to network variability in
like google and yahoo
such as data from
for a large percentage
as data from databases
transform a program object
network variability in the
a program object into
google and yahoo host
program object into a
a large percentage of
object into a web
variability in the context
into a web services
host on a wireless
a web services object
the multicast platforms we
large percentage of content
that software development projects
in the context of
and yahoo host hundreds
the context of bandwidth
multicast platforms we ve
context of bandwidth falls
he emergence of commodity
of bandwidth falls below
on a wireless network
bandwidth falls below a
or access a remote
falls below a threshold
and weather prediction systems
platforms we ve worked
software development projects will
yahoo host hundreds of
emergence of commodity clusters
and a wired host
access a remote ws
a wired host near
the application enters a
with a variety of
percentage of content accessed
a variety of collaboration
of commodity clusters and
variety of collaboration features
development projects will turn
commodity clusters and data
host hundreds of thousands
wired host near the
clusters and data centers
we ve worked with
of content accessed over
a remote ws object
content accessed over the
projects will turn to
accessed over the web
application enters a lowmfs
host near the base
and data centers has
near the base station
such as chat windows
at the touch of
hundreds of thousands of
the touch of a
ve worked with in
touch of a button
one popular style of
worked with in the
of thousands of servers
file system traces featuring
thousands of servers for
system traces featuring read
of servers for storage
popular style of streaming
with in the past
style of streaming on
a client cache manager
of streaming on the
client cache manager for
streaming on the web
data centers has enabled
on the web is
peer video and other
the web is on
performance leaves something to
web is on demand
as the mobile host
the second builds on
the mobile host moves
centers has enabled a
there is a catch
cache manager for a
in the past systems
manager for a distributed
will turn to cloud
for a distributed file
second builds on the
a distributed file system
leaves something to be
a hundred thousand servers
something to be desired
hundred thousand servers consume
turn to cloud computing
thousand servers consume a
factors such as the
servers consume a lot
in which users access
consume a lot of
we bandwidth mode in
has enabled a new
to cloud computing to
builds on the first
cloud computing to store
the past systems that
computing to store their
which users access pre
to store their master
but computers and networks
store their master code
enabled a new class
their master code repositories
on the first and
a new class of
past systems that run
the first and supports
new class of globally
computers and networks have
such as the distance
and networks have become
a lot of power
as the distance to
bandwidth mode in which
systems that run in
first and supports a
that run in unmanaged
video and other media
run in unmanaged settings
networks have become astonishingly
stored content at will
have become astonishingly fast
mode in which communication
class of globally distributed
and supports a way
either on a project
this paper won t
not only does this
paper won t tell
in which communication is
won t tell the
supports a way to
t tell the blow
another style requires streams
the distance to the
style requires streams to
major application providers are
requires streams to be
which communication is restricted
and other media streams
project basis or as
communication is restricted or
distance to the base
of globally distributed highperformance
application providers are planning
streams to be generated
a way to build
to be generated and
basis or as part
be generated and disseminated
to the base station
generated and disseminated in
providers are planning to
only does this translate
are planning to offer
is restricted or deshow
planning to offer ws
globally distributed highperformance applications
the base station and
existing web service technologies
distributed highperformance applications that
base station and local
web service technologies make
highperformance applications that coordinate
station and local interference
service technologies make it
and disseminated in real
technologies make it easy
does this translate to
make it easy to
restricted or deshow how
it easy to build
we use qsm in
easy to build applications
use qsm in a
way to build scripts
qsm in a series
this translate to many
in a series of
or deshow how mfs
a series of experiments
and local interference cause
series of experiments that
or as part of
of experiments that highlight
to offer ws interfaces
experiments that highlight fundamental
applications that coordinate over
that highlight fundamental factors
deshow how mfs is
to build applications in
how mfs is able
to build scripts of
mfs is able to
translate to many millions
is able to adapt
this may be the
able to adapt to
local interference cause the
to adapt to widely
as part of a
adapt to widely varying
offer ws interfaces to
to widely varying bandwidth
that coordinate over vast
widely varying bandwidth ferred
may be the case
build applications in which
be the case with
build scripts of simpler
the case with important
to many millions of
case with important social
these reveal linkages between
coordinate over vast geographical
reveal linkages between achievable
applications in which all
part of a larger
in which all data
ws interfaces to their
which all data travels
interference cause the host
all data travels through
linkages between achievable performance
scripts of simpler transactions
between achievable performance and
many millions of dollars
interfaces to their products
millions of dollars annually
over vast geographical distances
of dollars annually on
data travels through a
an important property of
achievable performance and the
important property of live
cause the host s
dollars annually on electricity
the host s network
travels through a data
host s network card
through a data center
s network card to
so it makes perfect
network card to switch
annually on electricity bills
card to switch to
an application has a
to switch to higher
streaming is that data
application has a small
it makes perfect sense
some might argue that
makes perfect sense that
performance and the costs
the heat produced by
is that data is
heat produced by so
implementing collaboration features using
a financial firm s
might argue that all
financial firm s new
of a larger migration
firm s new york
has a small number
s new york city
produced by so much
new york city data
perfect sense that the
york city data center
and the costs and
a larger migration of
the costs and characteristics
larger migration of a
collaboration features using these
migration of a sourceforge
argue that all reliability
features using these technologies
city data center may
that all reliability needs
using these technologies is
data center may receive
all reliability needs can
these technologies is problematic
that data is not
a small number of
data is not available
by so much computing
center may receive real
so much computing power
reliability needs can be
much computing power can
needs can be recast
computing power can be
small number of levels
power can be searing
sense that the marketing
technologies is problematic because
that the marketing community
such switching causes available
the marketing community would
can be recast in
switching causes available bandwidth
be recast in terms
an article in the
causes available bandwidth to
is problematic because collaborative
costs and characteristics of
problematic because collaborative applications
and characteristics of the
number of levels through
characteristics of the managed
even small code repositories
of the managed framework
article in the new
available bandwidth to oscillate
marketing community would feel
is not available in
community would feel that
not available in advance
would feel that finally
recast in terms of
small code repositories represent
in terms of transactions
code repositories represent a
because collaborative applications can
repositories represent a huge
of levels through the
represent a huge investment
they ve reached the
bandwidth to oscillate distributed
ve reached the promised
collaborative applications can generate
to oscillate distributed file
doing so sheds light
in the new york
levels through the use
the new york times
through the use of
reached the promised land
the use of modeless
applications can generate high
use of modeless adaptation
so sheds light on
a huge investment of
time updates from a
huge investment of developerhours
the past three decades
being generated just before
oscillate distributed file systems
generated just before transmission
new york times describes
just before transmission at
past three decades have
before transmission at the
bursty update rates and
transmission at the sender
and evaluate the possible
update rates and yet
york times describes one
sheds light on the
times describes one of
three decades have seen
light on the challenges
updates from a stock
decades have seen one
on the challenges of
so the need to
has an understandable emphasis
the need to store
distributed file systems are
need to store this
rates and yet often
to store this data
have seen one failed
store this data durably
describes one of google
this data durably and
one of google s
data durably and reliably
of google s data
durably and reliably is
google s data centers
and reliably is obvious
seen one failed attempt
evaluate the possible modes
an understandable emphasis on
file systems are a
the possible modes and
from a stock exchange
and yet often require
possible modes and chooses
one failed attempt after
yet often require low
modes and chooses the
failed attempt after another
often require low latencies
the challenges of working
less obvious are the
interested users ideally want
obvious are the shortcomings
understandable emphasis on facts
are the shortcomings of
and chooses the appropriate
the shortcomings of traditional
require low latencies and
chooses the appropriate one
systems are a common
users ideally want to
are a common feature
attempt after another to
a common feature of
emphasis on facts on
common feature of large
challenges of working in
on facts on the
the appropriate one based
a stock exchange in
ideally want to receive
stock exchange in switzerland
after another to build
shortcomings of traditional storage
another to build everything
low latencies and tight
to build everything over
facts on the ground
build everything over a
a computing center as
everything over a database
feature of large com
of traditional storage systems
of working in a
latencies and tight synchronization
appropriate one based on
and tight synchronization between
on the ground and
tight synchronization between collaborating
computing center as big
the ground and the
center as big as
conduct financial transactions with
as big as two
want to receive the
big as two football
over a database system
as two football fields
ground and the vogels
one based on the
financial transactions with banks
synchronization between collaborating users
transactions with banks in
to receive the stream
with banks in asia
and the vogels essay
with twin cooling plants
even when the mobile
twin cooling plants protruding
when the mobile host
and it s now
the mobile host is
the vogels essay reflects
it s now clear
cache data in london
cooling plants protruding four
data in london for
based on the benefit
in london for locality
working in a kind
london for locality and
vogels essay reflects the
for locality and mirror
one can often achieve
essay reflects the realities
mobile host is stationary
on the benefit of
reflects the realities of
in a kind of
s now clear that
protect against data loss
now clear that many
plants protruding four stories
clear that many kinds
receive the stream without
that many kinds of
the realities of an
many kinds of systems
but they are neither
realities of an architecture
can often achieve better
protruding four stories into
often achieve better performance
four stories into the
a kind of environment
stories into the sky
kinds of systems just
if it is to
of systems just don
it is to enputing
systems just don t
is to enputing environments
just don t match
locality and mirror it
don t match the
they are neither cheap
t match the model
the benefit of mechanisms
the stream without much
achieve better performance using
stream without much delay
better performance using direct
without much delay from
performance using direct client
much delay from its
kind of environment that
delay from its original
and mirror it to
from its original transmission
are neither cheap nor
benefit of mechanisms for
neither cheap nor simple
since they simplify sharing
of environment that will
of an architecture focused
environment that will be
these intrinsically distributed systems
that will be more
they simplify sharing data
intrinsically distributed systems make
especially when developers and
of mechanisms for improving
when developers and server
will be more and
mirror it to kansas
be more and more
simplify sharing data between
more and more prevalent
streaming systems now allow
sharing data between sure
developers and server administrators
data between sure that
and server administrators are
distributed systems make use
server administrators are geographically
mechanisms for improving file
administrators are geographically spread
systems now allow large
are geographically spread thin
it to kansas for
between sure that clients
to kansas for disaster
systems make use of
and more prevalent in
make use of direct
more prevalent in years
now allow large numbers
power conservation is an
sure that clients file
conservation is an important
an architecture focused at
is an important concern
prevalent in years to
an important concern for
in years to come
that clients file operations
but in today s
architecture focused at its
in today s soa
we focus on the
today s soa plat
important concern for big
use of direct communication
concern for big server
clients file operations are
for big server clusters
focused at its core
for improving file system
focus on the costs
improving file system performance
our insights should be
file system performance currently
allow large numbers of
system performance currently available
since disks account for
large numbers of interested
on the costs of
of direct communication between
insights should be of
file operations are executed
should be of value
to interconnect these bandwidth
be of value to
disks account for a
of value to developers
the costs of moving
value to developers of
at its core on
costs of moving source
band communication is hard
performance currently available bandwidth
communication is hard to
account for a significant
is hard to integrate
to developers of other
hard to integrate with
developers of other high
to integrate with hosted
of moving source code
numbers of interested users
direct communication between programs
for a significant fraction
communication between programs via
its core on using
between programs via the
integrate with hosted content
in the coda file
of interested users to
operations are executed in
interested users to receive
are executed in a
hungry data centers across
executed in a timely
programs via the trans
in a timely way
this problem is reflected
a significant fraction of
performance communication and event
significant fraction of the
core on using document
fraction of the energy
moving source code repositories
on using document exchange
current web services standards
problem is reflected by
using document exchange to
web services standards have
is reflected by a
services standards have many
users to receive streamed
standards have many critical
and can provide scalable
have many critical limitations
document exchange to access
source code repositories to
exchange to access backend
data centers across the
the coda file and
centers across the globe
of the energy consumed
can provide scalable and
reflected by a growing
provide scalable and highly
to access backend servers
scalable and highly available
coda file and cache
and highly available file
organizations are increasingly deploying
to receive streamed data
are increasingly deploying private
receive streamed data in
by a growing number
streamed data in near
highly available file ac
a growing number of
code repositories to the
growing number of publications
we propose a new
number of publications on
file and cache consistency
of publications on the
today s web services
publications on the integration
repositories to the cloud
on the integration of
several approaches for disk
to the cloud as
the integration of web
approaches for disk power
the cloud as an
s web services standards
cloud as an example
propose a new positioning
as an example of
a new positioning of
an example of moving
integration of web services
example of moving services
of web services with
of moving services in
web services with peer
data in near real
file system must adapt
in near real time
new positioning of multicast
increasingly deploying private lambda
positioning of multicast technology
this core has been
web services standards seem
core has been extended
services standards seem to
system must adapt to
without requiring extensive amounts
deploying private lambda networks
requiring extensive amounts of
as an extension of
extensive amounts of resources
standards seem to answer
for disk power management
seem to answer these
moving services in general
to answer these needs
has been extended with
an extension of the
must adapt to this
extension of the component
adapt to this variation
services in general to
raw bandwidth is ubiquitous
in general to the
these systems are based
bandwidth is ubiquitous and
and cache consistency using
of the component integration
been extended with such
the component integration features
a more probing analysis
systems are based on
more probing analysis reveals
are based on the
general to the cloud
disk power management have
extended with such mechanisms
power management have been
is ubiquitous and cheaply
cache consistency using microbenchmarks
ubiquitous and cheaply available
based on the peer
component integration features of
especially collaborative open source
management have been proposed
collaborative open source projects
consistency using microbenchmarks and
and cheaply available in
using microbenchmarks and file
integration features of the
microbenchmarks and file system
features of the microsoft
and file system system
cheaply available in the
such an endeavor includes
have been proposed and
an endeavor includes many
probing analysis reveals many
endeavor includes many costs
with such mechanisms as
supporting mobile clients requires
net managed runtime environment
such mechanisms as rpc
mobile clients requires coping
mechanisms as rpc and
analysis reveals many critical
as rpc and asynchronous
available in the form
rpc and asynchronous messaging
been proposed and studied
reveals many critical limitations
clients requires coping existing
the most critical of
requires coping existing systems
in the form of
coping existing systems tailored
most critical of which
existing systems tailored to
we will examine some
critical of which is
will examine some of
systems tailored to low
examine some of these
of which is storage
where nodes interested in
although we started with
which is storage since
the form of existing
some of these here
the cache manager operates
we started with a
bandwidth clients differenwith the
form of existing dark
nodes interested in receiving
of existing dark fiber
interested in receiving data
the major web services
in receiving data also
clients differenwith the atypical
receiving data also help
is storage since that
data also help disseminate
started with a sophisticated
also help disseminate it
cache manager operates in
help disseminate it to
a variety of roll
disseminate it to each
storage since that is
it to each other
running and maintaining high
since that is the
manager operates in either
that is the simplest
operates in either a
with a sophisticated multicast
in either a stronglytraces
but first let us
major web services standards
first let us lay
forward and rendezvous options
let us lay out
a sophisticated multicast protocol
us lay out some
alleviating the bottleneck at
lay out some of
free networks over this
out some of the
is the simplest and
some of the groundwork
the bottleneck at the
differenwith the atypical patterns
bottleneck at the source
web services standards dealing
the atypical patterns of
experiments reveal a series
but the primary usage
services standards dealing with
any disk power management
standards dealing with reliability
reveal a series of
networks over this fiber
a series of problematic
over this fiber is
atypical patterns of connectivity
this fiber is difficult
initial protocols were based
fiber is difficult and
the simplest and likely
series of problematic interactions
disk power management scheme
of problematic interactions between
the primary usage case
problematic interactions between its
is difficult and expensive
interactions between its high
patterns of connectivity that
simplest and likely first
of connectivity that characterise
protocols were based on
and likely first component
which affects the policy
likely first component to
connectivity that characterise them
first component to be
were based on building
component to be moved
affects the policy for
reliability provides for reliable
the policy for writing
processing logic and the
provides for reliable handoff
policy for writing changes
logic and the properties
capacity optical links are
and the properties of
primary usage case remains
optical links are almost
tiate between types of
links are almost never
for writing changes to
are almost never congested
writing changes to files
power management scheme essentially
changes to files back
for reliable handoff between
to files back to
we set an agenda
based on building a
the properties of the
on building a tree
management scheme essentially attempts
between types of file
scheme essentially attempts to
types of file system
essentially attempts to exploit
of file system communication
attempts to exploit one
properties of the managed
to exploit one fact
based overlay of nodes
they drop packets for
overlay of nodes through
usage case remains that
of nodes through which
of the managed framework
so that bandwhile a
set an agenda for
that bandwhile a desktop
files back to the
disks can be run
back to the server
can be run in
drop packets for numerous
be run in highpower
an agenda for demonstrating
run in highpower mode
nodes through which data
agenda for demonstrating the
through which data would
packets for numerous reasons
modal adaptation schemes are
reliable handoff between a
adaptation schemes are well
for demonstrating the financial
handoff between a client
case remains that of
demonstrating the financial storage
bandwhile a desktop client
which data would be
a desktop client is
data would be pushed
desktop client is well
the financial storage and
for numerous reasons dirty
between a client system
remains that of a
we addressed these and
introduction in which changes
with a corresponding performance
connected to a file
that of a client
to a file server
addressed these and achieved
a file server un
a client system and
a corresponding performance tradeoff
financial storage and computing
of a client sending
in which changes in
a client sending documents
client system and a
client sending documents to
these and achieved high
sending documents to a
width can be devoted
documents to a back
system and a queuing
which changes in bandwidth
and a queuing system
changes in bandwidth are
a disk can be
in bandwidth are relatively
disk can be shut
bandwidth are relatively predictable
can be shut off
a queuing system residing
be shut off so
and achieved high performance
shut off so that
end service in a
off so that it
service in a client
so that it consumes
storage and computing costs
achieved high performance by
and computing costs of
such as chainsaw and
computing costs of moving
as chainsaw and coolstreaming
that it consumes no
can be devoted to
it consumes no power
queuing system residing between
such as switching network
system residing between the
high performance by making
residing between the client
costs of moving source
between the client and
given a large cluster
of moving source code
performance by making some
moving source code repositories
be devoted to important
source code repositories to
have shown that the
code repositories to the
the assumption is that
repositories to the cloud
by making some unusual
assumption is that the
a large cluster of
shown that the use
large cluster of disks
the client and some
making some unusual architectural
is that the application
client and some service
that the use of
in section ii we
as switching network access
that the application can
switching network access from
the use of a
network access from an
section ii we explain
access from an ethernet
the application can tolerate
from an ethernet to
use of a mesh
an ethernet to a
some unusual architectural decisions
ethernet to a modem
only a fraction of
the standard isn t
yet the issue remains
standard isn t nearly
ii we explain what
isn t nearly as
a fraction of them
we explain what it
which we distill into
but mobility is now
t nearly as comprehensive
mobility is now an
a mobile client frequently
fraction of them is
mobile client frequently lacks
of them is accessed
client frequently lacks the
them is accessed at
the issue remains unresolved
is accessed at any
is now an major
accessed at any time
for example and in
explain what it means
example and in different
nearly as comprehensive as
what it means to
we distill into general
now an major feature
distill into general insights
and in different patterns
application can tolerate substantial
as comprehensive as the
can tolerate substantial delay
comprehensive as the name
an major feature of
as the name implies
it means to store
of a mesh of
tolerate substantial delay before
a mesh of connected
substantial delay before a
mesh of connected nodes
delay before a response
of connected nodes and
before a response arrives
cornell s live distributed
component integration environments such
s live distributed objects
means to store a
live distributed objects platform
it s limited to
major feature of computer
s limited to pipelines
feature of computer systems
so that the rest
connected nodes and a
that the rest could
nodes and a pull
integration environments such as
and mechanisms capable of
environments such as microsoft
to store a code
over the not as
the rest could potentially
the not as appropriate
mechanisms capable of introducing
not as appropriate in
store a code repository
as appropriate in for
rest could potentially be
appropriate in for wireless
based data dissemination approach
in for wireless networks
limited to pipelines that
data dissemination approach can
ranging from singleton drops
could potentially be switched
from singleton drops to
potentially be switched to
a code repository in
to pipelines that include
ee have become widely
live objects for short
capable of introducing delays
writes back changes to
of introducing delays are
in which bandwidth past
introducing delays are scattered
code repository in the
delays are scattered throughout
allow even a non
have become widely popular
singleton drops to extended
become widely popular with
be switched to a
widely popular with application
switched to a low
popular with application developers
repository in the cloud
are scattered throughout the
back changes to files
scattered throughout the architecture
which bandwidth past decade
pipelines that include queuing
dissemination approach can provide
that include queuing subsystems
in the cloud and
drops to extended bursts
the cloud and why
programmer to construct content
cloud and why there
the more basic assumption
changes to files asynbandwidth
who benefit from standardized
more basic assumption is
and why there are
approach can provide similar
since mode transitions consume
held devices capable of
mode transitions consume time
basic assumption is that
devices capable of wireless
rich solutions that blend
benefit from standardized memory
solutions that blend traditional
from standardized memory management
that blend traditional web
transitions consume time and
blend traditional web services
assumption is that it
traditional web services and
can provide similar results
web services and peer
provide similar results with
to files asynbandwidth to
similar results with better
capable of wireless availability
results with better resilience
why there are cost
of wireless availability is
consume time and power
files asynbandwidth to perform
is that it all
asynbandwidth to perform all
reliability boils down to
to perform all its
wireless availability is less
boils down to a
there are cost advantages
availability is less predictable
disk management schemes have
are cost advantages to
is less predictable and
management schemes have to
and to share them
with better resilience to
that it all boils
and performance analysis tools
noncongestion loss has been
down to a few
loss has been observed
less predictable and varies
has been observed on
to share them with
been observed on long
cost advantages to doing
performance analysis tools that
advantages to doing so
it all boils down
to a few options
schemes have to walk
predictable and varies over
haul networks as well
have to walk the
and varies over a
analysis tools that operate
varies over a larger
a few options that
over a larger possible
share them with others
few options that a
to walk the tightrope
all boils down to
section iii is a
tools that operate across
iii is a case
a larger possible network
is a case study
options that a client
a case study on
boils down to moving
that a client can
that operate across component
down to moving documents
operate across component boundaries
larger possible network access
to moving documents around
possible network access have
better resilience to failures
perform all its file
resilience to failures and
this is like creating
to failures and churn
case study on using
moving documents around whereas
study on using amazon
a client can use
on using amazon s
walk the tightrope of
using amazon s s
is like creating a
the tightrope of finding
nodes joining and leaving
like creating a slide
tightrope of finding the
creating a slide show
network access have become
documents around whereas the
access have become common
client can use to
around whereas the most
this paper describes quicksilver
of finding the right
paper describes quicksilver scalable
to host some popular
describes quicksilver scalable multicast
can use to tell
and wireless networks are
all its file operations
finding the right balance
its file operations in
host some popular open
file operations in a
use to tell the
operations in a timely
joining and leaving the
in a timely fashion
whereas the most basic
some popular open source
wireless networks are range
popular open source communities
the right balance between
after which the solution
right balance between power
the most basic assumption
balance between power consumption
and leaving the system
between power consumption and
to tell the queuing
power consumption and performance
which the solution can
and includes a cost
a new multicast platform
includes a cost analysis
tell the queuing system
the notion of insufficient
the solution can be
notion of insufficient bandwidth
solution can be shared
the queuing system whether
most basic assumption of
in section iv we
the solution space explored
of insufficient bandwidth can
can be shared in
insufficient bandwidth can vary
be shared in a
bandwidth can vary dependalso
solution space explored thus
can vary dependalso proliferating
assigns lower priorities to
space explored thus far
section iv we present
explored thus far in
basic assumption of a
queuing system whether or
new multicast platform designed
system whether or not
shared in a file
whether or not to
thus far in the
or not to reissue
assumption of a distributed
multicast platform designed to
nodes notify each other
iv we present an
notify each other of
lower priorities to asynmobile
each other of receipt
not to reissue a
other of receipt of
to reissue a request
of receipt of data
the inadequacy of commodity
receipt of data packets
inadequacy of commodity tcp
priorities to asynmobile file
applications that run on
of a distributed object
that run on hosts
reissue a request if
a distributed object system
and request packets from
ip in high bandwidthdelay
distributed object system is
platform designed to achieve
in a file or
designed to achieve high
a request if a
to achieve high performance
request if a failure
achieve high performance in
if a failure occurs
in high bandwidthdelay product
object system is that
run on hosts in
system is that the
we present an implementation
far in the literature
to asynmobile file systems
in the literature can
high performance in managed
the literature can be
a file or via
on hosts in wireless
file or via email
present an implementation that
or via email and
request packets from their
via email and opened
high bandwidthdelay product networks
email and opened on
literature can be divided
and opened on other
hosts in wireless neting
opened on other machines
an implementation that ties
asynmobile file systems typically
implementation that ties subversion
performance in managed environments
that ties subversion to
is that the world
ties subversion to s
and a way to
in wireless neting on
a way to timestamp
file systems typically assume
way to timestamp requests
can be divided as
to timestamp requests so
be divided as follows
timestamp requests so that
wireless neting on how
requests so that a
systems typically assume that
so that a service
that the world consists
that a service can
packets from their neighbors
a service can detect
neting on how much
service can detect duplicates
typically assume that a
the users are immersed
assume that a client
users are immersed in
that a client is
memoryrelated overheads and phenomena
a client is strongly
end servers running on
overheads and phenomena related
bandwidthdelay product networks is
from their neighbors based
product networks is extensively
on how much data
networks is extensively documented
transactions actually consists of
and phenomena related to
actually consists of two
their neighbors based on
consists of two side
servers running on amazon
how much data the
running on amazon s
are immersed in the
on amazon s ec
the world consists of
neighbors based on the
world consists of programs
based on the received
consists of programs and
immersed in the resulting
of programs and data
much data the application
and using yahoo s
on the received notifications
using yahoo s zookeeper
in the resulting collaborative
phenomena related to scheduling
the resulting collaborative application
chronous operations at the
one is aimed at
data the application is
active and passive objects
the application is trying
operations at the ip
application is trying to
related to scheduling are
is trying to send
yahoo s zookeeper for
practical systems based on
s zookeeper for consistency
systems based on pull
is aimed at applications
to scheduling are shown
at the ip level
scheduling are shown to
the gist of vogel
so that works must
they can interact with
based streaming now exist
that works must cope
can interact with the
in section v we
interact with the application
section v we evaluate
are shown to dominate
v we evaluate the
aimed at applications that
we evaluate the performance
works must cope with
evaluate the performance of
with the application and
the performance of this
the application and peers
performance of this solution
at applications that perform
the ip level to
must cope with constraints
each of these solutions
shown to dominate the
cope with constraints on
to dominate the behavior
applications that perform database
with constraints on access
streaming now exist in
of these solutions proposes
gist of vogel s
these solutions proposes a
and in section vi
solutions proposes a new
ip level to reduce
proposes a new system
constraints on access to
a new system of
application and peers see
new system of some
dominate the behavior of
system of some kind
that perform database transactions
level to reduce interference
perform database transactions with
on access to data
database transactions with the
and peers see the
transactions with the usual
the behavior of the
with the usual acid
behavior of the system
of vogel s essay
access to data that
vogel s essay is
in section vi we
based solutions propose novel
section vi we address
to reduce interference with
vi we address related
to data that are
s essay is that
peers see the results
essay is that even
see the results instantly
ip has three major
we discuss techniques that
has three major problems
we address related work
three major problems when
now exist in china
major problems when used
is that even with
problems when used over
discuss techniques that helped
data that are genit
techniques that helped us
updates are applied to
that helped us to
that even with all
helped us to alleviate
solutions propose novel storage
us to alleviate these
c loudifying s ource
propose novel storage hierarchies
where they are used
when used over such
even with all the
used over such networks
reduce interference with connected
are applied to all
to alleviate these problems
applied to all replicas
novel storage hierarchies to
they are used to
or the remote procedure
with all the contemplated
the remote procedure call
all the contemplated extensions
to all replicas in
and argue that they
all replicas in a
are used to disseminate
replicas in a consistent
loudifying s ource r
in a consistent manner
that are genit may
storage hierarchies to strike
web services are deeply
are genit may make
hierarchies to strike the
services are deeply mismatched
genit may make sense
to strike the right
are deeply mismatched with
interference with connected like
deeply mismatched with distributed
remote procedure call and
mismatched with distributed object
ip suffers throughput collapse
with distributed object computing
may make sense to
strike the right balance
make sense to adjust
with connected like a
the right balance between
connected like a desktop
in contrast to today
like a desktop host
suffers throughput collapse if
used to disseminate television
throughput collapse if the
sense to adjust network
collapse if the network
right balance between performance
if the network is
contrast to today s
the network is even
to today s web
network is even slightly
today s web service
is even slightly prone
s web service platforms
balance between performance and
connected and should foreground
s ource r epositories
and should foreground operations
procedure call and that
to adjust network usage
call and that can
even slightly prone to
adjust network usage when
between performance and power
network usage when the
performance and power consumption
limit its bandwidth consumption
and that can t
its bandwidth consumption to
that can t tolerate
to disseminate television channels
can t tolerate delay
argue that they reveal
usage when the bandwidth
the dilemma underlying the
disk management solutions interject
slightly prone to packet
dilemma underlying the debate
management solutions interject a
disseminate television channels to
underlying the debate is
when the bandwidth erally
p communication can coexist
the bandwidth erally not
prone to packet loss
ource r epositories in
these systems lack databases
r epositories in a
solutions interject a new
epositories in a revision
the debate is that
in a revision control
communication can coexist with
debate is that the
conservative flow control mechanisms
systems lack databases clean
is that the platforms
flow control mechanisms designed
lack databases clean separation
that the platforms one
control mechanisms designed to
databases clean separation of
the platforms one uses
clean separation of stored
interject a new disk
separation of stored data
a revision control system
of stored data from
that they reveal general
stored data from code
mechanisms designed to deal
they reveal general principles
platforms one uses to
reveal general principles applicable
a new disk management
general principles applicable to
can coexist with more
principles applicable to other
and any attempt to
applicable to other kinds
one uses to create
to other kinds of
a master copy of
other kinds of high
television channels to thousands
designed to deal with
channels to thousands of
to deal with the
any attempt to force
deal with the systematic
uses to create wscompatible
with the systematic congestion
master copy of the
the systematic congestion of
copy of the source
to thousands of users
of the source code
attempt to force them
rate protocols and applications
to create wscompatible objects
protocols and applications in
coexist with more standard
systematic congestion of the
create wscompatible objects impose
congestion of the commodity
to force them into
of the commodity internet
and applications in managed
the commodity internet react
with more standard solutions
new disk management layer
is stored in a
wscompatible objects impose no
force them into that
bandwidth erally not present
objects impose no such
erally not present in
even though the p
not present in wired
bandwidth consumption to a
present in wired networks
stored in a logically
them into that model
in a logically centralized
commodity internet react too
a logically centralized repository
internet react too sharply
disk management layer on
react too sharply to
applications in managed settings
distance from a base
impose no such restrictions
more standard solutions that
p paradigm allows systems
each developer checks out
management layer on top
into that model results
layer on top of
consumption to a minimum
on top of the
paradigm allows systems to
top of the file
from a base stadrops
of the file system
standard solutions that reach
introduction a component integration
allows systems to scale
that model results in
systems to scale with
there is nothing in
to scale with the
a component integration revolution
is nothing in j
developer checks out and
model results in unacceptable
solutions that reach back
results in unacceptable loss
a base stadrops by
in unacceptable loss of
base stadrops by half
unacceptable loss of performance
scale with the number
that reach back to
which controls disk configuration
reach back to the
checks out and then
back to the hosted
ms w n s
rather than just when
intrinsically distributed systems are
than just when it
distributed systems are common
just when it falls
component integration revolution is
when it falls to
controls disk configuration and
it falls to modem
out and then keeps
to the hosted content
w n s e
and then keeps a
n s e fig
disk configuration and data
and web services will
configuration and data layout
web services will need
adaptation by deferred transmission
services will need to
then keeps a working
will need to support
the hosted content and
keeps a working copy
hosted content and trigger
with the number of
content and trigger updates
net that warns a
need to support them
and data layout to
integration revolution is transforming
data layout to achieve
example lambda network ephemeral
revolution is transforming the
and trigger updates at
is transforming the development
trigger updates at the
a working copy on
updates at the associated
the number of users
at the associated data
lambda network ephemeral loss
that warns a user
network ephemeral loss on
transforming the development of
ephemeral loss on over
working copy on his
layout to achieve power
copy on his machine
contention with other hosts
on his machine that
warns a user that
his machine that mirrors
provisioned links a single
the associated data centers
links a single packet
optimal disk access patterns
with other hosts or
by deferred transmission of
the development of desktop
a user that an
development of desktop applications
it also leaves them
the existing reliability options
caching solutions devise new
a single packet in
solutions devise new power
single packet in ten
user that an intended
when an application needs
that an intended use
an application needs high
existing reliability options simply
application needs high data
packet in ten thousand
also leaves them vulnerable
in ten thousand is
other hosts or processes
ten thousand is enough
an intended use of
thousand is enough to
reliability options simply don
needs high data rates
aware caching algorithms that
platforms such as windows
leaves them vulnerable to
deferred transmission of file
hosts or processes on
transmission of file upwidth
or processes on the
is enough to reduce
processes on the same
enough to reduce tcp
on the same host
machine that mirrors the
intended use of the
that mirrors the repository
options simply don t
caching algorithms that allow
ee promote an application
of file upwidth lies
algorithms that allow large
simply don t address
them vulnerable to opportunistic
don t address the
it can use protocols
t address the requirement
promote an application development
file upwidth lies between
selecting a mode according
upwidth lies between these
ip throughput to a
lies between these extremes
throughput to a third
use of the architecture
can use protocols that
of the architecture may
that allow large fractions
the architecture may be
vulnerable to opportunistic behavior
architecture may be inappropriate
to a third over
assuming weak connectivity dates
a third over a
use protocols that bypass
weak connectivity dates has
allow large fractions of
the developer edits files
a lesson from the
developer edits files in
a mode according to
protocols that bypass the
connectivity dates has the
that bypass the data
opportunistic nodes attempt to
bypass the data center
lesson from the past
the data center to
mode according to the
data center to achieve
dates has the disadvantage
center to achieve the
and one in a
has the disadvantage of
edits files in his
from the past what
large fractions of the
according to the available
fractions of the storage
to the available bandwidth
to achieve the full
the available bandwidth can
achieve the full performance
the disadvantage of increasing
the full performance of
files in his working
disadvantage of increasing the
much of the excitement
of increasing the delay
nodes attempt to receive
increasing the delay before
available bandwidth can uninterference
the delay before upcan
an application development style
delay before upcan be
in his working copy
before upcan be too
of the excitement reflects
upcan be too conservative
attempt to receive a
the past what sorts
and switching between different
application development style in
of the storage system
his working copy and
the storage system to
the excitement reflects the
storage system to remain
to receive a stream
system to remain idle
since it delays sending
to remain idle for
one in a thousand
remain idle for longer
full performance of the
idle for longer periods
performance of the network
for longer periods of
receive a stream without
longer periods of time
it delays sending updates
working copy and periodically
delays sending updates to
excitement reflects the realization
this paper makes the
switching between different wireless
paper makes the following
a stream without uploading
between different wireless media
allowing them to be
stream without uploading their
them to be switched
without uploading their fair
to be switched to
uploading their fair share
be switched to lower
their fair share of
switched to lower power
fair share of data
to lower power modes
reflects the realization that
development style in which
the realization that with
in a thousand drops
realization that with web
different wireless media all
that with web services
past what sorts of
makes the following contributions
style in which components
copy and periodically commits
in which components are
sending updates to the
which components are implemented
updates to the dates
the principal contribution of
to the dates are
a thousand drops it
principal contribution of this
reducing the overall upload
interoperability really is easier
the overall upload capacity
components are implemented independently
we describe a new
are implemented independently and
describe a new class
and periodically commits the
a new class of
contribution of this paper
new class of service
overall upload capacity of
of this paper is
the dates are applied
implemented independently and heavily
dates are applied at
periodically commits the changes
developers have long struggled
commits the changes back
what sorts of scaling
the changes back to
this paper is to
changes back to the
independently and heavily reused
back to the repository
wireless media all necessarily
have long struggled with
media all necessarily constrain
long struggled with program
all necessarily constrain communication
paper is to argue
are applied at the
upload capacity of the
applied at the file
applications that integrate service
at the file server
is to argue that
sorts of scaling and
to argue that there
since it ignores what
and updates his working
by standardizing memory management
updates his working copy
standardizing memory management and
and therefore reduces the
of scaling and reliability
therefore reduces the deserver
argue that there is
scaling and reliability features
program interconnection and integration
capacity of the system
thousand drops it by
his working copy to
drops it by an
it ignores what data
it by an order
reduces the deserver in
ignores what data compound
and it is natural
despite the damage that
it is natural to
the damage that they
by an order of
damage that they may
that there is a
an order of magnitude
there is a fourth
what data compound the
is a fourth niche
that integrate service hosted
a fourth niche as
and reliability features are
fourth niche as yet
the deserver in order
niche as yet unexplored
working copy to reflect
data compound the variability
copy to reflect the
integrate service hosted content
compound the variability in
reliability features are lacking
memory management and type
features are lacking in
management and type checking
are lacking in web
that they may cause
lacking in web services
the variability in network
in web services standards
is natural to applaud
web services standards today
service hosted content with
these platforms enable safe
hosted content with peer
platforms enable safe and
to reflect the changes
enable safe and efficient
time or interactive applications
safe and efficient cross
variability in network performance
not much work has
natural to applaud a
much work has been
to applaud a widely
a good example is
applaud a widely adopted
in network performance to
a widely adopted advance
deserver in order to
work has been done
in order to aggregate
good example is data
we analyze two important
reflect the changes made
analyze two important examples
or interactive applications are
like it or not
order to aggregate modifications
interactive applications are impacted
we do not present
example is data replication
do not present a
the changes made by
not present a new
has been done in
present a new system
applications are impacted by
network performance to which
are impacted by the
changes made by other
impacted by the reliance
avoiding overheads associated with
by the reliance of
gree of consistency between
the reliance of reliability
performance to which apthe
reliance of reliability mechanisms
web services are becoming
of reliability mechanisms on
been done in studying
we take an idea
two important examples of
take an idea that
important examples of soc
to which apthe application
examples of soc applications
services are becoming a
reliability mechanisms on acknowledgments
are becoming a de
done in studying mechanisms
of consistency between clients
in studying mechanisms to
consistency between clients cached
studying mechanisms to avoid
between clients cached copies
overheads associated with protection
facto standard for everything
associated with protection boundaries
an idea that has
made by other developers
idea that has been
which apthe application actually
that has been around
mechanisms on acknowledgments and
that s not all
search and rescue mission
mechanisms to avoid their
and rescue mission and
each commit is assigned
has been around for
building a server that
been around for well
for its own this
a server that scales
to avoid their presence
rescue mission and virtual
commit is assigned a
mission and virtual worlds
around for well over
apthe application actually wants
for well over a
server that scales to
well over a decade
on acknowledgments and retransmissions
that scales to handle
based direct sales systems
its own this paper
application actually wants to
avoid their presence in
actually wants to send
their presence in live
wants to send over
direct sales systems are
to send over the
over a decade now
sales systems are turning
scales to handle load
our project is interested
limiting the latency of
own this paper examines
the latency of packet
is assigned a unique
latency of packet recovery
we list the key
of packet recovery to
project is interested in
packet recovery to at
this paper examines the
is interested in leveraging
to handle load often
the goal of this
interested in leveraging these
handle load often requires
goal of this the
systems are turning to
of this the authors
list the key challenges
this the authors were
the repository maintains complete
the key challenges that
load often requires replicating
repository maintains complete history
are turning to the
send over the network
turning to the ws
in leveraging these benefits
to the ws architecture
paper examines the effectiveness
leveraging these benefits to
often requires replicating data
maintains complete history so
requires replicating data on
the authors were supported
replicating data on multiple
key challenges that soc
data on multiple nodes
these benefits to help
on multiple nodes of
deferplications must adapt if
multiple nodes of a
the ws architecture as
nodes of a cluster
examines the effectiveness of
challenges that soc applications
the effectiveness of mafs
benefits to help developers
and argue that technological
must adapt if they
to help developers implement
adapt if they are
recovery to at least
if they are to
complete history so at
they are to perform
argue that technological evolution
history so at any
help developers implement robust
that technological evolution has
so at any point
authors were supported by
technological evolution has given
at any point in
were supported by afrl
evolution has given it
any point in time
developers implement robust and
are to perform well
ws architecture as a
another example is guaranteed
architecture as a means
example is guaranteed real
as a means of
has given it a
a means of enlarging
implement robust and scalable
means of enlarging their
that soc applications place
of enlarging their markets
supported by afrl award
point in time it
by afrl award fa
bandwidth client may decide
robust and scalable computing
ring writing back all
to at least the
soc applications place on
at least the round
in time it is
least the round trip
and scalable computing services
the round trip time
writing back all modifications
scalable computing services that
applications place on their
computing services that will
place on their runtime
a company that buys
on their runtime environments
back all modifications to
company that buys a
time it is possible
all modifications to files
that buys a cluster
it is possible to
client may decide to
buys a cluster probably
we describe a new
may decide to delay
describe a new class
services that will run
a new class of
given it a new
new class of multi
modifications to files may
a cluster probably wants
decide to delay sending
to files may not
cluster probably wants to
to delay sending a
files may not be
probably wants to guarantee
delay sending a file
may not be a
wants to guarantee that
sending a file system
is possible to check
to guarantee that some
that will run on
if delivery is sequenced
will run on clusters
it a new relevance
run on clusters or
layered mashups and contrast
on clusters or in
possible to check out
clusters or in datacenters
com has developed a
not be a sensible
has developed a web
a file system that
be a sensible this
guarantee that some service
file system that propagates
a sensible this paper
that some service will
to check out a
a new relevance today
check out a working
new relevance today as
out a working copy
relevance today as a
each lost packet acts
access library whereby third
lost packet acts as
system that propagates file
packet acts as a
sensible this paper focuses
acts as a virtual
some service will be
as a virtual road
mashups and contrast them
service will be responsive
that propagates file modifications
a working copy for
this paper focuses on
working copy for any
early users of our
block in the fifo
and contrast them with
in the fifo channel
contrast them with more
the fifo channel until
them with more traditional
fifo channel until it
party application developers can
channel until it is
will be responsive enough
propagates file modifications asynchronously
today as a natural
paper focuses on adaptation
as a natural power
users of our platform
focuses on adaptation techniques
until it is recovered
be responsive enough to
file modifications asynchronously file
responsive enough to keep
application developers can access
enough to keep its
on adaptation techniques for
to keep its customers
based approach to building
keep its customers happy
approach to building mashups
developers can access their
saving opportunity for large
can access their datacenters
adaptation techniques for management
access their datacenters from
of our platform are
their datacenters from a
characteristic of today s
datacenters from a diversity
of today s web
from a diversity of
today s web development
a diversity of end
modifications asynchronously file s
techniques for management policy
asynchronously file s update
the key insight is
our platform are creating
key insight is that
its customers happy even
copy for any specified
customers happy even when
file s update to
happy even when demand
platform are creating applications
we discuss the relative
for management policy if
for any specified version
ip requires massive buffers
any specified version number
even when demand is
requires massive buffers at
an application could order
where other solutions attempt
application could order thus
management policy if those
could order thus supplies
are creating applications in
order thus supplies directly
storing a repository in
thus supplies directly from
other solutions attempt to
supplies directly from amazon
policy if those are
when demand is high
if those are the
creating applications in areas
those are the only
a repository in the
are the only messages
solutions attempt to predict
the only messages available
discuss the relative advantages
only messages available to
the missing technologies don
messages available to send
massive buffers at the
attempt to predict disk
applications in areas such
s update to the
in areas such as
update to the file
areas such as parallelized
to the file server
such as parallelized data
of data accessed and
as parallelized data mining
repository in the cloud
missing technologies don t
query the fulfillment system
technologies don t stop
to predict disk access
don t stop there
data accessed and modified
in the cloud eliminates
event stream filtering software
the fulfillment system to
the cloud eliminates worries
the relative advantages of
cloud eliminates worries of
relative advantages of these
buffers at the communicating
advantages of these two
fulfillment system to track
of these two approaches
accessed and modified by
these two approaches for
and modified by mobile
two approaches for building
modified by mobile hosts
predict disk access to
system to track order
disk access to determine
to track order status
but this decision may
track order status or
at the communicating endhosts
order status or billing
we investigate we describe
the communicating endhosts to
access to determine which
communicating endhosts to fully
to determine which disks
approaches for building soc
determine which disks to
status or billing data
which disks to power
investigate we describe mfs
disks to power down
this decision may also
endhosts to fully exploit
decision may also affect
for building soc applications
may also affect at
and scalable web services
also affect at all
to fully exploit the
affect at all bandwidth
eliminates worries of data
at all bandwidth levels
cycle services that can
fully exploit the bandwidth
we discuss the advantages
exploit the bandwidth of
both the vendor and
the bandwidth of a
services that can launch
bandwidth of a long
rather than delaying writes
that can launch an
a flexible cache adaptation
the vendor and the
worries of data loss
vendor and the application
discuss the advantages of
and the application developer
the lfs automatically provides
the advantages of decoupling
developers of clustered services
of data loss due
mafs other clients that
data loss due to
flexible cache adaptation in
loss due to hardware
lfs automatically provides a
due to hardware failure
of clustered services need
can launch an application
clustered services need reliable
the application developer benefit
services need reliable multicast
advantages of decoupling transport
need reliable multicast protocols
even in the absence
reliable multicast protocols for
in the absence of
cache adaptation in the
the absence of packet
of decoupling transport and
absence of packet loss
other clients that would
decoupling transport and information
multicast protocols for data
automatically provides a perfect
protocols for data replication
but issues of access
launch an application on
issues of access control
transport and information layers
of access control and
adaptation in the context
access control and consistency
in the context of
an application on demand
the context of mfs
and information layers as
provides a perfect prediction
information layers as a
a perfect prediction mechanism
control and consistency must
resistant alternatives to tcp
and consistency must still
application on demand or
consistency must still be
and in light of
layers as a means
com enlarges its client
ip is not feasible
clients that would like
enlarges its client base
must still be addressed
simply by virtue of
as a means of
by virtue of the
a means of achieving
virtue of the fact
means of achieving reusability
of the fact that
in light of our
authorized users should be
is not feasible in
on demand or restart
not feasible in corporate
while the developer avoids
feasible in corporate data
a client cache manager
in corporate data centers
users should be able
client cache manager for
demand or restart a
cache manager for a
the developer avoids duplicating
ability to rapidly deploy
that would like to
should be able to
would like to read
or restart a failed
like to read the
light of our broader
to read the file
to rapidly deploy soc
of our broader goal
the fact that all
be able to commit
fact that all write
restart a failed component
developer avoids duplicating an
where standardization is the
avoids duplicating an enormous
optimistic concuruses rpc priorities
duplicating an enormous technology
able to commit new
concuruses rpc priorities to
our broader goal of
standardization is the key
manager for a manager
is the key to
accesses go to the
the key to low
go to the log
key to low and
to the log head
to low and predictable
an enormous technology investment
low and predictable maintenance
rapidly deploy soc applications
and predictable maintenance costs
or load balancers and
rpc priorities to reduce
broader goal of leveraging
for a manager for
priorities to reduce interference
deploy soc applications in
load balancers and technology
to commit new versions
explains and expands on
balancers and technology to
commit new versions of
soc applications in new
new versions of files
goal of leveraging the
versions of files to
to reduce interference between
of files to the
web service components will
files to the repository
neither is eliminating loss
service components will play
a manager for a
is eliminating loss events
and expands on this
reduce interference between read
expands on this idea
applications in new environments
interference between read and
of leveraging the power
in new environments and
between read and rency
leveraging the power and
new environments and adapt
read and rency control
manager for a distributed
eliminating loss events on
for a distributed file
components will play a
a distributed file system
the power and component
distributed file system client
and rency control and
and technology to automate
loss events on a
but not edit existing
events on a network
not edit existing history
on a network that
the views and conclusions
which differs from distributed
will play a critical
environments and adapt them
play a critical role
rency control and reconciliation
a critical role in
users expect the repository
control and reconciliation of
differs from distributed file
power and component integration
from distributed file system
and adapt them dynamically
a network that could
adapt them dynamically this
views and conclusions herein
them dynamically this work
expect the repository to
dynamically this work was
idea overview to see
we concentrate on distributed
technology to automate management
network that could span
critical role in tremendous
and conclusions herein are
role in tremendous numbers
the repository to be
in tremendous numbers of
and component integration features
tremendous numbers of end
concentrate on distributed file
to automate management of
that could span thousands
and reconciliation of conflicting
could span thousands of
this work was supported
span thousands of miles
repository to be consistent
component integration features of
on distributed file systraditional
integration features of a
conclusions herein are those
features of a managed
herein are those of
to be consistent and
automate management of a
distributed file systraditional cache
management of a machine
overview to see why
of a machine cluster
the challenge is to
a machine cluster running
there is a need
machine cluster running web
file systraditional cache manager
cluster running web services
to see why lfs
running web services applications
be consistent and for
challenge is to make
consistent and for any
is to make such
of a managed framework
to make such systems
are those of the
make such systems work
those of the authors
is a need to
and for any changes
systraditional cache manager design
for any changes they
see why lfs is
cache manager design in
the multicast technology must
why lfs is a
qi huang is a
lfs is a natural
reconciliation of conflicting updates
is a natural solution
a need to mask
a natural solution to
multicast technology must run
natural solution to the
technology must run in
solution to the problem
must run in a
working groups within the
run in a managed
need to mask loss
in a managed setting
huang is a visiting
such systems work reliably
is a visiting scientist
to the problem of
a visiting scientist from
groups within the world
visiting scientist from the
within the world wide
but little is known
manager design in two
outages that plague human
design in two important
to mask loss on
in two important respects
of conflicting updates are
the world wide web
conflicting updates are typwrite
world wide web consortium
any changes they make
that plague human users
changes they make not
mask loss on the
they make not to
the problem of disk
make not to be
scientist from the school
plague human users of
from the school of
loss on the link
the school of computer
problem of disk power
school of computer sci
little is known about
human users of web
is known about highperformance
tems because systems in
known about highperformance protocols
not to be pre
because systems in this
updates are typwrite traffic
users of web browsers
are typwrite traffic at
of disk power management
about highperformance protocols in
systems in this area
highperformance protocols in managed
of web browsers don
protocols in managed environments
on the link from
huazhong university of sci
the link from the
consider some of the
web browsers don t
some of the challenges
typwrite traffic at low
of the challenges involved
even in the face
in this area are
in the face of
link from the commodity
this area are highly
the primary organization developing
it is interesting to
primary organization developing web
the face of cloud
organization developing web services
from the commodity protocols
developing web services standards
browsers don t cause
is interesting to realize
don t cause much
server systems typically are
interesting to realize that
area are highly developed
systems typically are not
supported by the chinese
are highly developed and
by the chinese nsfc
t cause much harm
to realize that although
the commodity protocols running
realize that although microsoft
not one is addressing
that although microsoft pro
one is addressing these
traffic at low bandwidth
is addressing these kinds
typically are not idle
addressing these kinds of
highly developed and have
these kinds of issues
face of cloud services
developed and have mfs
outages could disrupt a
of cloud services that
and have mfs uses
cloud services that offer
to ensure that file
services that offer lesser
are not idle long
that offer lesser guarantees
this research was supported
have mfs uses an
research was supported by
ensure that file modifications
was supported by afrl
commodity protocols running at
not idle long enough
protocols running at end
mfs uses an rpc
for these reasons we
that file modifications ically
could disrupt a computer
file modifications ically used
if with additional support
uses an rpc library
with additional support from
idle long enough to
additional support from afosr
modifications ically used to
these reasons we do
ically used to resolve
a similar dynamic played
used to resolve inconsistencies
and to do so
reasons we do not
to do so rapidly
an rpc library supporting
computer pathway buried deep
long enough to make
we do not expect
enough to make it
similar dynamic played out
to make it worthwhile
dynamic played out in
do so rapidly and
played out in the
rpc library supporting priorities
out in the early
make it worthwhile to
library supporting priorities to
so rapidly and transparently
pathway buried deep within
do not expect that
it worthwhile to incur
supporting priorities to enable
buried deep within an
priorities to enable modewell
worthwhile to incur the
to enable modewell understood
to incur the time
not expect that clients
deep within an application
enable modewell understood semantics
expect that clients will
within an application on
because recovery delays for
an application on which
minimum and average download
application on which an
recovery delays for lost
on which an enterprise
power expense of switching
which an enterprise has
and average download rates
an enterprise has become
delays for lost packets
enterprise has become dependent
that clients will be
expense of switching the
department of computer science
of switching the disk
although the techniques we
switching the disk to
when bandwidth are rapidly
the disk to a
average download rates across
disk to a lowpower
the techniques we describe
to a lowpower mode
server computing was touted
bandwidth are rapidly propagated
computing was touted as
it is too easy
was touted as the
clients will be directly
techniques we describe less
will be directly using
we describe less adaptation
download rates across all
is too easy to
rates across all nodes
for lost packets translate
across all nodes when
are rapidly propagated to
all nodes when using
touted as the next
nodes when using the
and switching it back
when using the bar
be directly using the
layered mashup to the
too easy to dismiss
as the next big
lost packets translate into
the next big thing
using the bar gossip
rapidly propagated to the
the bar gossip and
mashup to the changing
bar gossip and chainsaw
switching it back when
gossip and chainsaw protocols
directly using the cloud
propagated to the clients
using the cloud storage
to the clients that
the cloud storage api
the clients that need
cloud storage api anytime
clients that need them
storage api anytime soon
packets translate into dramatic
it back when it
a silver bullet to
translate into dramatic reductions
easy to dismiss these
to the changing needs
into dramatic reductions in
but that they will
which allocates available bandwidth
that they will contact
mafs is very low
they will contact one
to dismiss these concerns
back when it is
we discuss the resulting
when it is accessed
allocates available bandwidth based
paper is to propose
will contact one of
is to propose and
dismiss these concerns by
to propose and evaluate
discuss the resulting objectoriented
propose and evaluate a
this can be an
and evaluate a mechanism
contact one of a
evaluate a mechanism that
these concerns by arguing
a mechanism that can
concerns by arguing that
mechanism that can defend
dramatic reductions in application
can be an acceptable
silver bullet to solve
one of a set
available bandwidth based should
the resulting objectoriented perspective
this is a notable
by arguing that the
that can defend against
be an acceptable price
can defend against this
of a set of
an acceptable price to
is a notable point
acceptable price to pay
in which instances of
price to pay for
bandwidth based should be
to pay for the
arguing that the web
pay for the abilalso
a notable point of
for the abilalso incorporates
because applications and os
notable point of difference
the abilalso incorporates a
applications and os networking
point of difference between
that the web is
and os networking stacks
the web is extremely
based should be broadly
web is extremely scalable
abilalso incorporates a new
is extremely scalable and
incorporates a new invalidation
extremely scalable and robust
a set of front
os networking stacks in
bullet to solve every
should be broadly applicable
defend against this problem
which instances of distributed
of difference between server
networking stacks in commodity
to solve every problem
be broadly applicable in
based update propagation ity
whithout incurring large overheads
but this ignores the
difference between server systems
this ignores the way
stacks in commodity data
ignores the way we
broadly applicable in other
the way we use
applicable in other application
way we use the
the embedding of qsm
between server systems and
embedding of qsm into
in commodity data centers
of qsm into windows
the approach that most
update propagation ity to
approach that most closely
in other application environments
that most closely relates
solve every problem related
most closely relates to
instances of distributed communication
closely relates to our
commodity data centers cannot
relates to our work
propagation ity to continue
we use the web
ity to continue accessing
every problem related to
to continue accessing a
end servers that are
continue accessing a file
data centers cannot be
accessing a file server
on the types of
server systems and typical
the types of messages
problem related to older
types of messages being
servers that are responsible
of messages being sent
centers cannot be rewritten
but if bandwidth is
cannot be rewritten from
if bandwidth is less
of distributed communication protocols
bandwidth is less scheme
to our work is
distributed communication protocols are
our work is the
qsm into windows yielded
systems and typical mobile
into windows yielded an
related to older mainframe
windows yielded an unexpected
unlike previous mobile file
by assigning priorities such
previous mobile file systems
communication protocols are modeled
assigning priorities such as
and typical mobile device
that are responsible for
typical mobile device scenarios
to older mainframe and
yielded an unexpected benefit
older mainframe and batch
be rewritten from scratch
mainframe and batch systems
priorities such as caching
a human can deal
are responsible for enforcing
human can deal with
responsible for enforcing access
such as caching dynamic
for enforcing access control
protocols are modeled uniformly
can deal with the
companies rushed to move
deal with the many
rushed to move everything
with the many error
are modeled uniformly as
the many error conditions
as caching dynamic internet
many error conditions the
to move everything from
error conditions the web
modeled uniformly as objects
conditions the web exposes
and pushing the data
client consistency is achievable
pushing the data into
work is the bar
the data into the
is the bar gossip
data into the cloud
the bar gossip protocol
caching dynamic internet content
handling those conditions in
which makes it hard
those conditions in a
uniformly as objects similar
conditions in a seamless
dynamic internet content or
codaniques that are oblivious
internet content or caching
makes it hard to
content or caching to
side appliance receiver buffer
which employs a tit
these might consist of
it enables what we
might consist of virtualized
move everything from mainframe
consist of virtualized server
or caching to improve
of virtualized server instances
appliance receiver buffer overflow
virtualized server instances in
that are oblivious to
server instances in the
it hard to translate
instances in the cloud
as objects similar to
hard to translate the
automated manner is an
tat approach for encouraging
manner is an entirely
are oblivious to the
is an entirely different
caching to improve appropriately
an entirely different challenge
to translate the solutions
local recovery locations of
enables what we are
recovery locations of packet
everything from mainframe settings
locations of packet loss
or traditional physical machines
of packet loss receive
translate the solutions devised
approach for encouraging nodes
what we are calling
for encouraging nodes to
from mainframe settings to
encouraging nodes to contribute
traditional physical machines owned
when we take what
physical machines owned by
we are calling live
machines owned by the
mainframe settings to client
the solutions devised for
oblivious to the exact
solutions devised for mobile
to the exact bandwidth
devised for mobile devices
are calling live distributed
for mobile devices to
a node only sends
mobile devices to server
side appliance receiving end
devices to server systems
objects similar to those
the exact bandwidth level
similar to those in
calling live distributed objects
to those in java
node only sends as
we take what was
only sends as much
as we shall see
take what was once
owned by the community
and can like file
sends as much data
can like file systems
as much data to
what was once a
much data to another
as the term suggests
data to another node
like file systems therefore
to another node as
but in either case
was once a batch
such as retrieving files
access to a small
file systems therefore switch
to a small subset
in either case their
a small subset of
maelstrom communication path forward
these are abstract data
communication path forward error
systems therefore switch between
can the performance of
there were notable successes
the performance of interactions
either case their local
performance of interactions with
are abstract data types
of interactions with web
once a batch service
interactions with web services
small subset of disks
but it quickly became
another node as it
case their local storage
path forward error correction
abstract data types in
therefore switch between a
data types in which
switch between a low
we evaluate proceed concurrently
node as it receives
their local storage systems
evaluate proceed concurrently with
the embedded script is
types in which content
proceed concurrently with background
embedded script is often
in which content evolves
local storage systems are
which content evolves over
it quickly became apparent
content evolves over time
a batch service or
concurrently with background activities
script is often tightly
when combined with a
with background activities such
is a promising solution
as it receives back
a promising solution for
when an application binds
storage systems are allowed
an application binds to
combined with a cache
application binds to a
with a cache that
binds to a live
it provides an elegant
to a live object
is often tightly integrated
systems are allowed to
background activities such as
are allowed to be
batch service or a
allowed to be cheap
a cache that absorbs
to be cheap and
cache that absorbs read
often tightly integrated with
quickly became apparent that
activities such as writing
became apparent that the
service or a web
apparent that the early
provides an elegant solution
the current state of
an elegant solution shown
tightly integrated with backend
elegant solution shown to
such as writing the
solution shown to tolerate
or a web site
shown to tolerate both
be cheap and unresilient
to tolerate both opportunistic
promising solution for reliability
tolerate both opportunistic behavior
solution for reliability over
both opportunistic behavior and
as writing the authors
opportunistic behavior and other
a web site and
current state of the
web site and transform
integrated with backend services
site and transform it
results in long disk
and transform it into
that the early platforms
transform it into a
writing the authors were
cheap and unresilient against
state of the object
and unresilient against hardware
with backend services in
unresilient against hardware failure
in long disk idle
behavior and other malicious
long disk idle periods
and other malicious attacks
the authors were supported
writes mode and a
of the object is
mode and a synchronous
backend services in the
the early platforms were
services in the data
low predictability of idle
in the data center
predictability of idle periods
another consideration with any
it into a web
consideration with any hosting
into a web service
for reliability over long
the object is imported
authors were supported in
early platforms were strikingly
with any hosting solution
platforms were strikingly immature
making it awkward to
were supported in part
acthe authors were supported
there is no way
any hosting solution is
authors were supported in
it awkward to access
supported in part by
processes needed to be
in part by darpa
needed to be automated
part by darpa under
to be automated and
object is imported and
be automated and standardized
is no way to
tat does present a
have shown that there
does present a few
by darpa under afrl
shown that there exists
is imported and the
no way to enforce
and the early generations
that there exists low
way to enforce appropriate
awkward to access the
there exists low correlation
hosting solution is resource
imported and the object
solution is resource provisioning
present a few undesirable
the early generations of
a few undesirable requirements
darpa under afrl grant
to access the underlying
under afrl grant radc
were supported in part
afrl grant radc back
and the object can
supported in part by
early generations of client
exists low correlation between
access the underlying services
packet recovery latency is
grant radc back changes
recovery latency is independent
to enforce appropriate patterns
latency is independent of
server systems cost a
low correlation between a
systems cost a fortune
open source communities with
correlation between a given
the object can send
source communities with limited
enforce appropriate patterns of
is independent of the
appropriate patterns of use
cost a fortune to
the data source should
in part by darpa
under the assurance that
a fortune to build
object can send and
communities with limited budgets
can send and receive
what s to stop
data source should ensure
part by darpa under
source should ensure that
the assurance that if
the underlying services directly
assurance that if bandwidth
with limited budgets and
that if bandwidth becomes
s to stop a
if bandwidth becomes f
by darpa under afrl
should ensure that packets
independent of the rtt
ensure that packets are
underlying services directly from
send and receive updates
services directly from a
and receive updates at
directly from a different
receive updates at high
darpa under afrl grant
updates at high data
of the rtt of
at high data rates
between a given idle
required armies of systems
to stop a web
armies of systems administrators
that packets are evenly
of systems administrators and
limited budgets and private
systems administrators and specialists
an object could be
from a different script
object could be a
under afrl grant radc
could be a place
the rtt of the
be a place in
budgets and private enterprises
a place in a
a different script or
place in a game
afrl grant radc cording
in a game like
rtt of the link
a game like second
stop a web client
game like second life
packets are evenly spread
different script or a
are evenly spread across
grant radc cording to
evenly spread across the
and private enterprises that
spread across the system
a given idle period
across the system by
and were extremely insecure
the system by sending
a web client from
system by sending data
private enterprises that are
by sending data to
given idle period s
sending data to a
while fec codes have
web client from trying
fec codes have been
enterprises that are increasingly
codes have been used
client from trying to
data to a fixed
from trying to download
to a fixed proportion
radc cording to the
that are increasingly cost
cording to the available
have been used for
to the available bandwidth
script or a standalone
trying to download amazon
or a standalone client
idle period s duration
the total cost of
period s duration and
a fixed proportion of
been used for decades
fixed proportion of nodes
total cost of ownership
used for decades within
com s entire catalog
live objects are a
s duration and the
objects are a natural
sensitive may well prefer
in a wireless f
and by sending different
may well prefer to
are a natural and
well prefer to pay
a natural and powerful
prefer to pay just
natural and powerful idea
to pay just for
the only way such
duration and the duration
the only answer is
only way such services
cost of ownership proved
pay just for the
by sending different packets
just for the resources
sending different packets to
way such services can
different packets to different
for decades within link
such services can be
and the duration of
and by afosr under
the duration of previous
by afosr under muri
duration of previous idle
afosr under muri grant
of previous idle periods
under muri grant f
packets to different nodes
and we plan to
for the resources they
we plan to pursue
of ownership proved to
plan to pursue the
the resources they use
to pursue the concept
ownership proved to be
pursue the concept in
this variability makes it
the concept in future
faster commodity processors have
variability makes it difficult
one might argue that
makes it difficult to
rather than trying to
it requires the source
proved to be unexpectedly
requires the source and
services can be mashed
the source and all
might argue that none
source and all nodes
than trying to budget
argue that none of
to be unexpectedly and
concept in future work
be unexpectedly and unacceptably
it difficult to devise
unexpectedly and unacceptably high
commodity processors have enabled
trying to budget in
processors have enabled packet
can be mashed up
and all nodes to
difficult to devise effective
all nodes to have
to budget in advance
the lesson of the
that none of these
lesson of the client
nodes to have full
none of these uses
to have full membership
this use of qsm
have full membership knowledge
be mashed up with
use of qsm raises
to devise effective predictive
mashed up with other
of qsm raises performance
budget in advance what
up with other web
level fec at end
these restrictions affect scalability
with other web content
of these uses are
qsm raises performance and
in advance what they
server era is that
advance what they are
restrictions affect scalability when
what they are going
these uses are what
they are going to
devise effective predictive mechanisms
are going to need
other web content is
effective predictive mechanisms for
raises performance and scalability
predictive mechanisms for disk
era is that incomplete
mechanisms for disk idle
web content is by
for disk idle times
performance and scalability issues
cloud computing makes this
is that incomplete platforms
computing makes this a
content is by either
affect scalability when the
and by afosr under
scalability when the data
uses are what the
when the data source
makes this a possibility
the data source has
and scalability issues beyond
by afosr under muri
the lfs neatly circumvents
afosr under muri grant
are what the architecture
under muri grant f
data source has bounded
scalability issues beyond the
source has bounded upload
lfs neatly circumvents this
has bounded upload bandwidth
what the architecture is
neatly circumvents this problem
that incomplete platforms can
issues beyond the ones
incomplete platforms can t
and increased competition among
platforms can t support
circumvents this problem by
can t support major
beyond the ones seen
the architecture is intended
the ones seen in
architecture is intended to
ones seen in our
is intended to support
to illustrate this problem
increased competition among providers
is by either having
this problem by predetermining
by either having the
competition among providers of
either having the data
not so many years
among providers of commodity
having the data center
so many years ago
my concern is that
seen in our original
we fixed the upload
in our original target
fixed the upload capacity
the data center compute
the upload capacity of
concern is that the
upload capacity of a
providers of commodity services
our original target domain
rather than the foreground
data center compute the
than the foreground ones
capacity of a data
is that the web
of commodity services will
problem by predetermining which
commodity services will ensure
end fec is very
by predetermining which disk
services will ensure that
fec is very attractive
predetermining which disk is
of a data source
which disk is written
a data source at
additional support from microsoft
server architectures faltered over
support from microsoft research
is very attractive for
from microsoft research and
center compute the mashup
mbps and simulated bar
we leave detailed discussion
and simulated bar gossip
architectures faltered over precisely
simulated bar gossip when
very attractive for communication
bar gossip when streaming
disk is written to
will ensure that prices
leave detailed discussion of
ensure that prices are
faltered over precisely this
that prices are reasonable
attractive for communication between
is written to at
for communication between data
written to at all
communication between data centers
to at all times
over precisely this type
so that it can
precisely this type of
detailed discussion of the
kbps with increasing numbers
that the web services
with increasing numbers of
this type of situation
the web services community
c ase s tudy
that it can be
increasing numbers of receivers
microsoft research and from
discussion of the idea
research and from the
of the idea for
and from the intel
the idea for the
from the intel corporation
idea for the future
web services community is
easy to deploy and
services community is about
to deploy and customize
server systems are often
it can be accessed
server technologies of the
can be accessed via
qsm has been available
systems are often constrained
has been available for
community is about to
been available for free
is about to face
varied between one and
about to face the
between one and thirty
to face the same
one and thirty thousand
face the same problem
and thirty thousand nodes
be accessed via the
and does not require
accessed via the minibrowser
by far the most
variations in bandwidth can
available for free download
we compare its scalability
in bandwidth can occur
platform developers are racing
far the most popular
bandwidth can occur without
application programs background processing
for free download since
does not require specialized
s were widely seen
programs background processing incoming
not require specialized equipment
the most popular general
can occur without the
background processing incoming traffic
most popular general purpose
developers are racing forward
are often constrained by
are racing forward at
or by embedding the
racing forward at top
free download since mid
forward at top speed
occur without the user
popular general purpose cloud
processing incoming traffic cache
were widely seen as
often constrained by service
widely seen as a
incoming traffic cache consistency
seen as a kind
jostling for position with
as a kind of
traffic cache consistency demand
a kind of panacea
constrained by service level
compare its scalability against
without the user s
its scalability against the
require specialized equipment in
scalability against the chainsaw
for position with ever
against the chainsaw protocol
cache consistency demand fetch
a silver bullet that
general purpose cloud storage
silver bullet that would
purpose cloud storage service
by embedding the entire
cloud storage service today
by service level agreements
storage service today is
consistency demand fetch access
service today is amazon
bullet that would slay
today is amazon s
demand fetch access monitoring
is amazon s s
service level agreements to
specialized equipment in the
for which we fixed
equipment in the network
which we fixed the
that would slay evil
we fixed the source
fetch access monitoring prefetch
fixed the source s
position with ever more
the source s upload
access monitoring prefetch outgoing
source s upload bandwidth
would slay evil mainframe
s upload bandwidth to
monitoring prefetch outgoing traffic
slay evil mainframe architectures
we chose to use
prefetch outgoing traffic synchronous
the user s with
and it has a
level agreements to guarantee
it has a number
in the network linking
has a number of
enterprises fell over themselves
a number of users
user s with additional
embedding the entire minibrowser
agreements to guarantee a
the entire minibrowser window
to guarantee a certain
the network linking the
guarantee a certain level
network linking the data
s with additional support
linking the data centers
we present the average
with additional support from
present the average and
fell over themselves in
the average and minimum
a certain level of
average and minimum download
with ever more exaggerated
certain level of performance
outgoing traffic synchronous writeback
additional support from microsoft
most working on clustered
support from microsoft research
working on clustered computing
and minimum download rates
entire minibrowser window in
endhost fec has two
minibrowser window in a
fec has two major
window in a web
has two major issues
in a web page
as ratios of the
so that finding a
over themselves in a
chose to use this
themselves in a kind
ever more exaggerated claims
in a kind of
two major issues first
a kind of technology
but an embedded minibrowser
from microsoft research and
to use this as
microsoft research and from
one large project is
research and from the
while closing their eyes
and from the intel
an embedded minibrowser can
from the intel corporation
use this as a
ratios of the stream
that finding a solution
large project is pairing
kind of technology gold
project is pairing qsm
closing their eyes to
is pairing qsm with
embedded minibrowser can t
pairing qsm with high
of the stream rate
minibrowser can t seamlessly
it s not transparent
can t seamlessly blend
traffic synchronous writeback update
t seamlessly blend with
this as a basis
synchronous writeback update logging
of technology gold rush
as a basis for
writeback update logging asynchronous
seamlessly blend with the
finding a solution that
blend with the surrounding
speed event stream filtering
with the surrounding content
so that changing modes
a basis for cost
that changing modes creates
requiring modification of the
changing modes creates unexpected
modification of the end
modes creates unexpected incon
event stream filtering and
it is like a
update logging asynchronous writeback
is like a standalone
of both protocols when
like a standalone browser
their eyes to the
a standalone browser within
stream filtering and data
standalone browser within its
logging asynchronous writeback mfs
browser within its own
both protocols when the
within its own frame
several clients concurrently modify
eyes to the dangerous
clients concurrently modify a
filtering and data mining
concurrently modify a file
asynchronous writeback mfs server
only to discover that
writeback mfs server adaptive
and runs independent of
to the dangerous potholes
runs independent of the
and data mining system
independent of the rest
basis for cost studies
of the rest of
mfs server adaptive rpc
the rest of the
the dangerous potholes in
rest of the page
it s not necessarily
data mining system to
the final contents depend
mining system to obtain
for cost studies and
system to obtain a
server adaptive rpc library
to obtain a scalable
to illustrate this point
adaptive rpc library mfs
to discover that the
rpc library mfs cache
a solution that provides
library mfs cache manager
protocols when the number
solution that provides acceptable
s not necessarily rapid
final contents depend on
discover that the technology
contents depend on the
that the technology had
dangerous potholes in the
the technology had been
potholes in the road
technology had been oversold
in the road ahead
depend on the client
when the number of
on the client that
the number of nodes
cost studies and for
fec works best over
studies and for the
works best over high
hosted service capable of
the client that closed
service capable of handling
the figures are screenshots
that provides acceptable performance
figures are screenshots of
architectural standards for scalability
provides acceptable performance to
client that closed it
stable traffic rates and
that closed it last
and for the implementation
the total cost of
for the implementation of
number of nodes is
standards for scalability to
of nodes is increased
acceptable performance to only
for scalability to properly
traffic rates and performs
scalability to properly address
total cost of ownership
to properly address scalability
mfs cache manager will
properly address scalability in
cache manager will be
a client can lock
manager will be penalised
rates and performs poorly
will be penalised first
cost of ownership for
and performs poorly if
bar gossip is not
address scalability in web
are screenshots of web
scalability in web services
the implementation of our
capable of handling very
implementation of our system
of ownership for clientserver
modeless adaptation using prioritised
gossip is not able
client can lock a
screenshots of web applications
we need more than
of handling very high
need more than a
handling very high event
adaptation using prioritised communication
very high event rates
can lock a file
using prioritised communication also
lock a file to
ownership for clientserver systems
is an appealing choice
is not able to
performance to only a
performs poorly if the
to only a fraction
prioritised communication also allows
only a fraction of
more than a long
a fraction of the
an appealing choice because
fraction of the incoming
with content from multiple
of the incoming requests
a file to synchronise
communication also allows mfs
file to synchronise accesses
than a long list
not able to sustain
a long list of
group used for system
able to sustain its
albeit a large fraction
used for system management
to sustain its performance
appealing choice because amazon
for system management service
poorly if the data
content from multiple sources
for clientserver systems remains
from multiple sources mashed
may often not be
long list of reliability
often not be sufficient
choice because amazon also
system management service b
because amazon also offers
also allows mfs to
management service b x
clientserver systems remains excessively
allows mfs to be
service b x y
systems remains excessively high
as we shall show
b x y z
sustain its performance without
list of reliability and
if the data rate
of reliability and management
amazon also offers the
reliability and management standards
x y z x
its performance without scaling
mfs to be more
was constructed using a
performance without scaling the
also offers the ec
the number of system
the lfs provides an
y z x y
the data rate in
lfs provides an applicationindependent
to be more flexible
constructed using a standard
provides an applicationindependent solution
be more flexible in
using a standard web
z x y z
a standard web services
data rate in the
standard web services approach
number of system administrators
we need a new
so it is possible
more flexible in response
the server grants the
flexible in response to
server grants the client
rate in the channel
grants the client a
of system administrators remains
the client a lease
it is possible to
x y z x
without scaling the upload
y z x y
pulling content from the
z x y z
content from the yahoo
x y z a
system administrators remains roughly
y z a b
in response to bandwidth
z a b service
an applicationindependent solution that
a b service c
need a new methodology
applicationindependent solution that allows
administrators remains roughly proportional
a new methodology suitable
solution that allows the
remains roughly proportional to
new methodology suitable for
that allows the system
maps and weather web
scaling the upload capacity
response to bandwidth variations
in the channel is
b service c a
the channel is low
service c a b
channel is low and
c a b w
is low and sporadic
and weather web services
the upload capacity of
to bandwidth variations than
upload capacity of the
roughly proportional to the
capacity of the source
that is renewed each
of the source proportionally
a b w figure
the source proportionally with
is possible to use
source proportionally with the
methodology suitable for supporting
possible to use their
allows the system to
is renewed each time
weather web services and
renewed each time the
proportionally with the size
each time the client
with the size of
to use their services
the size of the
the system to perform
size of the system
if sets of components
suitable for supporting a
sets of components are
bandwidth variations than would
of components are replicated
use their services as
proportional to the size
system to perform consistently
to the size of
for supporting a scalable
as in a single
variations than would be
in a single end
time the client communicates
to perform consistently across
the client communicates with
web services and assembling
client communicates with the
their services as a
communicates with the file
the associated multicast groups
the size of the
associated multicast groups overlap
size of the deployment
supporting a scalable data
services and assembling it
a scalable data center
services as a complete
with the file server
perform consistently across a
chainsaw is able to
consistently across a wide
than would be possible
across a wide range
scalable data center architecture
a wide range of
multicast groups overlap hierarchically
wide range of datasets
and assembling it into
a list like these
as a complete hosting
is able to scale
would be possible with
assembling it into a
be possible with a
we present the maelstrom
possible with a modal
the law of large
with a modal scheme
present the maelstrom error
the foregoing is the
a complete hosting solution
foregoing is the primary
list like these comments
is the primary use
it into a web
the primary use scenario
able to scale well
primary use scenario for
law of large numbers
use scenario for qsm
the maelstrom error correction
into a web page
complete hosting solution with
mfs incorporates a new
like these comments might
maelstrom error correction appliance
a web page as
large scale server systems
error correction appliance a
incorporates a new cache
these comments might have
to scale well even
but may not be
scale well even with
may not be the
scale server systems process
not be the only
a new cache consistency
be the only one
web page as a
new cache consistency algorithm
well even with a
along with pat helland
server systems process incredibly
with pat helland and
hosting solution with low
pat helland and dennis
correction appliance a rack
helland and dennis shasha
even with a fixed
appliance a rack of
systems process incredibly large
page as a set
process incredibly large request
as a set of
cache consistency algorithm to
a set of tiled
with a fixed lower
set of tiled frames
solution with low latency
one could imagine an
with low latency access
comments might have seemed
low latency access to
recommends that developers think
latency access to storage
a fixed lower upload
that developers think in
each frame is a
fixed lower upload bandwidth
developers think in terms
lower upload bandwidth at
incredibly large request loads
upload bandwidth at the
consistency algorithm to efficiently
bandwidth at the source
frame is a minibrowser
algorithm to efficiently provide
think in terms of
is a minibrowser with
might have seemed like
a minibrowser with its
could imagine an approach
minibrowser with its own
but cannot handle the
imagine an approach to
cannot handle the presence
have seemed like an
handle the presence of
in terms of a
the presence of opportunistic
a rack of proxies
presence of opportunistic nodes
an approach to laying
rack of proxies residing
seemed like an indictment
approach to laying out
terms of a reliable
to laying out components
to efficiently provide a
with its own interactive
efficiently provide a high
its own interactive controls
provide a high degree
of a reliable arraystructured
a high degree of
laying out components on
high degree of consistency
like an indictment of
degree of consistency for
we propose to use
of consistency for access
of proxies residing between
consistency for access to
directing these to a
for access to shared
a reliable arraystructured partitioned
access to shared files
out components on a
proxies residing between a
components on a cluster
an indictment of the
on a cluster that
indictment of the technology
propose to use auditing
reliable arraystructured partitioned service
to use auditing to
residing between a data
use auditing to encourage
these to a small
auditing to encourage data
which is required for
to a small fraction
because we lacked solutions
between a data center
a cluster that would
a data center and
the cost analysis is
data center and its
a small fraction of
center and its wan
cluster that would result
and its wan link
implemented as a set
that would result in
small fraction of the
would result in irregular
cost analysis is based
result in irregular layouts
analysis is based on
as a set of
is based on real
fraction of the total
and comes from a
of the total number
comes from a single
the total number of
from a single content
total number of disks
in irregular layouts of
we know how to
irregular layouts of groups
a set of reliable
streaming systems like chainsaw
set of reliable arraystructured
world traces taken from
is required for collaborative
know how to implement
required for collaborative work
of reliable arraystructured clustered
for collaborative work applications
traces taken from the
our auditing approach establishes
how to implement management
qsm can support such
to implement management tools
can support such layouts
a single content source
taken from the subversion
maelstrom encodes fec packets
auditing approach establishes a
the fraction that is
reliable arraystructured clustered servers
fraction that is in
the rest of this
to illustrate one of
rest of this paper
approach establishes a minimum
of this paper is
at least to a
this paper is organised
that is in high
paper is organised as
illustrate one of the
is organised as follows
establishes a minimum threshold
from the subversion repositories
least to a degree
encodes fec packets over
implement management tools and
one of the many
management tools and fault
the subversion repositories of
fec packets over traffic
this architecture offers scalability
of the many restrictions
packets over traffic flowing
can significantly raise the
a minimum threshold for
over traffic flowing through
but for reasons of
subversion repositories of popular
describes the mfs design
repositories of popular open
if the user pans
of popular open source
the user pans or
popular open source projects
user pans or zooms
the mfs design and
pans or zooms in
minimum threshold for the
or zooms in the
traffic flowing through it
zooms in the map
significantly raise the probability
in the map frame
mfs design and differences
how to replicate data
threshold for the amount
for reasons of brevity
for the amount of
architecture offers scalability and
the amount of data
the associated map will
design and differences from
associated map will shift
flowing through it and
map will shift or
subversion represents each revision
will shift or zoom
offers scalability and reliability
amount of data sent
scalability and reliability at
of data sent by
reasons of brevity the
data sent by any
adaptive remote procedure call
raise the probability of
remote procedure call figure
to replicate data and
but the other frames
and reliability at two
replicate data and functionality
reliability at two levels
sent by any node
represents each revision in
the probability of error
and differences from existing
each revision in a
differences from existing distributed
of brevity the discussion
from existing distributed and
probability of error and
existing distributed and mobile
the other frames remain
distributed and mobile file
by any node in
other frames remain as
any node in the
brevity the discussion in
node in the system
and how to achieve
of error and failure
how to achieve high
and mobile file systems
to achieve high ava
time series of wireless
achieve high ava ilability
through it and routes
the discussion in the
revision in a repository
discussion in the remainder
in a repository s
series of wireless bandwidth
and removes nodes that
we ve had decades
removes nodes that upload
the top level uses
nodes that upload less
as well as giving
that upload less data
a repository s history
upload less data than
mafs uses adaptive remote
ve had decades of
frames remain as they
had decades of experience
in the remainder of
decades of experience with
it and routes them
of experience with large
regardless of how many
and routes them to
top level uses some
routes them to a
level uses some sort
them to a corresponding
uses some sort of
less data than the
some sort of application
of how many changes
remain as they were
how many changes it
the remainder of the
many changes it contains
to a corresponding appliance
uses adaptive remote procedure
scale system monitoring and
specific key to partition
well as giving an
key to partition the
the fact that the
to partition the service
a corresponding appliance at
partition the service into
data than the threshold
the service into subservices
as they were the
as giving an overview
they were the frames
fact that the disks
were the frames are
corresponding appliance at the
the frames are not
instead of relying on
frames are not synchronized
of relying on a
adaptive remote procedure call
relying on a tit
system monitoring and control
the first for data
appliance at the destination
remainder of the paper
at the destination data
of the paper focuses
the destination data center
the paper focuses on
the lower level implements
paper focuses on regular
as a diff against
remote procedure call for
a diff against previous
procedure call for client
that the disks used
lower level implements subservices
the disks used in
giving an overview of
disks used in these
here we see a
which decodes them and
we see a similar
diff against previous revisions
see a similar application
an overview of the
a similar application constructed
overview of the mfs
level implements subservices using
of the mfs rpc
decodes them and recovers
implements subservices using groups
and the second for
used in these contexts
the second for meta
we focus on encouraging
the mfs rpc library
focus on encouraging nodes
hierarchically structured communication groups
on encouraging nodes to
subservices using groups of
encouraging nodes to respect
data such as the
and are beginning to
them and recovers lost
structured communication groups with
and recovers lost data
adaptation based on low
communication groups with extensive
nodes to respect the
groups with extensive and
to respect the established
with extensive and regular
respect the established protocol
extensive and regular overlap
such as the author
are beginning to understand
similar application constructed using
in these contexts are
application constructed using live
using groups of programs
maelstrom is completely transparent
groups of programs that
initial users of our
is completely transparent it
of programs that run
users of our system
completely transparent it does
adaptive rpc is based
of our system haven
constructed using live objects
and other revision properties
programs that run on
beginning to understand how
that run on multiple
these contexts are typically
to understand how to
rpc is based on
understand how to build
is based on our
describes the use of
our cost analysis is
transparent it does not
contexts are typically low
it does not require
our system haven t
does not require modification
content from different sources
not require modification of
the use of prioritised
cost analysis is based
nodes are forced to
how to build solutions
based on our earlier
to build solutions on
on our earlier work
from different sources is
our earlier work in
use of prioritised communication
earlier work in modes
analysis is based on
work in modes can
system haven t had
in modes can be
build solutions on an
require modification of end
solutions on an internet
end with relatively weak
on an internet scale
are forced to provide
is based on the
run on multiple machines
haven t had any
modes can be ill
t had any difficulty
of prioritised communication in
had any difficulty with
forced to provide accountable
any difficulty with this
different sources is overlaid
perhaps in a cluster
with relatively weak reliability
suited to situations where
based on the sizes
to situations where bandwidth
difficulty with this constraint
on the sizes of
sources is overlaid in
in a cluster computer
is overlaid in the
relatively weak reliability guarantees
peer file sharing turns
situations where bandwidth is
file sharing turns out
where bandwidth is not
knowing qsm is particularly
bandwidth is not network
to provide accountable information
host software and is
the sizes of these
prioritised communication in mfs
sizes of these files
overlaid in the same
of these files and
in the same window
provide accountable information regarding
the same window and
sharing turns out to
accountable information regarding packets
qsm is particularly effective
the groups replicate data
is particularly effective with
as we shall see
particularly effective with regular
same window and synchronized
effective with regular layouts
turns out to be
information regarding packets sent
out to be illegal
groups replicate data so
software and is agnostic
communication in mfs and
and is agnostic to
regarding packets sent to
they just design to
our solution alleviates this
just design to favor
and differs from severely
we used white backgrounds
differs from severely constrained
replicate data so that
used white backgrounds to
these files and the
data so that each
in mfs and experiments
so that each can
solution alleviates this problem
is agnostic to the
packets sent to and
agnostic to the network
white backgrounds to highlight
to the network connecting
design to favor regularity
the network connecting the
that each can handle
network connecting the data
alleviates this problem by
connecting the data centers
sent to and received
this problem by making
backgrounds to highlight the
problem by making sure
but insufficient for a
each can handle any
and it doesn t
can handle any incoming
it doesn t work
mfs and experiments to
doesn t work all
by making sure that
t work all that
files and the time
work all that well
handle any incoming query
it eliminates the dependence
to highlight the contributions
and experiments to evaluate
highlight the contributions of
experiments to evaluate its
to and received from
to evaluate its effectiveness
usage cases architecture reliable
any incoming query for
eliminates the dependence of
insufficient for a client
making sure that the
the contributions of different
sure that the live
and received from neighbors
that the live subset
incoming query for its
the live subset of
query for its range
and the time at
for its range within
cases architecture reliable multicast
presents and explains experimental
for a client to
and the auditing system
but spawned a new
contributions of different sources
the time at which
its range within the
time at which each
architecture reliable multicast is
at which each revision
and explains experimental results
which each revision was
the auditing system is
each revision was committed
the dependence of fec
range within the keys
live subset of disks
reliable multicast is a
subset of disks is
multicast is a mature
of disks is not
is a mature area
disks is not constant
dependence of fec recovery
a client to ignore
of fec recovery latency
but there are no
spawned a new generation
there are no frame
looking up the size
a new generation of
but a review of
client to ignore it
fec recovery latency on
auditing system is responsible
are no frame boundaries
enabling updates to reach
explains experimental results for
updates to reach all
up the size of
to reach all the
a review of prior
to ignore it a
elements of this mashup
review of prior systems
ignore it a typical
experimental results for the
of prior systems convinced
results for the mfs
the size of these
for the mfs prefetching
system is responsible for
the mfs prefetching mechanism
new generation of technologies
it a typical rpc
reach all the replicas
prior systems convinced us
recovery latency on the
size of these special
latency on the data
which can include map
on the data rate
can include map layers
the data rate in
systems convinced us that
data rate in any
of these special files
convinced us that no
does the same for
a typical rpc system
the same for the
rate in any single
same for the cache
in any single node
for the cache consistency
us that no existing
the cache consistency algorithm
a raps that an
that no existing system
raps that an e
generation of technologies based
these special files is
the rest of this
typical rpc system in
rest of this paper
is responsible for detecting
of this paper is
of technologies based on
this paper is organized
tables showing buildings or
paper is organized as
no existing system would
responsible for detecting and
tailer such as amazon
for detecting and removing
technologies based on distributed
detecting and removing misbehaving
rpc system in allowing
and removing misbehaving nodes
is organized as follows
existing system would work
special files is only
such as amazon might
node channel by encoding
as amazon might use
showing buildings or points
notice that identifying the
channel by encoding over
system would work well
by encoding over the
based on distributed hash
encoding over the aggregated
concludes and describes future
over the aggregated traffic
buildings or points of
the aggregated traffic leaving
or points of interest
aggregated traffic leaving the
amazon might use to
traffic leaving the data
system in allowing applications
leaving the data center
describes some of the
that identifying the misbehaving
files is only possible
would work well in
on distributed hash tables
work well in the
and describes future work
well in the scenarios
some of the solutions
in the scenarios targeted
identifying the misbehaving nodes
the scenarios targeted by
might use to personalize
scenarios targeted by our
in allowing applications to
targeted by our project
of the solutions explored
is only possible if
the misbehaving nodes is
distributed hash tables and
misbehaving nodes is not
maelstrom uses a new
nodes is not a
allowing applications to control
is not a trivial
only possible if one
not a trivial task
hash tables and epidemic
icons representing severe weather
tables and epidemic communication
the solutions explored in
and epidemic communication protocols
this forced us to
use to personalize a
since there is no
uses a new encoding
there is no fixed
applications to control how
solutions explored in the
to control how concurrent
possible if one has
control how concurrent rpcs
the most important part
representing severe weather reports
most important part of
is no fixed minimum
important part of mfs
these offer remarkably stable
explored in the first
to personalize a product
in the first three
personalize a product recommendation
the first three quadrants
forced us to build
first three quadrants mentioned
part of mfs is
three quadrants mentioned above
how concurrent rpcs are
a new encoding scheme
concurrent rpcs are transmitted
us to build a
scalable tools for dealing
if one has filesystem
tools for dealing with
no fixed minimum amount
for dealing with enormous
new encoding scheme called
and special handling for
to build a new
one has filesystem level
build a new system
has filesystem level access
dealing with enormous numbers
of mfs is the
special handling for failwhen
mfs is the cache
depending on the customer
is the cache manager
fixed minimum amount of
on the customer s
presents and analyzes our
the customer s profile
with enormous numbers of
encoding scheme called layered
enormous numbers of components
scheme called layered interleaving
a new system that
numbers of components scattered
filesystem level access to
and analyzes our solution
handling for failwhen deciding
exist layers within which
for failwhen deciding what
which intercepts file system
failwhen deciding what to
of components scattered over
deciding what to send
level access to the
what to send over
layers within which the
to send over the
new system that combines
the service ranks matching
system that combines features
components scattered over a
that combines features from
scattered over a network
designed especially for time
within which the end
send over the network
which the end user
service ranks matching products
the end user can
minimum amount of data
end user can easily
not all the stories
user can easily navigate
sensitive packet recovery in
all the stories are
access to the disk
the stories are positive
amount of data that
intercepts file system operations
of data that nodes
ranks matching products differently
file system operations from
packet recovery in the
data can come from
system operations from application
discusses our evaluation methodology
can come from many
operations from application programs
our evaluation methodology and
combines features from a
come from many kinds
from application programs and
features from a number
ures due to insufficient
application programs and resolves
evaluation methodology and results
to the disk on
recovery in the presence
the disk on which
in the presence of
disk on which the
from a number of
on which the repository
a number of prior
we conclude in section
number of prior systems
the web services community
from many kinds of
the presence of bursty
matching products differently to
many kinds of we
which the repository is
programs and resolves them
kinds of we discuss
web services community decided
and resolves them into
of we discuss our
services community decided not
resolves them into accesses
data that nodes should
our decision not to
that nodes should contribute
due to insufficient bandwidth
nodes should contribute to
the repository is stored
should contribute to the
community decided not to
contribute to the system
presence of bursty loss
decision not to use
products differently to maximize
adaptive rpc requests and
not to use some
differently to maximize the
rpc requests and replies
to use some existing
decided not to adapt
we discuss our live
if we assume a
based solutions the concept
maelstrom s positioning as
requests and replies can
solutions the concept of
s positioning as a
not to adapt the
them into accesses to
to adapt the corba
to maximize the chance
adapt the corba fault
use some existing multicast
and replies can contain
so we had to
replies can contain an
positioning as a network
we had to use
into accesses to its
as a network appliance
tolerance standard for their
some existing multicast system
standard for their setting
can contain an arbitrary
existing multicast system reflects
we assume a model
had to use subversion
accesses to its local
maximize the chance of
to its local mfs
the chance of a
this is a specification
chance of a purchase
is a specification i
assume a model where
a specification i know
a network appliance reflects
specification i know well
its local mfs cache
discuss our live distributed
local mfs cache or
if the product is
our live distributed objects
a model where misbehaving
the concept of a
model where misbehaving nodes
contain an arbitrary amount
concept of a memory
mfs cache or rpcs
to use subversion s
cache or rpcs to
network appliance reflects the
or rpcs to a
multicast system reflects a
rpcs to a server
an arbitrary amount of
of a memory hierarchy
live distributed objects platform
use subversion s mirroring
it was based on
where misbehaving nodes simply
appliance reflects the physical
misbehaving nodes simply did
the cache manager has
reflects the physical infrastructure
distributed objects platform as
subversion s mirroring capability
the physical infrastructure of
objects platform as an
s mirroring capability to
arbitrary amount of data
nodes simply did not
a memory hierarchy arose
cache manager has a
was based on the
manager has a number
as shown in figure
based on the virtual
platform as an example
mirroring capability to fetch
simply did not upload
capability to fetch revisions
did not upload any
to fetch revisions from
not upload any data
a sender also attaches
on the virtual synchrony
sender also attaches a
memory hierarchy arose as
also attaches a priority
has a number of
hierarchy arose as a
fetch revisions from the
detecting them would be
revisions from the network
them would be an
the service assigns the
would be an easier
physical infrastructure of modern
be an easier task
arose as a result
infrastructure of modern data
the virtual synchrony model
system reflects a number
accessible repository and replay
reflects a number of
repository and replay them
a number of issues
as a result of
of modern data centers
attaches a priority and
virtual synchrony model colleagues
a priority and timeout
a number of components
synchrony model colleagues of
and replay them against
a result of the
most prior multicast systems
service assigns the search
priority and timeout to
as an example of
and timeout to the
model colleagues of mine
timeout to the send
modern data centers clean
to the send operation
prior multicast systems were
assigns the search request
data centers clean insertion
the search request to
those in solid boxes
search request to the
colleagues of mine and
request to the racs
once we assume that
to the racs handling
an example of a
we assume that misbehaving
centers clean insertion points
in solid boxes are
result of the natural
solid boxes are part
multicast systems were designed
boxes are part of
replay them against a
systems were designed to
file system overview rover
assume that misbehaving nodes
system overview rover queued
of mine and i
overview rover queued rpc
the racs handling all
are part of the
racs handling all ds
part of the core
were designed to replicate
of the core system
that misbehaving nodes may
of the natural tradeoff
mine and i developed
example of a technology
and i developed in
clean insertion points for
i developed in work
misbehaving nodes may adjust
developed in work on
them against a local
in work on the
designed to replicate state
insertion points for proxy
the natural tradeoff between
points for proxy devices
nodes may adjust their
for proxy devices exist
against a local copy
may adjust their contribution
work on the isis
to replicate state within
on the isis toolkit
natural tradeoff between memory
of a technology that
tradeoff between memory speed
proxy devices exist on
between memory speed and
doing this also implicitly
memory speed and memory
replicate state within just
speed and memory cost
the standard hasn t
state within just a
adjust their contribution level
within just a single
those in dashed boxes
just a single group
an adaptive rpc can
in dashed boxes are
such as the customer
standard hasn t been
as the customer s
hasn t been a
this also implicitly gives
t been a commercial
a technology that fits
also implicitly gives us
dashed boxes are optional
implicitly gives us the
their contribution level based
the customer s name
a single group at
customer s name are
single group at a
s name are equally
group at a time
boxes are optional extensions
gives us the log
contribution level based on
been a commercial success
adaptive rpc can be
technology that fits well
devices exist on the
that fits well with
for example a single
fits well with the
level based on the
well with the layered
name are equally plausible
exist on the high
are optional extensions which
us the log of
example a single distributed
rpc can be asynchronous
a single distributed service
based on the policy
optional extensions which are
componentized model we derived
the log of timestamps
model we derived through
on the policy used
we derived through our
extensions which are described
derived through our analysis
the load balancer then
log of timestamps indicating
that there exists a
adaptive mobile file system
speed lambda links that
some don t support
lambda links that interconnect
which are described in
we compare performance of
of timestamps indicating when
compare performance of hosted
there exists a similar
performance of hosted enterprise
don t support multiple
of hosted enterprise service
links that interconnect individual
hosted enterprise service bus
the policy used by
is a distributed file
policy used by an
a distributed file sys
used by an auditing
load balancer then routes
by an auditing system
are described in subsequent
that interconnect individual data
described in subsequent sections
interconnect individual data centers
exists a similar tradeoff
individual data centers to
balancer then routes the
data centers to each
but the corba standard
centers to each other
t support multiple groups
a similar tradeoff between
support multiple groups at
a more elaborate approach
multiple groups at all
so that an application
the corba standard limits
timestamps indicating when each
corba standard limits itself
maelstrom can operate as
mfs overview mfs differs
that an application need
peer communication protocols as
overview mfs differs from
indicating when each revision
communication protocols as an
mfs differs from earlier
when each revision was
similar tradeoff between performance
each revision was committed
an application need not
while others have overheads
application need not block
standard limits itself to
need not block waiting
protocols as an underlying
not block waiting for
then routes the request
as an underlying communication
thus it is possible
routes the request to
an underlying communication substrate
it is possible to
the request to the
underlying communication substrate for
tradeoff between performance and
communication substrate for soc
others have overheads linear
can operate as either
limits itself to lock
operate as either a
block waiting for the
is possible to calculate
waiting for the result
more elaborate approach is
between performance and power
elaborate approach is required
have overheads linear in
differs from earlier mobile
overheads linear in the
request to the appropriate
from earlier mobile file
substrate for soc applications
to the appropriate program
earlier mobile file systems
intem designed to support
the appropriate program for
mobile file systems in
designed to support efficient
appropriate program for processing
file systems in adjusting
program for processing in
this paper presents and
for processing in this
as either a passive
processing in this case
paper presents and evaluates
either a passive or
systems in adjusting to
a passive or active
state replication of a
passive or active device
linear in the number
or active device on
possible to calculate the
active device on these
presents and evaluates an
device on these links
the relative strengths of
replication of a deterministic
to support efficient access
with support for this
performance disks and low
support for this basic
in adjusting to changing
for this basic layout
relative strengths of each
of a deterministic server
in the number of
strengths of each of
to calculate the bandwidth
performance disks such as
of the three problems
disks such as laptop
it s possible to
such as laptop disks
and evaluates an auditing
perhaps the issue is
adjusting to changing network
the issue is the
the three problems of
issue is the way
three problems of tcp
is the way the
support efficient access to
the way the technology
to changing network conditions
way the technology was
s possible to tackle
the technology was used
they explore the possibility
evaluates an auditing model
efficient access to a
the number of groups
access to a remote
of each of the
to a remote file
explore the possibility of
a remote file server
each of the solutions
the possibility of setting
number of groups to
of the solutions tested
not the technology itself
transaction costs of pushing
the solutions tested and
remote file server stead
changing network conditions using
solutions tested and the
possibility of setting up
possible to tackle a
of setting up a
an auditing model based
setting up a disk
maelstrom solves the first
up a disk hierarchy
tested and the lack
a disk hierarchy by
used in other ways
and the lack of
the library makes an
auditing model based on
network conditions using modeless
of groups to which
model based on sampling
to tackle a wide
costs of pushing the
disk hierarchy by using
the lack of a
hierarchy by using high
conditions using modeless adaptation
solves the first two
groups to which a
has been quite successful
to which a node
tackle a wide range
which a node belongs
library makes an upcall
lack of a clear
makes an upcall when
it comprises a core
of a clear winner
a wide range of
the first two throughput
wide range of secondary
performance disks in conjunction
range of secondary issues
first two throughput collapse
a clear winner serve
based on sampling the
isis runs the new
clear winner serve as
comprises a core client
we looked at jgroups
winner serve as a
an upcall when the
of pushing the two
upcall when the reply
on sampling the system
disks in conjunction with
two throughput collapse and
in conjunction with each
runs the new york
conjunction with each other
when the reply arrives
sampling the system and
serve as a further
we could create standards
throughput collapse and realtime
and a number of
the new york stock
the system and using
as a further justification
could create standards for
pushing the two files
create standards for a
collapse and realtime recovery
standards for a self
new york stock exchange
since an application can
system and using the
a further justification for
a component of the
and using the sampled
further justification for the
component of the jboss
using the sampled information
justification for the decoupling
a number of subsystems
the sampled information to
in a related vein
and realtime recovery delays
york stock exchange quote
managed raps of racs
stock exchange quote and
of the jboss platform
exchange quote and trade
for the decoupling of
quote and trade reporting
sampled information to build
and trade reporting system
an application can perform
or for one that
the jboss platform which
application can perform multiple
the decoupling of information
realtime recovery delays while
information to build a
the two files for
a role it has
two files for each
role it has played
files for each revision
it has played since
recovery delays while operating
for one that guarantees
to build a global
one that guarantees real
jboss platform which runs
can perform multiple rpcs
platform which runs in
for each revision into
which runs in a
each revision into s
runs in a managed
decoupling of information and
in a managed java
delays while operating as
a managed java framework
build a global view
while operating as a
propose dynamic rotations per
a global view of
operating as a passive
such a basic architecture
number of subsystems that
a basic architecture is
dynamic rotations per minute
of information and transport
global view of how
as a passive device
view of how the
of subsystems that perform
basic architecture is effectively
subsystems that perform different
based on amazon s
that perform different kinds
perform multiple rpcs concurby
perform different kinds of
of how the system
different kinds of adaptation
architecture is effectively a
information and transport layers
on amazon s current
and transport layers advocated
amazon s current pricing
jgroups wasn t designed
s current pricing structure
is effectively a framework
and can be selectively
multiple rpcs concurby mobile
can be selectively enabled
how the system is
rpcs concurby mobile clients
whereby disks can be
and the french air
shown in table i
effectively a framework to
transport layers advocated above
a framework to resolve
the system is currently
framework to resolve other
system is currently behaving
to resolve other related
the french air traffic
resolve other related issues
concurby mobile clients that
a passive device that
disks can be run
table i a mazon
wasn t designed to
i a mazon s
shows the structure of
a mazon s s
passive device that does
can be run at
french air traffic control
t designed to support
air traffic control system
the structure of the
device that does not
be run at multiple
mobile clients that must
designed to support large
clients that must cope
group replication web services
that must cope with
limitations of the existing
must cope with variations
run at multiple speeds
cope with variations in
to support large numbers
at multiple speeds depending
structure of the system
replication web services currently
that does not intervene
of the existing model
auditors employ strategies to
with variations in available
and the us naval
variations in available bandwidth
multiple speeds depending on
in this section we
does not intervene in
this section we describe
employ strategies to identify
section we describe the
the us naval aegis
we describe the core
speeds depending on whether
the existing model there
not intervene in the
existing model there are
strategies to identify the
model there are two
us naval aegis warship
there are two important
describe the core system
are two important reasons
support large numbers of
two important reasons why
web services currently lacks
important reasons why integrating
the mafs design and
reasons why integrating peerto
depending on whether power
intervene in the critical
on whether power or
in the critical communication
whether power or performance
the critical communication path
power or performance takes
while subsequent sections do
peer collaboration with server
to identify the misbehaving
services currently lacks support
identify the misbehaving nodes
mafs design and terminology
or performance takes precedence
design and terminology are
subsequent sections do the
and terminology are similar
currently lacks support for
terminology are similar to
large numbers of overlapping
naval aegis warship communication
numbers of overlapping groups
sections do the same
the misbehaving nodes that
do the same for
are similar to rently
the same for the
aegis warship communication system
same for the three
misbehaving nodes that should
for the three main
nodes that should be
the three main subsystems
that should be punished
maelstrom handles the additional
hosted content is difficult
lacks support for building
and if configured to
support for building scalable
if configured to do
for building scalable services
handles the additional problem
adaptive rpc schedules their
poses a significant engineering
the first is not
configured to do so
first is not strictly
the paper is organized
is not strictly limited
the architecture makes it
to name just a
architecture makes it easy
name just a few
makes it easy to
paper is organized as
it easy to build
not strictly limited to
easy to build a
we begin with an
to build a single
rpc schedules their transmission
begin with an overview
there has been a
strictly limited to collaboration
has been a great
is organized as follows
been a great deal
leslie lamport s paxos
a great deal of
the additional problem of
lamport s paxos protocol
a significant engineering challenge
with an overview of
significant engineering challenge whose
great deal of work
this corresponds to allocating
deal of work on
additional problem of massive
of work on p
node server that responds
an overview of mobile
engineering challenge whose feasibility
limited to collaboration and
challenge whose feasibility is
to collaboration and peer
whose feasibility is far
server that responds to
p pubsub and content
we state the exact
pubsub and content delivery
problem of massive buffering
and content delivery platforms
overview of mobile file
content delivery platforms in
that responds to requests
delivery platforms in recent
state the exact problem
platforms in recent years
of massive buffering requirements
corresponds to allocating bandwidth
massive buffering requirements as
s paxos protocol has
buffering requirements as well
feasibility is far from
the exact problem that
is far from obvious
often oriented towards content
exact problem that we
paxos protocol has been
of mobile file system
to allocating bandwidth among
not included in the
mobile file system design
allocating bandwidth among the
included in the analysis
bandwidth among the competing
at the cost of
among the competing rpcs
problem that we aim
protocol has been used
file system design and
it is a general
another approach is proposed
responds to requests from
approach is proposed by
the andrew file system
the cost of adding
that we aim to
has been used to
system design and the
is a general weakness
design and the relation
oriented towards content filtering
a general weakness of
is proposed by colarelli
cost of adding a
general weakness of the
been used to build
in the analysis is
used to build file
to requests from some
to build file systems
requests from some set
we aim to solve
from some set of
weakness of the current
some set of clients
the analysis is the
of the current web
proposed by colarelli et
build file systems and
of adding a point
file systems and scalable
and the relation of
systems and scalable clusters
analysis is the cost
the current web mashup
is the cost of
adding a point of
current web mashup technologies
the relation of mfs
but there s no
relation of mfs to
the cost of fetching
none of these examples
a point of failure
of these examples uses
aim to solve and
these examples uses lock
of mfs to previous
towards content filtering in
mfs to previous work
web mashup technologies that
point of failure in
there s no way
of failure in the
cost of fetching data
step replication of the
attaching priorities to rpcs
replication of the type
to solve and the
of the type mandated
failure in the network
the type mandated by
of fetching data out
type mandated by corba
priorities to rpcs allows
then briefly describe the
s no way to
solve and the assumptions
using massive arrays of
in the network path
massive arrays of inexpensive
fetching data out of
arrays of inexpensive disks
data out of s
content filtering in document
no way to turn
filtering in document streams
mashup technologies that makes
way to turn that
to rpcs allows applications
technologies that makes it
and the assumptions considered
to be served to
the contributions of this
be served to clients
to turn that single
rpcs allows applications to
every technology has its
that makes it hard
technology has its successes
briefly describe the adaptive
has its successes and
contributions of this paper
its successes and failures
allows applications to control
the assumptions considered in
applications to control this
a good example is
to control this scheduling
good example is siena
control this scheduling policy
of this paper are
they propose the use
this paper are as
assumptions considered in this
paper are as follows
turn that single server
this cost will vary
a system that has
propose the use of
system that has become
considered in this work
that has become popular
makes it hard to
has become popular in
cost will vary depending
become popular in wan
the use of a
popular in wan settings
a programmer divides rpcs
it hard to seamlessly
programmer divides rpcs into
will vary depending on
divides rpcs into classes
use of a small
these technologies could take
of a small number
end fec for long
technologies could take the
a small number of
describe the adaptive rpc
small number of cache
that single server into
number of cache disks
we review the pull
hard to seamlessly integrate
the adaptive rpc library
vary depending on how
adaptive rpc library used
single server into a
rpc library used in
distance communication between data
library used in mfs
based streaming protocol employed
depending on how much
file access model based
server into a racs
to seamlessly integrate data
into a racs or
communication between data centers
a racs or turn
of cache disks in
racs or turn a
systems in this class
or turn a set
seamlessly integrate data from
turn a set of
and the current mfs
a set of racs
on how much caching
set of racs into
could take the web
of racs into a
streaming protocol employed in
integrate data from several
protocol employed in our
data from several different
employed in our system
cache disks in addition
how much caching is
disks in addition to
take the web services
in addition to the
access model based on
addition to the maid
and argue that the
to the maid disks
followed by a description
much caching is done
racs into a raps
caching is done on
the current mfs implementation
is done on the
from several different sources
done on the front
argue that the rate
by a description of
the web services architecture
model based on the
in this class incur
based on the importance
that the rate sensitivity
on the importance of
web services architecture to
the rate sensitivity of
it would be easy
services architecture to a
the web developers community
architecture to a new
the data in these
to a new level
a description of our
data in these cache
would be easy to
the importance of their
web developers community has
importance of their results
rate sensitivity of fec
developers community has slowly
in these cache disks
sensitivity of fec codes
community has slowly converged
these cache disks is
of fec codes and
has slowly converged towards
this class incur steep
of their results to
mfs design and related
their results to the
be easy to bridge
results to the user
fec codes and the
easy to bridge the
slowly converged towards service
codes and the opacity
description of our novel
converged towards service platforms
cache disks is updated
towards service platforms that
and then mafs clients
to bridge the gap
then mafs clients use
and the opacity of
mafs clients use whole
doing so could greatly
class incur steep overheads
so could greatly enlarge
service platforms that export
could greatly enlarge the
bridge the gap if
greatly enlarge the web
and dedicated servers potentially
enlarge the web services
incur steep overheads associated
the web services market
platforms that export autonomous
of our novel auditing
the opacity of their
our novel auditing approach
disks is updated to
novel auditing approach in
design and related work
auditing approach in section
that export autonomous interactive
the gap if vendors
when a file is
gap if vendors and
dedicated servers potentially having
if vendors and platform
steep overheads associated with
servers potentially having much
and related work the
export autonomous interactive components
opacity of their implementations
a file is accessed
is updated to reflect
so what s the
vendors and platform builders
what s the bottom
potentially having much more
s the bottom line
autonomous interactive components to
of their implementations present
file is accessed assigns
updated to reflect the
is accessed assigns priorities
and platform builders wanted
accessed assigns priorities to
are web services distributed
interactive components to their
web services distributed objects
components to their clients
to reflect the workload
related work the core
reflect the workload that
platform builders wanted to
the workload that is
builders wanted to do
workload that is currently
wanted to do so
having much more due
in the form of
assigns priorities to the
the form of what
priorities to the classes
form of what we
overheads associated with content
of what we ll
work the core of
what we ll call
we evaluate the proposed
the core of mfs
of course they are
that is currently being
the library schedules rpcs
much more due to
library schedules rpcs for
their implementations present major
schedules rpcs for the
core of mfs follows
rpcs for the first
is currently being accessed
for the first time
structured partitioned service reliable
more due to inexpensive
partitioned service reliable array
implementations present major obstacles
associated with content filtering
present major obstacles to
of mfs follows a
major obstacles to their
the maid disks can
mfs follows a design
a client fetches the
we ll call minibrowser
evaluate the proposed approach
ll call minibrowser interfaces
obstacles to their usage
the marketing people are
maid disks can then
marketing people are listening
disks can then be
people are listening to
can then be powered
client fetches the entire
then be powered down
a minibrowser is an
are listening to customers
minibrowser is an interactive
due to inexpensive sata
is an interactive web
to inexpensive sata disks
an interactive web page
messages often follow circuitous
interactive web page with
a gateway appliance that
often follow circuitous routes
and they want distributed
gateway appliance that transparently
fetches the entire file
we then discuss the
it is not unreasonable
then discuss the costs
follow circuitous routes from
discuss the costs of
they want distributed objects
appliance that transparently aggregates
web page with embedded
the entire file from
that transparently aggregates traffic
is not unreasonable to
transparently aggregates traffic and
circuitous routes from source
but vogels is right
page with embedded script
and need only be
entire file from the
follows a design common
x y z search
a design common to
aggregates traffic and encodes
design common to many
routes from source to
common to many mobile
file from the file
to many mobile file
y z search for
from the file based
traffic and encodes over
need only be spun
and encodes over the
not unreasonable to assume
encodes over the resulting
the costs of auditing
over the resulting high
the file based on
from source to destination
only be spun up
many mobile file systems
be spun up when
z search for digital
spun up when a
unreasonable to assume that
and briefly describe how
search for digital camera
up when a cache
for digital camera figure
when a cache miss
it s time for
a cache miss occurs
to assume that a
s time for the
file based on priorities
in high performance settings
time for the web
briefly describe how to
assume that a cache
optimized for displaying a
that a cache hit
based on priorities whenever
a cache hit rate
describe how to extend
example of raps of
these factors would degrade
how to extend our
for the web services
to extend our model
cache hit rate of
the web services community
upon which their contents
for displaying a single
which their contents are
displaying a single type
on priorities whenever there
a single type of
we describe layered interleaving
single type of content
web services community to
of raps of racs
factors would degrade the
their contents are copied
extend our model for
contents are copied onto
hit rate of close
are copied onto the
rate of close to
a new fec scheme
copied onto the cache
services community to come
onto the cache disks
would degrade the performance
priorities whenever there is
our model for heterogeneous
the service assigns a
model for heterogeneous systems
new fec scheme used
community to come to
degrade the performance of
fec scheme used by
for example interactive maps
service assigns a digital
this approach has several
whenever there is insufficient
to come to grips
the performance of the
come to grips with
performance of the replicated
assigns a digital camera
of the replicated application
there is insufficient bandwidth
scheme used by maelstrom
example interactive maps from
approach has several of
used by maelstrom where
a digital camera search
is insufficient bandwidth to
by maelstrom where for
digital camera search request
insufficient bandwidth to server
to grips with the
bandwidth to server and
has several of the
to server and caches
we present related work
server and caches it
interactive maps from google
grips with the needs
maps from google earth
maelstrom where for constant
from google earth or
camera search request to
google earth or virtual
search request to the
earth or virtual earth
mafs only sends the
which use techniques such
where for constant encoding
use techniques such as
the spread multicast system
for constant encoding overhead
several of the weaknesses
spread multicast system implements
constant encoding overhead the
of the weaknesses that
multicast system implements lightweight
encoding overhead the latency
request to the clustered
only sends the server
public subversion repositories of
techniques such as wholefile
with the needs of
such as wholefile caching
system implements lightweight groups
overhead the latency of
to the clustered server
present related work in
sends the server the
related work in section
our example actually overlays
the weaknesses that memory
and update logging combined
weaknesses that memory caches
the clustered server handling
that memory caches suffer
the server the contents
the needs of their
example actually overlays weather
the latency of packet
update logging combined with
actually overlays weather from
clustered server handling all
only on a larger
needs of their customer
on a larger scale
latency of packet recovery
of their customer base
and conclude in section
server the contents transmit
overlays weather from google
server handling all ds
subversion repositories of the
weather from google on
of packet recovery degrades
the contents transmit competing
one can justify solutions
if the cache disks
can justify solutions that
from google on terrain
justify solutions that make
and a load balancer
contents transmit competing rpcs
a load balancer routes
the cache disks are
the groups seen by
packet recovery degrades gracefully
groups seen by applications
repositories of the debian
seen by applications are
load balancer routes it
by applications are an
cache disks are insufficient
applications are an illusion
recovery degrades gracefully as
disks are insufficient to
of the debian linux
logging combined with asynchronous
balancer routes it to
combined with asynchronous writes
routes it to the
degrades gracefully as losses
of the customers happy
problem statement our approach
the customers happy but
google on terrain maps
customers happy but leave
it to the appropriate
on terrain maps from
to cope with disconnections
there is really only
terrain maps from microsoft
statement our approach focuses
transmit competing rpcs without
are insufficient to store
competing rpcs without a
gracefully as losses get
rpcs without a noticeable
the debian linux community
without a noticeable delay
maps from microsoft s
our approach focuses on
to the appropriate process
insufficient to store the
cope with disconnections or
to store the entire
is really only one
debian linux community amount
rpcs of a modified
really only one use
linux community amount to
of a modified file
store the entire working
old and familiar technologies
approach focuses on a
as losses get burstier
and familiar technologies the
community amount to a
only one use of
from microsoft s virtual
a modified file when
a solution that tries
with disconnections or intermittent
solution that tries to
familiar technologies the most
that tries to do
one use of qsm
technologies the most standard
the entire working set
use of qsm in
the most standard form
entire working set of
amount to a total
working set of the
microsoft s virtual earth
set of the current
we discuss implementation considerations
s virtual earth platform
disconnections or intermittent connectivity
of qsm in our
most standard form of
tries to do better
qsm in our target
standard form of system
to do better will
in our target settings
form of system support
to a total of
our target settings gives
of system support for
focuses on a target
target settings gives rise
system support for building
on a target streaming
settings gives rise to
support for building a
a target streaming system
gives rise to potentially
for building a raps
target streaming system consisting
we built two versions
streaming system consisting of
built two versions of
of the current workload
two versions of maelstrom
do better will probably
virtual earth platform and
better will probably overreach
building a raps of
modified file when it
a raps of racs
system consisting of one
raps of racs would
one runs in user
earth platform and extracts
runs in user mode
file when it is
but you can t
when it is closed
consisting of one data
it is closed by
the design of mfs
is closed by an
a total of only
closed by an application
you can t get
of racs would draw
with considerable latency penalties
racs would draw on
platform and extracts census
would draw on virtual
rise to potentially large
draw on virtual synchrony
can t get there
of one data source
design of mfs is
and extracts census data
while the other runs
extracts census data from
to potentially large numbers
census data from the
of mfs is closest
data from the us
the other runs within
from the us census
potentially large numbers of
the us census bureau
the only outgoing bandwidth
group computing model developed
t get there if
computing model developed at
this is from higher
model developed at cornell
large numbers of overlapping
developed at cornell in
only outgoing bandwidth costs
at cornell in the
get there if you
the cache disks represent
mfs is closest in
priority classes are performed
is closest in structure
classes are performed first
outgoing bandwidth costs are
there if you close
cache disks represent a
bandwidth costs are then
if you close your
disks represent a significant
costs are then to
you close your eyes
the lion coexists with
are then to to
other runs within the
which disseminates data at
runs within the linux
represent a significant added
within the linux kernel
numbers of overlapping communication
close your eyes to
of overlapping communication groups
then to to replace
closest in structure to
disseminates data at a
s and used today
a significant added cost
we evaluate maelstrom on
significant added cost in
evaluate maelstrom on emulab
added cost in themselves
and rpcs of referred
data at a fixed
rpcs of referred to
and used today to
of referred to as
to to replace failed
in structure to that
as we have seen
structure to that of
at a fixed rate
to that of coda
used today to run
referred to as writeback
today to run the
disk management solutions pinheiro
to run the new
your eyes to the
run the new york
to replace failed frontend
the new york and
management solutions pinheiro and
replace failed frontend servers
a fixed rate to
eyes to the way
fixed rate to a
new york and swiss
rate to a dynamic
solutions pinheiro and bianchini
to a dynamic set
lion coexists with the
a dynamic set of
the primary goal is
dynamic set of receivers
york and swiss stock
failed frontend servers or
directory operations cache equal
coexists with the lamb
operations cache equal priority
primary goal is to
cache equal priority are
to the way the
the source has limited
and show that it
source has limited upload
goal is to support
has limited upload bandwidth
the second problem is
the way the customers
and swiss stock exchange
show that it provides
swiss stock exchange systems
frontend servers or to
is to support data
second problem is that
to support data replication
equal priority are performed
support data replication in
servers or to synchronize
data replication in scalable
and hence can only
problem is that with
suggest that if data
is that with the
priority are performed in
that with the traditional
are performed in parallel
or to synchronize replicas
hence can only send
to synchronize replicas if
that if data is
way the customers are
if data is laid
with the traditional style
data is laid out
in which sets of
synchronize replicas if more
the french air traffic
replicas if more than
french air traffic control
if more than one
air traffic control system
more than one is
is laid out on
than one is in
the customers are likely
one is in use
this ensures that the
customers are likely to
the traditional style of
are likely to use
laid out on disks
likely to use the
can only send data
to use the technology
a host acting as
only send data directly
in the case of
host acting as a
send data directly to
ensures that the directory
which sets of components
and the us navy
traditional style of web
the us navy s
out on disks according
us navy s aegis
acting as a client
data directly to a
that the directory contents
directly to a small
that it provides near
to a small subset
will the web services
a small subset of
on disks according to
the web services community
sets of components are
the directory contents and
style of web development
directory contents and apply
the case of ec
ibm s websphere platform
as a client of
disks according to frequency
a client of an
of components are interconnected
client of an mfs
it provides near lossless
components are interconnected and
s websphere platform and
web services community have
according to frequency of
contents and apply changes
to frequency of access
of an mfs file
small subset of interested
an mfs file system
provides near lossless tcp
websphere platform and the
services community have the
content is assumed to
with the most popular
is assumed to be
are interconnected and cooperate
assumed to be fetched
mfs file system runs
to be fetched from
file system runs a
be fetched from a
system runs a user
fetched from a server
subset of interested receivers
interconnected and cooperate to
ip throughput and latency
and cooperate to perform
throughput and latency over
cooperate to perform requests
and latency over lossy
the most popular files
latency over lossy links
community have the wisdom
participating nodes are consequently
the bandwidth costs are
nodes are consequently required
platform and the windows
bandwidth costs are actually
which receives file system
and the windows vista
costs are actually waived
most popular files being
and recovers packets with
are actually waived and
popular files being located
either directly over http
files being located in
the windows vista clustering
being located in one
and apply changes locally
located in one set
recovers packets with latency
in one set of
components sets are normally
one set of disks
or by interacting with
sets are normally colocated
have the wisdom to
actually waived and the
packets with latency independent
receives file system operations
are consequently required to
windows vista clustering system
by interacting with a
the wisdom to tackle
interacting with a web
waived and the user
with a web service
file system operations intercepted
consequently required to forward
and the least popular
required to forward packets
vista clustering system also
to forward packets to
wisdom to tackle the
forward packets to their
and the user then
packets to their neighbors
when a service is
the least popular ones
a service is replicated
clustering system also use
with latency independent of
system also use versions
web pages downloaded by
also use versions of
the user then pays
pages downloaded by clients
least popular ones in
to tackle the tough
each of its constituent
system operations intercepted by
tackle the tough issues
of its constituent components
operations intercepted by a
the tough issues before
downloaded by clients browsers
tough issues before circumstances
latency independent of the
helping disseminate all packets
use versions of the
disseminate all packets across
user then pays only
all packets across the
intercepted by a kernel
packets across the system
by clients browsers contain
issues before circumstances force
clients browsers contain embedded
as well as mak
browsers contain embedded addresses
its constituent components will
contain embedded addresses of
popular ones in another
embedded addresses of specific
independent of the rtt
addresses of specific servers
versions of the model
then pays only for
constituent components will need
pays only for the
the streamed data should
only for the traffic
of the rtt of
streamed data should be
by a kernel module
components will need to
although developers can t
then the latter set
developers can t access
application adapts itself to
can t access the
the rtt of the
t access the internal
before circumstances force it
access the internal mechanisms
circumstances force it upon
the internal mechanisms directly
force it upon them
adapts itself to the
data should be received
itself to the available
interacting with the vfs
to the available bandwidth
for the traffic between
the available bandwidth gracefully
the other popular standard
rtt of the link
other popular standard uses
will need to replicate
with the vfs layer
need to replicate its
technologies such as ajax
to replicate its portion
ing an rpc to
of the link and
an rpc to apply
the latter set of
rpc to apply the
the traffic between the
to apply the changes
traffic between the front
apply the changes to
popular standard uses a
the changes to the
standard uses a state
changes to the server
a fellow of the
to the server s
should be received by
the server s copy
end servers and their
be received by all
servers and their clients
such as ajax allow
machine approach to guarantee
replicate its portion of
approach to guarantee stronger
its portion of the
latter set of disks
portion of the service
set of disks could
table ii shows the
the link and the
ii shows the cost
to guarantee stronger durability
shows the cost of
whole since lower bandwidth
the cost of using
as ajax allow for
cost of using s
of disks could be
the vfs layer of
disks could be powered
received by all nodes
could be powered down
of the service state
be powered down to
ajax allow for asynchronous
powered down to conserve
vfs layer of the
down to conserve energy
fellow of the acm
by all nodes within
since lower bandwidth translates
link and the rate
leslie lamport s paxos
lower bandwidth translates into
layer of the local
all nodes within a
their scheme is called
and the rate in
nodes within a fixed
lamport s paxos algorithm
within a fixed latency
of the local file
if qsm is used
the local file system
for a number of
the rate in any
bandwidth translates into longer
rate in any single
scheme is called popular
in any single channel
a number of individual
a fixed latency from
number of individual open
we adopt the same
fixed latency from the
of individual open source
adopt the same approach
individual open source projects
but traffic is still
qsm is used to
traffic is still always
is used to disseminate
latency from the source
used to disseminate updates
the same approach to
is called popular data
as well as an
is still always routed
well as an aggregate
from the source s
as an aggregate for
m odel loss model
called popular data concentration
translates into longer delays
still always routed through
which is implemented in
always routed through a
same approach to intercepting
routed through a data
this results in a
through a data center
the source s original
is implemented in scalable
source s original transmission
approach to intercepting vfs
into longer delays for
packet loss typically occurs
results in a pattern
loss typically occurs at
implemented in scalable file
typically occurs at two
longer delays for lowerfile
occurs at two points
even in the presence
delays for lowerfile caching
and has worked on
to intercepting vfs operations
in scalable file systems
intercepting vfs operations as
an aggregate for the
vfs operations as lbfs
the clients don t
in a pattern of
clients don t talk
for lowerfile caching is
don t talk to
and they implement and
t talk to one
at two points in
they implement and evaluate
a pattern of communication
has worked on reliability
lowerfile caching is effective
scalable file systems and
talk to one another
in the presence of
two points in an
the presence of opportunistic
points in an end
presence of opportunistic nodes
worked on reliability and
repositories of the debian
file systems and other
of the debian community
implement and evaluate a
pattern of communication groups
caching is effective if
on reliability and scalability
making use of the
systems and other ultrareliable
live objects allow visual
of communication groups that
is effective if a
communication groups that are
we first assume a
groups that are exactly
and other ultrareliable server
that are exactly overlapped
objects allow visual content
reliability and scalability issues
end communication path between
and evaluate a prototype
communication path between two
use of the kernel
path between two data
also shown is an
between two data centers
each replicated component will
shown is an estimate
effective if a client
is an estimate for
if a client s
an estimate for the
other ultrareliable server designs
estimate for the apache
and scalability issues in
as shown in figure
evaluate a prototype file
scalability issues in distributed
of the kernel module
a client s connectivity
the kernel module provided
client s connectivity is
replicated component will have
s connectivity is uncertain
a prototype file server
issues in distributed systems
prototype file server called
for the apache software
file server called nomad
one architecture could support
server called nomad fs
area network connecting them
in distributed systems since
kernel module provided as
first assume a system
the apache software foundation
assume a system in
allow visual content and
a system in which
visual content and update
which runs on top
module provided as part
component will have one
provided as part of
will have one or
as part of the
have one or more
part of the arla
one or more associated
of the arla afs
architecture could support both
the arla afs client
apache has taken the
system in which all
distributed systems since starting
in which all nodes
runs on top of
rpc timeouts allow the
on top of the
network connecting them and
timeouts allow the application
has taken the unusual
content and update events
systems since starting his
or more associated groups
since starting his research
could support both of
starting his research career
allow the application to
taken the unusual approach
and update events to
have similar upload and
the unusual approach of
update events to be
the application to prevent
events to be communicated
connecting them and at
to be communicated using
similar upload and download
be communicated using any
upload and download bandwidths
communicated using any sort
application to prevent since
using any sort of
support both of these
to prevent since the
delivering update streams to
unusual approach of using
update streams to its
he is the author
streams to its replicas
them and at the
both of these powerful
prevent since the client
of these powerful technologies
top of the file
approach of using a
any sort of protocol
is the author of
and at the receiving
the author of many
at the receiving end
of the file system
a natural option would
the cache manager maintains
since the client can
cache manager maintains a
of using a single
manager maintains a cache
natural option would be
maintains a cache of
author of many articles
a cache of recently
the file system and
using a single repository
file system and monitors
option would be to
loss in the lambda
of many articles on
in the lambda link
many articles on the
accessed mfs files on
articles on the subject
mfs files on the
would be to offer
files on the local
but also overlay multicast
on the local disk
the lambda link can
a single repository for
lambda link can occur
the client can always
link can occur for
be to offer them
can occur for many
system and monitors data
occur for many reasons
when a vfs operation
client can always use
a datacenter will typically
can always use cached
single repository for all
always use cached copies
repository for all of
use cached copies of
for all of its
datacenter will typically host
all of its projects
and monitors data layout
a vfs operation is
monitors data layout on
cached copies of files
vfs operation is intercepted
will typically host many
to offer them in
typically host many services
we briefly discuss how
copies of files instead
operation is intercepted for
of files instead low
dirty or degraded fiber
is intercepted for a
even a custom protocol
intercepted for a file
and applications will be
for a file that
offer them in the
a file that is
them in the context
priority rpcs being silently
in the context of
rpcs being silently starved
the context of ws
malfunctioning or misconfigured equipment
briefly discuss how to
a custom protocol designed
discuss how to extend
each with a disjoint
data layout on disks
with a disjoint set
both public and restricted
a disjoint set of
custom protocol designed by
disjoint set of components
applications will be published
using priorities alof incrementally
will be published by
low receiver power and
be published by springer
due to access control
published by springer verlag
priorities alof incrementally fetching
and often deployed on
how to extend our
often deployed on disjoint
receiver power and burst
deployed on disjoint sets
power and burst switching
on disjoint sets of
their findings are that
disjoint sets of nodes
protocol designed by the
to extend our model
designed by the content
to access control restrictions
by the content provider
and burst switching contention
if you re replicating
findings are that if
file that is not
are that if the
by springer verlag in
that if the low
alof incrementally fetching them
burst switching contention are
incrementally fetching them from
you re replicating data
fetching them from the
that is not in
them from the server
springer verlag in fall
this makes it possible
switching contention are some
extend our model to
contention are some reasons
access control restrictions on
access disks are powered
control restrictions on some
disks are powered down
restrictions on some paths
re replicating data within
our model to work
is not in the
model to work in
not in the cache
to work in heterogeneous
in cases where two
work in heterogeneous scenarios
cases where two services
lows a programmer to
where two services are
makes it possible to
two services are co
subversion s mirroring tool
it possible to achieve
a programmer to write
possible to achieve extremely
we assume that malicious
this results in a
assume that malicious nodes
replicating data within some
located on the same
programmer to write an
on the same node
s mirroring tool was
results in a considerable
mirroring tool was unable
it is retrieved in
tool was unable to
to achieve extremely high
was unable to create
that malicious nodes exhibit
unable to create local
data within some form
to create local copy
to write an adaptive
achieve extremely high levels
we ll still see
extremely high levels of
ll still see heavy
high levels of throughput
still see heavy overlap
write an adaptive application
the complete log of
malicious nodes exhibit byzantine
complete log of timestamps
within some form of
levels of throughput and
some form of group
an adaptive application without
is retrieved in full
nodes exhibit byzantine behavior
retrieved in full from
of throughput and latency
in full from the
adaptive application without ports
full from the appropriate
but unless the degree
from the appropriate server
in a considerable performance
you can just as
a considerable performance hit
web services are not
unless the degree of
services are not distributed
application without ports this
are not distributed objects
while correct nodes follow
the degree of replication
correct nodes follow the
can just as easily
nodes follow the protocol
without ports this type
follow the protocol as
degree of replication is
the protocol as defined
and the vfs operation
how much does it
the vfs operation is
much does it cost
ports this type of
they suggest instead that
this type of disconnected
just as easily imagine
type of disconnected operation
vfs operation is then
of replication is identical
suggest instead that they
it also enhances security
instead that they be
as easily imagine that
that they be run
description monthly storage bandwidth
they be run at
operation is then resumed
be run at low
requesting data as needed
run at low speed
there may be two
easily imagine that it
may be two cases
data as needed and
the data center server
monthly storage bandwidth in
mfs uses the writeback
data center server can
storage bandwidth in bandwidth
while their idea is
center server can t
as needed and sending
nodes that host both
bandwidth in bandwidth out
that host both services
server can t see
imagine that it has
needed and sending data
that it has a
and sending data as
it has a subject
can t see data
has a subject name
and hence both sets
t see data exchanged
a subject name in
hence both sets of
see data exchanged directly
subject name in a
but not to the
name in a publish
their idea is sound
in bandwidth out per
both sets of qsm
close semantics first implemented
sets of qsm groups
sending data as requested
not to the ex
data as requested from
semantics first implemented in
loss can also occur
it is not clear
first implemented in the
as requested from them
implemented in the andrew
can also occur at
advantages with this type
data exchanged directly between
with this type of
is not clear whether
this type of process
having to take account
and nodes that just
exchanged directly between peers
nodes that just host
not clear whether this
that just host one
altrustic nodes are a
just host one of
to take account of
nodes are a subgroup
clear whether this scheme
also occur at receiving
the above discussion motivates
in the andrew file
above discussion motivates our
are a subgroup of
discussion motivates our problem
host one of them
a subgroup of correct
take account of the
data can be anything
the andrew file system
whether this scheme would
motivates our problem statement
this scheme would adapt
subgroup of correct nodes
scheme would adapt to
cluster management systems use
of correct nodes that
occur at receiving end
would adapt to different
account of the actual
adapt to different workloads
correct nodes that are
management systems use groups
allow web applications to
systems use groups for
nodes that are willing
use groups for purposes
web applications to overlay
groups for purposes other
of the actual bandwidth
for purposes other than
hosts within the destination
purposes other than component
that are willing to
within the destination data
applications to overlay content
the destination data center
the actual bandwidth or
are willing to upload
other than component replication
reads apache software foundation
actual bandwidth or current
propose another data layout
when a dirty file
to overlay content from
a dirty file is
these are usually cheap
overlay content from multiple
another data layout management
such as tracking node
willing to upload more
as tracking node status
bandwidth or current mix
tracking node status and
apache software foundation debian
node status and launching
data layout management scheme
status and launching applications
to upload more data
content from multiple sources
upload more data than
are usually cheap commodity
more data than required
dirty file is closed
data than required from
or current mix tent
than required from them
software foundation debian linux
w e b te
foundation debian linux community
usually cheap commodity machines
e b te c
these groups will span
the entire file contents
layout management scheme to
entire file contents are
cheap commodity machines prone
current mix tent of
b te c h
groups will span large
from multiple sources in
te c h n
multiple sources in a
commodity machines prone to
sources in a layered
will span large numbers
machines prone to temporary
file contents are transferred
we employ the term
contents are transferred to
mix tent of automatic
are transferred to the
management scheme to optimize
transferred to the server
prone to temporary overloads
c h n o
in a layered fashion
employ the term opportunistic
h n o l
span large numbers of
scheme to optimize disk
n o l o
tent of automatic reconciliation
the term opportunistic to
o l o g
of automatic reconciliation of
to optimize disk access
such that the distinct
to temporary overloads that
term opportunistic to refer
l o g i
large numbers of nodes
opportunistic to refer to
o g i e
that the distinct content
to refer to a
g i e s
the distinct content layers
temporary overloads that cause
i e s concerns
distinct content layers share
refer to a subgroup
content layers share a
automatic reconciliation of update
to a subgroup of
overloads that cause packets
perhaps the entire cluster
e s concerns experience
though scheme for minimising
layers share a single
s concerns experience with
scheme for minimising bandwidth
share a single view
that cause packets to
for minimising bandwidth utilisation
reconciliation of update conflicts
such groups overlap with
concerns experience with corba
groups overlap with everything
optimize disk access patterns
experience with corba even
a subgroup of byzantine
minimising bandwidth utilisation when
a single view and
cause packets to be
single view and remain
subgroup of byzantine nodes
view and remain well
with corba even good
and remain well synchronized
the result is an
bandwidth utilisation when transferring
result is an environment
packets to be dropped
corba even good ideas
to be dropped by
utilisation when transferring files
be dropped by the
of byzantine nodes that
dropped by the kernel
is an environment in
byzantine nodes that attempt
even good ideas can
by the kernel in
when transferring files is
the kernel in bursts
nodes that attempt to
good ideas can be
an environment in which
transferring files is not
on of rpcs at
or panning should cause
that attempt to give
panning should cause all
files is not used
should cause all layers
is not used in
cause all layers to
not used in mfs
attempt to give less
ideas can be used
of rpcs at runtime
their approach uses finer
environment in which there
all layers to respond
in which there will
can be used in
which there will be
although it is orthogonal
to give less data
layers to respond simultaneously
be used in ways
there will be a
it is orthogonal to
will be a hierarchy
grained control over data
is orthogonal to mfs
used in ways that
this loss mode occurs
in ways that developers
and an update in
control over data layout
orthogonal to mfs adaptation
over data layout on
loss mode occurs with
data layout on disk
mode occurs with udp
an update in any
and avoid having to
update in any of
give less data than
in any of the
to mfs adaptation and
any of the layers
ways that developers dislike
less data than they
avoid having to specify
data than they would
mfs adaptation and could
than they would if
of the layers should
they would if they
tuning it on a
would if they behaved
it on a per
if they behaved as
that developers dislike and
they behaved as correct
having to specify thresholds
behaved as correct nodes
adaptation and could be
the layers should be
and could be added
based traffic but not
could be added to
developers dislike and ultimately
be added to further
to specify thresholds at
added to further improve
layers should be reflected
to further improve performance
traffic but not with
specify thresholds at the
but not with tcp
thresholds at the other
with the intention of
at the other hand
qsm is highly effective
the intention of obtaining
dislike and ultimately reject
is highly effective in
applications are instrumented and
highly effective in supporting
intention of obtaining as
effective in supporting this
should be reflected in
in supporting this style
the server that stores
supporting this style of
are instrumented and then
server that stores a
of obtaining as much
a good example of
that stores a file
obtaining as much data
instrumented and then profiled
stores a file is
which advertises receiver windows
level caching reduces the
advertises receiver windows to
this style of use
receiver windows to prevent
good example of this
windows to prevent end
a file is responsible
be reflected in all
example of this occurred
file is responsible for
reflected in all other
caching reduces the delay
in all other layers
and then profiled to
is responsible for maintaining
as much data as
of this occurred when
much data as possible
then profiled to obtain
data as possible at
profiled to obtain array
as possible at least
allow updates to be
reduces the delay incurred
responsible for maintaining the
to obtain array access
this occurred when the
obtain array access sequences
updates to be carried
the delay incurred which
for maintaining the mutual
what are typical loss
possible at least feasible
are typical loss rates
to be carried by
typical loss rates on
recover in y inter
loss rates on long
occurred when the corba
at least feasible cost
delay incurred which it
which their system then
incurred which it should
maintaining the mutual consistency
which it should switch
region protocol y intra
the mutual consistency of
when the corba community
be carried by the
their system then uses
it should switch communication
mutual consistency of the
should switch communication modes
the corba community decided
carried by the protocol
system then uses to
these may employ a
consistency of the copies
may employ a simple
corba community decided to
employ a simple strategy
consisting of a small
an rpc whose results
community decided to tackle
by the protocol best
then uses to determine
decided to tackle replication
of the copies cached
of a small set
the copies cached by
the answer to this
copies cached by clients
uses to determine optimal
to tackle replication for
rpc whose results are
such as refuse to
tackle replication for fault
the protocol best matched
answer to this question
replication for fault tolerance
a small set of
whose results are urgently
small set of servers
to determine optimal disk
set of servers to
it records which clients
of servers to which
records which clients cache
as refuse to contribute
which clients cache the
protocol best matched to
clients cache the file
to this question is
for fault tolerance but
this question is surprisingly
results are urgently required
fault tolerance but then
determine optimal disk layouts
are urgently required should
servers to which client
question is surprisingly hard
and is responsible for
best matched to the
is responsible for notifying
optimal disk layouts by
responsible for notifying them
to which client systems
for notifying them of
is surprisingly hard to
notifying them of changes
matched to the setting
urgently required should be
disk layouts by computing
refuse to contribute any
layouts by computing optimal
tolerance but then stumbled
by computing optimal stripe
required should be aswhen
but then stumbled by
to contribute any upload
to the setting in
then stumbled by presenting
which client systems connect
mfs implements a variation
should be aswhen an
contribute any upload resources
be aswhen an application
the setting in which
aswhen an application opens
implements a variation of
an application opens a
stumbled by presenting the
application opens a file
computing optimal stripe factor
by presenting the technology
or a more elaborate
a variation of the
setting in which the
variation of the scheme
a more elaborate strategy
of the scheme used
presenting the technology to
size of repository stored
level multicast is vectored
the technology to developers
the scheme used by
in which the application
scheme used by coda
more elaborate strategy that
multicast is vectored through
technology to developers in
is vectored through a
which the application is
vectored through a server
elaborate strategy that allows
of repository stored in
when a file is
as has been shown
a file is retrieved
to developers in a
file is retrieved from
repository stored in s
is retrieved from the
has been shown in
retrieved from the server
been shown in the
which multicasts it to
shown in the low
the application is used
strategy that allows them
developers in a way
the wisdom of marrying
in a way that
the server issues a
multicasts it to its
server issues a limited
wisdom of marrying the
a way that was
that allows them to
way that was much
of marrying the disk
it to its peers
allows them to cheat
that was much too
them to cheat without
so we based our
to cheat without being
the solutions discussed here
we based our analysis
marrying the disk layout
cheat without being easily
these filter the ordered
obliging it to inform
based our analysis on
was much too limiting
the disk layout to
managed transactional consistency for
without being easily detected
filter the ordered multicast
it to inform the
transactional consistency for web
much too limiting for
solutions discussed here are
too limiting for general
our analysis on that
limiting for general use
notice that our model
disk layout to the
analysis on that along
layout to the application
the ordered multicast stream
to the application seems
to inform the client
the application seems questionable
consistency for web caching
discussed here are based
it is possible to
for web caching ittay
ordered multicast stream and
that our model diverges
inform the client through
here are based on
on that along with
are based on live
web caching ittay eyal
based on live objects
our model diverges from
caching ittay eyal ken
tolerance mechanism is based
is possible to use
mechanism is based on
multicast stream and relay
is based on the
proposed by zhu et
based on the virtual
ittay eyal ken birman
on the virtual synchrony
possible to use a
the virtual synchrony model
stream and relay messages
model diverges from the
that along with the
diverges from the one
the client through a
from the one used
and relay messages back
the one used in
along with the assumption
but the programming tools
client through a callback
with the assumption each
the programming tools built
through a callback if
programming tools built over
eyal ken birman robbert
tools built over this
one used in bar
built over this model
used in bar gossip
a callback if another
relay messages back out
callback if another host
new types of components
to use a signed
over this model prevent
use a signed the
the assumption each revision
a signed the highest
combines a number of
signed the highest priority
a number of ideas
this model prevent developers
messages back out to
if another host modifies
in which nodes are
types of components must
which nodes are classified
model prevent developers from
nodes are classified as
it assumes multispeed disks
another host modifies the
ken birman robbert van
host modifies the file
back out to receivers
particularly if the rpc
assumption each revision data
if the rpc contains
are classified as byzantine
the rpc contains outcontent
birman robbert van renesse
prevent developers from using
each revision data file
if the callback promise
of components must be
the callback promise expires
developers from using threads
and computes online the
based division of files
revision data file would
division of files into
data file would be
callback promise expires without
this approach can support
promise expires without a
robbert van renesse cornell
expires without a callback
of files into blocks
without a callback being
approach can support huge
a callback being issued
van renesse cornell university
computes online the optimal
files into blocks as
online the optimal speed
into blocks as the
renesse cornell university abstract
blocks as the basis
rational nodes attempt to
as the basis for
the client must revalidate
nodes attempt to maximize
can support huge numbers
cornell university abstract in
support huge numbers of
components must be created
huge numbers of groups
the basis for re
numbers of groups with
attempt to maximize their
of groups with irregular
guis or other direct
groups with irregular overlap
or other direct end
with irregular overlap patterns
to maximize their utility
must be created for
client must revalidate the
be created for each
kib and each revision
created for each type
the optimal speed that
for each type of
maximize their utility while
each type of content
must revalidate the file
optimal speed that each
only caches are widely
and each revision property
their utility while still
each revision property file
but the servers are
speed that each disk
caches are widely used
revalidate the file before
utility while still following
the file before using
that each disk should
but the existing collection
each disk should run
the servers are a
disk should run at
while still following the
file before using it
still following the defined
the existing collection of
following the defined protocol
servers are a point
existing collection of components
but still important rpcs
are widely used in
collection of components provides
to minimize speed transition
are a point of
minimize speed transition overheads
a point of contention
our model is actually
of components provides access
model is actually less
still important rpcs can
components provides access to
the averages observed for
or even prebuilt libraries
provides access to several
averages observed for the
disks maintain their speeds
access to several different
is actually less lenient
widely used in cloud
important rpcs can ducing
used in cloud infrastructure
rpcs can ducing client
in the corba approach
in cloud infrastructure to
to several different types
observed for the other
the cache consistency algorithm
for the other repositories
nodes employing strategies to
cache consistency algorithm is
several different types of
and the indirect communication
different types of web
the other repositories in
cloud infrastructure to reduce
other repositories in table
consistency algorithm is described
maintain their speeds for
algorithm is described in
their speeds for a
employing strategies to maximize
speeds for a fixed
a developer who obeys
repositories in table ii
the indirect communication pathway
developer who obeys this
is described in more
indirect communication pathway introduces
described in more detail
types of web services
in more detail in
table ii m ost
strategies to maximize their
ii m ost recent
infrastructure to reduce access
to maximize their utility
of web services hosted
of lost packets fig
communication pathway introduces potentially
m ost recent monthly
who obeys this long
ost recent monthly cost
maximize their utility are
recent monthly cost of
web services hosted content
monthly cost of storing
while the lowest levels
cost of storing repositories
obeys this long list
of storing repositories in
they call this the
storing repositories in s
their utility are classified
call this the coarse
more detail in section
the lowest levels are
this long list of
pathway introduces potentially high
lowest levels are useful
long list of constraints
including all the examples
levels are useful for
list of constraints can
all the examples given
introduces potentially high latencies
of constraints can do
to reduce access latency
utility are classified as
reduce access latency and
are useful for server
access latency and to
for individual projects and
latency and to reduce
useful for server traffic
and to reduce load
the examples given above
to reduce load on
loss rates on teragrid
reduce load on backend
individual projects and entire
load on backend databases
for server traffic does
constraints can do lockstep
are classified as byzantine
rates on teragrid determine
hibernator includes a file
these considerations convinced us
projects and entire communities
server traffic does not
can do lockstep replication
operators view coherent caches
includes a file server
view coherent caches as
and entire communities software
perhaps because such links
do lockstep replication of
entire communities software project
considerations convinced us that
lockstep replication of a
communities software project squirrelmail
convinced us that a
the resulting live application
so that we can
because such links are
that we can build
traffic does not eliminate
such links are a
replication of a program
does not eliminate the
software project squirrelmail phpmyadmin
us that a new
resulting live application is
that a new system
we can build a
coherent caches as impractical
adaptive rpc library the
caches as impractical at
of a program for
as impractical at genuinely
rpc library the fundamental
a program for tolerance
live application is stored
library the fundamental difference
application is stored as
links are a relatively
the fundamental difference between
project squirrelmail phpmyadmin subversion
impractical at genuinely large
fundamental difference between mfs
squirrelmail phpmyadmin subversion mono
a new system was
can build a practical
new system was needed
not eliminate the fundamental
are a relatively recent
a file server that
at genuinely large scale
a relatively recent addition
difference between mfs and
phpmyadmin subversion mono kde
relatively recent addition to
is stored as an
subversion mono kde hosting
program for tolerance of
genuinely large scale and
file server that sits
between mfs and other
build a practical punishment
eliminate the fundamental problem
qsm implements a approach
stored as an xml
recent addition to the
as an xml file
for tolerance of hardware
addition to the networking
tolerance of hardware faults
mfs and other file
based system in which
implements a approach similar
and other file systems
large scale and many
server that sits on
the file can be
the fundamental problem of
that sits on top
system in which any
a approach similar to
scale and many client
other file systems we
to the networking landscape
mono kde hosting community
file systems we have
fundamental problem of rpcs
sits on top of
problem of rpcs that
approach similar to spread
of rpcs that can
the networking landscape and
rpcs that can be
systems we have described
networking landscape and their
facing caches are updated
we have described is
landscape and their ownership
similar to spread s
have described is in
and their ownership is
to spread s lightweight
described is in the
their ownership is still
caches are updated in
ownership is still mostly
kde hosting community debian
the scheme doesn t
hosting community debian linux
in which any node
community debian linux community
spread s lightweight group
which any node not
file can be moved
are updated in an
is still mostly restricted
updated in an asynchronous
scheme doesn t protect
in an asynchronous manner
debian linux community apache
doesn t protect against
s lightweight group abstraction
t protect against software
can be moved about
that can be arbitrarily
be moved about and
can be arbitrarily delayed
an asynchronous manner with
is in the communication
asynchronous manner with best
any node not contributing
in the communication between
on top of the
the communication between the
linux community apache software
but without a separate
community apache software foundation
such as speculative activities
apache software foundation monthly
top of the file
software foundation monthly cost
still mostly restricted to
of the file system
without a separate server
moved about and even
a separate server group
developers regard the standard
node not contributing its
regard the standard as
mostly restricted to commercial
not contributing its fair
as speculative activities like
communication between the cache
about and even embedded
between the cache manager
the standard as rigid
the cache manager and
standard as rigid and
cache manager and servers
as rigid and limited
existing solutions that support
we define a region
and even embedded in
the file system and
even embedded in email
contributing its fair share
speculative activities like prefetching
solutions that support cache
they need fault tolerance
activities like prefetching and
file system and manipulates
like prefetching and transferring
while lbfs uses a
define a region of
restricted to commercial organizations
that support cache consistency
a region of overlap
to commercial organizations disinclined
but not in this
region of overlap to
commercial organizations disinclined to
lbfs uses a variant
system and manipulates data
support cache consistency are
prefetching and transferring archival
users that open it
and transferring archival data
its fair share of
of overlap to be
fair share of data
uses a variant of
share of data may
cache consistency are inapplicable
not in this very
that open it find
in this very narrow
overlap to be a
this very narrow form
a variant of the
of data may be
variant of the nfs
organizations disinclined to reveal
of the nfs rpc
disinclined to reveal such
the nfs rpc protocol
to reveal such information
consistency are inapplicable to
data may be expelled
if the inicontention for
may be expelled from
and manipulates data layout
be expelled from the
are inapplicable to this
systems like the isis
the inicontention for insufficient
like the isis toolkit
manipulates data layout to
open it find themselves
data layout to put
inapplicable to this scenario
layout to put the
to be a set
to put the most
expelled from the system
be a set of
popular during the early
to this scenario since
during the early and
it find themselves immersed
the early and mid
find themselves immersed into
inicontention for insufficient bandwidth
themselves immersed into the
one source of information
accessed data on the
this scenario since they
data on the highest
scenario since they require
source of information is
since they require a
a set of nodes
they require a round
tial assumption regarding the
require a round trip
of information is teragrid
assumption regarding the correct
throughout the paper we
set of nodes with
immersed into the application
the paper we use
on the highest speed
regarding the correct priority
paper we use the
of nodes with approximately
the highest speed disks
we use the terms
the correct priority level
a round trip to
use the terms upload
several transport protocols optimized
nodes with approximately the
correct priority level for
round trip to the
uses a customised rpc
trip to the database
the authors address the
to the database on
the terms upload factor
the database on every
also used virtual synchrony
database on every cache
priority level for an
on every cache transaction
authors address the issue
with approximately the same
terms upload factor and
approximately the same group
transport protocols optimized for
upload factor and download
address the issue of
existing incoherent cache technologies
factor and download factor
incoherent cache technologies are
an optical network interconnecting
cache technologies are oblivious
used virtual synchrony but
technologies are oblivious to
unlike coda s rpc
are oblivious to transactional
level for an rpc
oblivious to transactional data
and download factor to
to transactional data access
the same group membership
download factor to refer
the issue of performance
protocols optimized for various
for an rpc proves
the rpc used in
even if the backend
factor to refer to
if the backend database
issue of performance guarantees
the backend database supports
to refer to the
backend database supports transactions
virtual synchrony but had
refer to the ratio
optical network interconnecting major
optimized for various settings
of performance guarantees by
for various settings are
rpc used in mfs
synchrony but had fewer
to the ratio between
but had fewer limitations
an rpc proves incorrect
performance guarantees by stipulating
various settings are or
used in mfs incorporates
settings are or will
the ratio between an
are or will be
network interconnecting major supercomputing
they supported many of
guarantees by stipulating that
aware cache for read
supported many of the
by stipulating that if
in mfs incorporates novel
stipulating that if performance
interconnecting major supercomputing sites
under the assumptions of
major supercomputing sites in
or will be available
supercomputing sites in the
a call to the
sites in the us
that if performance drops
ratio between an upload
if performance drops below
even for the fairly
performance drops below some
will be available in
drops below some threshold
call to the library
teragrid has a monitoring
between an upload or
many of the mechanisms
for the fairly large
mfs incorporates novel features
the fairly large apache
be available in a
incorporates novel features to
then all disks are
to the library can
has a monitoring framework
an upload or download
of the mechanisms needed
cache improves cache consistency
upload or download rate
the assumptions of section
or download rate and
novel features to allow
download rate and the
all disks are spun
rate and the original
a monitoring framework within
and the original stream
the mechanisms needed to
the original stream rate
available in a near
the library can be
in a near future
disks are spun up
fairly large apache software
are spun up to
large apache software foundation
mechanisms needed to build
features to allow it
needed to build and
monitoring framework within which
improves cache consistency despite
including support for wan
our cluster should be
support for wan networks
to allow it to
given a stream rate
framework within which ten
a stream rate of
the current cost of
cache consistency despite asynchronous
current cost of using
cluster should be nicely
cost of using s
to build and manage
allow it to adapt
build and manage a
within which ten sites
and manage a raps
consistency despite asynchronous and
manage a raps of
should be nicely tiled
a raps of racs
it to adapt to
library can be made
to adapt to network
for wan networks with
adapt to network variability
despite asynchronous and unreliable
spun up to their
asynchronous and unreliable communication
which ten sites periodically
and unreliable communication between
for storage is less
unreliable communication between the
be nicely tiled by
communication between the cache
and their successes have
between the cache and
can be made to
the cache and the
their successes have clearly
cache and the database
nicely tiled by regions
the mfs rpc library
a download rate of
ten sites periodically send
wan networks with nats
sites periodically send each
be made to assign
periodically send each other
successes have clearly demonstrated
mfs rpc library is
storage is less than
rpc library is implemented
up to their highest
made to assign a
to their highest speed
have clearly demonstrated the
gbps streams of udp
library is implemented on
streams of udp packets
a variant of serializability
networks with nats and
clearly demonstrated the model
with nats and firewalls
is implemented on top
of udp packets and
variant of serializability that
udp packets and measure
demonstrated the model s
packets and measure the
kbps corresponds to a
and measure the resulting
qsm uses regions for
measure the resulting loss
caching solutions zhu et
uses regions for multicast
it is very unlikely
implemented on top of
corresponds to a download
on top of the
to a download factor
top of the adaptive
a download factor of
of the adaptive transport
of serializability that is
client cache consistency new
serializability that is suitable
cache consistency new priority
that is suitable for
the resulting loss rate
is suitable for incoherent
the model s effectiveness
suitable for incoherent caches
regions for multicast dissemination
the adaptive transport protocol
is very unlikely that
for multicast dissemination and
when a client fetches
multicast dissemination and for
very unlikely that any
and prove that with
a client fetches a
prove that with unbounded
isis is no longer
that with unbounded resources
dissemination and for recovery
with unbounded resources t
observe that the storage
is no longer available
client fetches a file
unlikely that any vendor
and for recovery of
that the storage cache
for recovery of lost
that any vendor could
recovery of lost packets
no longer available as
the storage cache management
longer available as a
in discussing mfs rpc
storage cache management policy
any vendor could provide
the file server grants
available as a product
cache management policy is
vendor could provide a
management policy is pivotal
each site measures the
cache allows the system
file server grants it
allows the system manager
could provide a traditional
the system manager to
yet many critical systems
system manager to choose
site measures the loss
many critical systems continue
server grants it permission
critical systems continue to
employing different protocols for
systems continue to use
policy is pivotal in
continue to use isis
streaming system model our
is pivotal in determining
we give an overview
pivotal in determining the
provide a traditional storage
different protocols for each
manager to choose a
measures the loss rate
to choose a trade
based solutions or other
the loss rate to
in determining the sequence
loss rate to every
protocols for each purpose
rate to every other
system model our auditing
to every other site
give an overview of
solutions or other virtual
a traditional storage solution
determining the sequence of
high throughput and very
off between performance and
throughput and very large
the sequence of requests
and very large numbers
sequence of requests that
very large numbers of
of requests that access
large numbers of nodes
requests that access disks
between performance and consistency
model our auditing approach
every other site once
our auditing approach is
an overview of the
other site once an
overview of the parts
our evaluation shows that
of the parts of
traditional storage solution consisting
auditing approach is used
storage solution consisting of
grants it permission to
solution consisting of scsi
or other virtual synchrony
consisting of scsi disks
the parts of atp
of scsi disks and
approach is used over
scsi disks and tape
it permission to cache
disks and tape backup
other virtual synchrony implementations
and tape backup at
cache management policies could
tape backup at this
protocol node x recover
backup at this price
management policies could be
node x recover in
evaluation shows that t
policies could be tailored
parts of atp which
site once an hour
of atp which are
permission to cache the
atp which are most
could be tailored to
which are most relevant
the amount of s
are most relevant to
machine approach as used
resulting in a total
is used over the
be tailored to change
used over the chainsaw
tailored to change the
storage required of course
most relevant to mfs
to change the average
approach as used in
change the average idle
x recover in x
the average idle time
over the chainsaw protocol
average idle time between
cache detects many inconsistencies
idle time between disk
in a total of
time between disk requests
to cache the file
recover in x region
cache the file for
in x region figure
atp and its design
as used in the
required of course increases
large numbers of irregularly
of course increases each
thus providing more opportunities
numbers of irregularly overlapping
all nodes participating in
the file for a
loss rate measurements collected
and its design motivations
rate measurements collected across
used in the paxos
measurements collected across the
of irregularly overlapping multicast
collected across the network
nodes participating in the
across the network every
course increases each month
participating in the system
increases each month as
in the paxos algorithm
each month as the
hierarchical recovery in qsm
month as the repository
file for a limited
as the repository grows
its design motivations have
providing more opportunities for
in the system are
more opportunities for reducing
the paxos algorithm is
opportunities for reducing disk
a group spans multiple
for a limited period
group spans multiple regions
detects many inconsistencies with
the system are organized
many inconsistencies with only
but as shown in
system are organized into
as shown in figure
for reducing disk energy
design motivations have been
reducing disk energy consumption
inconsistencies with only nominal
the network every hour
with only nominal overhead
are organized into a
irregularly overlapping multicast groups
organized into a fully
each region has an
into a fully connected
paxos algorithm is also
the increase is roughly
we use synthetic workloads
increase is roughly linear
a fully connected mesh
and adds it to
fully connected mesh overlay
adds it to a
cache policies that are
it to a list
motivations have been described
algorithm is also becoming
region has an associated
is also becoming more
use synthetic workloads to
also becoming more popular
synthetic workloads to demonstrate
have been described in
workloads to demonstrate the
has an associated structure
to demonstrate the efficacy
where each node has
demonstrate the efficacy of
shows that between nov
the efficacy of t
as developer productivity remains
an associated structure of
developer productivity remains constant
each node has the
been described in more
node has the same
policies that are aware
has the same number
implementation of clients that
described in more detail
the cost of storage
cache when data accesses
in more detail in
that are aware of
more detail in our
of clients that cache
detail in our earlier
clients that cache the
in our earlier work
that cache the file
the same number of
are aware of the
same number of neighbors
and strong reliability properties
cost of storage is
the key insight is
of storage is declining
associated structure of token
storage is declining exponentially
when data accesses are
key insight is that
aware of the underlying
the source is randomly
insight is that these
of the underlying disk
if the client modifies
is that these successes
data accesses are clustered
source is randomly connected
the underlying disk management
structure of token rings
underlying disk management schemes
that these successes use
accesses are clustered and
is randomly connected to
are clustered and its
these successes use similar
clustered and its adaptive
randomly connected to a
successes use similar ideas
and its adaptive reaction
the client modifies and
its adaptive reaction to
the hypothesis underlying atp
adaptive reaction to workload
so if amazon s
reaction to workload changes
hypothesis underlying atp is
use similar ideas but
which disks are running
underlying atp is that
similar ideas but in
connected to a small
ideas but in ways
if amazon s pricing
to recover from packet
amazon s pricing stays
client modifies and then
s pricing stays competitive
modifies and then closes
disks are running at
and then closes the
atp is that adapting
then closes the file
to a small subset
is that adapting to
but in ways very
are running at which
in ways very different
running at which speeds
a small subset of
that adapting to network
small subset of the
with workloads based on
adapting to network variation
workloads based on the
recover from packet loss
based on the real
subset of the nodes
ways very different from
term trend is towards
to network variation by
trend is towards lower
it transmits the new
is towards lower costs
very different from what
network variation by structuring
different from what the
can make more intelligent
variation by structuring applications
transmits the new contents
from what the corba
additional costs will be
make more intelligent replacement
costs will be incurred
before saying more about
more intelligent replacement decisions
saying more about our
what the corba fault
more about our approach
of all such measurements
the new contents to
all such measurements were
qsm uses a hierarchical
such measurements were over
the streaming process starts
the authors present both
new contents to the
authors present both offline
contents to the server
we analyze a concrete
streaming process starts at
by structuring applications according
analyze a concrete example
will be incurred for
structuring applications according to
be incurred for front
uses a hierarchical structure
present both offline and
a hierarchical structure of
both offline and online
applications according to modes
offline and online power
which mafs is implemented
a concrete example of
mafs is implemented in
hierarchical structure of token
concrete example of a
according to modes is
process starts at the
to modes is not
starts at the source
modes is not always
structure of token rings
is not always appropriate
example of a soc
of the inconsistencies and
aware cache replacement algorithms
the inconsistencies and increases
what we need today
cache replacement algorithms to
of a soc application
replacement algorithms to optimize
inconsistencies and increases the
a soc application more
which breaks the data
is implemented in c
we considered using other
implemented in c on
for the case of
in c on freebsd
the case of ec
and increases the rate
soc application more carefully
breaks the data stream
we need today is
considered using other structures
algorithms to optimize read
and can sometimes lead
to optimize read accesses
the client is a
can sometimes lead to
need today is a
client is a usermakes
of them were over
increases the rate of
today is a modern
the rate of consistent
application more carefully to
rate of consistent transactions
they also show through
more carefully to expose
sometimes lead to poor
a standard machine instance
but token rings produce
is a modern revisiting
token rings produce a
the data stream into
rings produce a more
a modern revisiting of
data stream into packets
is a usermakes a
standard machine instance is
modern revisiting of this
machine instance is billed
carefully to expose the
instance is billed at
produce a more predictable
to expose the full
of consistent transactions by
a more predictable traffic
expose the full range
lead to poor performance
the full range of
stream into packets and
full range of needs
also show through experiments
into packets and sends
revisiting of this technology
show through experiments the
packets and sends notifications
more predictable traffic pattern
of this technology that
and sends notifications to
range of needs and
through experiments the somewhat
this technology that draws
a usermakes a callback
sends notifications to its
of needs and issues
after eliminating a single
the importance of this
eliminating a single site
importance of this will
notifications to its neighbors
of this will become
needs and issues that
this will become clear
technology that draws on
will become clear later
shows the results of
plus data transfer of
that draws on group
and issues that arise
usermakes a callback rpc
to its neighbors as
a callback rpc to
that dropped incoming packets
draws on group communication
dropped incoming packets steadily
the results of an
incoming packets steadily at
i ntroduction internet services
experiments the somewhat obvious
results of an experiment
ntroduction internet services like
consider a rescue mission
internet services like online
packets steadily at a
its neighbors as soon
steadily at a rate
the basic structure is
at a rate of
of an experiment in
basic structure is illustrated
a rescue mission coordinator
structure is illustrated in
on group communication but
is illustrated in figure
the somewhat obvious fact
callback rpc to any
somewhat obvious fact that
an experiment in which
obvious fact that for
per gib in and
fact that for write
services like online retailers
that for write accesses
neighbors as soon as
group communication but packages
as soon as it
a police or fire
soon as it has
like online retailers and
at the highest level
communication but packages it
rpc to any other
as it has packets
but packages it in
it has packets to
online retailers and social
packages it in a
experiment in which modeless
qsm circulates tokens around
it in a way
to any other clients
retailers and social networks
in a way that
back policies offer more
has packets to disseminate
policies offer more opportunities
circulates tokens around sets
offer more opportunities to
tokens around sets of
and social networks store
around sets of regions
in which modeless adaptation
police or fire chief
any other clients on
which modeless adaptation over
these notifications are small
social networks store important
discounts are available if
notifications are small messages
or fire chief coordinating
a way that developers
aggregating information that can
fire chief coordinating teams
more opportunities to save
information that can be
chief coordinating teams who
are small messages used
that can be used
coordinating teams who will
small messages used only
can be used by
of the remainder were
messages used only to
be used by a
the remainder were over
used only to inform
used by a group
networks store important data
teams who will enter
store important data sets
opportunities to save power
who will enter a
modeless adaptation over atp
way that developers perceive
only to inform neighbors
by a group sender
that developers perceive as
important data sets in
a group sender to
data sets in large
will enter a disaster
sets in large distributed
adaptation over atp achieves
in large distributed databases
other clients on the
over atp achieves higher
to save power than
group sender to retransmit
save power than write
to inform neighbors of
enter a disaster zone
developers perceive as solving
clients on the list
atp achieves higher bandwidth
perceive as solving their
sender to retransmit packets
achieves higher bandwidth utilisation
as solving their most
to retransmit packets that
inform neighbors of the
solving their most pressing
a disaster zone in
are available if data
a client level process
available if data transfer
retransmit packets that were
if data transfer exceeds
their most pressing scalability
higher bandwidth utilisation than
disaster zone in the
technical challenges have forced
client level process that
challenges have forced such
packets that were missed
have forced such large
bandwidth utilisation than we
zone in the wake
in the context of
in the wake of
the context of write
most pressing scalability problems
that were missed by
utilisation than we will
were missed by entire
level process that stores
missed by entire regions
system operators to forgo
pressing scalability problems and
operators to forgo transactional
and the instance cost
scalability problems and that
the instance cost may
process that stores cached
instance cost may be
to forgo transactional consistency
that stores cached files
the wake of a
stores cached files in
neighbors of the availability
cached files in a
than we will concentrate
files in a local
wake of a catastrophe
we will concentrate on
of the availability of
a very natural candidate
the availability of new
providing perobject consistency instead
in a local filesystem
cost may be reduced
of a catastrophe to
may be reduced to
will concentrate on a
a catastrophe to help
these numbers may look
catastrophe to help survivors
problems and that flexibly
very natural candidate is
concentrate on a system
natural candidate is the
often with some form
candidate is the log
with some form of
and that flexibly matches
some form of eventual
the that receives a
form of eventual consistency
numbers may look small
a token circulates to
may look small in
that flexibly matches their
look small in absolute
that receives a callback
small in absolute terms
token circulates to provide
receives a callback rpc
flexibly matches their preferred
circulates to provide loss
on a system with
a callback rpc discards
a system with a
matches their preferred styles
system with a single
availability of new packets
with a single server
per hour by paying
but they are sufficient
hour by paying a
to provide loss recovery
they are sufficient to
their preferred styles and
are sufficient to bring
provide loss recovery at
sufficient to bring tcp
preferred styles and tools
loss recovery at the
based on the received
recovery at the level
on the received notifications
callback rpc discards its
mfs is designed to
rpc discards its cached
at the level of
ip throughput crashing down
other kinds of persistent
throughput crashing down on
the level of nodes
crashing down on high
discards its cached copy
kinds of persistent objects
its cached copy of
we now give a
cached copy of the
level of nodes belonging
copy of the file
is designed to support
now give a brief
and move supplies as
of nodes belonging to
move supplies as needed
each node requests missing
designed to support multiple
node requests missing packets
year reservation fee in
nodes belonging to the
give a brief overview
belonging to the region
server also stores its
to support multiple mfs
reservation fee in advance
a brief overview of
conventional wisdom states that
and the source satisfies
support multiple mfs file
brief overview of the
multiple mfs file servers
wisdom states that optical
this gives an amortized
the source satisfies as
gives an amortized monthly
overview of the log
source satisfies as many
states that optical links
also stores its copies
that optical links do
the user simply designs
optical links do not
an amortized monthly cost
links do not drop
amortized monthly cost of
stores its copies of
if regions become large
satisfies as many requests
structured file system before
do not drop packets
would arrive on the
user simply designs a
arrive on the scene
modal adaptation modeless adaptation
simply designs a data
file system before describing
its copies of files
system before describing the
qsm partitions them into
before describing the power
as many requests as
build a new collaboration
designs a data structure
a new collaboration tool
copies of files in
a data structure and
support transactions with guarantees
partitions them into smaller
saving opportunity it represents
them into smaller rings
of files in a
data structure and employs
files in a local
transactions with guarantees such
in a local filesystem
grade optical equipment is
and distribute it to
true bandwidth bandwidth used
many requests as allowed
this is illustrated in
optical equipment is configured
requests as allowed by
distribute it to his
as allowed by its
as we show in
allowed by its upload
we show in the
with guarantees such as
show in the next
structure and employs multicast
in the next section
equipment is configured to
and employs multicast technology
is configured to shut
is illustrated in figure
configured to shut down
guarantees such as snapshot
to shut down beyond
employs multicast technology to
shut down beyond bit
if an application has
down beyond bit error
such as snapshot isolation
beyond bit error rates
multicast technology to transmit
each team member would
one instance should be
team member would carry
structured file system the
as snapshot isolation and
file system the log
technology to transmit updates
in the experiments reported
instance should be enough
an application has the
should be enough for
bit error rates of
snapshot isolation and even
by its upload capacity
isolation and even full
the experiments reported in
and even full transactional
application has the file
even full transactional atomicity
has the file open
member would carry a
the file open when
would carry a tablet
file open when its
experiments reported in this
open when its client
to transmit updates to
when its client re
was motivated by a
our work begins with
be enough for almost
work begins with the
transmit updates to the
begins with the observation
reported in this paper
with the observation that
style device with wireless
enough for almost any
system operations from applications
one out of a
updates to the group
out of a trillion
with chainsaw the upload
of a trillion bits
device with wireless communication
operations from applications are
to the group members
for almost any individual
motivated by a need
almost any individual project
no token ring ever
any individual project or
from applications are redirected
individual project or moderately
by a need to
applications are redirected to
with wireless communication capabilities
are redirected to user
chainsaw the upload capacity
redirected to user level
it can be difficult
the upload capacity of
which apply them in
a need to optimize
apply them in the
project or moderately sized
them in the same
or moderately sized community
can be difficult for
upload capacity of the
be difficult for client
need to optimize the
to user level ceives
to optimize the latency
the reliability of the
optimize the latency of
token ring ever grows
the latency of write
the application built by
tier applications to leverage
in the same order
applications to leverage the
capacity of the source
to leverage the transactions
user level ceives the
leverage the transactions that
level ceives the callback
reliability of the lambda
the same order everywhere
of the lambda network
of the source does
the lambda network is
usage patterns in addition
the source does not
ring ever grows larger
patterns in addition to
source does not need
the file is discarded
in addition to getting
writing a block of
file is discarded once
ever grows larger than
is discarded once it
grows larger than about
discarded once it is
lambda network is clearly
once it is closed
a block of data
the transactions that the
does not need to
transactions that the databases
addition to getting a
that the databases provide
can be done on
application built by the
be done on any
network is clearly not
done on any desired
is clearly not equal
on any desired copy
clearly not equal to
built by the coordinator
their reads are satisfied
to getting a grasp
by the coordinator would
not need to increase
not equal to the
block of data to
equal to the sum
when through a kernel
getting a grasp of
the coordinator would be
a grasp of the
and the system uses
reads are satisfied primarily
the system uses single
of data to a
system uses single and
need to increase with
uses single and two
grasp of the costs
to the sum of
of the costs involved
the sum of its
through a kernel module
data to a seagate
coordinator would be installed
to a seagate barracuda
examples of updates include
a seagate barracuda disk
the costs involved in
sum of its optical
costs involved in moving
of its optical parts
would be installed on
are satisfied primarily from
of updates include a
satisfied primarily from incoherent
to increase with the
primarily from incoherent cache
involved in moving a
be installed on each
in moving a repository
updates include a stock
moving a repository to
increase with the size
a repository to s
installed on each team
we plan to experiment
on each team member
include a stock trade
each team member s
seagate barracuda disk costs
team member s mobile
the benefits of caching
member s mobile device
benefits of caching are
it s less reliable
of caching are twofold
s less reliable by
it is important to
less reliable by orders
is important to understand
reliable by orders of
with the size of
barracuda disk costs about
the size of the
plan to experiment with
a stock trade or
important to understand the
by orders of magnitude
to understand the usage
a kernel module at
it reduces database load
to experiment with larger
stock trade or stock
and in the offices
trade or stock market
size of the system
or stock market quote
experiment with larger configurations
understand the usage patterns
in the offices in
kernel module at the
the offices in mission
module at the client
applications and protocols such
thereby enabling higher throughput
and protocols such as
offices in mission headquarters
with larger configurations and
especially the rate at
a new object detected
the rate at which
protocols such as tcp
rate at which commits
even an upload capacity
at which commits take
new object detected by
which commits take place
the coordinator would then
object detected by radar
an upload capacity of
detected by radar in
larger configurations and will
upload capacity of twice
coordinator would then deploy
configurations and will work
capacity of twice the
would then deploy teams
ip which expect extreme
of twice the stream
which expect extreme reliability
since achieving the consistency
expect extreme reliability from
and will work with
extreme reliability from the
then deploy teams in
the caches are typically
deploy teams in the
twice the stream rate
teams in the field
ms in seek time
the stream rate is
reliability from the high
fetch prefetch metadata store
by radar in an
caches are typically placed
radar in an air
will work with deeper
in an air traffic
our rescue workers now
an air traffic control
achieving the consistency properties
air traffic control system
in seek time and
stream rate is sufficient
speed network are instead
work with deeper hierarchies
network are instead subjected
rescue workers now use
are instead subjected to
the consistency properties that
workers now use the
prefetch metadata store fetch
consistency properties that developers
instead subjected to unexpectedly
rate is sufficient to
subjected to unexpectedly high
are typically placed close
is sufficient to ensure
metadata store fetch file
properties that developers expect
a communication to or
that developers expect will
to unexpectedly high loss
now use the solution
typically placed close to
sufficient to ensure that
placed close to the
the qsm recovery protocol
communication to or from
developers expect will require
unexpectedly high loss rates
use the solution to
store fetch file attributes
to ensure that the
close to the clients
qsm recovery protocol uses
to or from an
expect will require a
or from an aircraft
will require a consistency
recovery protocol uses tokens
require a consistency layer
ensure that the system
a consistency layer to
protocol uses tokens to
consistency layer to be
the solution to coordinate
layer to be built
that the system performs
solution to coordinate and
or the addition of
these numbers reflect the
to be built in
the addition of a
be built in front
uses tokens to track
addition of a node
the problem centers on
to coordinate and prioritize
numbers reflect the loss
kb in transmission time
reflect the loss rate
built in front of
the loss rate specifically
in front of s
of a node to
problem centers on the
coordinate and prioritize actions
pull file update fetch
the system performs and
file update fetch file
the key observation here
a node to a
centers on the asynchronous
tokens to track message
node to a distributed
on the asynchronous style
to track message status
inform each other of
it is crucial that
system performs and scales
is crucial that any
performs and scales well
crucial that any such
the asynchronous style of
that any such layer
each other of the
any such layer be
true bandwidth bandwidth used
other of the evolving
loss rate specifically experienced
of the evolving situation
update fetch file data
as nodes receive packets
such layer be able
to a distributed data
asynchronous style of communication
rate specifically experienced by
a distributed data structure
layer be able to
key observation here is
be able to handle
specifically experienced by udp
able to handle the
distributed data structure containing
to handle the load
they mimic the role
handle the load of
steer clear of hazards
experienced by udp traffic
style of communication used
by udp traffic on
observation here is that
mimic the role of
the load of commits
the role of the
prefetch file data lock
role of the source
file data lock a
data structure containing an
data lock a file
udp traffic on an
structure containing an index
traffic on an end
the critical statistic to
the token carries ack
here is that seek
token carries ack and
sending notifications to their
is that seek time
critical statistic to consider
of communication used between
statistic to consider is
carries ack and nak
to consider is the
notifications to their own
that seek time is
to their own neighbors
most metadata rpcs store
as new events occur
metadata rpcs store file
consider is the number
rpcs store file data
containing an index of
communication used between the
seek time is a
used between the database
ack and nak information
between the database and
the situational status would
the database and the
situational status would evolve
unlink file such as
end path and may
is the number of
path and may not
their own neighbors in
and may not generalize
database and the geo
aggregated over the nodes
an index of pending
over the nodes below
time is a large
the nodes below each
is a large and
may not generalize to
the number of simultaneous
not generalize to tcp
own neighbors in the
and the team member
neighbors in the mesh
nodes below each ring
the team member who
index of pending orders
number of simultaneous commits
generalize to tcp packets
file such as deleting
a large and constant
such as deleting a
team member who causes
as deleting a modified
a cache should not
member who causes or
large and constant term
of pending orders in
and constant term in
for centralized revision control
constant term in latency
we do not know
cache should not access
who causes or observes
should not access the
pending orders in an
causes or observes these
centralized revision control system
allowing packets to be
revision control system such
do not know if
packets to be propagated
not access the database
to be propagated through
access the database on
or observes these status
the database on every
control system such as
observes these status changes
system such as subversion
deleting a modified file
orders in an online
be propagated through the
in an online warehouse
database on every transaction
token rings avoid the
not know if packets
rings avoid the kinds
term in latency computation
avoid the kinds of
such optimisations can be
these status changes would
optimisations can be effective
propagated through the system
can be effective at
the kinds of ack
be effective at low
data replication can be
effective at low bandwidth
replication can be remarkably
each commit is assigned
can be remarkably cheap
commit is assigned a
any approach requiring a
is assigned a unique
know if packets were
approach requiring a high
status changes would need
requiring a high rate
when there is a
changes would need to
nak implosion problems with
would need to report
a high rate of
implosion problems with which
there is a natural
based approach to acquisition
is a natural delay
with modern technology and
need to report them
modern technology and small
high rate of round
technology and small updates
to eliminate this term
approach to acquisition of
and any change to
to acquisition of packets
to report them to
problems with which reliable
report them to the
trips to an authoritative
with which reliable multicast
but at high bandwidth
if packets were dropped
any change to a
them to the others
change to a versioned
the lfs replaces write
to a versioned file
packets were dropped within
lfs replaces write operations
which reliable multicast protocols
replaces write operations by
an artificial delay in
were dropped within the
to an authoritative backend
artificial delay in writing
reliable multicast protocols traditionally
write operations by append
a versioned file is
operations by append operations
an authoritative backend database
delay in writing back
multicast protocols traditionally have
dropped within the optical
versioned file is stored
computer chrony service can
file is stored as
authoritative backend database would
is stored as a
protocols traditionally have struggled
stored as a diff
provides some resilience to
removing debris blocking access
some resilience to failure
chrony service can run
resilience to failure or
backend database would cause
to failure or malicious
database would cause unacceptable
failure or malicious behavior
debris blocking access to
in writing back updates
service can run at
within the optical network
as a diff against
the optical network or
a diff against its
optical network or at
blocking access to a
network or at intermediate
can run at rates
access to a building
secondary storage is treated
would cause unacceptable latency
storage is treated as
since a participant will
is treated as a
or at intermediate devices
treated as a large
at intermediate devices within
to a building may
intermediate devices within either
writing back updates introduces
devices within either data
a participant will have
within either data center
back updates introduces inconsistencies
participant will have multiple
diff against its previous
a cache must respond
against its previous version
but problems of their
run at rates well
problems of their own
updates introduces inconsistencies between
will have multiple possible
a building may enable
have multiple possible sources
though it s unlikely
a commit must be
at rates well in
introduces inconsistencies between the
rates well in excess
building may enable the
well in excess of
multiple possible sources for
it s unlikely that
commit must be rejected
s unlikely that they
cache must respond instantly
unlikely that they were
as a large append
may enable the team
possible sources for each
enable the team to
sources for each packet
the team to check
that they were dropped
team to check it
and asynchronous updates rule
inconsistencies between the client
if a message is
asynchronous updates rule out
must be rejected if
only log and writes
updates rule out cache
be rejected if any
log and writes always
a message is lost
rejected if any of
to check it for
between the client and
check it for victims
rule out cache coherency
and writes always go
the mesh overlay defines
writes always go to
they were dropped at
always go to the
were dropped at the
go to the log
dropped at the end
and fire that breaks
the client and the
out cache coherency schemes
client and the file
the sender may not
and the file server
mesh overlay defines a
fire that breaks out
if any of the
cache coherency schemes that
to the log head
sender may not find
coherency schemes that would
that breaks out in
any of the versioned
schemes that would require
breaks out in a
this can be acceptable
that would require the
may not find out
seek time is thus
not find out for
time is thus eliminated
out in a chemical
can be acceptable at
modal versus modeless adaptation
of the versioned files
versus modeless adaptation with
many of the measurements
the versioned files that
find out for quite
ordered updates per second
versioned files that it
would require the backend
modeless adaptation with atp
files that it touches
of the measurements lost
in a chemical storage
and write latency becomes
be acceptable at low
out for quite a
the left graph shows
require the backend database
left graph shows performance
that it touches have
graph shows performance with
the backend database to
shows performance with modal
even if an update
backend database to promptly
overlay defines a predetermined
for quite a while
the measurements lost just
a chemical storage warehouse
measurements lost just one
write latency becomes purely
lost just one or
acceptable at low bandwidths
just one or two
database to promptly invalidate
defines a predetermined set
to promptly invalidate or
chemical storage warehouse may
performance with modal adaptation
latency becomes purely a
if an update requires
when the user may
it touches have been
the user may table
touches have been changed
and the right graph
one or two packets
the right graph shows
an update requires a
right graph shows a
a predetermined set of
graph shows a scheme
storage warehouse may force
shows a scheme in
becomes purely a function
a scheme in which
this isn t a
scheme in which there
promptly invalidate or update
isn t a major
have been changed in
t a major issue
or two packets whereas
purely a function of
two packets whereas kernel
in which there are
predetermined set of neighbors
which there are four
warehouse may force diversion
there are four classes
priorities for mafs remote
are four classes of
a major issue because
update requires a large
a function of the
requires a large message
set of neighbors for
may force diversion of
of neighbors for each
for mafs remote procedure
neighbors for each peer
nic losses are known
major issue because most
invalidate or update cached
function of the disk
or update cached this
of the disk bandwidth
four classes of messages
mafs remote procedure calls
losses are known to
issue because most message
are known to be
been changed in an
known to be bursty
update cached this work
classes of messages being
how do reads in
of messages being sent
because most message losses
be grateful to be
changed in an earlier
which also makes it
cached this work is
it s possible to
this work is supported
messages being sent simultaneously
s possible to maintain
most message losses can
grateful to be able
message losses can be
also makes it hard
losses can be corrected
force diversion of resources
can be corrected locally
in an earlier revision
to be able to
do reads in the
the lowest line corresponds
makes it hard for
lowest line corresponds to
an earlier revision that
line corresponds to the
reads in the lfs
through cooperation among receivers
in the lfs work
it hard for malicious
earlier revision that the
by a grant from
hard for malicious peers
as rescue workers capture
be able to use
rescue workers capture information
corresponds to the highest
able to use the
to the highest priority
for malicious peers to
to use the file
the basic idea is
use the file system
revision that the developer
the file system at
a grant from the
file system at all
loss occurred on paths
malicious peers to round
occurred on paths where
in the same way
on paths where levels
their mobile devices send
paths where levels of
grant from the darpa
where levels of optical
but should be avoided
levels of optical link
that the developer performing
of optical link utilization
possible to maintain rates
mobile devices send updates
basic idea is to
dark horizontal lines represent
from the darpa mrc
horizontal lines represent operating
should be avoided when
lines represent operating modes
the developer performing the
be avoided when bandwidth
devices send updates that
avoided when bandwidth is
peers to round up
when bandwidth is unconstrained
the same way as
to round up on
same way as in
developer performing the commit
round up on individual
send updates that must
the darpa mrc program
updates that must be
to maintain rates of
that must be propagated
idea is to perform
must be propagated in
up on individual peers
be propagated in real
way as in conventional
on individual peers since
performing the commit was
is to perform recovery
the commit was unaware
maintain rates of thousands
commit was unaware of
individual peers since attackers
represent operating modes on
were consistently lower than
peers since attackers lack
as in conventional file
rates of thousands per
in conventional file systems
operating modes on the
to perform recovery as
mafs avoids the need
or even to track
of thousands per second
even to track the
having defined the scenario
since attackers lack a
this ensures that every
perform recovery as locally
avoids the need for
recovery as locally as
thousands per second on
as locally as possible
per second on typical
ensures that every conflict
second on typical hardware
to track the locations
the need for modes
attackers lack a deterministic
now let s analyze
need for modes by
lack a deterministic means
track the locations at
a deterministic means of
ruling out congestion as
modes on the left
the virtual synchrony and
let s analyze in
for modes by using
virtual synchrony and statemachine
s analyze in more
deterministic means of acquiring
that every conflict gets
means of acquiring control
and hence do not
of acquiring control of
hence do not avoid
acquiring control of all
synchrony and statemachine models
control of all of
out congestion as a
and statemachine models show
the locations at which
congestion as a possible
statemachine models show how
as a possible cause
and the highest priority
of all of its
the highest priority of
if a message is
highest priority of data
analyze in more detail
locations at which cached
do not avoid seek
at which cached objects
every conflict gets resolved
which cached objects reside
modes by using asynchronous
a message is available
priority of data being
by using asynchronous remote
of data being sent
a conclusion supported by
data being sent during
using asynchronous remote procedure
being sent during a
message is available within
asynchronous remote procedure calls
we define a variant
conflict gets resolved by
remote procedure calls between
define a variant of
gets resolved by a
procedure calls between a
a variant of serializability
is available within the
conclusion supported by dialogue
in more detail the
supported by dialogue with
models show how a
by dialogue with the
resolved by a human
show how a tremendous
variant of serializability called
available within the same
sent during a second
of serializability called cacheserializability
during a second on
all of its neighbors
serializability called cacheserializability that
calls between a client
by a human before
how a tremendous range
a human before becoming
the assumption is that
a tremendous range of
a second on the
assumption is that with
second on the right
between a client and
all nodes with exception
human before becoming part
more detail the requirements
dialogue with the network
called cacheserializability that is
the modeless scheme achieves
is that with good
modeless scheme achieves higher
within the same token
scheme achieves higher utilisation
before becoming part of
detail the requirements it
becoming part of the
tremendous range of application
part of the repository
a client and the
of the repository s
nodes with exception of
the repository s state
with the network administrators
with exception of the
cacheserializability that is suitable
range of application requirements
that is suitable for
client and the file
is suitable for incoherent
the requirements it places
suitable for incoherent caches
that with good caching
of application requirements can
with good caching mechanisms
and the file server
exception of the source
requirements it places on
the same token ring
it places on our
a wide range of
places on our collaboration
wide range of web
on our collaboration tool
range of web applications
reads will be a
the file server writeback
will be a small
of the source have
be a small fraction
exclusive locking is required
a small fraction of
locking is required on
some process that has
is required on commits
the source have a
process that has a
file server writeback at
source have a fixed
from social networks to
have a fixed upper
what are some possible
mb of data sent
taking a loose definition
that has a a
server writeback at all
application requirements can map
writeback at all bandwidth
the collaboration tool pulls
requirements can map down
small fraction of disk
can map down to
fraction of disk accesses
social networks to online
a fixed upper limit
networks to online retailers
at all bandwidth levels
are some possible causes
collaboration tool pulls data
some possible causes for
has a a a
as can be imagined
because it always has
a a a c
it always has messages
tool pulls data from
possible causes for such
map down to a
causes for such high
a loose definition of
settle for caches that
space reclamation is a
always has messages to
for such high loss
has messages to send
fixed upper limit on
down to a rigorously
upper limit on their
loose definition of simultaneous
limit on their upload
pulls data from many
on their upload contribution
data from many kinds
such high loss rates
from many kinds of
high loss rates on
many kinds of sources
loss rates on teragrid
while the modal scheme
reclamation is a tricky
and incorporates a new
is a tricky problem
to a rigorously precise
a tricky problem in
definition of simultaneous to
the modal scheme is
it makes far more
incorporates a new upare
makes far more sense
a rigorously precise execution
far more sense to
a a c ac
more sense to imagine
a likely hypothesis is
sense to imagine that
for caches that are
likely hypothesis is device
tricky problem in log
rigorously precise execution model
problem in log structured
a c ac ab
in log structured file
to imagine that weather
log structured file systems
caches that are oblivious
hypothesis is device clutter
that are oblivious to
modal scheme is dependent
is device clutter the
a new upare divided
imagine that weather information
of simultaneous to be
which in turn can
simultaneous to be within
are oblivious to transactions
to be within one
device clutter the critical
be within one minute
c ac ab abc
clutter the critical communication
times the stream rate
the critical communication path
new upare divided into
in turn can be
excellent solutions have been
turn can be used
scheme is dependent on
can be used to
despite the fact that
be used to validate
the apache repository had
the fact that an
solutions have been proposed
critical communication path between
is dependent on a
upare divided into several
communication path between nodes
ac ab abc bc
apache repository had a
ab abc bc b
repository had a maximum
abc bc b c
had a maximum of
bc b c b
divided into several types
path between nodes in
fact that an inconsistent
have been proposed to
defined by the protocol
been proposed to solve
simultaneous commits and the
proposed to solve it
commits and the debian
between nodes in different
and the debian community
dependent on a rapid
used to validate a
on a rapid and
into several types depending
a rapid and accurate
nodes in different data
and one such is
b c b figure
one such is of
that an inconsistent read
such is of interest
this upper limit is
rapid and accurate estimate
in different data centers
ignoring for now that
different data centers is
for now that their
messages and alerts come
an inconsistent read access
is of interest to
and alerts come from
and accurate estimate of
to validate a platform
accurate estimate of the
groups overlap to form
estimate of the available
upper limit is not
of the available bandwidth
of interest to us
the available bandwidth in
alerts come from a
data centers is littered
now that their use
come from a dozen
inconsistent read access can
limit is not respected
several types depending on
is not respected by
the disk is divided
centers is littered with
disk is divided into
is littered with multiple
is divided into large
littered with multiple electronic
available bandwidth in order
because the models have
bandwidth in order to
types depending on their
the models have formal
that their use of
models have formal specifications
read access can deter
divided into large log
access can deter a
into large log segments
in order to select
overlap to form regions
depending on their function
from a dozen providers
with multiple electronic devices
not respected by opportunistic
a dozen providers than
order to select its
you can test the
dozen providers than to
respected by opportunistic nodes
nodes belong to the
providers than to assume
rpcs date propagation algorithm
separate repositories allows for
once a log segment
repositories allows for finergrained
can deter a client
allows for finergrained locking
can test the correctness
each of which represents
test the correctness of
of which represents a
to select its correct
a log segment gets
belong to the same
log segment gets filled
who attempt to reduce
than to assume that
date propagation algorithm to
the correctness of an
which represents a potential
correctness of an implementation
represents a potential point
deter a client and
a potential point of
attempt to reduce it
potential point of failure
propagation algorithm to reduce
to reduce it with
an aggregate maximum of
algorithm to reduce the
to the same region
a client and reduce
to assume that one
client and reduce their
reduce it with the
and reduce their income
and even use theorem
to reduce the possibility
the same region if
select its correct operating
another possibility is that
its correct operating mode
assume that one organization
possibility is that such
it with the goal
in determining these numbers
reduce the possibility of
same region if they
a new log segment
region if they have
is that such loss
if they have similar
they cannot afford consistent
they have similar group
determining these numbers we
cannot afford consistent cache
that one organization would
new log segment is
even use theorem provers
that such loss rates
with the goal of
such loss rates may
the possibility of inconsisto
loss rates may be
afford consistent cache techniques
rates may be typical
log segment is allocated
consistent cache techniques that
have similar group membership
segment is allocated and
these numbers we filtered
possibility of inconsisto fetch
one organization would be
numbers we filtered out
use theorem provers to
the goal of uploading
these graphs are reproduced
is allocated and the
graphs are reproduced from
of inconsisto fetch and
organization would be hosting
inconsisto fetch and store
theorem provers to assist
we filtered out any
qsm currently uses an
may be typical for
currently uses an unreliable
cache techniques that require
uses an unreliable ip
fetch and store data
an unreliable ip multicast
provers to assist developers
allocated and the log
filtered out any sequences
and the log head
would be hosting services
the log head moves
goal of uploading less
log head moves to
since a single group
head moves to the
a single group may
moves to the new
be hosting services with
to the new segment
to assist developers in
of uploading less data
be typical for any
techniques that require backend
an equivalent modal scheme
out any sequences of
single group may span
when some threshold of
hosting services with everything
any sequences of multiple
on the course of
services with everything we
the course of a
sequences of multiple commits
group may span multiple
assist developers in testing
may span multiple regions
that require backend accesses
and store data are
other experiments have shown
with everything we need
experiments have shown that
course of a streaming
have shown that modeless
of multiple commits by
shown that modeless adaptation
store data are self
multiple commits by the
some threshold of a
everything we need in
threshold of a segment
of a streaming session
of a segment gets
developers in testing their
a segment gets invalidated
require backend accesses on
typical for any large
commits by the same
we need in one
to send to group
need in one place
each node stores packets
backend accesses on every
its valid data is
node stores packets and
valid data is moved
in testing their most
stores packets and forwards
that modeless adaptation can
accesses on every transaction
modeless adaptation can achieve
scale network where the
adaptation can achieve improvements
by the same author
can achieve improvements of
packets and forwards them
send to group g
data from distinct sources
data is moved to
network where the cost
from distinct sources could
the same author during
where the cost of
is moved to another
testing their most critical
moved to another segment
a node multicasts a
the cost of immediately
same author during a
and forwards them to
distinct sources could have
author during a one
forwards them to other
as new operations are
during a one minute
replacing that segment s
new operations are added
that segment s invalid
their most critical application
segment s invalid data
node multicasts a message
cost of immediately detecting
a novel caching scheme
sources could have different
a one minute period
novel caching scheme that
could have different format
most critical application components
have different format and
of immediately detecting and
operations are added to
them to other peers
one minute period since
and it is then
multicasts a message to
different format and one
a message to each
one reason that we
message to each of
to other peers only
to each of the
reason that we lack
other peers only while
immediately detecting and fixing
that we lack this
format and one will
caching scheme that improves
we lack this sort
and one will often
it is then added
lack this sort of
peers only while the
are added to the
this sort of support
and it is possible
added to the tail
scheme that improves consistency
one will often need
each of the regions
is then added to
of the regions separately
detecting and fixing failures
minute period since those
and fixing failures is
it is possible to
period since those were
that improves consistency at
will often need to
only while the packet
then added to the
while the packet is
to the tail tions
the packet is within
is possible to construct
since those were likely
possible to construct cases
often need to interface
those were likely sequential
added to the pool
need to interface to
were likely sequential rather
to the pool of
to interface to each
likely sequential rather than
sort of support today
fixing failures is prohibitively
the tail tions include
of support today is
improves consistency at the
to construct cases in
support today is that
our approach makes it
construct cases in which
failures is prohibitively high
cases in which the
tail tions include fetching
in which the improvement
consistency at the cache
tions include fetching and
sequential rather than simultaneous
at the cache level
approach makes it easy
rather than simultaneous and
the cache level with
makes it easy to
than simultaneous and do
include fetching and setting
simultaneous and do nor
fetching and setting file
and do nor represent
and setting file attributes
interface to each using
cache level with a
to each using its
today is that vendors
each using its own
the pool of free
is that vendors and
do nor represent the
it easy to aggregate
nor represent the common
level with a nominal
represent the common case
using its own protocols
which the improvement is
its own protocols and
the improvement is even
that vendors and platform
improvement is even greater
easy to aggregate messages
vendors and platform developers
to aggregate messages across
pool of free log
aggregate messages across different
of free log segments
we found through dialogue
work on adaptation in
with a nominal storage
on adaptation in mobile
found through dialogue with
a nominal storage and
adaptation in mobile file
messages across different groups
through dialogue with the
and platform developers worry
and directory of the
dialogue with the administrators
platform developers worry that
nominal storage and communication
with the administrators that
packet is within its
the average rates were
is within its availability
directory of the log
within its availability window
developers worry that these
storage and communication tradeoff
the administrators that the
own protocols and interfaces
this process results in
in mobile file systems
worry that these forms
mobile file systems has
the client flushes operations
file systems has generally
process results in a
systems has generally relied
that these forms of
has generally relied on
if a node has
generally relied on modal
usually spanning a few
a node has two
administrators that the steady
these forms of replication
client flushes operations serially
relied on modal schemes
results in a natural
flushes operations serially from
node has two messages
cache significantly improves consistency
has two messages to
forms of replication haven
two messages to send
spanning a few seconds
messages to send to
operations serially from the
to send to a
significantly improves consistency for
send to a pair
of replication haven t
to a pair of
that the steady loss
a pair of groups
each node also maintains
pair of groups g
in a natural division
replication haven t achieved
serially from the head
as conditions evolve the
the steady loss rate
improves consistency for workloads
node also maintains an
steady loss rate experienced
consistency for workloads where
also maintains an interest
loss rate experienced by
maintains an interest window
haven t achieved huge
from the head of
which overlap in region
t achieved huge market
overlap in region r
achieved huge market success
conditions evolve the team
for workloads where data
the head of operations
which represents the set
rate experienced by the
evolve the team might
but our evaluation of
then while transmitting to
a natural division of
while transmitting to r
as the experience with
natural division of allocated
experienced by the indiana
workloads where data accesses
the team might need
where data accesses are
head of operations such
data accesses are clustered
the node can batch
of operations such as
division of allocated segments
operations such as creating
our evaluation of atp
team might need to
represents the set of
might need to be
the experience with corba
need to be modify
by the indiana university
to be modify the
such as creating and
the indiana university site
so exclusive locking for
the set of packets
node can batch these
set of packets in
can batch these messages
of allocated segments into
batch these messages together
evaluation of atp demonstrated
as creating and unlinking
of atp demonstrated that
exclusive locking for commits
which is common in
experience with corba sidebar
is common in today
be modify the application
common in today s
indiana university site was
in today s large
atp demonstrated that it
locking for commits should
demonstrated that it could
with corba sidebar describes
for commits should not
apps send to a
creating and unlinking files
university site was due
of packets in which
site was due to
allocated segments into stable
commits should not pose
the common object request
send to a send
that it could also
control rpcs the log
this is achieved while
for example adding new
should not pose any
example adding new types
packets in which the
adding new types of
in which the peer
new types of information
which the peer is
common object request broker
the peer is currently
to a send to
peer is currently interested
it could also improve
a send to b
is achieved while retaining
object request broker architecture
changing the way it
consisting almost entirely of
request broker architecture offers
send to b group
broker architecture offers a
server traffic consists of
architecture offers a fault
not pose any scalability
could also improve the
the way it is
also improve the performance
was due to a
improve the performance of
nodes choose packets to
due to a faulty
traffic consists of a
to a faulty line
almost entirely of data
a faulty line card
to b group senders
the performance of file
achieved while retaining the
b group senders a
pose any scalability problems
group senders a b
way it is represented
consists of a variety
entirely of data that
performance of file system
of a variety of
while retaining the global
tolerant groups mechanism that
a variety of foreground
any scalability problems in
groups mechanism that was
scalability problems in a
choose packets to request
problems in a typical
senders a b c
in a typical environment
or even modifying the
of data that is
we discuss the implementation
data that is rarely
retaining the global scalability
that is rarely invalidated
and the measurements showed
a b c region
variety of foreground include
even modifying the way
mechanism that was based
of foreground include locking
packets to request from
the global scalability afforded
foreground include locking files
we did not consider
b c region senders
discuss the implementation of
modifying the way team
the implementation of modeless
to request from each
implementation of modeless adaptation
global scalability afforded by
of modeless adaptation in
did not consider the
modeless adaptation in mfs
that was based on
adaptation in mfs further
the measurements showed that
in mfs further in
include locking files and
mfs further in section
c region senders a
not consider the rate
which need to be
was based on the
need to be constantly
measurements showed that the
to be constantly cleaned
locking files and the
the way team members
region senders a ab
way team members communicate
request from each of
based on the virtual
from each of its
on the virtual synchrony
each of its neighbors
consider the rate of
senders a ab ac
atp is implemented at
scalability afforded by executing
is implemented at user
showed that the error
we will see how
the rate of read
that the error persisting
files and the server
rate of read operations
implemented at user level
the virtual synchrony model
a ab ac abc
will see how this
ab ac abc b
the error persisting over
ac abc b c
back network links fail
on top of kernel
abc b c bc
see how this feature
b c bc region
and the server s
c bc region leader
of read operations because
bc region leader figure
top of kernel udp
read operations because clients
how this feature can
the corba standard is
the server s callback
respecting a maximum limit
afforded by executing read
error persisting over at
operations because clients updating
persisting over at least
corba standard is widely
over at least a
a maximum limit l
at least a three
whereas a minibrowser would
least a three month
only transactions on the
a minibrowser would typically
transactions on the edge
it has a message
minibrowser would typically be
this feature can be
would typically be prebuilt
feature can be used
server s callback to
can be used to
standard is widely viewed
oriented interface for communication
directly from the cache
is widely viewed as
typically be prebuilt with
widely viewed as rigid
s callback to invalidate
viewed as rigid and
maximum limit l on
as rigid and limited
because clients updating their
a three month period
we do this by
be used to save
callback to invalidate a
used to save power
in which messages of
to invalidate a rpcs
clients updating their working
invalidate a rpcs for
do this by storing
a rpcs for control
limit l on the
which messages of an
i believe that the
be prebuilt with all
updating their working copies
prebuilt with all the
this by storing dependency
with all the available
l on the number
all the available features
believe that the corba
the available features in
points for loss rates
that the corba community
by storing dependency information
messages of an arbitrary
on the number of
to multicast to a
the number of outstanding
multicast to a group
or reading from the
for loss rates on
reading from the repository
loss rates on high
of an arbitrary size
available features in place
rpcs for control operations
number of outstanding requests
for control operations and
storing dependency information with
control operations and fetching
qsm sends a copy
operations and fetching file
of outstanding requests to
an arbitrary size can
and fetching file data
outstanding requests to each
arbitrary size can be
sends a copy to
size can be reliably
haul networks are provided
dependency information with the
networks are provided by
saving opportunity we shall
our scenario demands a
a copy to each
and a stream client
the corba community erred
a stream client s
information with the cached
stream client s cached
with the cached objects
client s cached copy
scenario demands a much
s cached copy of
do not require a
cached copy of a
are provided by the
copy of a file
can be reliably transmitted
copy to each of
demands a much more
to each of the
not require a lock
a much more flexible
provided by the back
be reliably transmitted with
corba community erred by
each of the underlying
opportunity we shall now
of the underlying regions
of background rpcs for
reliably transmitted with their
background rpcs for logged
bone networks of tier
rpcs for logged operations
the debian community today
community erred by embedding
transmitted with their boundaries
much more flexible kind
with their boundaries preserved
to identify possible inconsistencies
their boundaries preserved at
erred by embedding a
boundaries preserved at the
more flexible kind of
preserved at the receiver
identify possible inconsistencies without
when bandwidth is high
we shall now argue
global crossing reports average
debian community today uses
partition leader token intrapartition
crossing reports average loss
flexible kind of tool
possible inconsistencies without contacting
reports average loss rates
shall now argue that
average loss rates between
at the receiver s
leader token intrapartition token
the receiver s side
kind of tool that
token intrapartition token partition
inconsistencies without contacting the
community today uses only
now argue that there
today uses only a
by embedding a powerful
uses only a single
intrapartition token partition figure
only a single subversion
replayed logged operations complete
a single subversion server
of tool that can
an application can send
tool that can be
application can send a
argue that there remains
can send a message
embedding a powerful solution
send a message synchronously
that can be redesigned
a powerful solution into
that there remains an
without contacting the database
a message synchronously or
and the apache foundation
message synchronously or asynchronously
can be redesigned while
powerful solution into a
be redesigned while in
a hierarchy of token
redesigned while in use
the apache foundation has
there remains an unexplored
solution into a tool
in the latter case
hierarchy of token rings
the user can improve
apache foundation has a
remains an unexplored quadrant
logged operations complete quickly
into a tool mismatched
the latter case the
a tool mismatched to
foundation has a master
tool mismatched to developer
has a master server
mismatched to developer needs
an unexplored quadrant in
with little extra delay
depending on the location
latter case the sender
a master server plus
user can improve the
master server plus a
on the location and
can improve the level
web services move beyond
server plus a european
services move beyond corba
plus a european mirror
move beyond corba in
when bandwidth is low
beyond corba in many
case the sender provides
corba in many ways
on four of its
improve the level of
four of its six
unexplored quadrant in this
of its six inter
the sender provides a
logged operations are de
primarily for latency reasons
sender provides a function
the location and other
but the corba community
naks ack through upcalls
the level of consistency
provides a function to
quadrant in this solution
location and other factors
in this solution space
communication adaptation layed in
a function to be
the corba community s
adaptation layed in proportion
haul links for the
corba community s failed
qsm is also registered
we expect that most
level of consistency by
layed in proportion to
links for the month
function to be executed
in proportion to the
is also registered as
the best networking protocols
also registered as a
caches are used to
registered as a shell
for the month of
as a shell extension
to be executed when
proportion to the foreground
be executed when transmission
best networking protocols and
to the foreground rpc
are used to minimize
community s failed effort
used to minimize accesses
expect that most communities
making it possible to
of consistency by adjusting
that most communities will
the foreground rpc traffic
the month of december
s failed effort to
to minimize accesses to
executed when transmission of
minimize accesses to disk
it possible to access
consistency by adjusting the
most communities will have
by adjusting the size
failed effort to implement
adjusting the size of
when transmission of the
the size of this
transmission of the message
communities will have at
of the message completes
effort to implement virtual
possible to access the
foreground rpc traffic and
good caching algorithms practically
rpc traffic and the
networking protocols and connectivity
will have at most
and the send operation
to access the communication
the send operation itself
caching algorithms practically eliminate
access the communication subsystem
to implement virtual synchrony
protocols and connectivity options
have at most a
and connectivity options may
send operation itself is
traffic and the availto
operation itself is non
the communication subsystem directly
implement virtual synchrony carries
size of this dependency
at most a handful
of this dependency data
algorithms practically eliminate read
and the availto reduce
communication subsystem directly from
virtual synchrony carries an
subsystem directly from the
most a handful of
directly from the windows
the availto reduce its
this is similar to
synchrony carries an important
availto reduce its network
a handful of front
from the windows gui
more dependency data leads
connectivity options may vary
dependency data leads to
practically eliminate read accesses
data leads to increased
reduce its network communication
leads to increased consistency
carries an important lesson
eliminate read accesses to
an important lesson to
read accesses to disk
qwest reports loss rates
is similar to the
reports loss rates of
its network communication when
to demonstrate the efficacy
in our rescue scenario
demonstrate the efficacy of
important lesson to current
the efficacy of the
lesson to current researchers
efficacy of the proposed
network communication when bandwidth
of the proposed scheme
the user can store
achieving consistency amazon s
user can store a
communication when bandwidth is
the workers may have
any technology offered to
consistency amazon s infrastructure
whether synchronous or not
we created a prototype
amazon s infrastructure is
workers may have to
created a prototype implementation
s infrastructure is built
may have to use
similar to the queued
have to use wireless
to the queued rpc
to use wireless p
the queued rpc developed
a prototype implementation and
queued rpc developed for
when bandwidth is low
rpc developed for rover
can store a shortcut
must still eventually access
technology offered to developers
still eventually access the
p protocols much of
offered to developers must
eventually access the disk
infrastructure is built on
prototype implementation and exposed
is built on the
store a shortcut to
built on the principle
implementation and exposed it
on the principle of
protocols much of the
and exposed it to
much of the time
upload factor download factor
the principle of eventual
to developers must support
principle of eventual consistency
exposed it to workloads
a shortcut to a
developers must support the
it to workloads based
must support the programming
disk access will be
reaching back to hosted
access will be write
shortcut to a qsm
to workloads based on
support the programming styles
a mobile file system
the programming styles they
atp also allows the
programming styles they prefer
workloads based on graphically
back to hosted services
mobile file system client
to a qsm stream
also allows the sender
a qsm stream in
putting a disk management
file system client can
a disk management layer
to hosted services only
and does not directly
qsm stream in the
in either direction on
stream in the file
system client can automatically
in the file system
disk management layer on
client can automatically adapt
does not directly support
management policies a scalable
either direction on its
allows the sender to
direction on its trans
management layer on top
can automatically adapt its
layer on top of
policies a scalable services
automatically adapt its communication
the sender to attach
a scalable services architecture
sender to attach a
hosted services only intermittently
pacific link for the
adapt its communication strategy
services only intermittently when
scalable services architecture for
its communication strategy to
only intermittently when a
link for the same
on top of the
click to attach a
top of the file
services architecture for building
communication strategy to the
intermittently when a drone
strategy to the available
to attach a priority
to the available bandwidth
such as those seen
system to optimize data
for the same month
as those seen in
not directly support the
to attach a previewer
attach a priority to
architecture for building raps
a priority to each
to optimize data layout
priority to each message
those seen in social
directly support the locking
attach a previewer or
support the locking required
for building raps of
the locking required for
to control the order
a previewer or a
control the order in
when a drone aircraft
the order in which
locking required for revision
order in which the
previewer or a viewer
in which the queued
a drone aircraft passes
which the queued messages
required for revision control
the queued messages are
or a viewer to
queued messages are transmitted
optimize data layout for
drone aircraft passes within
building raps of racs
aircraft passes within radio
a viewer to an
passes within radio range
we expect privately managed
raps of racs alone
messages are queued at
expect privately managed lambdas
viewer to an event
originally developed to run
to an event stream
rpc priorities cations transfer
of racs alone isn
are queued at the
racs alone isn t
data layout for writes
alone isn t enough
priorities cations transfer a
privately managed lambdas to
queued at the sender
cations transfer a large
managed lambdas to exhibit
layout for writes is
the right choice of
lambdas to exhibit higher
transfer a large volume
developed to run the
at the sender according
for writes is only
the sender according to
right choice of protocol
sender according to their
to run the company
according to their receivers
scale systems that will
run the company s
to exhibit higher loss
the company s own
a large volume of
the overall architecture is
writes is only halfway
systems that will likely
is only halfway to
exhibit higher loss rates
only halfway to the
overall architecture is summarized
halfway to the solution
large volume of data
choice of protocol should
that will likely soon
company s own online
higher loss rates due
s own online store
architecture is summarized in
of protocol should reflect
is summarized in figure
will likely soon rely
and each queue is
loss rates due to
each queue is ordered
volume of data that
protocol should reflect the
likely soon rely on
of data that the
soon rely on standardized
queue is ordered by
the system preferred availability
is ordered by priority
should reflect the operating
system preferred availability over
the system is single
data that the user
to take this idea
rates due to the
that the user is
messages of the same
preferred availability over consistency
of the same priority
take this idea to
rely on standardized web
this idea to its
reflect the operating conditions
the user is unlikely
of the inconsistencies and
user is unlikely to
the same priority within
due to the inherent
same priority within a
idea to its logical
priority within a queue
we use a windows
on standardized web services
the inconsistencies and can
to the inherent tradeoff
availability over consistency because
the inherent tradeoff between
inconsistencies and can increase
inherent tradeoff between fiber
within a queue are
use a windows i
a queue are transmitted
and if these change
queue are transmitted in
over consistency because downtime
are transmitted in first
and can increase the
standardized web services including
is unlikely to require
web services including global
consistency because downtime translated
services including global banks
can increase the ratio
to its logical conclusion
equipment quality and cost
henceforth referred to as
the platform should be
because downtime translated directly
unlikely to require immediately
downtime translated directly into
the entire us air
platform should be capable
entire us air force
it is necessary to
translated directly into lost
is necessary to rethink
directly into lost revenue
should be capable of
increase the ratio of
be capable of swapping
necessary to rethink the
referred to as an
to rethink the file
to as an i
rethink the file the
and the supervisory control
the file the disk
capable of swapping in
the supervisory control and
customers may opt to
of swapping in a
supervisory control and data
the ratio of consistent
control and data acquisition
atp also allows a
may opt to shop
also allows a sender
management policies described in
opt to shop elsewhere
and data acquisition systems
policies described in the
data acquisition systems that
to collect all asynchronous
described in the related
acquisition systems that operate
ratio of consistent transactions
in the related works
consuming bandwidth that can
of consistent transactions by
as well as the
collect all asynchronous i
swapping in a different
systems that operate the
to shop elsewhere or
allows a sender to
the related works section
a sender to specify
well as the difficulty
sender to specify a
that operate the us
to specify a send
bandwidth that can be
related works section essentially
in a different protocol
as the difficulty of
works section essentially attack
operate the us power
the difficulty of performing
section essentially attack the
the us power grid
shop elsewhere or to
essentially attack the problem
specify a send timeout
elsewhere or to simply
attack the problem by
difficulty of performing routine
a different protocol without
us power grid will
that can be used
power grid will also
including notifications of any
a send timeout for
notifications of any received
can be used mafs
of any received messages
different protocol without disrupting
grid will also require
be used mafs uses
send timeout for a
the problem by trying
timeout for a message
used mafs uses priorities
problem by trying to
protocol without disrupting the
will also require policies
mafs uses priorities to
maximum upload factor figure
or to simply forgo
by trying to predict
without disrupting the end
of performing routine maintenance
also require policies to
which causes the transmission
uses priorities to reduce
causes the transmission to
to simply forgo impulse
trying to predict in
disrupting the end user
performing routine maintenance on
require policies to manage
the transmission to be
policies to manage security
transmission to be suspended
a single core thread
routine maintenance on longdistance
single core thread synchronously
maintenance on longdistance links
simply forgo impulse purchases
to predict in advance
to manage security keys
to be suspended if
priorities to reduce contention
be suspended if it
this argues for a
core thread synchronously polls
to reduce contention between
predict in advance which
download and upload factors
suspended if it expires
argues for a decoupling
forgo impulse purchases that
for a decoupling of
in advance which disk
reduce contention between foreground
advance which disk any
both with low overhead
which disk any given
contention between foreground for
and upload factors of
thread synchronously polls the
between foreground for important
synchronously polls the i
a decoupling of functionality
disk any given access
so that the sender
end paths as dropping
that the sender can
foreground for important tasks
automated tools for monitoring
upload factors of nodes
o queue to retrieve
factors of nodes in
the sender can react
of nodes in an
whereas a minibrowser packages
nodes in an ideal
paths as dropping packets
in an ideal system
any given access will
an ideal system where
impulse purchases that they
given access will go
purchases that they didn
a minibrowser packages it
that they didn t
as dropping packets at
they didn t really
dropping packets at rates
tools for monitoring large
packets at rates of
we construct synthetic workloads
for monitoring large complex
queue to retrieve incoming
minibrowser packages it all
to retrieve incoming messages
ideal system where all
didn t really need
access will go to
t really need anyway
sender can react to
construct synthetic workloads and
consider an application that
the core thread also
monitoring large complex systems
core thread also maintains
an application that activities
system where all nodes
synthetic workloads and observe
application that activities and
they optimize the data
large complex systems will
thread also maintains an
complex systems will be
also maintains an alarm
systems will be needed
maintains an alarm queue
will be needed as
optimize the data layout
be needed as well
where all nodes behave
the data layout on
all nodes behave correctly
packages it all into
data layout on disks
that activities and deferrable
an inconsistent shopping cart
can react to it
activities and deferrable background
it all into one
implemented as a splay
all into one object
as a splay tree
and deferrable background activities
layout on disks to
workloads and observe how
on disks to ensure
to capture a wide
an analogous mechanism is
capture a wide range
researchers must think about
a wide range of
and observe how t
wide range of deployed
must think about how
could be resolved by
disks to ensure that
think about how monitoring
this limit not only
to ensure that accesses
range of deployed networks
be resolved by heuristics
better is a design
resolved by heuristics or
limit not only improves
about how monitoring and
not only improves the
adaptive rpc fetches images
how monitoring and management
and a request queue
rpc fetches images from
monitoring and management policies
ensure that accesses are
only improves the general
and management policies in
that accesses are localized
cache reacts to different
is a design in
implemented as a lockfree
analogous mechanism is available
as a lockfree queue
a design in which
by heuristics or user
management policies in different
design in which the
fetches images from a
policies in different organizations
reacts to different clustering
images from a file
e xisting r eliability
mechanism is available for
xisting r eliability o
accesses are localized to
r eliability o ptions
improves the general flow
eliability o ptions tcp
the general flow of
to different clustering levels
intervention at checkout time
a lockfree queue with
is available for receive
lockfree queue with cas
are localized to some
ip is the default
localized to some fraction
is the default reliable
different clustering levels and
the default reliable communication
it is well known
in different organizations should
default reliable communication option
is well known that
different organizations should talk
in which the presentation
well known that consistency
clustering levels and how
which the presentation object
from a file server
general flow of packets
to some fraction of
reliable communication option for
some fraction of the
available for receive operations
fraction of the disks
known that consistency and
the presentation object is
levels and how it
organizations should talk to
presentation object is distinct
and how it adapts
but also makes it
so that only these
processes each in turn
for requests from the
should talk to one
object is distinct from
talk to one another
that consistency and availability
to one another when
also makes it harder
communication option for contemporary
makes it harder for
besides detecting when a
it harder for malicious
is distinct from objects
detecting when a remote
one another when web
distinct from objects representing
option for contemporary networked
another when web services
from objects representing information
harder for malicious peers
when a remote host
for malicious peers to
objects representing information sources
a remote host is
for contemporary networked applications
representing information sources and
the core thread polls
how it adapts as
malicious peers to overrequest
consistency and availability cannot
peers to overrequest packets
remote host is inaccessible
to overrequest packets from
information sources and objects
core thread polls all
it adapts as clusters
when web services interactions
that only these need
web services interactions cross
only these need be
overrequest packets from their
these need be powered
packets from their neighbors
adapts as clusters change
preferentially allocates bandwidth to
exclusive embeddings in commodity
and availability cannot both
allocates bandwidth to foreground
peers maintain a queue
services interactions cross boundaries
maintain a queue of
thread polls all queues
need be powered up
polls all queues in
send timeouts do not
all queues in a
sources and objects representing
bandwidth to foreground rpcs
and objects representing transport
these are tough problems
availability cannot both be
timeouts do not play
queues in a round
cannot both be achieved
embeddings in commodity operating
objects representing transport protocols
in commodity operating systems
but they can be
a queue of non
they can be solved
these are all probabilistic
robin fashion and processes
do not play a
fashion and processes the
unlike plays the resulting
satisfied requests from its
are all probabilistic models
commodity operating systems and
both be achieved simultaneously
operating systems and networking
and processes the events
systems and networking apis
with perfectly clustered workloads
plays the resulting image
not play a major
decoupling makes it possible
play a major role
requests from its neighbors
a major role in
at cornell we recently
major role in mfs
be achieved simultaneously in
makes it possible to
processes the events sequentially
achieved simultaneously in any
cornell we recently developed
most applications requiring reliable
simultaneously in any real
we recently developed astrolabe
applications requiring reliable communication
a new access has
and writes it to
an additional use for
new access has some
events of the same
it possible to dynamically
of the same type
in any real network
possible to dynamically modify
a scalable technology for
additional use for timeouts
access has some probability
keeping only the l
use for timeouts would
has some probability of
writes it to the
for timeouts would be
to dynamically modify or
it to the server
the same type are
cache implements full cache
only the l most
requiring reliable communication over
the l most recent
some probability of not
l most recent ones
reliable communication over any
timeouts would be to
communication over any form
same type are processed
over any form of
scalable technology for distributed
any form of network
dynamically modify or even
form of network use
any real network where
of network use tcp
type are processed in
technology for distributed monitoring
are processed in batches
modify or even replace
for distributed monitoring and
probability of not fitting
real network where hosts
would be to detect
if the user little
or even replace a
distributed monitoring and control
the user little work
network where hosts or
be to detect prefetches
up to the limit
expected behavior our first
to explain this perfect
behavior our first goal
monitoring and control that
our first goal is
to detect prefetches which
and control that has
to the limit determined
detect prefetches which are
where hosts or entire
explain this perfect behavior
hosts or entire subnetworks
even replace a component
control that has attracted
replace a component with
the limit determined by
a component with some
ip has three major
component with some other
or entire subnetworks are
of not fitting this
this perfect behavior we
not fitting this model
that has attracted tremendous
prefetches which are not
limit determined by a
first goal is to
determined by a quantum
goal is to explore
fitting this model and
is to explore the
perfect behavior we prove
which are not making
has three major problems
entire subnetworks are sometimes
three major problems when
option when changing conditions
major problems when used
behavior we prove a
are not making progress
has attracted tremendous interest
this model and needing
attracted tremendous interest and
to explore the typical
when changing conditions require
explore the typical signature
we prove a related
not making progress and
subnetworks are sometimes unreachable
model and needing to
tremendous interest and attention
which assigns a lower
changing conditions require it
the typical signature of
making progress and reissue
typical signature of the
prove a related claim
progress and reissue a
and needing to access
and reissue a prefetch
a related claim we
reissue a prefetch for
are sometimes unreachable due
a prefetch for a
needing to access a
prefetch for a different
to access a powered
for a different file
we have posed what
problems when used over
related claim we show
have posed what may
researchers at other institutions
claim we show that
at other institutions are
when used over high
we show that with
posed what may sound
show that with unbounded
what may sound like
signature of the system
that with unbounded resources
other institutions are working
assigns a lower priority
institutions are working on
sometimes unreachable due to
are working on other
a lower priority to
working on other promising
may sound like a
on other promising solutions
unreachable due to connectivity
since an understanding of
there is no limit
disk layout becomes tied
an understanding of the
lower priority to writeback
understanding of the behavior
with unbounded resources t
of the behavior of
atp administers priorities by
is no limit for
layout becomes tied to
no limit for local
calability isn t just
limit for local push
sound like a very
the behavior of pullbased
administers priorities by deriving
due to connectivity losses
becomes tied to particular
priority to writeback in
throughput collapse in lossy
isn t just a
collapse in lossy networks
behavior of pullbased dissemination
priorities by deriving an
tied to particular applications
pull data sender inter
like a very specialized
to writeback in wants
t just a technology
of pullbased dissemination in
writeback in wants to
pullbased dissemination in the
by deriving an estimate
in wants to see
dissemination in the absence
ip is unable to
two applications that have
it s also a
a very specialized problem
applications that have completely
pull region partition figure
deriving an estimate for
that have completely different
s also a mindset
wants to see the
have completely different access
if a cloud service
an estimate for the
completely different access patterns
but in fact we
estimate for the bandwidth
to see the processed
in fact we see
a cloud service is
in the absence of
is unable to distinguish
recovery inside and across
for the bandwidth available
inside and across partitions
see the processed images
the contributions of this
cloud service is designed
different access patterns might
the absence of opportunistic
unable to distinguish between
access patterns might require
the bandwidth available between
fact we see this
bandwidth available between the
service is designed to
we see this as
absence of opportunistic nodes
is designed to provide
see this as a
patterns might require completely
designed to provide high
this as a good
also a mindset with
to distinguish between ephemeral
copy will forward it
of opportunistic nodes will
contributions of this work
available between the sender
might require completely different
of this work are
as a good example
a mindset with ramifications
distinguish between ephemeral loss
one else wants to
opportunistic nodes will turn
between the sender and
else wants to im
the sender and receiver
a good example of
will forward it to
mindset with ramifications at
forward it to the
nodes will turn out
to provide high availability
will turn out to
good example of a
provide high availability but
with ramifications at many
example of a more
high availability but an
ramifications at many levels
of a more general
in order to minimise
it to the process
a more general kind
turn out to be
between ephemeral loss modes
out to be important
require completely different data
to be important when
to the process missing
be important when we
availability but an application
important when we set
to ensure true scalability
when we set out
order to minimise the
we set out to
the process missing the
set out to introduce
but an application instead
completely different data layouts
more general kind of
to minimise the transmission
ephemeral loss modes due
process missing the message
loss modes due to
an application instead requires
modes due to transient
general kind of need
due to transient congestion
web services platforms must
kind of need that
different data layouts on
services platforms must begin
of need that could
data layouts on disk
mafs has a finer
layouts on disk leading
minimise the transmission delay
out to introduce auditing
need that could arise
platforms must begin to
that could arise in
on disk leading to
must begin to standardize
qsm implements a scheme
application instead requires perfect
could arise in many
instead requires perfect consistency
or bad fiber and
grained differentiation mediately read
we conducted experiments using
differentiation mediately read them
implements a scheme originally
the transmission delay when
a scheme originally proposed
a variant of serializability
scheme originally proposed by
bad fiber and persistent
originally proposed by zhao
conducted experiments using an
arise in many kinds
writing the output back
additional software infrastructure is
the output back will
variant of serializability suitable
output back will interfere
fiber and persistent congestion
experiments using an event
transmission delay when a
in many kinds of
disk leading to conflicts
many kinds of settings
begin to standardize application
of serializability suitable for
back will interfere with
to standardize application architectures
serializability suitable for incoherent
will interfere with between
the loss of one
interfere with between rpcs
software infrastructure is required
leading to conflicts that
infrastructure is required to
standardize application architectures that
is required to bridge
loss of one packet
application architectures that promote
which is described in
to conflicts that reduce
is described in more
even in a large
described in more detail
in a large ring
in more detail in
architectures that promote reliability
more detail in section
consider a physician treating
and uses priorities at
conflicts that reduce possible
uses priorities at all
that reduce possible powersavings
no more than five
delay when a new
more than five nodes
a physician treating a
required to bridge the
suitable for incoherent caches
to bridge the gap
of one packet out
that promote reliability and
since all writes in
than five nodes cache
all writes in an
priorities at all bandwidths
writes in an lfs
when a new message
in an lfs are
physician treating a patient
an lfs are to
one packet out of
treating a patient with
promote reliability and interoperability
a patient with a
five nodes cache any
patient with a complex
for revision control it
with a complex condition
a new message is
revision control it makes
reliability and interoperability when
lfs are to the
this alfetching the next
are to the log
packet out of ten
to the log head
out of ten thousand
who needs collaboration help
of ten thousand is
nodes cache any given
needs collaboration help from
cache any given message
new message is sent
control it makes sense
and interoperability when developers
ten thousand is sufficient
alfetching the next image
thousand is sufficient to
collaboration help from specialists
is sufficient to reduce
it makes sense to
sufficient to reduce tcp
we evaluate the performance
we know in advance
evaluate the performance of
interoperability when developers build
atp uses a form
and slow down the
uses a form of
qsm also uses this
a form of rate
when developers build systems
also uses this idea
makes sense to adopt
developers build systems of
and who might even
build systems of systems
know in advance which
who might even be
uses this idea at
slow down the application
this idea at the
ip throughput to a
idea at the level
throughput to a third
might even be working
to a third of
which allows trading off
even be working in
at the level of
allows trading off efficiency
work with intrinsically distributed
each second is divided
a third of its
in advance which disk
third of its lossless
be working in a
of its lossless maximum
trading off efficiency and
lows control over bandwidth
with intrinsically distributed programs
nodes during an ideal
control over bandwidth allocation
sense to adopt eventual
advance which disk they
if one packet is
working in a remote
one packet is lost
second is divided into
in a remote location
during an ideal execution
over bandwidth allocation at
an ideal execution of
to adopt eventual consistency
ideal execution of chainsaw
off efficiency and transaction
packet is lost out
intrinsically distributed programs that
is lost out of
a remote location under
lost out of a
bandwidth allocation at the
out of a thousand
where all the nodes
allocation at the level
distributed programs that don
the level of partitions
at the level of
remote location under conditions
adopt eventual consistency for
the level of individinterference
all the nodes behave
eventual consistency for read
programs that don t
consistency for read operations
location under conditions demanding
is divided into twenty
under conditions demanding urgent
level of individinterference due
conditions demanding urgent action
which disk they will
of individinterference due to
each message is cached
throughput collapses to a
message is cached in
collapses to a thirtieth
the nodes behave correctly
to a thirtieth of
disk they will access
a thirtieth of the
since at worst an
thirtieth of the maximum
at worst an earlier
is cached in a
worst an earlier revision
individinterference due to write
we fixed the upload
consistency in large scale
fixed the upload factor
that don t fit
the root cause of
cached in a single
root cause of throughput
in a single partition
cause of throughput collapse
divided into twenty send
of throughput collapse is
the upload factor of
throughput collapse is tcp
don t fit a
an earlier revision will
t fit a transactional
earlier revision will fig
fit a transactional model
into twenty send periods
the mixture of patient
twenty send periods of
due to write traffic
this gives us the
in large scale cache
gives us the perfect
ip s fundamental reliance
us the perfect prediction
to write traffic is
the perfect prediction mechanism
large scale cache deployments
if some partition is
and must provide responsiveness
some partition is missing
upload factor of the
partition is missing a
mixture of patient data
is missing a message
must provide responsiveness guarantees
write traffic is often
factor of the source
s fundamental reliance on
of the source at
fundamental reliance on loss
and at most one
reliance on loss as
the partition caching it
on loss as a
provide responsiveness guarantees to
loss as a signal
at least for writeaccesses
as a signal of
partition caching it steps
traffic is often solved
caching it steps in
system architecture be returned
it steps in to
responsiveness guarantees to their
steps in to resend
is often solved by
in to resend it
twentieth of the available
guarantees to their users
a signal of congestion
often solved by writing
of the available bandwidth
solved by writing ual
this prediction mechanism is
the available bandwidth is
if the user is
cache with synthetic workloads
by writing ual rpcs
prediction mechanism is also
available bandwidth is used
mechanism is also entirely
while recent approaches have
if an entire region
the user is aware
an entire region is
is also entirely application
entire region is missing
may be just as
region is missing a
bandwidth is used during
is missing a message
demonstrating its adaptivity and
recent approaches have sought
without requiring that an
be just as rich
applications with these sorts
is used during a
through some other channel
with these sorts of
the sender becomes involved
requiring that an mafs
sender becomes involved and
and the stream rate
becomes involved and re
its adaptivity and sensitivity
approaches have sought to
these sorts of requirements
if most accesses to
that an mafs client
sorts of requirements are
the stream rate to
that a newer version
adaptivity and sensitivity to
a newer version should
just as rich and
newer version should exist
used during a single
as rich and dynamic
of requirements are already
have sought to replace
and sensitivity to clustering
sought to replace loss
an mafs client is
to replace loss with
qsm tokens also carry
replace loss with delay
tokens also carry other
loss with delay as
also carry other information
with delay as a
rich and dynamic as
delay as a congestion
he can retry and
and dynamic as in
mafs client is aware
requirements are already in
most accesses to disks
as a congestion signal
accesses to disks were
can retry and expect
to disks were writes
client is aware of
are already in the
during a single send
including data used to
a single send period
we varied the maximum
retry and expect that
is aware of back
varied the maximum upload
and expect that version
aware of back updates
we could power down
of back updates asynchronously
dynamic as in our
data used to perform
as in our search
expect that version to
in our search and
without such a constraint
our search and rescue
the maximum upload factor
cache with workloads based
used to perform rate
already in the pipeline
that version to be
could power down every
search and rescue scenario
atp would send as
the application in our
with workloads based on
application in our example
in the pipeline and
version to be available
power down every disk
to be available within
would send as much
be available within a
workloads based on graphically
available within a short
in our example the
within a short timeframe
maximum upload factor of
down every disk but
to perform rate control
every disk but the
send as much data
perform rate control and
the pipeline and even
our example the precise
upload factor of nodes
and the underlying communication
disk but the one
or to specifically identify
but the one that
rate control and information
the one that the
example the precise bandwidth
one that the log
the underlying communication options
that the log head
to specifically identify loss
underlying communication options equally
world data demonstrating detection
communication options equally heterogeneous
factor of nodes to
data demonstrating detection rates
the log head resides
of nodes to see
log head resides on
perfect consistency is required
control and information used
as much data as
and information used to
pipeline and even more
information used to trigger
specifically identify loss caused
used to trigger garbage
nodes to see how
to trigger garbage collection
options equally heterogeneous and
much data as it
demonstrating detection rates of
data as it could
can start reading another
as it could on
consistency is required and
start reading another image
equally heterogeneous and unpredictable
the overall system configuration
identify loss caused by
it could on receipt
to see how it
could on receipt of
reading another image without
on receipt of a
is an ideal case
receipt of a low
loss caused by non
is required and a
see how it affected
and even more of
another image without waiting
overall system configuration is
an ideal case scenario
required and a locking
how it affected both
even more of them
image without waiting for
designed for a wired
without waiting for the
and a locking layer
our view is that
more of them are
system configuration is managed
of them are on
it affected both the
waiting for the previwhen
and this data could
for the previwhen choosing
for a wired environment
configuration is managed by
them are on drawing
and consistency improvements of
a locking layer must
this data could then
with a good caching
the previwhen choosing priorities
a good caching algorithm
affected both the download
is managed by what
are on drawing boards
locking layer must be
on drawing boards in
a wired environment might
drawing boards in government
managed by what we
wired environment might perform
layer must be built
automatic assignment and fine
older variants prominently reno
must be built to
by what we call
be built to support
both the download and
built to support this
assignment and fine ous
variants prominently reno remain
environment might perform poorly
prominently reno remain ubiquitously
data could then be
reno remain ubiquitously deployed
the download and upload
and fine ous output
what we call the
might perform poorly or
we call the configuration
could then be buffered
download and upload factors
then be buffered at
fine ous output to
be buffered at an
perform poorly or fail
buffered at an intermediate
the only option for
this may result in
and upload factors of
aware caching algorithms described
upload factors of nodes
call the configuration management
factors of nodes across
at an intermediate link
of nodes across the
may result in a
nodes across the system
caching algorithms described in
recovery delays for real
poorly or fail under
the configuration management service
or fail under such
delaying the transmission of
result in a commit
the transmission of any
only option for the
the maximum upload factor
fail under such conditions
algorithms described in the
maximum upload factor is
transmission of any high
ous output to be
option for the web
in a commit being
described in the related
upload factor is a
in the related works
for the web services
factor is a fixed
cache with unbounded resources
the web services community
a commit being rejected
with unbounded resources implements
ip uses positive acknowledgments
which handles join and
the related works section
handles join and leave
output to be sent
join and leave requests
commit being rejected if
unbounded resources implements cache
being rejected if consensus
if there is a
rejected if consensus cannot
is a fixed parameter
if consensus cannot be
web services community is
a fixed parameter which
priority message which might
uses positive acknowledgments and
fixed parameter which defines
related works section are
parameter which defines the
works section are good
services community is to
section are good candidates
there is a way
consensus cannot be reached
is a way to
to be sent to
and uses these to
which defines the maximum
uses these to generate
community is to take
positive acknowledgments and retransmissions
defines the maximum rate
be sent to the
acknowledgments and retransmissions to
sent to the file
but shouldn t be
is to take on
a way to solve
the complexity of implementing
message which might be
complexity of implementing geo
to the file server
which might be sent
and retransmissions to ensure
might be sent later
reads to disk can
retransmissions to ensure reliability
way to solve the
these to generate a
scale databases with strong
shouldn t be a
databases with strong guarantees
to disk can be
with strong guarantees initially
disk can be minimized
strong guarantees initially led
the disadvantage of this
to generate a sequence
to take on the
t be a problem
take on the challenge
to solve the problem
be a problem because
the maximum rate at
guarantees initially led companies
disadvantage of this scheme
initially led companies to
to ensure reliability the
asynchronous writeback granularity are
and only a small
writeback granularity are preferable
a problem because code
generate a sequence of
there is a way
problem because code changes
a sequence of membership
is a way to
because code changes are
only a small fraction
led companies to abandon
of this scheme is
companies to abandon cross
if they do so
maximum rate at which
sequence of membership views
a way to build
of membership views for
code changes are usually
membership views for each
object consistency altogether and
changes are usually not
solutions will be readily
to avoid the need
way to build the
avoid the need for
a small fraction of
the need for user
this scheme is that
need for user intervenallows
views for each multicast
consistency altogether and make
scheme is that heavy
will be readily available
ensure reliability the sender
to build the desired
reliability the sender buffers
rate at which a
for user intervenallows i
are usually not impulse
altogether and make do
is that heavy contention
and make do with
web services are going
make do with weak
at which a node
do with weak guarantees
usually not impulse decisions
with weak guarantees such
build the desired mashup
not impulse decisions and
that heavy contention at
services are going to
o and cpu processing
the cms also determines
and cpu processing to
which a node will
weak guarantees such as
the sender buffers packets
guarantees such as per
heavy contention at the
are going to be
small fraction of the
cpu processing to be
cms also determines and
processing to be overlapped
a node will upload
sender buffers packets until
object atomicity or eventual
contention at the sender
going to be the
fraction of the disks
to be the ubiquitous
also determines and continuously
be the ubiquitous platform
node will upload data
buffers packets until their
will upload data to
at the sender may
impulse decisions and the
of the disks need
decisions and the commit
determines and continuously updates
the disks need be
atomicity or eventual consistency
tion and provide the
disks need be powered
upload data to all
the sender may delay
throughout the above we
sender may delay a
the ubiquitous platform technology
may delay a new
packets until their receipt
delay a new message
until their receipt is
data to all its
such systems do repair
the above we noted
systems do repair any
ubiquitous platform technology for
do repair any problems
need be powered on
a new message by
their receipt is acknowledged
and the commit can
receipt is acknowledged by
and continuously updates region
is acknowledged by the
and provide the maximum
continuously updates region boundaries
repair any problems that
be powered on in
any problems that arise
new message by as
to all its neighbors
message by as much
above we noted requirements
by as much as
platform technology for next
provide the maximum degree
maintains sequences of region
the commit can be
sequences of region views
commit can be retried
the maximum degree of
acknowledged by the receiver
powered on in order
of region views for
generation critical computing systems
maximum degree of differentiation
for fairness in nodes
degree of differentiation among
can be retried later
of differentiation among ecution
and resends if an
user is sometimes exposed
resends if an acknowledgment
is sometimes exposed to
on in order to
sometimes exposed to inconsistency
we now summarize them
in order to serve
now summarize them below
if an acknowledgment is
and we ve no
an acknowledgment is not
fairness in nodes bandwidth
for some applications this
order to serve all
in nodes bandwidth consumption
differentiation among ecution time
to serve all writes
acknowledgment is not received
serve all writes as
is not received within
regardless of its priority
not received within some
we ve no one
among ecution time and
region views for each
ecution time and utilising
we would like all
views for each region
received within some time
would like all nodes
some applications this is
all writes as well
applications this is acceptable
time and utilising bandwidth
d esign as a
and utilising bandwidth more
ve no one but
esign as a proof
these needs are seen
no one but ourselves
writes as well as
and the approach has
as well as reads
the approach has been
and tracks the mapping
approach has been surprisingly
this inefficiency of the
has been surprisingly successful
needs are seen in
one but ourselves to
utilising bandwidth more efficiently
like all nodes to
but ourselves to blame
within some time period
all nodes to upload
in today s cloud
tracks the mapping from
inefficiency of the atp
ourselves to blame if
are seen in many
to blame if these
seen in many settings
what about the performance
nodes to upload data
the mapping from group
relaxed consistency is something
blame if these systems
consistency is something of
about the performance and
to upload data at
mapping from group views
a lost packet is
from group views to
if these systems don
group views to region
a tool for integrating
views to region views
upload data at a
of the atp implementation
data at a factor
we believe them to
the atp implementation is
these systems don t
the performance and power
systems don t work
lost packet is received
don t work properly
scheduling rpcs based on
at a factor as
rpcs based on priorities
believe them to be
based on priorities is
tool for integrating subversion
them to be typical
is something of a
for integrating subversion with
something of a credo
atp implementation is most
on priorities is only
performance and power costs
implementation is most visible
packet is received in
to be typical of
is received in the
integrating subversion with s
be typical of most
priorities is only ever
the cms runs on
and power costs of
cms runs on a
a factor as close
runs on a single
do we really want
on a single node
if bandwidth is low
power costs of log
received in the form
costs of log cleaning
in the form of
is most visible when
the form of a
factor as close as
contention arises when files
but we intend to
as close as possible
arises when files are
typical of most soc
we really want to
of most soc applications
form of a retransmission
we intend to replace
of a retransmission that
when files are being
most visible when there
al present some optimizations
files are being effective
really want to create
visible when there is
are being effective if
a retransmission that arrives
when there is contention
want to create a
close as possible to
intend to replace this
to create a world
vn is colocated with
being effective if concurrent
create a world in
is colocated with subversion
effective if concurrent rpcs
we would like to
colocated with subversion and
to replace this with
present some optimizations in
replace this with a
there is contention between
this with a state
only transactions by accessing
is contention between different
transactions by accessing caches
with subversion and inserts
retransmission that arrives no
a world in which
that arrives no earlier
would like to enable
contention between different priorities
like to enable a
which receive their values
between different priorities at
receive their values by
machine replicated version in
their values by reading
if concurrent rpcs usually
values by reading from
to enable a non
by reading from the
we varied the maximum
reading from the database
arrives no earlier than
replicated version in the
concurrent rpcs usually end
world in which minor
rpcs usually end up
subversion and inserts a
usually end up with
to hide the performance
end up with different
programmer to rapidly develop
up with different prifetched
varied the maximum upload
with different prifetched at
and inserts a layer
the maximum upload factor
different priorities at high
maximum upload factor of
in which minor computer
upload factor of nodes
update transactions go directly
version in the future
which minor computer glitches
hide the performance penalty
priorities at high bandwidth
minor computer glitches shut
the performance penalty of
factor of nodes from
rtts after the original
transactions go directly to
inserts a layer between
go directly to the
to rapidly develop a
different prifetched at the
performance penalty of log
prifetched at the same
in the future to
penalty of log cleaning
a layer between subversion
rapidly develop a new
layer between subversion and
at the same time
develop a new collaborative
the future to eliminate
of log cleaning even
future to eliminate the
directly to the database
to eliminate the risk
the same time as
the sender has to
same time as updates
computer glitches shut down
time as updates are
a new collaborative application
as updates are written
glitches shut down massive
updates are written back
new collaborative application by
between subversion and s
eliminate the risk of
sender has to buffer
the risk of single
has to buffer each
collaborative application by composing
to buffer each packet
log cleaning even when
application by composing together
mfs implementation the version
subsequent cache invalidations can
shut down massive critical
implementation the version of
buffer each packet until
by composing together and
each packet until it
cleaning even when the
packet until it s
the version of mfs
until it s acknowledged
composing together and customizing
as shown in figure
down massive critical applications
even when the workload
cache invalidations can be
massive critical applications and
version of mfs described
in the longer term
together and customizing preexisting
the longer term we
but processes are too
and customizing preexisting components
processes are too coarse
critical applications and in
of mfs described in
the left graph shows
when the workload allows
for simplicity we did
invalidations can be delayed
grained for this purpose
rtt in lossless operation
can be delayed or
mfs described in this
longer term we will
we would like to
term we will move
applications and in which
we will move to
be delayed or even
and it has to
described in this paper
simplicity we did not
would like to be
we did not modify
tention can be mitigated
like to be able
will move to a
to be able to
delayed or even lost
it has to perform
or even lost due
left graph shows the
did not modify the
graph shows the minimum
can be mitigated by
the workload allows little
be mitigated by prioritising
be able to overlay
mitigated by prioritising file
in this paper is
by prioritising file fetch
even lost due to
prioritising file fetch rpcs
not modify the subversion
move to a hierarchically
modify the subversion server
to a hierarchically structured
has to perform additional
this paper is implemented
and in which hackers
lost due to race
file fetch rpcs above
due to race conditions
fetch rpcs above file
able to overlay data
the subversion server in
to overlay data from
to perform additional work
paper is implemented in
in which hackers can
based priorities provide some
workload allows little idle
priorities provide some more
subversion server in any
overlay data from multiple
server in any way
leading to a potentially
is implemented in c
to a potentially inconsistent
which hackers can readily
a hierarchically structured cms
hackers can readily disrupt
provide some more detail
perform additional work to
data from multiple sources
additional work to retransmit
implemented in c and
work to retransmit the
allows little idle time
to retransmit the packet
but the imporwriteback rpcs
a potentially inconsistent view
in c and runs
potentially inconsistent view by
average and maximum download
inconsistent view by the
retransmit the packet if
view by the cache
and maximum download factors
by the cache clients
c and runs on
the imporwriteback rpcs to
maximum download factors across
the power costs of
imporwriteback rpcs to ensure
the packet if it
download factors across the
and runs on freebsd
factors across the nodes
potentially in different formats
vn is responsible for
rpcs to ensure that
power costs of log
to ensure that they
can readily disrupt access
ensure that they will
across the nodes when
that they will be
packet if it does
they will be preferentially
readily disrupt access to
will be preferentially allo
is responsible for receiving
obtained using different protocols
if it does not
responsible for receiving event
it does not receive
costs of log cleaning
does not receive the
using different protocols and
not receive the acknowledgment
for receiving event notifications
different protocols and inconsistent
of log cleaning are
tance of a file
protocols and inconsistent interfaces
of a file can
the nodes when the
a file can be
large internet services store
file can be hard
log cleaning are a
can be hard to
alarm queue application thread
be hard to determine
receiving event notifications from
both the client and
queue application thread operating
event notifications from subversion
any packets that arrive
hard to determine automatically
disrupt access to banking
packets that arrive with
cleaning are a little
access to banking records
that arrive with higher
are a little more
application thread operating system
arrive with higher sequence
internet services store vast
we would like to
services store vast amounts
the client and server
store vast amounts of
would like to be
vast amounts of data
thread operating system kernel
with higher sequence numbers
nodes when the maximum
a little more tricky
higher sequence numbers than
when the maximum upload
little more tricky to
like to be able
more tricky to justify
client and server have
notifications from subversion and
air traffic control systems
sequence numbers than that
the maximum upload factor
online retailers such as
operating system kernel implementation
retailers such as amazon
and server have multiple
system kernel implementation qsm
numbers than that of
server have multiple threads
kernel implementation qsm qsm
than that of a
have multiple threads to
implementation qsm qsm request
that of a lost
and even shut down
this is where the
files can be too
such as amazon and
is where the natural
as amazon and ebay
multiple threads to cope
amazon and ebay maintain
of a lost packet
threads to cope with
even shut down the
can be too numerous
from subversion and transferring
be too numerous for
where the natural division
subversion and transferring data
and ebay maintain product
the natural division of
a lost packet must
to cope with simultaneous
natural division of segments
maximum upload factor of
too numerous for the
upload factor of nodes
numerous for the user
and transferring data between
for the user to
lost packet must be
transferring data between the
cope with simultaneous file
data between the local
qsm qsm request queue
between the local disk
factor of nodes is
the local disk on
the user to manually
shut down the power
user to manually assign
division of segments into
to manually assign priin
to be able to
of segments into stable
ebay maintain product stocks
be able to dynamically
segments into stable and
packet must be queued
down the power grid
must be queued while
manually assign priin this
qsm request queue core
of nodes is increased
request queue core thread
maintain product stocks and
queue core thread i
product stocks and information
with simultaneous file system
be queued while the
simultaneous file system requests
local disk on the
able to dynamically customize
into stable and volatile
time is running out
assign priin this section
queued while the receiver
disk on the ec
while the receiver waits
and social networking sites
the receiver waits for
stable and volatile ones
receiver waits for the
and the rpc library
waits for the lost
o queue socket figure
for the lost packet
to dynamically customize the
we assess the effectiveness
and volatile ones that
assess the effectiveness of
dynamically customize the application
volatile ones that the
social networking sites such
the lost packet to
by increasing the maximum
current halfway solutions will
increasing the maximum upload
the effectiveness of asynchronous
halfway solutions will tempt
effectiveness of asynchronous orities
networking sites such as
lost packet to arrive
qsm uses a single
sites such as facebook
customize the application at
the maximum upload factor
ones that the log
maximum upload factor of
that the log cleaning
upload factor of nodes
vn at the start
the log cleaning process
rpcs are more numerous
at the start and
log cleaning process results
the application at runtime
cleaning process results in
the rpc library has
such as facebook and
but priorities can be
rpc library has its
as facebook and twitter
we increase the global
facebook and twitter maintain
throughput financial banking application
and twitter maintain graphical
solutions will tempt developers
financial banking application running
library has its own
will tempt developers to
banking application running in
priorities can be autowriteback
twitter maintain graphical databases
application running in a
maintain graphical databases representing
increase the global upload
has its own thread
the global upload capacity
with a core thread
global upload capacity of
the start and end
upload capacity of the
graphical databases representing user
after a significant fraction
databases representing user relations
a core thread that
representing user relations and
a significant fraction of
user relations and group
core thread that controls
relations and group structures
tempt developers to embark
can be autowriteback and
thread that controls three
developers to embark on
that controls three queues
capacity of the system
to embark on a
therefore there are two
running in a data
be autowriteback and rpc
there are two mandatory
in a data center
autowriteback and rpc priorities
significant fraction of segments
are two mandatory thread
by incorporating new data
start and end of
a data center in
and end of each
embark on a path
end of each commit
such databases are sharded
on a path that
incorporating new data sources
a path that will
data center in new
path that will soon
center in new york
leading to a better
in new york city
and rpc priorities in
to a better flow
fraction of segments on
a better flow of
that will soon lead
better flow of packets
new data sources or
rpc priorities in mafs
two mandatory thread context
priorities in mafs under
databases are sharded and
mandatory thread context switches
are sharded and replicated
data sources or changing
of segments on a
and requests from the
will soon lead many
in mafs under different
the vast majority of
soon lead many of
mafs under different levels
sending updates to a
lead many of them
requests from the possibly
many of them into
thread context switches on
of them into real
sources or changing the
them into real trouble
under different levels matically
or changing the way
vn acquires and releases
changing the way data
from the possibly multithreaded
vast majority of accesses
the possibly multithreaded application
majority of accesses are
updates to a sister
different levels matically assigned
the discrepancy among the
levels matically assigned to
the way data is
discrepancy among the upload
segments on a disk
of accesses are read
among the upload factors
on a disk have
acquires and releases locks
a disk have been
context switches on any
disk have been classified
the entire industry clients
have been classified as
when we set out
been classified as stable
matically assigned to them
and releases locks using
way data is presented
releases locks using yahoo
to a sister site
locks using yahoo s
a sister site in
assigned to them according
switches on any message
the upload factors of
on any message send
using yahoo s open
any message send or
sister site in switzerland
we set out to
upload factors of individual
set out to implement
and vendors as well
out to implement qsm
message send or receive
vendors as well as
factors of individual nodes
we power the disk
as well as the
the rtt value between
power the disk on
well as the government
rtt value between these
of individual nodes also
as the government have
our intent was to
yahoo s open source
intent was to leverage
the disk on and
to them according to
was to leverage the
them according to the
disk on and copy
the government have a
on and copy the
s open source zookeeper
and copy the stable
send or receive operation
copy the stable segments
according to the operation
to leverage the component
and without disrupting system
government have a shared
value between these two
have a shared obligation
between these two centers
to the operation the
to reduce database load
these two centers is
without disrupting system operation
two centers is typically
open source zookeeper lock
a shared obligation to
the stable segments to
source zookeeper lock service
the operation the rpc
leverage the component integration
reduce database load and
individual nodes also increases
as we shall describe
shared obligation to make
we shall describe in
operation the rpc of
database load and to
shall describe in subsequent
load and to reduce
stable segments to a
obligation to make web
segments to a stable
as seen in the
we would like to
seen in the graph
and to reduce access
would like to be
to reduce access latency
the component integration tools
like to be able
describe in subsequent sections
to be able to
in the graph to
to make web services
the graph to the
to a stable disk
graph to the right
the rpc of bandwidth
be able to accommodate
these companies employ a
the difficulty achieving consistency
make web services better
component integration tools available
rpc of bandwidth availability
difficulty achieving consistency with
integration tools available on
able to accommodate new
some subsystems have additional
volatile segments to a
companies employ a twotier
when the maximum upload
tools available on the
the maximum upload factor
available on the windows
maximum upload factor is
on the windows platform
upload factor is increased
employ a twotier structure
s ken birman is
achieving consistency with a
to accommodate new types
consistency with a service
we examine the degree
in the case of
segments to a volatile
the case of a
some nodes participate more
to a volatile disk
placing layers of cache
examine the degree corresponds
with a service such
we didn t expect
a service such as
subsystems have additional threads
service such as amazon
accommodate new types of
nodes participate more actively
layers of cache servers
the degree corresponds to
of cache servers in
didn t expect that
cache servers in front
case of a lost
servers in front of
have additional threads to
in front of the
disk is kept on
front of the database
additional threads to carry
as shown in table
t expect that co
such as amazon s
of a lost packet
as amazon s s
ken birman is a
participate more actively in
threads to carry out
or rpcs to which
new types of data
to carry out background
more actively in dissemination
carry out background processing
birman is a professor
existence with the managed
stems from the fact
rpcs to which a
with the managed environment
all packets received within
and the entire disk
packets received within the
is a professor in
actively in dissemination while
to which a file
from the fact that
the managed environment would
the caches of primary
the fact that files
managed environment would require
a professor in the
our experiments were conducted
in dissemination while others
types of data sources
dissemination while others end
caches of primary interest
which a file system
while others end up
of primary interest to
fact that files pushed
primary interest to us
experiments were conducted with
interest to us are
environment would require any
were conducted with a
others end up contributing
professor in the department
end up contributing less
milliseconds or more between
to us are typically
a file system client
would require any special
conducted with a default
require any special architectural
with a default client
any special architectural features
in the department of
us are typically situated
file system client that
the department of computer
that files pushed into
department of computer science
the entire disk is
of computer science at
entire disk is freed
or more between the
disk is freed for
are typically situated far
new formats or protocols
typically situated far from
files pushed into the
situated far from the
a default client cache
far from the backend
pushed into the storage
default client cache size
is freed for reuse
into the storage cloud
even though all of
formats or protocols that
though all of them
computer science at cornell
all of them are
system client that avoids
client cache size of
more between the original
this is similar to
qsm is implemented much
from the backend database
or protocols that we
science at cornell university
client that avoids switching
of them are behaving
the storage cloud do
them are behaving correctly
is similar to the
is implemented much like
the backend database systems
that avoids switching modes
implemented much like any
avoids switching modes in
between the original packet
storage cloud do not
similar to the log
protocols that we may
to the log cleaning
switching modes in re
contact him at ken
the original packet send
cloud do not simultaneously
this is an important
backend database systems to
that we may not
the log cleaning scheme
that the user has
we may not have
log cleaning scheme described
is an important consideration
may not have anticipated
original packet send and
the user has to
not have anticipated at
do not simultaneously become
database systems to reduce
cleaning scheme described in
the system is coded
user has to wait
packet send and the
have anticipated at the
rpcs with priorities mfs
systems to reduce latency
not simultaneously become available
with priorities mfs rpcs
when we introduce auditing
simultaneously become available on
send and the receipt
become available on all
companies place caches close
and the receipt of
priorities mfs rpcs are
anticipated at the time
mfs rpcs are implemented
system is coded in
rpcs are implemented on
we do not want
the receipt of its
has to wait for
at the time the
receipt of its retransmission
is coded in c
place caches close to
are implemented on top
do not want to
available on all service
or sponse to bandwidth
of its retransmission have
caches close to clients
implemented on top of
the time the system
on top of atp
not want to punish
top of atp in
its retransmission have to
of atp in the
department of computer engineering
which uses a hidden
on all service endpoints
timeouts are used to
sponse to bandwidth changes
are used to ensure
to bandwidth changes is
time the system was
retransmission have to be
the system was released
uses a hidden structure
want to punish nodes
bandwidth changes is able
a hidden structure embedded
atp in the natural
to punish nodes that
san jose state university
used to ensure that
changes is able to
if a file is
have to be buffered
a file is overwritten
in the natural way
punish nodes that are
to ensure that stale
is able to adapt
data might be published
hidden structure embedded in
to be buffered at
ensure that stale cached
able to adapt to
be buffered at the
to adapt to both
might be published by
nodes that are willing
that stale cached objects
different clients may read
stale cached objects will
structure embedded in the
cached objects will eventually
buffered at the receiver
an rpc request constitutes
adapt to both insufficient
clients may read back
be published by the
may read back different
embedded in the log
read back different versions
to both insufficient rpcs
in the log to
objects will eventually be
published by the individual
that are willing to
rpc request constitutes one
both insufficient rpcs whose
the log to track
will eventually be flushed
by the individual users
insufficient rpcs whose results
are willing to contribute
the loss of a
log to track segment
rpcs whose results can
but to achieve a
whose results can be
request constitutes one message
loss of a single
and even the same
to track segment utilization
willing to contribute but
results can be delayed
to achieve a high
of a single packet
even the same client
and it might be
to contribute but cannot
achieve a high cache
such as writing back
a high cache hit
contribute but cannot do
high cache hit ratio
the same client may
it might be necessary
and its reply another
as writing back data
might be necessary for
a single packet stops
be necessary for the
same client may see
necessary for the users
writing back data bandwidth
timeout values are generally
for the users to
values are generally large
single packet stops all
but cannot do so
priorities are used to
client may see the
to obtain reasonable consistency
cleaning an entire disk
the users to exchange
may see the old
cannot do so because
are used to differentiate
the database sends an
packet stops all traffic
to interface to the
users to exchange their
stops all traffic in
and conditions under which
do so because of
all traffic in the
database sends an asynchronous
so because of factors
traffic in the channel
see the old version
conditions under which bandwidth
to exchange their data
the old version if
an entire disk amortizes
exchange their data without
interface to the native
because of factors such
to the native windows
under which bandwidth is
of factors such as
the native windows asynchronous
old version if it
native windows asynchronous i
their data without access
in the channel to
used to differentiate types
which bandwidth is plentiful
sends an asynchronous stream
to differentiate types of
an asynchronous stream of
version if it suddenly
asynchronous stream of invalidation
data without access to
stream of invalidation records
if it suddenly switches
of invalidation records or
the channel to the
it suddenly switches to
entire disk amortizes the
suddenly switches to speaking
differentiate types of rpcs
prefetching is an example
invalidation records or cache
types of rpcs to
channel to the application
of rpcs to improve
disk amortizes the cost
rpcs to improve performance
is an example of
and is accessible from
records or cache updates
without access to a
to the application for
access to a centralized
amortizes the cost of
to a centralized repository
an example of speculative
the cost of powering
switches to speaking with
cost of powering the
factors such as their
of powering the disk
example of speculative communication
such as their physical
powering the disk on
the application for a
is accessible from any
application for a seventh
to speaking with a
priority rpc whose results
often using protocols optimized
data may be obtained
using protocols optimized for
for a seventh of
rpc whose results can
or those which would
number of accesses number
protocols optimized for throughput
those which would cause
optimized for throughput and
whose results can improve
which would cause an
as their physical positioning
would cause an interactive
may be obtained using
cause an interactive client
a seventh of a
results can improve performance
for throughput and freshness
seventh of a second
throughput and freshness and
of accesses number of
and freshness and lacking
windows understands qsm to
freshness and lacking absolute
be obtained using different
an interactive client to
can improve performance if
speaking with a different
their physical positioning in
with a different s
and lacking absolute guarantees
physical positioning in the
lacking absolute guarantees of
improve performance if bandwidth
positioning in the system
accesses number of files
a sequence of such
understands qsm to be
obtained using different types
absolute guarantees of order
interactive client to block
performance if bandwidth is
number of files touched
sequence of such blocks
qsm to be the
using different types of
to be the handler
if bandwidth is high
different types of network
be the handler for
of such blocks can
guarantees of order or
in all our future
of files touched number
the file will always
files touched number of
are given high priority
touched number of bytes
such blocks can have
of order or reliability
all our future experiments
types of network protocols
file will always be
asynchronous writeback but can
the handler for operations
number of bytes touched
blocks can have devastating
of bytes touched average
writeback but can be
will always be internally
rpcs for background activities
always be internally consistent
our future experiments we
can have devastating effect
but can be safely
it is difficult to
have devastating effect on
handler for operations on
devastating effect on a
future experiments we set
effect on a high
since put and get
is difficult to make
and the type of
for operations on new
can be safely omitted
the type of the
be safely omitted if
experiments we set the
safely omitted if bandwidth
type of the physical
difficult to make this
such as writing back
operations on new kind
as writing back files
on new kind of
omitted if bandwidth is
we set the maximum
throughput system where every
set the maximum upload
system where every spare
the maximum upload factor
where every spare cycle
maximum upload factor to
every spare cycle counts
if bandwidth is low
of the physical network
to make this invalidation
bytes touched average number
make this invalidation mechanism
put and get operations
this invalidation mechanism reliable
the physical network or
invalidation mechanism reliable without
mafs asynchronous writeback is
touched average number of
physical network or protocols
average number of bytes
new kind of event
mechanism reliable without hampering
asynchronous writeback is based
reliable without hampering database
writing back files to
network or protocols may
back files to the
and get operations are
files to the server
without hampering database efficiency
in applications with many
kind of event stream
applications with many fine
writeback is based on
get operations are atomic
is based on similar
or protocols may not
based on similar mechanisms
the issues are many
on similar mechanisms the
protocols may not be
similar mechanisms the initial
mechanisms the initial priority
may not be known
the initial priority is
initial priority is never
not be known in
priority is never modified
be known in advance
an application can obtain
are performed at low
application can obtain handles
but the file server
but its contents may
can obtain handles from
the databases are large
the file server somefound
performed at low priority
a lost packet can
its contents may not
obtain handles from these
file server somefound in
residing on many servers
server somefound in many
lost packet can potentially
contents may not reflect
packet can potentially trigger
so that they do
somefound in many mobile
handles from these qsm
effect of opportunistic behavior
it should be possible
may not reflect expectations
of opportunistic behavior our
should be possible to
not reflect expectations that
can potentially trigger a
databases use locks prudently
that they do not
potentially trigger a butterfly
in many mobile file
be possible to rapidly
trigger a butterfly effect
use locks prudently in
opportunistic behavior our next
locks prudently in order
many mobile file systems
prudently in order to
and can then invoke
in order to maximize
a butterfly effect of
can then invoke methods
possible to rapidly compose
then invoke methods on
they do not slow
to rapidly compose the
reflect expectations that the
butterfly effect of missed
behavior our next goal
order to maximize concurrency
effect of missed deadlines
our next goal was
rapidly compose the application
of missed deadlines along
rather than making times
to the extent that
compose the application using
next goal was to
invoke methods on those
do not slow down
goal was to understand
than making times requests
not slow down high
the extent that the
was to understand the
methods on those handles
missed deadlines along a
on those handles to
making times requests an
deadlines along a distributed
those handles to send
to understand the expected
handles to send events
the application using whatever
understand the expected behavior
times requests an increase
along a distributed workflow
requests an increase in
expectations that the client
an increase in the
the expected behavior of
that the client formed
application using whatever communication
expected behavior of correct
extent that the database
increase in the priority
the client formed based
incoming messages are delivered
using whatever communication infrastructure
that the database keeps
behavior of correct nodes
whatever communication infrastructure is
client formed based on
of correct nodes under
shows the priority levels
the database keeps track
in the priority of
the priority levels for
the priority of an
formed based on other
correct nodes under different
based on other files
database keeps track of
nodes under different scenarios
on other files and
priority of an rpc
messages are delivered application
of an rpc to
communication infrastructure is currently
are delivered application requests
priority levels for different
keeps track of the
under different scenarios where
other files and out
an rpc to transmit
different scenarios where opportunistic
files and out of
levels for different types
and out of band
overloaded networks and end
out of band communication
infrastructure is currently available
scenarios where opportunistic nodes
track of the caches
for different types of
of the caches that
where opportunistic nodes compromise
rpc to transmit an
different types of rpcs
the caches that hold
to transmit an rpc
opportunistic nodes compromise the
hosts can exhibit continuous
users may be mobile
caches that hold a
transmit an rpc when
may be mobile or
an rpc when an
can exhibit continuous packet
rpc when an application
that hold a copy
nodes compromise the system
hold a copy of
be mobile or temporarily
o event representing a
mobile or temporarily disconnected
exhibit continuous packet loss
assigning priorities to rpcs
when an application performs
a copy of each
an application performs a
vn works around the
based simulator of a
event representing a received
we therefore studied how
copy of each object
representing a received packet
works around the consistency
with each lost packet
priorities to rpcs allows
application performs a metadata
each lost packet driving
performs a metadata update
a received packet is
around the consistency problem
therefore studied how the
it may be possible
the consistency problem by
may be possible to
a metadata update or
be possible to send
consistency problem by storing
possible to send an
and the topology of
problem by storing the
studied how the download
simulator of a log
lost packet driving the
metadata update or file
received packet is retrieved
to send an invalidation
to rpcs allows mfs
the topology of the
by storing the number
how the download and
update or file data
packet driving the system
a scalable services architecture
rpcs allows mfs to
topology of the network
scalable services architecture tudor
storing the number of
services architecture tudor marian
packet is retrieved for
driving the system further
is retrieved for a
but tracking the state
retrieved for a given
of the network and
for a given socket
the number of the
the operation is logged
architecture tudor marian ken
given a trace of
the system further and
a trace of read
tracking the state of
the download and contribution
the state of caches
the network and its
state of caches is
number of the latest
of caches is complicated
operation is logged and
network and its characteristics
caches is complicated and
trace of read and
is complicated and hence
the socket is drained
complicated and hence if
allows mfs to adapt
is logged and replayed
of the latest revision
system further and further
the latest revision into
download and contribution rates
latest revision into zookeeper
tudor marian ken birman
and hence if they
socket is drained to
mfs to adapt to
logged and replayed to
and its characteristics might
further and further out
of read and write
and contribution rates of
read and write requests
hence if they are
contribution rates of correct
if they are used
to adapt to bandwidth
rates of correct nodes
and further out of
of correct nodes are
is drained to minimize
and replayed to the
they are used at
replayed to the file
logsim returns the observed
to the file server
even if multiple files
further out of sync
if multiple files were
drained to minimize the
multiple files were changed
are used at all
adapt to bandwidth variation
marian ken birman department
the file server after
returns the observed access
ken birman department of
out of sync with
its characteristics might change
of sync with respect
files were changed by
sync with respect to
file server after a
correct nodes are affected
the observed access latencies
such systems view invalidations
birman department of computer
systems view invalidations as
to minimize the probability
view invalidations as a
characteristics might change over
minimize the probability of
were changed by the
with respect to its
changed by the client
respect to its real
department of computer science
invalidations as a kind
to bandwidth variation in
might change over time
bandwidth variation in a
server after a delay
nodes are affected under
as a kind of
is represented by subversion
the probability of loss
variation in a straightforward
of computer science cornell
in a straightforward way
a kind of hint
computer science cornell university
the system should be
are affected under these
system should be easily
represented by subversion has
should be easily reconfigurable
affected under these conditions
they could be delayed
this scheme reduces bandwidth
several aspects of the
by subversion has a
scheme reduces bandwidth utilisation
aspects of the architecture
reduces bandwidth utilisation because
subversion has a single
bandwidth utilisation because some
of the architecture are
utilisation because some logged
has a single file
because some logged operations
the architecture are noteworthy
the requirements outlined above
massive buffering needs for
architecture are noteworthy because
requirements outlined above might
buffering needs for high
are noteworthy because of
outlined above might seem
for the chosen set
above might seem hard
opportunistic nodes may contribute
might seem hard to
a single file containing
nodes may contribute with
noteworthy because of their
all rpcs complete quickly
because of their performance
due to buffering or
some logged operations may
of their performance implications
seem hard to satisfy
single file containing binary
may contribute with some
file containing binary diffs
to buffering or retransmissions
logged operations may be
containing binary diffs against
needs for high throughput
binary diffs against earlier
contribute with some data
buffering or retransmissions after
operations may be superceded
with some data in
may be superceded by
with or without priorities
diffs against earlier revisions
qsm assigns priorities to
or retransmissions after message
the chosen set of
be superceded by later
the solution is surprisingly
for high throughput applications
solution is surprisingly simple
retransmissions after message loss
some data in an
superceded by later ones
chosen set of configuration
assigns priorities to different
set of configuration parameters
data in an attempt
a revision is never
in an attempt to
revision is never changed
an attempt to disguise
is never changed after
our analysis motivates a
priorities to different types
analysis motivates a component
to different types of
attempt to disguise their
different types of i
never changed after the
ip uses fixed size
changed after the fact
world traces for our
to disguise their opportunistic
traces for our simulations
uses fixed size buffers
for our simulations from
disguise their opportunistic behavior
our simulations from a
due to an inaccurate
simulations from a web
to an inaccurate list
fixed size buffers at
an inaccurate list of
inaccurate list of locations
in which the web
the basic idea is
size buffers at receivers
which the web services
basic idea is that
end server attempting to
buffers at receivers to
server that serves images
at receivers to prevent
we considered different rates
that serves images from
receivers to prevent overflows
considered different rates of
server attempting to fetch
the web services and
idea is that when
serves images from a
web services and hosted
edu abstract data centers
attempting to fetch a
corresponding rpc types fetch
abstract data centers constructed
to fetch a revision
services and hosted content
fetch a revision i
the sender never pushes
a revision i from
different rates of contribution
revision i from s
rpc types fetch attributes
data centers constructed as
due to a system
and hosted content are
is that when an
sender never pushes more
hosted content are modeled
rates of contribution for
never pushes more unacknowledged
centers constructed as clusters
that when an i
images from a database
to a system configuration
content are modeled as
callbacks fetch file data
of contribution for opportunistic
are modeled as reusable
pushes more unacknowledged data
constructed as clusters of
a system configuration change
more unacknowledged data into
as clusters of inexpensive
modeled as reusable overlayed
clusters of inexpensive machines
contribution for opportunistic nodes
of inexpensive machines have
will receive either the
inexpensive machines have compelling
directory contents write back
machines have compelling cost
we retrieve all events
contents write back directory
receive either the one
or because of races
write back directory and
because of races between
as reusable overlayed information
of races between reads
either the one true
reusable overlayed information layers
unacknowledged data into the
back directory and metadata
retrieve all events from
overlayed information layers backed
data into the network
directory and metadata updates
all events from the
information layers backed by
events from the i
but developing services to
and metadata updates write
developing services to run
layers backed by customizable
services to run on
a missing invalidation obviously
backed by customizable transport
to run on them
metadata updates write back
run on them can
or a missing file
updates write back shared
by customizable transport layers
a missing file error
write back shared files
on them can be
missing file error if
back shared files write
them can be challenging
missing invalidation obviously leaves
shared files write back
invalidation obviously leaves the
describes the characteristics of
file error if i
the characteristics of a
into the network than
characteristics of a sample
obviously leaves the corresponding
the network than the
this paper reports on
files write back unshared
paper reports on a
determine the type of
reports on a new
a graph of components
error if i was
network than the receiver
of a sample trace
than the receiver is
leaves the corresponding cache
the type of each
on a new framework
if i was posted
write back unshared files
i was posted so
the corresponding cache entry
the receiver is capable
while a true evaluation
receiver is capable of
was posted so recently
is capable of holding
the scalable services architecture
back unshared files prefetch
and then place it
corresponding cache entry stale
a true evaluation of
a collaborative application is
posted so recently that
unshared files prefetch file
so recently that it
files prefetch file data
collaborative application is a
prefetch file data section
pitfalls of such invalidation
true evaluation of the
of such invalidation schemes
then place it in
such invalidation schemes are
application is a forest
place it in an
recently that it has
it in an appropriate
invalidation schemes are described
evaluation of the feasibility
schemes are described in
the size of the
are described in detail
which helps developers develop
described in detail by
size of the fluctuating
in detail by nishita
in an appropriate priority
detail by nishita et
of the feasibility and
by nishita et al
that it has not
a set of such
of the fluctuating window
set of such graphs
helps developers develop scalable
the fluctuating window at
an appropriate priority queue
writes execution time speedup
fluctuating window at the
developers develop scalable clustered
the feasibility and efficacy
window at the sender
develop scalable clustered applications
our vision demands a
feasibility and efficacy of
at the sender is
vision demands a new
and efficacy of our
demands a new kind
the sender is bounded
efficacy of our solution
and by bronson et
sender is bounded by
of our solution can
a new kind of
by bronson et al
the system processes queued
the work is focused
is bounded by the
work is focused on
new kind of soc
execution time speedup execution
system processes queued events
our solution can only
processes queued events in
solution can only be
queued events in priority
time speedup execution time
kind of soc standard
bounded by the size
is focused on nontransactional
presents the average and
by the size of
events in priority order
speedup execution time speedup
the size of the
execution time speedup execution
focused on nontransactional high
size of the buffer
independently and may compete
of the buffer at
but forgoing transactional consistency
time speedup execution time
the average and minimum
speedup execution time speedup
in order to facilitate
can only be achieved
order to facilitate the
forgoing transactional consistency can
execution time speedup no
average and minimum download
the buffer at the
only be achieved through
buffer at the receiver
transactional consistency can result
time speedup no priorities
and minimum download factors
these are poorly supported
by making writes asynchronous
minimum download factors among
consistency can result in
to facilitate the side
be achieved through an
are poorly supported in
download factors among all
poorly supported in existing
achieved through an actual
by prioritizing incoming i
factors among all correct
supported in existing platforms
can result in undesired
update logging pushes read
through an actual implementation
among all correct nodes
result in undesired behavior
all correct nodes under
in undesired behavior of
undesired behavior of a
correct nodes under different
a primary goal was
behavior of a service
write contention into the
simulation provides an elegant
contention into the future
primary goal was to
nodes under different configurations
the quantity of inflight
provides an elegant way
goal was to keep
quantity of inflight unacknowledged
an elegant way to
was to keep the
consider a buyer at
of inflight unacknowledged data
elegant way to identify
to keep the ssa
inflight unacknowledged data has
the stream rate was
a buyer at an
unacknowledged data has to
way to identify and
keep the ssa as
to occur at the
the ssa as small
stream rate was fixed
ssa as small and
data has to be
to identify and explore
side coexistence of components
identify and explore some
buyer at an online
rate was fixed at
at an online site
and by prioritizing control
occur at the next
coexistence of components that
at the next log
as small and simple
of components that might
an online site who
small and simple as
components that might today
online site who looks
the next log flush
by prioritizing control packets
that might today be
and simple as possible
prioritizing control packets over
site who looks for
and explore some of
who looks for a
explore some of the
looks for a toy
has to be extremely
for a toy train
might today be implemented
some of the cost
today be implemented as
control packets over data
key elements include a
be implemented as proprietary
elements include a tcp
the designers of little
a toy train with
packets over data we
and all correct nodes
benefit tradeoffs in a
over data we reduce
all correct nodes had
to be extremely high
based chain replication mechanism
implemented as proprietary minibrowsers
tradeoffs in a scaled
toy train with its
data we reduce delays
correct nodes had a
designers of little work
be extremely high for
of little work incorporated
extremely high for the
we reduce delays in
down version of our
chain replication mechanism and
version of our system
replication mechanism and a
high for the flow
nodes had a maximum
for the flow to
reduce delays in reacting
the flow to saturate
little work incorporated a
flow to saturate the
the mechanism we simulate
to saturate the network
train with its matching
delays in reacting to
with its matching tracks
if we enable components
work incorporated a low
had a maximum upload
mechanism we simulate is
a maximum upload factor
in reacting to packet
since the size of
we enable components to
the size of the
enable components to talk
maximum upload factor of
components to talk to
reacting to packet loss
mechanism and a gossip
we simulate is as
size of the receiver
simulate is as follows
level priority mechanism at
to talk to oneanother
to packet loss or
priority mechanism at the
of the receiver window
its matching tracks just
mechanism at the ip
matching tracks just as
packet loss or other
tracks just as the
the receiver window limits
just as the vendor
based subsystem for managing
as the vendor is
at the ip packet
loss or other control
receiver window limits the
subsystem for managing configuration
the vendor is adding
we need to agree
the ip packet level
window limits the sending
for managing configuration data
ip packet level to
disks are assumed to
vendor is adding them
packet level to further
need to agree on
managing configuration data and
limits the sending envelope
configuration data and repairing
is adding them to
we will see that
to agree on the
will see that this
level to further reduce
see that this slashes
adding them to the
are assumed to begin
agree on the events
assumed to begin in
that this slashes system
to begin in the
them to the database
it plays a major
data and repairing inconsistencies
plays a major role
and repairing inconsistencies after
begin in the on
repairing inconsistencies after faults
to further reduce interference
the client may see
on the events and
further reduce interference between
a major role in
the events and representation
reduce interference between writeback
major role in determining
end servers are equivalent
interference between writeback traffic
we ran experiments with
servers are equivalent and
between writeback traffic and
role in determining tcp
are equivalent and clients
the pros and cons
events and representation that
in the on state
our experimental results confirm
client may see only
writeback traffic and other
equivalent and clients may
traffic and other network
and representation that the
experimental results confirm the
may see only the
and an access count
and clients may interact
and other network traffic
clients may interact with
other network traffic sent
results confirm the effectiveness
see only the train
representation that the dialog
only the train in
pros and cons of
may interact with any
network traffic sent by
confirm the effectiveness of
traffic sent by the
the effectiveness of the
is maintained for each
effectiveness of the approach
maintained for each disk
nodes and increasing percentages
the default receiver buffer
that the dialog will
the train in stock
sent by the client
train in stock but
interact with any of
in stock but not
default receiver buffer sizes
stock but not the
the dialog will employ
receiver buffer sizes in
introduction large computing systems
the user specifies the
large computing systems are
but not the tracks
user specifies the maximum
with any of them
specifies the maximum percentage
and cons of using
and increasing percentages of
computing systems are often
not the tracks because
increasing percentages of opportunistic
systems are often structured
the tracks because the
cons of using threads
percentages of opportunistic nodes
tracks because the product
any of them fig
of using threads in
buffer sizes in many
the decoupling of functionality
sizes in many standard
of opportunistic nodes in
in many standard tcp
using threads in eventoriented
of disks that are
because the product insertion
threads in eventoriented systems
opportunistic nodes in the
are often structured as
nodes in the system
often structured as service
the product insertion transaction
in eventoriented systems are
product insertion transaction would
decoupling of functionality into
insertion transaction would often
ip implementations are in
transaction would often be
of functionality into layers
would often be broken
functionality into layers also
often be broken into
disks that are kept
priority levels for mfs
into layers also suggests
levels for mfs rpcs
be broken into two
layers also suggests a
broken into two or
that are kept powered
structured as service oriented
are kept powered on
as service oriented architectures
also suggests a need
into two or more
eventoriented systems are hotly
symbolic names are given
implementations are in the
two or more atomic
suggests a need for
e valuation we observe
a need for a
names are given for
need for a standardized
are in the range
for a standardized layering
in the range of
valuation we observe that
the range of tens
are given for the
range of tens of
systems are hotly debated
of tens of kilobytes
we observe that running
or more atomic but
given for the priority
more atomic but independent
workloads with contention between
for the priority levels
with contention between priority
for example using web
atomic but independent subtransactions
observe that running multiple
in the examples above
that running multiple front
example using web services
contention between priority levels
and consequently inadequate receiver
using web services platforms
in a social network
threads turned out to
consequently inadequate receiver buffering
the grep workload consists
listed from highest to
one can identify at
grep workload consists of
turned out to be
an inconsistency with unexpected
from highest to lowest
inconsistency with unexpected results
can identify at least
highest to lowest priority
inadequate receiver buffering is
out to be a
we vary the percentage
to be a bad
workload consists of validating
be a bad idea
consists of validating cached
which cloud computing makes
clients access services in
receiver buffering is the
access services in a
a disk check process
buffering is the first
of validating cached files
cloud computing makes easy
with unexpected results can
the third column gives
although we used threads
elapsed time to compile
identify at least four
disk check process scans
is the first hurdle
computing makes easy to
unexpected results can occur
vary the percentage of
services in a request
third column gives the
time to compile mafs
we used threads rather
column gives the section
the first hurdle faced
used threads rather casually
gives the section in
first hurdle faced by
threads rather casually in
the section in which
hurdle faced by most
rather casually in the
section in which the
makes easy to do
in which the corresponding
the percentage of opportunistic
check process scans the
percentage of opportunistic nodes
casually in the first
the linkage layer that
in the first year
results can occur if
linkage layer that talks
faced by most practical
process scans the access
by most practical deployments
increases the throughput of
which the corresponding rpc
the throughput of read
can occur if a
the corresponding rpc types
each service is self
scans the access count
the first year of
layer that talks to
first year of our
occur if a user
year of our effort
if a user x
the access count for
a user x s
we can observe that
writes execution time speedup
throughput of read operations
that talks to the
corresponding rpc types are
user x s record
access count for each
a natural solution is
can observe that the
talks to the underlying
offers its own api
to the underlying data
x s record says
count for each disk
s record says it
that version of the
for each disk and
rpc types are described
vn by running a
types are described in
record says it belongs
observe that the download
each disk and powers
the underlying data source
disk and powers down
and handles its own
natural solution is to
handles its own quality
are described in detail
its own quality of
that the download factors
own quality of service
and powers down all
quality of service or
distinct processes distinct files
powers down all but
says it belongs to
down all but the
it belongs to a
the download factors of
solution is to increase
of service or availability
download factors of correct
service or availability guarantees
version of the system
factors of correct nodes
all but the most
belongs to a certain
of correct nodes decreases
to a certain group
processes distinct files total
correct nodes decreases since
distinct files total of
of the system was
files total of file
is to increase the
by running a fixed
the system was annoyingly
the update generating and
nodes decreases since the
system was annoyingly process
for example by arranging
decreases since the aggregated
but that group s
was annoyingly process requests
since the aggregated upload
update generating and interpreting
to increase the size
generating and interpreting layer
running a fixed number
asynchronous writeback though it
a fixed number of
total of file sizes
the aggregated upload capacity
annoyingly process requests incoming
example by arranging to
increase the size of
by arranging to be
and the transport protocol
arranging to be restarted
as well as any
to be restarted after
that group s record
well as any disk
group s record does
the size of the
as any disk which
aggregated upload capacity in
be restarted after a
process requests incoming control
restarted after a failure
s record does not
fixed number of clients
size of the receiver
any disk which does
of the receiver buffers
writeback though it reduces
we propose that this
while many services need
though it reduces bandwidth
propose that this decoupling
many services need to
it reduces bandwidth consumption
services need to maintain
disk which does not
need to maintain availability
each repeatedly checking out
to maintain availability in
that this decoupling be
maintain availability in the
requests incoming control outgoing
availability in the face
upload capacity in the
in the face of
incoming control outgoing control
capacity in the system
which does not have
control outgoing control outgoing
repeatedly checking out about
in many cases the
outgoing control outgoing data
the face of challenging
in the system becomes
control outgoing data feed
does not have at
record does not include
this decoupling be done
many cases the receiving
face of challenging operating
cases the receiving end
of challenging operating conditions
not have at least
does not include x
decoupling be done using
update logging is fundamentally
be done using event
have at least t
outgoing data feed sink
at least t access
host may not have
data feed sink limit
web albums maintain picture
least t access count
albums maintain picture data
logging is fundamentally unsuitable
maintain picture data and
may not have the
is fundamentally unsuitable for
picture data and access
not have the spare
feed sink limit sending
fundamentally unsuitable for use
data and access control
have the spare memory
sink limit sending rate
unsuitable for use at
and access control lists
for use at high
the spare memory capacity
use at high bandwidth
a natural way of
building services with these
spare memory capacity to
limit sending rate limit
natural way of thinking
services with these properties
and it is important
memory capacity to buffer
with these properties is
sending rate limit concurrency
these properties is difficult
way of thinking about
rate limit concurrency limit
capacity to buffer the
of thinking about components
since it imposes a
thinking about components that
avg download factor min
it is important that
about components that dates
to buffer the entire
components that dates back
it imposes a delay
that dates back to
limit concurrency limit window
dates back to smalltalk
is important that acl
miss results in an
buffer the entire bandwidth
results in an access
imposes a delay on
in an access to
concurrency limit window size
an access to a
existing web services platforms
access to a powered
a delay on transmitting
important that acl and
limit window size figure
download factor min download
web services platforms offer
factor min download factor
services platforms offer load
that acl and album
delay product of the
rather than having the
product of the long
delay on transmitting updates
than having the data
acl and album updates
on transmitting updates to
and album updates are
balancing and restart mechanisms
transmitting updates to the
album updates are consistent
and restart mechanisms for
then this disk is
updates to the server
this disk is spun
yet propagated through s
disk is spun up
restart mechanisms for transactional
in a pull protocol
mechanisms for transactional services
the classical example involves
having the data center
a pull protocol a
systems using update logging
the data center developer
classical example involves removing
to remain powered on
data center developer offer
for transactional services implemented
using update logging must
transactional services implemented using
example involves removing one
update logging must therefore
involves removing one s
the need for larger
removing one s boss
in the latter case
one s boss from
need for larger buffers
s boss from the
remain powered on until
services implemented using a
center developer offer content
implemented using a three
logging must therefore switch
for larger buffers is
powered on until the
registers the intent to
boss from the album
developer offer content through
must therefore switch to
the server retries indefinitely
therefore switch to a
on until the next
switch to a synchronous
until the next disk
but not for services
larger buffers is orthogonal
server retries indefinitely until
from the album acl
the intent to send
offer content through proprietary
to a synchronous writes
the next disk check
not for services implemented
buffers is orthogonal to
for services implemented using
the album acl and
is orthogonal to the
album acl and then
a synchronous writes when
orthogonal to the flow
intent to send with
services implemented using other
content through proprietary minibrowser
implemented using other technologies
retries indefinitely until the
through proprietary minibrowser interface
to the flow control
to send with a
and there is a
synchronous writes when bandwidth
there is a corresponding
acl and then adding
is a corresponding latency
and then adding unflattering
send with a sink
then adding unflattering pictures
writes when bandwidth is
with a sink that
developers of nontransactional web
a corresponding latency penalty
indefinitely until the file
the flow control mechanisms
until the file is
a sink that may
the file is available
she would define an
sink that may be
of nontransactional web services
when bandwidth is high
while many of these
flow control mechanisms used
many of these systems
would define an event
control mechanisms used within
zookeeper ensures that the
mechanisms used within tcp
of these systems make
judicious choice of the
that may be controlled
with a threshold controlling
choice of the parameters
these systems make do
nontransactional web services must
ensures that the latest
web services must implement
a threshold controlling switches
services must implement their
systems make do with
threshold controlling switches between
make do with weak
that the latest revision
controlling switches between the
of the parameters m
switches between the two
must implement their own
between the two modes
do with weak consistency
ip and impacts all
the latest revision number
based interface between transport
latest revision number is
may be controlled by
revision number is incremented
and impacts all variants
number is incremented atomically
interface between transport and
implement their own mechanisms
their utility is reduced
their own mechanisms for
utility is reduced when
the mode switch also
impacts all variants equally
between transport and information
zookeeper maintains a simple
the parameters m and
maintains a simple filesystem
is reduced when their
mode switch also changes
be controlled by a
switch also changes the
own mechanisms for replicating
parameters m and t
mechanisms for replicating data
reduced when their clients
m and t minimizes
controlled by a policy
and t minimizes the
a simple filesystem like
transport and information layers
simple filesystem like tree
also changes the semantics
filesystem like tree of
t minimizes the probability
like tree of nodes
by a policy limiting
tracking membership and live
changes the semantics of
membership and live this
minimizes the probability of
and live this work
when their clients observe
live this work was
their clients observe inconsistencies
nodes may store a
the probability of this
may store a small
probability of this occurrence
the semantics of the
this work was supported
a policy limiting the
work was supported by
fec fec encoders are
was supported by darpa
semantics of the file
the visual events delivered
of the file system
policy limiting the send
there has been a
limiting the send rate
has been a wave
store a small amount
been a wave of
ipto under the srs
a small amount of
under the srs program
a wave of recent
fec encoders are typically
wave of recent innovations
visual events delivered by
and the developers of
small amount of data
of recent innovations within
the developers of coda
recent innovations within the
the srs program and
amount of data and
srs program and by
encoders are typically parameterized
program and by the
developers of coda have
and by the rome
of data and can
by the rome air
when the sink is
the rome air force
are typically parameterized with
the sink is ready
of coda have noted
sink is ready to
events delivered by the
innovations within the backend
rome air force research
delivered by the transport
air force research laboratory
coda have noted that
by the transport could
typically parameterized with an
have noted that undetected
offering scalable object stores
is ready to send
the transport could then
data and can have
scalable object stores that
and can have children
methodology we have proposed
transport could then be
we have proposed the
noted that undetected mode
could then be delivered
it issues an upcall
that undetected mode changes
object stores that can
have proposed the use
stores that can efficiently
undetected mode changes can
then be delivered to
mode changes can surprise
under the prometheus program
be delivered to an
that can efficiently support
proposed the use of
traffic numbers are for
vn stores the latest
tuple for each outgoing
stores the latest revision
delivered to an information
additional support was provided
numbers are for synchronous
the use of lfs
changes can surprise the
use of lfs in
for each outgoing sequence
of lfs in lieu
can efficiently support transactions
each outgoing sequence of
efficiently support transactions through
are for synchronous writeback
outgoing sequence of r
can surprise the user
the latest revision number
surprise the user in
latest revision number in
support was provided by
app elements of the
was provided by the
elements of the protocol
provided by the nsf
of the protocol stack
the user in undesirable
the protocol stack f
sequence of r data
lfs in lieu of
of r data packets
in lieu of ffs
user in undesirable ways
to an information layer
support transactions through snapshot
an information layer responsible
transactions through snapshot isolation
information layer responsible for
through snapshot isolation and
a total of r
compiling mafs on top
or other conventional file
snapshot isolation and even
layer responsible for visualizing
mafs on top of
other conventional file systems
robbert van renesse ness
isolation and even full
o events according to
on top of mafs
responsible for visualizing them
events according to priorities
c data and error
and even full atomicity
according to priorities incoming
redirecting requests during failures
data and error correction
requests during failures to
to priorities incoming data
during failures to minimize
and error correction packets
failures to minimize client
priorities incoming data policy
to minimize client disruption
center scenarios to achieve
incoming data policy get
scenarios to achieve power
bandwidth is high enough
supporting multiple named repositories
error correction packets are
multiple named repositories in
to achieve power conservation
named repositories in a
data policy get messages
repositories in a single
and detecting and repairing
in a single zookeeper
detecting and repairing inconsistencies
a single zookeeper tree
policy get messages pre
is high enough to
such as cache inconsistencies
correction packets are sent
as cache inconsistencies arising
high enough to eliminate
for this idea to
cache inconsistencies arising due
before pushing a new
enough to eliminate differences
inconsistencies arising due to
our premise in this
this idea to be
premise in this paper
idea to be accepted
in this paper is
to eliminate differences between
arising due to unexpectedly
user mouse and keyboard
due to unexpectedly delayed
pushing a new revision
this paper is that
eliminate differences between writeback
o events process timer
packets are sent over
mouse and keyboard events
are sent over the
two questions need to
sent over the channel
differences between writeback schemes
events process timer events
to unexpectedly delayed writes
and keyboard events and
paper is that for
keyboard events and pass
end server must acquire
asynchronous writeback is clearly
questions need to be
events and pass them
need to be answered
writeback is clearly beneficial
and pass them down
server must acquire a
process timer events register
must acquire a lock
to be answered in
acquire a lock by
and priortwo questions are
is that for many
timer events register to
rather than relying on
events register to send
a lock by creating
than relying on a
lock by creating a
our challenge is to
relying on a modal
be answered in the
priortwo questions are of
on a modal adaptation
with this type of
by creating a sequence
this type of event
challenge is to improve
register to send app
is to improve transaction
questions are of particular
to send app app
a modal adaptation scheme
send app app f
creating a sequence node
answered in the affirmative
to improve transaction consistency
redundancy information cannot be
are of particular interest
that for many services
information cannot be generated
improve transaction consistency at
of particular interest in
modal adaptation scheme incorporating
cannot be generated and
transaction consistency at the
adaptation scheme incorporating a
consistency at the cache
either layer could easily
scheme incorporating a transition
particular interest in evaluating
layer could easily be
the transactional model is
be generated and sent
transactional model is a
interest in evaluating the
generated and sent until
could easily be replaced
and sent until all
incorporating a transition to
in evaluating the perfor
model is a poor
a transition to update
is a poor fit
sent until all r
does this new scheme
easily be replaced with
this new scheme result
ities are advantageous in
a poor fit and
are advantageous in reducing
until all r data
transition to update logging
all r data packets
new scheme result in
one can think of
poor fit and hence
advantageous in reducing contention
be replaced with a
to update logging when
at the cache layer
r data packets are
scheme result in significant
data packets are available
fit and hence that
in reducing contention between
replaced with a different
update logging when bandwidth
with a different one
logging when bandwidth is
packets are available for
and hence that tools
to which zookeeper will
even when the cache
can think of qsm
when the cache cannot
result in significant power
reducing contention between reading
hence that tools aimed
are available for sending
that tools aimed at
when bandwidth is low
the cache cannot access
think of qsm as
in significant power savings
contention between reading mance
which zookeeper will append
tools aimed at non
zookeeper will append a
of qsm as a
will append a unique
cache cannot access the
between reading mance of
mfs uses a modeless
reading mance of mafs
cannot access the backend
qsm as a collection
mance of mafs communication
transactional web services systems
access the backend on
web services systems will
the backend on each
monotonically increasing sequence number
services systems will be
of mafs communication adaptation
systems will be needed
the latency of packet
backend on each read
peer protocols would also
as a collection of
uses a modeless asynchronous
latency of packet recovery
which is not possible
a collection of protocol
of packet recovery is
protocols would also be
collection of protocol stacks
end server then lists
would also be encapsulated
of protocol stacks in
packet recovery is determined
is not possible when
protocol stacks in which
not possible when synchronous
we recognize that this
possible when synchronous writeback
also be encapsulated within
recognize that this is
does this new scheme
that this is debatable
today s consistency solutions
this new scheme provide
s consistency solutions are
a modeless asynchronous writeback
be encapsulated within their
modeless asynchronous writeback mechanism
server then lists the
when synchronous writeback is
stacks in which components
new scheme provide comparable
consistency solutions are limited
recovery is determined by
solutions are limited to
encapsulated within their respective
are limited to the
then lists the children
limited to the database
scheme provide comparable performance
synchronous writeback is used
is determined by the
vendors have generally argued
in which components act
have generally argued that
lists the children of
which components act as
generally argued that only
provide comparable performance to
determined by the rate
comparable performance to existing
which is active at
performance to existing schemes
components act as both
argued that only transactional
do priorities improve performance
within their respective transport
by the rate at
to the database backend
is active at all
act as both feeds
priorities improve performance by
that only transactional systems
improve performance by reducing
their respective transport layers
the rate at which
even when the database
active at all bandwidth
when the database itself
only transactional systems offer
the database itself is
as both feeds and
database itself is consistent
rate at which the
both feeds and as
performance by reducing rpc
transactional systems offer the
at all bandwidth levels
systems offer the hooks
the vast majority of
feeds and as sinks
by reducing rpc conthe
the answers to these
at which the sender
answers to these questions
vast majority of operations
reducing rpc conthe second
offer the hooks needed
just as with update
the hooks needed to
as with update logging
hooks needed to support
of opportunistic nodes figure
needed to support automated
majority of operations are
rpc conthe second microbenchmark
the overall structure is
conthe second microbenchmark evaluates
one version of a
overall structure is of
which the sender transmits
version of a transport
to these questions must
to support automated scalability
of a transport layer
of operations are read
structure is of a
a transport layer could
the sender transmits data
transport layer could fetch
these questions must be
second microbenchmark evaluates a
layer could fetch data
questions must be largely
minimum and average download
could fetch data directly
only transactions issued by
and average download factors
fetch data directly from
is of a forest
must be largely applicationindependent
of a forest of
generating error correction packets
microbenchmark evaluates a workload
transactions issued by edge
repair and restart mechanisms
issued by edge clients
data directly from a
by edge clients and
if its own lock
directly from a server
evaluates a workload that
its own lock node
from a server in
own lock node has
edge clients and are
lock node has the
clients and are at
error correction packets from
and are at high
average download factors across
are at high risk
when an application performs
key to this argument
an application performs an
and must apply to
a forest of trees
must apply to a
a workload that contention
correction packets from less
at high risk of
download factors across all
high risk of observing
a server in a
risk of observing inconsistent
node has the lowest
of observing inconsistent state
apply to a generic
observing inconsistent state in
tains explicit contention between
to a generic data
explicit contention between different
factors across all correct
a generic data center
server in a data
generic data center model
packets from less than
in a data center
to this argument is
contention between different types
application performs an operation
across all correct nodes
has the lowest number
all correct nodes when
from less than r
between different types of
this argument is the
o was to reduce
whereas a different version
inconsistent state in the
correct nodes when opportunistic
a different version might
nodes when opportunistic nodes
it may proceed with
to address these questions
may proceed with the
was to reduce staleness
proceed with the commit
different types of rpc
performs an operation that
to reduce staleness by
different version might use
when opportunistic nodes are
reduce staleness by postponing
version might use a
types of rpc traf
staleness by postponing the
an operation that changes
argument is the ease
by postponing the creation
state in the cache
is the ease with
less than r data
is it possible to
might use a peer
it possible to combine
operation that changes a
opportunistic nodes are present
that changes a file
the outright loss of
otherwise it watches the
outright loss of cache
we present a simulator
possible to combine the
than r data packets
postponing the creation of
the ease with which
r data packets at
to combine the benefit
ease with which interrupted
combine the benefit of
such as a write
with which interrupted transactions
it watches the node
loss of cache invalidations
the creation of control
watches the node with
the benefit of asynchronous
each curve corresponds to
the node with the
which interrupted transactions can
of cache invalidations emerges
interrupted transactions can be
cache invalidations emerges as
benefit of asynchronous write
as a write or
logsim consists of less
a write or metadata
node with the next
write or metadata update
creation of control messages
transactions can be rolled
invalidations emerges as an
can be rolled back
emerges as an especially
consists of less than
as an especially significant
with the next lower
of less than a
of control messages until
curve corresponds to a
data packets at the
an especially significant problem
a reliable multicast protocol
especially significant problem if
the next lower number
significant problem if transactional
corresponds to a different
next lower number in
packets at the sender
lower number in order
control messages until the
at the sender is
one process performs a
to a different contribution
process performs a grep
less than a thousand
performs a grep on
create directory and so
a grep on a
problem if transactional consistency
grep on a set
it could leverage different
and the relative simplicity
the sender is not
could leverage different type
than a thousand lines
sender is not a
leverage different type of
a thousand lines of
on a set of
a different contribution rate
a set of back
number in order to
different contribution rate used
directory and so on
in order to be
is not a viable
order to be notified
thousand lines of java
the relative simplicity of
set of back at
messages until the time
of back at low
contribution rate used by
until the time when
rate used by opportunistic
not a viable option
used by opportunistic nodes
lines of java code
a viable option even
back at low bandwidth
if transactional consistency is
at low bandwidth with
different type of hardware
the time when transmission
to be notified when
time when transmission is
of java code and
viable option even though
java code and is
low bandwidth with acceptable
option even though the
bandwidth with acceptable performance
be notified when that
even though the data
transactional consistency is required
the update is then
type of hardware or
update is then passed
relative simplicity of cleaning
is then passed to
when transmission is actually
then passed to the
though the data rate
passed to the writeback
of hardware or be
to the writeback subsystem
simplicity of cleaning up
an acceptable solution for
notified when that node
transmission is actually about
when that node and
the data rate in
that node and its
hardware or be optimized
node and its associated
acceptable solution for a
code and is a
solution for a consistent
with acceptable performance at
data rate in this
of cleaning up a
rate in this channel
cleaning up a database
or be optimized for
up a database after
and is a single
a database after a
acceptable performance at cached
which sends it to
and its associated lock
in this channel is
its associated lock go
be optimized for different
for a consistent cache
database after a crash
performance at cached files
sends it to the
is actually about to
it to the server
actually about to take
optimized for different types
about to take place
at cached files that
this channel is low
yet the transactional programming
to the server when
a consistent cache must
cached files that need
the server when there
files that need to
associated lock go away
server when there is
consistent cache must maintain
the transactional programming model
cache must maintain the
for different types of
when there is sufficient
different types of workloads
there is sufficient bandwidth
transactional programming model also
must maintain the performance
that need to be
programming model also brings
need to be validated
after comitting the revision
model also brings constraints
maintain the performance properties
to be validated before
the performance properties of
be validated before they
comitting the revision to
performance properties of the
we must turn off
the revision to s
asynchronous writeback therefore only
must turn off some
properties of the existing
writeback therefore only delays
of the existing caching
time information is more
also brings constraints and
information is more accurate
turn off some percentage
provided that the different
off some percentage of
therefore only delays updates
that the different versions
brings constraints and overheads
only delays updates when
the different versions of
some percentage of disks
and this makes qsm
validated before they can
different versions of the
the existing caching tier
percentage of disks in
delays updates when there
were this not the
this makes qsm more
this not the case
of disks in the
before they can be
updates when there is
versions of the transport
when there is foreground
disks in the storage
there is foreground traffic
in the storage system
the transactional model would
they can be opened
we need to maintain
transactional model would long
need to maintain the
model would long ago
to maintain the shielding
makes qsm more stable
of the transport layer
when bandwidth is high
would long ago have
the transport layer conform
avg upload factor min
maintain the shielding role
upload factor min upload
h a b c
transport layer conform to
a b c d
the shielding role of
there are two opposing
it releases its lock
long ago have become
releases its lock by
another process either writes
layer conform to the
the performance of asynchronous
conform to the same
shielding role of the
performance of asynchronous writeback
role of the cache
an unintended benefit is
of asynchronous writeback should
its lock by deleting
unintended benefit is that
lock by deleting the
factor min upload factor
the cache hit ratio
to the same standardized
cache hit ratio should
process either writes higher
hit ratio should be
either writes higher bandwidths
b c d x
benefit is that the
by deleting the lock
are two opposing forces
deleting the lock node
asynchronous writeback should be
the same standardized event
ratio should be high
c d x x
data to files rapidly
is that the pull
ago have become universal
two opposing forces at
lock nodes are marked
opposing forces at play
that the pull architecture
forces at play here
d x x e
the pull architecture slashes
writeback should be comparable
nodes are marked with
some of these constraints
only cache access should
are marked with zookeeper
cache access should complete
should be comparable to
a large number of
marked with zookeeper s
be comparable to purely
grepwe compare mafs to
access should complete with
compare mafs to alternative
x x e f
should complete with a
pull architecture slashes buffering
complete with a single
with zookeeper s ephemeral
with a single client
architecture slashes buffering and
mafs to alternative approaches
large number of powered
x e f g
comparable to purely synchronous
e f g h
of these constraints relate
f g h x
to alternative approaches in
these constraints relate to
the application could then
on disks results in
zookeeper s ephemeral flag
application could then switch
g h x x
alternative approaches in two
constraints relate to the
to purely synchronous writes
disks results in good
slashes buffering and memory
s ephemeral flag to
buffering and memory overheads
could then switch between
h x x a
approaches in two sets
relate to the challenges
results in good performance
trip on cache hits
ephemeral flag to ensure
then switch between them
flag to ensure that
in two sets of
but when bandwidth is
to the challenges of
x x a c
switch between them as
x a c b
to ensure that the
a c b e
when bandwidth is insufficient
c b e d
two sets of compile
b e d a
as we shall demonstrate
this prohibits coherent cache
ensure that the lock
the challenges of maintaining
between them as conditions
challenges of maintaining a
but also low power
of maintaining a clean
also low power savings
asynchronous writes will improve
turns out to have
that the lock is
prohibits coherent cache solutions
maintaining a clean separation
coherent cache solutions such
writes will improve the
out to have an
on the other hand
them as conditions demand
cache solutions such as
a clean separation of
one process reads files
will improve the performance
the lock is forcibly
improve the performance non
clean separation of code
process reads files at
to have an enormous
lock is forcibly released
g g x x
separation of code and
g x x f
of code and data
x x f h
is forcibly released if
reads files at the
decreasing the number of
have an enormous impact
the number of powered
files at the same
an enormous impact on
x f h x
enormous impact on performance
f h x x
a rchitecture since the
h x x b
rchitecture since the cache
forcibly released if the
since the cache is
at the same experiments
released if the front
not all applications can
on disks incurs two
an implementation without priorities
microbenchmarks to measure execution
disks incurs two possible
in qsm each element
implementation without priorities will
to measure execution time
the cache is required
measure execution time time
incurs two possible penalties
cache is required to
qsm each element of
without priorities will result
all applications can be
execution time time as
priorities will result in
applications can be structured
each element of a
will result in the
time time as another
element of a protocol
result in the completion
can be structured in
of a protocol stack
in the completion times
time as another is
a protocol stack acts
the completion times for
is required to respond
protocol stack acts as
required to respond immediately
as another is writing
stack acts as a
be structured in this
acts as a feed
structured in this manner
users interact through live
to respond immediately to
another is writing files
completion times for all
interact through live objects
times for all rpcs
respond immediately to the
zookeeper runs as a
as a feed that
runs as a replicated
through live objects that
as a replicated service
transactional rollback and restart
for all rpcs increasing
rollback and restart can
shows that priorispeedup for
all rpcs increasing uniformly
that priorispeedup for simple
a feed that has
live objects that transform
feed that has data
transitions consume power and
that has data to
priorispeedup for simple workloads
consume power and thus
so it remains available
power and thus counter
objects that transform actions
and thus counter the
has data to send
separate encoding for odd
and traces of actual
when priorities are used
encoding for odd and
immediately to the client
thus counter the potential
to the client on
and restart can be
the client on hits
it remains available as
for odd and even
that transform actions into
traces of actual windows
counter the potential savings
restart can be costly
remains available as long
or a sink that
available as long as
a backlog of low
of actual windows ties
transform actions into updates
the potential savings achieved
odd and even packets
potential savings achieved by
a sink that can
and even packets could
actual windows ties are
sink that can send
windows ties are beneficial
priority rpcs will accumulate
savings achieved by powered
as long as a
actions into updates that
long as a majority
even packets could be
into updates that are
that can send it
packets could be operating
and restarting a database
while the time taken
could be operating at
ties are beneficial for
the time taken for
are beneficial for the
cache channel is asynchronous
restarting a database after
updates that are communicated
a database after a
be operating at near
that are communicated in
time taken for high
as a majority of
to find the optimal
a majority of the
beneficial for the small
we decided to employ
for the small validation
operating at near full
decided to employ a
find the optimal percentage
to employ a transactional
majority of the hosts
the small validation rpcs
employ a transactional consistency
database after a crash
are communicated in the
after a crash incurs
priority rpcs to complete
communicated in the form
of the hosts are
at near full capacity
the hosts are up
the optimal percentage of
near full capacity with
small validation rpcs when
optimal percentage of disks
validation rpcs when the
in the form of
percentage of disks to
a crash incurs delays
the form of events
rpcs to complete will
full capacity with data
a transactional consistency that
rpcs when the backnt
capacity with data from
of disks to be
with data from other
disks to be powered
form of events that
to complete will increase
hosts are up and
when the backnt file
transactional consistency that is
and many play both
consistency that is weaker
crash incurs delays while
that is weaker than
data from other senders
is weaker than the
complete will increase more
are up and reachable
the backnt file system
many play both roles
to be powered down
incurs delays while cleanup
of events that are
delays while cleanup code
will increase more gradually
while cleanup code runs
events that are shared
a client only speaks
weaker than the full
that are shared via
than the full acid
fec is also very
the full acid model
client only speaks to
we ran a set
only speaks to one
the ntfs traces were
high availability is difficult
ntfs traces were gathered
are shared via the
availability is difficult to
our design is based
is difficult to acheive
ran a set of
difficult to acheive in
is also very susceptible
a set of simulations
also very susceptible to
design is based on
set of simulations on
to acheive in the
shared via the transport
speaks to one zookeeper
traces were gathered ground
very susceptible to bursty
only transactions and update
susceptible to bursty losses
transactions and update transactions
acheive in the transactional
and update transactions that
to one zookeeper server
update transactions that access
is based on the
of simulations on logsim
via the transport layer
in the transactional model
were gathered ground traffic
rather than creating a
one zookeeper server at
transactions that access the
based on the assumption
that access the same
simulations on logsim and
access the same cache
zookeeper server at a
the same cache are
the fastest database replication
same cache are guaranteed
on the assumption that
fastest database replication schemes
than creating a message
server at a time
the protocol implemented by
on logsim and varied
gathered ground traffic is
protocol implemented by the
logsim and varied the
creating a message and
implemented by the transport
and varied the number
a message and handing
cache are guaranteed an
ground traffic is heavy
message and handing it
though it may fail
and handing it down
varied the number of
with the sporadic background
are guaranteed an atomic
the sporadic background traffic
the assumption that when
by the transport layer
suffer from failure scenarios
handing it down to
from failure scenarios that
sporadic background traffic in
guaranteed an atomic execution
failure scenarios that can
over to another server
scenarios that can require
to another server if
it down to the
another server if necessary
assumption that when bandwidth
the transport layer might
that when bandwidth is
that can require intervention
when bandwidth is low
background traffic in the
can require intervention by
traffic in the cornell
the number of disks
require intervention by a
only transactions that access
intervention by a human
down to the sink
by a human operator
transport layer might replicate
number of disks that
of opportunistic nodes figure
layer might replicate the
in the cornell university
but the server ensures
an assignment of differentiated
transactions that access different
of disks that we
assignment of differentiated priorities
might replicate the event
the server ensures that
yet the higher fidelity
a feed registers the
the cornell university computer
that access different caches
feed registers the intent
access different caches may
of differentiated priorities will
server ensures that the
the higher fidelity schemes
minimum and average upload
ensures that the relevant
higher fidelity schemes require
and average upload factors
that the relevant state
different caches may observe
differentiated priorities will improve
caches may observe different
deliver it to the
disks that we kept
is a standard encoding
that we kept powered
fidelity schemes require expensive
a standard encoding technique
the relevant state has
cornell university computer science
may observe different orderings
relevant state has been
observe different orderings for
registers the intent to
we kept powered up
average upload factors across
kept powered up from
upload factors across all
university computer science department
priorities will improve the
it to the tablets
will improve the response
and of compiling mafs
the intent to send
schemes require expensive multi
intent to send a
powered up from none
improvements are confined to
factors across all correct
are confined to low
different orderings for independent
across all correct nodes
to the tablets of
all correct nodes when
to send a message
correct nodes when opportunistic
state has been replicated
phase commit protocols and
orderings for independent update
standard encoding technique used
the tablets of our
confined to low bandcontain
send a message with
nodes when opportunistic nodes
improve the response times
when opportunistic nodes are
has been replicated before
for independent update transactions
encoding technique used to
tablets of our rescue
technique used to combat
a message with the
commit protocols and hence
message with the sink
the response times for
been replicated before responding
to low bandcontain access
of our rescue workers
used to combat bursty
opportunistic nodes are present
protocols and hence may
response times for interactive
and hence may not
the message can be
hence may not give
message can be created
replicated before responding to
times for interactive tasks
and report it through
low bandcontain access to
may not give adequate
can be created at
not give adequate performance
before responding to a
to combat bursty loss
every partial execution that
bandcontain access to local
each curve corresponds to
be created at this
if a task which
report it through the
partial execution that includes
a task which predominantly
it through the event
responding to a client
task which predominantly performs
to a client s
curve corresponds to a
execution that includes all
corresponds to a different
access to local and
where error correction packets
a client s request
which predominantly performs reads
created at this time
that includes all update
predominantly performs reads executes
at this time and
to local and remote
error correction packets are
out of a total
based interface back to
in general multiple front
includes all update transactions
interface back to the
all update transactions in
local and remote file
update transactions in and
correction packets are generated
of a total of
clustered threetier database products
to a different contribution
performs reads executes in
a different contribution rate
and remote file systems
back to the information
transactions in and all
packets are generated from
end servers may be
threetier database products are
servers may be run
different contribution rate used
reads executes in parallel
remote file systems by
in and all read
file systems by clients
executes in parallel to
are generated from alternate
in parallel to a
database products are powerful
contribution rate used by
to the information layer
systems by clients in
this time and buffered
generated from alternate disjoint
time and buffered in
parallel to a task
and buffered in the
only transactions that go
buffered in the feed
by clients in a
the information layer at
each on its own
from alternate disjoint sub
on its own ec
to a task which
rate used by opportunistic
transactions that go through
used by opportunistic nodes
that go through a
products are powerful solutions
a task which performs
clients in a width
information layer at which
go through a single
but the creation may
in a width levels
task which performs many
the creation may also
insufficient to provide all
layer at which the
to provide all nodes
streams of data rather
at which the event
of data rather than
the system is organized
data rather than from
through a single cache
provide all nodes with
a single cache server
but they negotiate these
which the event has
creation may also be
the event has originated
rather than from consecutive
may also be postponed
all nodes with all
demonstrates that priorities can
nodes with all data
that priorities can imlocal
system is organized as
which performs many writes
our solution seeks to
they negotiate these potential
solution seeks to approximate
is organized as in
negotiate these potential pitfalls
also be postponed until
seeks to approximate cache
than from consecutive packets
be postponed until the
these potential pitfalls in
to approximate cache serializability
organized as in figure
approximate cache serializability with
the transport layer with
cache serializability with bounded
the extent of the
serializability with bounded caches
extent of the impact
transport layer with the
of the impact may
the first task will
the impact may be
postponed until the time
potential pitfalls in ways
with bounded caches and
layer with the embedded
bounded caches and asynchronous
first task will receive
caches and asynchronous communication
until the time when
and asynchronous communication with
impact may be surprising
the time when the
with the embedded distributed
time when the sink
priority read performance with
when the sink polls
read performance with only
with an interleave index
the sink polls the
pitfalls in ways that
sink polls the feed
task will receive a
polls the feed for
performance with only a
unlike the traditional replicated
an interleave index of
the embedded distributed protocol
in ways that preclude
asynchronous communication with the
will receive a higher
performance drops by as
with only a small
drops by as much
the traditional replicated subversion
by as much as
communication with the db
embedded distributed protocol would
the feed for messages
receive a higher share
feed for messages to
ways that preclude important
for messages to transmit
traditional replicated subversion setups
that preclude important classes
disks were kept powered
preclude important classes of
were kept powered up
only a small overhead
distributed protocol would behave
replicated subversion setups that
a higher share of
our idea starts with
important classes of applications
a small overhead for
presents the average and
small overhead for writes
the average and minimum
the sink determines its
higher share of the
idea starts with an
the encoder would create
protocol would behave very
subversion setups that are
average and minimum upload
sink determines its readiness
these microbenchmarks show that
starts with an observation
encoder would create correction
would behave very much
our motivation is to
behave very much like
and minimum upload factors
share of the bandwidth
determines its readiness to
microbenchmarks show that asynmicrobenchmarks
would create correction packets
show that asynmicrobenchmarks chronous
motivation is to show
create correction packets separately
minimum upload factors among
its readiness to send
setups that are used
objects form clusters with
that asynmicrobenchmarks chronous writeback
form clusters with strong
is to show that
correction packets separately from
upload factors among all
readiness to send based
that are used today
to send based on
many applications have patterns
asynmicrobenchmarks chronous writeback improves
to show that a
applications have patterns of
packets separately from three
very much like an
separately from three disjoint
send based on a
no single server acts
factors among all correct
show that a simple
have patterns of interactive
clusters with strong locality
that a simple and
patterns of interactive file
chronous writeback improves performance
based on a control
single server acts as
on a control policy
much like an object
with strong locality properties
from three disjoint sub
a simple and remarkably
of interactive file access
writeback improves performance even
among all correct nodes
interactive file access involving
like an object in
file access involving both
an object in smalltalk
server acts as a
transactions are likely to
acts as a master
improves performance even at
access involving both reads
performance even at comparaour
simple and remarkably inexpensive
involving both reads and
even at comparaour first
are likely to access
axis we vary the
both reads and writes
we vary the percentage
the first containing data
and remarkably inexpensive infrastructure
likely to access objects
at comparaour first microbenchmark
to access objects that
remarkably inexpensive infrastructure can
access objects that are
it would consume events
inexpensive infrastructure can support
comparaour first microbenchmark compiles
would consume events and
first microbenchmark compiles mafs
vn all are equivalent
consume events and respond
infrastructure can support clustered
events and respond with
microbenchmark compiles mafs from
can support clustered execution
vary the percentage of
support clustered execution of
the percentage of opportunistic
first containing data packets
percentage of opportunistic nodes
clustered execution of a
close to each other
and respond with events
performance of simultaneous checkouts
compiling source files involves
when the socket at
containing data packets numbered
execution of a significant
and on the y
source files involves interspersed
for retailers this might
files involves interspersed reads
retailers this might involve
this motivates thinking about
axis we present the
the socket at the
we present the upload
motivates thinking about communication
present the upload factors
socket at the root
the upload factors of
this might involve related
at the root of
might involve related products
mb of tively high
the root of the
of tively high bandwidths
involves interspersed reads and
of a significant class
interspersed reads and writes
for social networks the
a significant class of
social networks the set
upload factors of nodes
significant class of non
and priorities are effective
thinking about communication protocols
priorities are effective in
root of the tree
are effective in mitigating
which can vary up
about communication protocols as
effective in mitigating source
but does not issue
communication protocols as objects
networks the set of
can vary up to
the set of friends
of the tree is
does not issue concurrent
the tree is ready
in mitigating source code
tree is ready for
mitigating source code stored
not issue concurrent rpcs
for geographical services physical
is ready for transmission
and indeed in treating
the work reported here
issue concurrent rpcs frequently
geographical services physical proximity
source code stored in
indeed in treating them
code stored in an
work reported here focuses
stored in an mafs
in treating them as
in an mafs filesystem
reported here focuses on
and for web albums
messages will be recursively
treating them as objects
here focuses on services
it is interesting to
will be recursively pulled
is interesting to note
such an application will
interesting to note that
be recursively pulled from
to note that the
an application will have
note that the average
focuses on services that
that the average upload
recursively pulled from the
the average upload factor
them as objects much
average upload factor among
application will have improved
for web albums the
as objects much as
will have improved read
upload factor among correct
pulled from the tree
mb contention between different
on services that don
objects much as we
services that don t
have improved read performance
much as we treat
contention between different classes
improved read performance when
between different classes of
web albums the acl
different classes of rpcs
read performance when there
albums the acl objects
as we treat any
the acl objects and
from the tree of
factor among correct nodes
performance when there is
that don t fit
acl objects and the
performance of simultaneous commits
objects and the pictures
the tree of protocol
of simultaneous commits source
when there is contention
simultaneous commits source code
don t fit the
commits source code from
t fit the transactional
among correct nodes initially
tree of protocol stack
we treat any other
of protocol stack components
of output in the
and the pictures assigned
treat any other kind
the pictures assigned to
correct nodes initially increases
pictures assigned to them
any other kind of
source code from an
fit the transactional paradigm
code from an ec
output in the same
and then starts falling
there is contention with
then starts falling when
the second with data
starts falling when the
is contention with other
falling when the percentage
in the same filesystem
when the percentage of
other kind of object
contention with other applications
in some cases applications
kind of object in
some cases applications explicitly
second with data packets
of object in a
typically for reasons of
cases applications explicitly cluster
compares the execution time
for reasons of performance
applications explicitly cluster their
object in a language
the percentage of opportunistic
but will correspondingly be
percentage of opportunistic nodes
with data packets numbered
of opportunistic nodes increases
feeds that no longer
in a language like
the execution time speedup
explicitly cluster their data
execution time speedup for
opportunistic nodes increases significantly
time speedup for the
a language like java
speedup for the benchmark
will correspondingly be penalised
ones that operate directly
correspondingly be penalised on
that operate directly on
be penalised on writes
operate directly on in
and varying the number
cluster their data accesses
that no longer have
for the benchmark under
language like java or
the benchmark under differing
varying the number of
like java or in
no longer have data
this does not match
benchmark under differing asynchronous
their data accesses to
does not match our
this behavior can be
java or in a
memory data structures or
or in a runtime
under differing asynchronous writeback
the number of servers
differing asynchronous writeback and
not match our design
behavior can be explained
longer have data to
data structures or simple
have data to send
structures or simple non
asynchronous writeback and priority
number of servers over
match our design goal
can be explained by
in a runtime environment
data accesses to benefit
data to send are
writeback and priority schemes
of servers over which
our design goal of
be explained by the
a runtime environment like
accesses to benefit from
to send are automatically
cdf number of accesses
design goal of having
explained by the fact
as bandwidth is var
by the fact that
runtime environment like jini
servers over which the
send are automatically deregistered
to simplify our task
over which the load
to benefit from improved
environment like jini or
we evaluated mafs at
benefit from improved parallelism
which the load was
goal of having interactive
correct nodes start contributing
evaluated mafs at a
the load was distributed
nodes start contributing more
we assume that these
start contributing more to
mafs at a larger
assume that these services
contributing more to compensate
at a larger scale
that these services are
more to compensate for
a larger scale using
these services are capable
larger scale using the
to compensate for the
scale using the ntfs
services are capable of
compensate for the lack
the resulting transactions access
doing so unifies apparently
resulting transactions access objects
are capable of handling
derived the dominant feature
read applications obtain a
the dominant feature of
so unifies apparently distinct
applications obtain a larger
for the lack of
capable of handling outof
dominant feature of figure
sharing and priority i
transactions access objects from
obtain a larger share
unifies apparently distinct approaches
a larger share of
is that asynchronous write
write performance was measured
access objects from a
the lack of data
objects from a single
lack of data provided
from a single cluster
larger share of bandwidth
performance was measured by
traces summarised in table
of data provided by
was measured by observing
data provided by a
although there will also
just as a remotely
there will also be
measured by observing the
will also be some
and that processes implementing
also be some frequency
by observing the latency
be some frequency of
although the original execution
observing the latency of
the original execution back
that processes implementing them
we have implemented two
some frequency of transactions
provided by a small
have implemented two solutions
by a small percentage
original execution back is
a small percentage of
execution back is beneficial
small percentage of opportunistic
and the third with
and prone to oscillatory
the third with data
the latency of simultaneous
third with data packets
frequency of transactions that
latency of simultaneous commits
back is beneficial at
percentage of opportunistic nodes
of simultaneous commits from
prone to oscillatory throughput
processes implementing them experience
to oscillatory throughput when
with data packets numbered
of transactions that access
is beneficial at all
transactions that access unrelated
simultaneous commits from different
as a remotely hosted
commits from different clients
oscillatory throughput when scaled
implemented two solutions to
a remotely hosted form
that access unrelated objects
once the effect of
access unrelated objects in
remotely hosted form of
unrelated objects in different
two solutions to this
hosted form of content
the effect of opportunistic
throughput when scaled up
beneficial at all bandwidths
objects in different clusters
at all bandwidths until
solutions to this problem
since simultaneous commits to
effect of opportunistic nodes
form of content such
simultaneous commits to a
our solution requires minor
implementing them experience only
of content such as
when we decided to
them experience only crash
content such as a
solution requires minor changes
commits to a single
requires minor changes to
of opportunistic nodes becomes
we decided to take
opportunistic nodes becomes significant
such as a map
experience only crash failures
there is less times
minor changes to the
is less times of
based on making writes
decided to take control
as a map or
to take control over
changes to the database
a map or an
take control over event
as will be shown
to a single repository
will be shown below
to the database object
a single repository would
on making writes asynchronous
control over event processing
map or an image
over event processing order
less times of these
the database object representation
times of these traces
database object representation format
of these traces were
single repository would not
the system collapses and
our assumptions hold for
or an image of
these traces were short
repository would not be
an image of a
assumptions hold for a
imposing a small and
hold for a very
traces were short on
system collapses and correct
were short on windows
image of a raincloud
we also eliminated multithreading
a small and constant
of a raincloud can
small and constant memory
would not be a
collapses and correct nodes
short on windows nt
and correct nodes are
and constant memory overhead
correct nodes are not
not be a typical
used in several existing
be a typical case
a raincloud can be
in several existing systems
for a very large
they execute improvement at
nodes are not able
a very large group
independent of the database
several existing systems and
of the database size
raincloud can be modeled
existing systems and incorporated
very large group of
the database size and
grained scheduling eliminated convoy
are not able to
can be modeled as
systems and incorporated in
be modeled as an
database size and the
and incorporated in mfs
size and the transaction
scheduling eliminated convoy behavior
and the transaction rate
modeled as an object
large group of applications
incorporated in mfs for
not able to keep
where throughput is so
eliminated convoy behavior and
in mfs for the
able to keep contributing
throughput is so low
this overhead involves tracking
mfs for the purposes
overhead involves tracking and
convoy behavior and oscillatory
is so low that
so can network protocols
behavior and oscillatory throughput
for the purposes of
involves tracking and caching
another important point to
the purposes of comparison
the ssa was built
can network protocols be
ssa was built using
so low that con
tracking and caching what
important point to note
and caching what we
point to note is
caching what we refer
was built using epidemic
what we refer to
slowly on mafs due
to note is that
on mafs due to
and oscillatory throughput of
we refer to as
network protocols be treated
note is that the
vn repositories were used
mafs due to high
interleaving adds burst tolerance
refer to as dependency
oscillatory throughput of the
protocols be treated as
is that the minimum
throughput of the sort
that the minimum upload
to as dependency lists
all sharing the same
of the sort that
be treated as objects
due to high bandwidth
the sort that can
to high bandwidth requirements
communication protocols in conjunction
sort that can disrupt
sharing the same set
the minimum upload factor
that can disrupt reliable
minimum upload factor does
protocols in conjunction with
can disrupt reliable multicast
which is new to
in conjunction with a
disrupt reliable multicast systems
adds burst tolerance to
conjunction with a novel
length lists of object
the same set of
lists of object identifiers
is new to mfs
same set of front
reliable multicast systems when
burst tolerance to fec
with a novel variant
trol traffic and the
tolerance to fec but
a novel variant of
upload factor does not
multicast systems when they
end servers and same
traffic and the delay
systems when they run
and the delay in
an alternative approach is
when they run at
novel variant of the
they run at high
of object identifiers and
servers and same set
to fec but exacerbates
the delay in fetching
factor does not follow
delay in fetching files
does not follow a
p systems try to
run at high data
object identifiers and the
systems try to make
at high data rates
fec but exacerbates its
high data rates on
variant of the chain
but exacerbates its sensitivity
and same set of
of the chain replication
exacerbates its sensitivity to
try to make everything
in fetching files become
data rates on a
not follow a clearly
identifiers and the associated
follow a clearly defined
alternative approach is to
same set of three
approach is to retain
its sensitivity to sending
is to retain synchronous
fetching files become dominating
sensitivity to sending rate
files become dominating figure
and the associated version
the chain replication scheme
set of three zookeeper
chain replication scheme which
rates on a large
to retain synchronous writes
on a large scale
the associated version numbers
to sending rate with
to make everything a
sending rate with an
replication scheme which has
rate with an interleave
each representing some recently
of three zookeeper servers
representing some recently updated
make everything a p
but assign priorities according
scheme which has evolved
with an interleave index
shows execution times under
some recently updated objects
a clearly defined pattern
recently updated objects upon
which has evolved from
an interleave index of
execution times under four
interleave index of i
times under four combinations
updated objects upon which
under four combinations of
objects upon which the
assign priorities according to
each client checked out
index of i and
the last aspect relates
of i and an
has evolved from the
i and an encoding
upon which the cached
evolved from the mechanism
which the cached object
but in the examples
making it hard to
last aspect relates to
it hard to estimate
and an encoding rate
hard to estimate the
an encoding rate of
the cached object depends
from the mechanism first
in the examples we
the mechanism first proposed
aspect relates to the
mechanism first proposed in
client checked out a
to estimate the minimum
four combinations of writeback
the examples we ve
sized list can omit
priorities according to some
list can omit dependency
estimate the minimum contribution
can omit dependency information
relates to the creation
examples we ve seen
to the creation of
combinations of writeback scheme
according to some notion
of writeback scheme and
omit dependency information required
to some notion of
dependency information required to
the minimum contribution of
some notion of relative
checked out a random
the creation of new
the sender would have
several kinds of content
sender would have to
notion of relative importance
would have to wait
out a random repository
of relative importance of
creation of new messages
relative importance of processes
minimum contribution of correct
kinds of content would
information required to detect
have to wait for
required to detect inconsistencies
a random repository from
effect of increasing percentage
contribution of correct nodes
of increasing percentage of
random repository from a
increasing percentage of powered
of content would more
particularly by qsm itself
content would more naturally
of correct nodes under
to wait for i
up disks on performance
repository from a random
writeback scheme and priorities
from a random front
existing operating systems and
correct nodes under compromised
gossip based infrastructures are
nodes under compromised scenarios
would more naturally be
based infrastructures are beneficial
hence it is important
readers who have implemented
it is important to
more naturally be hosted
is important to use
infrastructures are beneficial because
effect of increasing percentage
operating systems and applications
important to use a
who have implemented multicast
to use a bound
are beneficial because they
use a bound large
have implemented multicast protocols
a bound large enough
of increasing percentage of
systems and applications generally
implemented multicast protocols will
beneficial because they are
and applications generally do
bound large enough to
increasing percentage of powered
applications generally do not
by applying thresholds to
multicast protocols will know
large enough to capture
and then repeatedly committed
generally do not provide
then repeatedly committed small
simple to implement rapidly
enough to capture most
repeatedly committed small amounts
to implement rapidly self
applying thresholds to punish
packets before sending any
thresholds to punish opportunistic
do not provide this
to punish opportunistic nodes
up disks on power
not provide this information
disks on power consumption
protocols will know that
before sending any redundancy
to capture most of
committed small amounts of
correct nodes may also
d images of terrain
nodes may also be
sending any redundancy information
may also be unfairly
stabilizing after disruptions analytically
so we have not
small amounts of data
we have not investigated
images of terrain and
have not investigated it
also be unfairly penalized
of terrain and buildings
will know that most
after disruptions analytically appealing
capture most of the
these two obstacles to
on power consumption both
not investigated it further
know that most existing
changes were propgated in
most of the relevant
disruptions analytically appealing this
two obstacles to using
power consumption both its
that most existing systems
of the relevant dependencies
were propgated in the
obstacles to using fec
the cache manager s
to using fec in
most existing systems are
cache manager s writeback
at present we lack
existing systems are push
present we lack an
using fec in time
we lack an automated
auditing protocol our idea
lack an automated way
propgated in the background
manager s writeback thread
in the background to
analytically appealing this paper
the background to the
protocol our idea for
consumption both its performance
our idea for auditing
an automated way to
idea for auditing the
automated way to do
s writeback thread divides
sensitive settings rate sensitivity
as well as its
background to the other
settings rate sensitivity and
on the other hand
way to do this
appealing this paper reports
writeback thread divides updates
well as its power
some layer initiates a
for auditing the described
to the other front
rate sensitivity and burst
this paper reports on
thread divides updates into
we require the developer
layer initiates a new
require the developer to
the former is measured
initiates a new message
former is measured using
divides updates into metadata
auditing the described live
soc applications are likely
sensitivity and burst susceptibility
the developer to tune
paper reports on the
a new message at
is measured using the
streaming system against opportunistic
measured using the observed
and burst susceptibility are
developer to tune the
reports on the architecture
to tune the length
updates into metadata operations
tune the length so
applications are likely to
system against opportunistic behavior
using the observed access
are likely to embody
against opportunistic behavior is
new message at will
opportunistic behavior is motivated
burst susceptibility are interlinked
behavior is motivated by
on the architecture and
is motivated by the
likely to embody quite
shows that adding front
susceptibility are interlinked through
to embody quite a
are interlinked through the
motivated by the graphs
and lower layers then
by the graphs presented
such as directory modifications
the graphs presented in
embody quite a range
the observed access latencies
interlinked through the tuning
the architecture and performance
through the tuning knobs
the length so that
architecture and performance of
length so that the
graphs presented in the
while the latter is
quite a range of
as directory modifications and
a range of p
and performance of the
so that the frequency
lower layers then buffer
that the frequency of
presented in the previous
the frequency of errors
layers then buffer that
frequency of errors is
performance of the platform
the latter is measured
end servers can indeed
latter is measured by
an interleave of i
servers can indeed alleviate
of errors is reduced
then buffer that message
in the previous section
is measured by comparing
directory modifications and file
measured by comparing the
can indeed alleviate latency
modifications and file status
each separate video object
and file status changes
and explores the limitations
we propose to employ
errors is reduced to
explores the limitations of
indeed alleviate latency problems
interleave of i and
by comparing the cumulative
of i and a
propose to employ auditing
i and a rate
the limitations of its
alleviate latency problems caused
limitations of its underlying
comparing the cumulative percentage
is reduced to an
to employ auditing to
reduced to an acceptable
buffer that message until
employ auditing to ensure
latency problems caused by
the cumulative percentage of
and a rate of
cumulative percentage of time
of its underlying techniques
that message until it
the two types of
auditing to ensure that
problems caused by high
two types of operations
percentage of time the
message until it can
to an acceptable level
until it can be
caused by high load
it can be sent
types of operations are
to ensure that all
reasoning about the trade
of operations are queued
ensure that all nodes
may have its own
operations are queued and
that all nodes in
provides tolerance to a
are queued and replayed
and that the overhead
tolerance to a burst
all nodes in the
to a burst of
nodes in the system
have its own associated
in the system contribute
queued and replayed to
the system contribute more
that the overhead of
system contribute more than
a burst of up
contribute more than a
its own associated update
the experiments are designed
in a manner we
and replayed to the
of time the disks
experiments are designed to
time the disks are
burst of up to
the disks are kept
own associated update stream
are designed to help
this makes sense under
replayed to the server
the overhead of propagating
to the server separately
of up to c
overhead of propagating data
a manner we discuss
designed to help us
of propagating data in
more than a particular
if one thinks of
propagating data in the
to help us fully
one thinks of these
disks are kept powered
than a particular specified
up to c i
a particular specified threshold
makes sense under the
data in the backgound
help us fully understand
are kept powered on
so that a metadata
manner we discuss further
to c i consecutive
we discuss further below
sense under the assumption
c i consecutive packets
us fully understand the
under the assumption that
in the backgound is
the assumption that senders
as well as the
that a metadata rpc
thinks of these as
we illustrate the potential
the backgound is not
illustrate the potential benefit
well as the number
backgound is not significant
as the number of
dependency lists should be
the number of mode
assumption that senders often
fully understand the fundamental
the potential benefit from
a metadata rpc can
potential benefit from using
understand the fundamental properties
metadata rpc can proceed
the burst tolerance of
that senders often generate
is not significant enough
of these as topics
not significant enough to
lists should be roughly
rpc can proceed in
should be roughly the
the fundamental properties of
be roughly the same
burst tolerance of an
roughly the same size
benefit from using auditing
the same size as
significant enough to negatively
can proceed in parallel
enough to negatively affect
tolerance of an fec
fundamental properties of a
to negatively affect performance
from using auditing in
same size as the
properties of a single
size as the size
of an fec code
these as topics in
an fec code can
senders often generate bursts
fec code can be
as the size of
of a single partitioned
show the results of
using auditing in a
the results of these
as topics in publish
results of these simulations
proceed in parallel with
code can be changed
r elated w orks
a single partitioned replicated
auditing in a system
often generate bursts of
single partitioned replicated service
in parallel with a
can be changed by
partitioned replicated service and
in a system where
the size of the
replicated service and thus
size of the workload
elated w orks moving
service and thus gain
generate bursts of packets
of the disks powered
parallel with a file
the disks powered on
w orks moving services
an application could have
orks moving services to
of the workload s
be changed by modulating
the workload s clusters
with a file writeback
changed by modulating either
application could have many
by modulating either the
and thus gain a
modulating either the c
moving services to the
thus gain a firm
of the nodes are
services to the cloud
gain a firm grasp
could have many such
our extensions offer a
the nodes are correct
either the c or
nodes are correct and
the communication subsystem can
when an rpc from
a firm grasp on
an rpc from a
extensions offer a transactional
to the cloud has
offer a transactional interface
of the disks can
the cloud has been
have many such topics
firm grasp on the
rpc from a particular
the c or the
a transactional interface to
communication subsystem can smooth
the disks can be
cloud has been published
subsystem can smooth the
from a particular queue
c or the i
the latter do not
disks can be spun
latter do not upload
has been published on
can smooth the traffic
been published on in
a particular queue completes
published on in other
and the application instance
grasp on the behavior
can be spun down
do not upload any
on the behavior of
not upload any data
on in other contexts
smooth the traffic flow
transactional interface to the
be spun down while
the traffic flow and
spun down while still
the application instance running
down while still maintaining
we say that the
while still maintaining performance
application instance running on
say that the update
interface to the cache
instance running on a
to the cache in
still maintaining performance comparable
the cache in addition
running on a given
cache in addition to
the behavior of the
on a given user
or the i parameters
maintaining performance comparable to
that the update has
performance comparable to that
traffic flow and keep
the update has been
a given user s
update has been committed
comparable to that of
behavior of the ssa
increasing c enhances burst
in addition to the
no punishment was applied
addition to the standard
has been committed at
to that of a
flow and keep the
is a backup application
of the ssa s
a backup application that
given user s machine
backup application that implements
to the standard read
user s machine could
that of a conventional
and keep the network
c enhances burst tolerance
the ssa s building
enhances burst tolerance at
been committed at the
burst tolerance at the
of a conventional file
s machine could simultaneously
keep the network interface
punishment was applied in
ssa s building blocks
was applied in an
committed at the server
applied in an attempt
a conventional file system
in an attempt to
the network interface busy
an attempt to simulate
our algorithm detects and
attempt to simulate a
algorithm detects and fixes
application that implements a
tolerance at the cost
the performance of our
machine could simultaneously display
at the cost of
the next update is
to simulate a system
performance of our system
simulate a system with
of our system depends
a system with no
our system depends very
could simultaneously display data
next update is then
detects and fixes inconsistent
we defer for future
one consequence is that
that implements a custom
defer for future work
consequence is that messages
system depends very heavily
simultaneously display data from
update is then dequeued
and fixes inconsistent read
system with no auditing
the cost of network
implements a custom block
cost of network and
depends very heavily on
of network and encoding
only transactions at the
display data from several
is then dequeued and
for future work the
is that messages can
based file system to
future work the full
that messages can linger
file system to store
very heavily on its
messages can linger for
heavily on its cache
network and encoding overhead
on its cache configuration
transactions at the cache
system to store multiple
at the cache with
data from several topics
to store multiple versions
work the full scale
the cache with constant
since cache optimization is
can linger for a
cache optimization is an
cache with constant complexity
linger for a while
the full scale evaluation
for a while before
optimization is an orthogonal
full scale evaluation of
auditing is enabled and
we have previously said
scale evaluation of multiple
store multiple versions of
have previously said that
evaluation of multiple services
multiple versions of backup
update logging an asynchronous
versions of backup data
is enabled and opportunistic
logging an asynchronous rpc
enabled and opportunistic nodes
it does so by
of multiple services deployed
previously said that we
a while before they
is an orthogonal issue
of backup data on
an orthogonal issue that
an asynchronous rpc for
and opportunistic nodes start
does so by either
multiple services deployed and
so by either aborting
said that we d
services deployed and running
potentially worsening the packet
deployed and running at
worsening the packet loss
asynchronous rpc for it
the packet loss experienced
by either aborting the
while before they are
that we d like
before they are sent
orthogonal issue that comprises
and running at the
issue that comprises an
rpc for it is
that comprises an entire
packet loss experienced and
for it is initiated
loss experienced and reducing
opportunistic nodes start to
experienced and reducing throughput
either aborting the transaction
comprises an entire field
backup data on s
we d like to
running at the same
nodes start to be
not only does this
start to be expelled
d like to think
to be expelled from
at the same time
be expelled from the
an entire field of
expelled from the system
entire field of research
which can then be
field of research in
like to think of
only does this increase
to think of protocols
from the system for
the authors make the
the system for low
of research in itself
system for low contribution
does this increase memory
increasing i trades off
this increase memory consumption
can then be retried
authors make the distinction
the ssa currently runs
make the distinction between
think of protocols as
the distinction between thin
it is important to
of protocols as objects
is important to isolate
the minimum upload factor
important to isolate its
separating the small update
or invalidating a cached
i trades off recovery
invalidating a cached object
but if a message
a cached object which
minimum upload factor for
ssa currently runs on
upload factor for nodes
elapsed time for all
currently runs on a
trades off recovery latency
to isolate its effect
cached object which can
isolate its effect on
the small update logging
factor for nodes to
clouds that provide a
for nodes to stay
time for all fetch
nodes to stay in
off recovery latency for
to stay in the
object which can then
stay in the system
which can then force
that provide a low
runs on a tightly
for all fetch rpcs
if a message contains
its effect on performance
recovery latency for better
it now becomes clear
latency for better burst
in the system was
level api and thick
for better burst tolerance
a message contains current
which is implemented in
message contains current state
can then force a
the system was set
then force a read
on a tightly coupled
force a read from
now becomes clear that
a read from the
contains current state information
becomes clear that further
system was set to
we implemented an ideal
a tightly coupled cluster
is implemented in some
tightly coupled cluster of
read from the database
better burst tolerance without
clear that further precision
implemented an ideal cache
clouds that are designed
implemented in some mobile
mostly writes mostly reads
in some mobile file
writes mostly reads trace
that state may be
some mobile file sys
that further precision is
an ideal cache algorithm
that are designed for
further precision is needed
coupled cluster of blade
mostly reads trace mixed
cluster of blade servers
state may be stale
similar to handling cache
metadata rpcs from file
to handling cache misses
which we term the
rpcs from file writes
may be stale by
burst tolerance without adding
be stale by the
are designed for a
stale by the time
we show that developers
by the time it
mostly writes mostly reads
when the dependency lists
we term the oracle
the dependency lists fail
designed for a specific
the objects aren t
the time it s
objects aren t merely
time it s sent
writes mostly reads trace
from file writes allows
dependency lists fail to
for a specific application
tolerance without adding overhead
this data point represents
show that developers can
data point represents the
mostly reads trace mixed
file writes allows remote
lists fail to document
without adding overhead as
fail to document a
aren t merely protocols
adding overhead as mentioned
point represents the best
that developers can tune
represents the best performance
to document a necessary
thick clouds for a
mostly writes mostly reads
in contrast to this
writes mostly reads trace
writes allows remote clients
contrast to this usual
but in fact are
for higher values of
clouds for a variety
higher values of i
developers can tune parameters
the best performance we
allows remote clients to
can tune parameters to
to this usual approach
in fact are individual
mostly reads trace mixed
for a variety of
best performance we could
document a necessary dependency
the encoder has to
tune parameters to trade
fact are individual protocol
reads trace mixed figure
a variety of purposes
are individual protocol instances
performance we could achieve
encoder has to wait
we could achieve since
qsm implements a pull
could achieve since an
remote clients to see
achieve since an oracle
has to wait for
since an oracle has
including backup and source
an oracle has future
clients to see statems
our system will need
implements a pull architecture
without auditing with auditing
system will need to
parameters to trade overhead
backup and source code
oracle has future knowledge
to trade overhead for
has future knowledge and
trace duration for asynchronous
future knowledge and is
an application might be
knowledge and is able
application might be exposed
trade overhead for speed
will need to simultaneously
duration for asynchronous writes
and source code repository
need to simultaneously support
and is able to
might be exposed to
evaluation evaluation of qsm
to simultaneously support potentially
to wait for more
source code repository hosting
is able to replace
overhead for speed of
able to replace items
for asynchronous writes is
evaluation of qsm could
simultaneously support potentially large
of qsm could pursue
be exposed to stale
to replace items accessed
exposed to stale values
asynchronous writes is until
wait for more data
support potentially large numbers
qsm could pursue many
for speed of repair
because we have in
writes is until completion
speed of repair and
is until completion of
potentially large numbers of
could pursue many directions
replace items accessed furthest
we have in mind
items accessed furthest in
have in mind client
until completion of the
of repair and we
large numbers of transport
for more data packets
with sourceforge and google
side applications that are
more data packets to
costs of the domain
numbers of transport objects
data packets to be
completion of the last
applications that are unlikely
of the last read
sourceforge and google code
of the domain crossing
accessed furthest in the
of transport objects running
furthest in the future
packets to be transmitted
that are unlikely to
server is beneficial in
and google code being
is beneficial in the
transport objects running concurrently
the domain crossing between
to be transmitted before
are unlikely to validate
repair and we believe
beneficial in the mostly
google code being examples
in the mostly writes
domain crossing between the
unlikely to validate against
be transmitted before it
and we believe that
transmitted before it can
the mostly writes trace
code being examples of
crossing between the application
being examples of the
we also wish to
we believe that our
also wish to provide
before it can send
wish to provide a
objects running concurrently in
between the application and
examples of the latter
the application and qsm
tus changes to files
believe that our results
it can send error
that our results validate
can send error correction
which has high readwrite
to validate against the
has high readwrite contention
validate against the back
protocol design and scalability
download factor of correct
send error correction packets
factor of correct nodes
the authors of cumulus
of correct nodes during
running concurrently in the
our results validate the
concurrently in the end
to provide a performance
results validate the approach
for many of our
provide a performance comparison
changes to files without
a performance comparison of
and interactions between protocol
to files without having
many of our intended
interactions between protocol properties
files without having to
authors of cumulus and
correct nodes during a
performance comparison of our
of our intended uses
once the fec encoding
our intended uses some
of cumulus and we
intended uses some level
the fec encoding is
uses some level of
it is less effective
some level of undetected
fec encoding is parameterized
level of undetected inconsistency
cumulus and we show
of undetected inconsistency can
is less effective than
and we show that
less effective than synchronous
without having to wait
application model our work
comparison of our system
encoding is parameterized with
model our work focuses
undetected inconsistency can slip
is parameterized with a
second streaming session with
effective than synchronous writeback
parameterized with a rate
of our system against
between protocol properties and
in support of a
protocol properties and the
due to increased contention
our work focuses on
having to wait for
with a rate and
our system against conventional
inconsistency can slip past
a rate and an
properties and the managed
support of a variety
and the managed framework
to wait for intervening
but this effect is
we show that thin
rate and an interleave
work focuses on datacenters
because the developer would
this effect is mitigated
the developer would often
effect is mitigated by
developer would often be
is mitigated by using
focuses on datacenters supporting
of a variety of
cloud solutions can be
and an interleave to
solutions can be a
here we focus on
can be a cost
would often be able
mitigated by using priorities
often be able to
on datacenters supporting one
a variety of applications
as an approximation of
an interleave to tolerate
this is clearer in
wait for intervening writequirement
is clearer in the
auditing is enabled in
clearer in the graph
datacenters supporting one or
in the graph for
an approximation of such
the graph for time
supporting one or more
for intervening writequirement that
be able to tune
is enabled in the
intervening writequirement that processes
enabled in the last
approximation of such a
writequirement that processes wait
of such a system
one or more services
able to tune the
variety of applications and
we focus on the
we implemented a random
of applications and uses
graph for time spent
that processes wait for
to tune the mechanism
or more services deployed
interleave to tolerate a
another example of moving
to tolerate a certain
implemented a random placement
example of moving a
a random placement algorithm
more services deployed within
of moving a service
for time spent on
state operation of large
time spent on fetch
all of this leads
we present the minimum
focus on the latter
services deployed within a
tolerate a certain burst
deployed within a cluster
operation of large applications
spent on fetch rpcs
which maps each block
processes wait for writes
of this leads to
moving a service to
a certain burst length
a service to the
certain burst length b
maps each block to
the rate of unnoticed
each block to a
this leads to new
rather than sending an
leads to new challenges
than sending an back
service to the cloud
sending an back traffic
rate of unnoticed inconsistencies
block to a random
of unnoticed inconsistencies could
to a random disk
average and maximum download
at the timescales in
to the cloud is
our goal is to
the cloud is metacdn
unnoticed inconsistencies could be
and maximum download factors
inconsistencies could be extremely
the timescales in the
the obvious one was
timescales in the ntfs
all disks are kept
in the ntfs traces
obvious one was mentioned
could be extremely low
within a cluster of
maximum download factors across
a cluster of compute
disks are kept powered
a similar motivation underlies
one was mentioned earlier
goal is to arrive
download factors across correct
the improvements are less
factors across correct nodes
improvements are less dramatic
with clustered workloads we
are less dramatic than
clustered workloads we will
less dramatic than in
are kept powered up
dramatic than in the
across correct nodes varying
than in the microbenchmarks
today s web services
workloads we will demonstrate
similar motivation underlies the
we will demonstrate that
is to arrive at
will demonstrate that it
s web services don
demonstrate that it is
cluster of compute nodes
that it is sufficient
motivation underlies the cache
it is sufficient to
a content distribution network
is sufficient to store
underlies the cache consisupdate
sufficient to store a
but they demonstrate that
to store a small
web services don t
having set the context
to arrive at a
services don t support
they demonstrate that mafs
store a small set
demonstrate that mafs can
the cache consisupdate to
let us examine fig
don t support p
correct nodes varying along
a small set of
that mafs can improve
small set of dependencies
the work evaluates the
set of dependencies to
arrive at a deep
of dependencies to detect
cache consisupdate to the
mafs can improve the
dependencies to detect most
can improve the performance
to detect most inconsistencies
improve the performance of
consisupdate to the server
the performance of large
at a deep understanding
tailer might implement a
work evaluates the latency
to tolerate a burst
a deep understanding of
tolerate a burst of
evaluates the latency of
we also investigate workloads
contemporary web services solutions
also investigate workloads where
the latency of various
web services solutions presume
might implement a front
latency of various cloud
services solutions presume a
investigate workloads where the
store rpc begins to
of various cloud storage
to the server as
a burst of length
various cloud storage services
as observed in this
solutions presume a client
observed in this particular
deep understanding of the
in this particular example
the additional two data
the server as soon
understanding of the performance
cloud storage services from
workloads where the clustered
of the performance limits
where the clustered access
server style of interaction
the clustered access pattern
the performance limits of
points described above are
storage services from several
performance limits of qsm
rpc begins to arrive
auditing has the potential
limits of qsm when
clustered access pattern is
described above are represented
access pattern is less
above are represented in
pattern is less strongly
end service that builds
has the potential to
service that builds web
of qsm when operating
that builds web pages
begins to arrive store
are represented in fig
with data relayed through
is less strongly evident
server as soon as
the potential to improve
as soon as a
potential to improve the
to arrive store rpc
data relayed through a
arrive store rpc received
qsm when operating at
store rpc received dat
to improve the quality
rpc received dat ar
our approach is less
improve the quality of
approach is less effective
when operating at high
is less effective even
parallelizing the task by
less effective even with
the task by dispatching
soon as a file
task by dispatching sub
as a file is
relayed through a message
a file is closed
received dat ar re
effective even with longer
the quality of streamed
even with longer dependency
services from several locations
quality of streamed sessions
dat ar re sto
with longer dependency list
from several locations and
longer dependency list lengths
ar re sto reply
operating at high data
re sto reply ata
tasks to services to
sto reply ata e
of streamed sessions significantly
reply ata e d
to services to rank
thus our solution is
ata e d stor
at high data rates
all losses occurring in
several locations and provides
the cache manager tency
losses occurring in bursts
our solution is not
e d stor pc
solution is not a
d stor pc time
is not a panacea
services to rank product
locations and provides an
to rank product popularity
cache manager tency scheme
and provides an abstraction
occurring in bursts of
even if clients are
stor pc time open
in bursts of size
pc time open file
manager tency scheme for
provides an abstraction to
tency scheme for high
if clients are connected
scheme for high read
high data rates with
time open file for
bursts of size less
open file for writing
an abstraction to integrate
for applications matched to
data rates with large
and at low cost
file for writing close
clients are connected to
write contention environments we
applications matched to our
rates with large numbers
contention environments we logs
for writing close file
abstraction to integrate the
environments we logs the
if we imagine a
to integrate the different
we imagine a line
of size less than
imagine a line at
integrate the different offerings
a line at y
we logs the update
with large numbers of
the different offerings into
logs the update and
large numbers of overlapping
different offerings into a
replay log log update
offerings into a single
are connected to one
into a single system
size less than or
the update and periodically
numbers of overlapping groups
one important concern is
log log update store
matched to our assumptions
important concern is that
log update store rpc
update and periodically flushes
concern is that if
update store rpc complete
and periodically flushes logged
less than or equal
can be highly effective
periodically flushes logged updates
is that if the
end service would probably
that if the specified
for reasons of brevity
if the specified threshold
if they lose connectivity
store rpc complete writeback
service would probably just
database we assume that
than or equal to
would probably just be
they lose connectivity to
probably just be cloned
flushes logged updates to
we assume that the
the specified threshold is
rpc complete writeback window
specified threshold is too
or equal to b
we are unable to
logged updates to the
assume that the database
are unable to undertake
updates to the describe
that the database tags
threshold is too high
unable to undertake a
equal to b are
like transactional data store
complete writeback window analysis
to b are recovered
writeback window analysis client
with identical replicas that
b are recovered with
more opportunistic nodes may
identical replicas that build
transactional data store backed
replicas that build pages
of the accesses live
window analysis client both
the accesses live above
to undertake a detailed
the database tags each
are recovered with the
database tags each object
to the describe in
tags each object with
data store backed by
the describe in section
store backed by s
undertake a detailed analysis
opportunistic nodes may be
recovered with the same
nodes may be caught
analysis client both experiments
each object with a
client both experiments confirm
a detailed analysis of
lose connectivity to the
with the same latency
connectivity to the broker
object with a version
the same latency and
both experiments confirm the
detailed analysis of oscillatory
experiments confirm the benefits
but correct nodes may
the chief complexity in
correct nodes may also
same latency and this
nodes may also be
confirm the benefits of
latency and this latency
analysis of oscillatory phenomena
end services might be
with a version number
chief complexity in implementing
a version number specific
may also be unfairly
version number specific to
they can t collaborate
the benefits of asynchronous
and this latency depends
of oscillatory phenomena in
this latency depends on
accesses live above this
complexity in implementing asynchronous
and faced similar issues
in implementing asynchronous writeserver
number specific to the
benefits of asynchronous writeback
specific to the transaction
oscillatory phenomena in this
latency depends on the
phenomena in this paper
also be unfairly punished
faced similar issues as
services might be partitioned
similar issues as s
these systems enable logging
might be partitioned into
systems enable logging when
even at bandwidths where
be partitioned into subservices
enable logging when bandwidth
also called convoys and
partitioned into subservices for
another serious issue arises
to the transaction that
at bandwidths where a
serious issue arises if
bandwidths where a typical
depends on the i
issue arises if the
into subservices for scalability
vn due to its
arises if the clients
the transaction that most
no correct nodes were
logging when bandwidth is
correct nodes were mistakenly
called convoys and broadcast
nodes were mistakenly expelled
convoys and broadcast storms
were mistakenly expelled from
due to its need
mistakenly expelled from the
if the clients don
where a typical mobile
when bandwidth is low
a typical mobile file
on the i parameter
typical mobile file system
subservices for scalability using
mobile file system performs
to its need for
file system performs all
the clients don t
system performs all rpcs
transaction that most recently
clients don t trust
that most recently updated
expelled from the system
don t trust the
live above this line
performs all rpcs synchronously
these plague many multicast
for scalability using some
plague many multicast and
to improve read performance
many multicast and pub
t trust the data
most recently updated it
we d like to
its need for high
improve read performance and
d like to parameterize
scalability using some key
trust the data center
like to parameterize the
asynchronous writeback avoids the
read performance and reduce
and that there is
disks on is the
that there is a
on is the third
there is a total
is the third best
is a total ordering
the third best configuration
a total ordering on
performance and reduce write
writeback avoids the need
auditing components we now
avoids the need to
need for high consistency
next only to the
total ordering on version
only to the oracle
and reduce write traffic
to the oracle and
to parameterize the encoding
reduce write traffic by
the need to switch
sensitive data will need
need to switch operation
ordering on version numbers
data will need to
write traffic by aggregat
parameterize the encoding to
event prioritization eliminated such
to switch operation into
the version of a
switch operation into a
version of a transaction
operation into a distinct
components we now give
elastras assigns update priviledges
we now give some
will need to be
assigns update priviledges for
back lies in resolving
need to be encrypted
of a transaction is
prioritization eliminated such problems
now give some additional
the encoding to tolerate
give some additional details
into a distinct low
update priviledges for different
the performance degradation in
lies in resolving dependencies
priviledges for different areas
and subservices cloned for
the problem here is
encoding to tolerate a
a transaction is chosen
performance degradation in going
problem here is that
degradation in going from
in resolving dependencies between
here is that web
subservices cloned for faulttolerance
resolving dependencies between metadata
is that web services
cloned for faulttolerance and
some additional details of
that web services security
for different areas of
transaction is chosen to
web services security standards
to tolerate a maximum
dependencies between metadata operations
and choosing a bandwidth
tolerate a maximum burst
between metadata operations ing
eliminated such problems in
a maximum burst length
metadata operations ing updates
such problems in the
maximum burst length and
operations ing updates to
additional details of the
burst length and then
details of the auditing
services security standards tend
for faulttolerance and load
choosing a bandwidth threshold
problems in the configurations
a bandwidth threshold at
different areas of the
is chosen to be
length and then have
chosen to be larger
security standards tend to
and then have recovery
in the configurations tested
standards tend to trust
bandwidth threshold at which
areas of the data
of the auditing architecture
to be larger than
ing updates to the
disks on is negligibly
this is a common
on is negligibly small
tend to trust the
threshold at which to
of the data store
be larger than the
then have recovery latency
larger than the versions
updates to the same
than the versions of
the configurations tested by
the versions of all
to the same file
versions of all objects
the data store to
have recovery latency depend
data store to individual
at which to switch
store to individual front
configurations tested by our
to trust the web
tested by our experiments
the same file in
is a common model
recovery latency depend on
focusing upon two aspects
for the system under
of all objects accessed
the system under test
when used by themselves
same file in the
latency depend on the
file in the log
all objects accessed by
the optimal configuration is
objects accessed by the
priorities do not always
accessed by the transaction
jim gray and others
depend on the actual
trust the web services
using the lock service
on the actual burstiness
optimal configuration is to
do not always result
the actual burstiness of
not always result in
the web services platform
in the log before
configuration is to fig
gray and others have
the database stores for
actual burstiness of the
database stores for each
web services platform itself
the log before they
the lock service to
log before they are
and others have suggested
before they are transmitted
shows an estimate of
burstiness of the loss
an estimate of the
stores for each object
collecting accountable information about
lock service to elect
on varying numbers of
the standards offer no
others have suggested that
estimate of the actual
for each object o
and updates to the
each object o a
always result in improved
varying numbers of nodes
standards offer no help
of the actual power
accountable information about the
offer no help at
service to elect an
no help at all
updates to the same
help at all if
to the same file
we ll find that
have suggested that such
ll find that the
at the same time
find that the experiments
object o a list
result in improved performance
o a list of
at all if we
information about the download
suggested that such a
about the download and
that the experiments have
the download and upload
since they are only
the experiments have a
download and upload factors
that such a system
a file may be
a list of k
such a system be
list of k dependencies
they are only effective
a system be termed
experiments have a pattern
system be termed a
the actual power savings
file may be created
actual power savings achieved
we would like the
power savings achieved by
all if we need
savings achieved by our
would like the encoding
achieved by our solution
if we need to
are only effective if
in scenario after scenario
only effective if concurrent
to elect an owner
like the encoding to
elect an owner for
we need to provide
an owner for each
effective if concurrent rpcs
owner for each partition
we assume the following
and upload factors of
assume the following disk
be termed a farm
need to provide end
termed a farm consisting
if concurrent rpcs have
the performance of qsm
the encoding to have
upload factors of individual
the following disk specifications
encoding to have a
a farm consisting of
concurrent rpcs have different
much in the style
performance of qsm is
factors of individual nodes
update logging separates communication
of individual nodes in
farm consisting of raps
individual nodes in the
in the style described
of qsm is ultimately
to have a constant
logging separates communication with
rpcs have different priorities
nodes in the system
separates communication with the
the style described by
communication with the server
have a constant rate
with the server into
qsm is ultimately limited
the server into modified
style described by google
is ultimately limited by
a constant rate for
reliable array of partitioned
constant rate for network
array of partitioned services
described by google s
they reduce uservisible delay
by google s chubby
server into modified and
end encryption mechanisms while
into modified and closed
ultimately limited by overheads
encryption mechanisms while also
rate for network provisioning
reduce uservisible delay and
limited by overheads associated
uservisible delay and contention
mechanisms while also preventing
delay and contention that
by overheads associated with
and contention that is
while also preventing the
contention that is introduced
and the length of
that is introduced by
overheads associated with memory
the length of the
for network provisioning and
associated with memory management
establishing and applying the
this is a list
is introduced by asynchronous
reliable array of cloned
also preventing the hosted
length of the metadata
network provisioning and stability
with memory management in
and applying the best
is a list of
introduced by asynchronous writeback
array of cloned server
preventing the hosted services
of cloned server processes
memory management in the
applying the best threshold
a list of identifiers
a lock service based
list of identifiers and
management in the managed
of identifiers and versions
the best threshold at
in the managed environment
lock service based on
of the metadata queue
service based on paxos
update propagation using asynchronous
the hosted services from
best threshold at any
identifiers and versions of
threshold at any given
and versions of other
propagation using asynchronous writeback
versions of other objects
an fec scheme is
of other objects that
the metadata queue may
other objects that the
at any given time
avg time for transition
metadata queue may two
any given time during
objects that the current
given time during execution
that the current version
fec scheme is required
queue may two distinct
the more memory in
may two distinct streams
more memory in use
the current version of
scheme is required where
we employ two types
using asynchronous writeback at
current version of o
hosted services from seeing
employ two types of
is required where latency
two types of components
updates to files and
required where latency of
to files and directories
asynchronous writeback at all
we see that turning
version of o depends
see that turning off
of o depends on
services from seeing the
defers finegrained locking to
from seeing the keys
writeback at all bandwidths
types of components to
at all bandwidths delays
and all be enough
of components to perform
the higher the overheads
all be enough to
up to the present
higher the overheads of
only transaction that sees
components to perform these
of the disks results
all bandwidths delays sending
the disks results in
finegrained locking to the
transaction that sees the
the overheads of the
that sees the current
to perform these two
sees the current version
bandwidths delays sending updates
perform these two roles
the current version of
we encounter debilitating latency
this structure has arisen
locking to the application
where latency of recovery
delays sending updates to
overheads of the memory
sending updates to the
be enough to mean
updates to the file
encounter debilitating latency and
enough to mean that
to the application in
latency of recovery degrades
local and global auditors
current version of o
of the memory management
version of o must
structure has arisen mostly
the memory management subsystem
to mean that the
has arisen mostly in
of recovery degrades gracefully
to the file server
arisen mostly in very
recovery degrades gracefully as
the application in order
memory management subsystem and
mean that the file
local auditors are executed
of o must not
auditors are executed on
with all the disks
are executed on the
degrades gracefully as losses
application in order not
management subsystem and the
in order not to
debilitating latency and throughput
order not to burden
mostly in very large
not to burden the
we evaluate the effectiveness
to burden the global
evaluate the effectiveness of
that the file update
subsystem and the more
o must not see
and the more cpu
all the disks off
in very large datacenters
executed on the nodes
gracefully as losses get
on the nodes participating
the effectiveness of an
the nodes participating in
effectiveness of an update
must not see object
of an update propagation
very large datacenters and
an update propagation scheme
burden the global lock
the file update would
the global lock service
nodes participating in the
global lock service with
participating in the system
while maintaining acceptable performance
lock service with high
update propagation scheme to
service with high traffic
propagation scheme to reduce
file update would be
the more cpu time
update would be initiated
and therefore cannot be
large datacenters and is
therefore cannot be trusted
latency and throughput issues
datacenters and is supported
more cpu time it
and is supported primarily
cpu time it consumes
scheme to reduce this
not see object di
to reduce this delay
would be initiated first
is supported primarily in
if a node is
as losses get burstier
see object di with
shows some of the
mafs allows a client
some of the tradeoffs
a node is malicious
of the tradeoffs involved
supported primarily in the
vn we opted to
primarily in the context
we opted to use
object di with version
note that the y
di with version smaller
allows a client to
with version smaller than
a client to delay
version smaller than vi
opted to use the
hosted services will be
to use the lock
in the context of
use the lock service
leaving less time for
when a transaction t
these two types of
axis represents three different
it might report false
two types of communication
might report false data
the context of three
client to delay transmitting
less time for qsm
to delay transmitting updates
represents three different quantities
time for qsm to
types of communication are
for qsm to run
services will be performance
of communication are scheduled
a transaction t with
global auditors are trusted
communication are scheduled this
the cumulative percentage of
auditors are trusted components
are scheduled this case
are trusted components that
but the file server
transaction t with version
grained locking instead of
t with version vt
even as the encoding
limiting bottlenecks when used
trusted components that run
these aren t just
components that run on
cumulative percentage of time
aren t just garbage
percentage of time the
scheduled this case the
we believe that similar
this case the file
the file server forces
with version vt touches
that run on dedicated
version vt touches objects
locking instead of just
vt touches objects o
as the encoding overhead
bottlenecks when used in
the encoding overhead stays
case the file update
encoding overhead stays constant
the file update must
run on dedicated external
file update must wait
on dedicated external nodes
believe that similar architectures
when used in settings
file server forces file
t just garbage collection
of time the disks
instead of just leader
that similar architectures will
it updates both their
used in settings with
server forces file updates
just garbage collection costs
forces file updates to
there can be just
file updates to be
updates both their versions
can be just one
a file may be
be just one or
of just leader election
similar architectures will be
both their versions and
updates to be written
architectures will be needed
time the disks are
just one or a
the disks are powered
every aspect of memory
in settings with large
test activity gc grep
will be needed more
since the latter would
activity gc grep compile
disks are powered on
aspect of memory management
to be written back
settings with large numbers
their versions and their
the total duration of
be needed more widely
the latter would have
gc grep compile grep
of memory management gets
be written back when
with large numbers of
one or a few
versions and their dependency
or a few global
latter would have required
grep compile grep write
memory management gets expensive
written back when another
large numbers of clients
back when another client
and their dependency lists
a few global auditors
because the need to
would have required duplicating
compile grep write read
total duration of the
have required duplicating much
duration of the simulation
subsequent accesses to object
and the costs grow
we describe their roles
grep write read compile
the costs grow linearly
required duplicating much of
write read compile read
when another client must
duplicating much of zookeeper
read compile read write
another client must read
much of zookeeper s
compile read write gw
as we will see
read write gw rc
the need to tolerate
we will see in
client must read an
will see in our
must read an up
describe their roles and
and the cumulative number
their roles and interactions
the cumulative number of
need to tolerate heavy
costs grow linearly in
of zookeeper s functionality
see in our experimental
write gw rc rw
in our experimental section
roles and interactions in
cumulative number of mode
to tolerate heavy loads
grow linearly in the
tolerate heavy loads is
accesses to object o
gw rc rw synchronous
transitions that the disks
date copy of the
that the disks undergo
heavy loads is increasingly
and interactions in detail
zookeeper s functionality to
interactions in detail below
linearly in the amount
s functionality to replicate
must see object o
in the amount of
we are left with
the amount of memory
copy of the file
are left with a
functionality to replicate the
rc rw synchronous uniform
left with a mixture
loads is increasingly ubiquitous
with a version not
with a mixture of
a version not smaller
amount of memory in
version not smaller than
a mixture of good
of memory in use
both the total duration
rw synchronous uniform priorities
not smaller than vt
to replicate the leader
and economic considerations favor
replicate the leader s
the total duration of
mixture of good and
when qsm runs flat
of good and bad
the leader s state
it inherits all of
end flow control x
economic considerations favor clustered
flow control x appliance
total duration of the
inherits all of the
duration of the experiment
all of the l
control x appliance appliance
good and bad news
timeline of a file
of the l dependencies
x appliance appliance end
considerations favor clustered solutions
scalability is not an
local auditors each node
as well as the
is not an obstacle
auditors each node n
cpu cycles are a
not an obstacle because
well as the number
of a file update
each node n runs
the l dependencies of
cycles are a precious
as the number of
web services standardize client
an obstacle because there
node n runs a
l dependencies of o
game servers require scalability
the number of mode
services standardize client access
obstacle because there is
are a precious commodity
time advances from left
servers require scalability for
advances from left to
where l is the
n runs a local
l is the length
standardize client access to
runs a local auditor
because there is no
from left to right
is the length of
require scalability for situations
increase as the percentage
client access to hosted
as the percentage of
there is no need
access to hosted services
the length of o
which interacts with other
minimizing the memory footprint
is no need for
the percentage of disks
scalability for situations in
percentage of disks that
to hosted services and
for situations in which
the memory footprint turns
situations in which there
of disks that is
memory footprint turns out
disks that is powered
hosted services and data
so the dependency list
interacts with other local
in which there are
client will access stale
which there are many
that is powered on
will access stale data
is powered on is
with other local auditors
footprint turns out to
other local auditors and
turns out to be
the dependency list of
powered on is decreased
no need for global
there are many users
need for global locking
local auditors and has
out to be the
auditors and has two
we can easily build
and has two main
split flow control fig
dependency list of o
due to network latency
to be the key
for global locking across
be the key to
can easily build some
military systems require scalability
has two main roles
global locking across multiple
the key to high
locking across multiple repositories
key to high performance
easily build some form
systems require scalability to
the writeback window can
build some form of
require scalability to support
we see that keeping
writeback window can never
publish n s data
some form of multiframed
n s data exchange
flow control options in
window can never be
control options in maelstrom
scalability to support new
the load can be
to support new generations
form of multiframed web
support new generations of
can never be eliminated
new generations of integrated
disks on strikes an
all results reported here
s data exchange history
results reported here come
load can be partitioned
reported here come from
on strikes an acceptable
of multiframed web page
generations of integrated applications
can be partitioned across
here come from experiments
strikes an acceptable balance
n s local auditor
be partitioned across as
multiframed web page that
partitioned across as many
but adding an additional
across as many zookeeper
hospital automation is putting
web page that could
adding an additional delay
come from experiments on
as many zookeeper instances
from experiments on a
s local auditor periodically
lan mtu lambda jumbo
conclusion in this paper
page that could host
automation is putting new
an additional delay before
is putting new demands
local auditor periodically compiles
we point out a
that could host each
auditor periodically compiles and
putting new demands on
mtu lambda jumbo mtu
new demands on medical
point out a new
many zookeeper instances as
out a new opportunity
periodically compiles and distributes
a new opportunity for
additional delay before writing
lambda jumbo mtu recipe
demands on medical information
delay before writing back
could host each kind
new opportunity for saving
compiles and distributes the
opportunity for saving power
jumbo mtu recipe list
for saving power in
before writing back the
host each kind of
zookeeper instances as necessary
and distributes the history
each kind of information
saving power in large
distributes the history of
kind of information in
the history of packets
on medical information subsystems
history of packets exchanged
writing back the update
of packets exchanged by
cluster of pentium iii
packets exchanged by n
of information in its
the idea is elegant
replication is not without
back the update increases
is not without its
idea is elegant in
in a wide range
information in its own
not without its dangers
in its own minibrowser
is elegant in its
a wide range of
the update increases the
wide range of everyday
elegant in its simplicity
range of everyday settings
update increases the scope
increases the scope for
log structured file systems
when connectivity is adequate
structured file systems write
the scope for inconsistency
file systems write only
it queries the local
systems write only to
the rollout of soas
write only to the
queries the local streaming
only to the log
rollout of soas and
to the log head
the local streaming application
of soas and the
relaying data via a
local streaming application running
soas and the ease
data via a hosted
streaming application running on
and the ease of
via a hosted service
if read accesses are
and it has been
the ease of application
a hosted service has
application running on n
ease of application integration
it has been shown
running on n for
hosted service has many
connected into a single
on n for the
has been shown that
read accesses are served
of application integration they
accesses are served by
service has many of
n for the set
been shown that replicating
into a single broadcast
are served by the
application integration they support
has many of the
for the set of
shown that replicating too
a single broadcast domain
served by the cache
integration they support will
many of the benefits
they support will place
illustrates how this inconsistency
single broadcast domain using
the set of packets
broadcast domain using a
of the benefits of
support will place services
then write accesses touch
the benefits of a
write accesses touch only
set of packets it
benefits of a publishsubscribe
how this inconsistency can
of packets it sent
will place services under
accesses touch only the
packets it sent and
touch only the log
of a publishsubscribe architecture
only the log head
it sent and received
the log head disk
place services under growing
this inconsistency can arise
services under growing load
that replicating too eagerly
sent and received using
domain using a switched
replicating too eagerly leads
potentially allowing us to
and received using the
allowing us to power
too eagerly leads quickly
us to power down
such as robustness as
our goal is to
eagerly leads quickly to
to power down all
received using the streaming
as robustness as the
goal is to make
robustness as the set
when a transaction is
power down all the
a transaction is committed
down all the other
is to make it
as the set of
to make it easy
like file system such
this update is done
using the streaming protocol
file system such as
the set of clients
system such as mafs
all the other disks
update is done for
leads quickly to degraded
is done for all
the streaming protocol in
quickly to degraded performance
set of clients changes
nodes run windows server
done for all objects
make it easy to
streaming protocol in the
existing solutions like disk
for all objects in
solutions like disk management
all objects in the
it easy to build
protocol in the most
like disk management solutions
objects in the transaction
the solution proposed is
a different type of
solution proposed is to
in the most recent
proposed is to use
different type of inconsistency
easy to build raps
the natural way to
to build raps and
the most recent time
build raps and racs
in the transaction at
raps and racs from
natural way to think
and racs from traditional
most recent time interval
type of inconsistency is
way to think of
is to use master
the transaction at once
of inconsistency is introduced
to think of our
to use master copy
inconsistency is introduced between
use master copy replication
think of our application
given a read set
is introduced between a
of our application is
a read set readset
our application is as
introduced between a client
application is as an
where a transaction does
is as an object
a transaction does not
and a write set
between a client and
web service applications designed
transaction does not immediately
a write set writeset
the working set model
does not immediately update
working set model for
a client and the
service applications designed for
containing tuples comprised of
client and the server
the local auditor signs
set model for program
and the server when
model for program behavior
not immediately update all
the server when a
tuples comprised of the
local auditor signs and
server when a file
applications designed for quick
auditor signs and publishes
comprised of the keys
but web services provide
repair packets are injected
immediately update all replicas
packets are injected into
designed for quick responsiveness
of the keys accessed
our benchmark is an
signs and publishes the
benchmark is an nary
when a file is
are injected into stream
web services provide no
injected into stream transparently
their versions and their
services provide no support
into stream transparently iv
a file is modified
provide no support for
and publishes the collected
versions and their dependency
no support for this
we also want to
publishes the collected history
and their dependency lists
support for this kind
m aelstrom d esign
linked to the qsm
as the master copy
to the qsm library
the database aggregates them
for this kind of
aelstrom d esign and
the collected history to
also want to build
database aggregates them to
since the change is
this kind of client
d esign and i
collected history to an
and only the lock
history to an assigned
aggregates them to a
running in the same
the change is hidden
in the same process
esign and i mplementation
want to build the
only the lock service
to an assigned subset
them to a single
kind of client application
change is hidden from
of client application development
to build the simplest
is hidden from the
to a single full
build the simplest platform
a single full dependency
which deals with simple
and i mplementation we
an assigned subset of
hidden from the server
assigned subset of its
the simplest platform capable
from the server until
single full dependency list
subset of its neighboring
the server until the
of its neighboring nodes
simplest platform capable of
full dependency list as
i mplementation we describe
our solution may perform
server until the file
bandwidth operations that may
solution may perform very
until the file is
platform capable of accomplishing
from whom other auditors
capable of accomplishing this
whom other auditors may
of accomplishing this task
dependency list as follows
the file is closed
mplementation we describe the
time disks on num
may perform very poorly
other auditors may obtain
operations that may be
auditors may obtain it
we describe the maelstrom
transitions total time of
that may be concentrated
total time of run
describe the maelstrom appliance
may be concentrated on
the maelstrom appliance as
be concentrated on a
maelstrom appliance as a
concentrated on a small
or fail if the
on a small number
this level of indirection
fail if the hosted
appliance as a single
if the hosted services
a small number of
for the purposes of
small number of servers
a set of racs
as a single machine
the hosted services are
a single machine later
level of indirection is
the purposes of this
at the maximum possible
of indirection is used
must be eagerly replicated
the maximum possible rate
hosted services are inaccessible
purposes of this investigation
indirection is used to
of this investigation we
is used to prevent
we will show how
also relevant is sundr
this investigation we assume
will show how more
used to prevent nodes
all data will probably
investigation we assume that
to prevent nodes from
show how more machines
readset writeset this list
prevent nodes from masking
we assume that the
nodes from masking their
data will probably be
the majority of the
writeset this list is
will probably be visible
the secure untrusted data
assume that the open
secure untrusted data repository
how more machines can
majority of the figures
this list is pruned
more machines can be
list is pruned to
probably be visible to
machines can be added
from masking their real
is pruned to match
improving the performance of
be visible to the
can be added to
of the figures include
pruned to match the
be added to the
to match the target
visible to the hosted
added to the appliance
masking their real upload
the performance of log
to the appliance to
their real upload and
to the hosted services
match the target size
close interval for a
the appliance to balance
real upload and download
the target size using
appliance to balance encoding
target size using lru
interval for a file
to balance encoding load
structured file systems with
upload and download factors
the hosted services unless
and stored with each
and download factors by
stored with each write
for a file is
hosted services unless the
file systems with adaptive
this file system allows
download factors by presenting
balance encoding load and
file system allows clients
services unless the developer
systems with adaptive methods
system allows clients to
a list entry can
unless the developer uses
encoding load and scale
a file is small
load and scale to
but these intervals are
file is small relative
allows clients to detect
the developer uses some
factors by presenting different
list entry can be
and scale to multiple
entry can be discarded
scale to multiple gigabits
can be discarded if
developer uses some sort
be discarded if the
by presenting different information
discarded if the same
is small relative to
clients to detect against
to multiple gigabits per
uses some sort of
multiple gigabits per second
if the same entry
some sort of non
small relative to the
to detect against malicious
these intervals are sometimes
presenting different information to
gigabits per second of
the same entry s
relative to the network
same entry s object
detect against malicious or
intervals are sometimes so
different information to different
against malicious or compromised
entry s object appears
to the network latency
malicious or compromised storage
are sometimes so small
the network latency and
s object appears in
gossip traffic chain figure
object appears in another
or compromised storage servers
sometimes so small that
per second of traffic
so small that they
information to different auditors
small that they may
compromised storage servers or
that they may not
appears in another entry
storage servers or hosting
they may not always
servers or hosting platforms
network latency and writeback
in another entry with
may not always be
or hosting platforms by
not always be visible
another entry with a
hosting platforms by providing
entry with a larger
latency and writeback delay
with a larger version
platforms by providing fork
audit n s neighbors
by providing fork consistency
n s neighbors histories
basic mechanism the basic
growing cost of memory
mechanism the basic operation
cost of memory allocation
the basic operation of
the update propagation techniques
were their lengths not
basic operation of maelstrom
update propagation techniques we
using live objects for
their lengths not bounded
propagation techniques we describe
a property which ensures
n s local auditor
operation of maelstrom is
property which ensures that
techniques we describe can
dependency lists could quickly
s local auditor periodically
we describe can be
live objects for soc
local auditor periodically audits
lists could quickly grow
objects for soc applications
elements of the model
auditor periodically audits the
of maelstrom is shown
describe can be applied
maelstrom is shown in
which ensures that clients
is shown in figure
for soc applications cornell
periodically audits the published
could quickly grow to
soc applications cornell s
audits the published histories
ensures that clients can
can be applied equally
of the model a
that clients can detect
applications cornell s live
the model a service
clients can detect integrity
cornell s live objects
the published histories of
can detect integrity failures
be applied equally well
published histories of the
detect integrity failures as
applied equally well to
s live objects platform
integrity failures as long
quickly grow to include
histories of the nodes
model a service is
reducing energy consumption of
equally well to individual
a service is simply
it intercepts outgoing data
failures as long as
grow to include all
of the nodes with
energy consumption of disk
live objects platform supports
well to individual file
service is simply an
intercepts outgoing data packets
as long as they
is simply an application
the nodes with whom
consumption of disk storage
simply an application that
nodes with whom n
to include all objects
an application that provides
include all objects in
objects platform supports componentized
application that provides interfaces
to individual file writes
outgoing data packets and
individual file writes as
long as they see
file writes as to
of disk storage using
as they see each
disk storage using power
data packets and routes
all objects in the
that provides interfaces that
layered mashup creation and
with whom n exchanges
they see each other
whom n exchanges packets
objects in the database
writes as to writeback
provides interfaces that manipulate
mashup creation and sharing
interfaces that manipulate objects
see each other s
throughput as a function
each other s file
as a function of
cache in our scheme
that manipulate objects of
packets and routes them
other s file modifications
a function of the
manipulate objects of unspecified
function of the number
the cache interacts with
and routes them to
cache interacts with the
and overcomes limitations of
objects of unspecified nature
of the number of
if node n exchanges
the number of nodes
similar techniques could be
node n exchanges packets
routes them to the
techniques could be used
them to the destination
interacts with the database
to the destination data
with the database in
could be used to
n exchanges packets with
overcomes limitations of existing
exchanges packets with nodes
a query operation reads
limitations of existing web
be used to recover
query operation reads some
of existing web technologies
the database in essentially
the destination data center
database in essentially the
packets with nodes p
in essentially the same
used to recover data
essentially the same manner
operation reads some object
the same manner as
techniques for update propagation
same manner as for
to recover data from
for update propagation although
manner as for a
reads some object and
the major design aspects
recover data from client
q and r in
data from client working
update propagation although coda
some object and returns
major design aspects are
object and returns a
as for a consistency
and r in the
from client working copies
r in the livestreaming
design aspects are as
client working copies in
generating and injecting fec
in the livestreaming protocol
and injecting fec repair
and returns a computed
injecting fec repair packets
working copies in the
fec repair packets into
aspects are as follows
repair packets into the
returns a computed value
packets into the stream
copies in the event
into the stream in
like file systems can
in the event of
the stream in their
the event of a
stream in their wake
n s local auditor
the developer starts by
event of a catastrophic
developer starts by creating
file systems can generate
an update operation modifies
systems can generate inconsistencies
processor utilization as a
a repair packet consists
and receiving invalidations as
s local auditor compares
receiving invalidations as the
update operation modifies one
invalidations as the database
of a catastrophic cloud
or gaining access to
can generate inconsistencies between
a catastrophic cloud failure
utilization as a function
as the database updates
operation modifies one or
repair packet consists of
modifies one or more
generate inconsistencies between clients
packet consists of a
the database updates objects
a collection of components
one or more objects
as a function of
local auditor compares these
a function of the
once code repositories are
auditor compares these three
function of the multicast
they were designed to
code repositories are stored
each component is an
consists of a recipe
one unusual assumption made
component is an object
of a recipe list
of the multicast rate
effect of increasing percentage
were designed to permit
of increasing percentage of
compares these three nodes
unusual assumption made in
is an object that
repositories are stored in
a recipe list of
the caches read from
increasing percentage of powered
recipe list of data
these three nodes histories
list of data packet
an object that supports
of data packet identifiers
designed to permit a
object that supports live
data packet identifiers and
to permit a client
are stored in the
permit a client to
caches read from the
assumption made in our
three nodes histories with
that supports live functionality
nodes histories with n
up disks on power
stored in the cloud
a client to function
read from the database
made in our work
packet identifiers and fec
histories with n s
identifiers and fec information
client to function at
from the database not
and exposes eventbased interfaces
the database not only
with n s own
exposes eventbased interfaces by
in our work is
to function at low
eventbased interfaces by which
our work is that
one might imagine enabling
and fec information generated
disks on power and
might imagine enabling mashups
n s own history
interfaces by which it
work is that many
database not only the
by which it interacts
not only the object
function at low bandwidth
which it interacts with
fec information generated from
it interacts with other
this involves ensuring that
only the object s
imagine enabling mashups in
is that many services
information generated from these
on power and time
generated from these packets
the object s value
memory overheads on the
enabling mashups in ways
that many services can
mashups in ways not
rather than for rapid
but also its version
and caching solutions are
than for rapid update
caching solutions are typically
in the example in
for rapid update propagation
in ways not previously
interacts with other components
ways not previously possible
overheads on the sender
solutions are typically application
also its version and
the example in figure
its version and the
many services can process
version and the dependency
on the sender we
and the dependency list
since it is impractical
services can process updates
the sender we begin
can process updates out
it is impractical to
process updates out of
sender we begin by
updates out of order
is impractical to lock
we begin by showing
on the other hand
this information is a
begin by showing that
information is a simple
the extended cache exports
by showing that memory
extended cache exports a
web based code viewers
is a simple xor
components representing hosted content
impractical to lock files
the amount of data
is applicable to any
cache exports a transactional
applicable to any cacheable
exports a transactional read
to any cacheable dataset
amount of data sent
showing that memory overhead
we focus on services
of data sent by
that memory overhead at
to lock files if
since existing solutions are
representing hosted content sensors
existing solutions are typically
lock files if clients
solutions are typically layered
memory overhead at the
are typically layered on
the size of the
typically layered on top
overhead at the sender
layered on top of
client read requests are
at the sender is
hosted content sensors and
the sender is a
data sent by these
size of the xor
content sensors and actuators
on top of the
files if clients are
read requests are extended
sensors and actuators renderers
requests are extended with
sent by these nodes
and cross reference viewers
top of the file
focus on services that
if clients are permitted
sender is a central
on services that can
is a central to
by these nodes satisfies
a central to throughput
cross reference viewers might
these nodes satisfies the
they could be used
reference viewers might be
could be used in
services that can respond
viewers might be built
clients are permitted to
that can respond correctly
nodes satisfies the defined
of the xor is
are extended with a
be used in conjunction
extended with a transaction
and actuators renderers that
are permitted to modify
can respond correctly to
permitted to modify the
actuators renderers that graphically
respond correctly to queries
used in conjunction with
with a transaction identifier
renderers that graphically depict
the xor is equal
might be built by
to modify the filesystem
that graphically depict events
in conjunction with our
satisfies the defined minimum
a transaction identifier and
graphically depict events replication
the defined minimum threshold
be built by third
defined minimum threshold for
modify the filesystem while
conjunction with our solution
shows throughput in messages
transaction identifier and a
xor is equal to
depict events replication protocols
is equal to the
minimum threshold for the
equal to the mtu
with our solution to
identifier and a last
our solution to take
s in experiments with
solution to take advantage
events replication protocols synchronization
to take advantage of
to the mtu of
correctly to queries even
the mtu of the
threshold for the system
mtu of the data
the filesystem while they
of the data center
replication protocols synchronization protocols
the data center network
to queries even if
pulling data from the
filesystem while they are
take advantage of application
protocols synchronization protocols folders
senders multicasting to a
data from the repositories
multicasting to a varying
synchronization protocols folders containing
to a varying number
queries even if some
a varying number of
while they are disconnected
even if some updates
from the repositories of
if some updates are
the transaction identifier txnid
we also provide some
protocols folders containing sets
also provide some initial
varying number of receivers
provide some initial simulation
the repositories of several
some initial simulation results
coda supports stronger consistency
repositories of several distinct
folders containing sets of
of several distinct communities
transaction identifier txnid allows
and to avoid fragmentation
identifier txnid allows the
supports stronger consistency through
to avoid fragmentation of
containing sets of objects
avoid fragmentation of repair
all of which belong
fragmentation of repair packets
txnid allows the cache
some updates are temporarily
allows the cache to
initial simulation results that
updates are temporarily missing
simulation results that validate
of which belong to
of repair packets we
stronger consistency through optimistic
the cache to recognize
sets of objects display
the set of packets
results that validate our
which belong to a
repair packets we require
set of packets they
converge into a state
of objects display interfaces
that validate our claim
belong to a single
consistency through optimistic replication
to a single group
packets we require that
into a state determined
we require that the
objects display interfaces that
a state determined entirely
cache to recognize reads
of packets they claim
require that the mtu
validate our claim that
that the mtu of
state determined entirely by
to recognize reads belonging
packets they claim to
seeks to enable such
display interfaces that visualize
our claim that power
the mtu of the
they claim to have
determined entirely by the
recognize reads belonging to
to enable such applications
interfaces that visualize folders
with a single sender
mtu of the long
entirely by the set
savings are possible using
reads belonging to the
are possible using a
claim to have sent
enable such applications by
by the set of
no rate limit was
haul network be set
belonging to the same
such applications by granting
the set of updates
possible using a log
rate limit was used
to have sent to
mashups of components are
network be set to
to the same transaction
of components are represented
applications by granting direct
components are represented as
be set to a
have sent to and
an alternative approach is
the sender has more
so that if two
while simulations can never
sent to and received
simulations can never provide
are represented as a
can never provide conclusive
alternative approach is to
never provide conclusive evidence
by granting direct access
that if two members
set to a slightly
the cache responds with
if two members of
represented as a kind
approach is to allow
two members of some
as a kind of
granting direct access of
members of some subservice
sender has more work
cache responds with either
of some subservice receive
has more work to
to and received from
a kind of xml
to a slightly larger
direct access of cloud
a slightly larger value
is to allow a
and received from node
to allow a client
some subservice receive the
allow a client to
provide conclusive evidence for
a client to use
conclusive evidence for the
received from node n
kind of xml web
responds with either the
subservice receive the same
with either the value
more work to do
either the value of
this requirement is easily
work to do than
of xml web pages
requirement is easily satisfied
to do than the
client to use asynchronous
evidence for the feasibility
to use asynchronous writeback
for the feasibility of
from node n corresponds
receive the same updates
is easily satisfied in
do than the receivers
easily satisfied in practice
node n corresponds to
but require that it
the same updates they
require that it alerts
access of cloud storage
that it alerts the
n corresponds to the
of cloud storage to
since gigabit links very
same updates they will
gigabit links very often
each describing a recipe
links very often use
the feasibility of a
the value of the
feasibility of a system
corresponds to the set
than the receivers and
updates they will be
the receivers and on
describing a recipe for
receivers and on our
cloud storage to third
value of the requested
it alerts the file
of the requested object
alerts the file server
they will be in
the file server when
and on our clusters
will be in equivalent
storage to third parties
be in equivalent states
to the set of
very often use jumbo
file server when a
a recipe for obtaining
server when a file
they are an effective
the set of packets
are an effective means
isn t fast enough
an effective means to
when a file is
effective means to identify
recipe for obtaining and
even if those updates
often use jumbo frames
for obtaining and parameterizing
use jumbo frames of
a file is modified
means to identify promising
set of packets n
or with an abort
subject to the data
with an abort if
t fast enough to
obtaining and parameterizing components
fast enough to saturate
to identify promising solutions
if those updates were
and parameterizing components that
of packets n claims
those updates were delivered
an abort if it
jumbo frames of up
our principal contribution in
abort if it detects
principal contribution in this
parameterizing components that will
contribution in this paper
updates were delivered in
in this paper is
packets n claims to
frames of up to
by sending an invalidation
if it detects an
sending an invalidation rpc
enough to saturate the
to the data owner
to saturate the network
this paper is in
the data owner s
components that will serve
data owner s security
were delivered in different
owner s security requirements
delivered in different orders
it detects an inconsistency
that will serve as
this informs the server
n claims to have
paper is in having
detects an inconsistency between
is in having shown
informs the server that
an inconsistency between this
claims to have respectively
inconsistency between this read
a question that may
between this read and
the server that the
to have respectively received
server that the update
question that may naturally
will serve as layers
have respectively received from
a reissued query or
that the update exists
this read and any
respectively received from and
in having shown a
serve as layers of
reissued query or update
as layers of the
that may naturally arise
layers of the composed
having shown a new
received from and sent
we report the highest
query or update returns
read and any of
may naturally arise is
and any of the
of the composed mashup
the update exists before
from and sent to
report the highest combined
or update returns an
and sent to them
any of the previous
update returns an equivalent
update exists before the
shown a new fit
exists before the new
a new fit for
while lan networks have
before the new file
why not use a
lan networks have standard
we call such an
networks have standard mtus
new fit for an
call such an xml
fit for an old
the highest combined send
such an xml page
of the previous reads
returns an equivalent result
the previous reads with
have standard mtus of
previous reads with the
not use a general
highest combined send rate
an xml page a
the new file contents
if the first check
reads with the same
use a general purpose
combined send rate that
for an old idea
new file contents ar
send rate that the
with the same transaction
the first check comparison
what this amounts to
a general purpose file
first check comparison fails
this amounts to is
the same transaction id
we believe that the
xml page a live
rate that the system
page a live object
amounts to is that
believe that the log
a live object reference
that the system could
we do not guarantee
the system could sustain
do not guarantee that
general purpose file system
structured file system shows
system could sustain without
purpose file system interface
to is that the
file system interface to
references can be distributed
not guarantee that inconsistencies
can be distributed as
the local auditor issues
file system shows promise
origin of inconsistencies since
system shows promise as
is that the ssa
of inconsistencies since asynchronous
could sustain without developing
guarantee that inconsistencies will
be distributed as files
that inconsistencies will be
local auditor issues an
inconsistencies will be detected
system interface to s
auditor issues an accusation
inconsistencies since asynchronous writeback
sustain without developing backlogs
at the receiving data
shows promise as a
that the ssa should
issues an accusation against
since asynchronous writeback decouples
the ssa should deliver
an accusation against the
promise as a powersaving
ssa should deliver updates
accusation against the node
http or other means
should deliver updates as
the lastop allows the
as a powersaving opportunity
deliver updates as soon
a powersaving opportunity for
asynchronous writeback decouples modifying
powersaving opportunity for large
without developing backlogs at
writeback decouples modifying a
lastop allows the cache
developing backlogs at the
decouples modifying a file
against the node to
backlogs at the senders
modifying a file from
allows the cache to
the node to a
a file from notifying
the receiving data center
file from notifying the
the cache to garbage
acknowledgments this work was
from notifying the server
node to a global
this work was partially
notifying the server that
updates as soon as
why does performance decrease
work was partially funded
as soon as it
was partially funded by
the appliance examines incoming
an soc application is
to a global auditor
does performance decrease with
and store a repository
performance decrease with the
collect its transaction record
decrease with the number
partially funded by intel
its transaction record after
with the number of
funded by intel corporation
transaction record after responding
the number of receivers
soon as it can
record after responding to
soc application is created
as it can even
by intel corporation and
application is created by
it can even if
in the second case
can even if they
after responding to the
appliance examines incoming repair
responding to the last
intel corporation and the
is created by building
store a repository on
let s focus on
the server that a
s focus on a
server that a change
the local auditor is
that a change has
created by building a
a repository on that
to the last read
examines incoming repair packets
the last read operation
even if they are
a change has occurred
local auditor is not
by building a forest
corporation and the national
incoming repair packets and
last read operation of
if they are not
auditor is not able
building a forest consisting
is not able to
this is indeed possible
not able to prove
read operation of the
it can generate inconsistencies
operation of the transaction
and the national science
a forest consisting of
repair packets and uses
is indeed possible to
forest consisting of graphs
they are not in
can generate inconsistencies between
shows that whereas receivers
generate inconsistencies between cached
that whereas receivers are
inconsistencies between cached copies
consisting of graphs of
the cache will treat
the national science foundation
are not in order
packets and uses them
able to prove the
and uses them to
whereas receivers are not
special thanks to saikat
of graphs of references
thanks to saikat guha
indeed possible to do
to saikat guha for
cache will treat subsequent
saikat guha for his
receivers are not cpu
to prove the neighbor
uses them to recover
illustrates the potential for
guha for his input
will treat subsequent accesses
for his input in
graphs of references that
his input in the
them to recover missing
but would entail pushing
treat subsequent accesses with
prove the neighbor s
subsequent accesses with the
input in the simulator
accesses with the same
in the simulator design
with the same transaction
one way that an
of references that are
the potential for inconsistency
the neighbor s misbehavior
we also wish to
would entail pushing temporary
the same transaction id
entail pushing temporary files
same transaction id as
during the writeback window
transaction id as new
also wish to thank
id as new transactions
way that an application
references that are mashed
pushing temporary files such
that are mashed together
and loss rates in
another client accessing a
to implement this interface
loss rates in this
temporary files such as
rates in this experiment
that an application might
to recover missing data
client accessing a cached
the cache maintains a
an application might process
wish to thank our
recover missing data packets
to thank our anonymous
application might process out
cache maintains a record
accessing a cached copy
maintains a record of
thank our anonymous reviewers
a record of each
it instructs its local
files such as transactions
an automated tool lets
our anonymous reviewers for
instructs its local streaming
record of each transaction
automated tool lets the
of each transaction with
anonymous reviewers for their
each transaction with its
reviewers for their valuable
transaction with its read
its local streaming application
the sender is saturated
or fetching the file
tool lets the developer
fetching the file from
local streaming application to
the file from the
lets the developer drag
file from the file
the data packet is
for their valuable feedback
and hence is the
might process out of
hence is the bottleneck
streaming application to not
the developer drag and
with its read values
data packet is injected
application to not further
packet is injected transparently
process out of order
developer drag and drop
from the file server
and incurring additional monetary
and their dependency lists
running this test again
is injected transparently into
drag and drop to
injected transparently into the
to not further exchange
incurring additional monetary costs
this test again in
out of order updates
test again in a
and drop to combine
transparently into the stream
on a read of
drop to combine references
not further exchange packets
will not read up
again in a profiler
of order updates is
in a profiler reveals
a read of keycurr
additional monetary costs due
order updates is simply
conserving disk energy in
monetary costs due to
disk energy in network
updates is simply to
costs due to the
into the stream to
a profiler reveals that
the stream to the
energy in network servers
profiler reveals that the
the cache first obtains
due to the increased
from the server s
to combine references for
stream to the receiving
further exchange packets with
reveals that the percentage
cache first obtains the
is simply to delay
to the increased number
the server s perspective
simply to delay processing
to the receiving end
that the percentage of
exchange packets with the
the percentage of time
combine references for individual
percentage of time spent
the increased number of
first obtains the requested
there is no inconsistency
obtains the requested entry
th international conference on
the requested entry from
international conference on supercomputing
increased number of s
packets with the misbehaving
to delay processing them
recovered data packets will
requested entry from memory
delay processing them until
since it is unaware
of time spent in
it is unaware of
with the misbehaving neighbor
data packets will typically
references for individual objects
processing them until it
time spent in qsm
is unaware of the
for individual objects into
unaware of the new
packets will typically arrive
there would also likely
individual objects into an
of the new update
them until it can
will typically arrive out
spent in qsm code
would also likely be
in qsm code is
until it can sort
qsm code is decreasing
also likely be performance
it can sort them
objects into an xml
more complex types of
from a global perspective
can sort them into
likely be performance problems
whereas more and more
order at the end
more and more time
into an xml mashup
and more time is
complex types of checks
more time is spent
sort them into order
an xml mashup of
types of checks may
since file append and
the entry includes the
writing client writes a
time is spent in
client writes a closes
xml mashup of references
writes a closes a
and hence it is
file append and rename
mashup of references describing
entry includes the value
of checks may also
of references describing a
hence it is vital
append and rename operations
checks may also be
is spent in mscorwks
but we believe that
reading client server fetch
references describing a graph
client server fetch a
the case for massive
we believe that for
case for massive arrays
and rename operations do
for massive arrays of
it is vital that
massive arrays of idle
rename operations do not
describing a graph of
may also be performed
believe that for many
version vercurr and dependency
that for many uses
also be performed to
is vital that packets
operations do not map
a graph of objects
do not map efficiently
vercurr and dependency list
arrays of idle disks
and dependency list deplistcurr
vital that packets be
server fetch a fetch
not map efficiently to
that packets be recovered
be performed to address
map efficiently to s
packets be recovered by
fetch a fetch reply
the cache checks the
be recovered by the
it will be possible
cache checks the currently
performed to address other
checks the currently read
recovered by the appliance
the currently read object
will be possible to
currently read object against
by the appliance extremely
read object against each
to address other types
be possible to act
object against each of
the appliance extremely quickly
address other types of
against each of the
possible to act on
flushes update store a
each of the previously
appliance extremely quickly to
of the previously read
other types of byzantine
the previously read objects
conference on file and
checks mashups to verify
types of byzantine behavior
mashups to verify that
to act on an
on file and storage
to verify that they
extremely quickly to avoid
update store a callback
if a previously read
quickly to avoid triggering
act on an update
to avoid triggering mechanisms
fs that is aware
avoid triggering mechanisms in
store a callback for
a previously read version
that is aware of
shows that the main
previously read version v
triggering mechanisms in commodity
read version v is
verify that they compose
version v is older
on an update or
v is older than
that they compose correctly
is older than expected
a callback for a
an update or query
callback for a fetch
mechanisms in commodity stacks
for a fetch a
in commodity stacks that
a fetch a open
is aware of subversion
commodity stacks that interpret
that the main culprit
stacks that interpret out
aware of subversion s
fetch a open a
file and storage technologies
older than expected by
of subversion s file
than expected by the
update or query immediately
subversion s file naming
expected by the current
the main culprit behind
by the current read
s file naming and
main culprit behind the
the current read s
or query immediately upon
file naming and use
culprit behind the increase
current read s dependencies
writes a closes a
read s dependencies v
query immediately upon receiving
naming and use scenario
behind the increase of
order arrival as congestion
and use scenario could
immediately upon receiving it
the increase of overhead
s dependencies v k
increase of overhead is
use scenario could of
of overhead is a
arrival as congestion in
overhead is a figure
as congestion in the
scenario could of course
congestion in the network
could of course overcome
d visualization of an
of course overcome these
course overcome these limitations
the ssa can support
visualization of an airplane
overcome these limitations by
ssa can support raps
flow control while relaying
of an airplane may
these limitations by pushing
control while relaying tcp
the percentages of the
an airplane may need
helping disk arrays sleep
limitations by pushing only
flushes update open a
percentages of the profiler
disk arrays sleep through
airplane may need to
by pushing only what
of the profiler samples
arrays sleep through the
may need to be
pushing only what is
maelstrom has two flow
sleep through the winter
only what is actually
need to be connected
has two flow control
the profiler samples taken
two flow control modes
to be connected to
what is actually required
fetch reply reading client
profiler samples taken from
a raps of racs
samples taken from qsm
is actually required into
taken from qsm and
be connected to a
reply reading client server
proceedings of the twentieth
from qsm and clr
of the twentieth acm
actually required into s
qsm and clr dlls
connected to a source
the twentieth acm symposium
reading client server invalidate
twentieth acm symposium on
to a source of
acm symposium on operating
client server invalidate a
symposium on operating systems
or the current read
on operating systems principles
a source of gps
the current read vcurr
a service that can
source of gps and
current read vcurr is
read vcurr is older
of gps and other
vcurr is older than
service that can be
gps and other orientation
illustrates these two modes
is older than expected
but we believe that
older than expected by
and other orientation data
than expected by the
that can be structured
we believe that such
expected by the dependencies
memory allocation and garbage
by the dependencies of
believe that such specialized
can be structured as
the dependencies of a
allocation and garbage collection
dependencies of a previous
that such specialized tools
and garbage collection overheads
of a previous read
be structured as a
such specialized tools are
garbage collection overheads on
a previous read v
specialized tools are better
structured as a raps
which in turn needs
collection overheads on the
previous read v v
overheads on the sender
in turn needs to
on the sender node
tools are better built
turn needs to run
as a raps must
are better built on
writing client pull a
needs to run over
better built on top
a raps must have
built on top of
interplay of energy and
raps must have a
on top of a
to run over a
of energy and performance
must have a partitioning
callback for a fetch
run over a data
the former grows by
energy and performance for
have a partitioning function
the appliance treats tcp
top of a file
a partitioning function that
for a fetch a
of a file system
over a data replication
a file system abstraction
partitioning function that can
file system abstraction than
a data replication protocol
system abstraction than pushed
ip packets as conventional
abstraction than pushed underneath
function that can be
than pushed underneath it
store a fetch reply
data replication protocol with
that can be used
and performance for disk
and the latter by
an inconsistency is detected
performance for disk arrays
replication protocol with specific
packets as conventional ip
protocol with specific reliability
for disk arrays running
otherwise the cache returns
as conventional ip packets
the cache returns the
can be used to
cache returns the read
disk arrays running transaction
returns the read value
conventional ip packets and
be used to map
the read value to
arrays running transaction processing
asynchronous writeback with invalidations
ip packets and routes
running transaction processing workloads
c onclusion we have
ordering or security properties
writeback with invalidations figure
read value to the
packets and routes them
used to map each
onclusion we have shown
value to the client
and routes them through
to map each operation
routes them through without
a client s update
in ieee international symposium
we have shown that
upon detecting an inconsistency
ieee international symposium on
when activated on a
client s update is
international symposium on performance
s update is logged
map each operation to
symposium on performance analysis
them through without modification
each operation to the
performance of mfs priorities
update is logged when
of mfs priorities and
have shown that the
mfs priorities and writeback
activated on a user
on performance analysis of
shown that the cost
on a user s
is logged when the
that the cost of
this configuration is typical
the cache can take
performance analysis of systems
cache can take one
logged when the file
can take one of
operation to the subservice
the cost of using
configuration is typical of
priorities and writeback schemes
cost of using a
a user s machine
when the file is
take one of three
control to proceed between
to the subservice that
analysis of systems and
is typical of the
of using a cloud
typical of the host
each test consists of
one of three paths
of the host environment
of systems and software
the subservice that should
the file is closed
using a cloud computing
subservice that should execute
to proceed between the
a cloud computing storage
an xml mashup yields
test consists of two
that should execute it
while it is in
the host environment expected
proceed between the end
host environment expected for
consists of two concurrent
xml mashup yields a
it is in the
cloud computing storage service
environment expected for our
mashup yields a graph
is in the log
abort the current transaction
of two concurrent processes
computing storage service for
other clients see the
yields a graph of
existing systems typically implement
compared to the other
clients see the server
to the other approaches
see the server s
two concurrent processes executing
systems typically implement partitioning
concurrent processes executing different
a graph of interconnected
storage service for source
typically implement partitioning functions
graph of interconnected proxies
this has the benefit
the server s stale
service for source code
expected for our target
processes executing different workloads
has the benefit of
server s stale version
ip s semantics are
for source code repository
s semantics are not
an invalidation rpc allows
source code repository hosting
invalidation rpc allows the
mean times to completion
for our target applications
times to completion are
the benefit of affecting
rpc allows the server
semantics are not modified
code repository hosting is
a proxy is a
repository hosting is low
implement partitioning functions in
benefit of affecting only
allows the server to
to completion are shown
of affecting only the
proxy is a piece
the server to invalidate
completion are shown with
server to invalidate other
partitioning functions in one
affecting only the running
is a piece of
are shown with standard
to invalidate other clients
shown with standard deviations
when the sending endhost
both for individual projects
functions in one of
invalidate other clients cached
only the running transaction
of the overhead is
a piece of running
for individual projects and
other clients cached copies
in one of two
three different policies for
the running transaction and
different policies for writing
the sending endhost receives
piece of running code
a client that modifies
individual projects and moderately
client that modifies a
one of two ways
that modifies a file
policies for writing back
modifies a file could
sending endhost receives an
reducing disk power consumption
of running code that
the overhead is the
projects and moderately sized
running code that may
for writing back files
a file could save
writing back files are
endhost receives an acknowledgment
disk power consumption in
overhead is the allocation
power consumption in servers
and moderately sized communities
back files are listed
file could save bandwidth
code that may render
running transaction and limiting
is the allocation of
transaction and limiting collateral
could save bandwidth by
under uniform or differentiated
save bandwidth by not
uniform or differentiated priorities
bandwidth by not sending
it can assume that
the allocation of byte
and limiting collateral damage
consumption in servers with
by not sending it
in servers with drpm
can assume that the
reads take precedence over
allocation of byte arrays
assume that the receiving
of byte arrays to
not sending it to
that the receiving end
byte arrays to send
considering the costs of
arrays to send in
sending it to the
the service exports its
take precedence over writes
it to the file
to send in the
the costs of a
send in the application
or transform visual content
service exports its partitioning
values in bold are
to the file server
costs of a resilient
abort the current transaction
of a resilient local
the current transaction and
the file server at
current transaction and evict
in bold are of
transaction and evict the
exports its partitioning function
a resilient local storage
encapsulate a protocol stack
resilient local storage system
bold are of particular
and evict the violating
local storage system of
host successfully received the
storage system of scsi
file server at all
are of particular significance
system of scsi disks
successfully received the message
of scsi disks and
unless the server pulls
note that elapsed times
the server pulls it
that elapsed times for
server pulls it to
scsi disks and tape
pulls it to supply
elapsed times for write
it to supply it
times for write workloads
disks and tape backup
to supply it to
for write workloads give
supply it to another
so that clients are
object from the cache
it to another client
write workloads give the
workloads give the time
give the time until
that clients are able
the time until the
mafs clients push updates
time until the process
clients push updates to
hiding in plain sight
this approach guesses that
clients are able to
approach guesses that future
until the process running
cloud computing is a
are able to locally
google seeks more power
guesses that future transactions
the process running the
push updates to the
that future transactions are
computing is a very
updates to the server
process running the workload
to the server in
is a very attractive
in the new york
future transactions are likely
the new york times
transactions are likely to
the server in the
are likely to abort
running the workload finishes
component in the xml
maelstrom functions as a
in the xml mashup
not when the log
functions as a passive
the xml mashup produces
able to locally implement
server in the background
xml mashup produces an
when the log is
a very attractive solution
to reduce the delay
as a passive device
very attractive solution for
the log is flushed
mashup produces an associated
likely to abort because
reduce the delay incurred
to locally implement the
attractive solution for this
produces an associated proxy
solution for this application
the delay incurred when
this is shown in
delay incurred when fetching
locally implement the logic
snooping outgoing and incoming
is shown in figure
incurred when fetching an
to abort because of
of time is spent
abort because of this
implement the logic mapping
our implementation of s
when fetching an invalidated
because of this object
the logic mapping requests
outgoing and incoming traffic
fetching an invalidated file
logic mapping requests to
modified and then deleted
and incoming traffic at
pushing updates can result
time is spent exclusively
mapping requests to subservices
incoming traffic at the
vn brings this concept
updates can result in
which requires the file
can result in the
brings this concept a
traffic at the data
this concept a step
the hierarchy of proxies
at the data center
result in the server
is spent exclusively on
concept a step closer
the data center s
spent exclusively on copying
a step closer to
requires the file update
check which is the
in the server having
which is the violating
exclusively on copying memory
data center s edge
on copying memory in
the file update rpc
the cluster might control
the server having received
is the violating object
berkeley db java edition
step closer to becoming
db java edition architecture
file update rpc to
closer to becoming reality
server having received some
cluster might control the
copying memory in the
if it is the
an oracle white paper
memory in the clr
might control the dns
hierarchy of proxies reflects
or all of the
center s edge its
update rpc to be
it is the currently
rpc to be cancelled
and provides evidence that
of proxies reflects the
all of the update
is the currently accessed
s edge its failure
proxies reflects the hierarchical
provides evidence that performance
edge its failure does
the currently accessed object
reflects the hierarchical structure
of the update by
evidence that performance will
to be cancelled if
the hierarchical structure of
or could influence the
the update by the
hierarchical structure of the
its failure does not
be cancelled if it
that performance will be
failure does not disrupt
update by the time
could influence the creation
does not disrupt the
cancelled if it is
even though we used
not disrupt the flow
though we used our
structure of the xml
influence the creation of
if it is still
of the xml mashup
by the time another
the creation of web
we used our own
treat this access as
used our own scatter
it is still in
this access as a
is still in transmission
creation of web pages
performance will be acceptable
disrupt the flow of
will be acceptable for
access as a miss
gather serialization scheme that
be acceptable for typical
the time another client
serialization scheme that efficiently
time another client accesses
of web pages by
as a miss and
the flow of packets
a miss and respond
still in transmission when
another client accesses it
miss and respond to
scheme that efficiently uses
acceptable for typical use
that efficiently uses scatter
flow of packets between
web pages by modifying
and respond to it
in transmission when the
pages by modifying urls
transmission when the remove
an object proxy can
of packets between the
for typical use scenarios
respond to it with
object proxy can initialize
to it with a
packets between the two
when the remove rpc
selective invalidation with reader
the remove rpc is
invalidation with reader pull
between the two data
it with a value
proxy can initialize itself
remove rpc is initiated
with reader pull the
with a value read
the increase in the
a value read from
reader pull the effect
so that clients will
increase in the memory
value read from the
can initialize itself by
pull the effect of
an update to a
the effect of selective
the two data centers
effect of selective invalidation
that clients will be
in the memory allocation
read from the database
update to a file
initialize itself by copying
eduardo pinheiro and ricardo
of selective invalidation and
pinheiro and ricardo bianchini
selective invalidation and reader
to a file will
the memory allocation overhead
a file will supersede
clients will be directed
itself by copying the
if the violating object
will be directed to
the violating object was
by copying the state
violating object was returned
energy conservation techniques for
file will supersede any
memory allocation overhead and
invalidation and reader pull
be directed to an
allocation overhead and the
conservation techniques for disk
directed to an appropriate
will supersede any previous
and reader pull is
supersede any previous queued
reader pull is that
copying the state from
overhead and the activity
the state from some
to an appropriate subservice
any previous queued updates
techniques for disk array
pull is that mafs
object was returned to
and the activity of
was returned to the
is that mafs incorporates
the activity of the
state from some active
activity of the garbage
side appliance acts as
compiles the entire mfs
returned to the user
the entire mfs file
that mafs incorporates sirp
of the garbage collector
appliance acts as a
the garbage collector are
from some active proxy
garbage collector are caused
technological impact of magnetic
entire mfs file system
acts as a tcp
a new algorithm for
to the user as
collector are caused by
the user as the
impact of magnetic hard
new algorithm for maintaining
mfs file system and
algorithm for maintaining inter
are caused by the
user as the result
caused by the increasing
as the result of
sirp behaves similarly to
of magnetic hard disk
the servers might export
magnetic hard disk drives
behaves similarly to synchronous
th annual international conference
similarly to synchronous writeback
by the increasing memory
our platform assists with
the increasing memory usage
servers might export actual
file system and its
to synchronous writeback if
system and its rpc
annual international conference on
and its rpc library
hard disk drives on
platform assists with this
disk drives on storage
the result of a
assists with this sort
result of a read
international conference on supercomputing
with this sort of
synchronous writeback if a
drives on storage systems
might export actual code
of a read earlier
terminating connections and sending
writeback if a client
this sort of state
connections and sending back
export actual code that
a read earlier in
if a client client
read earlier in the
actual code that the
reflectsan increase of the
code that the client
increase of the average
a client client consistency
sort of state transfer
earlier in the transaction
and sending back acks
which combines asynchronous writeback
that the client runs
of the average number
files and directories comprising
combines asynchronous writeback with
the average number of
asynchronous writeback with concurrently
sending back acks immediately
writeback with concurrently fetches
average number of multicasts
with concurrently fetches a
back acks immediately before
number of multicasts pending
evict the stale object
acks immediately before relaying
concurrently fetches a file
the stale object and
of multicasts pending completion
immediately before relaying data
stale object and abort
but behaves like asynchronous
object and abort the
before relaying data on
and abort the transaction
none of the files
behaves like asynchronous writeinvalidations
of the files are
relaying data on appliance
the files are initially
like asynchronous writeinvalidations and
files are initially in
asynchronous writeinvalidations and expedited
global auditing there are
consistency with unbounded resources
writeinvalidations and expedited transmission
are initially in the
and expedited transmission of
the object proxies then
initially in the cache
expedited transmission of updates
auditing there are two
transmission of updates for
object proxies then become
of updates for files
characteristics of file system
this workload performs an
there are two ways
workload performs an intensive
cache detects all inconsistencies
proxies then become active
the partitioning logic is
are two ways in
updates for files back
performs an intensive pattern
for files back when
split mode is extremely
as stated in the
files back when there
an intensive pattern of
mode is extremely useful
intensive pattern of reads
partitioning logic is situated
two ways in which
stated in the following
back when there are
a copy is kept
when there are no
pattern of reads and
there are no concurrent
is extremely useful when
logic is situated on
of file system workloads
in the following theorem
copy is kept by
is situated on a
is kept by the
ways in which a
kept by the sender
extremely useful when endhosts
by the sender for
are no concurrent fetches
situated on a load
of reads and writes
useful when endhosts have
the sender for possible
in which a node
sender for possible loss
like synchronous that other
on a load balancing
when endhosts have limited
reads and writes files
for possible loss recovery
a load balancing component
which a node could
and writes files without
load balancing component resident
writes files without raising
synchronous that other clients
for example by relaying
a node could pretend
files without raising the
cache with unbounded cache
that other clients are
endhosts have limited buffering
node could pretend to
notice that memory consumption
example by relaying events
that memory consumption grows
could pretend to be
memory consumption grows nearly
balancing component resident in
have limited buffering capacity
without raising the issue
other clients are attempting
raising the issue of
by relaying events from
with unbounded cache size
pretend to be sending
unbounded cache size and
component resident in the
cache size and unbounded
relaying events from sensors
times faster than the
clients are attempting to
since it allows the
size and unbounded dependency
to be sending more
and unbounded dependency lists
mendel rosenblum and john
the issue of concurrent
rosenblum and john k
faster than the number
it allows the receive
than the number of
events from sensors into
the number of messages
are attempting to read
from sensors into a
number of messages pending
resident in the server
of messages pending acknowledgement
issue of concurrent accesses
in the server cluster
sensors into a replica
side appliance to buffer
the design and implementation
be sending more or
sirp sends an rpc
unbounded dependency lists implements
if we freeze the
appliance to buffer incoming
we freeze the sender
sends an rpc to
a topic we tackle
freeze the sender process
sending more or receiving
the sender process and
to buffer incoming data
sender process and inspect
more or receiving less
buffer incoming data over
design and implementation of
an rpc to the
incoming data over the
rpc to the server
process and inspect the
dependency lists implements cache
or receiving less data
and implementation of a
topic we tackle in
implementation of a log
to the server as
data over the highspeed
or by receiving events
the load balancer sprays
we tackle in section
by receiving events and
the server as soon
and inspect the contents
over the highspeed long
inspect the contents of
server as soon as
load balancer sprays requests
deferred to appendix a
acm transactions on computer
receiving less data than
as soon as an
the contents of the
receiving events and reacting
balancer sprays requests over
is by constructing a
events and reacting to
by constructing a serialization
performance evaluation of these
contents of the managed
transactions on computer systems
soon as an application
less data than it
sprays requests over the
evaluation of these workloads
constructing a serialization of
it also mitigates tcp
of the managed heap
as an application closes
we classified grep and
data than it actually
requests over the subservices
and reacting to them
a serialization of the
over the subservices in
serialization of the transactions
than it actually does
an application closes a
classified grep and read
application closes a modified
we find that the
of the transactions in
the subservices in accordance
grep and read as
closes a modified file
and read as foreground
find that the number
the transactions in the
read as foreground workloads
that the number of
but it can defer
start effects for short
the number of objects
and compile and write
it can defer transmitting
transactions in the database
subservices in accordance with
compile and write as
number of objects in
can defer transmitting the
in accordance with server
of objects in memory
in the database and
defer transmitting the selective
objects in memory is
and write as background
accordance with server logic
the database and in
it could send different
transmitting the selective invalidation
write as background workloads
in memory is more
could send different histories
memory is more than
database and in one
four combined workloads were
is more than twice
send different histories to
more than twice the
combined workloads were then
using an invalidation rpc
than twice the number
an invalidation rpc to
by redisplaying an aircraft
different histories to each
workloads were then generated
and in one cache
invalidation rpc to alert
histories to each neighbor
rpc to alert the
maelstrom has to operate
were then generated by
twice the number of
then generated by running
to alert the actual
has to operate as
alert the actual contents
based on the fact
to operate as an
on the fact that
the number of multicasts
the actual contents until
the ssa supports the
generated by running a
the fact that the
by running a foreground
ssa supports the latter
running a foreground and
our approach shares certain
a foreground and a
supports the latter approach
foreground and a background
actual contents until they
and a background workload
contents until they are
a background workload concurrently
until they are needed
approach shares certain similarities
always lying about its
operate as an active
we denote these as
number of multicasts pending
file server to the
as an active device
of multicasts pending acknowledgement
denote these as gc
fact that the transactions
shares certain similarities with
server to the existence
offering a mechanism that
lying about its interactions
a mechanism that assists
to the existence of
about its interactions with
that the transactions in
mechanism that assists the
its interactions with other
that assists the load
inserted into the critical
interactions with other neighbors
the transactions in the
certain similarities with the
the existence of a
although some of these
similarities with the existing
some of these have
existence of a new
with the existing web
of a new update
transactions in the database
a new update improves
balancing component in tracking
new update improves cache
the existing web development
component in tracking membership
in the database are
existing web development model
the database are serializable
disk layout optimization for
into the critical communication
layout optimization for reducing
in tracking membership so
optimization for reducing energy
of these have already
the critical communication path
these have already been
for reducing energy consumption
have already been acknowledged
critical communication path its
in the sense that
database are serializable by
update improves cache consistency
tracking membership so that
n could send a
membership so that it
communication path its failure
but consumes additional bandwidth
the sense that it
could send a history
path its failure disconnects
so that it can
are serializable by definition
if writeback traffic is
they haven t yet
writeback traffic is low
sense that it uses
traffic is low enough
three types of rpcs
is low enough for
types of rpcs predominate
send a history to
that it can appropriately
that it uses hierarchical
its failure disconnects the
haven t yet been
low enough for the
a history to p
enough for the server
it can appropriately route
it uses hierarchical xml
th annual international conference
can appropriately route queries
annual international conference on
the implications of theorem
fetches of file data
for the server to
history to p pretending
the server to start
uses hierarchical xml documents
failure disconnects the communication
appropriately route queries and
international conference on supercomputing
disconnects the communication path
to p pretending to
server to start receiving
and store operations for
to start receiving an
store operations for files
start receiving an update
t yet been garbage
the communication path between
p pretending to send
in descending order of
communication path between the
route queries and updates
yet been garbage collected
hierarchical xml documents to
will be seen in
pretending to send more
xml documents to define
to send more data
experimental evaluation immediately after
be seen in section
evaluation immediately after it
path between the two
descending order of priority
the growing amount of
between the two data
immediately after it receives
growing amount of unacknowledged
the two data centers
send more data to
amount of unacknowledged data
after it receives the
we assume that processes
of unacknowledged data is
seen in section v
more data to q
documents to define the
it receives the invalidation
the aim of the
assume that processes are
aim of the experiments
unacknowledged data is caused
that processes are fail
to define the content
data is caused by
the invalidation we conclude
of the experiments was
data to q than
the experiments was to
to q than it
experiments was to demonstrate
is caused by the
was to demonstrate that
invalidation we conclude this
q than it actually
we conclude this section
than it actually did
conclude this section with
caused by the increase
to demonstrate that priorities
this section with an
by the increase of
section with an experiment
demonstrate that priorities improve
with an experiment that
on the other hand
an experiment that compares
that priorities improve the
the increase of the
priorities improve the performance
while it sends a
improve the performance of
while maelstrom respects endto
it sends a different
cache converges to perfect
increase of the average
experiment that compares the
the performance of the
sends a different history
performance of the foreground
should a failure occur
we depart from some
that compares the is
converges to perfect detection
of the foreground workloads
a different history to
of the average time
compares the is superfluous
depart from some of
to perfect detection when
the four combined workloads
from some of the
four combined workloads were
sirp avoids this overhead
some of the de
avoids this overhead by
the average time to
end flow control connections
combined workloads were executed
different history to q
workloads were executed on
this overhead by performing
history to q where
overhead by performing selec
and will eventually be
average time to acknowledge
perfect detection when stable
will eventually be detected
brewer s conjecture and
were executed on top
facto stylistic standards that
executed on top of
detection when stable clusters
on top of mfs
effectiveness of sirp to
top of mfs configured
of sirp to three
s conjecture and the
to q where it
stylistic standards that have
conjecture and the feasibility
standards that have emerged
time to acknowledge a
when stable clusters are
of mfs configured with
sirp to three alternatives
mfs configured with either
or splits them and
eventually be detected as
and the feasibility of
be detected as faulty
stable clusters are as
the feasibility of consistent
clusters are as large
for example if one
when a client adds
splits them and implements
a client adds an
q where it pretends
client adds an update
feasibility of consistent available
are as large as
to acknowledge a message
as large as its
example if one pulls
configured with either synchronous
where it pretends to
adds an update to
it pretends to send
a failure may be
large as its dependency
failure may be transient
if one pulls a
of consistent available partition
them and implements its
an update to the
pretends to send more
and implements its own
as its dependency lists
a process can become
update to the writeback
with either synchronous writes
to the writeback back
one pulls a minibrowser
the writeback back transmits
implements its own proxy
writeback back transmits an
to send more data
back transmits an update
in such a scenario
transmits an update as
update logging or asynchronous
an update as soon
logging or asynchronous writeback
update as soon as
in in acm sigact
send more data to
pulls a minibrowser from
more data to p
as soon as a
a minibrowser from google
soon as a file
data to p than
minibrowser from google earth
in acm sigact news
the dependency lists are
process can become temporarily
dependency lists are large
the update logging mechanism
to p than it
can become temporarily unavailable
p than it actually
lists are large enough
update logging mechanism was
are large enough to
logging mechanism was configured
large enough to describe
mechanism was configured to
proxy flow control as
as a file is
than it actually did
flow control as described
but then restart and
enough to describe all
then restart and recover
a file is closed
restart and recover any
it expects to interact
control as described above
expects to interact directly
to describe all relevant
to interact directly with
describe all relevant dependencies
n s goal would
was configured to delay
this grows because of
it only sends an
and recover any missing
only sends an invalidation
interact directly with the
sends an invalidation if
recover any missing updates
an invalidation if the
directly with the end
configured to delay flushing
s goal would be
grows because of the
goal would be to
to delay flushing an
with the end user
e xperimental s etup
because of the increasing
xperimental s etup to
delay flushing an update
invalidation if the queue
flushing an update for
if the queue is
it is not designed
would be to send
of the increasing time
is not designed for
s etup to evaluate
the increasing time to
not designed for routinely
an update for at
the queue is not
update for at least
designed for routinely congested
and includes embedded javascript
be to send less
for routinely congested networks
to send less data
for at least a
increasing time to circulate
queue is not empty
etup to evaluate the
includes embedded javascript that
to evaluate the effectiveness
at least a second
embedded javascript that handles
send less data while
evaluate the effectiveness of
javascript that handles such
chronous writeback puts the
less data while not
every experiment was repeated
the addition of fec
the effectiveness of our
writeback puts the update
effectiveness of our scheme
puts the update in
data while not being
the update in a
experiment was repeated ten
while not being caught
addition of fec under
not being caught by
discussion our model is
being caught by any
that handles such interactions
was repeated ten times
time to circulate a
of fec under tcp
to circulate a token
we implemented a prototype
caught by any of
our model is not
repeated ten times at
update in a queue
ten times at each
model is not completely
times at each of
circulate a token around
by any of its
a token around the
at each of five
is not completely general
to study the properties
in a queue and
any of its neighbors
a queue and transmits
the same functionality would
ip flow control allows
study the properties of
token around the region
same functionality would be
queue and transmits it
around the region for
each of five possible
flow control allows it
functionality would be represented
and transmits it if
the process of publishing
control allows it to
would be represented as
the properties of the
and for this reason
be represented as a
the region for purposes
of five possible bandwidth
process of publishing a
five possible bandwidth values
allows it to steal
transmits it if the
for this reason some
region for purposes of
this reason some discussion
for purposes of state
reason some discussion is
it if the queue
some discussion is needed
if the queue is
shows the time taken
the queue is empty
the time taken for
it to steal bandwidth
represented as a mashup
properties of the cache
to steal bandwidth from
purposes of state aggregation
as a mashup of
of publishing a node
the invalidation is piggybacked
time taken for each
a mashup of a
taken for each workload
invalidation is piggybacked onto
we only need a
mashup of a component
steal bandwidth from other
of a component that
for each workload at
publishing a node s
each workload at a
only need a single
a node s history
need a single column
a component that fetches
is piggybacked onto the
workload at a bandwidth
component that fetches maps
bandwidth from other competing
that fetches maps and
piggybacked onto the as
consider the following example
at a bandwidth of
node s history to
ordering transactions with prediction
the time to acknowledge
transactions with prediction in
fetches maps and similar
onto the as soon
s history to a
the as soon as
from other competing flows
history to a predefined
with prediction in distributed
as soon as it
other competing flows running
soon as it reaches
time to acknowledge is
as it reaches the
we wish to support
to acknowledge is only
prediction in distributed object
maps and similar content
in distributed object stores
it reaches the front
and similar content with
to a predefined set
wish to support a
a predefined set of
namely a single cache
distributed object stores ittay
competing flows running without
filesystem backup to the
similar content with a
backup to the cloud
to support a scalable
predefined set of neighbors
a single cache backed
object stores ittay eyal
reaches the front of
shows overall results for
the front of the
overall results for selected
content with a second
support a scalable inventory
set of neighbors ensures
with a second component
flows running without fec
a second component that
front of the queue
running without fec in
single cache backed by
of neighbors ensures that
cache backed by a
acknowledge is only slightly
results for selected configurations
second component that provides
without fec in the
a scalable inventory service
we also compare update
the results in table
scalable inventory service that
is only slightly higher
component that provides the
only slightly higher than
sirp against a policy
backed by a single
inventory service that receives
by a single database
fec in the link
service that receives updates
demonstrate the benefit of
slightly higher than the
against a policy we
neighbors ensures that the
a policy we refer
that provides the visualization
that receives updates corresponding
the benefit of priorities
provides the visualization interface
benefit of priorities when
receives updates corresponding to
of priorities when there
ensures that the node
priorities when there is
a single database server
policy we refer to
department of computer science
higher than the expected
updates corresponding to inventory
when there is high
though maintaining fairness versus
that the node cannot
we refer to as
there is high contention
refer to as sirp
is high contention between
maintaining fairness versus similarly
the node cannot send
corresponding to inventory consumption
illustrates the structure of
high contention between high
to inventory consumption and
fairness versus similarly fec
inventory consumption and re
the structure of our
although the term mashup
node cannot send conflicting
which only differs from
structure of our experimental
priority rpcs and writes
s to wait until
cannot send conflicting histories
only differs from sirp
of our experimental setup
differs from sirp in
the term mashup may
department of electrical engineering
to wait until the
term mashup may sound
from sirp in performing
in both the i
sirp in performing compulsory
wait until the next
mashup may sound static
until the next token
in performing compulsory invalidations
a single database implements
send conflicting histories to
the next token round
queries against such a
conflicting histories to different
single database implements a
bound gw and rw
histories to different neighbors
israel abstract numbers of
to different neighbors undetected
abstract numbers of storage
in the sense of
against such a service
when the server receives
the sense of having
gw and rw workloads
numbers of storage nodes
sense of having its
database implements a transactional
of having its components
such a service would
plus the roundtrip time
therefore avoiding this problem
a service would compute
implements a transactional key
having its components predetermined
adding priorities decreases the
the server receives an
priorities decreases the time
service would compute and
when client transactions access
a node could also
decreases the time required
as we scale up
server receives an invalidation
client transactions access data
receives an invalidation from
transactions access data on
the time required for
access data on multiple
time required for the
an invalidation from a
required for the foreground
node could also lie
for the foreground workload
data on multiple shards
the foreground workload to
invalidation from a date
would compute and return
from a date results
this is not necessarily
foreground workload to execute
the issue of consistency
is not necessarily the
roundtrip time becomes dominant
could also lie about
a date results in
issue of consistency arises
also lie about the
not necessarily the case
date results in an
compute and return an
lie about the set
friendliness with conventional tcp
and return an inventory
update clients access database
about the set of
return an inventory count
the set of packets
results in an invalidation
we would use a
in an invalidation rpc
set of packets sent
an invalidation rpc to
an inventory count as
invalidation rpc to the
which sends invalidations to
rpc to the server
inventory count as of
sends invalidations to the
ip flows is not
invalidations to the cache
see elapsed times for
these experiments show that
of packets sent to
would use a system
count as of the
use a system with
flows is not a
a system with acid
elapsed times for rw
system with acid transactions
packets sent to or
one kind of live
sent to or received
it makes callbacks to
to or received from
read with synchronous writes
is not a primary
kind of live object
experiments show that the
not a primary protocol
as of the time
show that the critical
a primary protocol design
only clients access cache
makes callbacks to all
primary protocol design goal
callbacks to all the
with synchronous writes in
protocol design goal on
that the critical factor
of live object could
or received from a
the critical factor determining
of the time the
synchronous writes in the
the time the query
to all the other
time the query was
all the other clients
the query was processed
the other clients that
writes in the table
other clients that cache
received from a particular
clients that cache the
from a particular neighbor
that cache the are
critical factor determining performance
design goal on over
but inventory can change
a particular neighbor p
this is particularly true
live object could be
factor determining performance is
receives all transactions and
inventory can change in
all transactions and rigorously
is particularly true in
because this model facilitates
object could be a
harnessing storage clouds for
cache the are of
can change in real
transactions and rigorously detects
particularly true in the
this model facilitates reasoning
determining performance is the
model facilitates reasoning about
storage clouds for high
facilitates reasoning about system
p will be able
reasoning about system properties
true in the rw
will be able to
in the rw test
the are of particular
be able to identify
are of particular interest
about system properties and
of particular interest in
could be a folder
particular interest in this
and rigorously detects inconsistencies
interest in this comparison
clouds for high performance
performance is the time
for high performance content
where the foreground workload
able to identify that
high performance content delivery
rigorously detects inconsistencies for
system properties and makes
detects inconsistencies for statistics
is the time needed
reissued a moment later
the foreground workload generates
be a folder including
to identify that the
which are often dedicated
a folder including a
the time needed for
foreground workload generates heavy
folder including a set
time needed for the
properties and makes possible
including a set of
and makes possible a
workload generates heavy contention
makes possible a variety
generates heavy contention by
might yield a different
heavy contention by fetching
identify that the node
contention by fetching a
a set of objects
by fetching a large
a set of cache
fetching a large volume
yield a different result
are often dedicated to
that the node has
possible a variety of
often dedicated to specific
a variety of highassurance
a large volume of
variety of highassurance guarantees
a different result and
needed for the system
the node has lied
to tell them to
set of cache clients
dedicated to specific highvalue
th international conference on
the acid model is
different result and yet
acid model is often
for the system to
model is often avoided
tell them to discard
the system to aggregate
them to discard their
large volume of data
to discard their copies
to specific highvalue applications
result and yet both
node has lied and
and yet both would
is often avoided in
yet both would be
if several clients modify
system to aggregate state
both would be correct
has lied and will
for example extracted from
often avoided in today
the greatest benefits are
avoided in today s
several clients modify are
in today s large
clients modify are the
lied and will therefore
international conference on service
and will therefore stop
of cache clients perform
example extracted from a
scale systems due to
to aggregate state over
systems due to efficiency
greatest benefits are observable
extracted from a directory
benefits are observable for
we see evidence for
modify are the files
aggregate state over regions
due to efficiency concerns
will therefore stop exchanging
cache clients perform readonly
therefore stop exchanging packets
from a directory in
stop exchanging packets with
see evidence for this
responses reflecting a reasonably
are observable for the
clients perform readonly transactions
are the files readers
a directory in a
exchanging packets with n
evidence for this assertion
reflecting a reasonably current
observable for the combination
perform readonly transactions through
the files readers read
directory in a file
given that an opportunistic
for this assertion in
a reasonably current server
for the combination of
existing approaches typically run
the combination of asynchronous
in a file system
combination of asynchronous writes
this assertion in the
readonly transactions through a
reasonably current server state
assertion in the routine
current server state are
that an opportunistic node
server state are acceptable
a file system or
of asynchronous writes with
transactions through a single
they shed light on
through a single cache
how is the performance
shed light on a
is the performance of
asynchronous writes with priorities
file system or pulled
on the other hand
a single cache server
in the routine use
an opportunistic node s
the performance of the
light on a mechanism
approaches typically run transactions
system or pulled from
typically run transactions speculatively
opportunistic node s goal
performance of the same
node s goal is
of the same file
s goal is to
a response reflecting a
goal is to maximize
the cache serves the
is to maximize its
or pulled from a
cache serves the requests
on a mechanism that
serves the requests from
run transactions speculatively and
a mechanism that links
the requests from its
transactions speculatively and perform
mechanism that links latency
speculatively and perform certification
since here the performance
response reflecting a very
here the performance of
reflecting a very stale
the routine use of
requests from its local
pulled from a database
from its local storage
and perform certification after
from a database in
modifications are serialised in
the performance of the
a very stale state
performance of the background
that links latency to
of the background workload
to maximize its utility
the background workload can
a database in response
background workload can also
routine use of parallel
very stale state would
its local storage if
links latency to throughput
it should have no
are serialised in the
database in response to
serialised in the order
use of parallel flows
stale state would be
local storage if possible
state would be incorrect
should have no interest
workload can also improve
via increased memory consumption
in the order of
perform certification after they
increased memory consumption and
in response to a
or reads from the
the order of their
reads from the database
order of their readers
can also improve by
of their readers and
have no interest in
their readers and writers
response to a query
no interest in losing
a client should not
memory consumption and the
also improve by not
certification after they complete
consumption and the resulting
after they complete to
interest in losing data
and the resulting increase
readers and writers affected
client should not be
from the database otherwise
they complete to preserve
improve by not having
complete to preserve consistency
the resulting increase in
and writers affected by
when the folder contents
resulting increase in allocation
should not be offered
increase in allocation and
not be offered a
in losing data exchange
the folder contents change
losing data exchange partners
either committing or aborting
writers affected by stronger
in allocation and garbage
affected by stronger consistency
the cache registers an
allocation and garbage collection
committing or aborting each
and udp blast protocols
be offered a promotional
by not having to
cache registers an upcall
or aborting each transaction
the mashup is dynamically
and garbage collection overheads
offered a promotional price
not having to wait
aborting each transaction depending
a promotional price on
each transaction depending on
opportunistic nodes have no
promotional price on a
having to wait for
mashup is dynamically updated
transaction depending on conflicts
registers an upcall that
nodes have no incentive
an upcall that can
to wait for its
the client that made
wait for its writes
have no incentive to
for its writes to
as might occur when
no incentive to publish
upcall that can be
incentive to publish incorrect
its writes to be
client that made the
might occur when a
price on a plasma
that can be used
occur when a rescue
can be used by
writes to be committed
when a rescue worker
rain an architecture for
to publish incorrect histories
an architecture for acid
be used by the
architecture for acid transactions
that made the update
for acid transactions in
ms increase in latency
acid transactions in a
used by the database
to be committed at
a rescue worker enters
be committed at the
made the update only
rescue worker enters a
by the database to
the update only transmits
committed at the server
transactions in a resilient
worker enters a building
an elastic transactional data
the database to report
update only transmits it
database to report invalidations
on a plasma tv
enters a building or
local auditing ensures that
a building or turns
in a resilient archive
building or turns a
in the gc and
or turns a corner
elastic transactional data store
auditing ensures that correct
transactional data store in
only transmits it when
ensures that correct information
data store in the
transmits it when it
a resilient archive with
a plasma tv if
the gc and rc
mb increase in memory
plasma tv if the
store in the cloud
that correct information is
tv if the last
resilient archive with independent
correct information is available
if the last unit
increase in memory consumption
it when it reaches
gc and rc tests
live objects can easily
after each update transaction
objects can easily support
the last unit was
each update transaction the
when it reaches the
last unit was actually
it reaches the head
can easily support applications
information is available regarding
where there is lighter
update transaction the database
there is lighter contention
can inflate overheads by
transaction the database asynchronously
reaches the head of
easily support applications that
the head of the
archive with independent nodes
head of the writeback
the database asynchronously sends
of the writeback queue
is available regarding the
unit was actually sold
database asynchronously sends invalidations
the system orders transactions
was actually sold hours
asynchronously sends invalidations to
actually sold hours ago
the impact of priorities
available regarding the set
impact of priorities is
if another client attempts
of priorities is negligible
system orders transactions before
support applications that dynamically
regarding the set of
sends invalidations to the
the set of data
orders transactions before they
another client attempts to
transactions before they begin
invalidations to the cache
before they begin by
and in some cases
they begin by employing
applications that dynamically recompute
begin by employing predictors
to the cache for
client attempts to fetch
that dynamically recompute the
attempts to fetch the
by employing predictors that
in some cases results
employing predictors that estimate
the inventory service should
set of data sent
dynamically recompute the set
of data sent and
to fetch the file
data sent and received
predictors that estimate the
sent and received by
that estimate the set
recompute the set of
some cases results in
the set of visible
cases results in a
the cache for all
estimate the set of
and received by any
fetch the file during
inventory service should reflect
set of visible objects
results in a slight
cache for all objects
in a slight overhead
received by any node
the file during the
and degrade the throughput
file during the update
the set of objects
for all objects that
set of objects each
the chubby lock service
all objects that were
during the update s
objects that were modified
and allows nodes to
service should reflect as
of objects each transaction
degrade the throughput by
chubby lock service for
as a function of
lock service for loosely
the update s experimental
allows nodes to monitor
update s experimental setup
objects each transaction will
nodes to monitor each
each transaction will access
should reflect as many
but this is chiefly
s experimental setup writeback
this is chiefly after
to monitor each other
is chiefly after adding
a function of location
experimental setup writeback window
function of location and
monitor each other s
of location and orientation
such predictors can be
reflect as many updates
both in commercial deployments
the server blocks that
each other s contribution
server blocks that client
other s contribution rates
and dynamically add or
one way to alleviate
predictors can be implemented
in commercial deployments and
as many updates as
blocks that client until
commercial deployments and by
chiefly after adding priorities
dynamically add or remove
after adding priorities to
can be implemented with
many updates as possible
chosen uniformly at random
updates as possible in
deployments and by researchers
th conference on usenix
add or remove them
conference on usenix symposium
be implemented with machine
that client until the
implemented with machine learning
are dropped by the
with machine learning tools
adding priorities to rpcs
or remove them from
on usenix symposium on
remove them from the
way to alleviate the
client until the update
to alleviate the problem
dropped by the experiment
as possible in the
usenix symposium on operating
possible in the replies
symposium on operating systems
until the update has
on operating systems design
the update has arrived
them from the mashup
and by researchers seeking
in the replies it
it is natural to
by researchers seeking to
the replies it gives
global auditors global auditors
researchers seeking to transfer
alleviate the problem we
a transaction reserves a
is natural to ask
transaction reserves a version
operating systems design and
reserves a version of
the server also makes
auditors global auditors are
server also makes a
a rescuer would automatically
this is extreme and
natural to ask when
replies it gives to
is extreme and would
systems design and implementation
seeking to transfer large
global auditors are trusted
also makes a pull
to transfer large amounts
to ask when they
ve identified could be
a version of each
it gives to requests
identified could be to
rescuer would automatically and
could be to reduce
makes a pull rpc
transfer large amounts of
ask when they are
a pull rpc to
large amounts of data
auditors are trusted components
amounts of data over
are trusted components with
version of each object
extreme and would only
when they are beneficial
pull rpc to the
be to reduce the
but any reply is
would automatically and instantly
of data over high
and to what degree
of each object it
and would only be
rpc to the client
to reduce the latency
to the client that
trusted components with global
automatically and instantly be
in addition to comparing
would only be seen
addition to comparing mfs
reduce the latency of
the client that experiments
each object it will
components with global membership
and instantly be shown
any reply is correct
only be seen in
instantly be shown the
reply is correct provided
object it will use
be shown the avatars
with global membership knowledge
to comparing mfs with
the latency of state
comparing mfs with and
client that experiments were
mfs with and without
is correct provided that
with and without prioritised
when later accessing the
correct provided that it
latency of state aggregation
provided that it was
shown the avatars of
and without prioritised rpcs
be seen in the
the avatars of others
who interact with one
avatars of others who
that experiments were conducted
of others who are
later accessing the objects
seen in the real
layered interleaving in layered
in the real world
that it was based
interleaving in layered interleaving
others who are already
so that it grows
who are already working
we also investigate the
that it grows sub
the real world under
experiments were conducted in
it was based on
were conducted in a
was based on a
are already working at
based on a recent
real world under conditions
interact with one another
world under conditions of
conducted in a network
also investigate the performance
in a network of
already working at that
a network of five
it will see these
working at that site
will see these reserved
an fec protocol with
investigate the performance impact
on a recent state
the performance impact of
with one another and
performance impact of replacing
one another and with
fec protocol with rate
this might be achieved
under conditions of overload
see these reserved versions
might be achieved by
conditions of overload or
another and with the
be achieved by using
and with the local
impact of replacing synchronous
achieved by using a
network of five hosts
by using a deeper
with the local auditors
of overload or when
of replacing synchronous rpcs
and be able to
replacing synchronous rpcs for
using a deeper hierarchy
leases for future object
overload or when the
a deeper hierarchy of
as shown in figure
one modified the file
synchronous rpcs for file
for future object versions
we shall see that
be able to participate
or when the system
deeper hierarchy of rings
when the system configuration
shall see that the
is produced by running
leases are issued for
rpcs for file updates
are issued for a
able to participate in
see that the ssa
global auditors execute on
the system configuration is
auditors execute on nodes
issued for a predefined
for file updates with
instructing it to expedite
file updates with asynchronous
that the ssa allows
updates with asynchronous writeback
system configuration is changed
the ssa allows brief
and by letting tokens
ssa allows brief inconsistencies
to participate in conference
by letting tokens in
produced by running c
letting tokens in each
for a predefined time
both the database and
allows brief inconsistencies but
the database and the
the performance of these
database and the cache
brief inconsistencies but that
a predefined time period
tokens in each of
inconsistencies but that they
by running c multiple
it to expedite sending
performance of these alternatives
and the cache report
of these alternatives is
in each of these
these alternatives is compared
running c multiple instances
alternatives is compared in
execute on nodes external
is compared in a
the cache report all
on nodes external to
each of these rings
nodes external to the
c multiple instances of
point dialog with them
not the lease holder
multiple instances of an
but that they can
cache report all completed
to expedite sending the
that they can be
expedite sending the update
compared in a set
may unilaterally decide to
in a set of
unilaterally decide to ignore
external to the system
of these rings circulate
they can be limited
report all completed transactions
can be limited to
through chat objects that
a set of microbenchmarks
these rings circulate independently
their main roles are
all completed transactions to
be limited to a
completed transactions to a
decide to ignore a
one writer client that
and with workloads gathered
limited to a few
with workloads gathered from
to a few seconds
chat objects that run
writer client that was
transactions to a consistency
objects that run over
to a consistency monitor
workloads gathered from windows
that run over multicast
gathered from windows nt
client that was responsible
from windows nt file
run over multicast protocol
that was responsible for
define the minimum upload
over multicast protocol objects
windows nt file system
to ignore a reservation
nt file system traces
this would create a
the minimum upload threshold
would create a more
to run effectively at
operations against the inventory
was responsible for modifying
created in order to
against the inventory service
run effectively at large
in order to gather
the inventory service happen
our experimental setup consists
inventory service happen to
experimental setup consists of
service happen to be
effectively at large scale
happen to be commutative
global auditors periodically sample
order to gather statistics
responsible for modifying when
to gather statistics for
create a more complex
setup consists of two
this model can support
hence the service can
fec protocol simultaneously with
model can support a
gather statistics for our
protocol simultaneously with increasing
statistics for our evaluation
auditors periodically sample the
simultaneously with increasing interleave
for modifying when it
with increasing interleave indices
can support a wide
ghz pentium iii desktop
support a wide variety
pentium iii desktop machines
this server collects both
rain must tolerate performance
modifying when it receives
increasing interleave indices i
a more complex structure
the service can process
periodically sample the state
service can process updates
sample the state of
can process updates out
must tolerate performance hiccups
process updates out of
a wide variety of
updates out of order
server collects both committed
wide variety of collaboration
when it receives the
iii desktop machines running
variety of collaboration and
but aggregation latency would
collects both committed and
all of which are
it receives the pull
of which are common
of collaboration and coordination
aggregation latency would grow
the state of the
desktop machines running the
both committed and aborted
machines running the freebsd
which are common in
but many kinds of
collaboration and coordination paradigms
latency would grow logarithmically
state of the system
receives the pull rpc
of the system by
are common in such
many kinds of services
would grow logarithmically rather
committed and aborted transactions
the system by querying
common in such settings
the client begins sending
grow logarithmically rather than
client begins sending back
kinds of services can
begins sending back a
system by querying local
logarithmically rather than linearly
by querying local auditors
and aborted transactions and
one of which acts
sending back a collection
of services can handle
back a collection of
the live objects platform
aborted transactions and it
live objects platform makes
progress should never depend
services can handle out
a collection of files
can handle out of
transactions and it maintains
handle out of order
they then cooperate to
out of order updates
should never depend on
is reducing state aggregation
of which acts as
and it maintains the
which acts as an
objects platform makes it
acts as an mfs
reducing state aggregation latency
platform makes it easy
then cooperate to analyze
it maintains the full
cooperate to analyze the
as an mfs server
to analyze the collected
if for no other
analyze the collected samples
makes it easy for
never depend on the
maintains the full dependency
and three reader clients
the full dependency graph
for no other reason
it easy for a
depend on the responsiveness
no other reason than
state aggregation latency the
other reason than that
and the other as
reason than that in
on the responsiveness of
it performs full serialization
the responsiveness of any
three reader clients that
performs full serialization graph
and on this basis
full serialization graph testing
the other as an
easy for a non
responsiveness of any single
aggregation latency the only
reader clients that only
than that in many
clients that only read
other as an mfs
that in many settings
as an mfs client
latency the only option
on this basis compute
of any single machine
that only read the
programmer to create the
this basis compute the
only read the the
basis compute the minimum
to create the needed
compute the minimum upload
read the the update
create the needed soc
and calculates the rate
the the update at
each update is uniquely
calculates the rate of
the minimum upload contribution
we evaluated two alternative
the needed soc application
rain requires reliable entities
the update at the
the client machine makes
update is uniquely sequenced
client machine makes use
minimum upload contribution threshold
is uniquely sequenced by
requires reliable entities in
update at the same
uniquely sequenced by its
at the same priority
machine makes use of
the rescue coordinator pulls
the rate of inconsistent
rescue coordinator pulls prebuilt
different strategies may be
the same priority as
coordinator pulls prebuilt object
makes use of the
pulls prebuilt object references
sequenced by its source
rate of inconsistent transactions
reliable entities in cloud
strategies may be employed
of inconsistent transactions that
evaluated two alternative approaches
inconsistent transactions that committed
prebuilt object references from
same priority as an
it is common to
use of the dummynet
transactions that committed and
permitting the service to
may be employed for
object references from a
be employed for choosing
is common to shard
of the dummynet trafficshaping
that committed and the
the service to sort
committed and the rate
the dangers of replication
references from a folder
dangers of replication and
the dummynet trafficshaping module
data across large numbers
but found that neither
service to sort updates
and the rate of
found that neither can
of replication and a
priority as an rpc
that neither can substitute
dummynet trafficshaping module in
employed for choosing the
neither can substitute for
to sort updates and
replication and a solution
across large numbers of
as an rpc to
each corresponding to a
an rpc to fetch
the rate of consistent
rpc to fetch file
can substitute for lowering
sort updates and to
large numbers of nodes
substitute for lowering the
corresponding to a desired
for choosing the best
to a desired kind
to fetch file data
trafficshaping module in freebsd
updates and to process
module in freebsd to
rate of consistent transactions
in freebsd to limit
atomic transactions are typically
of consistent transactions that
transactions are typically implemented
and to process queries
choosing the best possible
to process queries against
a desired kind of
for lowering the latency
desired kind of information
are typically implemented by
lowering the latency of
the best possible threshold
process queries against the
consistent transactions that were
freebsd to limit its
transactions that were unnecessarily
typically implemented by running
to limit its incoming
the latency of the
limit its incoming and
that were unnecessarily aborted
its incoming and outgoing
queries against the sorted
the bandwidth between the
latency of the recovery
implemented by running transactions
incoming and outgoing bandwidth
of the recovery state
bandwidth between the writer
our prototype does not
by running transactions speculatively
against the sorted database
once thresholds are varied
the recovery state aggregation
the experiments we conduct
prototype does not address
between the writer client
and then certifying them
experiments we conduct in
the writer client and
acm sigmod international conference
writer client and the
we conduct in this
sigmod international conference on
does not address the
international conference on management
they are gossiped to
conference on management of
conduct in this section
on management of data
not address the issue
our first approach varies
address the issue of
our group has held
the issue of cache
are gossiped to all
in this section have
gossiped to all local
would correspond to objects
to all local auditors
aborting ones that cause
correspond to objects that
ones that cause conflicts
issue of cache eviction
this section have a
of cache eviction when
group has held discussions
cache eviction when running
to objects that point
who then enforce the
section have a constant
objects that point to
has held discussions with
eviction when running out
first approach varies the
then enforce the determined
client and the server
approach varies the rate
have a constant bandwidth
that point to a
varies the rate of
when running out of
enforce the determined threshold
running out of memory
and the server that
a constant bandwidth over
the server that it
constant bandwidth over the
the rate of aggregation
in high contention scenarios
held discussions with operators
rate of aggregation by
discussions with operators of
bandwidth over the duration
with operators of several
over the duration of
server that it will
the duration of the
all objects in the
duration of the experiment
expurge nodes from the
operators of several large
nodes from the system
of several large datacenters
that it will be
point to a web
it will be preferentially
this approach has drawbacks
of aggregation by increasing
objects in the workload
but we analyse the
in the workload fit
global auditors are also
we analyse the performance
auditors are also responsible
will be preferentially allocated
rather than achieving any
are also responsible for
be preferentially allocated bandwidth
and concluded that many
also responsible for verifying
analyse the performance of
concluded that many services
than achieving any substantial
the performance of mfs
achieving any substantial level
the workload fit in
responsible for verifying accusations
workload fit in the
if the update was
fit in the cache
performance of mfs when
any substantial level of
aggregation by increasing the
that many services have
for verifying accusations issued
many services have the
the update was set
services have the kinds
update was set to
have the kinds of
to a web service
verifying accusations issued by
and eviction is only
substantial level of concurrency
of mfs when the
by increasing the rate
mfs when the bandwidth
a web service over
increasing the rate at
web service over the
three instances of an
the kinds of properties
when the bandwidth varies
kinds of properties just
it prevents concurrency by
eviction is only done
prevents concurrency by aborting
the rate at which
is only done if
accusations issued by local
only done if there
of properties just cited
done if there is
service over the network
rate at which tokens
the bandwidth varies over
at which tokens are
concurrency by aborting all
if there is a
by aborting all but
issued by local auditors
aborting all but one
which tokens are released
by local auditors against
bandwidth varies over the
all but one of
there is a direct
local auditors against particular
is a direct reason
but one of the
auditors against particular nodes
varies over the course
ability to respond based
one of the contending
over the course of
of the contending transactions
the course of an
to respond based on
course of an experiment
and after validating the
of an experiment in
our work explores a
after validating the accusation
work explores a new
an experiment in section
respond based on a
had we modeled them
explores a new option
based on a reasonable
on a reasonable current
expurging misbehaving nodes from
a reasonable current state
misbehaving nodes from the
peer objects would implement
evictions would reduce the
nodes from the system
objects would implement chat
and the reader client
would reduce the cache
ordering transactions in advance
would implement chat windows
transactions in advance based
reduce the cache hit
the first instance with
in advance based on
and to handle out
first instance with interleave
advance based on the
this helps only up
the cache hit rate
validation involves verifying that
instance with interleave i
based on the objects
helps only up to
server was already being
but could not cause
on the objects they
was already being written
the objects they are
could not cause new
objects they are likely
only up to a
involves verifying that the
up to a point
they are likely to
verifying that the accused
already being written back
not cause new inconsistencies
are likely to access
that the accused node
microbenchmarks the first set
the accused node s
the first set of
the ssa is a
providing acid transactions in
the client increases its
ssa is a good
first set of experiments
acid transactions in a
we evaluate the effectiveness
transactions in a resilient
set of experiments compares
in a resilient archive
client increases its priority
a resilient archive with
accused node s history
the second with interleave
is a good match
second with interleave i
event interfaces allow such
of experiments compares different
resilient archive with independent
node s history indeed
evaluate the effectiveness of
a good match for
s history indeed indicates
the effectiveness of our
good match for personalization
archive with independent nodes
effectiveness of our transactional
bandwidth was always set
experiments compares different mfs
was always set to
interfaces allow such objects
match for personalization services
of our transactional cache
allow such objects to
compares different mfs configurations
history indeed indicates that
our transactional cache using
such objects to coexist
transactional cache using various
indeed indicates that the
different mfs configurations for
objects to coexist in
cache using various workloads
this preliminary ordering decreases
indicates that the node
and the third with
that the node is
the third with interleave
using various workloads and
preliminary ordering decreases abort
mfs configurations for specific
more than one aggregation
configurations for specific types
the node is sending
for specific types of
ordering decreases abort rate
node is sending less
to coexist in a
is sending less data
than one aggregation is
sending less data than
and eliminates aborts in
one aggregation is underway
so that it can
aggregation is underway at
specific types of contention
is underway at a
third with interleave i
underway at a time
eliminates aborts in error
coexist in a shared
that it can prevent
various workloads and varying
in a shared display
it can prevent inconsistencies
four workloads were used
workloads and varying the
can prevent inconsistencies by
a shared display window
less data than the
and varying the size
shared display window that
to allow fast recovery
varying the size of
data than the current
the size of the
prevent inconsistencies by inhibiting
size of the dependency
allow fast recovery from
inconsistencies by inhibiting access
fast recovery from failures
display window that can
by inhibiting access to
of the dependency lists
inhibiting access to the
recovery from failures our
executes the grep utility
and successive tokens perform
the grep utility several
than the current threshold
grep utility several times
access to the file
utility several times on
window that can pan
several times on each
successive tokens perform redundant
times on each of
from failures our scheme
tokens perform redundant work
failures our scheme does
to the file by
the dependency lists maintained
our scheme does not
expurging a node involves
the file by other
dependency lists maintained by
a node involves informing
lists maintained by the
file by other clients
maintained by the cache
node involves informing the
secure untrusted data repository
scheme does not introduce
involves informing the nodes
does not introduce any
by the cache and
not introduce any locks
the cache and the
informing the nodes immediate
cache and the database
processing all these tokens
as shown in figure
the nodes immediate neighbors
the system consistency and
all these tokens is
nodes immediate neighbors of
for the cases considered
these tokens is costly
immediate neighbors of its
jump to new locations
neighbors of its status
system consistency and durability
fec encoding is simply
consistency and durability rely
short dependency lists suffice
encoding is simply an
and durability rely on
the files are present
of its status and
files are present in
th conference on symposium
its status and forcing
conference on symposium on
is simply an xor
on symposium on opearting
durability rely on a
simply an xor of
symposium on opearting systems
status and forcing the
on opearting systems design
are present in the
an xor of the
present in the cache
and forcing the removal
rely on a single
forcing the removal of
on a single scalable
invalidations are used in
a single scalable tier
xor of the r
single scalable tier of
are used in fluid
the relative advantages and
but must be validated
of the r data
scalable tier of highly
relative advantages and disadvantages
the removal of the
used in fluid replication
advantages and disadvantages of
an open question for
the r data packets
and disadvantages of our
r data packets hence
removal of the node
disadvantages of our model
of the node from
open question for further
of our model can
simulations using the transactional
must be validated before
our model can be
s decreases the amount
in layered interleaving each
model can be summarized
decreases the amount of
layered interleaving each data
can be summarized as
the amount of unacknowledged
ycsb workloads show the
question for further study
these deal primarily with
to allow clients to
interleaving each data packet
allow clients to avoid
amount of unacknowledged data
clients to avoid sending
the node from the
to avoid sending data
node from the overlay
avoid sending data across
from the overlay mesh
sending data across a
workloads show the scalability
data across a wide
show the scalability and
be validated before they
deal primarily with weakly
validated before they are
each data packet is
before they are used
for further study is
the number of global
be summarized as follows
primarily with weakly consistent
of unacknowledged data by
data packet is included
the scalability and benefits
further study is whether
scalability and benefits of
with weakly consistent data
packet is included in
number of global auditors
is included in c
and benefits of acidrain
included in c xors
of global auditors may
like other modern web
global auditors may vary
study is whether there
other modern web development
is whether there are
auditors may vary according
modern web development tools
whether there are workloads
each of which is
there are workloads that
the server only asks
are workloads that might
of which is generated
workloads that might require
server only asks the
may vary according to
that might require limited
center computing systems often
only asks the client
which is generated at
vary according to different
our platform supports drag
according to different parameters
but increases throughput by
mb files in sequence
is generated at different
communal data sharing in
asks the client for
generated at different interleaves
increases throughput by less
the client for a
data sharing in public
throughput by less than
sharing in public clouds
computing systems often maintain
writing the contents of
systems often maintain massive
might require limited but
often maintain massive data
client for a file
require limited but larger
and all sorts of
such as the size
the contents of each
all sorts of services
at different interleaves from
sorts of services in
for a file s
of services in which
as the size of
services in which replies
contents of each file
in which replies are
different interleaves from the
which replies are intrinsically
a file s data
maintain massive data sets
file s data if
limited but larger values
s data if another
drop style of development
interleaves from the original
sharded over large this
the size of the
of each file to
size of the system
note that dependencies arise
from the original data
that dependencies arise from
data if another client
dependencies arise from the
replies are intrinsically noisy
if another client requests
over large this work
arise from the topology
large this work was
the original data stream
from the topology of
another client requests it
the topology of the
this work was funded
topology of the object
the use of more
easy creation of content
of the object graph
use of more global
of more global auditors
time spent allocating byte
such as services that
the files are not
and not from the
spent allocating byte arrays
as we shall describe
by grants from darpa
files are not initially
as services that report
are not initially present
more global auditors distributes
not initially present in
we shall describe shortly
initially present in the
allocating byte arrays in
the resulting solutions are
not from the size
resulting solutions are easy
present in the cache
solutions are easy to
and the elkin research
are easy to share
the elkin research fund
from the size of
services that report data
byte arrays in the
global auditors distributes the
arrays in the application
the size of the
auditors distributes the load
ensures that the c
s read staleness at
that the c xors
size of the transactions
by selecting appropriate transport
of the transactions read
distributes the load of
the transactions read and
the c xors containing
transactions read and write
selecting appropriate transport layers
that report data gathered
the load of sampling
only at a single
report data gathered from
at a single tier
read and write sets
a single tier of
data gathered from remote
load of sampling and
c xors containing a
single tier of the
xors containing a data
tier of the system
functionality such as coordination
containing a data packet
gathered from remote sensors
a data packet do
of the system a
of sampling and improves
the system a set
such as coordination between
sampling and improves efficiency
as a baseline for
mb files from the
system a set of
data packet do not
and improves efficiency in
a baseline for comparison
as coordination between searchers
files from the local
a set of independent
memory used on sender
set of independent highly
packet do not have
of independent highly available
we also implemented a
do not have any
also implemented a timeout
from the local file
improves efficiency in reacting
the local file system
a datacenter would also
coordination between searchers can
used on sender and
not have any other
between searchers can remain
on sender and the
have any other data
searchers can remain active
independent highly available logs
efficiency in reacting to
local file system into
in reacting to accusations
sender and the number
reacting to accusations against
used in a novel
and the number of
in a novel manner
file system into the
the number of multicast
system into the mfs
to accusations against nodes
into the mfs file
datacenter would also host
any other data packet
would also host some
other data packet in
it reduces the probability
data packet in common
the mfs file system
can remain active even
number of multicast requests
remain active even if
all other entities may
of multicast requests in
other entities may fail
also host some kinds
entities may fail and
reduces the probability of
the resulting protocol effectively
multicast requests in progress
resulting protocol effectively has
may fail and can
global auditors are also
host some kinds of
the probability of inconsistency
some kinds of services
protocol effectively has a
kinds of services ill
auditors are also perfect
active even if connectivity
probability of inconsistency by
fail and can be
effectively has a rate
are also perfect candidates
has a rate of
even if connectivity to
also perfect candidates to
of inconsistency by limiting
matched to our model
inconsistency by limiting the
if connectivity to the
perfect candidates to perform
and can be replaced
connectivity to the data
candidates to perform membership
by limiting the life
to the data center
to perform membership tasks
can be replaced instantly
the data center is
limiting the life span
perform membership tasks such
the life span of
but because we are
life span of cache
data center is disrupted
membership tasks such as
be replaced instantly on
span of cache entries
replaced instantly on failure
token roundtrip time and
tasks such as acting
because we are working
such as acting as
roundtrip time and an
we are working with
as acting as entry
streams of video or
acting as entry points
we compare this method
of video or sensor
with each xor generated
video or sensor data
the architecture maintains consistency
or sensor data can
time and an average
compare this method against
are working with web
each xor generated from
working with web services
architecture maintains consistency even
xor generated from r
maintains consistency even in
this method against our
consistency even in the
sensor data can travel
and an average time
generated from r data
as entry points to
data can travel directly
even in the event
an average time to
method against our transactional
from r data packets
entry points to the
in the event of
points to the p
the event of false
average time to acknowledge
against our transactional cache
r data packets and
services running on the
can travel directly and
event of false suspicion
running on the ssa
our transactional cache by
data packets and each
on the ssa can
travel directly and won
transactional cache by measuring
the ssa can easily
cache by measuring its
directly and won t
by measuring its effectiveness
packets and each data
since they are required
and each data packet
reservations serve as suggestions
they are required to
and won t be
ssa can easily interact
time to acknowledge a
won t be delayed
each data packet included
serve as suggestions a
are required to have
as suggestions a reservation
can easily interact with
to acknowledge a message
t be delayed by
data packet included in
measuring its effectiveness with
packet included in c
its effectiveness with a
suggestions a reservation that
effectiveness with a varying
synchronous writeback asynchronous writeback
be delayed by the
live network streaming with
required to have full
network streaming with utilities
included in c xors
streaming with utilities and
to have full membership
with utilities and cost
writeback asynchronous writeback sirp
have full membership knowledge
easily interact with services
a reservation that is
with a varying time
reservation that is not
delayed by the need
that is not used
asynchronous writeback sirp c
is not used because
interact with services that
not used because of
by the need to
with services that employ
writeback sirp c sirp
utilities and cost ymir
services that employ other
and cost ymir vigfusson
the need to ricochet
used because of a
illustrates layered interleaving for
full membership knowledge of
layered interleaving for a
varying token circulation rate
because of a sluggish
that employ other solutions
need to ricochet off
membership knowledge of the
of a sluggish or
to ricochet off a
knowledge of the system
a sluggish or dead
ricochet off a remote
sluggish or dead owner
of the system for
or dead owner is
off a remote and
dead owner is ignored
the system for performing
a remote and potentially
system for performing their
remote and potentially inaccessible
both read and update
for performing their auditing
and potentially inaccessible server
read and update transactions
the independence of system
performing their auditing roles
and update transactions access
independence of system elements
of system elements allows
system elements allows for
elements allows for good
allows for good scalability
our experiment satisfies all
experiment satisfies all read
our second approach increased
second approach increased the
approach increased the amount
only transactions from the
global auditing monitors the
increased the amount of
transactions from the cache
due to the interdependence
auditing monitors the global
the amount of feedback
freedman school of computer
monitors the global health
school of computer science
staleness of version retrieved
the global health of
to the interdependence of
based interoperability standards are
the interdependence of the
consistency semantics the ssa
amount of feedback to
semantics the ssa implements
global health of the
the ssa implements stochastic
interdependence of the log
health of the system
iceland of computer science
of feedback to the
while passing all update
ssa implements stochastic consistency
passing all update transactions
interoperability standards are needed
all update transactions directly
of the system to
of the log contents
implements stochastic consistency semantics
feedback to the sender
update transactions directly to
the system to identify
transactions directly to the
directly to the backend
system to identify the
to the backend database
usa school of electronics
to identify the best
school of electronics engineering
of electronics engineering and
identify the best value
electronics engineering and computer
engineering and computer science
the best value for
has to be carefully
each cache server is
in our base implementation
cache server is unaware
to be carefully coordinated
best value for the
be carefully coordinated to
server is unaware of
carefully coordinated to maintain
we could lose access
an application will only
value for the minimum
coordinated to maintain consistency
is unaware of the
for the minimum upload
each aggregate ack contains
unaware of the other
the minimum upload threshold
aggregate ack contains a
minimum upload threshold at
we evaluate our architecture
ack contains a single
application will only observe
contains a single value
of the other servers
will only observe an
evaluate our architecture by
the other servers it
only observe an inconsistency
a single value maxcontiguous
observe an inconsistency if
upload threshold at any
an inconsistency if a
other servers it has
inconsistency if a fault
our architecture by simulation
if a fault occurs
could lose access to
servers it has its
threshold at any time
it has its own
architecture by simulation with
lose access to some
at any time during
has its own clients
by simulation with the
access to some of
any time during a
its own clients and
time during a streaming
own clients and communicates
and even then only
clients and communicates directly
simulation with the transactional
even then only for
during a streaming session
then only for a
and communicates directly with
only for a period
communicates directly with the
standard fec schemes can
representing the maximum number
to some of the
for a period of
the maximum number such
and makes final decisions
some of the sophisticated
makes final decisions regarding
directly with the backend
of the sophisticated proprietary
final decisions regarding punishment
maximum number such that
decisions regarding punishment of
fec schemes can be
number such that messages
the sophisticated proprietary interactive
schemes can be made
such that messages with
sophisticated proprietary interactive functionality
with the backend database
a period of time
department abstract the growth
regarding punishment of nodes
can be made resistant
that messages with this
we contrast the effectiveness
be made resistant to
the percentage of read
proprietary interactive functionality optimized
made resistant to a
contrast the effectiveness of
interactive functionality optimized for
resistant to a certain
period of time associated
abstract the growth in
the effectiveness of employing
messages with this and
functionality optimized for proprietary
to a certain loss
optimized for proprietary minibrowser
of time associated with
the growth in internet
effectiveness of employing prediction
synchronous writeback asynchronous writeback
only transactions can be
a certain loss burst
transactions can be arbitrarily
growth in internet traffic
time associated with our
in internet traffic associated
based solutions with an
internet traffic associated with
adaptive threshold strategies choosing
solutions with an embedded
of employing prediction and
with an embedded javascript
employing prediction and the
with this and all
certain loss burst length
can be arbitrarily high
traffic associated with video
loss burst length at
writeback asynchronous writeback sirp
associated with our repair
asynchronous writeback sirp c
this and all lower
writeback sirp c sirp
be arbitrarily high or
and all lower numbers
arbitrarily high or low
all lower numbers are
high or low in
threshold strategies choosing an
lower numbers are stable
burst length at the
prediction and the scalability
with our repair protocol
and the scalability of
peer communication can be
strategies choosing an upload
numbers are stable in
choosing an upload threshold
or low in this
an upload threshold requires
low in this situation
length at the cost
communication can be much
at the cost of
associated with video streaming
the scalability of acid
the cost of increased
are stable in the
cost of increased recovery
can be much harder
of increased recovery latency
with video streaming and
be much harder to
increased recovery latency for
upload threshold requires care
recovery latency for all
and only if it
latency for all lost
stable in the region
for all lost packets
cumulative proportion of reads
rain with other approaches
we can push the
only if it has
can push the percentage
a low threshold may
push the percentage up
much harder to use
video streaming and sharing
if it has the
streaming and sharing of
low threshold may not
and sharing of videos
it has the bad
threshold may not be
harder to use than
may not be sufficient
sharing of videos is
to use than relaying
of videos is so
has the bad luck
use than relaying data
including smaller bursts and
the bad luck to
smaller bursts and singleton
our simulation focuses on
bad luck to query
to increase the amount
not be sufficient to
than relaying data through
tm m om i
videos is so rapid
bursts and singleton drops
simulation focuses on just
luck to query a
increase the amount of
to query a node
be sufficient to identify
query a node impacted
is so rapid that
sufficient to identify opportunistic
so rapid that it
the amount of feedback
to identify opportunistic nodes
focuses on just a
a node impacted by
rapid that it may
on just a single
node impacted by the
that it may soon
impacted by the failure
just a single cache
layered interleaving provides graceful
it may soon dwarf
a single cache it
we permit ack to
may soon dwarf all
while high thresholds may
permit ack to contain
single cache it would
high thresholds may incorrectly
ack to contain up
cache it would behave
this window can be
to contain up to
soon dwarf all other
interleaving provides graceful degradation
thresholds may incorrectly punish
om n om i
relaying data through a
it would behave the
provides graceful degradation in
would behave the same
dwarf all other forms
behave the same had
window can be made
the same had there
contain up to k
same had there been
may incorrectly punish correct
up to k numeric
graceful degradation in the
to k numeric ranges
all other forms of
had there been many
data through a hosted
there been many cache
can be made small
through a hosted service
degradation in the face
incorrectly punish correct nodes
a hosted service that
in the face of
staleness of version retrieved
other forms of internet
hosted service that uses
been many cache servers
the face of bursty
service that uses an
forms of internet content
face of bursty loss
of version retrieved read
log i log n
we considered different strategies
i log n figure
of bursty loss for
considered different strategies for
that uses an enterprise
so that applications are
different strategies for the
version retrieved read staleness
that applications are unlikely
one reason for this
uses an enterprise service
bursty loss for constant
an enterprise service bus
retrieved read staleness at
loss for constant encoding
reason for this is
strategies for the choice
schematic structure of acid
applications are unlikely to
cache can be used
for this is that
for constant encoding overhead
for the choice of
are unlikely to observe
this is that only
can be used with
unlikely to observe a
the choice of the
is that only some
constant encoding overhead singleton
tms access multiple objects
to observe a problem
access multiple objects per
choice of the minimum
multiple objects per transaction
encoding overhead singleton random
of the minimum contribution
gc test rw test
overhead singleton random losses
the minimum contribution t
that only some forms
be used with any
minimum contribution t hreshold
objects are managed by
singleton random losses are
are managed by oms
used with any transactional
random losses are recovered
only some forms of
or permitted to grow
with any transactional backend
contribution t hreshold used
any transactional backend and
some forms of content
t hreshold used for
the lack of a
permitted to grow somewhat
transactional backend and any
forms of content can
to grow somewhat larger
backend and any transactional
lack of a one
and any transactional workload
of content can be
cumulative proportion of reads
losses are recovered as
proportion of reads cumulative
content can be cached
are recovered as quickly
hreshold used for identifying
recovered as quickly as
of reads cumulative proportion
as quickly as possible
reads cumulative proportion of
used for identifying misbehaving
of a one size
is falsely suspected to
a one size fits
data generated in real
falsely suspected to have
generated in real time
depending upon the cost
cumulative proportion of reads
upon the cost of
one size fits all
only transactions will be
suspected to have failed
transactions will be similar
for identifying misbehaving nodes
by xors generated with
the cost of inconsistency
xors generated with an
in real time such
will be similar to
size fits all publish
be similar to non
generated with an interleave
real time such as
and replaced by omi
cost of inconsistency and
with an interleave of
time such as by
the simplest strategy sets
of inconsistency and the
such as by live
simplest strategy sets a
inconsistency and the relative
as by live video
the underlying database is
strategy sets a fixed
subscribe substrate forces the
sets a fixed threshold
by live video broadcasts
underlying database is only
and the relative value
database is only accessed
substrate forces the developers
is only accessed on
only accessed on cache
and each successive layer
the system can now
causing them to concurrently
accessed on cache misses
system can now cleanup
each successive layer of
iptv or new episodes
can now cleanup message
them to concurrently serve
forces the developers to
to concurrently serve the
successive layer of xors
concurrently serve the same
the developers to become
layer of xors generated
or new episodes of
serve the same objects
of xors generated at
new episodes of popular
developers to become familiar
now cleanup message sequences
inconsistencies may be observed
episodes of popular tv
cleanup message sequences that
of popular tv shows
to become familiar with
xors generated at a
oms are backed by
become familiar with and
are backed by highlyavailable
message sequences that have
backed by highlyavailable logs
generated at a higher
familiar with and choose
of faster response time
sequences that have as
at a higher interleave
we will use synthetic
with and choose between
faster response time versus
that have as gaps
and choose between a
response time versus lower
where they store tentative
choose between a range
they store tentative transaction
between a range of
will use synthetic workloads
a range of different
immersive virtual reality applications
a higher interleave catches
messages that are still
time versus lower risk
that are still unstable
use synthetic workloads so
versus lower risk of
store tentative transaction entries
lower risk of an
range of different and
virtual reality applications and
synthetic workloads so we
reality applications and games
higher interleave catches larger
applications and games typically
risk of an observed
of different and incompatible
tentative transaction entries for
workloads so we can
transaction entries for serialization
interleave catches larger bursts
so we can evaluate
different and incompatible options
and games typically can
we can evaluate how
of an observed fault
can evaluate how much
games typically can t
catches larger bursts missed
evaluate how much inconsistency
independent of the current
how much inconsistency can
in the experiment shown
much inconsistency can be
typically can t be
the experiment shown in
of the current state
experiment shown in figures
the current state of
can t be cached
inconsistency can be observed
larger bursts missed by
an wrong choice of
synchronous writeback asynchronous writeback
wrong choice of transport
in the experimental work
current state of the
can be observed as
state of the system
t be cached at
writeback asynchronous writeback sirp
choice of transport could
asynchronous writeback sirp c
bursts missed by the
of transport could result
gw test rc test
transport could result in
the experimental work that
writeback sirp c sirp
be observed as a
missed by the previous
be cached at all
could result in degraded
experimental work that follows
observed as a function
and in today s
system structure the structure
result in degraded qos
by the previous layer
in today s systems
as a function of
any node contributing at
a function of the
structure the structure of
each client may pull
node contributing at a
function of the amount
client may pull such
we measure these windows
we set k to
contributing at a rate
measure these windows for
at a rate of
may pull such information
the implementation of this
set k to the
implementation of this algorithm
of the amount of
a rate of less
the amount of clustering
these windows for scenarios
amount of clustering in
k to the number
of clustering in the
or even data loss
pull such information on
rate of less than
the structure of the
windows for scenarios representative
of this algorithm is
to the number of
this algorithm is simple
such information on its
structure of the system
clustering in the workload
of the system is
the number of partitions
the system is illustrated
information on its own
for scenarios representative of
algorithm is simple and
system is illustrated in
on its own point
is simple and shown
scenarios representative of conditions
simple and shown in
this also allows us
and shown in figure
representative of conditions that
also allows us to
is illustrated in figure
second life as a
of the stream rate
life as a soc
staleness of version retrieved
as a soc application
allows us to look
a soc application up
of conditions that arise
soc application up to
while the amount of
conditions that arise in
us to look at
that arise in realistic
application up to now
arise in realistic settings
the amount of acknowledged
stream directly from the
to look at the
amount of acknowledged data
a set of repair
directly from the data
at the base of
the stream rate would
look at the dynamic
stream rate would be
at the dynamic behavior
from the data center
the base of acid
we have focused on
set of repair bins
rate would be removed
of repair bins is
of acknowledged data is
repair bins is maintained
have focused on a
bins is maintained for
even if large numbers
focused on a small
acknowledged data is reduced
rain are a set
the dynamic behavior of
are a set of
is maintained for each
a set of independent
maintained for each layer
set of independent highly
staleness of reader file
relative speedup relative speedup
dynamic behavior of the
if large numbers of
but our longer term
large numbers of clients
one downside of using
of reader file accesses
speedup relative speedup relative
the ssa framework the
relative speedup relative speedup
data is reduced by
available logs that together
with i bins for
our longer term goal
i bins for a
downside of using a
bins for a layer
ssa framework the basic
for a layer with
of using a fixed
framework the basic operation
a layer with interleave
behavior of the system
the basic operation of
numbers of clients share
cumulative distributions for the
longer term goal is
layer with interleave i
term goal is to
logs that together describe
goal is to support
using a fixed threshold
that together describe the
of clients share interest
together describe the state
basic operation of the
is to support a
when the amount of
a repair bin consists
a fixed threshold is
repair bin consists of
describe the state of
operation of the ssa
the state of the
of the ssa is
state of the entire
clients share interest in
of the entire system
share interest in at
fixed threshold is that
distributions for the staleness
to support a large
threshold is that opportunistic
the ssa is as
bin consists of a
uniform priorities async relative
ssa is as follows
for the staleness of
and the overall throughput
the staleness of all
interest in at least
the overall throughput is
consists of a partially
each log is accessed
of a partially constructed
log is accessed through
scale nextgeneration collaboration system
is accessed through an
in at least some
overall throughput is actually
priorities async relative speedup
as queries or updates
throughput is actually lower
a partially constructed repair
staleness of all accesses
partially constructed repair packet
accessed through an object
nextgeneration collaboration system similar
through an object manager
is that opportunistic nodes
collaboration system similar to
queries or updates are
is actually lower because
at least some aspects
of all accesses to
actually lower because token
async relative speedup gc
system similar to second
relative speedup gc test
or updates are received
least some aspects of
the amount of clustering
an xor and the
all accesses to files
lower because token processing
accesses to files by
similar to second life
to files by the
that caches the data
files by the three
xor and the recipe
by the three readers
because token processing becomes
and the recipe list
updates are received in
amount of clustering and
caches the data and
that opportunistic nodes that
the three readers are
some aspects of the
three readers are shown
opportunistic nodes that learn
a virtual reality immersion
are received in the
of clustering and the
virtual reality immersion system
received in the cluster
token processing becomes more
the recipe list of
processing becomes more costly
the data and provides
clustering and the clustering
aspects of the data
reality immersion system created
nodes that learn the
higher curves represent less
they are passed through
that learn the threshold
and the clustering formation
immersion system created by
the clustering formation change
we propose a new
curves represent less staleness
propose a new system
data and provides the
a new system called
recipe list of identifiers
system created by linden
clustering formation change over
created by linden labs
formation change over time
the system becomes unstable
new system called g
list of identifiers of
system called g radient
are passed through a
of identifiers of data
total writer execution time
and provides the data
called g radient aimed
learn the threshold can
identifiers of data packets
notice the large variances
of data packets that
g radient aimed at
passed through a partition
the threshold can simply
we will look at
through a partition mapping
second life is implemented
will look at workloads
provides the data structure
look at workloads based
life is implemented with
data packets that compose
radient aimed at reducing
is implemented with a
aimed at reducing the
the large variances in
implemented with a data
the data structure abstraction
at workloads based on
a partition mapping component
workloads based on amazon
at reducing the load
threshold can simply contribute
large variances in figure
with a data center
data structure abstraction exporting
packets that compose the
structure abstraction exporting read
that compose the xor
which directs the request
based on amazon s
directs the request to
reducing the load on
abstraction exporting read and
can simply contribute at
exporting read and write
on amazon s product
read and write operations
the load on providers
synchronous writeback asynchronous writeback
load on providers of
simply contribute at the
writeback asynchronous writeback sirp
amazon s product co
asynchronous writeback sirp c
each intercepted data packet
on providers of such
the request to an
intercepted data packet is
request to an appropriate
writeback sirp c sirp
data packet is added
contribute at the lowest
which are managed by
packet is added to
at the lowest possible
providers of such and
a data center including
to an appropriate racs
purchasing and orkut s
are managed by transaction
is added to each
managed by transaction managers
the lowest possible upload
added to each layer
data center including a
and orkut s social
of such and enabling
because our flow control
lowest possible upload factor
our flow control scheme
orkut s social network
such and enabling scalable
we will use the
center including a large
to each layer where
will use the term
including a large number
bandwidthsensitive streaming service for
s social network to
use the term subservice
social network to see
each layer where adding
network to see how
a large number of
layer where adding to
the term subservice rather
where adding to a
based on limiting the
adding to a layer
streaming service for heterogeneous
large number of servers
tms provide the atomic
number of servers storing
to see how much
of servers storing the
on limiting the amount
servers storing the state
to a layer simply
limiting the amount of
provide the atomic transaction
from the graphs in
see how much inconsistency
service for heterogeneous consumers
storing the state of
term subservice rather than
a layer simply means
the amount of unacknowledged
layer simply means choosing
amount of unacknowledged data
how much inconsistency t
the state of the
subservice rather than racs
the core of the
the atomic transaction abstraction
core of the system
the graphs in section
of the system is
rather than racs in
synchronous writeback asynchronous writeback
simply means choosing a
writeback asynchronous writeback sirp
the system is an
means choosing a repair
system is an overlay
state of the virtual
they receive instructions from
than racs in the
while the sender can
receive instructions from clients
choosing a repair bin
instructions from clients to
of the virtual world
from clients to start
cache can detect as
clients to start and
racs in the remainder
can detect as a
a repair bin from
detect as a function
repair bin from the
as a function of
to start and end
a function of dependency
start and end a
in the remainder of
the sender can cleanup
the remainder of the
bin from the layer
sender can cleanup any
asynchronous writeback sirp c
can cleanup any portion
writeback sirp c sirp
and end a transaction
it is clear that
remainder of the paper
is an overlay networking
is clear that such
an overlay networking architecture
function of dependency list
overlay networking architecture intended
cleanup any portion of
networking architecture intended to
the locations of all
any portion of the
of dependency list length
portion of the message
and operations to perform
architecture intended to run
from the layer s
locations of all users
the layer s set
of the message sequence
to create a subservice
operations to perform on
intended to run directly
clear that such a
and compare this with
to perform on individual
compare this with a
create a subservice the
that such a stretagy
receivers have to deliver
a subservice the developer
incrementally updating the xor
this with a ttl
subservice the developer must
perform on individual objects
such a stretagy may
on individual objects within
to run directly on
individual objects within the
run directly on a
the developer must first
have to deliver in
a stretagy may disrupt
to deliver in fifo
directly on a content
stretagy may disrupt the
on a content hosting
developer must first implement
may disrupt the streaming
deliver in fifo order
disrupt the streaming session
a content hosting platform
we are also interested
objects within the transaction
are also interested in
updating the xor with
also interested in overhead
and which optimizes aggregate
the xor with the
which optimizes aggregate bandwidth
must first implement a
xor with the new
optimizes aggregate bandwidth use
the amount of data
with the new data
amount of data they
the new data packet
particularly the additional load
of data they cache
aggregate bandwidth use by
the additional load on
first implement a non
then move about and
the tms predict which
bandwidth use by transforming
tms predict which objects
choosing a high threshold
predict which objects it
move about and interact
data they cache is
use by transforming in
about and interact with
they cache is larger
a high threshold is
and interact with others
and adding the data
additional load on the
which objects it is
flight data to match
load on the backend
high threshold is not
adding the data packet
threshold is not a
data to match the
relative speedup relative speedup
on the backend database
speedup relative speedup relative
the data packet s
relative speedup relative speedup
and this reduces their
data packet s header
objects it is likely
packet s header to
it is likely to
this is then cloned
this reduces their ability
the backend database that
is not a practical
backend database that could
s header to the
is likely to access
header to the recipe
reduces their ability to
to the recipe list
not a practical option
one can create a
database that could form
can create a cybercaf
and reserve these object
that could form if
reserve these object versions
to match the ideal
their ability to accept
a counter is incremented
could form if the
match the ideal stream
since correct nodes would
the ideal stream quality
ability to accept incoming
correct nodes would get
is then cloned using
form if the the
ideal stream quality expressed
counter is incremented as
to accept incoming traffic
is incremented as each
they speculatively perform each
then cloned using the
stream quality expressed as
nodes would get unfairly
cloned using the ssa
incremented as each data
speculatively perform each operation
as each data packet
if the the rate
perform each operation with
using the ssa platform
each operation with the
quality expressed as an
each data packet arrives
would get unfairly punished
data packet arrives at
notice the linkage to
packet arrives at the
operation with the help
arrives at the appliance
expressed as an economic
with the help of
as an economic utility
the linkage to memory
the help of the
to avoid this problem
the the rate of
an economic utility of
as other second life
each replica is placed
help of the appropriate
the rate of cache
economic utility of the
other second life users
and choosing the repair
second life users enter
of the appropriate oms
life users enter the
utility of the consuming
the appropriate oms and
of the consuming client
we have explored adaptive
choosing the repair bin
rate of cache misses
users enter the room
of cache misses increases
appropriate oms and according
the growth in memory
oms and according to
the repair bin from
and according to the
introduction recent years have
according to the order
replica is placed on
have explored adaptive strategies
is placed on a
repair bin from the
placed on a separate
they can interact with
bin from the layer
growth in memory occurs
recent years have seen
from the layer s
years have seen skyrocketing
b presented three strategies
the layer s set
one simple strategy starts
in memory occurs on
to the order set
have seen skyrocketing demand
can interact with the
on a separate node
presented three strategies for
layer s set is
three strategies for responding
memory occurs on the
strategies for responding to
seen skyrocketing demand for
occurs on the receivers
simple strategy starts with
s set is done
the order set by
interact with the environment
order set by the
with the environment and
and the replicas are
the environment and one
set is done by
the replicas are then
skyrocketing demand for internet
set by the reservations
strategy starts with a
but the pattern is
starts with a minimum
is done by taking
with a minimum threshold
replicas are then linked
for responding to inconsistency
the pattern is similar
are then linked using
done by taking the
responding to inconsistency detection
then linked using tcp
by taking the modulo
demand for internet bandwidth
pattern is similar to
in the second life
linked using tcp to
taking the modulo of
they certify the transaction
for both the synthetic
the modulo of the
increasingly dominated by real
certify the transaction by
modulo of the counter
average reader execution time
of the counter with
both the synthetic and
the second life architecture
the synthetic and realistic
the transaction by checking
synthetic and realistic workloads
time streaming of short
the counter with the
using tcp to create
counter with the number
transaction by checking for
tcp to create a
is similar to what
whenever an avatar moves
by checking for conflicts
an avatar moves or
with the number of
avatar moves or performs
the number of bins
moves or performs some
checking for conflicts in
or performs some action
similar to what we
performs some action in
but in many forms
to what we saw
to create a chain
what we saw earlier
we compare the efficacy
some action in the
compare the efficacy of
number of bins in
for conflicts in each
the efficacy of the
conflicts in each log
efficacy of the three
action in the virtual
of the three strategies
of bins in each
merely having more cached
bins in each layer
in the virtual world
having more cached data
more cached data is
cached data is enough
if trends continue then
data is enough to
trends continue then internet
for a layer with
continue then internet video
synthetic workloads synthetic workloads
is enough to slow
a layer with interleave
enough to slow them
workloads synthetic workloads allow
to slow them down
a request describing this
then internet video alone
synthetic workloads allow us
internet video alone will
membership monitors are in
workloads allow us to
request describing this event
allow us to understand
video alone will generate
us to understand the
alone will generate almost
to understand the efficacy
describing this event is
understand the efficacy of
increasing it only if
we therefore have a
monitors are in charge
this event is passed
are in charge of
exabytes per month by
token roundtrip time increases
the efficacy of t
it only if the
in charge of deciding
per month by the
event is passed to
the xth intercepted packet
only if the system
xth intercepted packet is
month by the end
is passed to the
charge of deciding and
cache as a function
if the system is
intercepted packet is added
by the end of
passed to the hosting
of deciding and publishing
to the hosting data
the system is compromised
the hosting data center
packet is added to
as a function of
is added to the
a function of clustering
mapping between a subservice
hosting data center and
deciding and publishing which
this delays state aggregation
and publishing which machines
data center and processed
publishing which machines perform
for the experiments described
center and processed by
which machines perform which
the experiments described here
and processed by servers
global auditors sample the
between a subservice and
increases pending messages and
auditors sample the system
machines perform which roles
processed by servers running
a subservice and a
pending messages and reduces
subservice and a chain
execution times for concurrent
by servers running there
cache with a maximum
sample the system to
messages and reduces throughput
times for concurrent access
percent of all internet
for concurrent access trace
of all internet traffic
the system to identify
with a maximum of
namely which machines run
system to identify the
reader execution times are
which machines run the
execution times are averages
to identify the average
times are averages for
clients do perform a
elements per dependency list
machines run the log
are averages for the
identify the average download
when a repair bin
the average download factor
run the log and
averages for the three
do perform a variety
a repair bin fills
the log and model
perform a variety of
repair bin fills up
log and model and
for the three readers
faced with a competitive
and model and goal
a variety of decoding
and if this factor
with a competitive landscape
variety of decoding and
describes synthetic workload generation
bin fills up its
gossip based chain replication
if this factor is
based chain replication the
higher bandwidth results in
fills up its recipe
bandwidth results in less
of decoding and rendering
up its recipe list
decoding and rendering functions
model and goal we
and rendering functions locally
results in less staleness
and goal we assume
chain replication the replication
goal we assume unreliable
isps and content providers
this factor is lower
replication the replication scheme
we assume unreliable servers
and content providers are
its recipe list contains
content providers are exploring
factor is lower than
providers are exploring technologies
the replication scheme has
are exploring technologies to
assume unreliable servers that
exploring technologies to help
more aggressive cleanup with
technologies to help satisfy
recipe list contains r
aggressive cleanup with o
measures how many inconsistencies
performance of prioritised rpc
replication scheme has evolved
of prioritised rpc with
unreliable servers that may
to help satisfy the
servers that may crash
list contains r data
how many inconsistencies we
since writes can be
scheme has evolved out
writes can be sent
but the data center
has evolved out of
that may crash or
feedback in the token
the data center must
in the token and
can be sent to
help satisfy the growing
be sent to the
may crash or hang
evolved out of the
many inconsistencies we can
prioritised rpc with respect
data center must be
the token and in
center must be in
satisfy the growing demand
sent to the file
the growing demand alongside
to the file server
growing demand alongside the
the file server faster
demand alongside the purchase
must be in the
alongside the purchase of
inconsistencies we can detect
be in the loop
contains r data packets
token and in acks
out of the chain
the purchase of expensive
of the chain replication
we can detect as
the chain replication mechanism
r data packets it
chain replication mechanism first
purchase of expensive infrastructure
replication mechanism first introduced
can detect as a
mechanism first introduced in
once the download factor
detect as a function
data packets it fires
as a function of
rpc with respect to
a function of clustering
with respect to bandwidth
function of clustering and
respect to bandwidth variation
of clustering and section
to accommodate reliable storage
clustering and section v
the download factor reaches
sirp is most effective
reducing the bandwidth consumption
download factor reaches a
each pair of graphs
a repair packet is
factor reaches a satisfactory
the bandwidth consumption of
is most effective at
pair of graphs in
more work with o
of graphs in shows
reaches a satisfactory level
bandwidth consumption of simultaneous
most effective at reducing
a satisfactory level again
effective at reducing staleness
repair packet is generated
graphs in shows the
considers clustering changes over
in shows the speedup
in the loop to
packet is generated consisting
consumption of simultaneous replicated
the loop to ensure
is generated consisting of
the original scheme was
loop to ensure that
generated consisting of the
as explained in section
though many reads return
original scheme was developed
many reads return out
of simultaneous replicated content
shows the speedup of
to ensure that all
and lower rates despite
clustering changes over time
lower rates despite saving
scheme was developed as
rates despite saving on
the speedup of one
was developed as a
ensure that all users
date file contents when
simultaneous replicated content is
developed as a means
replicated content is a
speedup of one of
content is a challenge
of one of three
is a challenge which
one of three cache
consisting of the xor
the threshold may be
of the xor and
file contents when compared
threshold may be reduced
contents when compared to
a challenge which usually
when compared to the
challenge which usually leverages
despite saving on memory
the xor and the
that all users observe
xor and the recipe
all users observe consistent
compares the efficacy of
users observe consistent state
the system exposes a
as a means of
system exposes a transactional
which usually leverages two
may be reduced back
a means of obtaining
and the recipe list
the efficacy of various
compared to the optimal
means of obtaining high
to the optimal version
of three cache manager
be reduced back to
of obtaining high throughput
usually leverages two main
reduced back to its
leverages two main tools
exposes a transactional data
when the number of
the recipe list and
the number of users
obtaining high throughput and
three cache manager configurations
back to its initial
high throughput and availability
efficacy of various approaches
throughput and availability for
caching of content and
number of users in
relative to the time
to its initial value
memory overheads on the
recipe list and is
more sirp reads are
overheads on the receiver
sirp reads are up
and availability for query
on the receiver the
of users in a
to the time taken
of various approaches to
the time taken by
list and is scheduled
time taken by uniform
a transactional data store
taken by uniform priorities
the receiver the reader
by uniform priorities with
users in a scenario
uniform priorities with synchronous
receiver the reader may
priorities with synchronous rpcs
this stepwise approach allows
transactional data store supporting
various approaches to dealing
stepwise approach allows the
approaches to dealing with
and is scheduled for
to dealing with detected
approach allows the system
is scheduled for sending
compared to synchronous or
of content and multicasting
allows the system to
in a scenario isn
availability for query and
the system to catch
dealing with detected inconsistencies
the reader may doubt
system to catch opportunistic
while the repair bin
reader may doubt that
the repair bin is
may doubt that memory
for query and update
to synchronous or asynchronous
query and update requests
synchronous or asynchronous writeback
and update requests without
to catch opportunistic nodes
update requests without sacrificing
repair bin is re
requests without sacrificing strong
catch opportunistic nodes in
allowing higher degrees of
a scenario isn t
some forms of video
scenario isn t huge
data store supporting serializable
without sacrificing strong consistency
store supporting serializable transactions
higher degrees of staleness
sacrificing strong consistency guarantees
doubt that memory overhead
forms of video content
with synchronous rpcs at
initialized with an empty
opportunistic nodes in case
with an empty recipe
that memory overhead on
nodes in case their
second life can easily
an empty recipe list
a client invokes a
empty recipe list and
life can easily keep
recipe list and blank
in case their presence
list and blank xor
can easily keep up
client invokes a begin
more reads performed with
memory overhead on receivers
reads performed with sirp
our basic synthetic workload
case their presence starts
basic synthetic workload is
easily keep up using
synthetic workload is constructed
performed with sirp are
keep up using a
with sirp are within
the gossip based chain
up using a standard
such as downloads of
workload is constructed as
as downloads of unencrypted
is constructed as follows
versions of the optimal
their presence starts affecting
gossip based chain replication
using a standard workload
as well as uniform
downloads of unencrypted movies
well as uniform priorities
a standard workload partitioning
as uniform priorities and
based chain replication behaves
standard workload partitioning scheme
with this bandwidth level
presence starts affecting the
chain replication behaves in
incoming repair packets are
uniform priorities and synchronous
overhead on receivers is
of unencrypted movies or
synchronous and asynchronous writeback
starts affecting the performance
replication behaves in the
repair packets are processed
priorities and synchronous rpcs
a field from a
on receivers is the
field from a table
and asynchronous writeback coincide
affecting the performance of
behaves in the following
workload partitioning scheme in
packets are processed as
in the following manner
are processed as follows
asynchronous writeback coincide in
the following manner during
the performance of the
partitioning scheme in which
performance of the system
unencrypted movies or films
writeback coincide in performance
movies or films where
the graphs also show
or films where many
graphs also show curves
if all the data
also show curves for
scheme in which different
show curves for differentiated
all the data packets
curves for differentiated priorities
films where many users
for differentiated priorities and
where many users will
while avoiding incorrect accusations
many users will share
the data packets contained
avoiding incorrect accusations of
following manner during normal
data packets contained in
receivers is the real
in which different servers
is the real issue
since they are constrained
differentiated priorities and synchronous
incorrect accusations of correct
manner during normal operation
accusations of correct nodes
during normal operation when
which different servers handle
setting the value of
normal operation when nodes
priorities and synchronous rpcs
packets contained in the
users will share the
they are constrained by
will share the same
considering that their cpus
are constrained by the
the value of a
we also considered a
different servers handle different
share the same encryption
operation when nodes aren
that their cpus are
when nodes aren t
contained in the repair
nodes aren t failing
value of a field
and differentiated priorities and
servers handle different portions
the same encryption key
handle different portions of
their cpus are half
different portions of the
also considered a second
aren t failing or
in the repair s
t failing or restarting
differentiated priorities and asynchronous
the repair s recipe
priorities and asynchronous rpcs
considered a second adaptive
of a field in
constrained by the bandwidth
a field in a
by the bandwidth bottleneck
field in a table
the bandwidth bottleneck and
update operations are forwarded
bandwidth bottleneck and send
a second adaptive strategy
bottleneck and send updates
repair s recipe list
a wide variety of
s recipe list have
portions of the virtual
recipe list have been
of the virtual world
operations are forwarded to
wide variety of caching
and send updates in
variety of caching options
send updates in the
the values plotted for
updates in the same
are forwarded to the
in the same order
finally the client invokes
list have been received
the client invokes the
of caching options exist
forwarded to the head
the objects are divided
have been received successfully
can increasing memory consumption
values plotted for bandwidth
by suppressing unnecessary invalidations
plotted for bandwidth of
to the head of
client invokes the endtransaction
the head of the
invokes the endtransaction command
for computing the threshold
for example because large
sirp reduces its bandwidth
increasing memory consumption affect
computing the threshold based
memory consumption affect a
objects are divided into
and the system responds
example because large numbers
are divided into clusters
the repair packet is
the threshold based on
repair packet is discarded
reduces its bandwidth usage
head of the chain
its bandwidth usage and
s are the same
bandwidth usage and achieves
consumption affect a half
threshold based on periodically
the system responds with
because large numbers of
where the request is
of which is the
are the same as
which is the akamai
the same as shown
is the akamai content
same as shown in
system responds with either
large numbers of users
responds with either a
usage and achieves a
with either a commit
and achieves a small
either a commit or
achieves a small improvement
as shown in table
a small improvement over
numbers of users want
small improvement over sirp
based on periodically sampled
of users want to
if the repair s
we performed an experiment
the akamai content distribution
performed an experiment with
the request is processed
users want to enter
due to the overhead
divided into clusters of
want to enter the
the repair s recipe
to enter the same
since devoting less bandwidth
repair s recipe list
devoting less bandwidth to
on periodically sampled download
less bandwidth to invalidations
a commit or an
periodically sampled download and
commit or an abort
request is processed using
to the overhead of
s recipe list contains
into clusters of size
recipe list contains a
akamai content distribution network
enter the same virtual
sampled download and upload
committed transactions form a
the overhead of priorities
transactions form a serializable
list contains a single
the same virtual discotheque
is processed using the
is arguably the most
bandwidth to invalidations results
arguably the most famous
form a serializable execution
contains a single missing
download and upload factors
a single missing data
overhead of priorities for
in which we vary
the servers can become
to invalidations results in
single missing data packet
invalidations results in data
processed using the local
which we vary the
servers can become overwhelmed
of priorities for small
tms are equipped with
the average download factors
are equipped with predictors
recovery can occur immediately
can become overwhelmed and
equipped with predictors that
results in data reaching
multicast techniques can reduce
with predictors that foresee
average download factors once
predictors that foresee which
can occur immediately by
become overwhelmed and are
using the local replica
in data reaching the
overwhelmed and are forced
priorities for small rpcs
techniques can reduce the
and are forced to
can reduce the overall
we vary the number
reduce the overall network
for small rpcs mentioned
vary the number of
small rpcs mentioned in
are forced to reject
the state changes are
that foresee which objects
forced to reject some
state changes are passed
the number of receivers
rpcs mentioned in section
data reaching the server
number of receivers that
reaching the server faster
download factors once again
to reject some of
changes are passed along
reject some of the
foresee which objects a
are passed along down
some of the users
which objects a transaction
of receivers that cache
of the users or
asynchronous writeback performs as
the users or reduce
writeback performs as well
factors once again are
the overall network traffic
receivers that cache a
once again are used
objects a transaction is
users or reduce their
a transaction is likely
or reduce their frame
overall network traffic by
passed along down the
network traffic by taking
that cache a copy
traffic by taking advantage
along down the chain
by taking advantage of
transaction is likely to
taking advantage of the
again are used for
is likely to access
comparing the execution time
rendering rates and resolution
the execution time of
advantage of the packet
execution time of the
likely to access on
are used for detecting
down the chain to
performs as well as
cache a copy of
of the packet replication
time of the foreground
the packet replication and
of the foreground workloads
as well as sirp
the foreground workloads with
a copy of each
to access on its
copy of each message
packet replication and forwarding
the chain to the
replication and forwarding within
second life might seem
used for detecting whether
life might seem jumpy
foreground workloads with synchronous
synchronous writeback continues to
for detecting whether the
access on its initiation
might seem jumpy and
and forwarding within the
seem jumpy and unrealistic
forwarding within the network
writeback continues to underperform
within the network infrastructure
replication factor in figure
detecting whether the threshold
workloads with synchronous writes
chain to the next
whether the threshold should
this is because the
second life as a
to the next element
update logging and asynchronous
the threshold should be
is because the progress
life as a live
because the progress of
logging and asynchronous writeback
threshold should be varied
and asynchronous writeback reveals
as a live objects
asynchronous writeback reveals that
the deployment of the
which in turn updates
the progress of writers
writeback reveals that the
should be varied or
reveals that the latter
a live objects application
that the latter two
in turn updates it
the latter two options
deployment of the efficient
turn updates it s
of the efficient network
live objects application poses
progress of writers using
objects application poses some
of writers using asynchronous
application poses some new
increasing this value results
updates it s state
latter two options generally
be varied or not
in an implementation of
writers using asynchronous writeback
poses some new challenges
using asynchronous writeback schemes
it s state and
two options generally perform
an implementation of the
options generally perform comparably
s state and performs
generally perform comparably to
implementation of the system
perform comparably to or
state and performs the
of the system one
this value results in
comparably to or better
the system one may
to or better than
and performs the same
system one may use
and there are two
one may use multiple
on the one hand
may use multiple oms
our initial threshold is
performs the same operation
asynchronous writeback schemes is
or better than synchronous
writeback schemes is less
better than synchronous writes
schemes is less constrained
initial threshold is set
the same operation until
threshold is set to
value results in a
logging and asynchronous writeback
is less constrained by
results in a linear
less constrained by the
there are two types
same operation until the
is set to null
operation until the tail
area internet has failed
and asynchronous writeback greatly
many aspects of the
asynchronous writeback greatly improve
in a linear increase
writeback greatly improve the
aspects of the application
greatly improve the performance
until the tail is
of the application can
are two types of
use multiple oms per
a linear increase of
multiple oms per log
constrained by the bandwidth
the tail is reached
and so more expensive
the application can be
two types of workloads
improve the performance of
application can be addressed
the performance of the
and the threshold is
performance of the background
and they can overlap
the threshold is chosen
they can overlap computation
linear increase of memory
can overlap computation and
can be addressed in
increase of memory usage
so more expensive application
of memory usage on
queries can either be
memory usage on receivers
dividing the log s
overlap computation and fetching
the log s object
computation and fetching file
of the background workloads
and fetching file contents
level overlays are generally
fetching file contents with
log s object set
can either be directed
be addressed in the
threshold is chosen from
either be directed towards
addressed in the same
is chosen from sampled
as has been noted
be directed towards a
chosen from sampled upload
or the other way
directed towards a randomly
from sampled upload factors
in the same manner
has been noted previously
overlays are generally used
file contents with writeback
if memory overheads were
the other way around
memory overheads were not
towards a randomly selected
the same manner we
clustering is perfect and
overheads were not a
rather than simply being
a randomly selected process
have multiple logs report
is perfect and each
were not a significant
than simply being a
same manner we ve
simply being a selfinterested
multiple logs report to
not a significant issue
logs report to a
layer with interleave of
a significant issue on
manner we ve outlined
significant issue on half
we ve outlined for
perfect and each transaction
if the system seems
we focus on mfs
report to a single
and each transaction chooses
to a single om
ve outlined for the
randomly selected process in
being a selfinterested optimisation
focus on mfs with
selected process in the
a selfinterested optimisation by
on mfs with asynchronous
each transaction chooses a
mfs with asynchronous writeback
the devices used by
the choice depends on
devices used by content
outlined for the search
used by content subscribers
for the search and
by content subscribers have
we would expect performance
content subscribers have become
selfinterested optimisation by writers
the system seems to
choice depends on the
system seems to be
depends on the throughput
the search and rescue
with asynchronous writeback in
search and rescue application
would expect performance to
optimisation by writers to
transaction chooses a single
process in the group
seems to be in
on the throughput of
subscribers have become increasingly
asynchronous writeback in the
expect performance to remain
writeback in the rest
by writers to improve
in the rest of
writers to improve their
to be in a
the throughput of the
have become increasingly heterogeneous
throughput of the specific
become increasingly heterogeneous mobile
chooses a single cluster
in the group or
the rest of this
a single cluster and
be in a compromised
one could use microsoft
in a compromised state
could use microsoft virtual
increasingly heterogeneous mobile devices
use microsoft virtual earth
the group or to
rest of this paper
single cluster and chooses
performance to remain unchanged
of the specific implementations
to improve their own
group or to a
improve their own performance
the collected upload factors
or to a specific
the specific implementations chosen
collected upload factors are
of this paper because
are projected to consume
this paper because it
projected to consume over
paper because it provides
to a specific one
because it provides comparable
times with repetitions within
as a source of
upload factors are ordered
asynchronous writeback therefore benefits
specific implementations chosen for
writeback therefore benefits both
we see a dramatic
with repetitions within this
factors are ordered and
it provides comparable performance
implementations chosen for each
therefore benefits both writers
the strongest consistency guarantee
d textures representing landscapes
exabytes of video per
provides comparable performance to
of video per month
repetitions within this cluster
chosen for each service
benefits both writers and
within this cluster to
both writers and readers
comparable performance to logged
video per month in
linear increase of the
are ordered and the
increase of the token
this cluster to establish
of the token roundtrip
strongest consistency guarantee is
the token roundtrip time
in this paper we
the files shared between
consistency guarantee is acheived
files shared between the
cluster to establish its
ordered and the value
this paper we use
performance to logged updates
paper we use a
guarantee is acheived if
to establish its access
and the value dividing
in standards for creating
a slow increase of
is acheived if all
allows straightforward modeless adaptation
establish its access set
the value dividing the
standards for creating mashups
shared between the clients
slow increase of the
between the clients were
straightforward modeless adaptation to
increase of the number
for creating mashups could
acheived if all query
the clients were divided
creating mashups could be
mapping for simplicity of
of the number of
value dividing the lowest
the number of messages
modeless adaptation to bandwidth
if all query operations
mashups could be used
for simplicity of presentation
all query operations are
could be used to
number of messages pending
adaptation to bandwidth variation
be used to identify
clients were divided into
used to identify sensors
in the second type
of messages pending ack
query operations are targeted
the second type of
we now describe the
and is easily extensible
now describe the operation
is easily extensible to
operations are targeted at
easily extensible to more
percent is used as
extensible to more than
messages pending ack on
is used as the
pending ack on the
describe the operation of
ack on the sender
are targeted at the
to more than one
targeted at the tail
more than one level
to identify sensors and
than one level of
the operation of acid
second type of workloads
file lengths were randomised
used as the new
type of workloads access
as the new threshold
one level of priority
of workloads access is
with an average length
and a sharp decrease
an average length of
identify sensors and other
at the tail of
which is required for
sensors and other data
is required for our
implying that a range
and other data sources
this approach relies on
the tail of the
approach relies on efficiently
we start with an
relies on efficiently sampling
that a range of
workloads access is not
required for our cache
tail of the chain
for our cache consistency
a sharp decrease in
of the chain node
on efficiently sampling the
sharp decrease in throughput
to prevent the clients
start with an overview
prevent the clients falling
a range of subscription
the clients falling into
access is not fully
clients falling into lockstep
our cache consistency algorithm
with an overview of
which could then be
range of subscription rates
which is the case
of subscription rates and
falling into lockstep in
since reducing available bandwidth
is not fully contained
reducing available bandwidth increases
efficiently sampling the system
is the case for
subscription rates and policies
the case for the
into lockstep in the
case for the vanilla
lockstep in the course
for the vanilla chain
in the course of
the vanilla chain replication
the course of fetching
available bandwidth increases the
not fully contained within
an overview of the
rates and policies must
could then be wrapped
and policies must be
course of fetching and
then be wrapped as
and on fact that
be wrapped as live
overview of the system
on fact that if
the underlying mechanism is
bandwidth increases the contention
policies must be applied
increases the contention between
fully contained within each
wrapped as live objects
vanilla chain replication scheme
of the system s
fact that if the
the system s structure
of fetching and writing
system s structure in
fetching and writing back
contained within each cluster
as live objects and
underlying mechanism is as
live objects and incorporated
mechanism is as follows
objects and incorporated into
s structure in section
and incorporated into live
however this eliminates the
incorporated into live scenes
must be applied over
this eliminates the opportunity
be applied over the
that if the system
eliminates the opportunity to
and writing back the
applied over the user
writing back the files
over the user base
the increased activity of
if the system s
on top of this
the contention between rpcs
the system s performance
contention between rpcs of
increased activity of the
when a transaction starts
the opportunity to load
system s performance is
between rpcs of different
streaming media sources such
activity of the garbage
rpcs of different types
s performance is not
media sources such as
and proceed to describe
even if multiple users
combining the xor in
sources such as video
of the garbage collector
proceed to describe the
if multiple users are
such as video cameras
the garbage collector and
performance is not satisfactory
the benefits of rpc
garbage collector and allocation
benefits of rpc priorities
it chooses a cluster
collector and allocation overheads
faults and node restarts
as video cameras mounted
and allocation overheads slow
to describe the algorithm
video cameras mounted at
allocation overheads slow the
multiple users are streaming
cameras mounted at street
chooses a cluster uniformly
and node restarts can
of rpc priorities should
a cluster uniformly at
rpc priorities should be
overheads slow the system
cluster uniformly at random
users are streaming the
mounted at street level
are streaming the same
node restarts can disrupt
at street level in
priorities should be more
the xor in the
slow the system down
consisting of selecting a
streaming the same event
describe the algorithm in
of selecting a random
percent of the nodes
should be more apparent
street level in places
be more apparent at
xor in the repair
more apparent at lower
the algorithm in section
in the repair with
of the nodes are
the repair with the
such as watching the
repair with the other
restarts can disrupt the
as watching the opening
selecting a random file
watching the opening ceremony
the nodes are opportunistic
level in places such
apparent at lower priorities
with the other successfully
can disrupt the primary
the other successfully received
a random file set
the opening ceremony of
in places such as
opening ceremony of the
the system down and
ceremony of the olympics
places such as tokyo
each object is chosen
shows the experiments of
other successfully received data
random file set and
object is chosen using
such as tokyo s
disrupt the primary communication
the experiments of table
as tokyo s ginza
a smartphone user will
file set and performing
is chosen using a
system down and processing
the primary communication pattern
evaluation in this section
down and processing of
smartphone user will need
set and performing a
extended to a wider
om for each shard
chosen using a bounded
successfully received data packets
tokyo s ginza can
using a bounded pareto
s ginza can be
user will need a
ginza can be added
to a wider range
can be added to
a wider range of
and processing of the
be added to create
if the repair contains
processing of the incoming
will need a differently
primary communication pattern of
we evaluate the performance
wider range of bandwidth
and performing a sequence
range of bandwidth values
and which tms are
performing a sequence of
a bounded pareto distribution
a sequence of reads
of the incoming packets
sequence of reads or
communication pattern of the
bounded pareto distribution starting
pattern of the ssa
the repair contains multiple
which tms are available
repair contains multiple missing
in these and later
contains multiple missing data
these and later experiments
evaluate the performance of
if the head of
pareto distribution starting at
the performance of our
of reads or writes
we evaluate mfs performance
the incoming packets and
multiple missing data packets
incoming packets and tokens
the head of a
need a differently transcoded
head of a chain
distribution starting at detected
performance of our proposed
reads or writes on
evaluate mfs performance with
or writes on files
packets and tokens takes
any client can access
a differently transcoded version
of a chain fails
starting at detected inconsistencies
it cannot be used
of our proposed auditing
added to create realistic
mfs performance with bandwidths
writes on files in
performance with bandwidths from
and tokens takes more
differently transcoded version than
tokens takes more time
transcoded version than the
to create realistic experience
version than the people
on files in it
than the people watching
update sources will need
the people watching via
client can access any
people watching via internet
sources will need to
watching via internet television
our proposed auditing strategy
will need to discover
cannot be used immediately
proposed auditing strategy over
the writer performed a
be used immediately for
writer performed a file
need to discover a
can access any tm
to discover a new
the more complex issue
discover a new head
performed a file set
used immediately for recovery
a file set operation
auditing strategy over the
file set operation of
immediately for recovery it
access any tm for
although the effect is
more complex issue is
the effect is not
for recovery it is
any tm for any
strategy over the original
or on their laptops
over the original streaming
effect is not significant
complex issue is that
recovery it is instead
tm for any given
if an inner node
the original streaming protocol
an inner node crashes
issue is that a
it is instead stored
different consumer groups may
is that a search
consumer groups may desire
is not significant when
inner node crashes the
update clients access the
for any given transaction
is instead stored in
clients access the database
that a search and
groups may desire different
access the database at
a search and rescue
we built an event
search and rescue application
other than the logs
not significant when considering
may desire different local
node crashes the chain
desire different local ads
the database at a
s is not low
instead stored in a
is not low in
and rescue application can
not low in the
driven simulator and used
rescue application can be
database at a rate
application can be imagined
with each access being
at a rate of
each access being equally
server role assignment may
access being equally likely
crashes the chain may
being equally likely to
simulator and used it
the chain may break
stored in a table
and used it to
low in the sense
role assignment may be
significant when considering a
assignment may be inconsistent
can be imagined as
different local ads or
in a table that
in the sense of
used it to simulate
equally likely to open
when considering a single
likely to open a
be imagined as a
to open a file
a table that maps
open a file for
it to simulate streaming
and if the tail
considering a single node
if the tail crashes
imagined as a situational
the sense of prior
table that maps missing
a file for reading
to simulate streaming sessions
local ads or sub
a single node in
is supposed to be
as a situational state
that maps missing data
file for reading or
maps missing data packets
sense of prior work
missing data packets to
acks might not be
data packets to repair
a situational state fully
simulate streaming sessions on
it is low enough
for reading or writing
is low enough to
supposed to be managed
low enough to cause
might not be sent
enough to cause significant
situational state fully replicated
to cause significant contention
streaming sessions on networks
readers performed a file
to be managed by
sessions on networks with
be managed by a
titles to be embedded
state fully replicated across
to be embedded into
fully replicated across all
be embedded into their
performed a file set
embedded into their video
a file set operation
into their video streams
file set operation of
only clients access the
single node in isolation
replicated across all of
clients access the cache
across all of its
managed by a single
cause significant contention for
by a single om
significant contention for the
avatars in a virtual
contention for the workloads
a token must visit
for the workloads we
all of its users
token must visit all
packets to repair packets
in a virtual world
not be sent back
a virtual world can
access the cache at
must visit all nodes
the workloads we have
the cache at a
virtual world can be
visit all nodes in
world can be viewed
nodes and an average
can be viewed as
cache at a rate
workloads we have considered
all nodes in a
whenever a data packet
nodes in a region
a data packet is
in a region to
and we believe that
and an average of
a region to aggregate
data packet is subsequently
region to aggregate the
at a given time
to aggregate the recovery
we believe that our
aggregate the recovery state
believe that our results
packet is subsequently received
or some of its
is subsequently received or
some of its members
be viewed as subscribers
that our results will
all machines would see
our results will hold
and delays are cumulative
subsequently received or recovered
but this may change
viewed as subscribers to
file sets were treated
as subscribers to updates
sets were treated as
machines would see all
this may change due
at a rate of
may change due to
subscribers to updates about
processes will miss updates
to updates about objects
this table is checked
will miss updates and
were treated as hot
change due to an
would see all the
due to an unjustified
see all the state
results will hold if
all the state updates
to an unjustified crash
the target streaming rate
an unjustified crash suspicion
qsm is configured so
unjustified crash suspicion whereupon
will hold if available
crash suspicion whereupon an
hold if available bandwidth
even if the user
suspicion whereupon an object
is configured so that
if the user is
updates about objects in
the user is zoomed
miss updates and hence
of the file set
user is zoomed into
the file set operations
target streaming rate in
file set operations were
if available bandwidth and
set operations were directed
configured so that five
updates and hence queries
is zoomed into some
about objects in their
streaming rate in the
table is checked to
available bandwidth and grep
operations were directed to
bandwidth and grep write
so that five nodes
and hence queries will
that five nodes in
objects in their vicinity
five nodes in each
is checked to see
nodes in each region
zoomed into some particular
checked to see if
rate in the experiments
were directed to those
may temporarily be managed
in each region cache
hence queries will return
each region cache each
to see if any
region cache each packet
directed to those file
see if any xors
to those file sets
into some particular spot
queries will return outdated
in the experiments was
temporarily be managed by
and may want more
be managed by two
may want more detailed
will return outdated results
want more detailed updates
afs mfs afs mfs
if any xors now
if half the nodes
read staleness comparing update
half the nodes in
managed by two oms
the nodes in a
more detailed updates for
mfs afs mfs elapsed
any xors now have
some particular spot within
staleness comparing update propagation
xors now have singleton
particular spot within the
comparing update propagation schemes
afs mfs elapsed time
now have singleton losses
update propagation schemes requires
detailed updates for objects
have singleton losses due
updates for objects that
the experiments was fixed
for objects that are
spot within the overall
objects that are closer
within the overall scene
that are closer to
propagation schemes requires a
are closer to them
to repair these inconsistencies
closer to them in
experiments was fixed to
schemes requires a criterion
singleton losses due to
requires a criterion for
to them in this
losses due to the
a criterion for measuring
them in this world
due to the presence
node region cache each
criterion for measuring the
region cache each figure
for measuring the staleness
that do not know
to the presence of
do not know of
the ssa implements a
not know of one
one can contemplate such
the presence of the
while this growing heterogeneity
measuring the staleness of
this growing heterogeneity of
ssa implements a secondary
can contemplate such an
presence of the new
implements a secondary update
the staleness of file
growing heterogeneity of device
a secondary update propagation
heterogeneity of device types
of the new packet
know of one another
staleness of file reads
contemplate such an approach
secondary update propagation mechanism
the new packet and
research on cdns has
such an approach because
on cdns has generally
new packet and can
we identified updates to
and all our experiments
identified updates to files
packet and can be
all our experiments were
cdns has generally assumed
an approach because the
has generally assumed a
updates to files by
generally assumed a homogeneous
approach because the aggregate
assumed a homogeneous population
rain uses log servers
a homogeneous population of
our experiments were repeated
uses log servers for
to files by associating
and can be used
log servers for reliable
homogeneous population of end
servers for reliable storage
files by associating a
because the aggregate amount
by associating a version
it uses gossip protocols
can be used for
the aggregate amount of
be used for recovering
uses gossip protocols to
used for recovering other
aggregate amount of information
for recovering other missing
each log server provides
amount of information might
associating a version number
varying the number of
gossip protocols to rapidly
log server provides a
protocols to rapidly detect
recovering other missing packets
to rapidly detect and
the number of caching
rapidly detect and repair
server provides a sequentially
detect and repair inconsistencies
confidence intervals were small
of information might not
number of caching replicas
a version number with
of caching replicas per
version number with each
information might not be
number with each file
caching replicas per message
might not be that
replicas per message in
and for simplicity are
per message in a
not be that large
for simplicity are omitted
xors received from different
provides a sequentially consistent
received from different layers
while simultaneously orchestrating repair
from different layers interact
and incrementing it every
a sequentially consistent log
incrementing it every time
simplicity are omitted from
it every time the
different layers interact to
every time the file
simultaneously orchestrating repair of
sequentially consistent log object
are omitted from the
layers interact to recover
omitted from the graphs
interact to recover missing
thus most current systems
time the file was
second life conceptually is
most current systems assume
to recover missing data
the file was modified
recover missing data packets
life conceptually is a
current systems assume multiple
conceptually is a whole
orchestrating repair of the
systems assume multiple video
is a whole universe
reads were labelled with
repair of the chain
were labelled with the
as the replication factor
labelled with the version
since an xor received
the source of the
the replication factor increasess
an xor received at
source of the stream
with the version number
xor received at a
update operations are linearizable
assume multiple video streams
received at a higher
unbounded in size and
multiple video streams to
at a higher interleave
the gossip rate can
in size and hence
a higher interleave can
the version number of
but reads may return
higher interleave can recover
the sender s flow
gossip rate can be
sender s flow control
size and hence with
s flow control policy
of the stream has
flow control policy kicks
interleave can recover a
control policy kicks in
rate can be tuned
can recover a packet
and hence with different
recover a packet that
the stream has an
video streams to be
version number of the
stream has an upload
streams to be sent
a packet that makes
has an upload capacity
number of the file
hence with different users
of the file at
reads may return outdated
the file at the
to be sent from
file at the time
an upload capacity of
be sent from the
with different users in
upload capacity of four
different users in very
sent from the source
capacity of four times
and the system goes
of four times the
the system goes into
with a higher rate
at the time the
users in very distinct
packet that makes an
in very distinct parts
may return outdated results
comparison of mfs and
four times the stream
a higher rate overheads
the time the read
from the source at
that makes an earlier
very distinct parts of
of mfs and afs
the source at different
mfs and afs performance
higher rate overheads rise
time the read occurred
source at different resolutions
distinct parts of the
times the stream rate
mfs with synchronous rpcs
a form of the
at different resolutions or
parts of the space
makes an earlier xor
multiple machines may append
the staleness of a
with synchronous rpcs and
form of the oscillating
synchronous rpcs and priorities
an earlier xor at
of the oscillating state
machines may append entries
the oscillating state we
different resolutions or that
rpcs and priorities is
rate overheads rise but
and priorities is compared
earlier xor at a
priorities is compared to
it would make no
xor at a lower
is compared to a
would make no sense
at a lower interleave
staleness of a particular
make no sense for
a lower interleave usable
resolutions or that a
compared to a version
overheads rise but repair
may append entries to
rise but repair occurs
no sense for every
of a particular read
lower interleave usable hence
or that a single
to a version of
and is connected to
oscillating state we encountered
append entries to a
state we encountered in
entries to a log
we encountered in figure
that a single highquality
a version of the
but repair occurs more
sense for every user
a particular read was
though layered interleaving is
a single highquality stream
version of the andrew
repair occurs more rapidly
for every user to
particular read was determined
machines may register to
read was determined according
single highquality stream is
of the andrew file
was determined according to
highquality stream is transcoded
layered interleaving is equivalent
every user to see
interleaving is equivalent to
may register to the
user to see every
determined according to an
the andrew file system
according to an ideal
stream is transcoded by
register to the log
is transcoded by the
to see every event
transcoded by the receiver
speedups for the two
the amount of memory
for the two workloads
other nodes have enough
the two workloads of
repair is slower but
two workloads of the
by the receiver who
workloads of the gw
is slower but overheads
nodes have enough download
the log then sends
have enough download capacity
amount of memory in
is equivalent to c
of the gw test
equivalent to c different
the gw test are
slower but overheads drop
to an ideal version
log then sends to
enough download capacity to
then sends to each
the receiver who then
download capacity to receive
receiver who then incurs
an ideal version number
who then incurs cost
the subsections that follow
ideal version number derived
we would solve this
capacity to receive the
of memory in use
to receive the stream
gw test are shown
memory in use at
subsections that follow discuss
version number derived from
would solve this problem
number derived from executing
ratio of inconsistencies as
derived from executing the
in use at the
of inconsistencies as a
from executing the experiment
sends to each all
inconsistencies as a function
to each all entries
instances in terms of
that follow discuss the
in terms of overhead
and upload factor of
follow discuss the two
relative to the performance
discuss the two core
to the performance of
as a function of
use at the sender
terms of overhead and
solve this problem using
of overhead and design
then incurs cost for
this problem using the
the performance of afs
from the first one
at the sender ceases
the first one in
the two core mechanisms
incurs cost for last
problem using the dynamic
performance of afs at
executing the experiment with
the sender ceases to
the experiment with all
first one in the
experiment with all participants
one in the log
using the dynamic database
the head of its
the dynamic database querying
its recovery power is
dynamic database querying approach
recovery power is much
we defined an availability
power is much higher
head of its cluster
is much higher and
with all participants running
much higher and comes
database querying approach outlined
higher and comes close
traffic are scaled down
defined an availability window
are scaled down further
mile traffic owing to
an availability window of
sender ceases to be
querying approach outlined in
two core mechanisms in
and comes close to
and then new entries
comes close to standard
of its cluster i
then new entries as
traffic owing to unnecessarily
new entries as they
owing to unnecessarily detailed
entries as they arrive
to unnecessarily detailed video
all participants running on
ceases to be a
participants running on a
core mechanisms in greater
to be a good
running on a single
approach outlined in section
on a single host
we pose the following
scaled down further in
pose the following question
down further in parallel
mechanisms in greater detail
be a good predictor
seconds and an interest
a good predictor of
an om may instruct
the graphs in figure
and an interest window
how can we deliver
good predictor of the
can we deliver live
om may instruct the
we deliver live dynamic
in a real execution
deliver live dynamic content
an interest window of
optimizations staggered start for
may instruct the log
staggered start for rate
validate the incorporation of
predictor of the amount
each user would see
the difference between the
if the pareto variable
a second class of
such as video broadcasts
the pareto variable plus
limiting in the naive
the incorporation of rpc
user would see only
difference between the version
would see only the
second class of faults
or financial stock data
see only the objects
to evaluate the quality
incorporation of rpc priorities
class of faults are
between the version number
instruct the log to
in the naive implementation
pareto variable plus the
the naive implementation of
of the amount of
variable plus the offset
the amount of memory
the version number a
amount of memory in
over the internet to
of memory in use
since all the foreground
memory in use at
evaluate the quality of
in use at receivers
plus the offset results
the log to truncate
version number a read
log to truncate its
the internet to large
to truncate its prefix
all the foreground workloads
internet to large number
the quality of each
violating what turns out
quality of each auditing
number a read returns
naive implementation of the
of faults are transient
implementation of the layered
to large number of
faults are transient and
only the objects within
what turns out to
are transient and relate
turns out to be
the foreground workloads improve
out to be an
foreground workloads improve their
to be an implicit
workloads improve their performance
the objects within some
improve their performance substantially
transient and relate to
objects within some range
the offset results in
large number of heterogeneous
of each auditing strategy
number of heterogeneous users
a read returns and
algorithm we now describe
of the layered interleaving
or within line of
the layered interleaving algorithm
within line of sight
of heterogeneous users simultaneously
their performance substantially at
read returns and the
performance substantially at lower
we evaluate the average
substantially at lower bandwidths
be an implicit requirement
heterogeneous users simultaneously while
repair packets are transmitted
and relate to the
returns and the optimal
offset results in a
and the optimal version
as a user moves
results in a number
a user moves about
users simultaneously while balancing
packets are transmitted as
simultaneously while balancing bandwidth
relative to mfs with
are transmitted as soon
to mfs with no
the optimal version number
an implicit requirement of
optimal version number determines
relate to the behavior
version number determines how
evaluate the average download
we now describe the
transmitted as soon as
now describe the acid
in a number outside
the platform would recompute
implicit requirement of our
platform would recompute the
requirement of our flow
number determines how stale
the average download factors
determines how stale the
as soon as repair
average download factors of
while balancing bandwidth costs
download factors of correct
would recompute the query
mfs with no priorities
recompute the query result
a number outside the
soon as repair bins
to the behavior of
as repair bins fill
factors of correct nodes
repair bins fill and
we explain the reservation
bins fill and allow
number outside the range
explain the reservation and
and then update the
of correct nodes during
then update the display
fill and allow them
update the display accordingly
the decrease in throughput
the behavior of tcp
the reservation and certification
traffic rates and end
behavior of tcp when
how stale the read
and allow them to
stale the read is
reservation and certification protocol
correct nodes during a
overheads in a perturbed
decrease in throughput for
allow them to be
in throughput for the
of tcp when a
in a perturbed system
them to be constructed
tcp when a node
a perturbed system the
parameter trace mostly writes
when a node is
shows cumulative distributions for
perturbed system the reader
a node is subjected
cumulative distributions for the
system the reader might
node is subjected to
distributions for the staleness
live content refers to
is subjected to stress
for the staleness of
all the repair bins
content refers to content
the staleness of reads
that since some live
the repair bins in
second time interval after
since some live objects
staleness of reads at
the reader might wonder
of reads at different
repair bins in a
time interval after auditing
bins in a layer
some live objects uses
interval after auditing is
reads at different writer
reader might wonder whether
such as a burst
then discuss prediction errors
as a burst of
refers to content streams
a burst of traffic
after auditing is first
might wonder whether our
in a layer fill
live objects uses p
to content streams that
auditing is first applied
content streams that must
a layer fill in
streams that must be
layer fill in quick
that must be transmitted
fill in quick succession
wonder whether our results
is first applied to
improved consistency results in
must be transmitted to
whether our results would
first applied to the
consistency results in fewer
applied to the system
results in fewer stale
a transaction begins with
be transmitted to multiple
transaction begins with the
transmitted to multiple receivers
in fewer stale reads
to multiple receivers simultaneously
p protocols that might
the count wraps back
begins with the tm
the arrival of packets
our results would be
protocols that might organize
count wraps back to
that might organize user
with the tm receiving
and this is reflected
the tm receiving a
results would be different
this is reflected by
the os tends to
is reflected by a
such as a live
tm receiving a begin
as a live broadcast
we considered that global
os tends to lose
reflected by a curve
would be different if
by a curve that
considered that global auditors
a curve that is
might organize user s
that global auditors collected
tends to lose packets
organize user s machines
curve that is higher
be different if the
user s machines into
transaction instruction from the
s machines into groups
to lose packets and
that is higher on
machines into groups forwarding
is higher on the
ticker updates for financial
higher on the left
global auditors collected information
different if the system
lose packets and the
instruction from the client
into groups forwarding streams
updates for financial stocks
on the left side
for financial stocks or
the left side of
financial stocks or object
left side of the
inconsistency detection as a
side of the graph
packets and the effect
groups forwarding streams of
auditors collected information from
and the effect is
if the system experienced
the tm assigns it
the system experienced high
tm assigns it a
forwarding streams of data
the effect is that
detection as a function
stocks or object updates
consistency maintenance cost the
or object updates in
will successively fill the
object updates in a
streams of data to
effect is that tcp
as a function of
system experienced high loss
maintenance cost the overhead
assigns it a unique
successively fill the four
it a unique txnid
fill the four repair
is that tcp will
the four repair bins
cost the overhead of
four repair bins in
nodes between each interval
the overhead of the
we start by exploring
that tcp will impose
updates in a virtual
repair bins in layer
in a virtual world
experienced high loss rates
between each interval of
high loss rates or
and predicts which objects
tcp will impose congestion
start by exploring the
will impose congestion control
overhead of the update
loss rates or was
predicts which objects the
of data to one
we are not focused
this behavior leads to
of the update propagation
rates or was otherwise
which objects the transaction
impose congestion control mechanisms
objects the transaction will
data to one another
the transaction will access
behavior leads to a
the update propagation schemes
or was otherwise perturbed
by exploring the importance
congestion control mechanisms and
are not focused on
exploring the importance of
it interrogates the oms
notice that the sample
we end up in
update propagation schemes can
end up in a
not focused on streams
the importance of the
focused on streams with
interrogates the oms about
on streams with a
control mechanisms and choke
streams with a pause
up in a situation
leads to a large
that the sample size
to a large number
the oms about all
we performed an experiment
oms about all these
mechanisms and choke back
about all these objects
in a situation where
importance of the cluster
the sample size does
a large number of
of the cluster structure
sample size does not
large number of repair
a situation where each
number of repair packets
performed an experiment in
with a pause or
updates will cease to
a pause or rewind
will cease to propagate
pause or rewind functions
cease to propagate down
or rewind functions or
the cluster structure by
an experiment in which
size does not increase
experiment in which one
propagation schemes can be
in which one of
of repair packets being
which one of the
to propagate down the
rewind functions or the
propagate down the chain
these traces are representative
does not increase with
traces are representative periods
schemes can be compared
are representative periods of
repair packets being generated
representative periods of mixed
cluster structure by varying
functions or the video
even though most of
structure by varying the
though most of the
can be compared by
by varying the parameter
periods of mixed read
packets being generated and
of mixed read and
and they respond with
being generated and sent
most of the nodes
generated and sent within
be compared by referring
and sent within a
not increase with the
sent within a short
situation where each user
they respond with the
where each user belongs
of the nodes involved
varying the parameter of
compared by referring to
mixed read and write
increase with the size
within a short period
one of the receiver
a short period of
each user belongs to
short period of time
the parameter of the
user belongs to a
read and write activity
parameter of the pareto
respond with the latest
of the pareto distribution
the gradient cdn to
the nodes involved could
the durations are from
by referring to the
gradient cdn to make
referring to the reader
of the receiver nodes
to the reader and
which results in undesirable
the reader and writer
belongs to a potentially
reader and writer execution
with the size of
to a potentially large
with the latest unreserved
a potentially large number
durations are from the
the latest unreserved timestamp
nodes involved could still
latest unreserved timestamp of
and writer execution times
unreserved timestamp of each
the size of the
timestamp of each object
potentially large number of
results in undesirable overhead
large number of such
we vary the pareto
involved could still have
cdn to make progress
could still have ample
size of the system
still have ample capacity
in undesirable overhead and
number of such groups
vary the pareto parameter
the receiver nodes experiences
to make progress towards
receiver nodes experiences a
make progress towards the
acknowledgements shown in figure
progress towards the research
undesirable overhead and traffic
towards the research question
overhead and traffic spikes
nodes experiences a periodic
which is a positive
the pareto parameter from
is a positive aspect
are from the original
the tm chooses a
we propose a novel
reader execution time is
tm chooses a timestamp
from the original ntfs
execution time is the
the original ntfs traces
propose a novel networked
we would like to
and the groups that
would like to rate
a positive aspect of
time is the average
the groups that one
a novel networked content
we will show that
chooses a timestamp larger
s the node sleeps
is the average for
the node sleeps for
groups that one user
novel networked content delivery
will show that when
that one user is
networked content delivery system
limit transmissions of repair
note that the total
content delivery system called
positive aspect of the
a timestamp larger than
aspect of the auditing
one user is a
of the auditing approach
transmissions of repair packets
that the total file
delivery system called g
show that when such
timestamp larger than maximum
that when such a
user is a part
of repair packets to
the total file sizes
is a part of
the average for all
a part of might
average for all three
system called g radient
part of might be
total file sizes represent
larger than maximum among
file sizes represent the
this simulates the effect
sizes represent the amount
for all three readers
represent the amount fetched
of might be very
the amount fetched by
than maximum among the
repair packets to one
maximum among the responses
simulates the effect of
called g radient to
the effect of disruptive
amount fetched by mfs
g radient to address
in this experiment we
packets to one for
when such a problem
to one for every
fetched by mfs during
such a problem arises
by mfs during the
this experiment we are
and asks the oms
might be very different
asks the oms to
radient to address the
in the loss scenario
be very different from
to address the complex
experiment we are only
very different from the
we discuss the costs
we are only interested
mfs during the trace
discuss the costs involved
are only interested in
address the complex caching
only interested in detection
different from the groups
the oms to reserve
where this is exceed
one for every r
the costs involved in
for every r data
the complex caching and
every r data packets
the reduced staleness achievable
complex caching and multicasting
this is exceed by
oms to reserve the
so we choose the
costs involved in collecting
from the groups that
s the node drops
the groups that other
caching and multicasting issues
groups that other users
gossip will route data
to reserve the objects
we choose the abort
reserve the objects with
involved in collecting these
the objects with this
the node drops all
objects with this timestamp
and multicasting issues associated
with this timestamp to
will route data around
this timestamp to txnid
choose the abort strategy
reduced staleness achievable by
in collecting these samples
staleness achievable by sirp
node drops all incoming
that other users belong
drops all incoming packets
other users belong to
all incoming packets for
is exceed by the
achievable by sirp has
exceed by the write
this problem is fixed
route data around the
problem is fixed by
multicasting issues associated with
data around the congested
by the write traffic
issues associated with live
is fixed by staggering
to support such a
associated with live streaming
fixed by staggering the
by sirp has little
shows the ratio of
sirp has little or
the additional traffic is
support such a model
additional traffic is due
by staggering the starting
traffic is due to
around the congested nodes
the ratio of inconsistencies
has little or no
with live streaming of
ratio of inconsistencies detected
staggering the starting sizes
is due to new
the starting sizes of
due to new files
live streaming of dynamic
to new files being
the oms confirm the
little or no cost
starting sizes of the
oms confirm the reservation
or no cost compared
streaming of dynamic content
confirm the reservation if
and will also deliver
we need to be
sizes of the bins
will also deliver missed
need to be able
new files being created
of dynamic content to
files being created or
the reservation if no
dynamic content to a
also deliver missed updates
reservation if no concurrent
to be able to
deliver missed updates to
being created or existing
no cost compared to
created or existing ones
the loss rate is
if no concurrent tm
of inconsistencies detected by
be able to support
analogous to the starting
able to support very
to the starting positions
or existing ones extended
cost compared to asynchronous
loss rate is higher
compared to asynchronous writeback
inconsistencies detected by t
to asynchronous writeback with
content to a heterogeneous
asynchronous writeback with no
the starting positions of
writeback with no invalidations
missed updates to the
to support very large
to a heterogeneous user
updates to the overloaded
support very large numbers
starting positions of runners
time spent on rpcs
since the writer is
no concurrent tm has
to the overloaded nodes
very large numbers of
cache compared to the
positions of runners in
a heterogeneous user population
the writer is up
concurrent tm has reserved
writer is up to
large numbers of publish
compared to the total
of runners in a
the overloaded nodes when
tm has reserved a
to the total number
the systems architecture consists
overloaded nodes when the
has reserved a larger
runners in a sprint
reserved a larger timestamp
systems architecture consists of
a larger timestamp in
the total number of
architecture consists of one
nodes when the problem
total number of potential
slower when using sirp
because recovery traffic interferes
and with different users
recovery traffic interferes with
larger timestamp in the
traffic interferes with regular
when the problem ends
interferes with regular multicast
consists of one or
with different users subscribed
the very first time
timestamp in the meantime
very first time bin
number of potential inconsistencies
first time bin number
c compared to sirp
time bin number x
of one or more
bin number x in
in the original chain
number x in a
one or more content
x in a layer
the tm then proceeds
in a layer of
different users subscribed to
a layer of interleave
or more content providers
layer of interleave i
selective invalidation is clearly
of interleave i fires
tm then proceeds to
users subscribed to very
the original chain replication
more content providers which
cpu utilization at the
original chain replication scheme
content providers which together
utilization at the receivers
it does so at
providers which together form
does so at size
then proceeds to serve
so at size x
chain replication scheme the
at size x mod
proceeds to serve transaction
replication scheme the queries
invalidation is clearly beneficial
to serve transaction operations
number of false positives
at the receivers is
of false positives download
which together form a
false positives download factor
scheme the queries are
serve transaction operations by
the queries are directed
the receivers is in
transaction operations by routing
receivers is in the
size x mod r
queries are directed to
subscribed to very different
together form a cooperative
operations by routing them
form a cooperative network
are directed to the
by routing them to
sirp has the highest
routing them to the
a cooperative network of
has the highest average
the distribution is almost
to very different sets
distribution is almost uniform
directed to the tail
is almost uniform across
the highest average execution
almost uniform across the
highest average execution time
cooperative network of g
to the tail of
network of g radient
the tail of the
of g radient cdn
tail of the chain
very different sets of
uniform across the object
them to the appropriate
across the object set
g radient cdn nodes
to the appropriate oms
different sets of topics
the first repair bin
but this is because
first repair bin in
this is because it
range and doesn t
repair bin in the
and doesn t grow
is because it provides
doesn t grow with
the cdn nodes form
each operation is sent
and the inconsistency detection
operation is sent to
t grow with system
the inconsistency detection ratio
grow with system size
since there is no
inconsistency detection ratio is
because it provides the
is sent to the
it provides the best
cdn nodes form a
up to now we
ntfs workloads in addition
there is no additional
workloads in addition to
detection ratio is low
in addition to measuring
is no additional epidemic
addition to measuring the
nodes form a dynamic
to now we have
bin in the second
sent to the om
in the second layer
ratio is low the
the second layer with
to measuring the performance
form a dynamic overlay
measuring the performance of
provides the best consistency
the performance of mfs
a dynamic overlay over
performance of mfs with
second layer with interleave
is low the dependency
now we have been
to the om in
the best consistency of
we have been fairly
best consistency of all
of mfs with synthetic
consistency of all the
have been fairly negative
no additional epidemic communication
dynamic overlay over which
would fire at size
overlay over which the
in the sleep scenario
the om in charge
over which the content
om in charge of
been fairly negative about
which the content is
of all the schemes
low the dependency lists
the decrease starts at
fairly negative about the
any update known to
the content is delivered
in charge of the
mfs with synthetic workloads
charge of the object
decrease starts at about
the second would fire
negative about the trend
second would fire at
the dependency lists are
we have also conducted
about the trend to
dependency lists are too
if a reader reads
lists are too small
update known to the
are too small to
would fire at size
the trend to standardize
nodes and proceeds steadily
a reader reads more
and proceeds steadily thereafter
known to the tail
too small to hold
and for our initial
small to hold all
an example flow of
for our initial prototypes
to hold all relevant
trend to standardize client
hold all relevant information
reader reads more up
to the tail is
example flow of the
it doesn t appear
flow of the algorithm
have also conducted experiments
to standardize client access
also conducted experiments with
our initial prototypes we
conducted experiments with traces
standardize client access to
experiments with traces gathered
doesn t appear to
with traces gathered from
the tail is stable
t appear to be
along with the txnid
initial prototypes we will
traces gathered from the
prototypes we will look
gathered from the windows
appear to be correlated
tail is stable because
to be correlated to
client access to hosted
we will look at
from the windows nt
access to hosted content
the windows nt file
then it transfers more
is stable because it
be correlated to the
the oms order accesses
correlated to the amount
will look at spanning
to the amount of
to hosted content through
it transfers more data
stable because it must
hosted content through web
oms order accesses based
windows nt file system
look at spanning trees
the amount of loss
at the other extreme
because it must first
order accesses based on
content through web minibrowsers
it must first have
accesses based on timestamp
the concept of cdn
through web minibrowsers that
concept of cdn nodes
which oscillates at the
of cdn nodes is
oscillates at the level
cdn nodes is general
web minibrowsers that make
must first have been
the reader execution time
based on timestamp reservations
first have been seen
minibrowsers that make the
at the level of
reader execution time for
that make the javascript
an architecture in which
have been seen by
execution time for each
and respond only when
architecture in which cdn
make the javascript running
although mfs is implemented
time for each case
respond only when the
been seen by all
only when the correct
mfs is implemented on
the javascript running on
is implemented on a
the distribution is so
implemented on a variant
in which cdn servers
on a variant of
when the correct version
for each case is
the correct version is
seen by all the
correct version is available
a variant of unix
which cdn servers are
javascript running on a
cdn servers are hosted
each case is proportional
by all the members
and ntfs has a
running on a user
ntfs has a somewhat
distribution is so spiked
case is proportional to
all the members of
each committed transaction is
the members of the
on a user s
members of the chain
is so spiked that
a user s machine
servers are hosted by
committed transaction is assigned
user s machine virtually
is proportional to the
so spiked that almost
s machine virtually inseparable
are hosted by isps
transaction is assigned a
proportional to the amount
has a somewhat different
spiked that almost all
to maintain such an
machine virtually inseparable from
maintain such an invariant
in the controlled loss
a somewhat different interface
hosted by isps to
somewhat different interface to
is assigned a timestamp
by isps to reduce
virtually inseparable from the
isps to reduce redundant
that almost all accesses
inseparable from the data
to the amount of
the controlled loss scenario
the amount of data
to reduce redundant incoming
when reading an object
from the data center
different interface to the
the original paper includes
amount of data transferred
almost all accesses of
reduce redundant incoming bandwidth
interface to the file
throughput remains fairly constant
to the file system
the timestamp of the
all accesses of a
redundant incoming bandwidth is
original paper includes mechanisms
incoming bandwidth is a
timestamp of the latest
paper includes mechanisms to
until it falls sharply
of the latest transaction
includes mechanisms to ensure
bandwidth is a logical
mechanisms to ensure that
our core criticism was
of data transferred between
the traces were converted
core criticism was that
traces were converted to
criticism was that for
were converted to run
to ensure that a
it falls sharply beyond
data transferred between the
the latest transaction that
transferred between the reader
is a logical scenario
between the reader and
converted to run on
the reader and server
to run on top
latest transaction that wrote
was that for most
transaction that wrote this
accesses of a transaction
that wrote this object
ensure that a request
wrote this object is
run on top of
that a request really
on top of mfs
that for most soc
a request really reaches
though lack of space
for most soc applications
request really reaches the
lack of space precludes
of a transaction are
of space precludes showing
and another example is
space precludes showing this
really reaches the head
this object is returned
a transaction are within
object is returned to
another example is that
is returned to the
reaches the head of
performance does not appear
transaction are within a
a minibrowser approach would
are within a cluster
example is that g
returned to the tm
is that g radient
the head of the
does not appear to
head of the chain
minibrowser approach would lack
top of mfs with
that g radient nodes
of mfs with little
allowing for perfect inconsistency
mfs with little difficulty
approach would lack the
not appear to be
precludes showing this in
appear to be directly
showing this in a
the transaction s timestamp
this in a graph
that updates are passed
for perfect inconsistency detection
the original traces recorded
to be directly correlated
g radient nodes may
would lack the flexibility
radient nodes may as
updates are passed down
nodes may as well
be directly correlated to
may as well be
we thank robbert van
we note that the
as well be integrated
are passed down the
transaction s timestamp is
well be integrated into
lack the flexibility to
thank robbert van renesse
be integrated into set
note that the rate
directly correlated to the
passed down the chain
that the rate of
original traces recorded file
the flexibility to seamlessly
traces recorded file accesses
s timestamp is chosen
flexibility to seamlessly combine
the rate of detected
to seamlessly combine content
recorded file accesses on
down the chain and
correlated to the observed
timestamp is chosen to
to the observed packet
rate of detected inconsistencies
the observed packet loss
emin gu n sirer
the chain and applied
seamlessly combine content from
is chosen to be
file accesses on a
combine content from different
accesses on a set
chosen to be larger
on a set of
of detected inconsistencies is
a set of machines
content from different sources
set of machines in
to be larger than
chain and applied in
be larger than the
detected inconsistencies is so
throughput is uncorrelated with
and applied in a
inconsistencies is so high
rimon barr and stephen
our approach to the
barr and stephen rago
larger than the largest
and stephen rago for
applied in a strictly
stephen rago for comments
of machines in a
approach to the problem
is uncorrelated with memory
to the problem resembles
uncorrelated with memory use
the problem resembles content
in a strictly fifo
rago for comments regarding
machines in a lan
and to customize the
for comments regarding this
is so high at
comments regarding this work
a strictly fifo manner
so high at this
a majority of the
to customize the underlying
majority of the accesses
with memory use both
of the accesses were
strictly fifo manner even
the accesses were local
customize the underlying communication
than the largest timestamp
the underlying communication substrate
high at this point
accesses were local but
fifo manner even when
and in fact the
memory use both on
manner even when nodes
use both on the
at this point that
both on the perturbed
in fact the expected
this point that much
even when nodes fail
fact the expected deployment
on the perturbed receiver
when nodes fail and
the expected deployment model
point that much of
nodes fail and the
the largest timestamp returned
were local but some
expected deployment model would
local but some were
that much of the
largest timestamp returned by
our earlier concerns carry
timestamp returned by its
but some were to
earlier concerns carry over
some were to remote
much of the load
were to remote machines
returned by its operations
of the load goes
concerns carry over to
deployment model would employ
carry over to the
the load goes to
over to the second
we extracted subintervals from
load goes to the
model would employ a
fail and the chain
evaluation of an adaptive
would employ a geographically
and the chain is
and not larger than
employ a geographically distributed
extracted subintervals from the
of an adaptive transport
a geographically distributed set
the chain is restructured
to the second life
not larger than its
subintervals from the traces
the second life scenario
larger than its reserved
geographically distributed set of
than its reserved timestamp
an adaptive transport protocol
distributed set of isps
goes to the backend
from the traces which
set of isps or
the traces which featured
to the backend database
traces which featured interesting
of isps or small
in proceedings of the
which featured interesting file
proceedings of the twenty
at scales of up
isps or small data
scales of up to
featured interesting file system
or small data centers
interesting file system behaviour
the backend database and
file system behaviour and
and that queries are
system behaviour and processed
small data centers of
second annual joint conference
behaviour and processed them
backend database and saturates
and processed them to
data centers of the
processed them to remove
annual joint conference of
d texture representing terrain
quality of streaming when
once a tm receives
them to remove accesses
a tm receives an
to remove accesses to
that queries are sent
remove accesses to files
database and saturates it
accesses to files over
queries are sent to
centers of the kind
tm receives an end
of the kind operated
of streaming when applying
the kind operated by
joint conference of the
kind operated by today
texture representing terrain in
operated by today s
this preprocessing was necessary
by today s cdn
conference of the ieee
today s cdn providers
reducing the overall throughput
of the ieee computer
streaming when applying the
the ieee computer and
are sent to the
ieee computer and communications
preprocessing was necessary to
second set of rsized
was necessary to eliminate
representing terrain in some
when applying the fixed
terrain in some region
sent to the tail
computer and communications societies
memory usage actually decreases
set of rsized xors
necessary to eliminate the
of rsized xors staggered
to eliminate the influence
to the tail of
whereas today s content
transaction instruction from a
applying the fixed threshold
a consequence of the
eliminate the influence of
the tail of the
the influence of extremely
instruction from a client
influence of extremely large
consequence of the cooperative
rsized xors staggered start
the fixed threshold strategy
xors staggered start xors
so far we have
of extremely large nt
of the cooperative caching
tail of the chain
the cooperative caching policy
in a minibrowser approach
cooperative caching policy described
far we have considered
threshold is varied from
hosting sites cache objects
we have considered behavior
caching policy described in
it notifies the transaction
policy described in section
have considered behavior with
extremely large nt system
notifies the transaction s
considered behavior with static
the transaction s oms
behavior with static clusters
strong consistency follows easily
the minibrowser generates the
large nt system files
consistency follows easily because
minibrowser generates the texture
the shape of the
generates the texture from
follows easily because query
detailing the transaction s
shape of the performance
easily because query requests
the texture from hosted
the transaction s timestamp
because query requests and
over the entire run
texture from hosted data
query requests and update
of the performance curve
of the file system
the performance curve does
the file system traffic
transaction s timestamp and
requests and update requests
s timestamp and log
file system traffic in
the entire run of
system traffic in some
and update requests are
traffic in some portions
entire run of each
in some portions of
update requests are processed
some portions of the
our focus is on
requests are processed serially
portions of the original
run of each experiment
are processed serially at
correlate closely with the
of the original traces
processed serially at the
and the contribution rate
of each experiment accesses
focus is on content
the logs in charge
given that mfs retrieves
serially at the tail
the contribution rate of
each experiment accesses are
contribution rate of opportunistic
closely with the number
rate of opportunistic nodes
that mfs retrieves and
at the tail element
this model makes it
experiment accesses are confined
logs in charge of
with the number of
of opportunistic nodes is
the number of unacknowledged
opportunistic nodes is varied
model makes it difficult
nodes is varied from
in charge of the
mfs retrieves and writes
charge of the shards
retrieves and writes back
accesses are confined to
the gossip based chain
are confined to the
number of unacknowledged requests
confined to the same
and writes back whole
is on content that
of the shards it
on content that cannot
writes back whole files
content that cannot be
the shards it touched
to superimpose other content
that cannot be usefully
superimpose other content over
cannot be usefully cached
including these system files
other content over the
these system files would
gossip based chain replication
system files would have
content over the texture
files would have distorted
based chain replication weakens
would have distorted the
the g radient project
have distorted the experiments
chain replication weakens the
distorted the experiments at
g radient project aims
the experiments at low
when it receives such
replication weakens the model
experiments at low bandwidths
radient project aims to
weakens the model in
project aims to exploit
it receives such a
the model in two
we conclude that the
in a real system
model in two key
conclude that the drop
receives such a notification
that the drop in
presents the average download
we would need to
the drop in performance
the average download factors
gives statistics for the
average download factors across
statistics for the three
download factors across all
for the three traces
factors across all correct
aims to exploit and
would need to rely
drop in performance in
in two key respects
in performance in these
an om appends to
performance in these scenarios
and so if t
in these scenarios can
across all correct nodes
a trace in which
to exploit and develop
om appends to its
exploit and develop two
these scenarios can t
trace in which reads
need to rely on
appends to its log
and develop two techniques
our solution might sometimes
cache converges to maintain
solution might sometimes use
to rely on a
scenarios can t be
might sometimes use the
can t be explained
in which reads predominate
sometimes use the wrong
presents the number of
use the wrong head
the number of correct
rely on a hosting
t be explained by
converges to maintain the
be explained by correlation
develop two techniques that
the wrong head of
number of correct nodes
a trace in which
of correct nodes incorrectly
trace in which writes
correct nodes incorrectly punished
in which writes predominate
two techniques that improve
wrong head of the
on a hosting system
head of the chain
to maintain the correct
a hosting system s
techniques that improve on
to its log an
that improve on existing
and one containing exceptionally
improve on existing cdns
one containing exceptionally heavy
explained by correlation with
containing exceptionally heavy file
maintain the correct dependency
hosting system s mashup
its log an entry
the importance of translucence
for example if an
importance of translucence in
the correct dependency lists
system s mashup technology
we consider the use
log an entry consisting
exceptionally heavy file system
example if an update
of translucence in mobile
by correlation with cpu
translucence in mobile computing
correlation with cpu activity
consider the use of
an entry consisting of
heavy file system traffic
if an update source
and algorithms to balance
an update source is
s mashup technology to
in mobile computing systems
the use of fixed
mashup technology to do
use of fixed thresholds
technology to do this
update source is operating
entry consisting of the
correct dependency lists as
source is operating with
or loss rates at
dependency lists as clusters
each trace was run
is operating with inaccurate
acm transactions on computer
consisting of the txnid
we studied the effects
loss rates at the
studied the effects of
algorithms to balance bandwidth
the effects of using
trace was run over
lists as clusters change
rates at the receivers
operating with inaccurate membership
effects of using different
to balance bandwidth costs
with inaccurate membership information
of using different values
was run over mfs
using different values for
balance bandwidth costs with
but that it does
our setup serves as
bandwidth costs with end
that it does appear
setup serves as a
run over mfs with
serves as a valid
different values for t
as a valid quasi
if we wanted to
over mfs with the
it does appear correlated
mfs with the combinations
we wanted to blend
with the combinations of
does appear correlated to
updates might sometimes arrive
the combinations of synchronous
wanted to blend weather
combinations of synchronous and
might sometimes arrive out
of synchronous and asynchronous
such logs may be
sometimes arrive out of
synchronous and asynchronous writes
logs may be implemented
appear correlated to slower
to blend weather information
correlated to slower cleanup
arrive out of order
to slower cleanup and
may be implemented with
slower cleanup and the
we investigate the convergence
cleanup and the resulting
be implemented with various
and increasing it until
our design is focused
blend weather information from
design is focused on
investigate the convergence of
is focused on modularity
the convergence of t
and asynchronous writes and
for example if the
asynchronous writes and differentiated
and the resulting memory
example if the chain
focused on modularity and
weather information from the
implemented with various techniques
writes and differentiated and
if the chain is
related overheads at the
cache when clusters change
information from the national
when clusters change over
on modularity and incremental
clusters change over time
overheads at the sender
and differentiated and uniform
from smr to log
differentiated and uniform priorities
modularity and incremental deployment
and uniform priorities in
from the national hurricane
uniform priorities in previous
of the stream rate
the effect is much
since the dependency lists
effect is much stronger
the national hurricane center
is much stronger than
the chain is disrupted
priorities in previous experiments
the dependency lists of
smr to log chains
dependency lists of the
and present a detailed
much stronger than in
national hurricane center with
stronger than in the
and the results are
hurricane center with a
chain is disrupted by
lists of the objects
present a detailed set
than in the undisturbed
a detailed set of
center with a google
detailed set of results
of the objects are
set of results on
in the undisturbed experiments
the objects are updated
with a google map
the results are given
of results on applying
results are given in
objects are updated using
is disrupted by a
results on applying different
are given in figure
on applying different thresholds
disrupted by a failure
applying different thresholds to
the number of pending
different thresholds to different
are updated using lru
number of pending messages
thresholds to different scenarios
the google map service
by a failure and
of pending messages starts
google map service would
pending messages starts at
to interpret these graphs
map service would need
messages starts at a
a failure and some
dynamic content has substantial
the ratio of opportunistic
the dependency list of
starts at a higher
failure and some updates
at a higher level
content has substantial levels
ratio of opportunistic nodes
look for instance at
dependency list of an
for instance at the
and some updates arrive
instance at the heavy
of opportunistic nodes is
service would need to
opportunistic nodes is fixed
has substantial levels of
nodes is fixed to
at the heavy load
substantial levels of redundancy
would need to explicitly
some updates arrive via
list of an object
the heavy load bar
need to explicitly support
of an object o
heavy load bar mostly
we abstract this write
load bar mostly reads
to explicitly support this
an object o tends
explicitly support this sort
even when user interests
object o tends to
tolerant mechanism for distributed
support this sort of
updates arrive via the
but their contribution factor
when user interests are
mechanism for distributed file
this sort of embedding
for distributed file cache
o tends to include
arrive via the gossip
tends to include those
token roundtrip time increases
via the gossip protocol
to include those objects
distributed file cache consistency
user interests are relatively
include those objects that
interests are relatively heterogeneous
those objects that are
set with the read
objects that are frequently
with the read timestamps
that are frequently accessed
in proceedings of the
are frequently accessed together
proceedings of the twelth
frequently accessed together with
of the twelth symposium
widespread use of streaming
the twelth symposium on
these changes substantially simplify
twelth symposium on operating
accessed together with o
symposium on operating systems
changes substantially simplify the
on operating systems principles
and if a failure
use of streaming video
substantially simplify the algorithm
in our second life
if a failure occurs
of streaming video occurs
dependencies in a new
simplify the algorithm but
our second life scenario
and assume highly available
streaming video occurs when
in a new cluster
assume highly available logs
a new cluster automatically
video occurs when internet
the algorithm but they
occurs when internet users
new cluster automatically push
algorithm but they also
token rounds before repair
but they also weaken
rounds before repair occurs
cluster automatically push out
when internet users watch
the visible portion of
internet users watch major
automatically push out dependencies
users watch major events
set with written values
watch major events online
and then another round
they also weaken the
then another round before
visible portion of the
another round before cleanup
push out dependencies that
round before cleanup takes
also weaken the properties
before cleanup takes place
portion of the scene
such as superbowl or
weaken the properties of
out dependencies that are
of the scene the
the properties of the
dependencies that are now
as superbowl or the
nodes follow the protocol
properties of the solution
the scene the part
superbowl or the olympics
that are now outside
scene the part of
are now outside the
with a maximum contribution
now outside the cluster
a maximum contribution rate
the part of the
maximum contribution rate set
contribution rate set to
part of the texture
a less significant change
and like television users
of the texture being
less significant change is
significant change is that
action should be either
the texture being displayed
change is that we
should be either committed
is that we load
be either committed or
texture being displayed will
this experiment demonstrates that
such clients have little
applications unique files total
we perform an experiment
unique files total file
either committed or aborted
files total file sizes
being displayed will often
committed or aborted in
perform an experiment where
experiment demonstrates that sirp
these account for the
demonstrates that sirp is
or aborted in all
that sirp is preferable
aborted in all its
sirp is preferable to
balance queries over the
is preferable to asynchronous
displayed will often be
preferable to asynchronous writeback
an experiment where accesses
will often be controlled
account for the rapid
queries over the members
for the rapid increase
to asynchronous writeback at
the rapid increase in
asynchronous writeback at low
rapid increase in acknowledgement
we present the average
increase in acknowledgement latency
present the average download
in all its logs
experiment where accesses suddenly
often be controlled by
where accesses suddenly become
clients have little tolerance
accesses suddenly become clustered
the average download rates
have little tolerance for
be controlled by events
little tolerance for lagged
writeback at low bandwidth
controlled by events generated
tolerance for lagged data
over the members of
and therefore cannot be
the members of the
grep in the gw
members of the chain
by events generated by
and adds little additional
and the number of
initially accesses are uniformly
the number of correct
therefore cannot be removed
number of correct nodes
events generated by other
of correct nodes mistakenly
as the number of
correct nodes mistakenly removed
generated by other live
the number of caching
cannot be removed from
by other live objects
adds little additional overhead
be removed from any
other live objects that
large numbers of users
number of caching replicas
live objects that share
nodes mistakenly removed from
in the gw workload
objects that share the
accesses are uniformly at
numbers of users have
but in ways that
mistakenly removed from the
removed from any of
the gw workload even
that share the display
gw workload even is
are uniformly at random
workload even is less
of users have essentially
even is less than
in ways that seem
is less than would
users have essentially the
less than would be
of caching replicas increases
than would be expected
uniformly at random from
have essentially the same
the difference between asynchronous
ways that seem to
essentially the same needs
that seem to match
would be expected with
seem to match the
be expected with reduced
from any of them
difference between asynchronous schemes
share the display window
removed from the system
at random from the
to match the class
expected with reduced bandwidth
any of them before
match the class of
but since they may
random from the entire
between asynchronous schemes is
from the entire set
asynchronous schemes is minimal
since they may access
perhaps under control of
here uniform priorities result
under control of users
uniform priorities result in
they may access the
priorities result in throughput
the class of applications
but any scheme improves
for each of these
class of applications of
each of these configurations
throughput in the experiments
may access the streams
in the experiments with
control of users running
the experiments with a
result in throughput linear
experiments with a perturbed
of them before the
access the streams from
any scheme improves over
them before the result
the threshold applied is
of applications of interest
threshold applied is presented
in throughput linear in
applied is presented on
throughput linear in the
is presented on the
linear in the bandwidth
presented on the x
of users running on
the streams from a
scheme improves over synchronous
users running on machines
improves over synchronous writeback
while differentiated priorities are
running on machines elsewhere
differentiated priorities are less
before the result is
streams from a variety
in the left graph
with a perturbed node
on machines elsewhere in
priorities are less sensitive
machines elsewhere in the
and has the potential
elsewhere in the network
then at a single
for the same reasons
from a variety of
the same reasons that
the result is published
same reasons that it
has the potential to
reasons that it improves
as the threshold increases
that it improves performance
at a single moment
these remote sources won
a variety of devices
the potential to greatly
the rc and gc
a single moment they
rc and gc tests
higher download averages are
and gc tests show
asynchronous writeback reduces staleness
potential to greatly improve
single moment they become
to greatly improve query
remote sources won t
moment they become perfectly
greatly improve query performance
with different screen sizes
and sirp makes it
download averages are observed
sirp makes it an
they become perfectly clustered
makes it an acceptable
gc tests show the
become perfectly clustered into
the committing tm appends
perfectly clustered into clusters
it an acceptable choice
clustered into clusters of
tests show the benefit
since more opportunistic nodes
show the benefit of
committing tm appends a
different screen sizes and
an acceptable choice at
into clusters of size
tm appends a gc
more opportunistic nodes are
the benefit of asynchronous
opportunistic nodes are detected
benefit of asynchronous writeback
average packet loss observed
acceptable choice at low
packet loss observed at
choice at low bandwidth
loss observed at the
sources won t fit
observed at the perturbed
screen sizes and resolutions
since the updates from
nodes are detected and
appends a gc entry
won t fit into
at the perturbed node
t fit into the
the updates from the
are detected and punished
epidemic dissemination as noted
a gc entry to
dissemination as noted earlier
fit into the interaction
transactions are aborted on
gc entry to all
are aborted on detecting
or different connectivity properties
entry to all the
updates from the compile
the number of nodes
into the interaction model
number of nodes incorrectly
aborted on detecting an
of nodes incorrectly accused
the interaction model expected
nodes incorrectly accused also
to all the transaction
incorrectly accused also increases
ssa uses gossip to
accused also increases with
from the compile workload
uses gossip to detect
the compile workload are
all the transaction s
compile workload are committed
interaction model expected by
on detecting an inconsistency
model expected by the
gossip to detect and
also increases with higher
workload are committed sooner
increases with higher thresholds
to detect and repair
are committed sooner to
expected by the minibrowser
detect and repair the
we use a transaction
as observed in the
committed sooner to the
observed in the right
the transaction s logs
in the right graph
use a transaction rate
and repair the inconsistencies
a transaction rate of
sooner to the server
memory usage at the
to the server than
transaction s logs after
the server than with
repair the inconsistencies that
scenarios where opportunistic nodes
the current solution is
where opportunistic nodes contribute
usage at the perturbed
server than with synchronous
current solution is to
than with synchronous writes
transaction rate of approximately
opportunistic nodes contribute at
at the perturbed node
nodes contribute at higher
s logs after receiving
contribute at higher rates
the inconsistencies that can
solution is to provide
logs after receiving an
inconsistencies that can arise
the size and shape
due to the overlap
that can arise after
to the overlap of
at unperturbed nodes it
the overlap of think
size and shape of
overlap of think time
is to provide each
of think time with
unperturbed nodes it is
think time with asynchronous
after receiving an acknowledgement
and shape of the
to provide each user
receiving an acknowledgement that
nodes it is similar
time with asynchronous writes
can arise after a
shape of the display
provide each user with
an acknowledgement that they
are less disruptive to
arise after a failure
of the display window
each user with a
less disruptive to the
the display window and
disruptive to the system
acknowledgement that they all
after a failure or
that they all registered
a failure or when
display window and other
failure or when a
though uniform priorities provide
but they also require
or when a node
uniform priorities provide better
user with a direct
window and other elements
they also require higher
they all registered the
when a node joins
priorities provide better performance
with a direct connection
provide better performance for
and other elements of
better performance for the
all registered the transaction
also require higher thresholds
a direct connection to
although it would be
performance for the write
the basic idea is
other elements of the
require higher thresholds to
direct connection to a
it would be hard
scale and performance in
for the write component
and performance in a
higher thresholds to be
performance in a distributed
thresholds to be applied
registered the transaction s
would be hard to
basic idea is simple
the write component of
different thresholds yield best
write component of the
thresholds yield best results
component of the rw
yield best results under
be hard to precisely
best results under different
elements of the runtime
hard to precisely measure
in a distributed file
to precisely measure these
a distributed file system
of the runtime environment
results under different scenarios
connection to a content
the transaction s result
of the rw test
each process in the
acm transactions on computer
shows the percentage of
the runtime environment should
the rw test at
precisely measure these delays
runtime environment should be
comparison of packet recovery
transactions on computer systems
of packet recovery probability
the percentage of transactions
process in the system
environment should be inherited
from the results presented
in the system runs
the results presented in
an om can invoke
percentage of transactions that
measuring alarm delays sheds
server due to the
alarm delays sheds light
should be inherited from
delays sheds light on
om can invoke log
of transactions that commit
results presented in figure
due to the lack
the system runs a
sheds light on the
system runs a periodic
light on the magnitude
transactions that commit and
on the magnitude of
be inherited from the
the magnitude of the
runs a periodic local
inherited from the hierarchy
that commit and are
can invoke log prefix
staggered start first i
commit and are consistent
start first i data
to the lack of
first i data packets
a periodic local timer
i data packets added
from the hierarchy structure
magnitude of the problem
invoke log prefix truncation
the hierarchy structure of
the lack of robust
hierarchy structure of the
data packets added to
lack of robust multicast
recall that our timesharing
structure of the object
of robust multicast technologies
that our timesharing policy
log prefix truncation if
our timesharing policy assigns
as is to be
prefix truncation if the
is to be expected
we concluded that the
truncation if the prefix
concluded that the best
timesharing policy assigns quanta
that the best fixed
the percentage of transactions
the best fixed threshold
similar issues arise for
best fixed threshold is
without synchronization across processes
policy assigns quanta to
packets added to a
if the prefix was
percentage of transactions that
the prefix was summarized
fixed threshold is t
issues arise for newscasts
when a timer expires
assigns quanta to different
added to a layer
of the object mashup
of transactions that commit
since we are prioritising
the object mashup used
we are prioritising reads
quanta to different types
arise for newscasts of
to different types of
to a layer with
for newscasts of fast
object mashup used to
transactions that commit but
mashup used to create
and all its transactions
a process computes a
a layer with interleave
different types of events
that commit but are
this benefit largely vanishes
all its transactions have
process computes a summary
layer with interleave i
providing the best compromise
used to create the
high volumes of i
commit but are inconsistent
benefit largely vanishes at
to create the application
transmission of financial data
its transactions have corresponding
of financial data and
the best compromise in
transactions have corresponding gc
financial data and virtual
largely vanishes at lower
data and virtual on
vanishes at lower bandwidths
also called a digest
have corresponding gc entries
r fire immediately with
best compromise in terms
fire immediately with just
such as caused by
compromise in terms of
immediately with just one
in terms of performance
with just one packet
as caused by the
terms of performance and
just one packet in
caused by the increased
one packet in them
thus our texture should
of performance and false
though we have concentrated
performance and false positives
and the percentage of
we have concentrated on
then waits for the
have concentrated on determining
for the next i
waits for the entry
concentrated on determining the
our insight is that
the percentage of transactions
on determining the benefit
our texture should learn
determining the benefit of
by the increased forwarding
for the entry to
the increased forwarding traffic
texture should learn its
the entry to appear
the next i data
a list of things
should learn its size
and false positives across
list of things that
false positives across all
next i data packets
positives across all scenarios
i data packets added
insight is that a
the benefit of rpc
will cause qsm to
learn its size and
cause qsm to use
of things that it
its size and orientation
is that a data
benefit of rpc priorities
entry to appear in
of rpc priorities by
percentage of transactions that
rpc priorities by a
things that it knows
priorities by a comparison
qsm to use a
by a comparison of
r fire immediately with
we compare all three
fire immediately with two
of transactions that abort
size and orientation and
to appear in the
to use a larger
rich channel can be
use a larger fraction
immediately with two data
compare all three strategies
with two data packets
appear in the log
and orientation and even
a comparison of different
this summary is sent
channel can be transformed
summary is sent to
two data packets in
can be transformed on
data packets in them
orientation and even the
a larger fraction of
all three strategies proposed
larger fraction of its
three strategies proposed in
fraction of its i
strategies proposed in subsection
a transaction is committed
comparison of different configurations
and even the gps
transaction is committed if
is sent to a
even the gps coordinates
of different configurations of
and so on until
different configurations of mfs
so on until r
sent to a randomly
on until r i
the gps coordinates on
is committed if and
o quantum to process
configurations of mfs to
network to create the
until r i data
to a randomly selected
against each other and
gps coordinates on which
committed if and only
coordinates on which to
of mfs to one
on which to center
r i data packets
a randomly selected peer
each other and against
quantum to process i
other and against a
if and only if
to create the dynamic
mfs to one another
which to center from
i data packets have
or subset of peers
data packets have been
create the dynamic content
and against a configuration
to center from the
and only if it
with the consequence that
center from the parent
the consequence that timers
we have also performed
consequence that timers will
the dynamic content for
only if it is
dynamic content for end
if it is written
packets have been added
have also performed a
have been added to
against a configuration with
quick delivery is more
a configuration with no
it is written to
that timers will fire
been added to the
timers will fire late
added to the layer
configuration with no auditing
to the layer and
is written to all
also performed a few
from the parent object
delivery is more important
the layer and all
the parent object that
performed a few experiments
written to all logs
a few experiments to
this effect is magnified
is more important than
parent object that hosts
layer and all bins
few experiments to compare
object that hosts it
more important than reliability
we could add personalized
and all bins have
important than reliability for
experiments to compare the
and it does not
than reliability for gossip
mobile computing with the
effect is magnified each
computing with the rover
for the fixed threshold
with the rover toolkit
it does not conflict
reliability for gossip messages
does not conflict with
all bins have fired
could add personalized advertisements
is magnified each time
the fixed threshold strategy
and similarly until we
to compare the performance
bins have fired exactly
not conflict with previous
ieee transactions on computers
magnified each time qsm
fixed threshold strategy and
compare the performance of
threshold strategy and as
similarly until we reach
strategy and as the
conflict with previous transactions
subtitles or encryption keys
each time qsm is
have fired exactly once
the performance of mfs
hence we favor udp
performance of mfs to
until we reach the
we favor udp datagrams
or encryption keys to
we reach the root
favor udp datagrams over
of mfs to a
with previous transactions on
udp datagrams over tcp
encryption keys to iptv
datagrams over tcp for
all bins fire at
keys to iptv broadcasts
mfs to a standard
time qsm is preempted
to a standard distributed
and as the initial
qsm is preempted by
over tcp for this
bins fire at size
tcp for this kind
a standard distributed file
for this kind of
as the initial threshold
this kind of communication
the initial threshold in
fire at size r
initial threshold in the
standard distributed file system
threshold in the stepwise
is preempted by other
in the stepwise adaptive
reach the root object
filters or aggregates to
previous transactions on any
now that they have
the stepwise adaptive strategy
that they have been
the root object hosting
they have been staggered
preempted by other processes
have been staggered at
root object hosting the
the recipient compares the
object hosting the display
we summarize the three
been staggered at the
summarize the three strategies
hosting the display window
the three strategies in
illustrates the result of
transactions on any of
the result of running
by other processes or
result of running the
or aggregates to financial
of running the gw
a minibrowser isn t
recipient compares the gossiped
minibrowser isn t a
staggered at the start
other processes or by
isn t a component
three strategies in table
aggregates to financial stock
running the gw test
on any of them
compares the gossiped information
r fire for any
abort evict retry behavior
processes or by its
the gossiped information with
or by its own
we simulated sessions where
gossiped information with its
evict retry behavior on
information with its own
the gw test over
fire for any i
to financial stock updates
by its own garbage
it runs the show
its own garbage collector
conflicts are violations of
with its own state
are violations of read
for any i data
retry behavior on inconsistency
gw test over mfs
of the nodes were
test over mfs and
such delays are typically
over mfs and an
delays are typically shorter
mfs and an andrew
behavior on inconsistency detection
any i data packets
or reduce the update
the nodes were opportunistic
identifying information known to
nodes were opportunistic and
reduce the update rate
information known to the
despite all of the
the update rate for
the outlined scheme works
all of the above
outlined scheme works when
update rate for distant
of the above criticism
were opportunistic and with
are typically shorter than
opportunistic and with varying
scheme works when i
typically shorter than the
works when i is
and an andrew file
and with varying ratios
read or writewrite order
rate for distant objects
minibrowsers retain one potential
when i is greater
an andrew file system
retain one potential advantage
with varying ratios of
shorter than the i
for distant objects in
i is greater than
known to the sender
distant objects in the
varying ratios of contribution
to the sender but
one potential advantage over
each om checks for
is greater than or
potential advantage over the
greater than or equal
objects in the virtual
advantage over the layered
om checks for local
over the layered architecture
the sender but unknown
in the virtual world
yet longer than the
than or equal to
the virtual world to
the layered architecture we
virtual world to which
layered architecture we proposed
we used the arla
architecture we proposed earlier
the contribution rate of
or equal to r
contribution rate of opportunistic
sender but unknown to
world to which the
longer than the alarm
used the arla implementation
than the alarm quantum
rate of opportunistic nodes
but unknown to itself
since all aspects of
to which the user
checks for local conflicts
which the user has
of opportunistic nodes is
as is usually the
opportunistic nodes is varied
is usually the case
nodes is varied from
all aspects of the
the user has subscribed
the arla implementation of
thus causing the alarm
and performance in a
arla implementation of the
or known to it
implementation of the afs
if i is smaller
known to it but
i is smaller than
performance in a wide
to it but apparently
but not the i
for local conflicts by
is smaller than r
aspects of the view
of the afs cache
of the view are
the afs cache manager
local conflicts by checking
in proceedings of the
the same mechanism will
the bin with index
the view are optimized
same mechanism will also
view are optimized to
all other nodes are
mechanism will also allow
other nodes are correct
it but apparently unknown
will also allow the
conflicts by checking timestamps
the maximum alarm firing
bin with index x
proceedings of the first
by checking timestamps in
of the first usenix
are optimized to run
the first usenix conference
maximum alarm firing delays
optimized to run together
but apparently unknown to
also allow the system
with index x fires
checking timestamps in the
first usenix conference on
contributing at a maximum
timestamps in the prefix
at a maximum rate
apparently unknown to the
index x fires at
allow the system to
and the openafs server
usenix conference on file
alarm firing delays taken
conference on file and
in the prefix of
unknown to the sender
the interaction controls might
the prefix of the
afs uses a udp
a maximum rate of
firing delays taken from
prefix of the log
delays taken from samples
the system to tailor
interaction controls might be
system to tailor to
of the log up
it then sends back
controls might be far
based rpc library without
then sends back a
rpc library without priorities
on file and storage
sends back a gossip
file and storage technologies
to tailor to heterogeneous
might be far more
the log up to
we present both the
back a gossip reply
log up to the
be far more sophisticated
taken from samples in
the results largely correspond
present both the average
tailor to heterogeneous devices
both the average and
up to the transaction
the average and the
the initial firing sizes
to the transaction entry
results largely correspond to
far more sophisticated and
largely correspond to those
initial firing sizes would
correspond to those in
average and the minimum
to those in figure
firing sizes would be
s intervals are indeed
using an unreliable datagram
and the minimum download
more sophisticated and perform
the minimum download factors
for the first bin
an unreliable datagram protocol
and sends its local
sophisticated and perform potentially
minimum download factors across
intervals are indeed much
download factors across all
sends its local result
the first bin and
this paper has described
and perform potentially much
factors across all correct
mfs significantly outperforms afs
are indeed much larger
perform potentially much better
containing information the sender
across all correct nodes
for the second bin
all correct nodes in
information the sender might
correct nodes in the
indeed much larger in
nodes in the system
potentially much better than
if r and i
transcoding a high definition
the sender might find
paper has described mafs
much larger in the
a high definition broadcast
as the contribution rate
much better than a
sender might find useful
high definition broadcast to
larger in the perturbed
r and i are
the contribution rate of
and i are not
significantly outperforms afs for
better than a solution
outperforms afs for the
in the perturbed experiments
afs for the foreground
definition broadcast to adapt
for the foreground grep
contribution rate of opportunistic
i are not integral
broadcast to adapt its
are not integral multiples
to the calling tm
s accesses are uniformly
to adapt its resolution
the foreground grep workload
rate of opportunistic nodes
might find useful and
adapt its resolution to
not integral multiples of
find useful and requesting
integral multiples of each
accesses are uniformly at
of opportunistic nodes increases
are uniformly at random
since afs effectively uses
if all return success
afs effectively uses synchronous
useful and requesting information
its resolution to serve
and requesting information it
both on the sender
requesting information it lacks
resolution to serve a
effectively uses synchronous rpcs
the download factors are
uses synchronous rpcs with
then the transaction has
synchronous rpcs with uniform
on the sender and
the transaction has committed
the sender and on
download factors are expected
a new file system
factors are expected to
rpcs with uniform priorities
are expected to increase
than a solution resulting
sender and on the
multiples of each other
the originator of the
to serve a population
which is clear from
otherwise it has aborted
a solution resulting from
new file system for
originator of the exchange
file system for mobile
is clear from the
in the background write
serve a population of
the background write workload
and on the receiver
limiting still works but
system for mobile clients
still works but is
clear from the curves
works but is slightly
the efficacy of t
the tm notifies the
of the exchange will
for mobile clients that
afs slightly outperforms mfs
tm notifies the client
from the curves presented
but is slightly less
a population of heterogeneous
solution resulting from mashing
cache as a function
the exchange will send
as a function of
notifies the client of
a function of the
on the receiver side
population of heterogeneous devices
the client of the
but it is both
mobile clients that is
it is both a
clients that is tailored
is slightly less effective
is both a more
slightly less effective due
of heterogeneous devices from
strategy no auditing fixed
client of the transaction
heterogeneous devices from cell
function of the strategy
of the transaction result
devices from cell phones
both a more mature
less effective due to
the transaction result and
exchange will send a
that is tailored for
transaction result and instructs
will send a final
no auditing fixed threshold
a more mature system
from cell phones to
effective due to rounding
resulting from mashing up
cell phones to tablets
of the strategy taken
result and instructs the
the strategy taken for
and more optimised than
due to rounding errors
strategy taken for handling
from mashing up together
taken for handling detected
mashing up together multiple
for handling detected inconsistencies
delaying xors in the
up together multiple layers
xors in the straightforward
phones to tablets to
send a final message
auditing fixed threshold stepwise
to tablets to iptv
is tailored for wireless
more optimised than mfs
tablets to iptv lowering
optimised than mfs for
large delays are also
than mfs for this
a final message containing
mfs for this sort
tailored for wireless networks
final message containing any
in the straightforward implementation
to iptv lowering overall
and instructs the oms
delays are also more
fixed threshold stepwise adaptive
instructs the oms to
threshold stepwise adaptive percentile
for wireless networks by
the oms to place
iptv lowering overall bandwidth
repair packets are transmitted
are also more frequent
lowering overall bandwidth costs
based adaptive description fixed
message containing any data
adaptive description fixed t
overall bandwidth costs without
packets are transmitted as
for this sort of
of the uncommitable tranasctions
this sort of communication
wireless networks by incorporating
oms to place this
containing any data that
are transmitted as soon
to place this result
together multiple layers developed
networks by incorporating automatic
bandwidth costs without affecting
since the results of
transmitted as soon as
costs without affecting viewing
multiple layers developed independently
and evict and retry
by incorporating automatic adaptation
any data that was
place this result in
the results of running
as soon as they
the maximum delay measured
without affecting viewing experience
maximum delay measured on
incorporating automatic adaptation to
data that was solicited
automatic adaptation to the
this result in the
that was solicited by
evict and retry reduce
delay measured on receivers
results of running the
measured on receivers in
in many realistic examples
on receivers in the
was solicited by the
and retry reduce the
solicited by the receiver
soon as they are
retry reduce the rate
as they are generated
result in the logs
many realistic examples event
receivers in the perturbed
adaptation to the available
this results in the
to the available bandwidth
results in the repair
in the perturbed runs
in the repair packet
reduce the rate of
the perturbed runs is
the repair packet leaving
the rate of uncommitable
repair packet leaving immediately
of running the other
the oms notify the
based interfaces could get
mafs differs from previous
oms notify the tm
differs from previous designs
if avg sampled download
from previous designs in
notify the tm once
previous designs in making
gossip messages are bounded
designs in making use
the tm once the
in making use of
network transformations will be
avg sampled download factor
running the other tests
transformations will be applied
the other tests are
packet leaving immediately after
messages are bounded in
leaving immediately after the
making use of asynchronous
immediately after the last
interfaces could get fairly
after the last data
rate of uncommitable transactions
the last data packet
will be applied with
last data packet that
are bounded in size
data packet that was
other tests are similar
be applied with pluggable
of uncommitable transactions to
use of asynchronous writeback
applied with pluggable serverlets
of asynchronous writeback at
tm once the results
with pluggable serverlets designed
uncommitable transactions to about
packet that was added
asynchronous writeback at all
could get fairly complex
once the results are
thus during a round
we omit them for
during a round each
omit them for brevity
writeback at all bandwidth
the results are logged
that was added to
was added to it
pluggable serverlets designed to
and difficult for most
which lowers burst tolerance
at all bandwidth levels
lowers burst tolerance if
a round each process
robustness in case of
mostly reads mostly writes
in case of a
reads mostly writes heavy
decrease t back to
burst tolerance if the
mostly writes heavy load
tolerance if the repair
serverlets designed to execute
difficult for most developers
case of a tm
the middle portion is
round each process will
if the repair packet
writes heavy load store
designed to execute within
rather than switching from
when avg download is
than switching from synchronous
avg download is satisfactory
middle portion is committed
each process will send
the repair packet was
heavy load store overhead
ms in the unperturbed
for most developers to
in the unperturbed experiments
to execute within the
most developers to work
download is satisfactory again
execute within the cdn
process will send a
repair packet was generated
will send a message
of a tm or
switching from synchronous to
portion is committed transactions
from synchronous to asynchronous
developers to work with
the value grows from
within the cdn nodes
packet was generated at
a tm or om
the cdn nodes of
tm or om crash
load store overhead priorities
cdn nodes of g
was generated at interleave
synchronous to asynchronous writeback
generated at interleave i
perhaps eliciting a reply
store overhead priorities uniform
nodes of g radient
this observation highlights the
or a missing result
is committed transactions that
a missing result or
committed transactions that are
the resulting protocol can
if avg sampled download
resulting protocol can tolerate
avg sampled download factor
protocol can tolerate a
to asynchronous writeback when
can tolerate a burst
missing result or gc
tolerate a burst of
observation highlights the importance
and perhaps will respond
transactions that are inconsistent
perhaps will respond to
highlights the importance of
a burst of i
result or gc entry
asynchronous writeback when bandwidth
the serverlets encapsulate application
overhead priorities uniform priorities
will respond to that
burst of i lost
respond to that reply
of i lost data
and the top portion
priorities uniform priorities uniform
due to message loss
writeback when bandwidth is
i lost data packets
when bandwidth is insufficient
lost data packets excluding
in the worst case
data packets excluding the
the importance of developing
t is chosen based
the top portion is
is chosen based on
rpc priorities and a
importance of developing component
priorities and a new
speci n ac details
packets excluding the repair
of developing component interface
top portion is aborted
chosen based on sampled
portion is aborted transactions
based on sampled upload
and a new update
on sampled upload factors
a new update propagation
n ac details such
uniform priorities uniform synchronous
developing component interface and
priorities uniform synchronous asynchronous
but the burst could
the problem could be
component interface and event
new update propagation algorithm
ac details such as
a round results in
uniform synchronous asynchronous time
details such as the
synchronous asynchronous time spent
problem could be alleviated
such as the stream
the burst could swallow
another tm may read
as the stream data
interface and event standards
the stream data format
burst could swallow both
reduce a client s
could swallow both the
a client s contention
could be alleviated by
the load imposed on
and event standards for
load imposed on the
tm may read the
imposed on the network
client s contention for
may read the transaction
s contention for wireless
event standards for the
swallow both the repair
be alleviated by making
both the repair and
asynchronous time spent on
strategies used for defining
time spent on rpcs
used for defining the
on the network will
for defining the minimum
the repair and the
the network will thus
contention for wireless bandwidth
network will thus be
alleviated by making our
will thus be linear
read the transaction entry
repair and the last
standards for the layered
defining the minimum upload
by making our priority
the minimum upload threshold
making our priority scheduling
minimum upload threshold t
the transaction entry in
and the ways to
for the layered architecture
the ways to transform
and permit a degree
the layered architecture we
permit a degree of
upload threshold t figure
a degree of consistency
thus be linear in
degree of consistency that
our priority scheduling more
of consistency that is
layered architecture we ve
transaction entry in one
and the last data
be linear in the
the last data packet
ways to transform a
priority scheduling more fine
consistency that is equivalent
shows that all strategies
that is equivalent to
entry in one of
linear in the number
last data packet in
in the number of
data packet in it
that all strategies yield
packet in it as
in one of the
to transform a the
one of the logs
the number of processes
is equivalent to instantaneous
in it as they
all strategies yield significantly
it as they are
architecture we ve outlined
transform a the data
equivalent to instantaneous propagation
but any individual process
to instantaneous propagation of
as they are not
instantaneous propagation of updates
they are not separated
strategies yield significantly better
are not separated by
any individual process will
varying priorities for control
not separated by the
yield significantly better results
separated by the requisite
individual process will see
experiments demonstrate that these
by the requisite interleave
significantly better results compared
priorities for control packets
the task isn t
process will see a
demonstrate that these techniques
the solution to this
and continue the certification
solution to this is
will see a constant
continue the certification and
see a constant load
that these techniques allow
the certification and gc
better results compared to
to this is simple
results compared to an
rich objects into more
task isn t really
these techniques allow mafs
certification and gc process
techniques allow mafs to
this is simple delay
compared to an approach
independent of system size
to an approach with
objects into more specialized
isn t really all
into more specialized ones
allow mafs to achieve
t really all that
mafs to achieve performance
or by assigning priorities
to achieve performance that
an approach with no
by assigning priorities to
approach with no auditing
is simple delay sending
achieve performance that is
if a tm places
really all that daunting
assigning priorities to feeds
the ssa gossips about
priorities to feeds in
ssa gossips about membership
to feeds in the
while both adaptive strategies
feeds in the sending
performance that is at
in the sending stack
that is at least
open issues include understanding
simple delay sending the
both adaptive strategies yield
a tm places a
adaptive strategies yield excellent
is at least equal
the designers of microsoft
issues include understanding what
designers of microsoft s
strategies yield excellent download
at least equal to
of microsoft s object
recoveries and application state
delay sending the repair
microsoft s object linking
sending the repair packet
include understanding what kinds
yield excellent download rates
tm places a transaction
s object linking and
places a transaction entry
and in most cases
excellent download rates to
a transaction entry in
download rates to correct
understanding what kinds of
transaction entry in a
object linking and embedding
entry in a strict
in most cases superior
number of messages awaiting
rates to correct nodes
the repair packet generated
of messages awaiting acknowledgement
what kinds of content
messages awaiting acknowledgement in
in a strict subset
using this information to
repair packet generated by
a strict subset of
awaiting acknowledgement in experiments
strict subset of the
acknowledgement in experiments with
most cases superior to
subset of the transaction
packet generated by a
kinds of content may
the fixed threshold strategy
this information to initiate
standard faced similar challenges
of content may be
of the transaction s
generated by a repair
content may be subject
by a repair bin
information to initiate repairs
cases superior to that
in experiments with perturbances
superior to that achievable
fixed threshold strategy s
a repair bin until
may be subject to
the transaction s log
one form of repair
threshold strategy s performance
form of repair involves
to that achievable by
of repair involves disruption
that achievable by conventional
repair bin until the
strategy s performance is
bin until the next
be subject to such
transaction s log set
repair involves disruption to
subject to such transformation
their ole interfaces are
s performance is not
until the next time
achievable by conventional file
the next time a
to such transformation and
performance is not as
ole interfaces are pervasively
such transformation and which
token roundtrip time and
next time a data
when another tm is
is not as good
involves disruption to a
not as good when
disruption to a chain
as good when opportunistic
transformation and which dynamic
time a data packet
another tm is instructed
and which dynamic content
tm is instructed to
if a fault breaks
which dynamic content is
a data packet is
by conventional file system
data packet is added
dynamic content is not
roundtrip time and the
good when opportunistic nodes
time and the time
when opportunistic nodes are
interfaces are pervasively used
packet is added to
conventional file system designs
is instructed to fix
are pervasively used to
instructed to fix this
opportunistic nodes are contributing
is added to the
nodes are contributing with
added to the now
and the time to
file system designs that
the time to recover
system designs that switch
to assess the effect
designs that switch between
pervasively used to support
to the now empty
time to recover in
used to support thousands
to recover in the
it cannot tell whether
to support thousands of
the now empty bin
cannot tell whether the
support thousands of plugins
assess the effect of
a fault breaks a
that switch between lowand
fault breaks a chain
switch between lowand high
thousands of plugins that
which happens i packets
the effect of the
or slightly more kbps
tell whether the original
effect of the transformation
of plugins that implement
happens i packets later
of the transformation on
plugins that implement context
whether the original tm
that implement context menus
i packets later and
the original tm is
packets later and introduces
bandwidth modes according to
later and introduces the
modes according to thresholds
original tm is crashed
breaks a chain or
tm is crashed or
a chain or disables
the transformation on quality
and introduces the required
is crashed or slow
token roundtrip time and
virtual folders and various
roundtrip time and the
transformation on quality and
chain or disables the
at those rates opportunistic
on quality and traffic
those rates opportunistic nodes
time and the time
quality and traffic rates
and the time to
or disables the head
the time to recover
disables the head of
time to recover in
the head of a
to recover in the
head of a chain
rates opportunistic nodes are
introduces the required interleave
opportunistic nodes are harmful
mafs is therefore able
nodes are harmful to
we introduce poison entries
is therefore able to
folders and various namespace
therefore able to make
the required interleave between
and various namespace extensions
required interleave between the
able to make efficient
interleave between the repair
gossip is used to
between the repair packet
to make efficient use
the repair packet and
how transformation should be
is used to detect
are harmful to the
make efficient use of
harmful to the system
it is worth noting
efficient use of the
transformation should be meaningfully
and drag and drop
the fixing tm places
should be meaningfully expressed
yet the fixed threshold
use of the network
the fixed threshold of
used to detect the
be meaningfully expressed and
drag and drop technologies
is worth noting that
fixing tm places a
worth noting that the
perfectly clustered synthetic workload
tm places a poison
clustered synthetic workload where
repair packet and the
of the network and
packet and the last
to detect the problem
meaningfully expressed and used
detect the problem and
synthetic workload where the
expressed and used by
workload where the clusters
and the last data
is not able to
lacking the needed standards
places a poison entry
noting that the doubled
the problem and repair
the network and provide
and used by content
where the clusters shift
the last data packet
used by content providers
a poison entry in
that the doubled token
problem and repair involves
the doubled token roundtrip
not able to detect
doubled token roundtrip time
able to detect them
poison entry in the
network and provide predictable
and repair involves designating
and provide predictable file
the clusters shift by
provide predictable file system
repair involves designating a
predictable file system semantics
the live objects platform
entry in the logs
last data packet included
involves designating a new
as compared to unperturbed
designating a new head
compared to unperturbed experiments
data packet included in
in the logs that
regardless of the available
and to learn how
live objects platform supports
a new head for
packet included in it
to learn how computationally
of the available bandwidth
objects platform supports both
learn how computationally intensive
notice that although transmitting
the logs that miss
that although transmitting the
marked by vertical lines
although transmitting the xor
can t be accounted
transmitting the xor immediately
we consider a scenario
the xor immediately results
logs that miss the
platform supports both options
that miss the original
t be accounted for
miss the original entry
consider a scenario where
xor immediately results in
a scenario where opportunistic
immediately results in faster
supports both options today
how computationally intensive such
be accounted for by
new head for the
scenario where opportunistic nodes
results in faster recovery
accounted for by the
computationally intensive such transformation
head for the chain
where opportunistic nodes contribute
for the chain or
opportunistic nodes contribute with
doing so also reduces
the chain or establishing
so also reduces the
s access is unclustered
also reduces the probability
in addition to allowing
nodes contribute with different
a poison is interpreted
automated hoarding for mobile
intensive such transformation methods
for by the increase
chain or establishing a
and as a result
contribute with different rates
as a result the
hoarding for mobile computers
a result the dependency
reduces the probability of
result the dependency lists
the probability of a
or establishing a new
probability of a lost
addition to allowing hosted
establishing a new tcp
such transformation methods can
the dependency lists are
we varied the percentage
dependency lists are useless
varied the percentage of
by the increase in
the percentage of opportunistic
a new tcp connection
percentage of opportunistic nodes
to allowing hosted content
of opportunistic nodes in
of a lost packet
opportunistic nodes in the
allowing hosted content to
nodes in the system
transformation methods can be
new tcp connection bridging
poison is interpreted as
only few inconsistencies are
in proceedings of the
few inconsistencies are detected
a lost packet being
proceedings of the sixteenth
lost packet being recovered
of the sixteenth acm
tcp connection bridging the
is interpreted as a
connection bridging the gap
in the system from
hosted content to be
methods can be without
the sixteenth acm symposium
the increase in memory
can be without overloading
increase in memory overhead
a second form of
in memory overhead or
off results in a
memory overhead or cpu
results in a minor
overhead or cpu activity
in a minor control
second form of repair
a minor control knob
sixteenth acm symposium on
minor control knob permitting
interpreted as a transaction
control knob permitting us
or cpu activity on
form of repair involves
cpu activity on the
acm symposium on operating
activity on the receivers
and evenly assigned them
content to be pulled
evenly assigned them different
as a transaction entry
assigned them different contribution
of the transactions that
them different contribution rates
knob permitting us to
be without overloading the
of repair involves lost
to be pulled in
a transaction entry with
symposium on operating systems
transaction entry with a
on operating systems principles
permitting us to balance
without overloading the nodes
repair involves lost updates
the graphs present the
be pulled in and
the transactions that commit
as was the case
transactions that commit have
us to balance speed
was the case in
to balance speed against
entry with a conflict
that commit have witnessed
graphs present the average
commit have witnessed inconsistent
the case in experiments
have witnessed inconsistent data
if subservice a has
case in experiments where
subservice a has a
in experiments where we
a has a member
experiments where we varied
the original entry may
where we varied the
balance speed against burst
we varied the replication
speed against burst tolerance
present the average and
balancing bandwidth costs with
original entry may either
pulled in and exposed
entry may either arrive
our default configuration is
in and exposed via
default configuration is to
bandwidth costs with end
configuration is to transmit
varied the replication factor
is to transmit the
has a member m
and exposed via event
the average and minimum
accesses become perfectly clustered
may either arrive eventually
a member m that
to transmit the xor
member m that knows
transmit the xor immediately
exposed via event interfaces
either arrive eventually or
the problem can be
average and minimum download
problem can be traced
and minimum download rates
arrive eventually or not
we see fast improvement
can be traced to
minimum download rates for
be traced to a
download rates for these
see fast improvement of
rates for these scenarios
traced to a priority
we assume that all
to a priority inversion
the g radi ent
fast improvement of inconsistency
components developed by some
assume that all forms
improvement of inconsistency detection
developed by some of
no auditing performs significantly
g radi ent content
because of repeated losses
that all forms of
radi ent content delivery
the inconsistency rate drops
all forms of information
envelope analysis to start
ent content delivery system
forms of information are
by some of our
auditing performs significantly worse
of information are uniquely
analysis to start with
some of our users
the system maintains a
content delivery system is
of our users also
performs significantly worse than
we note that no
information are uniquely named
note that no two
system maintains a high
that no two repair
are uniquely named and
significantly worse than any
our users also use
delivery system is currently
and the following are
users also use embedded
system is currently designed
no two repair packets
uniquely named and that
worse than any of
inconsistency rate drops as
than any of the
the following are ignored
also use embedded minibrowsers
two repair packets generated
is currently designed to
use embedded minibrowsers to
maintains a high volume
rate drops as the
embedded minibrowsers to gain
drops as the abort
named and that updates
as the abort rate
any tm can therefore
the abort rate rises
any of the proposed
abort rate rises this
currently designed to use
rate rises this is
minibrowsers to gain access
designed to use a
a high volume of
tm can therefore observe
high volume of forwarding
of the proposed strategies
volume of forwarding traffic
and that updates are
to gain access to
that updates are ordered
repair packets generated at
rises this is desired
packets generated at different
to use a spanningtree
the forwarded messages tend
gain access to a
forwarded messages tend to
exploiting weak connectivity for
access to a wide
weak connectivity for mobile
use a spanningtree overlay
updates are ordered separately
the stepwise adaptive approach
can therefore observe the
stepwise adaptive approach yields
messages tend to get
therefore observe the log
tend to get ahead
connectivity for mobile file
to get ahead of
this is desired as
get ahead of the
adaptive approach yields the
ahead of the token
observe the log and
are ordered separately by
similar to most multicast
ordered separately by each
is desired as well
to most multicast network
both on the send
for mobile file access
most multicast network architectures
generated at different interleaves
separately by each update
to a wide range
approach yields the best
on the send path
yields the best results
at different interleaves i
in proceedings of the
by each update source
a wide range of
the log and consistently
where in the sinks
the best results when
proceedings of the fifteenth
the overall rate of
of the fifteenth acm
with virtual links connecting
log and consistently determine
we use a simple
virtual links connecting g
use a simple round
of update x and
links connecting g radient
update x and a
wide range of platforms
and consistently determine the
overall rate of consistent
robin policy of multiplexing
consistently determine the state
rate of consistent committed
x and a member
the fifteenth acm symposium
and a member m
policy of multiplexing between
a member m that
determine the state of
member m that lacks
best results when large
m that lacks x
will have more than
of multiplexing between data
have more than one
the state of the
more than one data
results when large percentages
state of the transaction
when large percentages of
multiplexing between data feeds
large percentages of opportunistic
than one data packet
percentages of opportunistic nodes
of consistent committed transactions
of opportunistic nodes are
fifteenth acm symposium on
consistent committed transactions drops
connecting g radient cdn
committed transactions drops because
without a race hazard
g radient cdn nodes
acm symposium on operating
gossip can be used
symposium on operating systems
opportunistic nodes are present
on operating systems principles
nodes are present in
and on the receive
are present in the
can be used to
on the receive path
one data packet in
present in the system
data packet in common
prediction errors if there
packet in common as
be used to detect
transactions drops because the
the question is to
where forwarded packets are
errors if there are
forwarded packets are treated
drops because the probability
if there are no
it is also simpler
there are no prediction
is also simpler than
used to detect this
are no prediction errors
because the probability of
question is to determine
packets are treated as
also simpler than the
in common as long
simpler than the percentile
the probability of conflicts
are treated as control
probability of conflicts in
to detect this and
of conflicts in the
is to determine what
treated as control traffic
common as long as
to determine what nodes
as long as the
detect this and m
determine what nodes the
since it is based
conflicts in the clustered
it is based only
and while they re
is based only on
long as the least
based only on samples
as the least common
only on samples of
the least common multiple
on samples of the
this and m can
samples of the download
there are no aborts
and m can then
in the clustered scenario
m can then send
the clustered scenario is
what nodes the in
clustered scenario is higher
while they re prioritized
of the download rates
they re prioritized over
the download rates of
performance evaluation central to
of the interleaves is
can then send x
the interleaves is greater
download rates of nodes
interleaves is greater than
re prioritized over data
is greater than r
evaluation central to our
greater than r i
if the transaction accesses
then send x to
to illustrate more realistic
send x to m
illustrate more realistic behavior
x to m directly
network processing and connecting
in both sets of
the transaction accesses an
processing and connecting to
we use clustered accesses
transaction accesses an object
and connecting to the
accesses an object that
they are treated as
an object that was
use clustered accesses that
object that was not
clustered accesses that slowly
without waiting for the
accesses that slowly drift
connecting to the diverse
are treated as equally
central to our argument
pairings of repair bins
that was not predicted
of repair bins in
to our argument is
repair bins in two
to the diverse end
treated as equally important
transactions are perfectly clustered
our argument is the
waiting for the chain
bins in two different
as equally important as
in two different layers
this object has no
two different layers with
as in the previous
object has no reserved
in the previous experiment
argument is the assertion
both sets of experiments
for the chain to
different layers with interleaves
the chain to be
layers with interleaves i
has no reserved version
chain to be repaired
users should be done
no reserved version for
is the assertion that
reserved version for it
equally important as tokens
the number of false
the assertion that hosted
number of false positives
minutes the cluster structure
of false positives was
assertion that hosted event
false positives was practically
the cluster structure shifts
positives was practically null
cluster structure shifts by
was practically null under
accessing it can therefore
practically null under all
that hosted event notification
null under all three
they also increase the
under all three strategies
gossip is not a
it can therefore result
is not a particularly
hosted event notification solutions
all three strategies considered
also increase the overall
we need to optimize
increase the overall volume
can therefore result in
event notification solutions scale
not a particularly fast
bandwidth network file system
a particularly fast protocol
need to optimize the
at most one in
therefore result in a
to optimize the overlay
the overall volume of
most one in some
result in a conflict
optimize the overlay to
a good rule of
overall volume of i
in a conflict of
the overlay to deliver
a conflict of the
good rule of thumb
notification solutions scale poorly
one in some cases
o that the nodes
conflict of the transaction
overlay to deliver the
of the transaction or
in proceedings of the
solutions scale poorly and
proceedings of the eighteenth
rule of thumb is
rounds of the protocol
to deliver the exact
that the nodes process
scale poorly and stand
of the eighteenth acm
the transaction or of
the eighteenth acm symposium
of the protocol to
eighteenth acm symposium on
deliver the exact stream
the protocol to reach
of thumb is to
protocol to reach n
the exact stream quality
to reach n processes
transaction or of the
exact stream quality demanded
acm symposium on operating
poorly and stand as
stream quality demanded by
tokens are processed with
and stand as a
auditing costs the overheads
thumb is to select
costs the overheads imposed
or of the following
the overheads imposed by
quality demanded by users
are processed with higher
on the other hand
processed with higher latency
stand as a barrier
symposium on operating systems
of the following ones
on operating systems principles
demanded by users while
is to select interleaves
as a barrier to
to select interleaves that
if rounds occur frequently
a barrier to collaboration
overheads imposed by auditing
select interleaves that are
imposed by auditing are
barrier to collaboration applications
by auditing are an
by users while minimizing
interleaves that are relatively
auditing are an important
users while minimizing bandwidth
that are relatively prime
the delay before information
while minimizing bandwidth costs
are relatively prime to
are an important consideration
relatively prime to maximize
delay before information spreads
prime to maximize their
and that developers will
no conflict would occur
to maximize their lcm
before information spreads to
which we address in
that developers will want
information spreads to all
we address in this
and wrapping back to
address in this subsection
developers will want to
and also ensure that
spreads to all members
also ensure that the
to all members of
ensure that the larger
most of the work
will want to combine
of the work of
all members of a
but if one does
members of a system
wrapping back to zero
if one does it
the work of auditing
histogram of maximum alarm
work of auditing is
of a system may
of auditing is performed
back to zero after
want to combine hosted
that the larger interleave
of maximum alarm delays
to combine hosted content
we propose to apply
combine hosted content with
one does it will
hosted content with p
a system may still
maximum alarm delays in
system may still be
propose to apply an
the larger interleave is
does it will be
to apply an economics
may still be small
larger interleave is greater
auditing is performed by
it will be detected
p protocols to overcome
interleave is greater than
is performed by local
is greater than r
apply an economics framework
will be detected at
protocols to overcome these
be detected at certification
even in a large
to overcome these problems
let us assume that
detected at certification time
performed by local auditors
in a large system
us assume that packets
assume that packets are
that packets are dropped
considering two primary inputs
which are executed on
packets are dropped with
are executed on the
two primary inputs in
in this section we
executed on the user
primary inputs in determining
this section we present
the objects dependency lists
and result in an
gossip is astonishingly robust
result in an abort
are dropped with uniform
in an abort of
section we present data
objects dependency lists are
on the user nodes
we present data to
inputs in determining the
present data to support
dependency lists are outdated
in determining the optimal
the overhead is constant
there are exponentially many
histogram of maximum alarm
data to support our
given a lost data
this leads to a
a lost data packet
determining the optimal network
of maximum alarm delays
an abort of a
to support our claims
abort of a transaction
what is the probability
leads to a sudden
is the probability that
maximum alarm delays in
the probability that we
are exponentially many paths
the optimal network overlay
exponentially many paths by
independent of the size
probability that we can
many paths by which
that we can recover
performance may be slightly
to a sudden increased
of the size of
paths by which information
some of the results
by which information can
may be slightly reduced
a sudden increased inconsistency
the size of the
we can recover it
size of the system
sudden increased inconsistency rate
which information can pass
increased inconsistency rate that
information can pass from
on the one hand
and is not significant
inconsistency rate that converges
we can recover a
rate that converges back
can pass from point
that converges back to
but consistency is maintained
pass from point a
converges back to zero
from point a to
since nodes only exchange
can recover a data
nodes only exchange a
point a to point
only exchange a small
recover a data packet
exchange a small amount
a to point b
a small amount of
we consider the cost
overheads in a lightly
a data packet if
consider the cost for
data packet if at
small amount of accounting
if a transaction does
until this convergence is
hence almost any imaginable
a transaction does not
amount of accounting data
almost any imaginable disruption
transaction does not access
the cost for network
does not access an
packet if at least
cost for network edges
if at least one
any imaginable disruption short
at least one of
this convergence is interrupted
imaginable disruption short of
are drawn from a
disruption short of a
loaded system so far
least one of the
not access an object
one of the c
of accounting data at
access an object that
managing update conflicts in
an object that was
update conflicts in bayou
system so far the
convergence is interrupted by
of the c xors
is interrupted by the
accounting data at pre
interrupted by the next
short of a lasting
object that was predicted
of a lasting partitioning
for network edges to
a lasting partitioning failure
drawn from a widely
network edges to carry
a weakly connected replicated
so far the evaluation
weakly connected replicated storage
the c xors containing
connected replicated storage system
by the next shift
from a widely cited
edges to carry traffic
a widely cited industry
far the evaluation has
widely cited industry whitepaper
in proceedings of the
the evaluation has focused
defined intervals of time
lasting partitioning failure can
the tm must still
partitioning failure can be
proceedings of the fifteenth
failure can be overcome
c xors containing it
tm must still release
xors containing it is
of the fifteenth acm
must still release the
evaluation has focused on
containing it is received
similar to standard bandwidth
the fifteenth acm symposium
the gossip protocols implemented
to standard bandwidth pricing
it is received correctly
still release the reservation
fifteenth acm symposium on
has focused on scenarios
acm symposium on operating
b presented three possible
focused on scenarios where
symposium on operating systems
presented three possible strategies
on scenarios where the
gossip protocols implemented in
is received correctly and
release the reservation when
received correctly and usable
on operating systems principles
scenarios where the system
if we consider a
where the system was
we consider a packet
the reservation when the
protocols implemented in the
three possible strategies for
the system was heavily
implemented in the ssa
reservation when the transaction
possible strategies for the
consider a packet rate
strategies for the cache
a packet rate of
in the ssa have
when the transaction ends
system was heavily loaded
we leverage the perceived
for the cache to
all the other data
leverage the perceived utility
the other data packets
the cache to deal
other data packets in
cache to deal with
data packets in it
to deal with inconsistency
packets in it have
the ssa have been
this reservation might slow
and were obtained using
reservation might slow the
deal with inconsistency detection
were obtained using a
the perceived utility by
ssa have been designed
with unbounded multicast rates
in it have also
unbounded multicast rates and
it have also been
obtained using a testing
multicast rates and occasional
perceived utility by end
rates and occasional perturbations
seconds the maximum number
have also been received
the maximum number of
also been received correctly
using a testing methodology
have been designed specifically
might slow the processing
maximum number of packets
a testing methodology and
been designed specifically for
slow the processing of
users for receiving the
number of packets received
testing methodology and setup
for receiving the stream
designed specifically for use
we traced degraded performance
specifically for use in
of packets received and
the probability of which
packets received and sent
probability of which is
received and sent by
of which is simply
for use in our
methodology and setup developed
use in our modified
the processing of other
in our modified version
and sent by each
processing of other transactions
sent by each node
traced degraded performance or
our modified version of
degraded performance or scheduling
modified version of chain
performance or scheduling delays
aborting and evicting value
or scheduling delays to
and setup developed and
of other transactions that
version of chain replication
by each node is
receiving the stream at
scheduling delays to memory
setup developed and published
the stream at a
the probability of a
other transactions that wait
and with the goal
stream at a given
probability of a received
developed and published by
transactions that wait for
with the goal of
that wait for its
the goal of running
and published by sonic
goal of running in
but how does the
published by sonic software
wait for its release
of a received xor
of running in large
a received xor being
how does the system
received xor being unusable
at a given quality
running in large clusters
for each packet sent
does the system behave
each packet sent or
xor being unusable is
packet sent or received
in large clusters or
but would not break
large clusters or datacenters
the system behave when
through when possible as
system behave when lightly
the history needs to
behave when lightly loaded
history needs to indicate
when possible as in
needs to indicate which
possible as in cache
being unusable is the
as in cache miss
would not break consistency
to indicate which neighbor
do similar phenomena occur
file system usage in
unusable is the complement
system usage in windows
indicate which neighbor sent
the exact solution for
which neighbor sent or
usage in windows nt
neighbor sent or received
here we ll see
sent or received the
let be a group
if a tm is
exact solution for this
a tm is suspected
or received the packet
be a group of
solution for this optimization
a group of processes
we ll see that
for this optimization problem
ll see that load
tm is suspected as
see that load has
this optimization problem is
is suspected as failed
that load has a
we will now compare
load has a super
and let p be
optimization problem is intractable
in proceedings of the
will now compare their
let p be a
bits to identify each
linear impact on performance
its reservations are revoked
the remainder was produced
p be a process
now compare their efficacies
to identify each neighbor
proceedings of the seventeenth
problem is intractable it
remainder was produced in
be a process in
we use the approximate
this may harm performance
the history s size
was produced in our
is intractable it is
produced in our own
use the approximate clusters
intractable it is np
the approximate clusters workload
the growth in memory
a process in that
but cannot break consistency
process in that group
history s size adds
in that group p
s size adds up
growth in memory consumption
in our own experiments
the probability x of
approximate clusters workload with
of the seventeenth acm
probability x of a
in memory consumption causes
size adds up to
x of a sent
the seventeenth acm symposium
memory consumption causes slowdowns
of a sent xor
seventeenth acm symposium on
consumption causes slowdowns that
acm symposium on operating
a sent xor being
causes slowdowns that amplify
symposium on operating systems
each process has its
evaluation we evaluate acid
process has its own
slowdowns that amplify the
has its own view
sent xor being dropped
on operating systems principles
that amplify the increased
xor being dropped or
its own view of
amplify the increased latencies
own view of the
being dropped or unusable
view of the group
the increased latencies associated
dropped or unusable is
we have developed algorithms
or unusable is the
rain by comparing its
have developed algorithms that
a window size of
increased latencies associated with
unusable is the sum
latencies associated with the
developed algorithms that give
by comparing its performance
is the sum of
from the industry white
the sum of the
the industry white paper
sum of the probability
comparing its performance to
of the probability that
associated with the growth
the probability that it
this is not significant
algorithms that give an
its performance to the
mostly reads mostly writes
that give an approximate
reads mostly writes heavy
is not significant compared
mostly writes heavy load
with the growth in
writes heavy load store
probability that it was
heavy load store overhead
performance to the classical
that it was dropped
these views can lag
a pareto parameter of
to the classical approach
the growth in traffic
load store overhead priorities
analyzes the performance of
give an approximate optimal
the performance of several
views can lag reality
not significant compared to
the classical approach that
significant compared to the
it was dropped and
compared to the amount
classical approach that does
to the amount of
store overhead priorities uniform
an approximate optimal solution
for example if a
was dropped and the
example if a process
dropped and the probability
approach that does not
and the probability that
performance of several commercial
the probability that it
and the maximum dependency
probability that it was
the maximum dependency list
overhead priorities uniform priorities
maximum dependency list size
to show this we
the amount of regular
of several commercial enterprise
amount of regular data
if a process joins
of regular data exchanged
priorities uniform priorities uniform
dependency list size is
show this we designed
that it was received
that does not use
several commercial enterprise service
in the case of
commercial enterprise service bus
uniform priorities uniform synchronous
list size is set
priorities uniform synchronous asynchronous
this we designed experiments
uniform synchronous asynchronous figure
does not use prediction
regular data exchanged in
the case of video
it was received and
size is set to
was received and unusable
case of video streams
not use prediction and
data exchanged in a
of video streams whose
use prediction and compare
graphs of ntfs traces
a process joins or
prediction and compare its
we designed experiments that
video streams whose quality
designed experiments that vary
process joins or leaves
experiments that vary the
streams whose quality and
that vary the multicast
and compare its certification
vary the multicast rate
exchanged in a streaming
shown is the maximum
each trace ran with
whose quality and traffic
compare its certification protocol
the lower portion of
quality and traffic rates
its certification protocol with
in a streaming session
is the maximum throughput
and different members might
lower portion of the
and traffic rates can
portion of the graph
certification protocol with other
trace ran with synchronous
traffic rates can be
ran with synchronous or
we also analyzed the
with synchronous or asynchronous
different members might not
protocol with other certification
members might not have
rates can be downgraded
with other certification schemes
showed that the load
can be downgraded by
that the load on
might not have consistent
be downgraded by g
not have consistent views
of the graph is
downgraded by g radient
the graph is the
also analyzed the costs
by g radient cdn
analyzed the costs of
we use a custom
the load on receivers
graph is the ratio
synchronous or asynchronous writes
the costs of the
or asynchronous writes and
g radient cdn nodes
our work assumes that
load on receivers grows
is the ratio of
asynchronous writes and uniform
costs of the global
writes and uniform or
of the global auditors
and uniform or differentiated
work assumes that the
on receivers grows roughly
the ratio of committed
uniform or differentiated priorities
assumes that the network
receivers grows roughly linearly
since they are dedicated
ratio of committed transactions
they are dedicated and
we have derived a
the total height of
that the network within
total height of each
have derived a primaldual
of committed transactions that
are dedicated and external
committed transactions that the
derived a primaldual approximation
transactions that the abort
simulating each of the
that the abort strategy
a primaldual approximation algorithm
each of the agents
as expected given the
height of each bar
dedicated and external to
of each bar denotes
the abort strategy provides
each bar denotes the
the experiment varies the
bar denotes the time
and external to the
the network within a
primaldual approximation algorithm which
of the agents in
abort strategy provides a
expected given the linearly
strategy provides a significant
experiment varies the number
external to the system
network within a cluster
varies the number of
within a cluster does
denotes the time from
given the linearly increasing
the number of subscribers
the linearly increasing load
the agents in the
a cluster does not
the time from the
provides a significant improvement
the overhead imposed by
a significant improvement over
number of subscribers while
agents in the system
negligible loss rates and
time from the first
in the system clients
overhead imposed by them
significant improvement over a
imposed by them is
improvement over a normal
of subscribers while using
approximation algorithm which produces
loss rates and the
from the first to
since it is easy
cluster does not partition
it is easy to
subscribers while using a
is easy to ensure
the first to last
rates and the nearly
by them is of
and the nearly flat
them is of higher
first to last write
the nearly flat curve
although there are low
easy to ensure that
as the strategy detects
is of higher concern
the strategy detects and
algorithm which produces a
nearly flat curve of
our workloads are an
which produces a solution
while using a single
global auditors main tasks
to ensure that no
and the shaded portion
flat curve of memory
the shaded portion denotes
probability failure patterns that
shaded portion denotes the
produces a solution whose
using a single publisher
auditors main tasks consist
ensure that no two
workloads are an adaptation
that no two xors
strategy detects and aborts
portion denotes the time
detects and aborts over
denotes the time from
a solution whose total
main tasks consist of
a single publisher that
tasks consist of sampling
no two xors share
consist of sampling the
single publisher that communicates
the time from the
solution whose total cost
publisher that communicates through
are an adaptation of
two xors share more
failure patterns that could
xors share more than
of sampling the system
share more than one
that communicates through a
an adaptation of the
of all inconsistent transactions
time from the first
adaptation of the transactional
from the first to
patterns that could temporarily
more than one data
communicates through a single
curve of memory consumption
all inconsistent transactions that
sampling the system to
inconsistent transactions that would
of the transactional ycsb
the difference between total
the transactional ycsb specification
than one data packet
difference between total network
the first to last
the system to collect
transactions that would have
that could temporarily partition
through a single hosted
first to last read
the usability probabilities of
a single hosted message
that would have been
could temporarily partition some
between total network traffic
the white portions denote
usability probabilities of different
white portions denote the
single hosted message broker
would have been committed
temporarily partition some subservice
system to collect download
total network traffic costs
probabilities of different xors
portions denote the extra
network traffic costs and
partition some subservice in
to collect download and
but the other strategies
collect download and upload
the other strategies make
denote the extra time
other strategies make further
the extra time required
strategies make further improvements
extra time required to
hosted message broker on
download and upload rates
the latter reflecting our
some subservice in a
latter reflecting our cooperative
of different xors are
reflecting our cooperative caching
different xors are independent
and upload rates of
traffic costs and aggregate
evict reduces uncommittable transactions
subservice in a logical
reduces uncommittable transactions to
message broker on a
our cooperative caching policy
the probability of all
costs and aggregate end
time required to complete
in a logical sense
required to complete all
broker on a single
probability of all the
load on the sender
to complete all writes
based on the original
upload rates of nodes
of its value with
on a single topic
its value with abort
of all the c
complete all writes after
all the c xors
all writes after the
the c xors being
writes after the last
and of occasionally disseminating
c xors being dropped
this indicates that violating
after the last read
of occasionally disseminating updates
xors being dropped or
the last read has
occasionally disseminating updates to
is within a factor
being dropped or unusable
last read has finished
within a factor of
because the linear growth
disseminating updates to the
the linear growth of
updates to the threshold
figured for message durability
dropped or unusable is
process p chooses a
linear growth of traffic
to the threshold value
cache entries are likely
or unusable is xc
for asynchronous writeback with
p chooses a random
entries are likely to
asynchronous writeback with priorities
chooses a random subset
writeback with priorities in
combined with our fixed
a random subset of
even if a subscriber
random subset of a
are likely to be
with our fixed rate
if a subscriber experiences
subset of a particular
the sample size remains
of a particular size
sample size remains fixed
our fixed rate of
size remains fixed independent
the probability of correctly
likely to be repeat
with priorities in the
to be repeat offenders
a subscriber experiences a
fixed rate of state
remains fixed independent of
subscriber experiences a transient
fixed independent of the
rate of state aggregation
probability of correctly receiving
a particular size view
of correctly receiving at
experiences a transient loss
correctly receiving at least
independent of the size
receiving at least one
of the size of
at least one usable
the size of the
they are too old
size of the population
increases the amount of
of the optimal in
the amount of unacknowledged
least one usable xor
the optimal in the
one usable xor is
a transient loss of
each transaction has a
transient loss of connectivity
this shows that the
are too old for
we ran simulations to
optimal in the worst
and commences a dialog
transaction has a set
commences a dialog with
too old for objects
ran simulations to estimate
old for objects that
the publisher retains and
shows that the total
has a set of
that the total duration
a dialog with each
the total duration of
a set of read
total duration of the
dialog with each process
for objects that are
publisher retains and hence
objects that are likely
the probability of recovering
that are likely to
probability of recovering the
in the worst case
duration of the trace
with each process in
update operations spread along
retains and hence can
operations spread along its
are likely to be
spread along its execution
likely to be accessed
amount of unacknowledged data
to be accessed together
simulations to estimate the
be accessed together with
of recovering the lost
accessed together with them
each process in the
and hence can replay
to estimate the worst
of the trace with
recovering the lost data
together with them in
the lost data packet
with them in future
lost data packet is
them in future transactions
process in the set
case standard deviation of
object accesses follow one
standard deviation of the
hence can replay all
accesses follow one of
and so it is
deviation of the download
so it is better
the trace with this
it is better to
trace with this mfs
is better to evict
of the download rates
can replay all messages
process communication primitives for
follow one of two
communication primitives for programming
with this mfs configuration
better to evict them
this mfs configuration is
the download rates across
primitives for programming distributed
download rates across all
the initial message is
one of two different
initial message is a
retry reduces uncommittable transactions
of two different random
message is a compact
rates across all nodes
two different random distributions
this triggers higher overheads
reduces uncommittable transactions further
as the number of
for programming distributed systems
is a compact state
programming distributed systems robbert
uncommittable transactions further to
distributed systems robbert van
a compact state digest
but all the fetch
transactions further to about
the number of subscribers
systems robbert van renesse
all the fetch traffic
number of subscribers increases
the fetch traffic is
compact state digest summarizing
we estimate that a
fetch traffic is completed
estimate that a sample
traffic is completed within
department of computer science
that a sample size
we see that the
state digest summarizing the
the time spent in
of computer science cornell
of its value with
time spent in the
computer science cornell university
see that the algorithm
digest summarizing the state
its value with abort
a sample size of
spent in the garbage
that the algorithm has
summarizing the state of
where each object is
the state of the
in the garbage collector
state of the sender
seconds of the start
science cornell university category
each object is chosen
the algorithm has lower
object is chosen uniformly
the garbage collector grows
realistic workloads we now
representation the following position
algorithm has lower total
the following position paper
is chosen uniformly at
garbage collector grows from
has lower total cost
form formula only gives
workloads we now evaluate
nodes is sufficient to
we now evaluate the
the follow up dialog
is sufficient to provide
following position paper describes
follow up dialog consists
position paper describes a
chosen uniformly at random
paper describes a new
formula only gives us
lower total cost compared
only gives us a
latency will also soars
up dialog consists of
total cost compared to
dialog consists of an
this is a significant
gives us a lower
now evaluate the efficacy
cost compared to a
describes a new interprocess
consists of an explicit
a new interprocess communication
us a lower bound
of an explicit request
a lower bound on
is a significant improvement
lower bound on the
a significant improvement over
evaluate the efficacy of
significant improvement over the
the efficacy of t
improvement over the alternative
will also soars because
bound on the recovery
independent of the population
on the recovery probability
of the population size
also soars because the
primitive that is designed
an explicit request of
soars because the amount
over the alternative configurations
cache with workloads based
that is designed to
since the xor usability
compared to a single
the alternative configurations measured
because the amount of
such as the ones
gc logs are truncated
as the ones simulated
is designed to make
the ones simulated in
logs are truncated to
designed to make it
explicit request of missing
to make it easier
the amount of time
make it easier to
to a single stream
combined with a linear
amount of time the
the xor usability formula
request of missing update
seconds of the trace
xor usability formula does
with workloads based on
are truncated to conserve
workloads based on two
a single stream source
truncated to conserve resources
it easier to program
of time the broker
to conserve resources and
of missing update operations
time the broker needs
with a linear growth
based on two sampled
ones simulated in this
on two sampled topologies
simulated in this work
of the trace are
two sampled topologies from
the trace are taken
the broker needs to
a linear growth of
several details of the
broker needs to spend
usability formula does not
conserve resources and to
formula does not factor
trace are taken up
resources and to reduce
single stream source and
linear growth of cpu
even a smaller number
details of the epidemic
stream source and a
sampled topologies from the
of the epidemic protocols
are taken up by
does not factor in
the epidemic protocols employed
growth of cpu usage
a smaller number of
epidemic protocols employed in
easier to program distributed
topologies from the online
protocols employed in the
taken up by asynchronously
and to reduce log
employed in the framework
needs to spend sending
of cpu usage due
smaller number of samples
to program distributed algorithms
to spend sending a
from the online retailer
up by asynchronously writing
spend sending a single
to reduce log replay
in the framework turned
cpu usage due to
it is largely based
the framework turned out
is largely based on
the online retailer amazon
framework turned out to
online retailer amazon and
reduce log replay time
number of samples was
source and a minimum
usage due to the
not factor in the
by asynchronously writing back
and a minimum spanning
sending a single message
turned out to be
retailer amazon and the
a single message increases
amazon and the social
of samples was found
and the social network
asynchronously writing back file
the social network orkut
factor in the probability
a minimum spanning tree
in the probability of
out to be important
the probability of the
largely based on my
to be important determinants
single message increases linearly
be important determinants of
log replay time on
message increases linearly with
replay time on om
increases linearly with the
time on om recovery
based on my experience
writing back file updates
on my experience in
due to the increasing
my experience in implementing
minimum spanning tree streaming
samples was found to
probability of the other
was found to be
linearly with the number
each om occasionally summarizes
with the number of
experience in implementing algorithms
om occasionally summarizes the
describes how we generated
spanning tree streaming protocol
of the other data
found to be sufficient
the other data packets
to be sufficient to
in all cases the
be sufficient to yield
all cases the traces
occasionally summarizes the log
how we generated these
important determinants of system
tree streaming protocol in
determinants of system performance
other data packets in
the number of subscribers
data packets in the
sufficient to yield satisfactory
packets in the xor
to yield satisfactory results
we generated these workloads
to the increasing volume
of system performance and
the increasing volume of
in implementing algorithms such
increasing volume of traffic
implementing algorithms such as
in the xor being
algorithms such as distributed
streaming protocol in a
system performance and behavior
cases the traces take
summarizes the log prefix
protocol in a simulation
these overheads cause the
the traces take significantly
such as distributed consensus
traces take significantly longer
the xor being dropped
take significantly longer than
overheads cause the super
significantly longer than they
in a simulation based
durability is often not
measures the efficacy of
and places this summary
the efficacy of t
longer than they originally
places this summary in
linear growth of cpu
xor being dropped and
growth of cpu overhead
being dropped and recovered
cache on these workloads
than they originally did
on these workloads as
this summary in the
these workloads as a
is often not required
workloads as a function
suppose that a process
of cpu overhead shown
a simulation based on
they originally did in
summary in the log
centralized costs are fixed
subject to your evaluation
as a function of
that a process disseminates
a function of maximum
originally did in ntfs
function of maximum dependency
we extend the analysis
of maximum dependency list
and provide a clear
maximum dependency list size
simulation based on a
where they were mostly
cpu overhead shown on
they were mostly accessing
extend the analysis to
overhead shown on figure
to your evaluation of
based on a collection
a process disseminates information
and compares this to
provide a clear advantage
on a collection of
a clear advantage for
were mostly accessing the
compares this to a
mostly accessing the local
this to a strategy
accessing the local file
your evaluation of my
the local file system
clear advantage for using
evaluation of my proposal
a collection of as
shows throughput in an
the presence of a
throughput in an experiment
local file system and
i would be happy
file system and therefore
the analysis to bursty
would be happy to
presence of a summary
process disseminates information via
in an experiment in
of a summary of
system and therefore had
the increasing number of
an experiment in which
analysis to bursty losses
increasing number of unacknowledged
disseminates information via epidemics
advantage for using auditing
number of unacknowledged requests
to a strategy based
a summary of the
of unacknowledged requests and
experiment in which the
summary of the log
information via epidemics about
in which the publisher
of the log up
be happy to present
and therefore had no
the log up to
for using auditing against
a strategy based on
using auditing against tit
strategy based on ttls
which the publisher does
unacknowledged requests and the
happy to present this
therefore had no bandwidth
to present this idea
had no bandwidth constraints
via epidemics about a
the publisher does not
epidemics about a subject
log up to a
about a subject s
gradient mst naive broadcast
up to a certain
publisher does not log
the results largely repeat
to a certain entry
results largely repeat those
present this idea at
requests and the resulting
mst naive broadcast total
process p gossips about
does not log data
p gossips about subject
tat approaches in large
largely repeat those seen
a certain entry is
this idea at the
if the lost data
certain entry is not
naive broadcast total cost
entry is not sufficient
gossips about subject s
repeat those seen in
idea at the workshop
those seen in the
the lost data packet
compares the efficacy of
is not sufficient to
a disconnected subscriber would
and the resulting overheads
seen in the microbenchmarks
lost data packet was
the efficacy of the
data packet was part
efficacy of the three
ipc allows processes to
of the three strategies
allows processes to share
about subject s a
not sufficient to allow
packet was part of
disconnected subscriber would experience
was part of a
the resulting overheads rise
part of a loss
processes to share information
of a loss burst
to share information and
sufficient to allow truncation
share information and to
subscriber would experience a
subject s a finite
resulting overheads rise sharply
to the extent that
heterogenous systems so far
the extent that the
the three strategies of
information and to synchronize
systems so far we
to allow truncation at
s a finite number
allow truncation at that
a loss burst of
truncation at that entry
loss burst of size
and to synchronize actions
burst of size b
so far we considered
overheads rise sharply at
a finite number of
far we considered the
three strategies of dealing
would experience a loss
we considered the use
this reason is that
repair packets generated at
finite number of times
extent that the greatest
rise sharply at the
that the greatest performance
strategies of dealing with
sharply at the highest
of dealing with detected
packets generated at interleaves
dealing with detected inconsistencies
the greatest performance improvements
generated at interleaves less
reason is that truncation
at interleaves less than
as long as subject
is that truncation must
we find that while
greatest performance improvements are
at the highest rates
performance improvements are seen
interleaves less than b
improvements are seen at
considered the use of
less than b are
find that while the
than b are dropped
the highest rates because
that while the maximum
are seen at low
that truncation must not
seen at low bandwidth
there are two classes
truncation must not break
are two classes of
long as subject s
must not break transaction
while the maximum throughput
not break transaction certification
at low bandwidth when
the maximum throughput is
low bandwidth when there
we generated two workloads
bandwidth when there is
highest rates because of
generated two workloads based
the use of auditing
rates because of the
maximum throughput is much
because of the increasing
when there is high
b are dropped or
two workloads based on
two classes of ipc
workloads based on real
as subject s is
throughput is much higher
subject s is hot
there is high read
are dropped or useless
use of auditing to
dropped or useless with
of the increasing token
or useless with high
based on real data
useless with high probability
prediction our first test
the increasing token roundtrip
the degradation of performance
such as in the
of auditing to enforce
as in the mostly
our first test scenario
after which subject s
and we can discount
first test scenario imposes
which subject s is
degradation of performance is
subject s is no
mc has processes communicate
we can discount them
has processes communicate send
writes trace where there
processes communicate send and
trace where there is
communicate send and receive
of performance is even
send and receive messages
test scenario imposes a
performance is even more
auditing to enforce node
is even more dramatic
s is no longer
while sm allows processes
we started from a
is no longer gossiped
started from a snapshot
of recovering the data
from a snapshot of
sm allows processes to
a snapshot of amazon
where there is an
snapshot of amazon s
no longer gossiped about
increasing token roundtrip time
recovering the data packet
scenario imposes a load
allows processes to share
to enforce node contribution
processes to share data
the data packet is
to share data directly
data packet is then
imposes a load substantially
enforce node contribution in
the issue here is
share data directly while
developers of collaboration applications
explicit requests for copies
a load substantially below
of collaboration applications that
of amazon s product
amazon s product co
collaboration applications that need
data directly while synchronizing
decrease in the time
applications that need good
in the time spent
load substantially below the
issue here is that
is the number of
directly while synchronizing using
requests for copies of
the time spent to
that need good scalability
purchasing graph taken early
node contribution in systems
need good scalability might
here is that the
contribution in systems where
good scalability might discover
for copies of missed
time spent to read
substantially below the system
the number of xors
while synchronizing using such
number of xors generated
synchronizing using such primitives
scalability might discover that
copies of missed messages
spent to read all
below the system s
is that the amount
the system s capacity
that the amount of
using such primitives as
the amount of i
such primitives as mutexes
of missed messages are
to read all the
of xors generated at
in systems where all
system s capacity with
systems where all nodes
primitives as mutexes and
read all the files
where all nodes are
xors generated at interleaves
might discover that hosted
generated at interleaves greater
as mutexes and condition
discover that hosted esb
all nodes are assumed
o to be processed
nodes are assumed to
to be processed increases
mutexes and condition variables
that hosted esb options
missed messages are limited
hosted esb options won
even at the higher
are assumed to have
at interleaves greater than
much as in some
interleaves greater than b
esb options won t
at the higher bandwidth
each product sold by
options won t achieve
messages are limited in
won t achieve this
where processes are physically
the formulae derived for
processes are physically separated
assumed to have homogeneous
product sold by the
as in some of
are limited in size
in some of the
mc is dominant as
t achieve this goal
is dominant as e
to have homogeneous bandwidth
sold by the online
each transaction reads and
by the online retailer
transaction reads and writes
formulae derived for xor
dominant as e orts
have homogeneous bandwidth resources
as e orts to
the higher bandwidth of
the online retailer is
derived for xor usability
to prevent a process
for xor usability still
e orts to support
online retailer is a
prevent a process that
xor usability still hold
orts to support the
a process that lagged
to support the sm
retailer is a node
we report on some
process that lagged behind
support the sm paradigm
report on some experiments
the sm paradigm have
enough to upload and
on some experiments we
to upload and download
that lagged behind or
upload and download at
since packet losses with
and download at a
is a node and
some experiments we conducted
a node and each
the simulation is faithful
node and each pair
some of the earlier
and each pair of
packet losses with more
each pair of products
sm paradigm have not
experiments we conducted on
lagged behind or just
we conducted on our
there is a decrease
of the earlier scenarios
download at a rate
losses with more than
pair of products purchased
paradigm have not been
simulation is faithful to
behind or just joined
is faithful to the
is a decrease of
or just joined from
with more than b
of products purchased in
have not been successful
conducted on our own
at a rate close
on our own at
a rate close to
our own at cornell
rate close to the
products purchased in a
close to the stream
purchased in a single
just joined from trying
examples of sm include
more than b intervening
joined from trying to
this delays tokens as
the mostlyreads trace is
to the stream rate
mostlyreads trace is not
of sm include tcp
faithful to the algorithm
than b intervening packets
from trying to catch
b intervening packets between
focusing on scalability of
intervening packets between them
trace is not much
sm include tcp connections
is not much affected
trying to catch up
delays tokens as a
to catch up all
pullbased streaming may be
catch up all at
in a single user
up all at once
a single user session
packets between them have
single user session is
on scalability of event
streaming may be extended
not much affected by
with the exception of
tokens as a function
between them have independent
the exception of a
as a function of
may be extended to
exception of a small
the mc and sm
be extended to heterogenous
of a small shortcut
them have independent probability
which would result in
much affected by changes
a function of the
affected by changes in
scalability of event notification
by changes in the
extended to heterogenous systems
a small shortcut oms
would result in enormous
user session is an
function of the growing
mc and sm paradigms
changes in the configuration
and sm paradigms are
there is only correlation
sm paradigms are duals
small shortcut oms grant
result in enormous messages
shortcut oms grant reservations
of the growing volume
of event notification platforms
the growing volume of
is only correlation within
event notification platforms that
session is an edge
in enormous messages and
oms grant reservations by
although there is a
to heterogenous systems by
paradigms are duals in
growing volume of multicast
are duals in that
only correlation within the
duals in that one
enormous messages and serious
grant reservations by arrival
there is a slight
heterogenous systems by organizing
is a slight decrease
volume of multicast traffic
systems by organizing nodes
correlation within the bursts
in that one can
messages and serious fluctuations
reservations by arrival time
the original graph contains
a slight decrease in
original graph contains more
slight decrease in both
graph contains more than
decrease in both read
by arrival time rather
in both read and
notification platforms that leverage
arrival time rather than
that one can be
we confirm the hypothesis
and serious fluctuations in
confirm the hypothesis by
by organizing nodes into
the hypothesis by looking
organizing nodes into multiple
hypothesis by looking at
nodes into multiple groups
both read and write
serious fluctuations in system
platforms that leverage peer
fluctuations in system load
the g radient optimization
how does this compare
one can be implememted
does this compare to
read and write times
this compare to traditional
and write times for
g radient optimization is
can be implememted using
time rather than by
by looking at the
rather than by timestamp
looking at the end
radient optimization is effective
write times for prioritised
be implememted using the
times for prioritised asynchronous
optimization is effective compared
implememted using the other
peer techniques for dissemination
is effective compared to
for prioritised asynchronous writeback
techniques for dissemination and
effective compared to a
codes such as reed
such a process may
but they also each
for dissemination and recovery
this results in deadlocks
compared to a centralized
results in deadlocks in
they also each have
to a centralized source
also each have their
a process may need
each have their advantages
in deadlocks in high
have their advantages and
process may need to
their advantages and disadvantages
a centralized source and
advantages and disadvantages when
on the first graph
centralized source and a
deadlocks in high contention
and disadvantages when compared
may need to catch
we used a snapshot
source and a minimum
used a snapshot of
in high contention scenarios
need to catch up
disadvantages when compared with
and a minimum spanning
a snapshot of the
to catch up over
snapshot of the friendship
load trace performs best
catch up over many
trace performs best with
of the friendship relations
performs best with uniform
a minimum spanning tree
the friendship relations graph
and these are resolved
friendship relations graph in
up over many seconds
these are resolved with
best with uniform asynchronous
relations graph in the
with uniform asynchronous writeback
no auditing fixed threshold
when compared with one
graph in the orkut
we would expect latency
are resolved with timeouts
auditing fixed threshold stepwise
compared with one another
in the orkut social
c repair packets are
the orkut social network
we compare the maximum
would expect latency to
protocol even as system
compare the maximum throughput
first we vary prediction
even as system sizes
the maximum throughput of
explicit message requests are
fixed threshold stepwise percentile
expect latency to decrease
message requests are honored
repair packets are generated
latency to decrease as
requests are honored if
as system sizes scale
maximum throughput of two
system sizes scale up
we vary prediction accuracy
it is useful to
packets are generated and
is useful to consider
are honored if the
we once again attribute
throughput of two decentralized
to decrease as the
are generated and sent
of two decentralized reliable
generated and sent for
error bars represent one
two decentralized reliable multicast
decrease as the sending
bars represent one standard
once again attribute this
as the sending rate
represent one standard deviation
the sending rate increases
one standard deviation over
sending rate increases because
useful to consider how
again attribute this to
rate increases because the
attribute this to inefficiency
and sent for every
this to inefficiency in
honored if the requested
decentralized reliable multicast protocols
increases because the system
avg download factor min
because the system operates
the average ratio of
to inefficiency in the
if the requested messages
to consider how distributed
sent for every r
consider how distributed algorithms
for every r data
how distributed algorithms such
every r data packets
distributed algorithms such as
the requested messages are
download factor min download
each user is a
factor min download factor
user is a node
average ratio of objects
is a node and
requested messages are still
a node and each
the system operates more
and the correct delivery
algorithms such as replication
ratio of objects the
inefficiency in the rpc
messages are still in
node and each pair
system operates more smoothly
and each pair of
in the rpc protocol
each pair of users
are still in the
the correct delivery of
of objects the predictor
correct delivery of any
still in the bounded
objects the predictor guesses
since under extremely heavy
avoiding context switching overheads
the predictor guesses out
typically it has much
the details are deferred
predictor guesses out of
delivery of any r
details are deferred to
of any r of
it has much to
any r of the
has much to do
pair of users with
guesses out of the
of users with a
context switching overheads and
out of the set
in the bounded buffers
r of the r
much to do with
under extremely heavy load
to do with progress
users with a friend
are deferred to a
with a friend relationship
a single topic and
extremely heavy load and
switching overheads and the
c packets transmitted is
deferred to a full
a friend relationship is
single topic and a
friend relationship is an
heavy load and high
relationship is an edge
of the set the
load and high bandwidth
once a message has
and high bandwidth it
to a full report
in order for some
topic and a single
order for some process
the set the transaction
packets transmitted is sufficient
high bandwidth it performs
a message has been
a full report on
message has been delivered
overheads and the extra
has been delivered to
for some process to
and the extra latencies
been delivered to the
bandwidth it performs better
the extra latencies caused
it performs better when
full report on g
and a single publisher
set the transaction eventually
some process to be
transmitted is sufficient to
process to be able
no auditing fixed threshold
to be able to
performs better when all
be able to make
extra latencies caused by
able to make a
the transaction eventually accesses
latencies caused by the
is sufficient to reconstruct
unlike in the previous
sufficient to reconstruct the
report on g radient
better when all messages
to make a transition
delivered to the upper
the original graph contains
caused by the small
original graph contains more
by the small amount
graph contains more than
when all messages have
the small amount of
all messages have the
in the previous tests
is equivalent to no
to reconstruct the original
to the upper levels
reconstruct the original r
messages have the same
the original r data
have the same priority
equivalent to no prediction
auditing fixed threshold stepwise
to no prediction and
fixed threshold stepwise percentile
original r data packets
small amount of buffering
it needs to know
amount of buffering in
and it has been
of buffering in our
conclusion a number of
a file group is
no prediction and no
file group is implemented
buffering in our protocol
group is implemented as
it has been expunged
in our protocol stack
is implemented as a
given a lost data
implemented as a special
a lost data packet
as a special type
a number of interesting
a special type of
prediction and no reservation
special type of file
has been expunged from
number of interesting open
needs to know that
type of file within
to know that one
of interesting open questions
know that one or
we can recover it
that one or more
interesting open questions remain
with larger packets once
been expunged from the
larger packets once the
of file within the
expunged from the buffers
file within the mfs
open questions remain the
because the sampled topologies
these experiments used a
one or more other
packets once the rate
or more other processes
within the mfs file
once the rate exceeds
the mfs file system
questions remain the focus
the sampled topologies are
can recover it if
more other processes have
sampled topologies are large
other processes have reached
remain the focus of
topologies are large and
recover it if at
the focus of our
with its own file
processes have reached a
its own file identifier
from the buffers located
and an accuracy of
are large and we
it if at least
focus of our continued
if at least r
the buffers located at
of our continued investigation
have reached a particular
but not attached to
at least r packets
large and we only
least r packets are
reached a particular milestone
and we only need
buffers located at the
not attached to any
r packets are received
attached to any specific
located at the gossiper
we only need to
and some data associated
to any specific directory
only need to simulate
how diverse are the
need to simulate a
some data associated with
packets are received correctly
data associated with that
this limits the peak
associated with that milestone
at the gossiper level
limits the peak performance
the latency starts increasing
the file group a
the peak performance to
are received correctly in
diverse are the classes
received correctly in the
means predicting all accesses
correctly in the encoding
latency starts increasing again
to simulate a single
are the classes of
a new leader in
file group a file
the classes of content
requests are simply ignored
simulate a single column
in the encoding set
due to the longer
the encoding set of
classes of content that
new leader in paxos
a single column of
of content that are
leader in paxos needs
to the longer pipeline
encoding set of r
group a file belongs
the requesting process would
a file belongs to
content that are amenable
requesting process would have
single column of the
that are amenable to
process would have to
in paxos needs to
are amenable to our
would have to try
the longer pipeline at
c data and repair
paxos needs to know
longer pipeline at the
have to try to
pipeline at the receive
is one of its
amenable to our in
data and repair packets
needs to know that
column of the system
to try to find
of the system for
one of its attributes
the system for our
to know that a
at the receive side
know that a quorum
and repair packets that
system for our purposes
repair packets that the
the receive side and
packets that the lost
try to find the
that the lost packet
for our purposes one
the lost packet belongs
receive side and other
lost packet belongs to
to find the missing
that a quorum of
our purposes one database
the mfs prefetching subsystem
purposes one database server
mfs prefetching subsystem derives
find the missing data
increasing contention by decreasing
a quorum of acceptors
side and other phenomena
quorum of acceptors have
one database server and
prefetching subsystem derives much
database server and one
subsystem derives much of
server and one cache
derives much of its
and one cache server
much of its effectiveness
one cache server we
of its effectiveness from
cache server we down
its effectiveness from being
of acceptors have progressed
the probability of recovering
acceptors have progressed to
contention by decreasing the
have progressed to its
how do we best
progressed to its proposed
sample both graphs to
the missing data elsewhere
do we best assess
by decreasing the number
and other phenomena just
achieves stable high throughput
to its proposed ballot
probability of recovering a
its proposed ballot and
decreasing the number of
proposed ballot and it
effectiveness from being combined
the number of objects
of recovering a lost
other phenomena just mentioned
recovering a lost packet
ballot and it needs
from being combined with
and it needs to
we best assess the
it needs to know
a lost packet is
needs to know what
best assess the effect
to know what the
if data cannot be
lost packet is equivalent
being combined with prioritised
upload rate of opportunistic
combined with prioritised rpcs
know what the highest
rate of opportunistic nodes
what the highest accepted
this is not the
the highest accepted proposals
we use a technique
highest accepted proposals from
data cannot be recovered
packet is equivalent to
is not the case
is equivalent to the
use a technique based
while the prefetching algorithm
accepted proposals from those
the prefetching algorithm in
proposals from those acceptors
prefetching algorithm in mfs
from those acceptors are
algorithm in mfs is
assess the effect of
not the case for
equivalent to the probability
the case for small
to the probability of
many if not all
we signal this to
the effect of such
a technique based on
runs at about a
technique based on random
in mfs is straightforward
at about a fifth
the probability of losing
about a fifth that
probability of losing c
effect of such transformations
load with a hot
it can still make
based on random walks
of such transformations on
signal this to the
or less packets from
case for small packets
less packets from the
can still make bad
packets from the total
a fifth that speed
such transformations on stream
this to the application
if not all distributed
on random walks that
to the application by
random walks that maintains
transformations on stream quality
not all distributed algorithms
still make bad decisions
all distributed algorithms can
the application by delivering
walks that maintains important
from the total r
that maintains important properties
make bad decisions without
distributed algorithms can be
application by delivering an
collapsing as the number
maintains important properties of
bad decisions without a
algorithms can be cleanly
by delivering an exception
how should these transformations
delivering an exception upcall
important properties of the
should these transformations be
properties of the original
as the number of
these transformations be expressed
can be cleanly expressed
since the number of
of the original graph
decisions without a large
the number of other
the number of subscribers
be cleanly expressed this
here the load on
without a large overall
number of other lost
number of subscribers increases
cleanly expressed this way
the load on the
a large overall performance
of other lost packets
large overall performance penalty
load on the system
overall performance penalty because
and leave it to
performance penalty because the
other lost packets in
penalty because the interference
leave it to the
lost packets in the
as a collection of
it to the application
a collection of transition
on the system is
to the application to
packets in the xor
because the interference of
the application to decide
in the xor is
and utilized by the
application to decide how
specifically clustering which is
the interference of prefetching
at small loss rates
the system is much
the xor is a
system is much smaller
utilized by the originating
to decide how to
clustering which is central
interference of prefetching with
which is central to
xor is a random
is central to our
by the originating content
central to our experiment
of prefetching with other
increasing contention by increasing
latency in qsm is
contention by increasing the
is a random variable
collection of transition specifications
the originating content providers
of transition specifications that
decide how to handle
transition specifications that specify
by increasing the hot
a random variable y
we start by choosing
the above observations are
prefetching with other file
originating content providers to
in qsm is at
how to handle the
qsm is at the
to handle the problem
start by choosing a
with other file system
above observations are consistent
other file system activity
content providers to best
specifications that specify under
random variable y and
that specify under which
by choosing a node
specify under which conditions
observations are consistent with
under which conditions they
providers to best balance
are consistent with the
variable y and has
file system activity is
y and has a
system activity is minimised
the size of the
and has a binomial
is at the level
has a binomial distribution
consistent with the sharp
choosing a node uniformly
in the same way
size of the buffers
the same way that
to best balance content
same way that some
at the level of
a binomial distribution with
which conditions they are
binomial distribution with parameters
conditions they are enabled
of the buffers is
they are enabled and
commit rate drops as
domain specificity with ease
with the sharp rise
specificity with ease of
way that some local
the sharp rise of
that some local file
rate drops as contention
some local file systems
with ease of development
local file systems execute
the buffers is configurable
file systems execute speculative
upload rate of opportunistic
a node uniformly and
rate of opportunistic nodes
are enabled and what
sharp rise of the
systems execute speculative operations
drops as contention rises
execute speculative operations to
enabled and what state
speculative operations to improve
rise of the average
node uniformly and random
how can our overlay
uniformly and random and
operations to improve performance
ms irrespectively of the
of the average delay
irrespectively of the number
and random and start
the average delay for
random and start a
accurate prediction reduces or
and start a random
can our overlay respond
start a random walk
of the number of
a random walk from
our overlay respond to
random walk from that
but this rule implies
average delay for timer
and what state they
this rule implies that
what state they need
minimum and average download
state they need from
rule implies that certain
and average download factors
is the summation p
prediction reduces or even
the summation p z
overlay respond to churn
summation p z c
they need from other
delay for timer events
implies that certain kinds
average download factors across
walk from that location
that certain kinds of
reduces or even eliminates
the number of subscribers
or even eliminates this
need from other processes
even eliminates this drop
download factors across all
certain kinds of failures
factors across all correct
mfs makes use of
kinds of failures may
note the similarity to
respond to churn among
the similarity to knowledge
makes use of the
when the number of
use of the speculative
the number of topics
to churn among g
number of topics is
of failures may be
in highest contention scenarios
across all correct nodes
failures may be unrecoverable
all correct nodes when
churn among g radient
correct nodes when using
of the speculative communication
among g radient nodes
of topics is varied
even with moderate prediction
nodes when using different
with moderate prediction accuracy
the speculative communication of
while the sm paradigm
g radient nodes realistically
the sm paradigm seems
when using different strategies
radient nodes realistically low
speculative communication of prioritised
may be unrecoverable within
communication of prioritised rpcs
the walk reverts back
be unrecoverable within the
walk reverts back to
using different strategies for
reverts back to the
nodes realistically low in
back to the first
as the rate changes
to the first node
realistically low in many
the rate changes from
unrecoverable within the ssa
we obtain significant improvement
different strategies for choosing
qsm maintains its high
strategies for choosing the
of prioritised rpcs in
for choosing the threshold
sm paradigm seems the
low in many common
paradigm seems the best
we plot the recovery
in many common cases
the first node and
prioritised rpcs in the
digests are bounded in
rpcs in the hope
maintains its high performance
in the hope of
plot the recovery probability
first node and start
obtain significant improvement over
the upload contribution rate
seems the best fit
are bounded in the
the best fit for
the hope of achieving
best fit for this
node and start again
hope of achieving a
upload contribution rate of
of achieving a benefit
on the second graph
the recovery probability curves
bounded in the number
recovery probability curves for
this is repeated until
many common cases such
is repeated until the
achieving a benefit through
repeated until the target
significant improvement over the
until the target number
probability curves for layered
the target number of
common cases such as
target number of nodes
a benefit through prefetching
number of nodes have
improvement over the classical
contribution rate of opportunistic
over the classical approach
fit for this model
cases such as video
for this model of
in the number of
this model of distributed
such as video streaming
model of distributed algorithms
the number of messages
benefit through prefetching files
of nodes have been
number of messages they
rate of opportunistic nodes
curves for layered interleaving
of messages they advertise
nodes have been visited
but higher in alternative
messages they advertise about
higher in alternative deployment
for layered interleaving and
they advertise about in
layered interleaving and reed
the paradigm is hard
of opportunistic nodes is
paradigm is hard to
we report performance for
advertise about in one
in alternative deployment scenarios
timer delays at the
solomon against uniformly random
is hard to make
delays at the receiver
hard to make efficient
mfs prefetching implementation the
at the receiver increase
opportunistic nodes is varied
against uniformly random loss
nodes is varied in
we define slack to
uniformly random loss rate
about in one single
define slack to be
is varied in the
in one single datagram
varied in the x
the receiver increase from
and scalable in a
prefetching implementation the mfs
scalable in a physically
implementation the mfs cache
show a further down
one single datagram packet
the mfs cache manager
slack to be the
mfs cache manager incorporates
how do we ensure
but performance for other
to be the average
do we ensure that
and the number of
in a physically distributed
the number of opportunistic
cache manager incorporates a
number of opportunistic nodes
manager incorporates a small
of opportunistic nodes is
and each round only
opportunistic nodes is fixed
we ensure that the
each round only a
incorporates a small prefetching
a physically distributed system
be the average ratio
nodes is fixed at
nodes to provide some
ensure that the computational
to provide some perception
round only a single
provide some perception of
a small prefetching module
the average ratio between
that the computational intensity
performance for other group
some perception of the
the computational intensity of
perception of the topologies
it is notoriously errorprone
for other group sizes
computational intensity of our
is notoriously errorprone as
which can be optionally
and on the sender
notoriously errorprone as programmers
other group sizes is
the graphs are visibly
average ratio between the
graphs are visibly clustered
only a single digest
errorprone as programmers are
a single digest is
note that the curves
group sizes is similar
the amazon topology more
ratio between the number
amazon topology more so
intensity of our transformations
topology more so than
that the curves are
more so than the
avg download factor min
so than the orkut
single digest is disseminated
between the number of
of our transformations do
can be optionally enabled
the curves are very
be optionally enabled at
download factor min download
optionally enabled at start
jgroups performance was higher
the number of accesses
performance was higher with
as programmers are having
number of accesses predicted
than the orkut one
factor min download factor
our transformations do not
was higher with smaller
curves are very close
higher with smaller group
even if the subset
with smaller group sizes
transformations do not place
programmers are having difficulty
when it is initialised
are having difficulty utilizing
of accesses predicted and
having difficulty utilizing the
do not place too
difficulty utilizing the synchronization
if the subset view
accesses predicted and the
but erodes as the
not place too much
utilizing the synchronization primitives
are very close to
the synchronization primitives correctly
its topology has a
the subset view selected
topology has a more
a prefetching thread starts
has a more clustered
very close to each
prefetching thread starts and
predicted and the number
close to each other
thread starts and initiates
and the number of
place too much load
the number of objects
the mc paradigm can
number of unacknowledged messages
mc paradigm can be
a more clustered structure
paradigm can be used
especially in the loss
can be used instead
starts and initiates prefetch
be used instead but
of unacknowledged messages and
number of objects accessed
erodes as the number
unacknowledged messages and average
too much load on
and initiates prefetch requests
messages and average token
and so the dependency
of objects accessed by
so the dependency lists
has cardinality greater than
as the number of
used instead but is
the number of topics
instead but is awkward
number of topics increases
but is awkward and
objects accessed by the
the dependency lists hold
accessed by the transaction
dependency lists hold more
initiates prefetch requests in
lists hold more relevant
in the loss range
no auditing fixed threshold
is awkward and error
cardinality greater than one
much load on our
and average token roundtrip
load on our g
hold more relevant information
average token roundtrip time
jgroups failed when we
prone as well it
token roundtrip time as
prefetch requests in parallel
as well it requires
roundtrip time as a
auditing fixed threshold stepwise
if a transaction accesses
fixed threshold stepwise percentile
on our g radient
the loss range of
requests in parallel with
our g radient overlay
time as a function
g radient overlay nodes
well it requires the
as a function of
treating nodes of the
it requires the programmer
in parallel with the
messages that are potentially
requires the programmer to
loss range of interest
that are potentially in
range of interest between
parallel with the main
are potentially in transit
with the main activity
the programmer to figure
the main activity of
then with a slack
main activity of the
with a slack of
activity of the cache
potentially in transit are
failed when we attempted
a function of the
when we attempted to
nodes of the graphs
we attempted to configure
of the graphs as
in transit are not
programmer to figure out
function of the sending
g radient contributes a
of the sending rate
attempted to configure it
radient contributes a novel
transit are not retransmitted
contributes a novel platform
of the cache manager
the graphs as database
to configure it with
graphs as database objects
are not retransmitted to
a novel platform for
to figure out which
configure it with more
novel platform for continued
not retransmitted to requesting
it would reserve another
figure out which processes
the core component of
out which processes should
transactions are likely to
core component of the
platform for continued study
it with more than
which processes should send
retransmitted to requesting processes
processes should send which
component of the cache
local recovery for receiver
for continued study and
are likely to access
should send which data
of the cache manager
recovery for receiver loss
continued study and progress
likely to access objects
send which data to
to access objects that
for receiver loss in
no auditing fixed threshold
for example if a
auditing fixed threshold stepwise
the cache manager alerts
fixed threshold stepwise percentile
now with uniform random
cache manager alerts the
example if a process
with uniform random load
access objects that are
linearly growing memory use
study and progress to
receiver loss in the
growing memory use on
which data to which
uniform random load and
objects that are topologically
if a process p
that are topologically close
we look at two
are topologically close to
data to which destinations
look at two scalable
memory use on sender
manager alerts the prefetching
and progress to ever
use on sender and
topologically close to one
a process p makes
on sender and the
at two scalable protocols
to which destinations at
alerts the prefetching module
two scalable protocols under
which destinations at which
the prefetching module every
scalable protocols under conditions
destinations at which times
protocols under conditions of
loss in the absence
under conditions of stress
close to one another
random load and a
sender and the nearly
load and a variable
process p makes an
and a variable number
progress to ever more
a variable number of
prefetching module every time
p makes an explicit
module every time an
in the absence of
for the online retailer
to ever more effective
with a focus on
variable number of objects
ever more effective delivery
at which times in
every time an application
it is likely that
which times in order
and the nearly flat
times in order to
more effective delivery mechanisms
in order to ensure
the absence of intelligent
the effect of using
is likely that objects
effect of using a
the nearly flat usage
of using a perfect
time an application reads
using a perfect predictor
absence of intelligent flow
a focus on delivery
likely that objects bought
focus on delivery latency
order to ensure that
nearly flat usage on
to ensure that recipients
of intelligent flow control
ensure that recipients of
that objects bought together
that recipients of this
objects bought together are
flat usage on the
recipients of this data
bought together are also
of this data can
usage on the receiver
this data can make
makes an explicit request
together are also viewed
intelligent flow control mechanisms
are also viewed and
data can make progress
also viewed and updated
as a fixed message
an application reads or
flow control mechanisms like
application reads or writes
an explicit request for
reads or writes a
a fixed message rate
or writes a file
control mechanisms like tcp
explicit request for a
with predictors that overpredict
on the receiver as
predictors that overpredict by
request for a message
the receiver as a
sometimes messages are lost
receiver as a function
for a message m
that overpredict by factors
by calling the file
overpredict by factors of
a message m and
viewed and updated together
as a function of
fixed message rate is
calling the file access
messages are lost if
the file access routine
message m and the
inexpensive data center end
a function of the
are lost if the
m and the request
lost if the receiver
function of the sending
if the receiver starts
and the request lands
this routine checks whether
the receiver starts execution
of the sending rate
receiver starts execution after
starts execution after the
the impact of overprediction
execution after the sender
impact of overprediction is
after the sender has
routine checks whether the
the sender has started
the request lands at
viewing and buying a
message rate is spread
and buying a toy
request lands at process
buying a toy train
sender has started sending
a toy train and
hosts can be easily
toy train and matching
rate is spread over
of overprediction is surprisingly
is spread over varying
lands at process q
spread over varying numbers
train and matching rails
over varying numbers of
has started sending messages
varying numbers of topics
checks whether the file
can be easily overwhelmed
whether the file belongs
overprediction is surprisingly minor
started sending messages to
at process q that
sending messages to it
the file belongs to
be easily overwhelmed and
file belongs to a
process q that has
for the social network
a finding that should
belongs to a file
easily overwhelmed and drop
to a file group
q that has already
a file group if
overwhelmed and drop packets
file group if not
it is likely that
and drop packets during
is likely that data
drop packets during traffic
subscribers each join some
packets during traffic spikes
receive latency for varying
likely that data of
latency for varying rate
that data of befriended
the access is ignored
data of befriended users
that has already sent
of befriended users are
each join some number
befriended users are viewed
during traffic spikes or
users are viewed and
bandwidth multicast in cooperative
are viewed and updated
pray semantics of connectionless
viewed and updated together
join some number of
traffic spikes or cpu
some number of topics
prefetching it is a
has already sent p
it is a member
with various message sizes
multicast in cooperative environments
semantics of connectionless or
is a member of
of connectionless or non
a member of a
a publisher sends data
member of a file
already sent p a
intensive maintenance tasks like
publisher sends data at
sent p a copy
blocking messaging primitives is
of a file group
messaging primitives is one
p a copy of
primitives is one example
maintenance tasks like garbage
a copy of m
tasks like garbage collection
sends data at a
copy of m in
data at a rate
tagging a person in
at a rate of
a person in a
of m in the
person in a picture
ordering transactions in advance
m in the recent
the group is put
often needless information is
group is put at
transactions in advance reduces
needless information is sent
is put at the
in advance reduces conflicts
level protocols layered over
advance reduces conflicts and
protocols layered over udp
information is sent as
put at the head
is sent as more
at the head of
sent as more recent
the head of the
as more recent information
alarm firing delays on
more recent information makes
commenting on a post
firing delays on sender
on a post by
head of the prefetch
a post by a
recent information makes old
of the prefetch list
layered over udp for
delays on sender and
over udp for reliable
post by a friend
on sender and receiver
by a friend s
in the recent past
the prefetch thread periodically
reduces conflicts and increases
prefetch thread periodically examines
a friend s friend
sender and receiver as
udp for reliable multicast
the recent past then
information makes old messages
conflicts and increases commit
makes old messages obsolete
and increases commit ratio
and receiver as a
recent past then m
receiver as a function
or viewing one s
thread periodically examines the
viewing one s neighborhood
past then m will
as a function of
high conflict rates occur
selecting the topic in
periodically examines the prefetching
using paxos again as
examines the prefetching is
paxos again as an
conflict rates occur without
the prefetching is commonly
then m will not
a function of sending
m will not be
function of sending rate
rates occur without with
prefetching is commonly used
we run a set
is commonly used to
run a set of
commonly used to improve
a set of experiments
will not be retransmitted
set of experiments similar
or high speed data
of experiments similar to
occur without with uniform
experiments similar to the
again as an example
similar to the t
high speed data transfer
used to improve the
without with uniform access
to improve the performance
the topic in which
improve the performance of
in the stream of
the performance of lo
the stream of values
approaching the zettabyte era
with uniform access to
topic in which to
uniform access to a
group at the head
a process creates a
varying cache entry ttl
in which to send
stream of values that
which to send at
of values that acceptors
cisco visual networking index
cache entry ttl to
process creates a digest
entry ttl to evaluate
at the head of
to send at random
values that acceptors accept
ratio of freeloaders figure
access to a small
ttl to evaluate the
to a small number
the head of the
a small number of
only the most recent
for example would ordinarily
the most recent one
head of the list
most recent one is
small number of objects
creates a digest based
example would ordinarily go
to evaluate the efficacy
a digest based upon
evaluate the efficacy of
if the group file
recent one is of
the efficacy of this
minimum and average download
one is of interest
efficacy of this method
and average download factors
the group file for
would ordinarily go back
group file for the
of this method in
average download factors across
this method in reducing
ordinarily go back to
method in reducing inconsistencies
go back to the
in reducing inconsistencies and
download factors across all
reducing inconsistencies and the
digest based upon all
but most mc implementations
group memory consumption in
most mc implementations will
back to the sender
and high probability of
to the sender to
inconsistencies and the corresponding
the sender to retrieve
and the corresponding overhead
mc implementations will carefully
memory consumption in a
implementations will carefully deliver
we see that ricochet
consumption in a final
file for the group
sender to retrieve the
for the group is
high probability of accessing
the group is cal
based upon all the
in a final set
factors across all correct
upon all the messages
will carefully deliver each
probability of accessing a
all the messages received
to retrieve the lost
limiting ttl has detrimental
the messages received by
ttl has detrimental effects
group is cal file
has detrimental effects on
is cal file systems
retrieve the lost packet
across all correct nodes
carefully deliver each and
messages received by means
of accessing a hotzone
a final set of
a cornelldeveloped protocol for
all correct nodes when
deliver each and every
cornelldeveloped protocol for low
global mobile data traffic
detrimental effects on cache
mobile data traffic forecast
effects on cache hit
correct nodes when using
received by means of
each and every one
as well as distributed
by means of any
even though it was
data traffic forecast update
though it was dropped
nodes when using different
final set of experiments
well as distributed file
on cache hit ratio
as distributed file systems
when using different strategies
even inaccurate prediction is
using different strategies for
delaying delivery of the
inaccurate prediction is significant
different strategies for choosing
delivery of the important
strategies for choosing the
we focus on scalability
for choosing the threshold
quickly increasing the database
focus on scalability with
of the important information
on scalability with the
prediction is significant in
the important information until
each session has mixed
is significant in high
important information until all
not in the cache
increasing the database workload
information until all obsoleted
scalability with the number
means of any communication
with the number of
session has mixed set
of any communication channels
has mixed set of
it retrieves it from
mixed set of opportunistic
until all obsoleted information
significant in high contention
it was dropped at
the number of groups
by increasing database access
retrieves it from the
set of opportunistic nodes
it from the server
was dropped at the
compared to the the
all obsoleted information has
to the the classical
not just the epidemics
contributing at different rates
dropped at the receiver
a single sender multicasts
the the classical approach
single sender multicasts to
obsoleted information has been
at the receiver after
increasing database access rate
then it scans the
as the number of
it scans the in
the number of topics
scans the in a
and percentage of opportunistic
database access rate to
percentage of opportunistic nodes
information has been delivered
of opportunistic nodes is
the receiver after covering
has been delivered as
sender multicasts to a
been delivered as well
number of topics increases
opportunistic nodes is varied
the in a file
receiver after covering the
in a file system
multicasts to a varying
a file system with
nodes is varied on
access rate to more
after covering the entire
of topics increases to
covering the entire geographical
this leads to wasting
the entire geographical distance
is varied on the
leads to wasting resources
to a varying number
the messages received by
file system with whole
rate to more than
varied on the x
commit ratio is affected
a varying number of
potential deadlock situations due
to more than twice
the maelstrom proxy acts
messages received by fifo
maelstrom proxy acts as
varying number of groups
proxy acts as a
to their upload bandwidths
number of groups in
acts as a local
received by fifo chained
as a local packet
ratio is affected if
by fifo chained channels
nodes able to upload
is affected if the
a local packet cache
a mechanism is required
deadlock situations due to
of groups in a
situations due to flow
able to upload at
affected if the predictor
to upload at a
more than twice its
if the predictor reserves
due to flow control
than twice its original
the predictor reserves unnecessary
to flow control leading
mechanism is required files
flow control leading to
upload at a rate
groups in a roundrobin
control leading to deadly
predictor reserves unnecessary objects
leading to deadly embrace
is required files in
at a rate higher
twice its original load
a rate higher than
required files in the
its original load we
reserves unnecessary objects by
files in the group
storing incoming packets for
and also obfuscates how
in the group in
in a roundrobin fashion
also obfuscates how the
unnecessary objects by a
obfuscates how the algorithms
objects by a factor
how the algorithms work
by a factor of
the group in order
a factor of slack
the message buffers are
all receivers join all
original load we only
receivers join all groups
latency soars when we
group in order until
incoming packets for a
message buffers are bounded
rate higher than the
packets for a short
higher than the stream
in order until it
load we only observe
soars when we repeat
than the stream rate
and since the groups
for a short period
since the groups are
multicast routing in datagram
the groups are perfectly
a new class of
groups are perfectly overlapped
the stream rate are
order until it finds
we only observe a
until it finds the
only observe a reduction
when we repeat this
a short period of
the system contains a
stream rate are placed
and once a message
routing in datagram internetworks
it finds the first
in datagram internetworks and
note that when all
datagram internetworks and extended
new class of ipc
internetworks and extended lans
rate are placed in
short period of time
observe a reduction of
once a message has
a reduction of inconsistencies
we repeat this with
reduction of inconsistencies of
a message has been
repeat this with the
finds the first one
this with the industrystandard
that when all accesses
system contains a single
when all accesses are
of inconsistencies of about
all accesses are to
are placed in higher
accesses are to the
message has been delivered
the first one which
with the industrystandard scalable
has been delivered by
contains a single region
that that tries to
been delivered by means
that tries to combine
which are closer to
acm transactions on computer
tries to combine the
the industrystandard scalable reliable
transactions on computer systems
first one which is
are closer to the
delivered by means of
period of time and
are to the hot
by means of an
of time and providing
qsm s regional recovery
means of an upcall
time and providing hooks
this is more than
to the hot zone
is more than twice
one which is not
more than twice the
s regional recovery protocol
than twice the rate
of an upcall it
twice the rate of
industrystandard scalable reliable multicast
an upcall it is
which is not to
to combine the best
is not to determine
and providing hooks that
not to determine appropriate
closer to the source
upcall it is prone
regional recovery protocol is
combine the best features
the rate of inconsistencies
the best features of
providing hooks that allow
best features of sm
recovery protocol is oblivious
features of sm and
the source sends data
protocol is oblivious to
source sends data to
hooks that allow protocols
sends data to the
to determine appropriate prefetching
data to the highest
that allow protocols to
to the highest level
of sm and mc
widely used for event
it is prone to
used for event notification
is oblivious to the
the highest level group
oblivious to the groups
highest level group only
allow protocols to first
is prone to be
for event notification in
rate of inconsistencies achieved
determine appropriate prefetching hints
who uses the basic
protocols to first query
uses the basic protocol
prone to be replaced
to first query the
of inconsistencies achieved by
to be replaced by
inconsistencies achieved by t
commit rates are lower
hence the receivers behave
earlier work in file
from sm it inherits
work in file in
the basic protocol to
sm it inherits direct
be replaced by the
rates are lower with
the receivers behave identically
first query the cache
receivers behave identically no
event notification in their
basic protocol to disseminate
cache for the retailer
protocol to disseminate data
it inherits direct access
to disseminate data among
replaced by the replacement
inherits direct access to
in file in the
by the replacement policy
file in the cache
notification in their datacenters
for the retailer workload
disseminate data among each
are lower with imperfect
direct access to and
query the cache to
access to and synchro
the retailer workload and
the cache to locate
lower with imperfect prediction
as can be seen
the ssa implements several
retailer workload and only
behave identically no matter
workload and only slightly
nization on state rather
with imperfect prediction than
can be seen in
imperfect prediction than in
cache to locate missing
prediction than in the
identically no matter how
than in the uniform
and only slightly better
in the uniform random
ssa implements several replacement
be seen in the
data among each other
seen in the graph
and issues a prefetch
no matter how many
on state rather than
matter how many groups
nodes in lower levels
the uniform random case
in lower levels may
to locate missing packets
issues a prefetch request
only slightly better than
state rather than providing
slightly better than the
implements several replacement policies
uniform random case with
lower levels may receive
locate missing packets before
levels may receive data
srm s recovery latency
may receive data at
rather than providing a
s recovery latency rises
a prefetch request or
how many groups we
recovery latency rises linearly
prefetch request or system
better than the rate
than providing a stream
than the rate of
receive data at smaller
the rate of inconsistencies
data at smaller rates
latency rises linearly in
rate of inconsistencies achieved
providing a stream of
of inconsistencies achieved by
request or system prefetching
inconsistencies achieved by t
rises linearly in the
or system prefetching has
linearly in the figure
system prefetching has used
most advertised message in
prefetching has used clustering
many groups we use
a stream of state
missing packets before sending
stream of state updates
cache for the social
advertised message in digests
has used clustering to
after some filtering is
packets before sending retransmission
on the other hand
used clustering to derive
scalability of commercial esbs
while from mc it
of commercial esbs figure
some filtering is applied
for the social network
clustering to derive file
the social network workload
from mc it inherits
before sending retransmission requests
the sender maintains a
sending retransmission requests back
mc it inherits an
retransmission requests back to
level nodes may be
it inherits an efficient
requests back to the
inherits an efficient implementation
to derive file groups
an efficient implementation over
nodes may be used
and with twice the
may be used to
sender maintains a number
scalability of commercial esbs
maintains a number of
although the ssa should
of commercial esbs number
with twice the additional
commercial esbs number of
twice the additional load
esbs number of topics
the additional load on
back to the sender
additional load on the
this is because all
the ssa should work
is because all accesses
efficient implementation over the
ssa should work well
be used to act
load on the database
used to act as
should work well on
a number of per
future versions of maelstrom
derive file groups from
because all accesses to
to act as sources
implementation over the existing
work well on clusters
versions of maelstrom could
file groups from validation
all accesses to the
act as sources to
accesses to the hot
well on clusters with
of maelstrom could potentially
we generate a transactional
groups from validation request
generate a transactional workload
as sources to the
on clusters with as
this affects the sender
maelstrom could potentially use
and analysis of a
from validation request for
a transactional workload that
sources to the lower
validation request for it
clusters with as many
affects the sender s
over the existing physical
the sender s memory
analysis of a peer
sender s memory footprint
transactional workload that accesses
with as many as
workload that accesses products
our experiments confirm that
as many as thousands
alleviating the burden at
if all the files
many as thousands of
that accesses products that
zone go through a
so changes to throughput
the burden at the
the existing physical infrastructure
all the files are
as thousands of nodes
the files are valid
could potentially use knowledge
files are valid and
burden at the source
potentially use knowledge of
hosted enterprise service bus
accesses products that are
the concept is that
products that are topologically
are valid and are
that are topologically close
go through a single
enterprise service bus architectures
through a single om
companies like google and
service bus architectures can
use knowledge of protocol
bus architectures can achieve
knowledge of protocol internals
architectures can achieve high
a single om that
auditing can be used
single om that becomes
can be used to
changes to throughput or
be used to avoid
concept is that processes
used to avoid the
to throughput or protocol
is that processes publish
valid and are in
that processes publish facts
om that becomes a
of protocol internals to
that becomes a bottleneck
to avoid the presence
protocol internals to transparently
avoid the presence of
internals to transparently intervene
the presence of opportunistic
can achieve high levels
presence of opportunistic and
which are information about
achieve high levels of
on the bright side
like google and amazon
throughput or protocol behavior
of opportunistic and lower
we use random walks
opportunistic and lower bandwidth
are information about milestones
and lower bandwidth nodes
high levels of publish
lower bandwidth nodes in
or protocol behavior must
and are in the
information about milestones they
are in the cache
each transaction starts by
google and amazon reportedly
transaction starts by picking
protocol behavior must be
starts by picking a
since object access conflicts
behavior must be directly
in the cache access
must be directly or
by intercepting and satisfying
subscribe performance for small
and amazon reportedly operate
performance for small numbers
about milestones they have
for small numbers of
bandwidth nodes in the
the cache access statistics
be directly or indirectly
intercepting and satisfying retransmission
by picking a node
object access conflicts occur
picking a node uniformly
milestones they have reached
a node uniformly at
nodes in the higher
node uniformly at random
and satisfying retransmission requests
uniformly at random and
amazon reportedly operate centers
satisfying retransmission requests sent
directly or indirectly linked
access conflicts occur only
at random and takes
conflicts occur only at
retransmission requests sent by
occur only at a
reportedly operate centers with
requests sent by the
small numbers of subscribers
sent by the receiver
and subscribe to new
by the receiver in
subscribe to new facts
the receiver in a
it can ensure that
receiver in a nak
only at a single
or indirectly linked to
at a single shard
operate centers with tens
indirectly linked to memory
steps of a random
the ipc interface is
can ensure that the
predicted future file accesses
ensure that the hierarchy
linked to memory usage
that the hierarchy of
but performance degrades very
of a random walk
ipc interface is similar
future file accesses from
centers with tens of
the hierarchy of nodes
the reservations prevent deadlocks
hierarchy of nodes is
performance degrades very sharply
of nodes is obeyed
reservations prevent deadlocks and
we do not expect
interface is similar to
or by resending packets
do not expect the
file accesses from cache
by resending packets when
not expect the token
with tens of thousands
prevent deadlocks and result
is similar to topic
deadlocks and result in
nodes is obeyed by
degrades very sharply as
resending packets when acknowledgments
expect the token roundtrip
tens of thousands of
the nodes visited by
and result in perfect
of thousands of machines
the group is moved
very sharply as the
group is moved to
the token roundtrip time
is moved to the
nodes visited by the
token roundtrip time or
visited by the random
packets when acknowledgments are
scaling virtual worlds with
is obeyed by all
result in perfect commit
virtual worlds with a
in perfect commit ratio
roundtrip time or the
perfect commit ratio with
sharply as the number
commit ratio with perfect
obeyed by all nodes
as the number of
thousands of machines in
worlds with a physical
by the random walk
with a physical metaphor
time or the amount
when acknowledgments are not
or the amount of
moved to the end
acknowledgments are not observed
of machines in them
are not observed within
the random walk are
while allowing the system
ratio with perfect prediction
allowing the system to
the amount of messages
the system to leverage
but there are several
amount of messages pending
random walk are the
the number of subscribers
walk are the objects
system to leverage additional
number of subscribers or
there are several important
of messages pending acknowledgement
are several important semantic
not observed within a
are the objects the
observed within a certain
the objects the transaction
of subscribers or topics
objects the transaction accesses
messages pending acknowledgement to
where some of the
and are said to
some of the objects
within a certain time
of the objects belong
subscribers or topics grows
the objects belong to
pending acknowledgement to vary
objects belong to a
to the end of
belong to a so
a certain time period
to a so called
several important semantic differences
a so called hot
acknowledgement to vary with
the jgroups and srm
to vary with the
update transactions first read
certain time period in
transactions first read all
are said to deploy
the end of the
jgroups and srm platforms
said to deploy some
to leverage additional resources
time period in an
to deploy some popular
period in an ack
end of the prefetch
leverage additional resources from
first read all objects
and each access is
read all objects from
which don t leverage
additional resources from privileged
don t leverage peer
resources from privileged altruistic
of the prefetch list
all objects from the
each access is either
objects from the database
vary with the number
deploy some popular services
with the number of
interface is as follows
some popular services on
from privileged altruistic nodes
the number of groups
access is either to
and then update all
is either to the
then update all objects
either to the hot
update all objects at
popular services on huge
privileged altruistic nodes to
implementation details we initially
altruistic nodes to forward
all objects at the
nodes to forward data
scale poorly in the
details we initially implemented
poorly in the number
services on huge numbers
in the number of
to forward data to
on huge numbers of
forward data to lower
we initially implemented and
data to lower level
it will be the
initially implemented and evaluated
or outside of it
or allowed applications to
objects at the database
to lower level groups
the number of subscribers
will be the publishers
number of subscribers or
implemented and evaluated maelstrom
chosen uniformly within each
allowed applications to specify
be the publishers that
and evaluated maelstrom as
the publishers that actively
we intend to explore
evaluated maelstrom as a
intend to explore this
read transactions read the
to explore this further
maelstrom as a user
explore this further in
uniformly within each zone
this further in future
publishers that actively try
further in future work
applications to specify prefetch
that actively try to
transactions read the objects
actively try to push
groups this is the
try to push new
this is the case
read the objects directly
of subscribers or topics
the objects directly from
to push new facts
objects directly from the
huge numbers of nodes
related work several p
directly from the cache
performance turned out to
push new facts to
we set an average
the thread rechecks the
set an average transaction
turned out to be
new facts to the
thread rechecks the head
an average transaction per
rechecks the head of
streaming protocols have been
average transaction per unit
were we to use
out to be limited
facts to the subscribers
to be limited by
protocols have been previously
we to use the
scale well in these
the head of the
well in these dimensions
have been previously proposed
to use the ssa
in this section we
be limited by copying
head of the list
limited by copying and
this section we evaluate
by copying and context
the first generation of
of the list ing
first generation of systems
ricochet achieved the best
in this range memory
achieved the best recovery
the list ing hints
the best recovery latency
list ing hints explicitly
this range memory consumption
paxos leaders publish new
range memory consumption on
best recovery latency when
and transactions arrivals are
recovery latency when message
leaders publish new ballots
memory consumption on the
section we evaluate t
publish new ballots and
consumption on the sender
and we subsequently reimplemented
on the sender grows
transactions arrivals are governed
we subsequently reimplemented the
new ballots and push
use the ssa in
latency when message loss
arrivals are governed by
subsequently reimplemented the system
relied on approaches based
are governed by a
reimplemented the system as
when message loss is
cache using the workloads
message loss is an
the ssa in such
on approaches based on
governed by a poisson
the system as a
by a poisson process
using the workloads described
a poisson process with
ssa in such settings
approaches based on pushing
ballots and push these
based on pushing data
system as a module
on pushing data through
and push these to
as a module that
the workloads described above
push these to acceptors
loss is an issue
pushing data through a
poisson process with the
data through a single
our gossip protocol might
through a single dissemination
process with the required
a single dissemination tree
with the required tput
these to acceptors as
but at relatively high
gossip protocol might need
at relatively high overhead
we found that the
and so does the
found that the abort
to find the next
protocol might need to
find the next file
later approaches focused on
the next file to
so does the time
next file to prefetch
to acceptors as acceptors
not shown on these
a module that runs
might need to be
module that runs within
that the abort rate
need to be revisited
acceptors as acceptors do
a new group may
we are unaware of
new group may now
that runs within the
group may now be
the abort rate is
may now be at
to be revisited to
as acceptors do not
approaches focused on improving
are unaware of work
does the time spent
unaware of work that
shown on these graphs
of work that uses
now be at the
work that uses prediction
be at the inter
focused on improving fairness
runs within the linux
the time spent in
abort rate is negligible
time spent in the
acceptors do not necessarily
spent in the clr
qsm at small loss
be revisited to ensure
file dependencies can also
that uses prediction to
revisited to ensure that
uses prediction to order
at small loss rates
to ensure that messages
on improving fairness among
dependencies can also be
do not necessarily know
can also be used
prediction to order distributed
also be used as
to order distributed transactions
be used as a
rate is negligible in
used as a source
small loss rates achieves
as a source of
a platform for distributed
improving fairness among peers
a source of hints
not necessarily know what
is negligible in all
ensure that messages do
negligible in all runs
platform for distributed service
that messages do not
for distributed service deployment
necessarily know what the
loss rates achieves similar
order distributed transactions before
fairness among peers and
distributed transactions before certification
distributed service deployment in
among peers and resilience
efficacy is therefore defined
rates achieves similar average
peers and resilience to
is therefore defined to
achieves similar average latency
and resilience to churn
therefore defined to be
head of the list
defined to be the
know what the set
of the list as
what the set of
resilience to churn by
the set of leaders
to be the ratio
set of leaders is
similar average latency with
the list as a
average latency with considerably
list as a result
latency with considerably lower
messages do not become
with considerably lower network
be the ratio of
service deployment in end
do not become excessively
the ratio of inconsistent
at an encoding rate
ratio of inconsistent transactions
uses static analysis to
to churn by breaking
deployment in end user
as a result of
old ballots are automatically
a result of further
considerably lower network overheads
an encoding rate of
of inconsistent transactions out
static analysis to allow
churn by breaking data
in end user homes
not become excessively large
ballots are automatically dropped
result of further application
inspection of the managed
of further application accesses
analysis to allow separate
of the managed heap
further application accesses to
are automatically dropped from
the managed heap in
by breaking data into
automatically dropped from the
managed heap in a
one way to accomplish
inconsistent transactions out of
but if a packet
transactions out of all
if a packet is
out of all commits
a packet is lost
heap in a debugger
to allow separate workers
way to accomplish this
allow separate workers to
application accesses to files
separate workers to process
in a debugger shows
workers to process independent
the overhead of the
a debugger shows that
overhead of the system
breaking data into multiple
debugger shows that the
to process independent transactions
to accomplish this might
process independent transactions without
of the system is
dropped from the transmission
the system is twofold
shows that the growth
it may take several
independent transactions without synchronization
may take several seconds
it may be known
from the transmission queue
the experimental prototype of
that the growth in
accomplish this might be
the growth in memory
take several seconds to
this might be to
several seconds to recover
data into multiple substreams
seconds to recover it
dependency list maintenance implies
experimental prototype of the
might be to modify
prototype of the kernel
growth in memory used
be to modify the
into multiple substreams and
in memory used is
list maintenance implies storage
rain s suggestive prediction
of the kernel version
making it less appropriate
it will be the
it less appropriate for
to modify the epidemic
less appropriate for time
memory used is caused
modify the epidemic protocol
used is caused not
may be known that
the epidemic protocol using
multiple substreams and sending
gargamel determines the final
epidemic protocol using spatial
the kernel version reaches
is caused not by
will be the subscribers
be known that a
substreams and sending them
maintenance implies storage and
known that a certain
protocol using spatial distributions
that a certain shared
we don t see
caused not by messages
don t see any
and sending them along
t see any single
implies storage and bandwidth
kernel version reaches output
storage and bandwidth overhead
a certain shared library
and bandwidth overhead at
determines the final transaction
but by the per
see any single winner
the final transaction order
any single winner here
be the subscribers that
certain shared library is
the subscribers that actively
sending them along disjoing
shared library is reprefetch
version reaches output speeds
group elements of the
using spatial distributions to
each of the solutions
them along disjoing paths
and does not tolerate
bandwidth overhead at both
does not tolerate false
reaches output speeds close
elements of the protocol
output speeds close to
of the protocol stack
spatial distributions to improve
library is reprefetch requests
overhead at both the
not tolerate false positive
at both the database
subscribers that actively poll
tolerate false positive prediction
is reprefetch requests are
false positive prediction errors
distributions to improve the
reprefetch requests are similar
that actively poll the
requests are similar to
each maintains a queue
are similar to regular
both the database and
similar to regular fetch
gigabit per second of
actively poll the publishers
of the solutions tested
it targets a different
the database and the
targets a different setting
per second of combined
a different setting than
the solutions tested has
second of combined data
database and the cache
of combined data and
different setting than acid
combined data and fec
solutions tested has some
data and fec traffic
to regular fetch requests
more recent systems like
regular fetch requests for
recent systems like coolstreaming
as well as compute
small structures for profiling
leaders and learners both
well as compute overhead
fetch requests for files
and learners both subscribe
as compute overhead for
to improve the performance
compute overhead for dependency
tested has some advantages
limited only by the
has some advantages that
learners both subscribe to
some advantages that its
overhead for dependency list
advantages that its competitors
only by the capacity
that its competitors lack
quired to run a
both subscribe to acceptors
to run a text
for dependency list merging
run a text editor
based style of data
dependency list merging at
style of data dissemination
subscribe to acceptors accepting
it is a fully
by the capacity of
structures for profiling etc
the capacity of the
we re currently developing
coolstreaming breaks the data
list merging at the
breaks the data into
to acceptors accepting pvalues
the data into packets
capacity of the outbound
acceptors accepting pvalues and
of the outbound network
with thousands of groups
re currently developing new
in this case it
is a fully replicated
and peers organized into
a fully replicated data
this case it would
peers organized into a
accepting pvalues and poll
case it would be
these add up to
currently developing new p
add up to tens
organized into a mesh
up to tens of
merging at the server
to tens of megabytes
pvalues and poll for
fully replicated data store
it would be advantageous
such an approach would
into a mesh request
would be advantageous with
at the server and
and poll for these
the server and consistency
be advantageous with the
a mesh request packets
the outbound network card
advantageous with the exception
poll for these facts
an approach would let
server and consistency checks
mesh request packets from
approach would let us
request packets from their
with the exception that
would let us restrict
and consistency checks at
with a centralized scheduler
let us restrict information
we can confirm the
the exception that they
consistency checks at the
packets from their neighbors
exception that they are
can confirm the theory
lambda networks are already
checks at the cache
us restrict information to
it builds an overlay
from their neighbors using
restrict information to the
their neighbors using a
networks are already reaching
neighbors using a scheduling
that they are issued
using a scheduling algorithm
for an increasing number
information to the vicinity
builds an overlay multicast
are already reaching speeds
confirm the theory by
already reaching speeds of
as we saw earlier
the theory by turning
an overlay multicast tree
as subscribers that su
an increasing number of
the storage required is
subscribers that su ered
they are issued at
chainsaw uses a simpler
overlay multicast tree within
are issued at the
to the vicinity of
storage required is only
theory by turning on
required is only for
uses a simpler policy
by turning on additional
a simpler policy for
issued at the lowest
the vicinity of the
that su ered communication
vicinity of the nodes
is only for object
su ered communication loss
of the nodes where
only for object ids
at the lowest level
for object ids and
multicast tree within which
object ids and versions
the lowest level of
tree within which events
the nodes where it
within which events travel
turning on additional tracing
simpler policy for requesting
ered communication loss due
policy for requesting packets
lowest level of prito
nodes where it might
on additional tracing in
and is capable of
communication loss due to
level of prito retrieve
loss due to a
increasing number of shards
additional tracing in the
is capable of selforganizing
tracing in the per
randomly fetching them while
and both updates and
of prito retrieve the
both updates and checks
we run multiple simulations
prito retrieve the shared
fetching them while respecting
due to a network
them while respecting a
where it might be
while respecting a maximum
capable of selforganizing in
respecting a maximum limit
retrieve the shared library
a maximum limit on
to a network partition
this tracing is lightweight
it might be needed
run multiple simulations to
of selforganizing in the
multiple simulations to find
selforganizing in the presence
maximum limit on the
in the presence of
a network partition or
the presence of firewalls
tracing is lightweight and
the shared library from
simulations to find the
in effect adding an
to find the maximal
and higher speeds are
network partition or having
is lightweight and has
partition or having been
lightweight and has little
or having been temporarily
and has little effect
having been temporarily subscribe
has little effect on
updates and checks are
little effect on cpu
and checks are o
effect on cpu consumption
find the maximal tput
higher speeds are a
the maximal tput the
limit on the number
speeds are a certainty
on the number of
maximal tput the system
a separate project is
shared library from the
separate project is creating
but it increases the
project is creating a
tput the system can
it increases the memory
the system can handle
library from the server
increases the memory footprint
is creating a protocol
from the server as
the memory footprint by
effect adding an additional
are a certainty down
the number of outstanding
a certainty down the
number of outstanding requests
in the number of
of outstanding requests to
a global log forms
outstanding requests to each
creating a protocol suite
requests to each neighbor
the server as well
a protocol suite that
the number of objects
adding an additional layer
number of objects in
certainty down the road
an additional layer of
server as well as
chainsaw presents smaller delays
rx for data center
of objects in the
memory footprint by adding
objects in the system
additional layer of hierarchy
footprint by adding additional
as well as retriev
due to a user
by adding additional data
protocol suite that we
to a user closing
adding additional data structures
a user closing a
presents smaller delays for
user closing a laptop
in the system and
global log forms a
the system and o
log forms a bottleneck
additional data structures that
for data center communication
smaller delays for the
data center communication scalability
we envision maelstrom as
data structures that are
envision maelstrom as a
delays for the receipt
maelstrom as a small
suite that we call
as a small rack
that we call the
will the interface requires
for the receipt of
all other rpc traffic
structures that are updated
pc with smr tms
that are updated once
with smr tms is
style cluster of servers
are updated once per
other rpc traffic takes
layer of hierarchy to
we call the properties
of hierarchy to the
call the properties framework
smr tms is blocked
the receipt of packets
tms is blocked by
rpc traffic takes precedence
is blocked by contention
in the size of
hierarchy to the architecture
the size of the
updated once per second
size of the dependency
the interface requires that
of the dependency lists
blocked by contention much
each acting as an
by contention much earlier
traffic takes precedence over
contention much earlier than
receipt of packets compared
much earlier than acid
interface requires that the
takes precedence over a
requires that the fact
precedence over a prefetch
that the fact type
of packets compared to
which is limited to
the fact type for
we believe the required
fact type for a
over a prefetch rpc
type for a par
packets compared to the
the goal is to
which burdens the gc
goal is to offer
rain due to its
acting as an individual
due to its longer
believe the required changes
is to offer strong
compared to the coolstreaming
continue to poll publishers
to its longer certification
ing the text editor
the required changes would
the text editor executable
to offer strong forms
required changes would be
offer strong forms of
to poll publishers to
strong forms of reliability
as an individual proxy
poll publishers to receive
the second and potentially
changes would be relatively
its longer certification time
forms of reliability that
to the coolstreaming protocol
publishers to receive facts
second and potentially more
would be relatively minor
to receive facts they
and potentially more significant
we briefly review here
receive facts they have
of reliability that can
facts they have ticular
reliability that can be
they have ticular topic
potentially more significant overhead
have ticular topic is
in a more recent
more significant overhead is
a more recent work
that can be customized
significant overhead is the
can be customized for
ticular topic is totally
be customized for special
as shown in table
customized for special needs
traffic would be distributed
overhead is the effect
topic is totally ordered
briefly review here work
would be distributed over
review here work related
is the effect on
here work related to
be distributed over such
the effect on cache
work related to acidrain
distributed over such a
it is worth noting
related to acidrain s
and those facts will
to acidrain s certification
effect on cache hit
acidrain s certification protocol
those facts will missed
on cache hit ratio
based approaches are shown
speed and scalability are
approaches are shown to
over such a rack
cache hit ratio due
and only one tion
and scalability are only
are shown to present
only one tion such
one approach for certification
one tion such as
hit ratio due to
all this is invisible
ratio due to evictions
is worth noting that
epidemic analytical model one
such a rack by
approach for certification is
tion such as the
for certification is to
scalability are only elements
this is invisible to
such as the operating
shown to present better
worth noting that the
to present better performance
a rack by partitioning
present better performance over
certification is to use
better performance over tree
is to use a
due to evictions and
to use a single
analytical model one benefit
noting that the memory
live streaming with utilities
are only elements of
rack by partitioning the
only elements of a
as the operating system
to evictions and hence
use a single highly
the operating system s
that the memory usages
operating system s database
elements of a broader
by partitioning the address
of a broader story
model one benefit of
available service that orders
is invisible to the
service that orders all
invisible to the core
that orders all transactions
previous papers have considered
partitioning the address space
papers have considered a
the memory usages reported
system s database of
memory usages reported here
to the core application
developers will need different
the core application be
will need different solutions
the address space of
have considered a variety
evictions and hence the
s database of installed
and hence the database
orders all transactions in
hence the database load
core application be delivered
need different solutions for
considered a variety of
different solutions for different
usages reported here are
solutions for different purposes
one benefit of using
all transactions in the
application be delivered in
transactions in the system
address space of the
database of installed software
reported here are averages
benefit of using gossip
a variety of possible
be delivered in order
of using gossip in
space of the remote
of installed software prefetch
using gossip in the
of the remote data
installed software prefetch is
by offering a flexible
software prefetch is made
since cache load is
gossip in the ssa
an architecture for scalable
the remote data center
in the ssa is
offering a flexible yet
prefetch is made at
and the peak values
architecture for scalable and
is made at a
remote data center and
the ssa is that
any data can be
a flexible yet structured
data can be made
flexible yet structured component
can be made to
for scalable and fault
yet structured component mashup
data center and routing
structured component mashup environment
cache load is significantly
center and routing different
the peak values are
made at a time
peak values are typically
variety of possible mechanisms
load is significantly larger
of possible mechanisms to
is significantly larger than
possible mechanisms to encourage
live objects makes it
mechanisms to encourage node
and routing different segments
to encourage node contribution
a transaction commits if
routing different segments of
this is more a
significantly larger than database
but can be managed
larger than database load
objects makes it possible
transaction commits if and
different segments of the
commits if and only
segments of the space
if and only if
makes it possible to
and only if it
it possible to create
can be managed through
possible to create applications
is more a matter
ssa is that we
is a framework proposed
of the space through
is that we can
to create applications that
more a matter of
create applications that mix
orders of magnitude for
applications that mix hosted
the space through distinct
that mix hosted with
that we can use
mix hosted with p
a matter of implementapackages
be managed through the
of magnitude for facebook
a framework proposed to
space through distinct maelstrom
framework proposed to enforce
we can use analytical
proposed to enforce download
only if it has
can use analytical methods
if it has no
through distinct maelstrom appliance
and that can adapt
to enforce download rate
that can adapt their
use analytical methods to
can adapt their behavior
the nodes on our
analytical methods to predict
nodes on our cluster
enforce download rate limitations
on our cluster only
it has no conflicts
our cluster only have
managed through the contally
methods to predict the
specified dependency information tion
download rate limitations on
dependency information tion convenience
rate limitations on p
to achieve desired properties
information tion convenience than
distinct maelstrom appliance pairs
has no conflicts with
through the contally ordered
no conflicts with previous
to predict the behavior
conflicts with previous committed
the contally ordered by
predict the behavior of
p media streaming systems
tion convenience than a
even a minor deterioration
achieve desired properties in
with previous committed transactions
contally ordered by tagging
the behavior of a
convenience than a design
ordered by tagging it
desired properties in a
by tagging it with
properties in a way
a minor deterioration in
in a way matched
behavior of a cluster
the protocol relies on
tagging it with a
than a design decision
a way matched to
minor deterioration in hit
way matched to the
protocol relies on a
matched to the environment
we plan to experiment
relies on a set
complementing our experimental work
plan to experiment with
on a set of
other work has shown
to experiment with such
work has shown can
deterioration in hit ratio
has shown can be
experiment with such configurations
shown can be used
it with a sequence
in hit ratio can
with a sequence number
a set of trusted
transaction rate is high
a basic result of
hit ratio can yield
set of trusted nodes
basic result of epidemic
the benefits initiating multiple
of trusted nodes that
scalability of qsm and
such a global service
benefits initiating multiple concurrent
a global service becomes
which would also permit
initiating multiple concurrent prefetches
of qsm and jgroups
ratio can yield a
multiple concurrent prefetches from
global service becomes a
memory footprint is significant
concurrent prefetches from differany
result of epidemic theory
can yield a prohibitive
prefetches from differany of
of epidemic theory states
service becomes a bottleneck
would also permit us
epidemic theory states that
the hope is that
trusted nodes that store
hope is that fact
from differany of these
throughput for various group
also permit us to
for various group sizes
yield a prohibitive load
nodes that store information
differany of these techniques
our system has no
permit us to explore
of these techniques could
theory states that simple
based ipc will simplify
system has no such
a prohibitive load on
has no such bottleneck
us to explore fault
prohibitive load on the
states that simple epidemics
load on the backend
that store information on
on the backend database
ipc will simplify disbut
these techniques could be
that simple epidemics eventually
will simplify disbut often
techniques could be used
simple epidemics eventually infect
simplify disbut often times
could be used to
store information on the
disbut often times facts
the peak footprint approaches
epidemics eventually infect the
be used to derive
prior work the idea
used to derive hints
information on the data
often times facts such
on the data downloaded
if a maelstrom blade
times facts such as
work the idea of
to derive hints for
the idea of integrating
the data downloaded by
idea of integrating web
a maelstrom blade fails
of integrating web services
facts such as ballots
integrating web services with
derive hints for use
web services with peer
hints for use ent
eventually infect the entire
for use ent servers
such as ballots are
c shows the experiment
and the system is
serialized all transactions when
the system is close
data downloaded by each
system is close to
shows the experiment results
is close to swapping
all transactions when they
as ballots are totally
peer platforms is certainly
infect the entire population
ballots are totally ortributed
downloaded by each node
platforms is certainly not
are totally ortributed programming
each data point is
by each node receiving
transactions when they enter
totally ortributed programming and
the entire population with
data point is the
each node receiving data
is certainly not new
when they enter the
and to support load
they enter the system
point is the result
enter the system to
is the result of
the system to achieve
entire population with probability
system to achieve a
ortributed programming and make
to achieve a deterministic
the result of a
nodes only send an
result of a single
programming and make it
only send an object
balancing schemes that might
mfs does not currently
of a single run
achieve a deterministic order
and make it easier
send an object after
schemes that might vary
does not currently make
make it easier to
an object after consulting
moreover starting with a
it easier to reason
we vary the dependency
that might vary the
not currently make use
vary the dependency list
despite nondeterministic operations the
easier to reason dered
starting with a single
to reason dered already
might vary the ip
with a single infected
the dependency list size
nondeterministic operations the transactions
object after consulting the
operations the transactions take
groups are enough to
a single infected site
are enough to trigger
currently make use of
enough to trigger signs
single infected site this
dependency list size and
vary the ip address
after consulting the trusted
list size and for
the ip address space
consulting the trusted nodes
size and for each
ip address space partitioning
the trusted nodes to
infected site this is
address space partitioning dynamically
they consider only stored
make use of timeouts
given a stream of
use of timeouts by
to trigger signs of
trusted nodes to verify
trigger signs of instability
space partitioning dynamically to
consider only stored procedures
and for each value
a stream of facts
of timeouts by the
stream of facts on
nodes to verify if
timeouts by the mfs
for each value run
by the mfs prefetching
token roundtrip times start
the mfs prefetching subsystem
partitioning dynamically to spread
which enable this approach
to verify if the
site this is achieved
verify if the nodes
of facts on some
this is achieved in
dynamically to spread the
our evaluation uses hand
if the nodes requesting
roundtrip times start to
the nodes requesting the
times start to grow
each value run the
whereas we address long
to spread the encoding
we address long running
is achieved in expected
address long running transactions
value run the experiment
achieved in expected time
spread the encoding load
run the experiment for
as we have noted
thus delaying message cleanup
we have noted earlier
nodes requesting the stream
in expected time proportional
requesting the stream are
the encoding load over
the stream are not
facts on some topic
stream are not overrequesting
expected time proportional to
are not overrequesting data
the experiment for the
but it could easily
time proportional to the
long running transactions and
proportional to the log
experiment for the two
running transactions and use
encoding load over multiple
it could easily to
transactions and use prediction
for the two workloads
and use prediction to
load over multiple machines
it is targeted to
to the log of
and increasing memory overhead
about safety and liveness
the two workloads and
use prediction to infer
could easily to exspecified
prediction to infer an
the log of the
two workloads and measure
is targeted to systems
easily to exspecified dependency
to infer an order
to exspecified dependency information
workloads and measure the
targeted to systems where
and measure the average
the argument for this
measure the average values
to systems where nodes
the average values of
argument for this is
average values of these
systems where nodes upload
values of these metrics
which is inaccurate in
for this is only
log of the population
this is only the
is inaccurate in some
where nodes upload full
of the population size
nodes upload full media
inaccurate in some tended
upload full media objects
is only the highest
full media objects from
although the process is
in some tended to
the process is fairly
media objects from each
process is fairly unpredictable
transactions are also serialized
some tended to abandon
are also serialized by
objects from each other
most recent fact need
tended to abandon a
we present the implementation
to abandon a prefetching
cache is able to
abandon a prefetching attempt
we see spikes and
and not for live
see spikes and anomalies
present the implementation and
is able to reduce
a prefetching attempt that
able to reduce inconsistencies
recent fact need be
to reduce inconsistencies significantly
the implementation and performance
prefetching attempt that does
also serialized by a
attempt that does not
serialized by a central
the protocol roughly falls
streaming systems where all
implementation and performance of
systems where all nodes
that does not complete
we can easily recognize
does not complete cases
can easily recognize a
for the retailer workload
easily recognize a super
and performance of a
where all nodes are
by a central service
all nodes are interested
rather than reimplementing an
linear trend starting at
a single dependency reduces
fact need be delivered
single dependency reduces inconsistencies
nodes are interested in
than reimplementing an existing
protocol roughly falls under
reimplementing an existing hint
and then scheduled according
performance of a single
need be delivered that
dependency reduces inconsistencies to
are interested in receiving
be delivered that the
roughly falls under the
delivered that the paradigm
trend starting at around
interested in receiving the
generation in a timely
in receiving the exact
in a timely manner
that the paradigm allows
then scheduled according to
falls under the category
scheduled according to this
the paradigm allows the
receiving the exact same
under the category of
the exact same data
paradigm allows the programmer
exact same data in
the category of a
same data in close
of their original value
category of a push
allows the programmer to
according to this global
data in close to
to this global order
the programmer to clearly
we focus on the
programmer to clearly eventually
in close to real
two dependencies reduce inconsistencies
close to real time
the kernel implementation is
focus on the performance
dependencies reduce inconsistencies to
at around this point
kernel implementation is a
rain avoids a central
while older facts can
avoids a central service
implementation is a module
on the performance of
and the exact formula
we also start to
is a module for
older facts can be
a module for linux
facts can be dropped
the existing work falls
also start to see
existing work falls roughly
the exact formula for
the performance of mfs
start to see occasional
work falls roughly into
of their original value
consider fairness issues in
to see occasional bursts
fairness issues in the
performance of mfs with
issues in the context
exact formula for it
in the context of
see occasional bursts of
the context of tree
of mfs with prefetchthe
also specify transitions and
targets a different problem
falls roughly into two
and three to less
roughly into two categories
formula for it can
mfs with prefetchthe main
specify transitions and under
with prefetchthe main complexity
three to less than
transitions and under which
occasional bursts of packet
the first line of
and under which conditions
bursts of packet losses
prefetchthe main complexity in
for it can be
main complexity in implementing
under which conditions they
complexity in implementing the
where it embraces non
which conditions they di
it can be expressed
conditions they di erent
can be expressed as
they di erent from
first line of research
di erent from pub
determinism and separates execution
line of research is
in implementing the prefetching
of research is focused
the authors present mechanisms
research is focused on
be expressed as log
is focused on the
often roughly correlated across
focused on the use
authors present mechanisms that
on the use of
for the social network
the use of peer
roughly correlated across receivers
implementing the prefetching subing
present mechanisms that rank
and separates execution from
the social network workload
separates execution from verification
if no more facts
mechanisms that rank peers
with hooks into the
that rank peers according
no more facts are
rank peers according to
such events trigger bursty
the result is somewhat
more facts are enabled
using a deliberately simple
peers according to their
hooks into the kernel
according to their level
result is somewhat analogous
to their level of
a deliberately simple hint
their level of cooperation
into the kernel packet
deliberately simple hint mechanism
is somewhat analogous to
events trigger bursty recovery
level of cooperation with
trigger bursty recovery overloads
of cooperation with the
as a basis for
cooperation with the system
somewhat analogous to our
facts are enabled without
analogous to our separation
simple hint mechanism for
to our separation of
are enabled without having
hint mechanism for the
a basis for scalable
enabled without having to
the kernel packet filter
our separation of optimistic
of the inconsistencies remain
separation of optimistic ordering
basis for scalable web
of optimistic ordering and
for scalable web service
mechanism for the purposes
scalable web service discovery
without having to worry
optimistic ordering and conservative
one of their techniques
ordering and conservative certification
having to worry much
for the purposes system
in both workloads there
of their techniques involves
the second line of
both workloads there is
their techniques involves the
second line of research
workloads there is no
techniques involves the reconstruction
line of research concentrates
there is no visible
involves the reconstruction of
of research concentrates on
the purposes system lies
make it easier to
research concentrates on the
number of messages pending
is no visible effect
for large values of
no visible effect on
large values of n
visible effect on cache
concentrates on the use
effect on cache hit
of messages pending ack
on cache hit ratio
purposes system lies in
messages pending ack and
the reconstruction of trees
pending ack and token
to worry much about
ack and token roundtrip
system lies in handling
worry much about how
reconstruction of trees as
maelstrom proxies work in
of trees as a
and token roundtrip time
proxies work in pairs
token roundtrip time as
and hence no increased
roundtrip time as a
much about how are
it easier to create
on the use of
easier to create a
lies in handling a
to create a practical
hence no increased access
create a practical predictor
about how are published
trees as a way
the use of replication
where n the number
use of replication protocols
time as a function
n the number of
certification scalability to evaluate
one on each side
the number of sites
no increased access rate
of replication protocols at
as a function of
replication protocols at the
a function of the
protocols at the web
function of the number
at the web service
of the number of
increased access rate at
how are published but
access rate at the
scalability to evaluate the
are published but some
to evaluate the scalability
number of sites participating
published but some process
the number of groups
of sites participating in
but some process later
in handling a demand
some process later subscribes
evaluate the scalability of
the web service backend
the scalability of acid
rate at the database
sites participating in the
on each side of
participating in the epidemic
as a way of
each side of the
it these conditions are
in the epidemic spread
side of the long
a way of punishing
handling a demand fetch
way of punishing opportunistic
web service backend to
the reduction in inconsistency
service backend to achieve
rain s certification mechanism
backend to achieve fault
memory usage grows with
of punishing opportunistic nodes
usage grows with the
of the long haul
grows with the number
a compulsory fetch to
with the number of
these conditions are discovered
compulsory fetch to of
let pi be the
fetch to of evaluation
the number of groups
we avoid prediction and
the long haul link
avoid prediction and measure
pi be the probability
most of their mechanisms
reduction in inconsistency ratio
prediction and measure the
be the probability that
in inconsistency ratio is
beyond a certain threshold
of their mechanisms require
inconsistency ratio is significantly
and measure the maximal
will eventually receive the
ratio is significantly better
dependencies between files are
the system is increasingly
their mechanisms require peers
system is increasingly unstable
each proxy acts both
mechanisms require peers to
eventually receive the most
p platforms such as
is significantly better for
proxy acts both as
measure the maximal commit
significantly better for the
require peers to keep
receive the most recent
platforms such as jxta
between files are conveyed
the most recent fact
acts both as an
the maximal commit rate
better for the next
maximal commit rate it
such as jxta are
for the next we
files are conveyed using
as jxta are treated
the next we compared
are conveyed using a
commit rate it can
next we compared our
peers to keep track
both as an ingress
to keep track of
the probability that a
as an ingress and
conveyed using a service
time spent in the
using a service a
spent in the clr
assuming both publisher and
keep track of their
jxta are treated not
probability that a site
are treated not as
rate it can accommodate
that a site remains
a service a cache
in the clr code
service a cache miss
track of their parents
an ingress and egress
we compared our technique
treated not as means
ingress and egress router
compared our technique with
both publisher and subscriber
of their parents and
publisher and subscriber are
a site remains susceptible
and subscriber are correct
our technique with a
it can accommodate with
for a file which
can accommodate with an
and egress router at
accommodate with an increasing
their parents and children
with an increasing number
technique with a simple
throughput decreases with the
not as means of
decreases with the number
an increasing number of
as means of collaboration
egress router at the
means of collaboration or
a file which is
of collaboration or media
parents and children s
collaboration or media carrying
router at the same
and children s behavior
with a simple approach
file which is already
at the same time
which is already being
not touched by the
or media carrying live
the same time since
with the number of
a simple approach in
these semantics are similar
simple approach in which
touched by the epidemic
approach in which we
media carrying live content
the number of groups
same time since they
is already being prefetched
semantics are similar to
increasing number of shards
are similar to the
in which we limited
similar to the anti
studied the effect of
but rather as a
after the ith round
time since they handle
which we limited the
the effect of different
we limited the life
since they handle duplex
limited the life span
the ith round of
which is a list
entropy style of gossip
is a list of
they handle duplex traffic
a list of file
ith round of the
list of file identifiers
style of gossip protocols
of file identifiers for
writes of objects chosen
rather as a supporting
handle duplex traffic in
as a supporting infrastructure
effect of different types
duplex traffic in the
of objects chosen uniformly
of different types of
a supporting infrastructure at
objects chosen uniformly at
different types of incentives
supporting infrastructure at the
traffic in the following
infrastructure at the data
file identifiers for the
all groups have the
identifiers for the related
groups have the same
for the related files
but the underlying implementation
in the following manner
here inconsistencies are not
chosen uniformly at random
inconsistencies are not detected
uniformly at random from
have the same subscribers
at the data center
the underlying implementation can
the data center backend
types of incentives on
at random from a
this conflict arises very
random from a small
underlying implementation can be
but their probability of
the egress router captures
conflict arises very frequently
from a small set
of incentives on the
round of the protocol
incentives on the chainsaw
egress router captures ip
on the chainsaw protocol
a small set of
our work is focused
implementation can be anything
their probability of being
router captures ip packets
work is focused on
probability of being witnessed
is focused on blending
a site remains susceptible
particularly when an appliit
site remains susceptible after
captures ip packets and
there is also a
remains susceptible after the
ip packets and creates
susceptible after the i
focused on blending the
packets and creates redundant
on blending the content
when an appliit is
blending the content available
of being witnessed is
the content available through
an appliit is assumed
the key insight is
being witnessed is reduced
key insight is that
content available through p
th round if it
witnessed is reduced by
round if it was
appliit is assumed that
if it was susceptible
is also a control
is assumed that after
insight is that all
also a control interface
it was susceptible after
and creates redundant fec
is reduced by having
creates redundant fec packets
p and web service
reduced by having the
and web service protocols
a control interface that
tat and some variations
assumed that after one
is that all these
was susceptible after the
that after one file
that all these effects
control interface that controls
after one file in
by having the cache
neither technology is subordinate
acidrain against two approaches
technology is subordinate with
the authors propose an
is subordinate with respect
interface that controls routing
having the cache evict
all these effects originate
susceptible after the ith
one file in the
more details in section
subordinate with respect to
that controls routing of
the cache evict entries
these effects originate at
after the ith cycle
the original ip packets
authors propose an algorithm
file in the group
original ip packets are
in the group has
effects originate at the
cache evict entries after
originate at the sender
with respect to the
at the sender node
evict entries after a
the group has been
the ith cycle and
entries after a certain
group has been accessed
controls routing of facts
after a certain period
ip packets are routed
a certain period even
smr tms is two
certain period even if
respect to the other
which is more loaded
cation performs a fast
ith cycle and it
packets are routed through
propose an algorithm that
period even if the
technologies that use peer
is more loaded and
even if the database
phase commit with reliable
are routed through unaltered
commit with reliable coordinators
an algorithm that sets
routed through unaltered as
more loaded and less
performs a fast linear
loaded and less responsive
routing of facts for
a fast linear scan
algorithm that sets up
fast linear scan of
if the database did
linear scan of files
of facts for a
scan of files in
through unaltered as they
of files in a
cycle and it is
unaltered as they would
and it is not
facts for a particular
that sets up local
for a particular topic
files in a file
peer protocols to support
in a file group
detailed analysis of the
as they would have
analysis of the captured
global log is an
the database did not
of the captured network
sets up local markets
it is not contacted
the captured network traffic
is not contacted by
they would have been
not contacted by any
captured network traffic shows
an it becomes advantageous
up local markets at
log is an architecture
local markets at every
contacted by any infectious
protocols to support live
is an architecture where
would have been originally
it becomes advantageous to
database did not indicate
paxos acceptors subscribe to
becomes advantageous to prefetch
by any infectious site
network traffic shows that
to support live and
an architecture where tms
support live and interactive
markets at every node
architecture where tms submit
advantageous to prefetch the
acceptors subscribe to ballots
traffic shows that the
did not indicate they
live and interactive content
any infectious site in
not indicate they are
and interactive content have
to prefetch the remainder
indicate they are invalid
where neighbors compete for
infectious site in the
subscribe to ballots and
shows that the multicast
interactive content have existed
that the multicast stream
content have existed earlier
prefetch the remainder of
site in the i
neighbors compete for the
to ballots and to
compete for the node
where tms submit all
for the node s
the redundant packets are
the remainder of the
ballots and to new
remainder of the files
redundant packets are then
tms submit all transactions
the node s upload
the multicast stream in
packets are then forwarded
multicast stream in all
of the files in
stream in all cases
relation that we obtain
are then forwarded to
node s upload capacity
and to new proposals
submit all transactions to
to new proposals from
in all cases looks
all transactions to a
that we obtain is
new proposals from leaders
transactions to a single
the files in efficient
all cases looks basically
nodes favor neighbors who
files in efficient implementation
favor neighbors who contribute
then forwarded to the
cases looks basically identical
when the leader publishes
to a single global
in efficient implementation of
a single global log
an excellent example of
single global log and
excellent example of such
global log and check
example of such technology
efficient implementation of prefetching
of such technology is
compares the efficacy of
the leader publishes one
the efficacy of the
neighbors who contribute more
efficacy of the abort
log and check conflicts
forwarded to the remote
and check conflicts on
implementation of prefetching requires
to the remote ingress
leader publishes one of
the remote ingress router
such technology is the
evict and retry policies
technology is the croquet
of prefetching requires that
and hence we cannot
prefetching requires that the
check conflicts on that
requires that the demand
conflicts on that single
and retry policies with
publishes one of these
hence we cannot attribute
remote ingress router via
we cannot attribute token
since infection starts with
ingress router via a
cannot attribute token latency
with nodes classified as
attribute token latency or
infection starts with one
retry policies with the
router via a udp
policies with the amazon
nodes classified as fast
with the amazon and
token latency or losses
the amazon and orkut
latency or losses to
via a udp channel
or losses to the
classified as fast or
losses to the increased
on that single log
to the increased volume
in which the entire
the increased volume of
it is transmitted to
as fast or slow
is transmitted to all
fast or slow nodes
the ingress router captures
increased volume of traffic
amazon and orkut workloads
starts with one site
which the entire state
transmitted to all subscribers
the entire state of
ingress router captures and
for any randomly chosen
entire state of a
throughput spikes or longer
router captures and stores
the results indicate that
state of a virtual
captures and stores ip
in these experiments we
results indicate that the
any randomly chosen site
these experiments we use
and stores ip packets
and the underlying communication
d world is stored
indicate that the proposed
spikes or longer bursts
experiments we use dependency
that the proposed algorithm
stores ip packets coming
world is stored in
the proposed algorithm improves
is stored in a
randomly chosen site p
we use dependency lists
the underlying communication layer
use dependency lists of
or longer bursts of
underlying communication layer will
longer bursts of data
has lower latency for
ip packets coming from
stored in a peer
dependency lists of length
proposed algorithm improves the
communication layer will continue
lower latency for a
algorithm improves the performance
as a function of
packets coming from the
latency for a given
improves the performance of
the sender spends more
layer will continue retransmission
sender spends more time
for a given throughput
peer fashion and updated
coming from the direction
fashion and updated using
the performance of the
a function of the
will continue retransmission until
function of the rate
spends more time transmitting
of the rate of
from the direction of
and updated using a
just as with the
updated using a two
the rate of gossip
as with the synthetic
more time transmitting at
with the synthetic workload
pc since its faster
continue retransmission until either
since its faster certification
time transmitting at lower
retransmission until either acknowledged
transmitting at lower rates
the direction of the
its faster certification reduces
direction of the egress
we can predict the
until either acknowledged or
evicting conflicting transactions is
other work in this
faster certification reduces contention
work in this direction
can predict the delay
performance of the system
but doesn t produce
either acknowledged or another
doesn t produce any
of the egress router
acknowledged or another fact
predict the delay before
of the system when
the delay before a
conflicting transactions is an
delay before a typical
it has no bottleneck
or another fact renders
has no bottleneck as
in this direction includes
the system when the
before a typical process
transactions is an effective
system when the total
another fact renders it
is an effective way
upon receipt of a
an effective way of
t produce any faster
no bottleneck as with
effective way of invalidating
fact renders it obsolete
a typical process that
receipt of a redundant
when the total upload
of a redundant packet
bottleneck as with a
way of invalidating stale
as with a global
produce any faster data
the total upload capacity
typical process that has
with a global log
total upload capacity is
any faster data bursts
process that has been
upload capacity is not
faster data bursts than
an ip packet is
data bursts than those
of invalidating stale objects
bursts than those we
none of these systems
ip packet is recovered
of these systems supports
capacity is not enough
packet is recovered if
that has less overhead
is not enough to
is recovered if there
than those we observe
invalidating stale objects that
those we observe with
these systems supports the
stale objects that might
systems supports the sorts
not enough to supply
supports the sorts of
we observe with smaller
the sorts of componentized
recovered if there is
that has been disrupted
objects that might cause
enough to supply all
has less overhead in
to supply all the
layered architectures that we
has been disrupted by
that might cause problems
observe with smaller numbers
less overhead in small
with smaller numbers of
architectures that we have
smaller numbers of groups
been disrupted by a
might cause problems for
if there is an
cause problems for future
supply all the nodes
problems for future transactions
disrupted by a failure
overhead in small scale
there is an opportunity
that we have advocated
by a failure will
we have advocated here
a failure will learn
is an opportunity to
failure will learn about
will learn about inconsistency
learn about inconsistency introduced
the effects are more
an opportunity to do
effects are more pronounced
the types of peer
about inconsistency introduced by
are more pronounced for
inconsistency introduced by the
opportunity to do so
more pronounced for the
introduced by the failure
while the parameters we
pronounced for the well
the parameters we choose
by the failure and
the failure and can
parameters we choose are
receiver performance indicators such
failure and can initiate
we choose are arbitrary
performance indicators such as
and can initiate repair
peer protocols these systems
indicators such as delays
protocols these systems can
such as delays in
these systems can leverage
streaming system where nodes
as delays in firing
redundant packets that can
delays in firing timer
the trends are robust
packets that can be
if the model predicts
and the types of
the model predicts that
that can be used
model predicts that for
with the amazon workload
can be used at
the types of a
system where nodes choose
choosing other parameters would
in firing timer event
where nodes choose their
firing timer event or
predicts that for a
other parameters would provide
be used at a
types of a traditional
nodes choose their neighbors
of a traditional hosted
timer event or cpu
choose their neighbors based
event or cpu utilization
used at a later
that for a given
abort is able to
at a later time
parameters would provide similar
a later time are
would provide similar trends
for a given gossip
a traditional hosted content
is able to detect
traditional hosted content they
or cpu utilization don
hosted content they can
a given gossip rate
cpu utilization don t
content they can blend
later time are stored
their neighbors based on
a broken chain should
they can blend with
neighbors based on their
can blend with their
utilization don t show
blend with their p
based on their history
broken chain should be
don t show any
on their history of
t show any noticeable
chain should be repaired
their history of interaction
show any noticeable trend
should be repaired within
if the redundant packet
the redundant packet is
of the inconsistent transactions
redundant packet is useless
packet is useless it
nodes are placed in
is useless it is
are placed in the
useless it is immediately
one can anticipate that
placed in the system
it is immediately discarded
all roads lead back
our platform is designed
roads lead back to
in the system according
can anticipate that the
whereas with the less
anticipate that the disruption
platform is designed from
that the disruption associated
lead back to the
the disruption associated with
is designed from ground
disruption associated with a
the system according to
designed from ground up
upon recovery the ip
system according to their
back to the sender
recovery the ip packet
according to their current
clustered orkut workload it
from ground up with
associated with a failure
the ip packet is
to their current trading
and the main thing
ground up with extensibility
with a failure should
the main thing going
up with extensibility in
their current trading performances
orkut workload it only
ip packet is sent
a failure should be
main thing going on
failure should be limited
with extensibility in mind
should be limited to
thing going on in
be limited to the
workload it only detects
packet is sent through
going on in the
limited to the maximum
is sent through a
on in the sender
encouraging nodes to contribute
sent through a raw
every part of it
nodes to contribute more
in the sender is
to the maximum number
through a raw socket
part of it can
to contribute more and
of it can be
the maximum number of
a raw socket to
the sender is that
it can be replaced
sender is that it
can be replaced and
raw socket to its
be replaced and customized
contribute more and therefore
socket to its intended
maximum number of updates
is that it has
number of updates that
phase commit for transaction
to its intended destination
commit for transaction certification
of updates that would
that it has a
and different components within
it has a steadily
in both cases evict
updates that would be
different components within a
both cases evict reduces
has a steadily growing
that would be sent
cases evict reduces uncommittable
would be sent to
components within a single
be sent to a
a steadily growing memory
the downside of these
steadily growing memory footprint
using fec requires that
evict reduces uncommittable transactions
downside of these approaches
within a single mashup
reduces uncommittable transactions considerably
sent to a given
a single mashup application
to a given subservice
more and therefore be
we also looked at
of these approaches compared
a given subservice during
and therefore be closer
these approaches compared to
also looked at token
approaches compared to acid
looked at token round
fec requires that each
relative to their value
single mashup application can
to their value with
therefore be closer to
their value with abort
requires that each data
mashup application can leverage
given subservice during a
be closer to the
rain is that they
closer to the source
the distribution of token
is that they require
that each data packet
application can leverage different
distribution of token roundtrip
can leverage different transport
each data packet have
of token roundtrip times
that they require a
leverage different transport protocols
data packet have a
they require a coordinator
token roundtrip times for
require a coordinator that
roundtrip times for different
if we know how
packet have a unique
a coordinator that performs
we know how large
prior work on typed
have a unique identifier
is a more recent
work on typed component
coordinator that performs transactions
a more recent live
on typed component architectures
that performs transactions to
times for different numbers
a unique identifier that
for different numbers of
know how large the
performs transactions to be
typed component architectures includes
with the amazon workload
component architectures includes a
how large the typical
unique identifier that the
transactions to be highly
different numbers of groups
identifier that the receiver
streaming approach that tolerates
architectures includes a tremendous
that the receiver can
approach that tolerates the
to be highly available
numbers of groups shows
large the typical update
the amazon workload and
includes a tremendous variety
the receiver can use
a tremendous variety of
the typical update is
of groups shows an
receiver can use to
tremendous variety of programming
that tolerates the existence
variety of programming languages
groups shows an increase
tolerates the existence of
shows an increase of
and we know the
can use to keep
of programming languages and
this requires another consensus
use to keep track
an increase of the
we know the size
programming languages and platforms
the existence of opportunistic
to keep track of
increase of the token
know the size limit
of the token roundtrip
the size limit on
the token roundtrip time
in addition to the
including early languages such
addition to the one
early languages such as
keep track of received
languages such as smalltalk
size limit on data
to the one at
existence of opportunistic and
the one at the
such as smalltalk alongside
of opportunistic and malicious
track of received data
caused almost entirely by
in the amazon workload
one at the shard
limit on data sent
as smalltalk alongside modern
opportunistic and malicious nodes
smalltalk alongside modern component
at the shard itself
on data sent in
of received data packets
data sent in response
sent in response to
retry further reduces this
in response to explicit
received data packets and
response to explicit requests
based environments such as
data packets and to
time is divided into
environments such as java
packets and to identify
we can predict the
further reduces this value
of the tokens that
reduces this value to
the tokens that are
and to identify missing
tokens that are delayed
is divided into rounds
that are delayed the
can predict the amount
to identify missing data
are delayed the most
predict the amount of
identify missing data packets
the amount of time
amount of time that
missing data packets in
of time that will
time that will be
data packets in a
specialized component architectures such
that will be needed
packets in a repair
will be needed to
related work our transaction
in a repair packet
component architectures such figure
be needed to repair
in which each peer
work our transaction ordering
needed to repair the
which each peer communicates
our transaction ordering protocol
to repair the resulting
of its value with
each peer communicates with
repair the resulting data
transaction ordering protocol is
peer communicates with another
the resulting data inconsistency
if we had access
communicates with another peer
ordering protocol is inspired
scalability qsm and jgroups
these capabilities should help
its value with abort
capabilities should help the
with another peer selected
should help the developer
protocol is inspired by
help the developer parameterize
we had access to
the developer parameterize the
which points to disruptive
developer parameterize the cluster
another peer selected using
throughput for various numbers
had access to end
for various numbers of
parameterize the cluster to
various numbers of topics
the cluster to balance
peer selected using a
points to disruptive events
is inspired by a
cluster to balance overhead
selected using a pseudo
r elated w ork
to balance overhead for
inspired by a state
to disruptive events as
elated w ork a
disruptive events as the
balance overhead for gossip
events as the culprit
overhead for gossip against
for gossip against repair
gossip against repair times
against repair times desired
repair times desired by
times desired by the
desired by the application
machine ordering mechanism suggested
rather than a uniform
ordering mechanism suggested by
than a uniform increase
we could have added
mechanism suggested by lamport
a uniform increase of
membership some readers may
could have added a
uniform increase of the
some readers may be
have added a header
readers may be curious
recent years have seen
increase of the token
may be curious about
added a header to
of the token processing
years have seen a
the token processing overhead
be curious about what
for srm and ricochet
a header to each
peers exchange their current
curious about what will
have seen a surge
srm and ricochet with
header to each packet
seen a surge of
exchange their current history
to each packet with
about what will seem
and ricochet with varying
each packet with a
their current history containing
packet with a unique
a surge of progress
we find that these
what will seem to
with a unique sequence
current history containing the
ricochet with varying numbers
but we have generalized
history containing the identifiers
find that these tokens
a unique sequence number
will seem to be
surge of progress in
with varying numbers of
we have generalized the
varying numbers of topics
that these tokens were
seem to be a
of progress in the
containing the identifiers of
have generalized the protocol
these tokens were most
to be a chicken
progress in the development
the identifiers of all
as mit s argus
generalized the protocol to
tokens were most commonly
the protocol to work
were most commonly delayed
mit s argus system
on the one hand
in the development of
protocol to work with
most commonly delayed on
to work with arbitrary
commonly delayed on the
identifiers of all the
we use gossip epidemics
the development of scalable
of all the current
delayed on the sender
development of scalable object
all the current data
work with arbitrary overlapping
use gossip epidemics to
flexible protocol composition stacks
of scalable object stores
protocol composition stacks such
gossip epidemics to propagate
scalable object stores that
the current data they
object stores that support
with arbitrary overlapping par
stores that support transactions
epidemics to propagate information
with many thousands of
to propagate information about
current data they hold
composition stacks such as
propagate information about membership
many thousands of groups
stacks such as bast
information about membership changes
references the approaches of
some systems such as
the approaches of mdcc
yet the gossip protocol
the gossip protocol uses
the average time to
as basis for the
gossip protocol uses membership
average time to travel
protocol uses membership information
basis for the next
uses membership information to
we intercept traffic transparently
for the next exchanges
membership information to select
intercept traffic transparently and
information to select gossip
to select gossip peers
traffic transparently and need
transparently and need to
our solution starts with
solution starts with approximate
nodes also perform a
starts with approximate membership
with approximate membership information
also perform a phase
time to travel by
route it without modification
extracted from a group
to travel by one
it without modification or
perform a phase of
without modification or addition
oriented architectures such as
travel by one hop
architectures such as juni
a phase of optimistic
from a group management
by one hop from
phase of optimistic push
a group management service
one hop from sender
group management service component
management service component that
hop from sender to
service component that list
component that list the
from sender to receiver
that list the nodes
list the nodes in
sender to receiver or
the nodes in the
nodes in the cluster
to receiver or receiver
in the cluster and
forwarding useful updates to
receiver or receiver to
the cluster and the
useful updates to pseudo
or receiver to sender
cluster and the rough
receiver to sender can
and the rough mapping
to sender can grow
we identify ip packets
the rough mapping of
sender can grow to
rough mapping of services
has been used in
identify ip packets by
can grow to nearly
randomly picked peers with
ip packets by a
been used in the
mapping of services to
packets by a tuple
picked peers with no
are close to acid
used in the context
of services to those
by a tuple consisting
peers with no guarantee
services to those nodes
in the context of
a tuple consisting of
rain s certification mechanism
the context of integrating
with no guarantee of
and then refines this
tuple consisting of the
context of integrating service
then refines this with
no guarantee of useful
refines this with incremental
consisting of the source
this with incremental updates
guarantee of useful return
of the source and
a different concern relates
the source and destination
different concern relates to
concern relates to behavior
as compared to an
relates to behavior when
source and destination ip
compared to an average
rain separates the om
to behavior when membership
and destination ip address
separates the om abstraction
behavior when membership information
discussion of component integration
the om abstraction from
when membership information is
ms per hop from
om abstraction from the
per hop from receiver
of component integration systems
membership information is perceived
abstraction from the highly
component integration systems and
information is perceived differently
hop from receiver to
integration systems and their
from receiver to receiver
is perceived differently at
systems and their relation
conclusion we propose and
and their relation to
perceived differently at different
size of the ip
we propose and evaluate
of the ip header
their relation to live
differently at different nodes
propose and evaluate a
the ip header plus
and evaluate a scalable
although such a condition
relation to live objects
such a condition may
ip header plus data
evaluate a scalable auditing
a condition may arise
condition may arise during
leasing mechanism and fast
may arise during transitional
arise during transitional periods
mechanism and fast recovery
these quickly resolve as
the overloaded sender occasionally
export novel consistency definitions
quickly resolve as additional
overloaded sender occasionally releases
resolve as additional rounds
based technique for enforcing
sender occasionally releases the
novel consistency definitions that
technique for enforcing fairness
as additional rounds of
consistency definitions that allow
occasionally releases the tokens
is beyond the scope
releases the tokens with
additional rounds of gossip
the tokens with a
we also address garbage
and a checksum over
beyond the scope of
also address garbage collection
the scope of this
definitions that allow for
tokens with a delay
for enforcing fairness in
a checksum over the
rounds of gossip replace
scope of this paper
that allow for effective
enforcing fairness in a
allow for effective optimizations
fairness in a live
of gossip replace stale
checksum over the ip
gossip replace stale data
more details can be
replace stale data with
over the ip data
which cannot be done
stale data with more
details can be found
the ip data payload
can be found in
several recent systems implement
data with more accurate
cannot be done independently
recent systems implement full
be done independently at
done independently at the
systems implement full fledged
independently at the logs
implement full fledged atomicity
the checksum over the
our approach employs local
we have never observed
full fledged atomicity while
approach employs local auditors
have never observed a
fledged atomicity while preserving
checksum over the payload
never observed a membership
atomicity while preserving the
observed a membership inconsistency
over the payload is
a membership inconsistency that
employs local auditors that
the value of the
while preserving the system
value of the delay
the payload is necessary
of the delay grows
membership inconsistency that persisted
preserving the system s
local auditors that execute
the delay grows with
payload is necessary since
delay grows with the
the system s scalability
grows with the number
auditors that execute on
with the number of
much relevant prior work
the number of groups
system s scalability with
is necessary since the
that execute on all
inconsistency that persisted for
relevant prior work consists
s scalability with a
prior work consists of
prefetch no prefetch prefetch
work consists of the
execute on all nodes
consists of the scripting
scalability with a wide
that persisted for longer
no prefetch prefetch no
necessary since the ip
prefetch prefetch no prefetch
of the scripting languages
persisted for longer than
with a wide variety
on all nodes in
a wide variety of
the scripting languages mentioned
for longer than a
since the ip identification
all nodes in a
the ip identification field
longer than a few
scripting languages mentioned in
wide variety of workloads
languages mentioned in the
nodes in a streaming
than a few hundred
ip identification field is
our old culprit is
mentioned in the discussion
old culprit is back
in the discussion above
identification field is only
a few hundred milliseconds
in a streaming session
google s spanner utilizes
the ssa is quite
s spanner utilizes accurate
ssa is quite tolerant
is quite tolerant of
spanner utilizes accurate clock
quite tolerant of short
prefetch no prefetch relative
related costs at the
utilizes accurate clock synchronization
no prefetch relative speedup
costs at the sender
they are responsible for
customuserserviceapp heartbeatmonitor gossiper subserviceprocess
prefetch relative speedup relative
bits long and a
are responsible for collecting
long and a single
relative speedup relative speedup
responsible for collecting auditable
and a single pair
heartbeatmonitor gossiper subserviceprocess chainlink
a single pair of
gossiper subserviceprocess chainlink subservicecontrol
for collecting auditable information
single pair of end
subserviceprocess chainlink subservicecontrol nonblockingtransport
increasing the number of
collecting auditable information about
the number of groups
number of groups slows
auditable information about other
of groups slows the
groups slows the sender
information about other neighbors
our belief is that
about other neighbors data
hosts communicating at high
belief is that even
other neighbors data exchanges
by balakrishnan et al
is that even though
and this cascades to
the component stack of
communicating at high speeds
that even though these
component stack of one
this cascades to create
even though these languages
stack of one subservice
at high speeds will
cascades to create all
of one subservice process
though these languages are
to create all sorts
a new paradigm for
and for verifying that
new paradigm for building
is constructed on top
for verifying that neighbors
create all sorts of
failure and recovery process
verifying that neighbors upload
and recovery process failure
these languages are intended
recovery process failure detection
high speeds will use
that neighbors upload more
all sorts of downstream
speeds will use the
process failure detection is
languages are intended for
paradigm for building scalable
will use the same
neighbors upload more data
sorts of downstream problems
failure detection is accomplished
upload more data than
of downstream problems that
use the same identifier
downstream problems that can
detection is accomplished by
are intended for fairly
for building scalable distributed
intended for fairly general
the same identifier for
is accomplished by means
problems that can destabilize
more data than a
that can destabilize the
building scalable distributed systems
data than a specified
accomplished by means of
constructed on top of
same identifier for different
on top of the
for fairly general use
by means of two
than a specified threshold
can destabilize the system
top of the scalable
destabilize the system as
means of two mechanisms
of the scalable corfu
the system as a
identifier for different data
they have evolved to
system as a whole
for different data packets
have evolved to focus
detecting fifo channels that
this threshold is defined
different data packets within
evolved to focus on
fifo channels that break
data packets within a
threshold is defined by
to focus on minibrowser
packets within a fairly
focus on minibrowser situations
in our case they
within a fairly short
is defined by dedicated
a fairly short interval
on minibrowser situations in
our case they are
discussion the experiments just
prefetch no prefetch relative
fairly short interval unless
no prefetch relative speedup
minibrowser situations in which
prefetch relative speedup relative
the experiments just reported
case they are tcp
experiments just reported make
defined by dedicated global
just reported make it
relative speedup relative speedup
reported make it clear
they are tcp channels
situations in which the
are tcp channels with
by dedicated global auditors
tcp channels with low
short interval unless the
channels with low value
in which the application
with low value for
interval unless the checksum
which the application lives
low value for the
unless the checksum is
value for the so
make it clear that
for the so timeout
the application lives within
the checksum is added
application lives within a
the so timeout property
it clear that the
checksum is added to
clear that the performance
which periodically sample the
prefetch no prefetch relative
lives within a dedicated
no prefetch relative speedup
is added to differentiate
uses an architecture similar
periodically sample the state
added to differentiate between
limiting factor in the
based heartbeat detection mechanism
sample the state of
factor in the qsm
an architecture similar to
in the qsm system
the state of the
the qsm system is
once a process is
within a dedicated browser
a process is deceased
architecture similar to our
to differentiate between them
similar to our certification
state of the system
utilize a large set
the information is propagated
qsm system is latency
information is propagated within
to our certification mechanism
is propagated within the
a large set of
a dedicated browser frame
large set of independent
propagated within the group
of the system to
and that in addition
prefetch no prefetch relative
set of independent logs
the system to determine
but addresses minitransactions that
interacts directly with the
no prefetch relative speedup
directly with the user
that in addition to
system to determine if
in addition to protocol
within the group in
prefetch relative speedup bad
to determine if the
relative speedup bad groups
the group in two
addresses minitransactions that are
and cannot be mixed
addition to protocol factors
minitransactions that are submitted
to protocol factors such
unique identifiers result in
protocol factors such as
cannot be mixed with
identifiers result in garbled
group in two ways
factors such as the
determine if the overall
be mixed with content
result in garbled recovery
mixed with content from
if the overall download
with content from other
in garbled recovery by
content from other sources
the overall download rate
from other sources in
such as the length
overall download rate is
other sources in a
garbled recovery by maelstrom
the process that has
as the length of
that are submitted as
the length of token
download rate is compromised
process that has detected
sources in a layered
that has detected the
length of token rings
has detected the membership
are submitted as a
detected the membership change
rate is compromised by
in a layered fashion
submitted as a whole
is compromised by the
the membership change feeds
an event which will
membership change feeds the
latency is strongly influenced
change feeds the event
compromised by the presence
is strongly influenced by
event which will be
strongly influenced by the
live objects can support
influenced by the memory
which will be caught
by the memory footprint
by the presence of
the memory footprint of
with no attempt to
memory footprint of the
the presence of opportunistic
footprint of the system
will be caught by
presence of opportunistic nodes
objects can support minibrowsers
no attempt to order
can support minibrowsers as
feeds the event description
attempt to order potentially
be caught by higher
support minibrowsers as objects
the event description into
to order potentially conflicting
caught by higher level
event description into the
order potentially conflicting transactions
by higher level checksums
when we built the
global auditing determines the
description into the chain
use lock chains and
into the chain itself
higher level checksums designed
lock chains and assume
auditing determines the minimum
chains and assume transactions
but we ve argued
this is delivered in
level checksums designed to
we ve argued that
determines the minimum threshold
we address full transactions
and assume transactions are
is delivered in chain
we built the system
delivered in chain order
checksums designed to deal
built the system it
the minimum threshold for
the system it was
in chain order to
ve argued that by
designed to deal with
assume transactions are known
where the clients sequentially
to deal with tranmission
system it was obvious
the clients sequentially access
argued that by modeling
transactions are known in
minimum threshold for uploads
are known in advance
deal with tranmission errors
it was obvious that
clients sequentially access objects
with tranmission errors on
chain order to every
was obvious that minimizing
tranmission errors on commodity
obvious that minimizing latency
order to every non
that by modeling hosted
these methods all scale
and works with local
that minimizing latency would
sequentially access objects before
errors on commodity networks
by modeling hosted content
access objects before ending
on commodity networks and
modeling hosted content at
minimizing latency would be
objects before ending a
hosted content at a
works with local auditing
content at a lower
commodity networks and hence
with local auditing to
faulty process and where
networks and hence does
process and where necessary
local auditing to punish
and hence does not
before ending a transaction
hence does not have
at a lower level
latency would be important
auditing to punish nodes
methods all scale well
chain repair procedure is
does not have significant
all scale well and
to punish nodes that
repair procedure is undertaken
and use prediction to
punish nodes that do
scale well and in
a lower level as
not have significant consequences
this motivated several of
use prediction to order
motivated several of the
well and in many
several of the design
have significant consequences unless
and in many cases
prediction to order them
the same detector process
in many cases allow
of the design decisions
nodes that do not
significant consequences unless it
that do not upload
consequences unless it occurs
same detector process starts
many cases allow databases
the design decisions discussed
to order them in
design decisions discussed in
order them in advance
decisions discussed in section
detector process starts up
cases allow databases to
lower level as components
do not upload enough
level as components that
process starts up a
not upload enough data
starts up a backup
allow databases to accept
as components that interact
unless it occurs frequently
components that interact via
up a backup gossip
but the repeated linkage
a backup gossip notification
databases to accept loads
backup gossip notification stream
we believe our techniques
to accept loads similar
that interact via events
believe our techniques could
accept loads similar to
this is a fast
we study the efficiency
loads similar to those
interact via events and
study the efficiency of
via events and focusing
the repeated linkage of
the kernel version of
our techniques could be
is a fast dying
kernel version of maelstrom
a fast dying epidemic
similar to those handled
version of maelstrom can
to those handled by
techniques could be used
of maelstrom can generate
repeated linkage of latency
the efficiency of our
linkage of latency and
events and focusing on
efficiency of our auditing
could be used to
and focusing on the
those handled by non
focusing on the multi
of latency and oscillatory
maelstrom can generate up
latency and oscillatory throughputs
of our auditing approach
it spreads rapidly but
be used to reduce
our auditing approach through
and oscillatory throughputs to
spreads rapidly but also
auditing approach through simulation
rapidly but also dies
layered style of mashups
can generate up to
style of mashups as
used to reduce abort
generate up to a
oscillatory throughputs to memory
of mashups as opposed
throughputs to memory was
mashups as opposed to
to memory was a
but also dies out
memory was a surprise
also dies out rapidly
and show that it
to reduce abort rates
they are not expected
up to a gigabit
the fifo channels are
we expected a much
show that it is
are not expected to
as opposed to the
reduce abort rates of
opposed to the standard
expected a much smaller
to the standard tiled
a much smaller impact
the standard tiled model
fifo channels are rebuilt
abort rates of systems
channels are rebuilt appropriately
not expected to disrupt
are rebuilt appropriately by
that it is able
expected to disrupt the
to a gigabit per
to disrupt the prevailing
it is able to
a gigabit per second
rebuilt appropriately by the
rates of systems using
appropriately by the processes
disrupt the prevailing two
by the processes that
gigabit per second of
the processes that identify
we can summarize our
processes that identify themselves
is able to maintain
per second of data
of systems using sinfonia
second of data and
that identify themselves to
able to maintain the
can summarize our design
systems using sinfonia or
summarize our design insights
identify themselves to be
our design insights as
themselves to be affected
to maintain the throughput
conclusions to build ambitious
using sinfonia or a
maintain the throughput of
sinfonia or a similar
to be affected by
or a similar certification
to build ambitious collaboration
a similar certification mechanism
of data and fec
the throughput of the
data and fec traffic
note that we are
design insights as follows
build ambitious collaboration application
be affected by the
throughput of the streaming
that we are addressing
affected by the membership
of the streaming system
by the membership change
we are addressing the
the web services community
with the input data
web services community will
are addressing the problem
and the group converges
the streaming system even
addressing the problem of
services community will need
the problem of read
community will need ways
the group converges to
will need ways to
group converges to a
the input data rate
converges to a stable
streaming system even in
input data rate depending
need ways to combine
system even in the
minimize the memory footprint
only incoherent caches that
even in the presence
to a stable configuration
incoherent caches that respond
in the presence of
data rate depending on
caches that respond to
rate depending on the
the presence of a
depending on the encoding
that respond to queries
presence of a large
update sources can use
respond to queries without
of a large number
to queries without access
content from multiple sources
queries without access to
sources can use this
on the encoding rate
can use this update
we expected that the
use this update to
a large number of
this update to reconnect
without access to the
update to reconnect to
these include hosted sources
to reconnect to a
large number of opportunistic
reconnect to a new
access to the backend
to a new head
include hosted sources that
a new head of
expected that the primary
to the backend database
that the primary cost
new head of any
hosted sources that run
head of any chain
number of opportunistic nodes
sources that run in
we were able to
of any chain that
the primary cost of
any chain that may
were able to saturate
chain that may have
that run in data
that may have lost
primary cost of managed
may have lost its
previous work on coherent
have lost its previous
able to saturate the
work on coherent caches
run in data centers
to saturate the outgoing
relative speedup of workloads
saturate the outgoing card
speedup of workloads with
in data centers and
of workloads with prefetching
lost its previous head
the outgoing card at
cost of managed memory
data centers and support
of managed memory would
centers and support web
its previous head as
and support web services
previous head as a
managed memory would be
support web services interfaces
outgoing card at rates
head as a consequence
these graphs show the
memory would be associated
graphs show the speedup
as a consequence of
card at rates as
but also direct peer
show the speedup gained
a consequence of the
would be associated with
at rates as high
be associated with garbage
consequence of the crash
the speedup gained by
rates as high as
associated with garbage collection
speedup gained by adding
gained by adding prefetching
peer protocols capable of
by adding prefetching for
protocols capable of transporting
adding prefetching for a
capable of transporting audio
prefetching for a range
if a process wants
for a range of
a process wants to
a range of bandwidth
process wants to join
range of bandwidth values
all costs associated with
costs associated with managed
it starts by sending
associated with managed memory
starts by sending a
relative to the time
by sending a request
whiteboard data and other
sending a request to
with managed memory rise
data and other content
a request to a
to the time taken
request to a random
and other content at
to a random member
managed memory rise in
other content at high
a random member of
content at high data
random member of the
memory rise in the
at high data rates
member of the group
rise in the amount
the time taken with
in the amount of
time taken with a
the amount of allocated
taken with a bandwidth
amount of allocated memory
with a bandwidth of
the group member will
group member will commence
member will commence a
at least in the
will commence a membership
least in the windows
commence a membership change
with cpu overload occurring
a membership change protocol
in the windows clr
a further need is
cpu overload occurring at
further need is to
membership change protocol as
need is to allow
change protocol as described
s and no prefetching
protocol as described above
is to allow disconnected
to allow disconnected collaboration
a case for end
again once all the
where a test comprises
once all the nodes
a test comprises two
all the nodes receive
test comprises two separate
the nodes receive the
case for end system
comprises two separate processes
nodes receive the membership
for end system multicast
receive the membership event
the membership event and
back to data centers
membership event and update
event and update their
and update their view
only the speedup for
the speedup for the
speedup for the foreground
for the foreground process
our review of the
the foreground process is
foreground process is shown
whereas traditional multicast systems
review of the performance
traditional multicast systems accept
implementation details the framework
of the performance of
details the framework was
multicast systems accept messages
where each incoming data
the performance of enterprise
fetch wait for the
the framework was implemented
wait for the prefetch
framework was implemented using
performance of enterprise service
was implemented using the
supports transactions using locks
for the prefetch to
each incoming data packet
the prefetch to complete
implemented using the java
of enterprise service bus
transactions using locks or
systems accept messages whenever
enterprise service bus eventing
using the java language
using locks or communication
service bus eventing solutions
accept messages whenever the
locks or communication with
the java language and
messages whenever the application
or communication with the
or that the prefetch
bus eventing solutions in
that the prefetch be
java language and its
the prefetch be aborted
language and its non
communication with the database
incoming data packet had
highly available storage for
eventing solutions in the
data packet had to
with the database on
solutions in the standard
packet had to be
issuing a fetch rpc
had to be xored
whenever the application layer
the database on each
the application layer or
available storage for interactive
application layer or the
the system design was
in the standard hosted
system design was strongly
a fetch rpc at
storage for interactive services
layer or the multicast
database on each transaction
or the multicast protocols
the standard hosted web
the multicast protocols produce
design was strongly influenced
multicast protocols produce it
fetch rpc at the
standard hosted web services
was strongly influenced by
rpc at the same
strongly influenced by prior
hosted web services model
these techniques are not
at the same time
web services model made
the same time as
qsm uses an upcall
same time as a
services model made it
time as a prefetch
techniques are not applicable
buffering requirements at the
influenced by prior work
model made it clear
by prior work on
as a prefetch is
prior work on highperformance
made it clear that
are not applicable in
a prefetch is in
it clear that hosted
prefetch is in progress
work on highperformance services
is in progress needlessly
on highperformance services platforms
often we can delay
not applicable in our
we can delay generating
requirements at the receive
can delay generating a
notably welsh s seda
applicable in our scenario
in progress needlessly wastes
clear that hosted event
progress needlessly wastes bandwidth
welsh s seda architecture
delay generating a message
that hosted event channels
generating a message until
hosted event channels won
a message until the
event channels won t
since it retrieves the
message until the last
channels won t have
it retrieves the same
until the last minute
won t have the
retrieves the same file
t have the scalability
the same file from
incoming data packets are
same file from the
have the scalability and
data packets are buffered
and we can also
file from the server
packets are buffered so
from the server twice
the scalability and latency
are buffered so that
components are highly autonomous
we can also avoid
buffered so that they
scalability and latency properties
can also avoid situations
and latency properties needed
the same could be
so that they can
same could be true
latency properties needed by
could be true if
that they can be
be true if we
properties needed by many
true if we opt
they can be used
also avoid situations in
there are only four
needed by many applications
are only four distinct
can be used in
only four distinct control
avoid situations in which
four distinct control threads
be used in conjunction
distinct control threads in
situations in which data
control threads in the
used in conjunction with
if we opt for
in which data piles
we opt for aborting
in conjunction with xors
opt for aborting prefetches
which data piles up
conjunction with xors to
threads in the component
data piles up on
in the component stack
p alternatives often achieve
piles up on behalf
the component stack of
alternatives often achieve far
component stack of a
up on behalf of
often achieve far better
with xors to recover
stack of a process
since an aborted prefetch
on behalf of an
achieve far better scalability
behalf of an aggressive
an aborted prefetch could
of an aggressive sender
xors to recover missing
aborted prefetch could be
to recover missing data
prefetch could be very
recover missing data packets
could be very close
be very close to
very close to completion
namely one for the
one for the non
for the non blocking
the non blocking transport
mfs therefore makes the
a transactional record manager
they also have security
transactional record manager for
also have security advantages
record manager for shared
therefore makes the demand
manager for shared flash
makes the demand fetch
limit buffering and caching
the demand fetch wait
any received xor that
the tcp chain and
the data center doesn
tcp chain and for
received xor that is
demand fetch wait for
data center doesn t
fetch wait for the
xor that is missing
chain and for the
most existing multicast protocols
that is missing more
wait for the prefetch
existing multicast protocols buffer
is missing more than
and for the heartbeat
multicast protocols buffer data
for the heartbeat component
missing more than one
protocols buffer data at
center doesn t get
more than one data
doesn t get a
buffer data at many
t get a chance
than one data packet
get a chance to
data at many layers
one data packet is
a chance to see
the ssa is roughly
but also raises the
at many layers and
data packet is stored
many layers and cache
also raises the priority
layers and cache data
packet is stored temporarily
raises the priority of
and cache data rather
the priority of the
cache data rather casually
priority of the prefetch
data rather casually for
of the prefetch rpc
rather casually for recovery
the prefetch rpc to
in case all but
prefetch rpc to that
casually for recovery purposes
reliable multicasting with an
case all but one
rpc to that of
the live objects platform
to that of a
multicasting with an overlay
that of a regular
live objects platform can
with an overlay network
this turns out to
all but one of
turns out to be
objects platform can seamlessly
out to be extremely
but one of the
platform can seamlessly support
of a regular fetch
one of the missing
a regular fetch operation
can seamlessly support applications
to be extremely costly
of the missing packets
seamlessly support applications that
be extremely costly in
the missing packets are
extremely costly in a
to prevent a priority
missing packets are received
prevent a priority inversion
costly in a managed
packets are received later
support applications that require
in a managed setting
applications that require a
a managed setting and
that require a mixture
this requires an additional
require a mixture of
requires an additional raise
are received later or
managed setting and must
th symposium on operating
a mixture of data
received later or recovered
mixture of data sources
symposium on operating systems
setting and must be
priority rpc to the
on operating systems design
rpc to the server
later or recovered through
operating systems design and
including both hosted and
and must be avoided
systems design and implementation
both hosted and direct
or recovered through other
which results in more
hosted and direct p
must be avoided whenever
recovered through other xors
be avoided whenever possible
results in more overhead
in more overhead than
more overhead than the
overhead than the case
than the case where
the case where a
allowing the recovery of
case where a demand
the recovery of the
where a demand fetch
a middleware for highperformance
recovery of the remaining
middleware for highperformance transaction
a demand fetch occurs
of the remaining missing
demand fetch occurs without
further benefits include an
fetch occurs without a
for highperformance transaction processing
occurs without a fetch
benefits include an easy
the remaining missing packet
include an easy to
remaining missing packet from
cumulative distribution of the
missing packet from this
an easy to use
packet from this xor
easy to use drag
distribution of the multicast
of the multicast rates
on the other hand
the multicast rates for
in practice we stored
practice we stored data
we stored data and
drop programming style that
stored data and xor
programming style that yields
data and xor packets
style that yields applications
and xor packets in
that yields applications represented
xor packets in double
yields applications represented as
packets in double buffered
applications represented as xml
the fetch can frequently
in double buffered red
represented as xml files
fetch can frequently make
double buffered red black
can frequently make use
buffered red black trees
frequently make use of
red black trees for
make use of the
use of the data
which can be shared
of the data already
can be shared as
the data already transferred
token roundtrip times for
be shared as files
data already transferred and
shared as files or
already transferred and so
as files or even
transferred and so still
files or even via
and so still results
or even via email
so still results in
still results in a
results in a faster
in a faster response
a faster response to
faster response to the
response to the application
users that open such
that open such files
as we have explained
open such files find
such files find themselves
files find themselves immersed
find themselves immersed in
the implementation of the
themselves immersed in a
implementation of the prefetching
immersed in a mediarich
of the prefetching subsystem
in a mediarich collaborative
the prefetching subsystem is
prefetching subsystem is not
a mediarich collaborative environment
subsystem is not sophisticated
mediarich collaborative environment that
collaborative environment that also
environment that also offers
that also offers strong
while it will reach
also offers strong reliability
intervals between the subsequent
entries this occupies around
between the subsequent tokens
it will reach an
will reach an equilibrium
reach an equilibrium if
an equilibrium if the
equilibrium if the total
if the total size
the total size of
total size of the
boosting dbms performance by
size of the file
dbms performance by parallelising
of the file groups
performance by parallelising write
the file groups in
in the near future
by parallelising write transactions
file groups in the
groups in the prefetch
in the prefetch list
the prefetch list is
prefetch list is less
list is less than
is less than the
less than the cache
than the cache size
the repair bins in
repair bins in the
bins in the layered
there is no mechanism
in the layered interleaving
is no mechanism to
the layered interleaving scheme
no mechanism to prevent
layered interleaving scheme store
mechanism to prevent the
interleaving scheme store incrementally
to prevent the prefetching
scheme store incrementally computed
prevent the prefetching subsystem
store incrementally computed xors
the prefetching subsystem running
incrementally computed xors and
prefetching subsystem running ahead
computed xors and lists
subsystem running ahead of
xors and lists of
running ahead of actual
and lists of data
ahead of actual file
clear messages out of
of actual file accesses
messages out of the
actual file accesses and
lists of data packet
file accesses and evicting
most important of all
accesses and evicting useful
out of the system
and evicting useful files
of data packet headers
evicting useful files from
of the system quickly
useful files from the
files from the cache
prediction of transaction behavior
of transaction behavior has
without the data packet
transaction behavior has the
or evicting files which
data paths should have
evicting files which it
the data packet payloads
paths should have rapid
live objects are real
should have rapid data
files which it has
behavior has the potential
which it has prefetched
have rapid data movement
it has prefetched but
has the potential to
has prefetched but have
rapid data movement as
prefetched but have not
highbandwidth content distribution in
but have not yet
resulting in low storage
content distribution in cooperative
the potential to significantly
in low storage overheads
data movement as a
distribution in cooperative environments
have not yet been
potential to significantly decrease
not yet been referenced
the platform is available
to significantly decrease abort
movement as a key
yet been referenced by
as a key goal
been referenced by the
platform is available for
low storage overheads for
significantly decrease abort rates
referenced by the user
decrease abort rates in
storage overheads for each
abort rates in large
is available for free
rates in large scale
overheads for each layer
in large scale transactional
available for free download
techniques for preventing this
for each layer that
large scale transactional systems
for free download from
scale transactional systems with
each layer that rise
transactional systems with high
free download from cornell
for preventing this behaviour
layer that rise linearly
preventing this behaviour have
systems with high contention
th acm symposium on
we ve already mentioned
that rise linearly with
this behaviour have been
acm symposium on operating
rise linearly with the
behaviour have been discussed
symposium on operating systems
ve already mentioned that
have been discussed elsewhere
already mentioned that data
on operating systems principles
mentioned that data paths
that data paths should
rain we employ prediction
data paths should clear
paths should clear messages
we employ prediction to
should clear messages quickly
employ prediction to obtain
prediction to obtain soft
to obtain soft reservations
but there are other
obtain soft reservations and
there are other important
linearly with the value
are other important forms
with the value of
other important forms of
soft reservations and implement
the value of the
important forms of delay
reservations and implement atomic
value of the interleave
and implement atomic transactions
implement atomic transactions while
atomic transactions while requiring
transactions while requiring high
the memory footprint for
while requiring high availability
memory footprint for a
most situations in which
footprint for a longrunning
situations in which qsm
requiring high availability only
in which qsm developed
for a longrunning proxy
which qsm developed convoy
high availability only in
a longrunning proxy was
availability only in a
in order to characterise
longrunning proxy was around
only in a single
order to characterise the
like behavior or oscillatory
in a single tier
to characterise the effect
behavior or oscillatory throughput
a single tier of
characterise the effect of
or oscillatory throughput can
single tier of independent
oscillatory throughput can be
tier of independent logs
mb in our experiments
throughput can be traced
the effect of adding
can be traced to
effect of adding prefetching
this allows for low
be traced to design
traced to design decisions
to design decisions that
design decisions that caused
decisions that caused scheduling
other performance enhancing roles
that caused scheduling jitter
performance enhancing roles maelstrom
caused scheduling jitter or
we ran a set
enhancing roles maelstrom appliances
scheduling jitter or allowed
db access rate normed
roles maelstrom appliances can
ran a set of
rain s operations never
jitter or allowed some
a set of eight
or allowed some form
s operations never depend
allowed some form of
maelstrom appliances can optionally
some form of priority
set of eight microbenchmarks
appliances can optionally aggregate
form of priority inversion
operations never depend on
of priority inversion to
can optionally aggregate small
never depend on a
priority inversion to occur
optionally aggregate small subkilobyte
depend on a single
aggregate small subkilobyte packets
on a single machine
small subkilobyte packets from
a single machine by
the experimental setup was
single machine by allowing
lateral error correction for
experimental setup was the
delaying a crucial message
db access rate normed
a crucial message behind
subkilobyte packets from different
crucial message behind a
setup was the same
machine by allowing fast
error correction for time
by allowing fast recovery
message behind a less
packets from different flows
behind a less important
was the same as
allowing fast recovery from
a less important one
the same as in
fast recovery from failures
from different flows into
recovery from failures and
same as in the
from failures and performance
implications included the following
as in the priority
failures and performance hiccups
different flows into larger
in the priority tests
flows into larger ones
into larger ones for
larger ones for better
ones for better communication
for better communication efficiency
better communication efficiency over
communication efficiency over the
efficiency over the long
though this time mfs
event handlers should be
this time mfs was
handlers should be short
eliminating trees from overlay
time mfs was configured
trees from overlay multicast
mfs was configured to
was configured to run
configured to run with
to run with asynchronous
in split flow control
run with asynchronous writeback
split flow control mode
th international workshop on
we struggled to make
international workshop on peer
flow control mode they
struggled to make the
control mode they can
mode they can perform
to make the overall
they can perform send
make the overall behavior
and rpc with priorities
the overall behavior of
overall behavior of the
side buffering of in
behavior of the system
of the system as
the system as predictable
flight data for multi
system as predictable as
and only prefetching was
as predictable as possible
only prefetching was either
predictable as possible not
gigabyte flows that exceed
prefetching was either enabled
as possible not a
flows that exceed the
possible not a trivial
that exceed the sending
was either enabled or
exceed the sending end
not a trivial task
either enabled or disabled
a trivial task in
hit ratio hit ratio
benchmarking cloud serving systems
trivial task in configurations
host s buffering capacity
cloud serving systems with
task in configurations where
serving systems with ycsb
in configurations where hundreds
configurations where hundreds of
where hundreds of processes
the tests were run
hundreds of processes might
tests were run at
of processes might be
maelstrom appliances can act
processes might be multicasting
were run at a
might be multicasting in
appliances can act as
run at a range
can act as multicast
be multicasting in thousands
at a range of
multicasting in thousands of
act as multicast forwarding
in thousands of overlapping
a range of bandwidth
as multicast forwarding nodes
thousands of overlapping groups
range of bandwidth values
appliances send multicast packets
by keeping event handlers
send multicast packets to
keeping event handlers short
multicast packets to each
event handlers short and
packets to each other
handlers short and predictable
to each other across
as in the previous
short and predictable and
each other across the
and predictable and eliminating
other across the long
predictable and eliminating the
in the previous section
and eliminating the need
eliminating the need for
the need for locking
and use ip multicast
each microbenchmark consists of
product a nity social
microbenchmark consists of one
a nity social network
we obtained a more
consists of one or
obtained a more predictable
a more predictable system
of one or two
more predictable system and
one or two processes
predictable system and were
or two processes accessing
system and were able
two processes accessing files
and were able to
to spread them within
were able to eliminate
spread them within their
able to eliminate multithreading
them within their data
within their data centers
with the associated context
the associated context switching
with some or all
associated context switching and
we plan to build
context switching and locking
some or all of
plan to build on
switching and locking overheads
to build on our
or all of the
appliances can take on
build on our simulation
can take on other
on our simulation results
take on other existing
our simulation results by
as seen by the
simulation results by implementing
all of the files
driven overlay network for
of the files forming
overlay network for efficient
results by implementing acid
the files forming file
seen by the entire
network for efficient live
on other existing roles
for efficient live media
other existing roles in
rain and exploring the
files forming file groups
here we encounter a
by the entire chain
we encounter a tension
and exploring the different
encounter a tension between
existing roles in the
a tension between two
exploring the different aspects
tension between two goals
roles in the data
efficient live media streaming
in the data center
the different aspects of
different aspects of its
aspects of its performance
from a memory footprint
of its performance in
a memory footprint perspective
its performance in realistic
performance in realistic settings
acting as security and
as security and vpn
security and vpn gateways
write test is the
and vpn gateways and
one might prefer not
of particular interest are
might prefer not to
vpn gateways and as
test is the same
gateways and as conventional
prefer not to pull
is the same as
and as conventional performance
the same as in
th conference on computer
same as in section
conference on computer communications
not to pull in
as conventional performance enhancing
to pull in a
on computer communications and
pull in a message
conventional performance enhancing proxies
in a message until
computer communications and networking
a message until qsm
different network topologies with
message until qsm can
network topologies with a
until qsm can process
topologies with a single
qsm can process it
with a single datacenter
a single datacenter and
single datacenter and with
datacenter and with multiple
and with multiple datacenters
but in a datacenter
with a file group
in a datacenter or
a file group added
a datacenter or cluster
file group added for
exploiting gossip for self
group added for the
added for the read
most message loss occurs
for the read data
message loss occurs in
loss occurs in the
occurs in the operating
in the operating system
management in scalable event
behavior in face of
in scalable event notification
in face of high
not on the network
scalable event notification systems
face of high contention
experimental results and validation
the compile mfs test
e valuation we evaluated
hence message loss rates
valuation we evaluated maelstrom
message loss rates soar
we evaluated maelstrom on
loss rates soar if
compile mfs test has
rain should prove efficient
evaluated maelstrom on the
rates soar if we
mfs test has six
maelstrom on the emulab
soar if we leave
on the emulab testbed
if we leave messages
test has six file
the emulab testbed at
we leave messages on
has six file groups
where its overhead may
leave messages on input
its overhead may be
emulab testbed at utah
messages on input sockets
six file groups for
overhead may be wasteful
on input sockets for
the tests reported here
input sockets for long
file groups for the
tests reported here employ
reported here employ a
here employ a hard
groups for the main
for the main directories
the main directories of
main directories of the
defense against intrusion in
the ssa is a
against intrusion in a
directories of the system
ssa is a work
behavior in error prone
control the event processing
in error prone scenarios
intrusion in a live
the event processing order
is a work in
for all the experiments
in a live streaming
a work in progress
a live streaming multicast
live streaming multicast system
we used a dumbbell
used a dumbbell topology
fledged system will use
a dumbbell topology of
system will use a
dumbbell topology of two
performance with predictors of
will use a software
with predictors of different
use a software partitioning
predictors of different qualities
semantic integration of web
topology of two clusters
integration of web services
mb of data in
of web services and
a software partitioning mechanism
of two clusters of
software partitioning mechanism based
th ieee international conference
partitioning mechanism based on
product a nity social
two clusters of nodes
web services and peer
clusters of nodes connected
ieee international conference on
of nodes connected via
a nity social network
nodes connected via routing
mechanism based on the
connected via routing nodes
based on the web
and the imposition of
via routing nodes with
on the web services
routing nodes with a
the web services request
the imposition of an
nodes with a high
web services request invocation
international conference on peer
imposition of an internal
services request invocation model
of an internal event
an internal event processing
internal event processing prioritization
latency link in between
peer networks to achieve
although extracting the partitioning
link in between them
extracting the partitioning key
networks to achieve fault
the partitioning key from
small delays add up
partitioning key from incoming
delays add up in
key from incoming requests
add up in large
from incoming requests will
forming a single file
designed to emulate the
up in large systems
a single file group
to emulate the setup
incoming requests will impose
emulate the setup in
requests will impose some
the setup in figure
will impose some overhead
lightweight elasticity in shared
tight control over event
elasticity in shared storage
control over event processing
in shared storage databases
we do not expect
over event processing largely
do not expect performance
shared storage databases for
event processing largely eliminated
not expect performance of
storage databases for the
expect performance of the
processing largely eliminated convoy
and ran the proxy
performance of the full
databases for the cloud
largely eliminated convoy effects
for the cloud using
ran the proxy code
the cloud using live
eliminated convoy effects and
cloud using live data
fledged system to deviate
the proxy code on
convoy effects and oscillatory
proxy code on the
effects and oscillatory throughput
code on the routers
and oscillatory throughput problems
mb of small files
system to deviate significantly
using live data migration
to deviate significantly from
deviate significantly from what
significantly from what is
from what is reported
what is reported below
act on fresh state
show the performance of
many inefficiencies can be
the performance of the
inefficiencies can be traced
performance of the kernel
can be traced to
of the kernel version
be traced to situations
the kernel version at
traced to situations in
kernel version at gigabit
to situations in which
version at gigabit speeds
situations in which one
flexible protocol composition in
in which one node
protocol composition in bast
which one node takes
one node takes action
the remainder of the
node takes action on
remainder of the graphs
takes action on the
of the graphs show
action on the basis
the graphs show the
on the basis of
graphs show the performance
the basis of stale
show the performance of
basis of stale state
the performance of the
of stale state information
performance of the user
stale state information from
state information from some
information from some other
from some other node
all the files are
space version at slower
the files are in
version at slower speeds
triggering redundant retransmissions or
files are in a
redundant retransmissions or other
are in a single
to emulate the mtu
retransmissions or other overheads
emulate the mtu difference
in a single file
the mtu difference between
th conference on computer
mtu difference between the
a single file group
the pull architecture has
difference between the long
conference on computer communications
pull architecture has the
update injection time against
injection time against delivery
architecture has the secondary
time against delivery time
live migration in shared
has the secondary benefit
against delivery time at
haul link and the
migration in shared nothing
link and the data
in shared nothing databases
delivery time at node
shared nothing databases for
and the data center
nothing databases for elastic
the secondary benefit of
the data center network
databases for elastic cloud
secondary benefit of letting
for elastic cloud platforms
benefit of letting us
of letting us delay
letting us delay the
us delay the preparation
fetch runs as two
delay the preparation of
runs as two process
the preparation of status
preparation of status packets
of status packets until
we set an mtu
status packets until they
set an mtu of
packets until they are
until they are about
limited cache entry ttl
they are about to
cache entry ttl fig
are about to be
about to be transmitted
self organizing live objects
conclusions the premise of
experiments with workloads based
the premise of our
with workloads based on
bytes on the network
premise of our work
on the network connecting
workloads based on a
the network connecting the
of our work is
network connecting the end
based on a web
our work is that
on a web retailer
work is that developers
a web retailer product
is that developers of
web retailer product affinity
hosts to the proxy
that developers of services
to the proxy and
retailer product affinity topology
developers of services intended
the proxy and an
product affinity topology and
proxy and an mtu
of services intended to
and an mtu of
affinity topology and a
services intended to run
topology and a social
intended to run on
and a social network
to run on clustered
a social network topology
run on clustered platforms
social network topology illustrated
on clustered platforms desire
network topology illustrated in
clustered platforms desire the
platforms desire the productivity
desire the productivity and
the productivity and robustness
productivity and robustness benefits
and robustness benefits of
robustness benefits of managed
benefits of managed environments
bytes on the long
which form a file
and need replication tools
form a file group
need replication tools integrated
haul link between proxies
replication tools integrated with
tools integrated with those
integrated with those environments
the only exception is
only exception is figure
building such tools so
compared against the alternative
such tools so posed
against the alternative of
tools so posed challenges
the other does the
the alternative of reducing
so posed challenges to
alternative of reducing cache
posed challenges to us
other does the same
of reducing cache entry
challenges to us as
reducing cache entry time
to us as protocol
where we maintained equal
us as protocol and
we maintained equal mtus
as protocol and system
maintained equal mtus of
protocol and system designers
which were the primary
but without a file
were the primary focus
without a file group
the primary focus of
primary focus of our
focus of our paper
update delay as seen
delay as seen by
as seen by individual
data points are medians
seen by individual processes
a central insight is
bytes on both links
points are medians and
central insight is that
are medians and error
insight is that high
medians and error bars
and error bars bound
simultaneous writeback executes in
error bars bound the
writeback executes in the
performance protocols running in
all the experiments are
executes in the same
the experiments are done
jms performance comparison for
experiments are done with
in the same way
protocols running in managed
performance comparison for publish
running in managed settings
are done with maelstrom
comparison for publish subscribe
done with maelstrom using
in managed settings need
with maelstrom using end
for publish subscribe messaging
managed settings need to
settings need to maintain
need to maintain the
to maintain the smallest
maintain the smallest possible
the smallest possible memory
but the second process
smallest possible memory footprint
fiorano software technologies pvt
the dangers of replication
the second process writes
dangers of replication and
of replication and d
second process writes the
this could work well
process writes the files
could work well if
work well if a
writes the files to
well if a system
if a system has
fast distributed transactions a
the files to the
a system has multiple
distributed transactions a solution
files to the server
system has multiple classes
th symposium on operating
to the server instead
has multiple classes of
symposium on operating systems
the server instead of
on operating systems design
plication of this principle
operating systems design and
server instead of reading
multiple classes of objects
our experiments were conducted
instead of reading them
experiments were conducted using
which illustrates the performance
were conducted using the
systems design and implementation
conducted using the ssa
all clustered but with
qsm achieves scalability and
clustered but with different
using the ssa framework
but with different associated
the ssa framework deployed
illustrates the performance of
ssa framework deployed on
with different associated clustering
framework deployed on a
the performance of split
achieves scalability and stability
performance of split mode
deployed on a tightly
of split mode flow
on a tightly coupled
for partitioned database systems
a tightly coupled homogeneous
the remaining tests investigate
split mode flow control
different associated clustering properties
scalability and stability even
tightly coupled homogeneous cluster
and stability even at
remaining tests investigate the
coupled homogeneous cluster of
stability even at very
even at very high
tests investigate the overhead
at very high loads
investigate the overhead paid
the overhead paid for
an unexpected side effect
the nodes are connected
unexpected side effect of
nodes are connected by
overhead paid for weaknesses
are connected by two
side effect of building
connected by two separate
effect of building qsm
paid for weaknesses in
by two separate high
of building qsm in
two separate high speed
for weaknesses in the
separate high speed ethernet
building qsm in windows
high speed ethernet backbone
show that commodity tcp
qsm in windows was
speed ethernet backbone planes
weaknesses in the prefetching
in windows was that
ip throughput collapses in
in the prefetching algorithm
we experimented with several
throughput collapses in the
windows was that by
collapses in the presence
experimented with several configurations
in the presence of
was that by integrating
the presence of non
that by integrating our
by integrating our system
some placed the control
integrating our system tightly
placed the control traffic
our system tightly with
the control traffic on
system tightly with the
control traffic on a
tightly with the platform
consistent inconsistent aborted ab
traffic on a different
inconsistent aborted ab ev
on a different switched
and that maelstrom successfully
a different switched ethernet
aborted ab ev re
that maelstrom successfully masks
leveraging collaboration of peer
different switched ethernet segment
we created a new
switched ethernet segment while
maelstrom successfully masks loss
ethernet segment while others
created a new kind
segment while others aggregated
successfully masks loss and
while others aggregated both
a new kind of
others aggregated both the
masks loss and prevents
aggregated both the control
ab ev re ab
loss and prevents this
new kind of live
and prevents this collapse
kind of live distributed
both the control traffic
of live distributed objects
the control traffic and
prevents this collapse from
control traffic and the
distributed main memory transaction
peer and web services
main memory transaction processing
traffic and the data
ev re ab ev
and the data traffic
this collapse from occurring
the data traffic on
memory transaction processing system
data traffic on the
abstract data types that
re ab ev re
data types that form
traffic on the same
types that form groups
on the same segment
ab ev re i
ev re i i
re i i tr
i i tr tr
no significant differences were
i tr tr o
significant differences were observed
tr tr o o
tr o o rt
o o rt ct
and that are updated
but this may be
o rt ct rt
this may be because
high bandwidth data dissemination
may be because our
shows the performance of
rt ct rt ct
that are updated using
ct rt ct y
be because our control
rt ct y y
because our control traffic
ct y y amazon
our control traffic consisted
bandwidth data dissemination using
are updated using qsm
data dissemination using an
updated using qsm multicasts
control traffic consisted mainly
the performance of the
y y amazon orkut
performance of the userspace
y amazon orkut fig
dissemination using an overlay
traffic consisted mainly of
using an overlay mesh
of the userspace version
these look natural to
the userspace version on
look natural to the
consisted mainly of fast
natural to the windows
userspace version on a
to the windows user
the efficacy of t
which put little stress
such an object changes
put little stress on
little stress on the
an object changes faster
stress on the communication
object changes faster than
on the communication channels
changes faster than the
cache as a function
faster than the average
as a function of
than the average windows
th acm symposium on
mbps link and figure
the average windows object
in the future we
a function of the
acm symposium on operating
the future we hope
function of the inconsistency
future we hope to
symposium on operating systems
we hope to explore
of the inconsistency handling
on operating systems principles
hope to explore scenarios
but the same basic
to explore scenarios that
the inconsistency handling strategy
the same basic mechanisms
shows the kernel version
explore scenarios that generate
inconsistency handling strategy for
scenarios that generate exceptionally
the kernel version on
that generate exceptionally heavy
same basic mechanisms can
kernel version on a
generate exceptionally heavy control
handling strategy for realistic
basic mechanisms can support
strategy for realistic workloads
exceptionally heavy control traffic
mechanisms can support them
kb files and forming
which would allow us
files and forming its
the experiment in each
and the component integration
experiment in each case
and forming its own
would allow us to
the component integration environment
much work has been
allow us to explore
work has been done
forming its own file
in each case involves
us to explore the
its own file group
based web service composition
has been done on
each case involves running
been done on creating
web service composition with
done on creating consistent
case involves running iperf
on creating consistent caches
to explore the benefits
creating consistent caches for
explore the benefits of
consistent caches for web
the benefits of isolation
caches for web servers
extends seamlessly to encompass
benefits of isolation of
seamlessly to encompass them
on its first iteration
of isolation of that
service composition with jade
isolation of that traffic
verify replication for multi
although a great deal
of that traffic with
a great deal of
that traffic with respect
composition with jade and
great deal of additional
traffic with respect to
deal of additional work
with respect to data
with jade and jxta
respect to data traffic
flows from one node
of additional work is
from one node to
additional work is needed
the workload accesses the
one node to another
in the interest of
workload accesses the first
node to another across
qsm should eventually enable
the interest of brevity
should eventually enable casual
interest of brevity we
accesses the first file
to another across the
eventually enable casual use
another across the long
enable casual use of
of brevity we did
casual use of live
brevity we did not
the first file in
use of live objects
we did not perform
distance link with and
of live objects not
did not perform any
link with and without
not perform any experiments
first file in each
live objects not just
with and without intermediary
file in each directory
and without intermediary maelstrom
objects not just in
perform any experiments to
without intermediary maelstrom proxies
any experiments to evaluate
not just in datacenters
experiments to evaluate the
intermediary maelstrom proxies and
to evaluate the load
just in datacenters but
maelstrom proxies and measuring
evaluate the load balancing
in datacenters but also
proxies and measuring obtained
the load balancing component
datacenters but also on
load balancing component but
and measuring obtained throughput
balancing component but we
but also on desktops
component but we plan
measuring obtained throughput while
also on desktops in
a comparative study of
but we plan to
comparative study of live
we plan to do
on desktops in wan
study of live p
plan to do so
desktops in wan settings
to do so in
obtained throughput while varying
do so in the
throughput while varying loss
so in the future
while varying loss rate
opening the door to
the door to a
door to a new
to a new style
a new style of
left graph on each
all the experiments involved
graph on each figure
the experiments involved a
new style of distributed
experiments involved a single
style of distributed programming
involved a single partitioned
a single partitioned and
single partitioned and replicated
partitioned and replicated service
the current version of
current version of qsm
for ease of exposition
version of qsm is
th conference on computer
of qsm is stable
conference on computer communications
to provoke a large
this service implements a
qsm is stable in
provoke a large amount
service implements a simple
is stable in cluster
a large amount of
implements a simple wall
stable in cluster settings
large amount of useless
in cluster settings and
the error bars on
amount of useless prefetches
based architecture for semanticweb
error bars on the
the service itself maintains
architecture for semanticweb service
service itself maintains the
bars on the graphs
itself maintains the time
for semanticweb service automatic
on the graphs to
semanticweb service automatic composition
has a growing community
the graphs to the
a growing community of
with updates coming from
growing community of users
updates coming from client
graphs to the left
coming from client applications
to the left are
from client applications that
good order and bad
looking to the future
client applications that read
the left are standard
order and bad order
applications that read a
left are standard errors
that read a high
and bad order investigate
we plan to scale
are standard errors of
plan to scale qsm
bad order investigate the
quality clock and send
standard errors of the
to scale qsm into
order investigate the effect
scale qsm into wan
clock and send the
errors of the throughput
qsm into wan settings
of the throughput over
investigate the effect of
and send the current
the throughput over ten
send the current value
the effect of the
to support a wider
throughput over ten runs
support a wider range
a wider range of
effect of the ordered
as processes forward updates
wider range of multicast
of the ordered list
range of multicast reliability
processes forward updates along
the ordered list of
of multicast reliability properties
forward updates along the
using time instead of
ordered list of files
updates along the chain
time instead of timeout
list of files in
instead of timeout for
ip s cache of
of timeout for fault
and to introduce a
of files in a
to introduce a gossip
they will track the
files in a file
s cache of tuning
in a file group
cache of tuning parameters
introduce a gossip infrastructure
will track the clock
of tuning parameters to
a gossip infrastructure that
track the clock themselves
tuning parameters to allow
gossip infrastructure that would
parameters to allow for
infrastructure that would support
to allow for repeatable
that would support configuration
all of our partitioning
would support configuration discovery
of our partitioning scenarios
allow for repeatable results
our partitioning scenarios included
support configuration discovery and
partitioning scenarios included at
preventing dos attacks in
scenarios included at least
configuration discovery and other
dos attacks in peer
included at least four
and higher level objects
discovery and other self
at least four subservices
the clients in the
clients in the experiment
in the experiment are
the experiment are running
and each subservice included
experiment are running tcp
each subservice included between
peer media streaming systems
ip reno on a
reno on a linux
live objects pose a
objects pose a protocol
prefetching evaluation having added
pose a protocol design
evaluation having added prefetching
we expect these to
a protocol design challenge
expect these to be
having added prefetching to
and jong hoon ahnn
these to be typical
added prefetching to mfs
to be typical cases
they give rise to
be typical cases for
programming with live distributed
th annual multimedia computing
with live distributed objects
typical cases for real
give rise to irregular
annual multimedia computing and
rise to irregular patterns
cases for real deployments
to irregular patterns of
for real deployments of
multimedia computing and networking
irregular patterns of overlapping
computing and networking conference
patterns of overlapping multicast
we evaluated whether such
real deployments of the
of overlapping multicast groups
such systems consider only
deployments of the ssa
systems consider only one
evaluated whether such a
consider only one object
only one object at
whether such a straightforward
one object at a
it should be noted
object at a time
such a straightforward algorithm
should be noted that
the maelstrom parameters used
a straightforward algorithm can
maelstrom parameters used are
oriented state aggregation mechanisms
parameters used are r
and only individual read
straightforward algorithm can have
be noted that small
state aggregation mechanisms will
algorithm can have a
aggregation mechanisms will need
only individual read and
mechanisms will need to
individual read and write
will need to be
read and write operations
noted that small subservice
can have a benefit
need to be redesigned
that small subservice sizes
have a benefit for
as they do not
a benefit for some
we have an idea
benefit for some repre
they do not support
have an idea for
do not support a
an idea for solving
not support a transactional
idea for solving this
can result in degenerate
achieving reliability through distributed
result in degenerate behavior
support a transactional interface
in degenerate behavior and
reliability through distributed data
degenerate behavior and are
through distributed data flows
behavior and are not
distributed data flows and
and are not appropriate
order accesses the files
there are few if
are not appropriate configurations
recovery would be performed
not appropriate configurations for
would be performed by
data flows and recursive
are few if any
flows and recursive delegation
accesses the files in
appropriate configurations for the
be performed by selecting
few if any multi
configurations for the ssa
the files in the
performed by selecting a
for the ssa architecture
files in the group
by selecting a subset
in the group in
selecting a subset of
the group in the
a subset of nodes
group in the same
subset of nodes that
these systems generally try
of nodes that form
in the same order
nodes that form a
systems generally try to
that form a clean
generally try to avoid
form a clean overlay
mapping between service processes
try to avoid staleness
between service processes and
the same order as
a clean overlay structure
to avoid staleness through
from paxos to corfu
same order as the
service processes and physical
avoid staleness through techniques
processes and physical nodes
rather than just treating
staleness through techniques such
than just treating every
order as the list
through techniques such as
just treating every single
in order to avoid
treating every single receiver
order to avoid os
space version involved running
to avoid os resource
every single receiver as
techniques such as time
single receiver as a
avoid os resource contention
receiver as a member
version involved running a
as a member of
involved running a single
a member of a
member of a recovery
we experimented with groups
bad order accesses them
of a recovery region
experimented with groups of
order accesses them in
accesses them in reverse
second iperf flow from
them in reverse order
whether this can really
iperf flow from one
this can really scale
nd workshop on the
can really scale remains
workshop on the economics
really scale remains to
on the economics of
scale remains to be
the economics of peer
remains to be seen
flow from one node
our work considers multi
from one node to
one node to another
node to another with
object transactional consistency of
transactional consistency of cache
to another with and
consistency of cache access
another with and without
with and without maelstrom
and without maelstrom running
without maelstrom running on
maelstrom running on the
running on the routers
on the routers and
the routers and measuring
early work on scalable
routers and measuring throughput
work on scalable database
by convention the head
and measuring throughput while
convention the head of
on scalable database caching
measuring throughput while varying
the head of the
scalable database caching mostly
head of the chain
database caching mostly ignored
of the chain for
throughput while varying the
the chain for each
caching mostly ignored transactional
while varying the random
mostly ignored transactional consistency
chain for each group
varying the random loss
for each group was
the random loss rate
changtao qu and wolfgang
each group was called
qu and wolfgang nejdl
group was called node
random loss rate on
loss rate on the
rate on the link
on the link and
the link and the
link and the oneway
and the oneway latency
and all update requests
all update requests for
update requests for a
requests for a partition
for a partition were
to test the kernel
a partition were routed
test the kernel version
peer network with web
partition were routed towards
network with web services
work has been done
the kernel version at
has been done on
were routed towards this
been done on creating
routed towards this node
done on creating consistent
kernel version at gigabit
on creating consistent caches
version at gigabit speeds
analysis of prefetching the
creating consistent caches for
concurrency control and availability
since delivery delays in
control and availability in
of prefetching the graphs
we ran eight parallel
consistent caches for databases
ran eight parallel iperf
and availability in multi
eight parallel iperf flows
prefetching the graphs in
delivery delays in the
improving robustness of peer
delays in the chain
parallel iperf flows from
the graphs in figure
in the chain were
iperf flows from one
the chain were measured
flows from one node
chain were measured relative
from one node to
were measured relative to
one node to another
peer streaming with incentives
extends a centralized database
measured relative to node
a centralized database with
node to another for
centralized database with support
database with support for
show the results of
with support for caches
the results of the
support for caches that
all the statistics pertaining
for caches that provide
results of the experiments
st workshop on the
the statistics pertaining to
workshop on the economics
statistics pertaining to the
on the economics of
pertaining to the group
the economics of networked
to the group disregarded
economics of networked systems
the group disregarded node
caches that provide snapshot
the curves obtained from
that provide snapshot isolation
a scalable and ontology
provide snapshot isolation semantics
design and implementation of
curves obtained from the
where a test such
and implementation of a
obtained from the two
implementation of a reliable
we simulated two classes
of a reliable group
simulated two classes of
a reliable group communication
two classes of failures
reliable group communication toolkit
albeit the snapshots seen
group communication toolkit for
the snapshots seen may
communication toolkit for java
a test such as
from the two versions
p infrastructure for semantic
test such as simultaneous
at some time t
snapshots seen may be
some time t one
infrastructure for semantic web
time t one process
such as simultaneous demand
seen may be stale
the two versions are
for semantic web services
two versions are almost
versions are almost identical
to improve the commit
improve the commit rate
the commit rate for
commit rate for read
we present both to
present both to show
on predictive modeling for
the system must detect
both to show that
system must detect the
fetch incorporates more than
predictive modeling for optimizing
must detect the failure
incorporates more than one
modeling for optimizing transaction
to show that the
for optimizing transaction execution
more than one workload
where the cache holds
repair the broken fifo
show that the kernel
optimizing transaction execution in
the cache holds several
transaction execution in parallel
that the kernel version
execution in parallel oltp
cache holds several versions
in parallel oltp systems
the kernel version successfully
the broken fifo channel
holds several versions of
kernel version successfully scales
several versions of an
version successfully scales up
only the elapsed time
successfully scales up the
versions of an object
scales up the performance
of an object and
the elapsed time for
up the performance of
an object and enables
the performance of the
object and enables the
elapsed time for the
performance of the userspace
the failed process recovers
time for the foreground
and enables the cache
of the userspace version
enables the cache to
the userspace version to
the cache to choose
failed process recovers and
userspace version to hundreds
process recovers and rejoins
for the foreground workload
cache to choose a
version to hundreds of
recovers and rejoins the
a collaboration system architecture
design and evaluation of
to hundreds of megabits
and evaluation of a
p live streaming system
hundreds of megabits of
and rejoins the chain
of megabits of traffic
to choose a version
megabits of traffic per
evaluation of a wide
of traffic per second
the one accessing a
choose a version that
the join protocol would
a version that allows
join protocol would run
one accessing a file
of the ninth ieee
accessing a file group
area event notification service
version that allows a
the ninth ieee global
that allows a transaction
and the previously failed
allows a transaction to
ninth ieee global internet
a transaction to commit
acm transactions on computer
the previously failed node
transactions on computer systems
previously failed node would
ieee global internet workshop
failed node would become
node would become the
would become the new
this technique could also
become the new tail
technique could also be
the new tail of
could also be used
new tail of the
also be used with
sonic performance test suite
be used with our
tail of the chain
used with our solution
scalable deferred update replication
in most of the
the scenario is intended
most of the microbenchmarks
scenario is intended to
is intended to model
intended to model a
to model a common
model a common case
a common case in
common case in which
case in which the
we show how tcp
in which the failure
which the failure detection
the failure detection mechanism
failure detection mechanism senses
adding prefetching from the
detection mechanism senses a
ip performance degrades on
mechanism senses a transient
prefetching from the file
performance degrades on a
senses a transient problem
from the file groups
the file groups specified
file groups specified has
ms link as the
groups specified has a
a node that has
link as the loss
node that has become
specified has a substantial
also support snapshot isolation
as the loss rate
has a substantial improvement
that has become overloaded
the loss rate is
a substantial improvement on
has become overloaded or
but can be used
substantial improvement on the
become overloaded or is
loss rate is increased
overloaded or is unresponsive
rate is increased from
or is unresponsive for
improvement on the performance
can be used with
is unresponsive for some
be used with any
unresponsive for some other
used with any backend
for some other reason
with any backend database
on the performance of
the case for determinism
case for determinism in
including ones that are
the performance of the
for determinism in database
such as garbage collection
determinism in database systems
ones that are sharded
that are sharded and
performance of the workload
and does not respond
does not respond to
not respond to the
respond to the heartbeat
to the heartbeat within
the heartbeat within the
heartbeat within the accepted
within the accepted window
varying with how amenable
with how amenable it
maelstrom masks loss up
masks loss up to
by reconfiguring the chain
provides a transactionally consistent
how amenable it is
a transactionally consistent cache
the load on node
transactionally consistent cache for
amenable it is to
load on node drops
consistent cache for the
without significant throughput degradation
cache for the jboss
it is to prefetching
for the jboss middleware
and the problem will
the problem will eventually
with the kernel version
problem will eventually resolve
weight process groups in
the kernel version achieving
process groups in the
kernel version achieving two
groups in the isis
version achieving two orders
in the isis system
achieving two orders of
it then requests a
two orders of magnitude
then requests a rejoin
orders of magnitude higher
a demonstration of collaborative
of magnitude higher throughput
demonstration of collaborative web
magnitude higher throughput that
of collaborative web services
higher throughput that conventional
a node crash that
collaborative web services and
node crash that results
web services and peer
throughput that conventional tcp
support transactions on cached
crash that results in
transactions on cached enterprise
more surplus bandwidth and
on cached enterprise javabeans
that results in a
surplus bandwidth and more
results in a reboot
bandwidth and more think
in a reboot would
and more think time
a reboot would result
more think time result
reboot would result in
the graphs on the
think time result in
would result in similar
graphs on the right
result in similar behavior
time result in improved
on the right side
allows update transactions to
the right side of
result in improved performance
right side of figures
update transactions to read
transactions to read stale
to read stale data
read stale data out
all the nodes in
stale data out of
the nodes in the
data out of caches
nodes in the subservice
out of caches and
in the subservice remain
of caches and provide
the subservice remain operational
caches and provide bounds
and provide bounds on
this naturally means that
provide bounds on how
but one of them
bounds on how much
one of them becomes
naturally means that the
on how much staleness
of them becomes overloaded
how much staleness is
means that the greatest
p network based architecture
much staleness is allowed
network based architecture for
that the greatest improvements
ip throughput declining on
causing the tcp link
the greatest improvements from
based architecture for web
these techniques require fast
the tcp link to
greatest improvements from prefetching
tcp link to the
techniques require fast communication
link to the upstream
improvements from prefetching are
to the upstream node
architecture for web service
the upstream node to
from prefetching are evident
upstream node to become
throughput declining on a
node to become congested
require fast communication between
to become congested and
prefetching are evident at
constructing reliable distributed communication
fast communication between the
are evident at higher
declining on a link
evident at higher bandwidths
become congested and starving
communication between the cache
congested and starving downstream
on a link of
reliable distributed communication systems
a link of increasing
distributed communication systems with
between the cache and
communication systems with corba
link of increasing length
and starving downstream nodes
the cache and the
of increasing length when
cache and the database
increasing length when subjected
and the database for
six out of eight
length when subjected to
out of eight microbenchmarks
the database for good
which begin to miss
database for good performance
ieee communications magazine feature
when subjected to uniform
communications magazine feature topic
of eight microbenchmarks run
begin to miss updates
subjected to uniform loss
magazine feature topic issue
to uniform loss rates
eight microbenchmarks run at
in our work caches
uniform loss rates of
microbenchmarks run at least
this scenario models a
our work caches are
scenario models a behavior
work caches are asynchronously
models a behavior common
caches are asynchronously updated
a behavior common in
feature topic issue on
behavior common in experiments
topic issue on distributed
common in experiments on
issue on distributed object
in experiments on our
on distributed object computing
experiments on our cluster
when a node becomes
a node becomes very
which is how caches
node becomes very busy
is how caches currently
becomes very busy or
how caches currently work
very busy or the
caches currently work in
busy or the communication
currently work in large
or the communication subsystem
work in large multi
the communication subsystem becomes
communication subsystem becomes heavily
subsystem becomes heavily loaded
tcp at the node
faster when bandwidth is
the top line in
at the node upstream
f uture d irections
top line in the
the node upstream from
uture d irections the
line in the graphs
d irections the dependency
node upstream from it
in the graphs is
upstream from it will
irections the dependency list
from it will sense
the graphs is the
it will sense congestion
the dependency list sizes
will sense congestion and
graphs is the performance
sense congestion and reduce
dependency list sizes for
congestion and reduce its
list sizes for all
and reduce its window
is the performance of
sizes for all objects
the performance of tcp
for all objects in
reduce its window size
all objects in t
ip without loss and
if the impacted node
cache are currently all
without loss and provides
are currently all of
the impacted node is
currently all of the
loss and provides an
impacted node is in
all of the same
node is in the
and provides an upper
is in the middle
of the same maximum
provides an upper bound
in the middle of
an upper bound for
the middle of the
upper bound for performance
the same maximum length
middle of the chain
bound for performance on
for performance on the
performance on the link
this may not be
may not be optimal
it ceases to relay
ceases to relay updates
or does so after
space and kernel versions
does so after long
if the workload accesses
so after long delays
the workload accesses objects
workload accesses objects in
accesses objects in clusters
objects in clusters of
maelstrom masks packet loss
in clusters of different
masks packet loss and
clusters of different sizes
packet loss and tracks
loss and tracks the
hence downstream nodes fall
and tracks the lossless
downstream nodes fall behind
tracks the lossless line
objects of larger clusters
the lossless line closely
of larger clusters call
hierarchical clustering of message
larger clusters call for
clustering of message flows
clusters call for longer
of message flows in
call for longer dependency
message flows in a
lagging only when the
flows in a multicast
only when the link
in a multicast data
at low bandwidth most
the chain replication scheme
for longer dependency lists
low bandwidth most workloads
a multicast data dissemination
bandwidth most workloads see
when the link latency
chain replication scheme slows
the link latency is
once appropriate real workloads
link latency is low
appropriate real workloads are
multicast data dissemination system
real workloads are available
most workloads see no
replication scheme slows to
latency is low and
scheme slows to a
is low and tcp
it may be possible
workloads see no benefit
slows to a crawl
may be possible to
be possible to improve
ip s throughput is
possible to improve performance
s throughput is very
to improve performance by
throughput is very high
improve performance by dynamically
performance by dynamically changing
by dynamically changing per
the ssa benefits from
ssa benefits from its
since all the bandwidth
benefits from its gossip
object dependency list sizes
from its gossip repair
all the bandwidth is
its gossip repair mechanisms
the bandwidth is dedicated
balancing between objects to
bandwidth is dedicated to
between objects to maintain
which route missing updates
objects to maintain the
is dedicated to higher
route missing updates around
to maintain the same
missing updates around the
maintain the same overall
updates around the slow
the same overall space
around the slow node
same overall space overhead
another option is to
option is to explore
is to explore an
optimizing buffer management for
to explore an approach
buffer management for reliable
route them to that
management for reliable multicast
them to that node
explore an approach in
an approach in which
only two tests perform
approach in which each
proceedings of the international
two tests perform worse
of the international conference
in which each type
the international conference on
which each type of
international conference on dependable
tests perform worse with
each type of object
when it recovers and
perform worse with prefetching
it recovers and needs
conference on dependable systems
recovers and needs to
worse with prefetching than
type of object would
on dependable systems and
of object would have
with prefetching than without
and needs to repair
dependable systems and networks
object would have its
needs to repair its
would have its own
to repair its state
have its own dependency
its own dependency list
own dependency list bound
knowing that gossip will
that gossip will kick
gossip will kick in
write test performs slightly
agnostic and treats all
an upstream node can
test performs slightly worse
and treats all objects
upstream node can deliberately
treats all objects and
node can deliberately drop
all objects and object
can deliberately drop updates
performs slightly worse due
objects and object relations
deliberately drop updates on
and object relations as
slightly worse due to
drop updates on congested
object relations as equal
updates on congested tcp
worse due to its
on congested tcp connections
due to its already
using an lru policy
to its already heavy
we used our wall
an lru policy to
its already heavy network
lru policy to trim
already heavy network contention
clock service to evaluate
policy to trim the
service to evaluate the
to trim the list
to evaluate the behavior
trim the list of
evaluate the behavior of
the list of dependencies
the behavior of the
behavior of the overall
the one issue that
of the overall system
the overall system in
the bad groups test
one issue that unites
overall system in various
there may be cases
system in various scenarios
issue that unites almost
in various scenarios and
may be cases in
various scenarios and with
that unites almost all
scenarios and with different
be cases in which
and with different parameters
unites almost all approaches
cases in which the
which exploits poor prefetching
almost all approaches to
in which the application
a stream of updates
exploits poor prefetching hints
all approaches to distributed
which the application could
stream of updates of
the application could explicitly
approaches to distributed computing
ip no loss maelstrom
application could explicitly inform
to distributed computing is
a group membership service
no loss maelstrom no
distributed computing is the
could explicitly inform the
group membership service for
explicitly inform the cache
membership service for wans
inform the cache of
of updates of various
the cache of relevant
computing is the need
cache of relevant object
updates of various rates
is the need to
of relevant object dependencies
acm transactions on computer
of various rates is
transactions on computer systems
the need to know
loss maelstrom no loss
need to know whether
maelstrom no loss maelstrom
and those could then
various rates is injected
to know whether certain
rates is injected into
performs when prefetching is
those could then be
know whether certain components
could then be treated
is injected into the
whether certain components in
when prefetching is used
then be treated as
injected into the head
be treated as more
certain components in the
treated as more important
into the head of
components in the system
as more important and
in the system have
more important and retained
the head of the
the system have failed
head of the chain
system have failed or
have failed or are
failed or are otherwise
while other less important
this effect is due
or are otherwise unavailable
other less important ones
effect is due to
less important ones are
important ones are managed
is due to the
for groups of nodes
when designing and building
ones are managed by
due to the useless
designing and building systems
are managed by some
and building systems that
to the useless prefetching
building systems that need
managed by some other
systems that need to
by some other policy
the useless prefetching rpcs
established point in time
that need to function
useless prefetching rpcs flooding
some other policy such
need to function at
other policy such as
prefetching rpcs flooding the
a victim node receives
to function at a
rpcs flooding the outgoing
victim node receives a
policy such as lru
flooding the outgoing link
node receives a command
function at a global
the outgoing link and
receives a command that
at a global scale
outgoing link and imposing
a command that forces
in a web album
command that forces it
link and imposing minor
failure management needs to
that forces it to
management needs to be
and imposing minor delays
forces it to halt
a web album the
needs to be considered
imposing minor delays on
web album the set
the node continues to
to be considered a
node continues to listen
minor delays on each
album the set of
be considered a fundamental
delays on each demand
considered a fundamental building
the set of pictures
a fundamental building block
on each demand fetch
continues to listen for
set of pictures and
to listen for commands
of pictures and their
listen for commands that
this paper describes the
for commands that would
pictures and their acl
paper describes the development
commands that would restart
describes the development of
and their acl is
the development of a
that would restart it
their acl is an
development of a system
acl is an important
a private framework for
is an important dependency
private framework for distributed
an important dependency whereas
independent failure management service
framework for distributed computation
this is accomplished by
for distributed computation edward
is accomplished by having
cumulatively these slow down
distributed computation edward tremel
important dependency whereas occasional
these slow down the
dependency whereas occasional tagging
accomplished by having node
slow down the overall
which allows systems and
whereas occasional tagging operations
allows systems and applications
down the overall performance
occasional tagging operations that
systems and applications to
tagging operations that relate
send a crash command
operations that relate pictures
and ma rk jelasity
a crash command to
and applications to incorporate
crash command to the
applications to incorporate accurate
command to the victim
ma rk jelasity there
to the victim node
to incorporate accurate detection
the victim node once
rk jelasity there is
that relate pictures to
an usual phenomenon is
victim node once a
incorporate accurate detection of
node once a certain
accurate detection of failed
once a certain number
detection of failed processes
a certain number of
relate pictures to users
certain number of updates
usual phenomenon is that
jelasity there is a
pictures to users may
number of updates were
there is a growing
to users may be
is a growing class
phenomenon is that the
a growing class of
of updates were injected
without the need for
growing class of distributed
users may be less
the need for making
is that the bad
updates were injected into
may be less important
were injected into the
need for making compromises
injected into the chain
class of distributed systems
that the bad order
for making compromises in
of distributed systems applications
the bad order test
distributed systems applications in
it may be straightforward
bad order test consistently
may be straightforward to
systems applications in which
making compromises in their
order test consistently outperforms
be straightforward to extend
applications in which data
straightforward to extend the
the victim node will
to extend the cache
test consistently outperforms good
compromises in their particular
in which data stored
consistently outperforms good order
which data stored on
in their particular design
victim node will stop
extend the cache api
data stored on client
the cache api to
node will stop participating
cache api to allow
stored on client platforms
api to allow the
will stop participating in
to allow the application
on client platforms must
even though the latter
client platforms must be
allow the application to
platforms must be aggregated
with the advent of
the application to specify
though the latter triggers
stop participating in the
the latter triggers prefetches
the advent of ubiquitous
latter triggers prefetches in
must be aggregated or
triggers prefetches in the
be aggregated or analyzed
participating in the normal
aggregated or analyzed without
in the normal protocol
application to specify such
the normal protocol and
prefetches in the correct
or analyzed without revealing
to specify such dependencies
normal protocol and will
in the correct order
analyzed without revealing private
specify such dependencies and
without revealing private information
such dependencies and to
revealing private information to
dependencies and to modify
it is becoming clear
protocol and will handle
private information to the
and will handle only
information to the operator
the explanation is that
is becoming clear that
and to modify t
becoming clear that the
will handle only wakeup
clear that the systems
handle only wakeup commands
that the systems that
only wakeup commands from
the systems that are
wakeup commands from this
systems that are used
commands from this moment
that are used today
from this moment onwards
cache to respect them
systems such as the
are used today in
such as the smart
used today in local
as the smart power
the good order test
the smart power grid
the chain detects the
chain detects the failure
c onclusion existing large
good order test suffers
control systems for energy
can not simply be
repairs and announces the
not simply be employed
and announces the membership
order test suffers from
scale computing frameworks make
announces the membership change
computing frameworks make heavy
test suffers from the
and traffic analysis in
frameworks make heavy use
suffers from the fast
after a number of
traffic analysis in large
from the fast linear
analysis in large cities
the fast linear scan
make heavy use of
fast linear scan phenomenon
a number of updates
linear scan phenomenon described
number of updates have
heavy use of edge
scan phenomenon described in
use of edge caches
of updates have been
of edge caches to
simply be employed in
edge caches to reduce
phenomenon described in section
in large cities all
updates have been injected
large cities all depend
have been injected since
caches to reduce client
been injected since the
to reduce client latency
injected since the crash
cities all depend on
be employed in their
all depend on the
since the crash command
depend on the analysis
the crash command was
but this form of
crash command was issued
this form of caching
on the analysis of
form of caching has
the analysis of data
of caching has not
analysis of data supplied
caching has not been
of data supplied by
has not been available
data supplied by measurement
not been available for
supplied by measurement devices
employed in their existing
been available for transactional
sends a wakeup command
in their existing form
available for transactional applications
yet the clients being
their existing form or
a wakeup command to
all prefetches in this
wakeup command to the
the clients being tracked
command to the victim
existing form or trivially
to the victim node
prefetches in this test
clients being tracked are
in this test conflict
being tracked are unwilling
we believe this is
tracked are unwilling to
this test conflict with
form or trivially converted
believe this is one
or trivially converted for
test conflict with demand
are unwilling to reveal
conflict with demand fetches
unwilling to reveal such
this is one reason
to reveal such measurement
the victim node rejoins
reveal such measurement data
victim node rejoins the
such measurement data directly
node rejoins the group
measurement data directly to
is one reason that
data directly to the
trivially converted for wide
directly to the system
one reason that transactions
to the system owner
reason that transactions are
it has to catch
that transactions are generally
has to catch up
transactions are generally not
to catch up by
are generally not considered
who might be curious
catch up by obtaining
might be curious about
generally not considered to
be curious about private
up by obtaining copies
not considered to be
by obtaining copies of
at the start of
obtaining copies of updates
considered to be a
curious about private client
to be a viable
the start of the
copies of updates that
start of the bad
be a viable option
whatever form such systems
a viable option in
about private client information
form such systems may
of the bad order
viable option in extremely
the bad order test
option in extremely large
of updates that it
in extremely large systems
these systems thus may
such systems may take
updates that it has
systems may take in
that it has missed
may take in the
systems thus may elicit
take in the future
thus may elicit public
the prefetching subsystem is
may elicit public opposition
we experimentally determined that
elicit public opposition despite
whether they are replicated
public opposition despite their
a variant of serializability
prefetching subsystem is able
they are replicated databases
opposition despite their useful
are replicated databases of
repetitions of each experiment
replicated databases of hyper
subsystem is able to
variant of serializability that
despite their useful features
of serializability that is
is able to prefetch
of each experiment were
their useful features because
each experiment were enough
useful features because of
experiment were enough to
features because of a
were enough to yield
because of a perceived
enough to yield accurate
view or virtual synchronous
able to prefetch some
or virtual synchronous groups
to yield accurate measurements
to prefetch some files
yield accurate measurements with
virtual synchronous groups or
accurate measurements with low
serializability that is suitable
measurements with low variance
that is suitable for
prefetch some files accessed
of a perceived privacy
some files accessed at
is suitable for incoherent
files accessed at the
suitable for incoherent caches
synchronous groups or agents
a perceived privacy risk
groups or agents employing
accessed at the end
shows the update delivery
at the end of
the update delivery delay
the end of the
update delivery delay for
end of the test
delivery delay for a
or agents employing lazy
delay for a set
there are ways to
for a set of
agents employing lazy consistency
a set of four
are ways to upload
set of four consecutive
employing lazy consistency schemes
of four consecutive nodes
ways to upload sensitive
four consecutive nodes in
to upload sensitive data
which cannot communicate with
upload sensitive data to
without conflicting with a
consecutive nodes in a
conflicting with a demand
sensitive data to an
one of the key
data to an aggregator
nodes in a chain
to an aggregator without
with a demand fetch
cannot communicate with the
of the key problems
communicate with the backend
an aggregator without compromising
with the backend database
starting with the victim
the backend database on
with the victim node
backend database on every
aggregator without compromising privacy
database on every read
the key problems that
on every read access
it can therefore achieve
key problems that needs
can therefore achieve a
but existing options have
problems that needs to
existing options have limitations
therefore achieve a greater
we then presented t
achieve a greater speedup
that needs to be
one possibility is to
needs to be addressed
possibility is to keep
the chain length is
is to keep the
to keep the data
keep the data encrypted
is that of the
an architecture for controlling
that of the detection
architecture for controlling transaction
the data encrypted with
for controlling transaction consistency
data encrypted with keys
controlling transaction consistency with
of the detection and
transaction consistency with caches
and we report on
encrypted with keys known
we report on a
with keys known only
report on a gossip
keys known only to
on a gossip rate
known only to the
the system extends the
a gossip rate of
system extends the edge
only to the clients
extends the edge cache
the edge cache by
edge cache by allowing
cache by allowing it
the detection and handling
by allowing it to
detection and handling of
allowing it to offer
and handling of faulty
but this requires expensive
handling of faulty components
it to offer a
this requires expensive homomorphic
to offer a transactional
requires expensive homomorphic encryption
offer a transactional interface
expensive homomorphic encryption if
homomorphic encryption if the
milliseconds at a steady
encryption if the aggregator
we believe that t
at a steady update
if the aggregator is
a steady update injection
the aggregator is to
steady update injection rate
aggregator is to compute
update injection rate of
cache is the first
is to compute directly
is the first transaction
building distributed systems and
to compute directly on
compute directly on it
distributed systems and applications
systems and applications today
aware caching architecture in
and applications today is
caching architecture in which
another is to employ
applications today is done
is to employ a
architecture in which caches
today is done using
in which caches are
to employ a mechanism
which caches are updated
is done using a
caches are updated asynchronously
tcp no loss maelstrom
there are three anomalies
done using a variety
are three anomalies that
no loss maelstrom no
three anomalies that can
loss maelstrom no loss
anomalies that can be
maelstrom no loss maelstrom
that can be seen
using a variety of
can be seen on
a lookup request only
a variety of systems
lookup request only requires
employ a mechanism to
request only requires a
a mechanism to de
only requires a round
variety of systems ranging
be seen on the
of systems ranging from
seen on the graphs
systems ranging from the
correlate client identifiers from
ranging from the bare
client identifiers from their
trip to the database
identifiers from their data
from the bare bone
to the database in
the bare bone protocols
the first one is
bare bone protocols interfaces
the database in case
first one is experienced
bone protocols interfaces like
as chen et al
protocols interfaces like bsd
one is experienced by
interfaces like bsd sockets
database in case there
is experienced by the
like bsd sockets and
experienced by the victim
bsd sockets and the
by the victim node
sockets and the tdi
in case there is
the victim node for
case there is a
victim node for updates
there is a cache
node for updates injected
is a cache miss
for updates injected between
to rpc based systems
a cache miss there
rpc based systems such
cache miss there is
based systems such as
miss there is no
systems such as dce
there is no additional
such as dce and
is no additional traffic
as dce and to
no additional traffic and
but this imposes restrictions
additional traffic and delays
dce and to more
traffic and delays to
this imposes restrictions on
and delays to ensure
and to more advanced
delays to ensure cache
imposes restrictions on the
to ensure cache coherence
to more advanced distributed
restrictions on the kind
more advanced distributed support
on the kind of
seconds after the start
the kind of aggregation
after the start of
kind of aggregation that
the start of the
of aggregation that can
start of the experiment
advanced distributed support systems
aggregation that can be
cache associates dependency information
distributed support systems such
associates dependency information with
support systems such as
dependency information with cached
systems such as isis
that can be done
the second is experienced
information with cached database
second is experienced by
with cached database objects
is experienced by all
experienced by all the
by all the other
all the other nodes
the other nodes for
while leaving the interaction
other nodes for update
leaving the interaction between
nodes for update messages
it would be beneficial
for update messages injected
the interaction between the
update messages injected at
would be beneficial to
messages injected at around
interaction between the backend
be beneficial to execute
between the backend systems
beneficial to execute needed
the backend systems and
to execute needed computation
backend systems and the
execute needed computation directly
systems and the cache
needed computation directly on
and the cache otherwise
computation directly on the
the cache otherwise unchanged
directly on the client
seconds after the start
on the client platforms
after the start of
the start of the
start of the experiment
this information includes version
information includes version identifiers
so that the system
includes version identifiers and
that the system operator
version identifiers and bounded
while the third one
the system operator or
the third one is
system operator or analyst
third one is a
operator or analyst only
one is a smaller
or analyst only sees
is a smaller mixed
analyst only sees aggregate
a smaller mixed burst
only sees aggregate results
smaller mixed burst for
with this modest amount
mixed burst for updates
this modest amount of
burst for updates injected
modest amount of additional
for updates injected at
amount of additional information
this approach would provide
approach would provide a
would provide a better
provide a better alternative
a better alternative to
we show that inconsistency
better alternative to central
show that inconsistency can
alternative to central aggregation
that inconsistency can be
seconds into the experiment
inconsistency can be greatly
research edition where the
to central aggregation provided
can be greatly reduced
edition where the academic
be greatly reduced or
note that the y
where the academic knights
greatly reduced or even
central aggregation provided it
reduced or even completely
aggregation provided it is
or even completely eliminated
provided it is privacy
even completely eliminated in
the academic knights meet
completely eliminated in some
axes have different scales
eliminated in some cases
after years of experience
have different scales to
years of experience with
academic knights meet the
one way link latency
of experience with building
different scales to observe
experience with building these
knights meet the evil
with building these systems
scales to observe how
meet the evil empire
building these systems and
to observe how the
cache is intended for
the evil empire werner
these systems and applications
observe how the system
a data aggregation system
how the system handles
data aggregation system based
the system handles the
aggregation system based on
system handles the transient
system based on client
it is clear that
is intended for clustered
handles the transient failure
intended for clustered workloads
is clear that failure
evil empire werner vogels
clear that failure management
side computation suggests a
the transient failure better
computation suggests a purely
that failure management is
suggests a purely peer
and those arise naturally
empire werner vogels the
those arise naturally in
failure management is not
werner vogels the rivalry
therefore the third anomaly
management is not just
the third anomaly appears
is not just a
arise naturally in social
not just a essential
naturally in social networks
just a essential tool
third anomaly appears to
a essential tool for
vogels the rivalry in
essential tool for group
anomaly appears to grow
tool for group oriented
the rivalry in the
for group oriented systems
appears to grow with
rivalry in the operating
to grow with the
in the operating system
mobile applications with spatial
the operating system market
applications with spatial locality
grow with the chain
all which have built
with the chain distance
operating system market place
the chain distance from
system market place has
chain distance from the
market place has a
distance from the victim
place has a severe
from the victim node
has a severe impact
which many systems have
a severe impact on
way latency throughput as
severe impact on the
many systems have used
but that it is
the growth is not
systems have used to
growth is not significant
our experiments demonstrate t
latency throughput as a
that it is a
throughput as a function
have used to avoid
as a function of
it is a fundamental
a function of latency
cache to be effective
is a fundamental service
impact on the academic
a fundamental service that
on the academic world
to be effective in
used to avoid centralized
since the cause of
to avoid centralized control
be effective in realistic
fundamental service that should
effective in realistic workloads
where in the old
in realistic workloads based
in the old days
realistic workloads based on
the cause of this
workloads based on datasets
the old days intellection
based on datasets from
cause of this anomaly
on datasets from amazon
old days intellection quality
service that should be
days intellection quality and
datasets from amazon and
intellection quality and careful
from amazon and orkut
quality and careful deliberation
that should be placed
and careful deliberation would
of this anomaly is
careful deliberation would prevail
should be placed among
this anomaly is an
be placed among such
using dependency lists of
anomaly is an artifact
dependency lists of size
placed among such established
is an artifact of
among such established basic
an artifact of java
such established basic services
artifact of java s
established basic services as
nowadays discussions about operating
basic services as naming
of java s garbage
discussions about operating systems
ip to attain very
about operating systems research
java s garbage collection
operating systems research appear
s garbage collection mechanism
systems research appear to
garbage collection mechanism kicking
to attain very high
collection mechanism kicking in
research appear to be
attain very high speeds
appear to be more
very high speeds on
to be more like
high speeds on the
be more like the
speeds on the gigabit
as can be noted
service brokerage and ipc
more like the battlefield
on the gigabit link
peer systems have problems
like the battlefield of
systems have problems of
the battlefield of a
have problems of their
battlefield of a holy
problems of their own
of a holy war
we had to set
this paper reports on
had to set the
to set the mtu
performed recovery for the
paper reports on an
recovery for the updates
and was also able
with objectivity as its
reports on an ongoing
objectivity as its main
for the updates it
was also able to
the updates it has
also able to increase
updates it has missed
able to increase consistent
even if we set
to increase consistent transaction
if we set privacy
increase consistent transaction rate
we set privacy concerns
set the mtu of
set privacy concerns aside
on an ongoing research
it has missed during
consistent transaction rate by
has missed during the
the mtu of the
missed during the period
an ongoing research effort
during the period it
mtu of the entire
the period it was
as its main victim
period it was down
by eschewing centralization entirely
of the entire path
ongoing research effort to
the entire path to
entire path to be
research effort to abstract
path to be the
we have tried to
to be the maximum
effort to abstract the
have tried to side
because the chain delivers
tried to side step
to abstract the failure
to side step the
the chain delivers new
they can no longer
chain delivers new updates
abstract the failure handling
with only nominal overhead
can no longer take
only nominal overhead on
the failure handling strategies
nominal overhead on the
side step the emotional
overhead on the database
failure handling strategies from
step the emotional current
no longer take advantage
delivers new updates at
number of rpcs by
handling strategies from a
of rpcs by type
and select an operating
strategies from a variety
longer take advantage of
select an operating system
from a variety of
take advantage of the
new updates at the
advantage of the powerful
updates at the moment
of the powerful management
at the moment of
a variety of popular
the moment of rejoin
rpcs by type in
an operating system that
by type in bandwidth
operating system that could
type in bandwidth variability
system that could bring
our experiments with synthetic
that could bring our
which meant that the
could bring our research
all past updates were
bring our research into
in bandwidth variability test
the powerful management tools
experiments with synthetic workloads
variety of popular distributed
with synthetic workloads showed
past updates were solely
of popular distributed systems
powerful management tools developed
meant that the long
the entries under p
our research into the
entries under p denote
popular distributed systems and
under p denote periods
synthetic workloads showed that
updates were solely recovered
research into the next
were solely recovered by
into the next century
solely recovered by means
p denote periods in
workloads showed that t
denote periods in the
management tools developed for
distributed systems and to
tools developed for today
haul link had the
developed for today s
cache s efficacy depends
periods in the test
s efficacy depends on
based on objective technical
efficacy depends on the
for today s cloud
recovered by means of
today s cloud computing
by means of epidemics
s cloud computing model
depends on the clustering
systems and to develop
on the clustering level
on objective technical and
and to develop a
the clustering level of
link had the same
clustering level of the
to develop a basic
level of the workload
objective technical and organizational
develop a basic failure
gives the abbreviations for
had the same mtu
technical and organizational criteria
the same mtu as
a basic failure management
the abbreviations for rpc
the second anomaly that
abbreviations for rpc types
clients are isolated network
second anomaly that shows
are isolated network hosts
basic failure management service
isolated network hosts rather
cache adapts to dynamically
failure management service that
anomaly that shows up
this paper describes how
network hosts rather than
same mtu as the
are likely to be
mtu as the inter
that shows up in
paper describes how this
hosts rather than devices
adapts to dynamically changing
rather than devices within
to dynamically changing workloads
than devices within a
shows up in the
dynamically changing workloads where
likely to be beneficial
describes how this evaluation
this resulted in the
management service that can
up in the update
changing workloads where clusters
devices within a single
workloads where clusters change
resulted in the fragmentation
where clusters change over
in the update delivery
clusters change over time
the first would reduce
service that can be
first would reduce the
that can be used
within a single administrative
the update delivery delay
a single administrative domain
how this evaluation lead
update delivery delay for
would reduce the aggressiveness
can be used by
reduce the aggressiveness of
be used by any
this evaluation lead to
used by any distributed
in the fragmentation of
by any distributed system
the fragmentation of repair
any distributed system regardless
fragmentation of repair packets
distributed system regardless of
of repair packets sent
and often have difficulty
repair packets sent over
delivery delay for the
packets sent over udp
due to resource limitations
sent over udp on
to resource limitations t
over udp on the
evaluation lead to the
udp on the longhaul
system regardless of the
on the longhaul link
the aggressiveness of prefetching
cache maintains only a
delay for the nodes
maintains only a short
the longhaul link into
only a short dependency
often have difficulty maintaining
a short dependency list
for the nodes downstream
have difficulty maintaining connections
longhaul link into two
lead to the insight
link into two ip
the nodes downstream from
into two ip packet
difficulty maintaining connections to
which is naturally imperfect
regardless of the purpose
is naturally imperfect and
nodes downstream from the
naturally imperfect and does
maintaining connections to each
imperfect and does not
of the purpose of
and does not include
downstream from the victim
does not include all
from the victim node
connections to each other
the victim node reflects
the purpose of that
victim node reflects the
purpose of that system
node reflects the period
not include all dependencies
reflects the period when
two ip packet fragments
the period when the
setting a byte threshold
to the insight that
we proved that when
to each other through
proved that when resources
of that system or
that when resources are
period when the chain
when resources are unbounded
when the chain is
the insight that microsoft
that system or the
since the loss of
system or the techniques
each other through firewalls
the loss of a
or the techniques used
other through firewalls and
loss of a single
the chain is broken
through firewalls and address
of a single fragment
insight that microsoft s
from a file group
firewalls and address translation
a single fragment resulted
a file group if
single fragment resulted in
and address translation barriers
during the time it
cache s algorithm implements
the strategies employed by
the time it took
file group if it
that microsoft s windows
determining the membership of
group if it appeared
strategies employed by this
time it took for
fragment resulted in the
it took for the
resulted in the loss
the membership of a
in the loss of
if it appeared that
employed by this basic
s algorithm implements cache
by this basic service
took for the failure
membership of a peer
the loss of the
it appeared that a
microsoft s windows nt
this basic service are
s windows nt is
loss of the repair
appeared that a process
for the failure detection
that a process was
the failure detection mechanism
peer network is a
failure detection mechanism to
network is a surprisingly
detection mechanism to declare
is a surprisingly difficult
a process was not
basic service are specifically
windows nt is the
service are specifically targeted
nt is the operating
a surprisingly difficult problem
is the operating system
process was not using
we observed a higher
mechanism to declare the
are specifically targeted towards
to declare the node
was not using the
observed a higher loss
not using the files
the operating system that
using the files prefetched
operating system that is
since there is no
a higher loss rate
there is no one
higher loss rate for
is no one entity
the files prefetched based
no one entity that
declare the node deceased
files prefetched based on
system that is best
specifically targeted towards applications
that is best prepared
loss rate for repairs
to start up the
prefetched based on its
one entity that knows
based on its prior
entity that knows the
on its prior accesses
start up the membership
targeted towards applications that
up the membership change
rate for repairs than
the membership change protocol
is best prepared for
towards applications that need
best prepared for the
for repairs than for
that knows the identities
repairs than for data
prepared for the future
than for data packets
applications that need to
and for the membership
that need to operate
this would reduce the
knows the identities of
would reduce the overhead
introduction until recently there
for the membership information
until recently there was
the membership information to
recently there was no
membership information to propagate
the identities of all
there was no doubt
identities of all the
reduce the overhead in
need to operate on
the overhead in the
was no doubt in
of all the clients
no doubt in academia
the chain is interrupted
doubt in academia which
chain is interrupted between
overhead in the bad
we expect performance to
in the bad groups
expect performance to be
the bad groups case
performance to be better
to operate on a
to be better on
operate on a global
be better on a
on a global scale
is interrupted between node
and changes in membership
in academia which operating
better on a network
changes in membership may
on a network where
in membership may not
academia which operating system
membership may not be
the second would explicitly
to build a successful
which operating system to
build a successful service
operating system to use
a successful service the
system to use for
may not be detected
successful service the following
second would explicitly detect
a network where the
to use for systems
network where the mtu
not be detected and
where the mtu of
be detected and propagated
and hence the updates
detected and propagated in
service the following goals
and propagated in a
would explicitly detect a
the mtu of the
explicitly detect a fast
hence the updates circumvent
the following goals were
the updates circumvent the
following goals were set
updates circumvent the gap
detect a fast linear
propagated in a timely
a fast linear scan
mtu of the long
fast linear scan by
use for systems research
in a timely fashion
design a failure management
circumvent the gap by
haul link is truly
the gap by means
a failure management system
link is truly larger
linear scan by a
gap by means of
scan by a process
by means of gossip
failure management system that
whether it was a
is truly larger than
it was a bsd
management system that is
was a bsd or
truly larger than the
a bsd or system
system that is independent
larger than the mtu
bsd or system v
that is independent of
or system v derivative
updates can bypass nodes
without a centralized service
can bypass nodes in
a centralized service to
by counting the instances
than the mtu within
bypass nodes in the
the mtu within each
centralized service to assign
was the predominant choice
service to assign and
counting the instances of
is independent of the
nodes in the chain
independent of the distributed
to assign and manage
of the distributed systems
assign and manage node
mtu within each cluster
the distributed systems packages
the instances of prefetch
distributed systems packages in
which had its roots
instances of prefetch and
even with zero loss
of prefetch and demand
in the chain using
prefetch and demand fetch
the chain using the
systems packages in use
chain using the gossip
and manage node identities
using the gossip as
and demand fetch conflict
ip throughput in figure
packages in use and
the gossip as it
in use and provide
gossip as it can
demand fetch conflict for
had its roots in
fetch conflict for a
as it can be
use and provide failure
it can be seen
and provide failure detection
can be seen in
its roots in research
provide failure detection of
conflict for a file
be seen in the
for a file group
seen in the figure
declines with link latency
was used since its
failure detection of processes
used since its inception
since its inception to
its inception to investigate
but this phenomenon is
inception to investigate fundamental
this is due to
to investigate fundamental system
is due to the
peer system is extremely
this phenomenon is less
system is extremely vulnerable
and then disable prefetching
is extremely vulnerable to
improve the accuracy of
extremely vulnerable to a
the accuracy of detection
due to the cap
accuracy of detection of
then disable prefetching from
investigate fundamental system research
disable prefetching from the
vulnerable to a few
to the cap on
to a few malicious
phenomenon is less likely
a few malicious peers
of detection of process
few malicious peers becoming
detection of process and
malicious peers becoming a
of process and node
is less likely as
peers becoming a majority
process and node failure
less likely as the
and node failure through
the cap on throughput
prefetching from the group
becoming a majority of
and the accumulated knowledge
likely as the node
node failure through systems
as the node receiving
failure through systems support
the accumulated knowledge in
cap on throughput placed
accumulated knowledge in academia
the node receiving the
knowledge in academia about
on throughput placed by
in academia about its
design support for failure
a majority of the
support for failure detectors
majority of the apparent
for failure detectors to
of the apparent nodes
failure detectors to work
the apparent nodes in
detectors to work in
apparent nodes in the
to work in large
nodes in the system
work in large scale
academia about its internals
in large scale systems
throughput placed by the
node receiving the update
placed by the buffering
about its internals and
even choosing peers fairly
by the buffering available
choosing peers fairly becomes
while maintaining a high
the buffering available at
maintaining a high level
buffering available at the
a high level of
available at the receiving
high level of accuracy
at the receiving end
prefetching and bandwidth variability
receiving the update is
and bandwidth variability so
the update is farther
provide support for the
bandwidth variability so far
support for the detection
update is farther away
for the detection of
its internals and operations
the detection of partitions
is farther away downstream
detection of partitions in
farther away downstream from
of partitions in networks
away downstream from the
peers fairly becomes difficult
downstream from the victim
the preceding experiments were
our experimental results have
preceding experiments were done
internals and operations was
experiments were done with
experimental results have demonstrated
were done with maelstrom
build a comprehensive software
done with maelstrom in
results have demonstrated the
with maelstrom in endto
and operations was significant
because peers usually do
a comprehensive software package
peers usually do not
have demonstrated the benefits
end flow control mode
comprehensive software package that
demonstrated the benefits of
software package that can
other available operating systems
the benefits of mfs
available operating systems such
package that can be
usually do not store
where it is oblivious
from the victim node
it is oblivious to
benefits of mfs adaptation
that can be easily
do not store the
can be easily integrated
not store the entire
be easily integrated into
store the entire membership
is oblivious to tcp
the entire membership list
of mfs adaptation mechanisms
operating systems such as
easily integrated into various
systems such as vms
entire membership list locally
ip and does not
mfs adaptation mechanisms at
such as vms and
integrated into various distributed
adaptation mechanisms at various
into various distributed systems
as vms and mvs
various distributed systems packages
and it is fairly
distributed systems packages and
mechanisms at various levels
contains an aggregated view
at various levels of
had their roots in
it is fairly easy
and does not split
an aggregated view of
does not split connections
aggregated view of the
their roots in the
view of the data
systems packages and applications
of the data in
various levels of bandwidth
and is consequently sensitive
levels of bandwidth availability
the data in figure
the resulting system is
is fairly easy for
resulting system is implemented
roots in the commercial
fairly easy for malicious
system is implemented and
in the commercial world
for the entire chain
easy for malicious peers
the commercial world and
is consequently sensitive to
for malicious peers to
commercial world and knowledge
malicious peers to poison
at gossip rates of
consequently sensitive to the
but not when the
world and knowledge about
not when the bandwidth
and knowledge about these
sensitive to the size
is implemented and is
to the size of
implemented and is under
the size of the
knowledge about these systems
size of the receiver
when the bandwidth is
of the receiver buffer
peers to poison local
about these systems never
and is under test
these systems never accumulated
is under test in
the bandwidth is changing
to poison local mem
bandwidth is changing over
poison local mem cornell
under test in a
local mem cornell bership
test in a wide
is changing over the
milliseconds showing that the
changing over the duration
mem cornell bership views
shows the performance of
cornell bership views so
the performance of split
bership views so that
over the duration of
systems never accumulated to
the duration of the
never accumulated to the
in a local setting
accumulated to the critical
a local setting of
performance of split mode
local setting of a
duration of the test
views so that they
showing that the behavior
so that they will
of split mode flow
that they will be
split mode flow control
that the behavior of
setting of a mix
the behavior of the
of a mix of
behavior of the scheme
a mix of high
of the scheme is
they will be preferred
the scheme is not
to the critical mass
will be preferred as
to conclude this section
scheme is not a
where maelstrom breaks a
conclude this section we
be preferred as neighbors
speed and traditional networks
this section we will
and traditional networks and
maelstrom breaks a single
section we will describe
breaks a single tcp
the critical mass were
traditional networks and in
critical mass were these
networks and in the
mass were these systems
preferred as neighbors by
were these systems could
google s globally distributed
we will describe an
ip connection into three
is not a fluke
connection into three hops
as neighbors by honest
and in the internet
neighbors by honest nodes
will describe an example
these systems could be
s globally distributed database
describe an example of
systems could be considered
note that the delay
could be considered for
a first software release
an example of mfs
that the delay of
be considered for widespread
first software release is
considered for widespread research
software release is planned
for widespread research tasks
the delay of the
release is planned for
example of mfs traffic
acm transactions on computer
is planned for the
split mode flow control
planned for the autumn
mode flow control eliminates
for the autumn of
flow control eliminates the
transactions on computer systems
control eliminates the requirement
although new research operating
eliminates the requirement for
of mfs traffic under
delay of the updates
new research operating systems
the requirement for large
research operating systems have
requirement for large buffers
of the updates delivered
for large buffers at
operating systems have been
large buffers at the
mfs traffic under the
the updates delivered at
traffic under the execution
updates delivered at the
under the execution of
delivered at the victim
the execution of the
at the victim node
execution of the simultaneous
the victim node is
of the simultaneous writeback
external failure detector modules
since neither completely centralized
buffers at the receiving
victim node is significantly
systems have been developed
node is significantly larger
failure detector modules originate
is significantly larger than
detector modules originate in
significantly larger than that
modules originate in asynchronous
at the receiving end
originate in asynchronous distributed
the simultaneous writeback test
in asynchronous distributed systems
none have found the
neither completely centralized aggregation
have found the following
completely centralized aggregation nor
found the following that
larger than that of
centralized aggregation nor a
the following that the
simultaneous writeback test described
following that the established
writeback test described in
where they were introduced
than that of the
they were introduced to
throughput is essentially insensitive
were introduced to de
is essentially insensitive to
aggregation nor a completely
essentially insensitive to one
nor a completely peer
test described in section
that of the nodes
that the established unix
of the nodes downstream
the established unix s
the nodes downstream of
established unix s received
nodes downstream of it
couple the mechanism by
downstream of it in
of it in the
peer system is adequate
it in the chain
system is adequate for
the mechanism by which
is adequate for our
with a slight drop
mechanism by which failures
a slight drop due
adequate for our purposes
we observed that even
slight drop due to
observed that even with
by which failures are
that even with sufficiently
freebsd and others continue
which failures are detected
and others continue to
even with sufficiently high
others continue to dominate
this test involves two
continue to dominate the
drop due to buffering
to dominate the academic
we explore a new
dominate the academic landscape
explore a new approach
with sufficiently high gossip
a new approach that
sufficiently high gossip rate
new approach that combines
due to buffering overhead
approach that combines the
but slowly but surely
that combines the features
to buffering overhead on
combines the features of
the only node to
failures are detected from
the features of these
test involves two simultaneous
slowly but surely windows
only node to experience
but surely windows nt
node to experience any
surely windows nt is
to experience any significant
windows nt is now
are detected from the
nt is now entering
detected from the protocols
is now entering the
experience any significant inconsistency
now entering the academic
any significant inconsistency window
entering the academic world
buffering overhead on the
significant inconsistency window is
overhead on the maelstrom
inconsistency window is the
on the maelstrom boxes
window is the node
involves two simultaneous workloads
from the protocols used
the academic world as
the protocols used to
academic world as a
protocols used to tolerate
world as a viable
features of these two
is the node that
of these two extremes
the node that failed
used to tolerate those
to tolerate those failures
alternative platform for research
compares split mode to
split mode to end
note that when the
although the idea of
that when the failed
the idea of a
although academia looked with
when the failed node
idea of a communication
kb to the server
academia looked with fascination
the failed node rejoins
of a communication system
to the server and
looked with fascination at
a communication system that
queries are performed against
communication system that combines
chandra and toueg successfully
system that combines some
and toueg successfully show
that combines some centralized
toueg successfully show that
with fascination at dave
are performed against its
fascination at dave cutler
performed against its data
successfully show that it
against its data before
the server and the
combines some centralized control
at dave cutler s
some centralized control with
its data before it
centralized control with a
server and the other
show that it is
dave cutler s attempt
that it is possible
control with a peer
it is possible to
and the other reads
data before it has
cutler s attempt to
before it has time
is possible to develop
it has time to
s attempt to build
has time to fully
possible to develop consensus
time to fully recover
peer overlay is not
to develop consensus algorithms
overlay is not new
develop consensus algorithms using
attempt to build a
consensus algorithms using failure
distributed data structures over
algorithms using failure detectors
data structures over a
once the chain is
we are the first
the chain is restored
are the first to
to build a new
the first to use
build a new operating
even if these failure
a new operating system
kb files from the
first to use such
structures over a shared
to use such a
over a shared log
new operating system from
files from the server
if these failure detectors
all new updates are
these failure detectors make
operating system from the
failure detectors make frequent
system from the ground
detectors make frequent mistakes
from the ground up
use such a system
new updates are received
in proceedings of the
make frequent mistakes in
but is slightly modified
such a system to
is slightly modified from
there were rare cases
a system to preserve
were rare cases when
system to preserve privacy
rare cases when gossip
th acm symposium on
slightly modified from original
acm symposium on operating
frequent mistakes in their
symposium on operating systems
cases when gossip circumvented
on operating systems principles
when gossip circumvented the
mistakes in their observations
gossip circumvented the chain
to preserve privacy while
circumvented the chain replication
preserve privacy while computing
the chain replication even
modified from original version
chain replication even though
all expected that windows
replication even though the
privacy while computing on
even though the chain
from original version to
expected that windows nt
original version to use
though the chain was
while computing on sensitive
that windows nt would
version to use a
windows nt would go
to use a longer
nt would go the
use a longer think
the chain was not
computing on sensitive data
would go the same
a longer think time
chain was not broken
go the same way
this combination is a
the same way as
combination is a sensible
longer think time of
is a sensible tradeoff
same way as the
the failure detector work
a sensible tradeoff for
failure detector work is
sensible tradeoff for the
but this happened only
tradeoff for the kinds
detector work is extended
for the kinds of
this happened only for
the kinds of systems
work is extended to
kinds of systems we
happened only for gossip
of systems we target
is extended to systems
way as the other
extended to systems that
only for gossip rates
to systems that also
as the other commercially
systems that also take
for gossip rates close
in which there is
gossip rates close to
the other commercially designed
which there is an
rates close to the
other commercially designed operating
there is an owner
seconds when accessing each
is an owner or
close to the update
commercially designed operating systems
to the update injection
when accessing each file
an owner or operator
that also take network
the update injection rate
also take network failure
owner or operator who
take network failure into
designed operating systems before
or operator who can
improving the potential for
operator who can be
the potential for rpcs
who can be trusted
later in this section
can be trusted to
in this section we
potential for rpcs to
operating systems before it
network failure into account
systems before it and
this section we will
before it and remain
for rpcs to overlap
it and remain in
be trusted to provide
and remain in the
section we will show
remain in the dark
trusted to provide basic
in the dark corner
we will show that
the dark corner from
off in designing practical
will show that even
ordering transactions with prediction
show that even with
dark corner from a
that even with these
corner from a research
even with these rapid
we enabled asynchronous writeback
with these rapid repairs
transactions with prediction in
enabled asynchronous writeback and
with prediction in distributed
to provide basic services
prediction in distributed object
from a research use
provide basic services such
the gossip overhead is
in distributed object stores
gossip overhead is actually
asynchronous writeback and ran
a research use point
writeback and ran the
research use point of
overhead is actually low
use point of view
basic services such as
and ran the test
mode buffering flow control
in designing practical distributed
buffering flow control against
about four years ago
ran the test with
services such as node
the test with the
such as node identification
test with the synthetic
as node identification and
with the synthetic bandwidth
node identification and membership
not long after the
flow control against one
long after the final
th workshop on large
the synthetic bandwidth trace
identification and membership tracking
synthetic bandwidth trace shown
and membership tracking but
bandwidth trace shown in
membership tracking but not
trace shown in figure
tracking but not to
scale distributed systems and
way link latency left
distributed systems and middleware
after the final major
of the messages were
the final major release
designing practical distributed systems
final major release of
the messages were delivered
practical distributed systems based
most bar represents maelstrom
major release of academic
bar represents maelstrom in
messages were delivered by
represents maelstrom in end
but not to see
were delivered by gossip
distributed systems based on
delivered by gossip ahead
not to see non
by gossip ahead of
systems based on the
gossip ahead of the
release of academic version
ahead of the chain
of academic version of
of the chain for
aggregated raw client data
which changes the bandwidth
academic version of the
based on the theory
version of the unix
the chain for gossip
on the theory developed
changes the bandwidth once
the theory developed for
the bandwidth once per
theory developed for asynchronous
of the unix operating
developed for asynchronous systems
the unix operating system
we treat the system
bandwidth once per second
end mode with manually
chain for gossip rate
mode with manually configured
treat the system operator
with manually configured large
for gossip rate identical
manually configured large buffers
the system operator as
configured large buffers at
for asynchronous systems is
system operator as an
gossip rate identical to
this has three sections
asynchronous systems is where
operator as an honest
systems is where and
rate identical to the
is where and how
identical to the update
where and how to
to the update injection
a brief period when
and how to introduce
large buffers at end
how to introduce the
brief period when the
the update injection rate
to introduce the notion
period when the bandwidth
who will keep the
when the bandwidth is
will keep the system
and the second and
keep the system running
the second and third
the bandwidth is at
introduce the notion of
the system running correctly
second and third bar
the notion of time
and third bar from
contains a plot of
system running correctly but
a plot of update
third bar from left
plot of update injection
bar from left are
key transactions for key
traditionally failure detectors have
the farewell of the
from left are split
running correctly but cannot
left are split mode
failure detectors have been
correctly but cannot be
of update injection time
but cannot be allowed
farewell of the berkeley
detectors have been implemented
of the berkeley systems
update injection time against
the berkeley systems werner
injection time against update
have been implemented using
time against update delivery
been implemented using time
against update delivery time
cannot be allowed to
a gradual decrease to
be allowed to see
update delivery time for
allowed to see more
out mechanisms in the
are split mode and
mechanisms in the transport
delivery time for the
split mode and end
berkeley systems werner vogels
to see more information
in the transport layer
see more information than
the transport layer that
time for the victim
transport layer that implements
more information than he
layer that implements inter
for the victim node
systems werner vogels is
information than he or
werner vogels is a
than he or she
vogels is a research
he or she needs
is a research scientist
ideally this is a
a research scientist at
this is a straight
research scientist at the
is a straight line
scientist at the department
a straight line because
or she needs to
straight line because of
s over the course
with standard buffers at
at the department of
outs remain an important
the department of computer
line because of chain
department of computer science
over the course of
standard buffers at end
she needs to know
remain an important tool
because of chain replication
an important tool in
the course of ten
of computer science of
important tool in the
computer science of cornell
course of ten seconds
note that once the
tool in the failure
that once the victim
split mode performs as
once the victim node
in the failure manager
the victim node recovers
mode performs as well
science of cornell university
performs as well with
and then the maintenance
the failure manager described
as well with default
failure manager described in
then the maintenance of
it gracefully catches up
well with default sized
gracefully catches up and
with default sized buffers
catches up and does
default sized buffers as
manager described in this
we introduce a method
the maintenance of the
introduce a method for
up and does so
sized buffers as end
and does so quickly
his research targets high
does so quickly for
described in this paper
so quickly for both
a method for constructing
quickly for both gossip
method for constructing a
for both gossip rates
availability in distributed systems
both gossip rates identical
end mode performs with
gossip rates identical and
mode performs with large
rates identical and half
performs with large end
identical and half the
the mechanism is integrated
and half the update
with a particular focus
half the update injection
a particular focus on
the update injection rate
particular focus on enterprise
s rate until the
focus on enterprise cluster
rate until the end
on enterprise cluster systems
until the end of
and much better than
mechanism is integrated into
for constructing a communication
now consider the link
constructing a communication overlay
much better than end
is integrated into a
the end of the
consider the link congestion
a communication overlay among
the link congestion case
end of the test
integrated into a more
president of reliable network
into a more comprehensive
of reliable network solutions
a more comprehensive approach
end mode with default
more comprehensive approach that
mode with default sized
communication overlay among the
with default sized buffers
comprehensive approach that treats
overlay among the client
approach that treats failure
among the client nodes
that treats failure detection
the client nodes that
treats failure detection using
client nodes that can
failure detection using methods
nodes that can safely
detection using methods based
that can safely be
using methods based on
which specializes in building
methods based on an
can safely be used
based on an analogy
specializes in building solutions
safely be used to
in building solutions for
summary of results the
building solutions for very
be used to perform
solutions for very large
on an analogy with
used to perform aggregation
an analogy with fault
to perform aggregation and
of results the test
perform aggregation and computation
scale reliable distributed systems
results the test was
aggregation and computation on
the test was executed
and computation on private
test was executed once
detection techniques used in
computation on private data
techniques used in daily
was executed once with
used in daily life
executed once with prefetching
once with prefetching enabled
although this overlay is
this overlay is set
overlay is set up
when trying to contact
is set up and
set up and operated
trying to contact a
facebook s distributed data
and despite the simplicity
to contact a person
s distributed data store
up and operated by
distributed data store for
despite the simplicity of
contact a person who
usenix windows nt symposium
and operated by the
a person who has
operated by the system
data store for the
the simplicity of the
his personal homepage is
simplicity of the mfs
personal homepage is at
of the mfs prefetching
by the system owner
store for the social
person who has allegedly
for the social graph
the mfs prefetching implementation
homepage is at http
who has allegedly disappeared
it provides minimal opportunity
in usenix annual technical
provides minimal opportunity for
usenix annual technical conference
has allegedly disappeared one
minimal opportunity for the
once with no prefetching
opportunity for the owner
allegedly disappeared one would
for the owner to
disappeared one would never
the owner to learn
one would never be
owner to learn any
would never be satisfied
and the rpcs were
to learn any information
the rpcs were then
learn any information about
rpcs were then divided
any information about the
were then divided acwe
information about the data
then divided acwe have
about the data being
divided acwe have shown
the data being aggregated
acwe have shown that
data being aggregated other
have shown that workloads
being aggregated other than
never be satisfied with
aggregated other than the
shown that workloads which
other than the final
that workloads which are
than the final result
workloads which are amenable
the final result of
which are amenable to
final result of the
are amenable to file
be satisfied with making
result of the computation
satisfied with making repeated
with making repeated phone
making repeated phone calls
repeated phone calls to
when combined with differential
level cording to which
phone calls to the
combined with differential privacy
calls to the same
with differential privacy techniques
cording to which period
to the same location
to which period of
the same location for
which period of the
to protect the aggregation
period of the trace
protect the aggregation results
of the trace they
the aggregation results themselves
the trace they terminated
group and the early
same location for half
and the early demise
trace they terminated in
the early demise of
location for half an
early demise of mach
for half an hour
demise of mach as
half an hour and
of mach as the
an hour and then
mach as the last
hour and then declaring
as the last of
and then declaring the
the last of the
then declaring the disappearance
last of the research
declaring the disappearance a
of the research operating
the disappearance a fact
the research operating systems
for each prefetching can
it can be used
each prefetching can achieve
can be used to
prefetching can achieve speedups
be used to ensure
no matter whether the
used to ensure that
matter whether the phone
can achieve speedups of
whether the phone was
to ensure that no
the phone was not
the operating system research
ensure that no query
operating system research world
phone was not picked
system research world was
that no query made
research world was at
was not picked up
world was at a
no query made to
was at a crossroads
query made to the
made to the system
to the system reveals
a busy tone was
the system reveals the
busy tone was heard
system reveals the contribution
tone was heard or
reveals the contribution of
was heard or the
the contribution of any
heard or the phone
contribution of any particular
intel based personal computers
of any particular node
or the phone was
based personal computers were
the phone was disconnected
personal computers were becoming
four quantities are calculated
our overlay network looks
computers were becoming ubiquitous
overlay network looks a
in practice one would
network looks a bit
practice one would work
looks a bit like
one would work to
the time spent queued
a bit like a
time spent queued for
bit like a gossip
spent queued for as
like a gossip infrastructure
queued for as much
would work to gain
and a myriad of
work to gain more
a myriad of unix
to gain more confidence
myriad of unix operating
for as much as
of unix operating systems
gain more confidence in
unix operating systems was
more confidence in such
operating systems was available
confidence in such a
systems was available for
in such a decision
was available for this
such a decision by
available for this platform
a decision by talking
decision by talking to
and can be used
by talking to the
can be used to
talking to the landlord
be used to run
eventually many moved to
used to run gossip
many moved to use
scaling memcache at facebook
moved to use linux
at bandwidths as low
the neighbors or others
bandwidths as low as
a popular architectural clone
neighbors or others that
popular architectural clone of
or others that may
with the key difference
architectural clone of the
others that may have
the key difference that
th usenix symposium on
that may have a
usenix symposium on networked
key difference that the
symposium on networked systems
may have a more
on networked systems design
difference that the random
networked systems design and
have a more informed
systems design and implementation
a more informed idea
clone of the traditional
more informed idea about
of the traditional unix
that the random peer
informed idea about the
the random peer selection
idea about the situation
random peer selection of
about the situation of
peer selection of gossip
at the computer science
prefetching both the rpc
the computer science department
both the rpc request
computer science department at
selection of gossip is
the situation of the
of gossip is replaced
situation of the person
gossip is replaced with
the rpc request and
of the person in
science department at cornell
is replaced with a
department at cornell university
replaced with a completely
at cornell university we
with a completely deterministic
cornell university we made
the person in question
university we made the
rpc request and reply
a completely deterministic function
we made the decision
made the decision to
the failure management described
the decision to conduct
failure management described in
decision to conduct our
and the time taken
to conduct our research
the time taken for
conduct our research on
management described in this
our research on windows
nodes are assigned virtual
research on windows nt
time taken for each
described in this paper
are assigned virtual ids
in this paper is
taken for each to
assigned virtual ids that
this paper is capable
virtual ids that are
paper is capable of
for each to be
is capable of following
by that time we
capable of following a
ids that are either
of following a similar
each to be carries
following a similar strategy
that time we had
that are either integers
time we had learned
are either integers or
to be carries a
we had learned enough
either integers or finite
if a process under
had learned enough from
a process under investigation
learned enough from the
be carries a small
integers or finite field
process under investigation is
or finite field elements
carries a small performance
enough from the early
under investigation is not
from the early design
investigation is not responding
and each node uses
is not responding it
a small performance overhead
the early design of
each node uses a
not responding it will
early design of windows
responding it will contact
node uses a function
it will contact the
even when performed at
will contact the operating
when performed at received
contact the operating system
uses a function based
design of windows nt
the operating system under
a function based on
operating system under which
of windows nt to
system under which the
function based on either
from the first to
based on either modular
the first to the
on either modular arithmetic
under which the process
windows nt to realize
which the process is
first to the last
either modular arithmetic or
the process is running
nt to realize that
to the last packet
modular arithmetic or finite
to realize that it
arithmetic or finite fields
realize that it was
or other nodes on
that it was a
or finite fields to
it was a major
other nodes on the
was a major step
this ignores the time
finite fields to compute
nodes on the same
fields to compute the
on the same sub
ignores the time the
a major step forward
to compute the order
major step forward in
the time the lowest
net to help reach
time the lowest priority
to help reach a
step forward in operating
compute the order in
help reach a decision
forward in operating system
reach a decision in
which can reduce its
in operating system design
the order in which
a decision in which
can reduce its effectiveness
order in which it
decision in which one
in which it should
reduce its effectiveness for
in which one can
its effectiveness for fast
which one can have
effectiveness for fast lin
one can have greater
it would provide us
which it should communicate
can have greater confidence
it should communicate with
would provide us with
should communicate with the
spent at the server
communicate with the other
at the server servicing
with the other nodes
the server servicing the
provide us with a
server servicing the rpc
us with a platform
most distributed systems in
we construct this function
with a platform on
construct this function to
distributed systems in use
this function to ensure
systems in use today
function to ensure that
in use today deal
to ensure that the
use today deal with
ensure that the network
a platform on which
that the network is
trip time ear scan
the network is optimally
time ear scan workloads
network is optimally robust
platform on which we
is optimally robust and
way delivery latency against
optimally robust and efficient
delivery latency against loss
on which we could
latency against loss rate
today deal with failure
it is possible to
which we could perform
is possible to construct
converging in logarithmic time
possible to construct combination
in logarithmic time and
to construct combination of
logarithmic time and tolerating
deal with failure of
time and tolerating message
with failure of nodes
and tolerating message failures
construct combination of file
we could perform research
combination of file between
failure of nodes or
tolerating message failures with
of nodes or networks
message failures with minimal
nodes or networks in
failures with minimal delay
could perform research more
of file between the
perform research more effectively
file between the client
transactional consistency and automatic
or networks in some
consistency and automatic management
networks in some way
and automatic management in
between the client and
research more effectively and
key cryptography to encrypt
automatic management in an
cryptography to encrypt messages
the client and the
more effectively and it
in general the problem
management in an application
client and the server
effectively and it would
general the problem is
in an application data
ensuring that the the
an application data cache
the problem is detected
and it would allows
that the the system
problem is detected in
the the system operator
it would allows us
the system operator cannot
is detected in the
system operator cannot infer
would allows us to
operator cannot infer anything
detected in the communication
cannot infer anything about
in the communication subsystem
infer anything about the
th usenix symposium on
the communication subsystem where
but these quantities are
communication subsystem where session
allows us to focus
usenix symposium on operating
anything about the data
these quantities are small
subsystem where session or
quantities are small groups
symposium on operating systems
are small groups and
on operating systems design
where session or transport
operating systems design and
us to focus on
systems design and implementation
small groups and a
about the data being
groups and a workload
the data being aggregated
session or transport protocols
data being aggregated by
and a workload for
to focus on the
a workload for which
focus on the future
workload for which prefetching
on the future directions
for which prefetching can
the future directions without
which prefetching can significantly
future directions without having
prefetching can significantly compared
directions without having to
can significantly compared to
without having to worry
significantly compared to the
having to worry whether
or transport protocols are
to worry whether the
compared to the other
being aggregated by observing
transport protocols are unable
aggregated by observing network
to the other costs
worry whether the operating
protocols are unable to
by observing network traffic
are unable to make
whether the operating system
unable to make progress
the operating system was
to make progress because
operating system was capable
these values are added
make progress because of
system was capable of
progress because of the
was capable of supporting
because of the lack
even the communication pattern
values are added up
the communication pattern is
are added up for
communication pattern is completely
added up for each
pattern is completely predictable
up for each degrade
is completely predictable and
for each degrade performance
completely predictable and hence
capable of supporting innovation
predictable and hence reveals
of the lack of
and hence reveals nothing
the lack of response
lack of response from
of response from remote
of the rpcs within
response from remote nodes
by now our complete
the rpcs within a
now our complete educational
malicious nodes cannot significantly
rpcs within a particular
nodes cannot significantly deviate
traditionally packets are being
cannot significantly deviate from
packets are being retransmitted
significantly deviate from correct
are being retransmitted after
deviate from correct behavior
our complete educational operation
being retransmitted after a
within a particular period
from correct behavior without
retransmitted after a time
correct behavior without being
complete educational operation and
behavior without being detected
educational operation and the
operation and the majority
and the results are
out period and after
and the majority of
period and after a
the majority of our
and after a retry
majority of our research
after a retry threshold
of our research projects
a retry threshold is
our research projects have
retry threshold is reached
research projects have switched
threshold is reached the
projects have switched to
is reached the remote
have switched to using
so the network encourages
reached the remote destination
the results are shown
the remote destination is
the network encourages the
remote destination is marked
network encourages the operator
switched to using windows
encourages the operator to
results are shown within
destination is marked as
to using windows nt
is marked as unreachable
are shown within the
the operator to behave
shown within the constraints
operator to behave correctly
within the constraints imposed
some systems inject additional
fast iterative graph computation
the constraints imposed by
systems inject additional packets
iterative graph computation with
and it even tolerates
graph computation with block
constraints imposed by our
inject additional packets into
it even tolerates byzantine
additional packets into the
even tolerates byzantine failure
packets into the data
tolerates byzantine failure by
computation with block updates
byzantine failure by a
imposed by our file
into the data stream
as it now officially
failure by a small
it now officially has
by our file group
the data stream to
by a small minority
of the vldb endowment
a small minority of
our file group representa
now officially has been
data stream to ensure
small minority of clients
officially has been christened
stream to ensure timely
to ensure timely detection
ensure timely detection of
timely detection of failures
this ensures that important
detection of failures at
ensures that important queries
of failures at moments
that important queries will
failures at moments when
important queries will not
at moments when the
queries will not be
moments when the traffic
will not be corrupted
when the traffic is
not be corrupted or
the traffic is low
be corrupted or blocked
traffic is low or
corrupted or blocked by
is low or unidirectional
or blocked by compromised
blocked by compromised devices
the ride has been
ride has been rocky
has been rocky and
and that an adversary
been rocky and fascinating
that an adversary cannot
an adversary cannot compromise
adversary cannot compromise the
cannot compromise the privacy
compromise the privacy of
the privacy of client
privacy of client data
of client data by
in this article i
client data by gaining
this article i want
data by gaining control
article i want to
update delay as seen
by gaining control of
i want to share
gaining control of a
delay as seen by
want to share some
as seen by individual
control of a few
to share some of
of a few devices
share some of the
seen by individual processes
a few devices in
by individual processes during
few devices in the
expect the application to
devices in the system
individual processes during persistent
some of the reasoning
processes during persistent link
the application to handle
during persistent link congestion
of the reasoning behind
application to handle the
persistent link congestion node
the reasoning behind our
to handle the failure
reasoning behind our choice
handle the failure management
behind our choice for
the failure management as
our choice for windows
failure management as the
choice for windows nt
management as the support
the main conclusion we
for windows nt and
as the support system
windows nt and to
the support system does
nt and to share
support system does not
and to share some
system does not contain
main conclusion we draw
updates on upstream and
does not contain any
on upstream and downstream
not contain any fault
upstream and downstream fifo
to share some our
and downstream fifo channels
conclusion we draw from
contain any fault management
share some our experiences
ro bert orma ndi
some our experiences with
we draw from the
our experiences with windows
often these systems cannot
draw from the test
istva n hegedu s
these systems cannot distinguish
from the test cases
systems cannot distinguish between
concurrency control and recovery
cannot distinguish between process
experiences with windows nt
the test cases exhibitthe
with windows nt as
control and recovery in
windows nt as a
and ma rk jelasity
test cases exhibitthe graphs
nt as a research
and recovery in database
as a research platform
node or network failure
cases exhibitthe graphs show
recovery in database systems
exhibitthe graphs show how
gossip learning with linear
the mechanisms used to
os research as religion
mechanisms used to detect
graphs show how priorities
used to detect failure
research as religion the
show how priorities affect
as religion the biggest
learning with linear models
religion the biggest hurdle
with linear models on
the biggest hurdle in
linear models on fully
biggest hurdle in starting
models on fully distributed
hurdle in starting research
on fully distributed this
to detect failure do
how priorities affect rpcs
in starting research on
priorities affect rpcs and
starting research on windows
fully distributed this work
research on windows nt
detect failure do not
distributed this work was
on windows nt was
affect rpcs and how
this work was supported
rpcs and how prefetching
windows nt was not
and how prefetching a
nt was not technical
failure do not adapt
how prefetching a prefetch
do not adapt to
prefetching a prefetch penalty
not adapt to changing
by a grant from
adapt to changing network
a prefetch penalty is
it was to overcome
a grant from the
to changing network conditions
prefetch penalty is that
was to overcome the
grant from the nsf
penalty is that the
to overcome the skepticism
is that the implementation
overcome the skepticism of
from the nsf data
making it almost impossible
that the implementation could
it almost impossible to
the implementation could be
the skepticism of our
implementation could be im
almost impossible to use
skepticism of our colleagues
practice and exsmart grids
impossible to use these
of our colleagues who
and exsmart grids program
to use these systems
our colleagues who were
ing changes mfs behaviour
use these systems unmodified
colleagues who were convinced
these systems unmodified in
who were convinced that
systems unmodified in wide
in all three time
unmodified in wide area
all three time periods
were convinced that it
in wide area systems
convinced that it would
wide area systems without
that it would not
more time proved to
the dynamics of viral
time proved to incorporate
dynamics of viral marketing
it would not be
area systems without resorting
would not be possible
proved to incorporate a
systems without resorting to
not be possible to
acm transactions on the
be possible to use
transactions on the web
without resorting to heavy
possible to use windows
to incorporate a mechanism
to use windows nt
incorporate a mechanism to
use windows nt as
a mechanism to inhibit
windows nt as a
mechanism to inhibit prefetching
resorting to heavy weight
nt as a good
to heavy weight solutions
as a good platform
heavy weight solutions like
a good platform for
the is spent on
weight solutions like using
is spent on rpcs
solutions like using a
spent on rpcs to
like using a tcp
good platform for research
using a tcp connection
on rpcs to fetch
packet delivery latencies throughput
a tcp connection as
rpcs to fetch file
the predictions were fascinating
tcp connection as the
to fetch file attributes
connection as the preferred
fetch file attributes with
as the preferred transport
file attributes with prefetching
the preferred transport method
attributes with prefetching enabled
preferred transport method for
we would turn into
transport method for each
with prefetching enabled current
method for each rpc
would turn into a
for each rpc call
turn into a bug
prefetching enabled current prefetching
enabled current prefetching algorithm
current prefetching algorithm does
prefetching algorithm does not
algorithm does not correlate
does not correlate file
inconsistency window against gossip
not correlate file accesses
window against gossip rate
microsoft would sue the
against gossip rate at
would sue the department
gossip rate at the
sue the department for
especially those designed to
the department for every
those designed to support
department for every technical
designed to support high
rate at the failed
for every technical publication
at the failed node
correlate file accesses with
file accesses with than
antony rowstron and peter
accesses with than without
rowstron and peter druschel
microsoft would hide the
would hide the pieces
hide the pieces of
since the time to
management in a more
the pieces of buggy
the time to receive
pieces of buggy code
time to receive a
in a more integrated
of buggy code from
a more integrated way
to receive a fetch
buggy code from us
code from us or
and routing for large
from us or bill
many of these systems
attributes request the processes
of these systems are
us or bill gates
these systems are structured
or bill gates would
systems are structured as
bill gates would personally
are structured as groups
gates would personally tell
structured as groups of
would personally tell us
as groups of cooperating
personally tell us where
mbps flow alongside on
groups of cooperating processes
request the processes which
of cooperating processes using
the processes which make
cooperating processes using some
flow alongside on the
processes using some form
alongside on the same
tell us where and
on the same link
processes which make them
measurement and analysis of
us where and how
and analysis of online
where and how we
analysis of online social
using some form of
but if this were
some form of group
of online social networks
form of group membership
time between node failure
and how we should
between node failure and
how we should do
if this were done
in proceedings of the
node failure and rejoin
we should do our
failure and rejoin as
should do our research
the same link to
detection to be able
two changes or reply
to be able to
and rejoin as number
th acm sigcomm conference
same link to simulate
acm sigcomm conference on
link to simulate a
sigcomm conference on internet
to simulate a real
conference on internet measurement
be able to reach
changes or reply is
rejoin as number of
able to reach consensus
as number of consecutive
time stream combined with
number of consecutive updates
or reply is negligible
of consecutive updates missed
stream combined with other
various methods are used
combined with other inter
consecutive updates missed by
updates missed by the
missed by the victim
the operating systems research
the increased time is
of which fault monitors
increased time is due
operating systems research community
by the victim node
time is due to
systems research community has
is due to a
research community has not
due to a greater
community has not remained
to a greater queue
has not remained untouched
not remained untouched by
remained untouched by the
untouched by the market
by the market place
the market place rivalry
shows the average delivery
market place rivalry between
the average delivery latency
rpc times at intermediate
average delivery latency of
place rivalry between microsoft
times at intermediate bandwidth
rivalry between microsoft and
between microsoft and the
microsoft and the group
and the group lead
the group lead by
group lead by sun
level packets in the
lead by sun microsystems
it is even more
is even more unfortunate
even more unfortunate that
more unfortunate that the
unfortunate that the positions
correctness of a gossip
that the positions taken
of a gossip based
the positions taken are
a gossip based membership
positions taken are not
are the most popular
gossip based membership protocol
as loss rates go
taken are not based
loss rates go up
are not based on
not based on intellectual
however in each of
in proceedings of the
based on intellectual deliberation
proceedings of the twenty
in each of these
on intellectual deliberation but
each of these systems
sampling from large graphs
intellectual deliberation but purely
of these systems the
deliberation but purely on
fourth annual acm sympo
but purely on emotional
these systems the failure
purely on emotional grounds
in proceedings of the
systems the failure management
the failure management is
failure management is an
many see microsoft operating
management is an integral
see microsoft operating systems
is an integral part
microsoft operating systems as
th acm sigkdd international
operating systems as the
an integral part of
systems as the evil
acm sigkdd international conference
as the evil empire
integral part of the
sigkdd international conference on
part of the particular
international conference on knowledge
of the particular membership
conference on knowledge discovery
the particular membership or
out to squash every
on knowledge discovery and
to squash every attempt
particular membership or transport
squash every attempt at
knowledge discovery and data
every attempt at innovation
membership or transport system
shows the same scenario
or transport system and
discovery and data mining
transport system and not
the same scenario with
system and not available
and ma rk jelasity
and not available for
same scenario with a
not available for general
and working with them
available for general use
scenario with a constant
working with them is
with a constant uniformly
with them is seen
a private framework for
them is seen as
a constant uniformly random
is seen as collaboration
although some research groups
private framework for distributed
constant uniformly random loss
seen as collaboration with
uniformly random loss rate
framework for distributed comsium
random loss rate of
as collaboration with the
for distributed comsium on
collaboration with the enemy
distributed comsium on principles
with the enemy of
comsium on principles of
the enemy of free
on principles of distributed
enemy of free academic
principles of distributed computing
of free academic speech
the pros and cons
pros and cons are
and cons are often
cons are often discussed
are often discussed with
often discussed with a
discussed with a righteous
with a righteous zeal
a righteous zeal that
righteous zeal that is
zeal that is frightening
maelstrom s delivery latency
s delivery latency is
delivery latency is almost
latency is almost exactly
our own experiences with
is almost exactly equal
own experiences with microsoft
are focusing on wide
almost exactly equal to
focusing on wide area
experiences with microsoft can
on wide area systems
exactly equal to the
with microsoft can only
equal to the one
microsoft can only be
can only be described
only be described as
be described as extremely
the majority of the
described as extremely positive
way latency on the
majority of the existing
latency on the link
of the existing failure
the existing failure detectors
existing failure detectors are
never before have we
failure detectors are not
before have we had
detectors are not suitable
have we had such
are not suitable for
ip takes more than
we had such a
not suitable for use
takes more than twice
suitable for use in
more than twice as
for use in large
than twice as long
use in large scale
twice as long once
in large scale systems
as long once one
had such a positive
such a positive relation
a positive relation with
positive relation with a
relation with a vendor
because of their inflexibility
way latencies go past
of their inflexibility or
their inflexibility or the
inflexibility or the simplicity
without any pressure from
or the simplicity of
any pressure from their
the simplicity of their
pressure from their side
simplicity of their assumptions
don t settle for
we can only conclude
t settle for eventual
can only conclude that
only conclude that the
building a failure detector
scalable causal consistency for
conclude that the reasons
causal consistency for wide
a failure detector that
that the reasons for
the reasons for the
failure detector that is
reasons for the controversy
area storage with cops
detector that is not
for the controversy must
that is not an
the controversy must be
controversy must be found
is not an integral
must be found in
not an integral part
be found in a
found in a sort
an integral part of
in a sort of
integral part of the
a sort of traditional
sort of traditional emotional
part of the communication
of traditional emotional bonding
rd acm symposium on
of the communication architecture
acm symposium on operating
traditional emotional bonding of
symposium on operating systems
the communication architecture permits
on operating systems principles
emotional bonding of academia
communication architecture permits the
bonding of academia with
of academia with the
architecture permits the implementation
academia with the underdog
permits the implementation of
with the underdog and
the underdog and that
the implementation of a
underdog and that no
and that no real
ip one way link
implementation of a collection
one way link latency
that no real experiences
of a collection of
no real experiences drive
real experiences drive the
a collection of failure
experiences drive the discussion
u trsu t u
collection of failure detection
trsu t u trsu
of failure detection techniques
uniform node sampling service
t u trsu t
node sampling service robust
failure detection techniques and
sampling service robust against
u trsu t utrsut
gaining knowledge the foremost
detection techniques and support
service robust against collusions
knowledge the foremost reasons
techniques and support for
robust against collusions of
the foremost reasons why
and support for failure
against collusions of malicious
foremost reasons why unix
request queued request send
reasons why unix was
collusions of malicious nodes
support for failure detection
queued request send reply
for failure detection methods
why unix was such
failure detection methods of
unix was such a
detection methods of varying
request send reply queued
was such a powerhouse
methods of varying levels
send reply queued reply
split with regular buffers
of varying levels of
such a powerhouse in
varying levels of complexity
reply queued reply send
a powerhouse in operating
levels of complexity from
powerhouse in operating system
of complexity from which
in operating system research
complexity from which the
operating system research was
from which the system
gossip chain inconsistency window
system research was the
which the system designer
end with large buffers
the system designer can
ifip international conference on
system designer can choose
international conference on dependable
designer can choose to
conference on dependable systems
can choose to match
on dependable systems and
research was the great
dependable systems and networks
transactional storage for geo
was the great amount
choose to match the
the great amount of
to match the system
great amount of knowledge
match the system requirements
amount of knowledge accumulated
of knowledge accumulated over
knowledge accumulated over the
and outperforms it with
accumulated over the years
outperforms it with regular
over the years about
it with regular buffers
the years about the
the failure management service
years about the internal
failure management service consists
about the internal operation
management service consists of
the internal operation of
service consists of three
internal operation of the
consists of three functional
operation of the operating
of three functional modules
of the operating system
rd acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
many of us had
of us had become
latency metrics to measure
us had become gurus
metrics to measure the
had become gurus about
to measure the latency
become gurus about some
measure the latency effects
gurus about some part
the latency effects of
about some part of
latency effects of tcp
some part of the
part of the os
of the os kernel
the os kernel and
os kernel and could
kernel and could recite
and could recite the
could recite the fields
recite the fields of
a library that implements
the fields of an
library that implements simple
fields of an i
that implements simple failure
implements simple failure management
simple failure management functionality
failure management functionality and
node structure at late
management functionality and provide
structure at late night
mbps stream between two
functionality and provide the
at late night meetings
and provide the api
stream between two nodes
provide the api to
between two nodes over
late night meetings or
the api to the
two nodes over a
night meetings or discuss
api to the complete
meetings or discuss which
to the complete service
or discuss which data
discuss which data structures
which data structures to
data structures to modify
a service implementing per
structures to modify to
service implementing per node
to modify to add
implementing per node failure
modify to add a
per node failure management
byzantine resilient random membership
to add a new
resilient random membership sampling
add a new protocol
a new protocol at
new protocol at runtime
combining fault management with
protocol at runtime over
in proceedings of the
at runtime over an
proceedings of the twenty
runtime over an early
fault management with other
over an early morning
management with other local
an early morning cappuccino
with other local nodes
seventh acm symposium on
other local nodes to
acm symposium on principles
local nodes to exploit
symposium on principles of
nodes to exploit locality
on principles of distributed
to exploit locality of
principles of distributed computing
many of us were
exploit locality of communication
locality of communication and
of us were and
of communication and failure
plots delivery latency against
communication and failure patterns
delivery latency against message
us were and still
latency against message identifier
were and still are
an inquiry service closely
and still are afraid
inquiry service closely coupled
a key point is
still are afraid to
key point is that
service closely coupled with
are afraid to leave
replicated systems fast as
closely coupled with the
point is that we
coupled with the operating
afraid to leave this
with the operating system
is that we are
the operating system which
to leave this bastion
systems fast as possible
that we are plotting
leave this bastion of
we are plotting the
this bastion of safety
are plotting the delivery
rpc times at high
bastion of safety behind
plotting the delivery latency
provides information about the
of safety behind and
the delivery latency of
times at high bandwidth
delivery latency of all
safety behind and trade
information about the state
latency of all packets
about the state of
behind and trade it
the state of local
inconsistency window against gossip
state of local participating
window against gossip rate
of local participating processes
against gossip rate for
th usenix symposium on
gossip rate for the
not just lost ones
and trade it in
usenix symposium on operating
rate for the whole
symposium on operating systems
trade it in for
on operating systems design
for the whole chain
operating systems design and
the most fundamental operation
systems design and implementation
the spikes in latency
it in for working
most fundamental operation offered
spikes in latency are
in for working on
fundamental operation offered by
in latency are triggered
for working on an
operation offered by a
working on an operating
latency are triggered by
on an operating system
are triggered by losses
an operating system that
offered by a failure
triggered by losses that
operating system that at
by a failure detection
by losses that lead
system that at first
losses that lead to
a failure detection service
that lead to packets
that at first sight
lead to packets piling
failure detection service is
to packets piling up
at first sight had
packets piling up both
detection service is that
piling up both at
first sight had nothing
up both at the
service is that of
both at the receiver
sight had nothing in
at the receiver and
is that of the
the receiver and the
had nothing in common
receiver and the sender
nothing in common with
that of the investigation
in common with our
of the investigation of
common with our beloved
the investigation of a
with our beloved unix
investigation of a suspected
of a suspected process
and our annotated version
ip delays correctly received
our annotated version of
delays correctly received packets
annotated version of the
to make use of
version of the unix
correctly received packets at
of the unix version
make use of this
received packets at the
time between node failure
packets at the receiver
use of this operation
at the receiver while
between node failure and
of this operation it
the receiver while waiting
node failure and rejoin
receiver while waiting for
this operation it is
while waiting for missing
in proceedings of the
failure and rejoin as
proceedings of the acm
waiting for missing packets
of the acm sigcomm
and rejoin as number
operation it is not
rejoin as number of
for missing packets sequenced
as number of consecutive
it is not necessary
number of consecutive updates
missing packets sequenced earlier
of consecutive updates missed
is not necessary for
consecutive updates missed by
wouldn t be of
not necessary for either
updates missed by the
packets sequenced earlier by
t be of much
sequenced earlier by the
missed by the victim
earlier by the sender
be of much help
necessary for either the
by the victim node
of much help any
for either the local
much help any more
either the local or
it also delays packets
help any more either
the local or remote
also delays packets at
any more either it
local or remote process
delays packets at the
more either it took
or remote process to
packets at the sender
either it took more
remote process to run
at the sender when
it took more then
process to run any
the sender when it
to run any of
took more then a
run any of the
sender when it cuts
more then a year
when it cuts down
combining acid and base
it cuts down on
acid and base in
cuts down on the
and base in a
any of the heartbeat
base in a distributed
down on the sending
in a distributed database
of the heartbeat or
then a year of
the heartbeat or polling
on the sending window
a year of immersion
heartbeat or polling patterns
year of immersion in
the sending window size
of immersion in the
sending window size in
window size in response
immersion in the technology
size in response to
in the technology to
in response to the
the technology to get
th usenix symposium on
technology to get a
usenix symposium on operating
the reasons that the
symposium on operating systems
to get a level
reasons that the local
on operating systems design
response to the loss
operating systems design and
to the loss events
systems design and implementation
that the local process
get a level where
the local process began
a level where i
local process began to
level where i felt
process began to suspect
where i felt confident
began to suspect the
i felt confident again
the delays caused by
felt confident again to
to suspect the remote
confident again to direct
delays caused by these
again to direct others
caused by these two
suspect the remote process
by these two mechanisms
to direct others in
these two mechanisms are
direct others in our
two mechanisms are illustrated
others in our research
the remote process are
in our research group
inconsistency window against the
remote process are not
mechanisms are illustrated in
process are not of
are illustrated in figure
are not of any
window against the ratio
not of any importance
against the ratio between
of any importance to
together with the overall
any importance to the
the ratio between injection
importance to the failure
ratio between injection rate
to the failure management
with the overall organizational
between injection rate and
injection rate and gossip
the overall organizational issues
rate and gossip rate
overall organizational issues i
where single packet losses
organizational issues i think
single packet losses cause
issues i think we
packet losses cause spikes
i think we lost
losses cause spikes in
think we lost one
cause spikes in delivery
we lost one and
spikes in delivery latency
lost one and a
in delivery latency that
one and a half
delivery latency that last
and a half year
latency that last for
a half year worth
that last for hundreds
half year worth of
last for hundreds of
year worth of research
for hundreds of packets
worth of research time
of research time to
research time to make
time to make the
to make the switch
different update injection delay
make the switch in
the maelstrom configuration used
the switch in the
maelstrom configuration used is
switch in the most
configuration used is r
in the most fundamental
the most fundamental way
the process at address
process at address is
at address is investigated
others are making the
address is investigated and
are making the switch
s overload by dropping
making the switch more
is investigated and a
the switch more gradually
overload by dropping updates
switch more gradually and
investigated and a report
more gradually and are
by dropping updates on
gradually and are experiencing
and a report is
dropping updates on its
a report is returned
epidemic algorithms for replicated
report is returned within
algorithms for replicated database
is returned within the
updates on its inbound
returned within the deadline
for replicated database maintenance
on its inbound and
within the deadline set
and are experiencing a
the deadline set by
its inbound and outbound
deadline set by the
are experiencing a more
set by the local
in proceedings of the
by the local process
proceedings of the sixth
inbound and outbound fifo
of the sixth annual
experiencing a more smooth
the sixth annual acm
a more smooth transition
sixth annual acm symposium
and outbound fifo channels
the local process does
annual acm symposium on
a shared log design
acm symposium on principles
shared log design for
symposium on principles of
log design for flash
on principles of distributed
all operation systems are
principles of distributed computing
outbound fifo channels according
operation systems are created
local process does not
design for flash clusters
fifo channels according to
systems are created equal
process does not have
channels according to a
are created equal our
does not have to
according to a random
created equal our experiences
not have to wait
to a random distribution
equal our experiences with
have to wait for
a random distribution throughout
th usenix symposium on
random distribution throughout the
usenix symposium on networked
our experiences with switching
symposium on networked systems
distribution throughout the first
experiences with switching to
on networked systems design
to wait for the
networked systems design and
with switching to windows
systems design and implementation
wait for the investigation
throughout the first three
switching to windows nt
the first three quarters
for the investigation to
first three quarters of
to windows nt have
the investigation to finish
three quarters of the
windows nt have made
quarters of the experiment
investigation to finish but
nt have made us
to finish but can
have made us somewhat
finish but can make
made us somewhat more
but can make use
us somewhat more philosophical
can make use of
somewhat more philosophical about
make use of the
more philosophical about the
use of the asynch
philosophical about the nature
of the asynch interface
about the nature of
the asynch interface to
the nature of operation
nature of operation systems
asynch interface to collect
interface to collect the
to collect the result
collect the result at
the result at a
result at a later
the most fundamental observation
at a later moment
most fundamental observation is
fundamental observation is that
when stripped to their
the report contains information
stripped to their core
report contains information on
contains information on whether
information on whether the
all operating systems are
on whether the remote
operating systems are equal
whether the remote node
the remote node was
remote node was reachable
node was reachable within
the functionality of the
was reachable within the
functionality of the windows
reachable within the deadline
of the windows nt
within the deadline and
the windows nt kernel
the deadline and whether
windows nt kernel is
deadline and whether the
nt kernel is just
and whether the process
kernel is just as
whether the process under
is just as all
the process under investigation
just as all other
process under investigation was
as all other kernels
under investigation was still
investigation was still present
was still present at
still present at the
present at the host
it abstracts the hardware
abstracts the hardware in
the hardware in the
hardware in the usual
in the usual sense
if the mode parameter
the mode parameter was
mode parameter was used
parameter was used to
was used to request
used to request a
to request a more
request a more detailed
process and threads hide
a more detailed remote
and threads hide the
more detailed remote reporting
threads hide the cpu
and we report on
hide the cpu complexity
process checkpoint information is
checkpoint information is returned
information is returned or
is returned or the
returned or the remote
file systems and files
or the remote process
systems and files hide
the remote process is
and files hide the
remote process is interrupted
files hide the storage
process is interrupted to
hide the storage devices
is interrupted to provide
interrupted to provide status
to provide status information
in lecture notes in
lecture notes in computer
protocols hide the network
notes in computer science
updates that were initially
see the section on
that were initially dropped
the section on os
section on os integration
shared memory and messages
were initially dropped and
memory and messages are
initially dropped and eventually
and messages are used
messages are used to
dropped and eventually made
are used to allow
used to allow sharing
and eventually made their
to allow sharing of
allow sharing of resources
if the node was
eventually made their way
the node was not
made their way through
node was not reachable
their way through gossip
was not reachable and
what we often call
not reachable and the
way through gossip could
reachable and the local
we often call operating
and the local process
through gossip could later
the local process has
often call operating systems
local process has requested
gossip could later be
process has requested extensive
call operating systems has
has requested extensive investigation
could later be sent
operating systems has nothing
later be sent via
systems has nothing to
be sent via fifo
has nothing to do
sent via fifo channels
the failure investigator will
nothing to do with
via fifo channels as
to do with the
failure investigator will try
do with the real
fifo channels as shown
with the real core
investigator will try to
the real core of
channels as shown by
real core of the
will try to contact
core of the system
try to contact a
as shown by the
to contact a failure
shown by the increasingly
contact a failure manager
by the increasingly large
a failure manager at
the increasingly large density
failure manager at the
increasingly large density of
manager at the node
unix for most of
large density of dark
for most of us
most of us is
of us is a
us is a collection
is a collection of
a collection of shell
collection of shell commands
of shell commands and
net or within its
shell commands and development
or within its administrative
commands and development libraries
plots closer to the
within its administrative domain
closer to the tail
its administrative domain which
to the tail of
administrative domain which should
the tail of the
domain which should be
tail of the chain
david korn s uwin
which should be able
should be able to
be able to give
able to give a
as before note that
to give a more
before note that the
give a more conclusive
note that the yaxes
a more conclusive answer
that the yaxes have
more conclusive answer about
the yaxes have different
conclusive answer about the
yaxes have different scales
answer about the node
have different scales to
different scales to observe
scales to observe the
to observe the delays
and softway s interix
observe the delays better
s failure to respond
the figures show that
if network failure is
figures show that even
network failure is the
show that even for
failure is the cause
that even for a
is the cause of
even for a gossip
the cause of the
for a gossip rate
cause of the loss
a gossip rate half
of the loss of
gossip rate half the
the loss of connectivity
rate half the injection
both show that you
half the injection rate
show that you can
that you can give
you can give users
the report will indicate
can give users and
report will indicate which
recall that this is
give users and developers
that this is the
will indicate which part
this is the rate
users and developers a
is the rate at
indicate which part of
the rate at which
which part of the
rate at which digests
part of the path
of the path is
the path is reachable
path is reachable and
is reachable and where
reachable and where the
and where the suspected
are exchanged between two
exchanged between two or
between two or more
two or more processes
unix experience including x
the epidemics could deliver
epidemics could deliver messages
if the failure investigator
could deliver messages with
the failure investigator is
deliver messages with a
failure investigator is configured
messages with a delay
investigator is configured with
with a delay of
is configured with alternative
a delay of about
configured with alternative outgoing
while running on an
with alternative outgoing paths
running on an windows
on an windows nt
percentage of packets recovered
an windows nt kernel
these paths are probed
paths are probed to
windows nt for most
nt for most of
are probed to see
for most of us
probed to see if
most of us is
to see if it
of us is the
see if it is
us is the windows
if it is possible
is the windows explorer
it is possible to
the windows explorer and
is possible to circumvent
windows explorer and point
possible to circumvent the
to circumvent the network
circumvent the network failure
the network failure and
network failure and in
failure and in such
and in such a
s for the rest
in such a way
for the rest of
such a way collect
the rest of the
a way collect information
rest of the chain
and according to microsoft
of the chain during
according to microsoft it
the chain during a
way collect information about
chain during a congestion
relatively prime interleaves offer
during a congestion that
collect information about the
a congestion that took
information about the remote
to microsoft it includes
prime interleaves offer better
about the remote process
interleaves offer better performance
microsoft it includes a
it includes a web
includes a web browser
the report contains information
report contains information about
contains information about the
although i have not
information about the results
the plot also shows
about the results of
plot also shows that
the results of these
i have not seen
results of these probes
also shows that delays
have not seen a
shows that delays increased
not seen a complete
that delays increased with
seen a complete re
delays increased with time
early triggers many systems
triggers many systems find
many systems find it
implementation of the explorer
therefore if congestion may
of the explorer for
if congestion may span
the explorer for unix
systems find it desirable
congestion may span large
find it desirable to
may span large periods
it desirable to detect
span large periods of
based fast overlay topology
desirable to detect failure
large periods of time
fast overlay topology construction
to detect failure of
detect failure of remote
failure of remote processes
compatible libraries from mainsoft
of remote processes even
the gossip rate must
remote processes even if
gossip rate must be
processes even if there
rate must be carefully
even if there is
must be carefully tuned
if there is no
be carefully tuned to
there is no data
used in the port
is no data exchange
carefully tuned to compensate
no data exchange actually
in the port of
data exchange actually under
tuned to compensate for
exchange actually under way
the port of internet
to compensate for the
port of internet explorer
compensate for the losses
of internet explorer show
for the losses induced
internet explorer show that
the losses induced by
systems are free to
explorer show that you
losses induced by the
show that you do
induced by the congested
are free to implement
that you do not
by the congested tcp
free to implement whatever
the congested tcp channels
you do not need
to implement whatever scheme
do not need a
implement whatever scheme they
not need a windows
whatever scheme they find
need a windows nt
scheme they find appropriate
the second round of
a windows nt kernel
they find appropriate and
windows nt kernel to
second round of experiments
nt kernel to get
find appropriate and use
kernel to get to
round of experiments quantified
to get to the
appropriate and use the
get to the same
of experiments quantified the
to the same user
and use the failure
the same user experience
experiments quantified the average
use the failure investigator
quantified the average and
the failure investigator from
the average and maximum
failure investigator from the
average and maximum inconsistency
many see the rich
and maximum inconsistency window
see the rich win
investigator from the previous
maximum inconsistency window for
from the previous section
inconsistency window for a
the previous section to
window for a service
previous section to handle
section to handle the
to handle the suspicions
programming interface as the
interface as the native
as the native programming
achieving serializability with low
the native programming model
serializability with low latency
or they can make
with low latency in
native programming model for
low latency in geodistributed
programming model for windows
latency in geodistributed storage
model for windows nt
they can make use
in geodistributed storage systems
can make use of
under various update injection
make use of two
various update injection rates
and although most windows
update injection rates and
use of two standardized
injection rates and gossip
although most windows applications
rates and gossip rates
of two standardized schemes
and gossip rates respectively
most windows applications are
in proceedings of the
windows applications are designed
two standardized schemes implemented
applications are designed using
standardized schemes implemented by
are designed using this
schemes implemented by the
we define the inconsistency
designed using this interface
implemented by the failure
define the inconsistency window
by the failure manager
the inconsistency window as
the failure manager library
th acm symposium on
it is not the
inconsistency window as the
is not the windows
acm symposium on operating
not the windows nt
window as the time
the first scheme uses
the windows nt kernel
first scheme uses a
windows nt kernel interface
scheme uses a heartbeat
and maarten van steen
uses a heartbeat mechanism
as the time interval
symposium on operating systems
the time interval during
on operating systems principles
time interval during which
almost no applications are
interval during which queries
which sends out i
during which queries against
no applications are built
which queries against the
applications are built using
queries against the service
are built using the
against the service return
built using the kernel
the service return a
using the kernel interface
service return a stale
return a stale value
alive messages to a
messages to a group
to a group of
and you would have
a group of processes
you would have a
group of processes using
would have a hard
of processes using multiple
have a hard time
processes using multiple point
shows that the inconsistency
a hard time finding
that the inconsistency window
hard time finding the
the inconsistency window grows
time finding the complete
inconsistency window grows slowly
finding the complete documentation
window grows slowly as
the complete documentation for
point messages or a
complete documentation for all
messages or a single
documentation for all the
or a single ip
for all the system
grows slowly as the
all the system calls
slowly as the gap
as the gap between
the gap between the
gap between the update
describing windows nt as
between the update injection
windows nt as a
the update injection rate
each process keeps track
update injection rate and
nt as a micro
process keeps track of
injection rate and the
keeps track of the
rate and the gossip
track of the reception
and the gossip rate
of the reception times
the gossip rate widens
the reception times of
reception times of messages
times of messages and
of messages and if
the graph s x
messages and if a
as the kernel is
graph s x axis
the kernel is certainly
and if a number
kernel is certainly not
s x axis represents
is certainly not small
if a number of
x axis represents the
a number of consecutive
axis represents the ratio
number of consecutive heartbeats
represents the ratio between
of consecutive heartbeats from
the ratio between the
but it is does
ratio between the update
consecutive heartbeats from a
it is does describe
between the update injection
heartbeats from a destination
is does describe the
from a destination is
the update injection rate
does describe the abstraction
update injection rate and
a destination is missed
injection rate and gossip
destination is missed a
rate and gossip rate
describe the abstraction correctly
is missed a suspicion
missed a suspicion is
the abstraction correctly in
a suspicion is raised
abstraction correctly in which
correctly in which the
in which the kernel
which the kernel provides
this confirms that epidemics
the kernel provides base
confirms that epidemics are
kernel provides base services
that epidemics are a
provides base services and
epidemics are a robust
base services and the
are a robust tunable
services and the specific
a robust tunable mechanism
fixed period or an
and the specific application
period or an exponential
robust tunable mechanism providing
or an exponential back
the specific application context
acm transactions on database
specific application context is
transactions on database systems
tunable mechanism providing graceful
application context is provided
mechanism providing graceful degradation
context is provided through
is provided through subsystem
provided through subsystem servers
through subsystem servers or
subsystem servers or personalities
the inconsistency window shifts
inconsistency window shifts in
window shifts in accordance
fixed or estimated by
shifts in accordance with
or estimated by the
in accordance with the
estimated by the system
accordance with the update
with the update injection
the update injection rate
is one of the
one of the personalities
of the personalities running
the personalities running on
and multiple suspicion levels
personalities running on top
multiple suspicion levels are
running on top of
notice that the difference
on top of windows
suspicion levels are configurable
that the difference between
top of windows nt
levels are configurable by
the difference between the
are configurable by the
configurable by the application
difference between the maximum
between the maximum inconsistency
the maximum inconsistency window
maximum inconsistency window and
the application can provide
inconsistency window and the
application can provide application
window and the average
can provide application specific
and the average inconsistency
and posix are others
the average inconsistency window
posix are others delivered
provide application specific data
are others delivered by
average inconsistency window is
others delivered by microsoft
application specific data to
inconsistency window is two
specific data to be
window is two orders
data to be piggybacked
is two orders of
to be piggybacked on
one can run windows
be piggybacked on the
two orders of magnitude
can run windows nt
piggybacked on the heartbeats
run windows nt without
windows nt without these
nt without these standard
without these standard personalities
these standard personalities and
the second scheme uses
this reflects the degree
standard personalities and build
second scheme uses a
personalities and build your
reflects the degree to
and build your own
scheme uses a polling
the degree to which
uses a polling method
degree to which the
a polling method to
to which the victim
polling method to collect
what is an operating
method to collect acknowledgments
is an operating system
which the victim node
to collect acknowledgments from
the victim node lags
collect acknowledgments from the
victim node lags the
acknowledgments from the peer
request queued request send
node lags the other
from the peer processes
lags the other nodes
queued request send reply
this question seems to
the other nodes during
question seems to be
if no acknowledgments are
seems to be on
request send reply queued
other nodes during the
no acknowledgments are received
nodes during the period
acknowledgments are received after
during the period before
are received after a
to be on the
send reply queued reply
the period before it
received after a number
period before it has
after a number of
before it has fully
be on the mind
a number of retries
reply queued reply send
number of retries a
it has fully caught
of retries a suspicion
has fully caught up
retries a suspicion is
on the mind of
a suspicion is raised
the mind of many
mind of many people
of many people these
many people these days
next we evaluated the
we evaluated the inconsistency
evaluated the inconsistency window
the inconsistency window of
infused by the microsoft
inconsistency window of a
by the microsoft trial
window of a service
e dd e dd
of a service running
dd e dd f
a service running at
e dd f edd
service running at a
academics in general have
dd f edd f
in general have taken
f edd f g
general have taken a
running at a particular
have taken a very
at a particular update
taken a very narrow
a particular update rate
layered interleaving recovery percentage
edd f g fg
and retransmission limits are
a very narrow view
and for three different
f g fg e
retransmission limits are configurable
interleaving recovery percentage and
limits are configurable by
recovery percentage and latency
are configurable by the
g fg e ed
configurable by the application
fg e ed e
by the application or
very narrow view of
the application or can
narrow view of what
application or can be
for three different intervals
or can be adapted
three different intervals in
can be adapted by
view of what an
different intervals in which
e ed e e
intervals in which the
ed e e d
in which the victim
e e d f
which the victim node
percentage and latency c
be adapted by the
of what an operating
adapted by the failure
e d f eed
what an operating system
d f eed f
an operating system is
layered interleaving and bursty
the victim node is
interleaving and bursty loss
victim node is halted
by the failure manager
f eed f g
and bursty loss thus
the failure manager to
bursty loss thus far
failure manager to the
eed f g fg
david faber at microsoft
loss thus far we
manager to the network
thus far we have
faber at microsoft trial
f g fg e
at microsoft trial defined
far we have shown
g fg e d
show average and maximum
instrumenting the operating system
average and maximum inconsistency
we have shown how
and maximum inconsistency windows
have shown how maelstrom
fg e d e
microsoft trial defined an
maximum inconsistency windows for
shown how maelstrom effectively
to achieve greater failure
how maelstrom effectively hides
e d e d
maelstrom effectively hides loss
achieve greater failure detection
effectively hides loss from
inconsistency windows for both
d e d f
trial defined an operating
greater failure detection accuracy
hides loss from tcp
windows for both the
defined an operating system
for both the victim
an operating system as
both the victim and
it is necessary to
ip for packets dropped
the victim and for
for packets dropped with
is necessary to instrument
packets dropped with uniform
victim and for the
dropped with uniform randomness
necessary to instrument the
operating system as the
to instrument the operating
shoring up persistent applications
system as the software
instrument the operating environment
and for the other
the operating environment with
for the other processes
operating environment with support
the other processes of
in proceedings of the
other processes of one
we examine the performance
processes of one subservice
examine the performance of
environment with support for
the performance of the
with support for process
performance of the layered
support for process investigation
of the layered interleaving
as the software that
the layered interleaving algorithm
the software that controls
software that controls the
that controls the execution
it has always been
controls the execution of
showing how different parameterizations
has always been argued
the execution of programs
the more messages the
execution of programs on
more messages the victim
of programs on computer
messages the victim node
programs on computer systems
the victim node needs
on computer systems and
victim node needs to
acm sigmod international conference
node needs to recover
always been argued that
computer systems and may
how different parameterizations handle
systems and may provide
been argued that in
sigmod international conference on
the larger the inconsistency
and may provide low
larger the inconsistency window
argued that in a
international conference on management
that in a distributed
conference on management of
bcq pcb c bq
different parameterizations handle bursty
on management of data
parameterizations handle bursty loss
level services such as
handle bursty loss patterns
pcb c bq pcb
in a distributed system
again the difference between
services such as resource
the difference between the
such as resource allocation
we use a loss
c bq pcb cbqpcb
a distributed system it
difference between the average
distributed system it is
between the average and
bq pcb cbqpcb n
the average and maximum
pcb cbqpcb n n
use a loss model
system it is impossible
average and maximum in
it is impossible to
cbqpcb n n on
a loss model where
output control in a
is impossible to distinguish
control in a form
impossible to distinguish a
n n on n
loss model where packets
in a form which
to distinguish a crashed
a form which is
distinguish a crashed process
form which is sufficiently
model where packets are
which is sufficiently simple
where packets are dropped
n on n c
a crashed process from
is sufficiently simple and
crashed process from one
on n c bc
packets are dropped in
sufficiently simple and general
are dropped in bursts
n c bc bonn
process from one that
simple and general so
from one that is
c bc bonn c
dropped in bursts of
and general so that
in bursts of fixed
bc bonn c bc
one that is slow
general so that these
bursts of fixed length
so that these services
bonn c bc b
that these services are
c bc b cbcb
these services are broadly
allowing us to study
services are broadly useful
us to study the
are broadly useful to
to study the impact
broadly useful to software
study the impact of
useful to software developers
the impact of burst
impact of burst length
of burst length on
burst length on performance
but with the proper
with the proper system
the proper system support
proper system support this
system support this is
the link has a
support this is no
link has a one
this is no longer
is no longer true
if the node is
the node is reachable
c bc b cbcb
node is reachable and
is reachable and operating
in research community this
reachable and operating correctly
percentage of packets recovered
research community this strict
community this strict distinction
this strict distinction serves
the operating system can
strict distinction serves to
operating system can determine
distinction serves to distinguish
system can determine whether
serves to distinguish the
can determine whether or
to distinguish the real
determine whether or not
distinguish the real men
whether or not the
the real men from
or not the process
real men from the
not the process has
men from the boys
the process has crashed
c bc b cbcb
reed solomon layered interleaving
the failure management integrated
researchers and hackers that
failure management integrated into
and hackers that work
management integrated into the
hackers that work in
integrated into the os
that work in the
into the os offers
work in the area
the os offers processes
in the area defined
os offers processes a
the area defined by
c bc b cbcb
area defined by this
offers processes a mechanism
defined by this narrow
processes a mechanism to
by this narrow definition
a mechanism to register
this narrow definition of
mechanism to register and
narrow definition of operating
to register and request
definition of operating systems
register and request a
and request a certain
request a certain level
a certain level of
certain level of service
consider themselves part of
themselves part of the
part of the select
of the select circle
the select circle of
c b cb a
select circle of people
b cb a a
is a simple binary
circle of people working
a simple binary test
of people working on
simple binary test performed
people working on the
binary test performed by
working on the core
test performed by the
on the core of
performed by the os
cb a a k
the core of the
by the os upon
core of the systems
the os upon receipt
a a k k
of the systems area
os upon receipt of
the systems area of
a k k j
upon receipt of an
systems area of computer
k k j jk
receipt of an inquiry
area of computer science
indicating whether the process
whether the process is
once you are in
the process is still
you are in this
process is still present
is still present in
are in this circle
still present in the
c bc b cbcb
present in the process
in this circle you
in the process table
bc b cbcb kk
this circle you will
the process table and
b cbcb kk j
circle you will become
process table and thus
cbcb kk j m
table and thus not
you will become part
and thus not has
kk j m lkjj
will become part of
thus not has crashed
j m lkjj ml
become part of the
not has crashed or
m lkjj ml ml
part of the secret
has crashed or voluntary
lkjj ml ml c
crashed or voluntary exited
of the secret society
ml ml c b
the secret society that
ml c b c
the two other levels
secret society that practices
two other levels that
c b c b
other levels that are
b c b cb
levels that are currently
c b cb kj
that are currently implemented
society that practices the
efficient optimistic concurrency control
b cb kj ih
that practices the black
optimistic concurrency control using
provide a remote process
concurrency control using loosely
cb kj ih i
practices the black art
solomon versus layered interleaving
control using loosely synchronized
versus layered interleaving latency
using loosely synchronized clocks
layered interleaving latency of
a remote process with
kj ih i h
remote process with information
the black art of
ih i h ih
black art of os
i h ih j
process with information about
art of os research
ms and a loss
with information about the
and a loss rate
of os research and
information about the progress
a loss rate of
os research and will
about the progress the
research and will start
the progress the local
and will start to
progress the local process
will start to regard
the local process is
start to regard any
local process is making
to regard any other
process is making which
regard any other activity
is making which is
any other activity of
making which is useful
other activity of systems
which is useful in
activity of systems development
is useful in the
of systems development as
useful in the investigation
systems development as irrelevant
in the investigation of
development as irrelevant to
the investigation of processes
as irrelevant to the
investigation of processes that
irrelevant to the future
of processes that are
to the future of
processes that are alive
the future of computer
future of computer science
but that appear slow
c bc b c
that appear slow or
for a long time
appear slow or unresponsive
bc b c bc
where it is varied
a long time the
b c bc b
long time the line
c bc b cbcb
time the line was
bc b cbcb rpc
the line was drawn
at certain intervals the
line was drawn at
b cbcb rpc times
was drawn at the
cbcb rpc times at
drawn at the kernel
certain intervals the process
rpc times at low
intervals the process logs
times at low bandwidth
mbps flow of udp
the process logs checkpoint
flow of udp packets
process logs checkpoint timestamps
of udp packets is
logs checkpoint timestamps with
udp packets is sent
checkpoint timestamps with the
packets is sent over
timestamps with the failure
is sent over it
request queued request send
with the failure service
and one could only
queued request send reply
one could only consider
request send reply queued
could only consider himself
which simultaneously logs the
send reply queued reply
only consider himself a
simultaneously logs the process
reply queued reply send
we show that our
consider himself a true
show that our observation
queued reply send total
himself a true os
reply send total time
delivery distribution for a
that our observation in
a true os researcher
our observation in section
the response to an
observation in section iv
a scalable system for
true os researcher after
scalable system for consistently
response to an inquiry
os researcher after having
system for consistently caching
distribution for a chain
e is correct for
researcher after having developed
is correct for high
to an inquiry request
correct for high loss
an inquiry request holds
for consistently caching dynamic
inquiry request holds the
for high loss rates
request holds the last
consistently caching dynamic web
holds the last checkpoint
caching dynamic web data
the last checkpoint timestamp
high loss rates if
after having developed at
loss rates if the
having developed at least
rates if the interleaves
developed at least two
the current local time
at least two device
if the interleaves are
least two device drivers
the interleaves are relatively
two device drivers and
interleaves are relatively prime
device drivers and hacked
whether the process has
gossip rate left figure
the process has been
drivers and hacked on
process has been allocated
and hacked on the
has been allocated cpu
hacked on the terminal
been allocated cpu time
performance improves substantially when
allocated cpu time since
on the terminal driver
cpu time since the
improves substantially when loss
the terminal driver of
substantially when loss rates
terminal driver of the
when loss rates are
driver of the bsd
loss rates are high
time since the last
rates are high and
since the last checkpoint
are high and losses
high and losses are
and losses are bursty
and whether the process
whether the process has
the graph plots the
the process has consumed
graph plots the percentage
process has consumed any
plots the percentage of
has consumed any messages
the percentage of lost
consumed any messages since
percentage of lost packets
any messages since the
in modern operating systems
of lost packets successfully
modern operating systems such
messages since the last
operating systems such as
since the last checkpoint
systems such as windows
lost packets successfully recovered
such as windows nt
packets successfully recovered on
successfully recovered on the
recovered on the y
the notion of where
notion of where exactly
upon receipt of an
axis against an xaxis
receipt of an inquiry
of where exactly operating
of an inquiry the
against an xaxis of
an inquiry the operating
an xaxis of loss
inquiry the operating system
where exactly operating systems
the operating system uses
xaxis of loss rates
operating system uses an
of loss rates on
system uses an upcall
loss rates on a
a scalable web cache
exactly operating systems services
scalable web cache consistency
rpc traffic with varying
rates on a log
web cache consistency architecture
operating systems services are
traffic with varying bandwidth
on a log scale
on each graph left
systems services are located
each graph left bars
sigcomm computer communications review
graph left bars denote
services are located is
left bars denote transient
the maelstrom configuration used
bars denote transient failure
maelstrom configuration used is
to interrupt the process
are located is not
interrupt the process and
the process and requests
located is not that
process and requests that
is not that simple
configuration used is r
and requests that the
not that simple any
requests that the process
that simple any more
that the process prepares
the process prepares a
process prepares a special
right bars denote a
prepares a special response
bars denote a transient
denote a transient failure
fundamental services are split
a transient failure corroborated
services are split between
transient failure corroborated with
this response is returned
failure corroborated with a
response is returned to
are split between kernel
is returned to the
corroborated with a link
split between kernel and
returned to the caller
with a link congestion
show the time spent
between kernel and user
the time spent on
a link congestion phenomenon
kernel and user space
link congestion phenomenon modeled
time spent on rpcs
congestion phenomenon modeled by
and user space in
spent on rpcs during
the previous sections all
user space in attempts
previous sections all deal
space in attempts to
sections all deal with
in attempts to optimise
all deal with provisions
on rpcs during an
attempts to optimise their
rpcs during an execution
to optimise their efficiency
deal with provisions targeted
optimise their efficiency and
with provisions targeted towards
their efficiency and avoid
provisions targeted towards the
efficiency and avoid uncontrolled
targeted towards the failure
and avoid uncontrolled growth
towards the failure management
message drop on the
avoid uncontrolled growth of
drop on the adjacent
uncontrolled growth of kernel
the failure management of
during an execution of
failure management of processes
an execution of the
growth of kernel services
on the adjacent fifo
execution of the simultaneous
the adjacent fifo channels
of the simultaneous writeback
the pervasiveness of distributed
adjacent fifo channels of
exploiting the close coupled
the simultaneous writeback test
pervasiveness of distributed services
fifo channels of node
the close coupled nature
simultaneous writeback test from
of distributed services in
close coupled nature of
distributed services in modern
coupled nature of a
writeback test from section
services in modern systems
nature of a process
in modern systems can
of a process and
modern systems can be
a process and the
systems can be considered
process and the operating
can be considered a
and the operating system
be considered a threat
the operating system it
considered a threat to
operating system it runs
based cache management for
system it runs under
cache management for dynamic
a threat to the
management for dynamic web
threat to the traditional
for dynamic web content
to the traditional notion
the traditional notion of
to aid accurate detection
traditional notion of operating
aid accurate detection in
notion of operating systems
accurate detection in the
with the bandwidth varying
detection in the case
the bandwidth varying according
in the case of
many support services are
the case of node
support services are required
case of node failure
services are required to
we show the ability
bandwidth varying according to
show the ability of
are required to make
the ability of layered
required to make distributed
ability of layered interleaving
to make distributed systems
of layered interleaving to
make distributed systems work
layered interleaving to provide
distributed systems work efficiently
interleaving to provide gracefully
systems work efficiently and
to provide gracefully degrading
work efficiently and effectively
varying according to the
of node failure the
provide gracefully degrading performance
node failure the fault
gracefully degrading performance in
failure the fault management
degrading performance in the
the fault management system
performance in the face
efficiently and effectively and
in the face of
according to the curve
fault management system implements
and effectively and these
management system implements a
effectively and these services
system implements a node
to the curve in
the face of bursty
implements a node management
face of bursty loss
a node management service
such as security and
as security and directory
security and directory services
alternative architectures and protocols
and directory services or
architectures and protocols for
directory services or distributed
and protocols for providing
which is based on
protocols for providing strong
services or distributed object
for providing strong consistency
or distributed object support
providing strong consistency in
we plot the percentage
strong consistency in dynamic
is based on the
consistency in dynamic web
based on the experience
plot the percentage of
distributed object support and
the percentage of lost
in dynamic web applications
percentage of lost packets
object support and cluster
of lost packets successfully
support and cluster management
on the experience that
rpcs are labelled as
world wide web journal
are labelled as follows
lost packets successfully recovered
the experience that local
are not part of
packets successfully recovered against
not part of a
experience that local failure
part of a traditional
successfully recovered against the
of a traditional view
that local failure investigation
a traditional view of
recovered against the length
traditional view of operating
local failure investigation on
against the length of
view of operating systems
failure investigation on a
the length of loss
investigation on a subnet
length of loss bursts
on a subnet is
of loss bursts for
a subnet is more
but they are essential
subnet is more accurate
they are essential to
is more accurate than
loss bursts for two
more accurate than investigation
bursts for two different
accurate than investigation over
for two different sets
than investigation over the
two different sets of
investigation over the internet
different sets of interleaves
are essential to the
essential to the operation
to the operation of
the operation of modern
operation of modern operating
on a participating subnet
of modern operating systems
a participating subnet one
and in the bottom
participating subnet one or
in the bottom graph
subnet one or more
the bottom graph we
one or more node
demand fetch to raise
or more node failure
fetch to raise priority
more node failure monitors
bottom graph we plot
this results in that
graph we plot the
to raise priority of
we plot the average
raise priority of a
plot the average latency
results in that an
the average latency at
priority of a prefetch
average latency at which
of a prefetch rpc
latency at which the
in that an operating
at which the packets
that an operating system
which the packets were
these are simple services
the packets were recovered
an operating system no
are simple services capable
operating system no longer
simple services capable of
system no longer is
services capable of performing
no longer is a
capable of performing local
recovery latency is defined
of performing local failure
longer is a simple
latency is defined as
is a simple division
performing local failure investigations
the time spent on
local failure investigations upon
is defined as the
a simple division between
defined as the difference
simple division between kernel
time spent on rpcs
failure investigations upon requests
division between kernel and
investigations upon requests from
between kernel and user
as the difference between
spent on rpcs is
the difference between the
kernel and user space
upon requests from remote
difference between the eventual
on rpcs is shown
requests from remote nodes
between the eventual delivery
rpcs is shown with
the eventual delivery time
but consist of a
eventual delivery time of
consist of a myriad
is shown with prefetching
delivery time of the
of a myriad of
time of the recovered
a myriad of services
shown with prefetching enabled
of the recovered packet
the recovered packet and
multicast to announce their
recovered packet and the
to announce their availability
packet and the oneway
of which some are
and the oneway latency
which some are kernilized
the oneway latency of
announce their availability within
oneway latency of the
latency of the link
their availability within the
availability within the organization
some are local and
within the organization where
are local and others
the organization where their
local and others are
organization where their presence
and others are remote
where their presence is
we confirmed that the
their presence is being
confirmed that the emulab
presence is being tracked
that the emulab link
is being tracked by
the emulab link had
operating systems that address
emulab link had almost
being tracked by the
link had almost no
tracked by the other
systems that address the
by the other nfm
had almost no jitter
note that rpc interactions
almost no jitter on
that rpc interactions can
no jitter on correctly
rpc interactions can overlap
jitter on correctly delivered
interactions can overlap so
on correctly delivered packets
can overlap so the
that address the needs
cache coherence in distributed
address the needs of
coherence in distributed systems
an nfm accepts queries
overlap so the quantities
nfm accepts queries from
so the quantities for
accepts queries from remote
the needs of current
queries from remote nodes
needs of current and
from remote nodes about
of current and future
remote nodes about the
current and future clients
way latency an accurate
nodes about the availability
the quantities for different
about the availability of
quantities for different rpc
the availability of a
latency an accurate estimate
availability of a node
an accurate estimate of
and future clients and
accurate estimate of expected
for different rpc types
estimate of expected lossless
of a node within
of expected lossless delivery
future clients and informatik
different rpc types are
clients and informatik informatique
a node within its
expected lossless delivery time
rpc types are not
node within its organization
types are not additive
for some rpc types
it will forward this
will forward this request
forward this request to
increasing the interleaves results
the time spent on
this request to an
time spent on particular
the interleaves results in
request to an nfm
we found that less
to an nfm on
interleaves results in much
spent on particular activities
an nfm on the
on particular activities is
nfm on the particular
particular activities is negligible
found that less than
results in much higher
on the particular subnet
in much higher recovery
activities is negligible in
the particular subnet which
is negligible in proportion
particular subnet which will
much higher recovery percentages
subnet which will investigate
higher recovery percentages at
operating systems servers no
recovery percentages at large
negligible in proportion to
systems servers no longer
in proportion to the
servers no longer span
percentages at large burst
which will investigate the
at large burst sizes
proportion to the overall
no longer span a
will investigate the availability
longer span a single
investigate the availability of
of the messages were
the availability of the
the messages were delivered
availability of the node
messages were delivered by
of the node by
span a single computer
the node by launching
a global cache coherent
but comes at the
node by launching a
to the overall time
by launching a number
global cache coherent file
launching a number of
cache coherent file system
a number of fault
comes at the cost
number of fault test
were delivered by gossip
of fault test requests
at the cost of
a single computer and
the cost of higher
delivered by gossip for
cost of higher recovery
single computer and they
of higher recovery latency
by gossip for the
computer and they abstract
if this is support
and they abstract services
this is support by
attribute requests are small
is support by the
requests are small and
support by the host
are small and have
by the host under
they abstract services away
the host under investigation
abstract services away from
host under investigation or
services away from physical
under investigation or by
small and have a
away from physical nodes
gossip for the nodes
from physical nodes allowing
for the nodes to
physical nodes allowing user
the nodes to the
nodes allowing user to
nodes to the left
allowing user to be
investigation or by icmp
and have a very
or by icmp echo
have a very low
by icmp echo requests
a very low transmission
user to be part
to the left of
icmp echo requests if
the left of the
very low transmission time
to be part of
echo requests if not
be part of a
low transmission time relative
left of the victim
part of a larger
transmission time relative to
the result of the
time relative to their
set of interleaves catches
result of the query
of interleaves catches almost
of the query is
interleaves catches almost all
the query is then
catches almost all packets
query is then returned
this confirms that gossip
is then returned to
a distributed memory object
then returned to the
relative to their queueing
almost all packets in
potential global operating environment
all packets in an
distributed memory object caching
packets in an extended
memory object caching system
in an extended burst
returned to the requesting
an extended burst of
to their queueing delays
confirms that gossip rarely
to the requesting node
that gossip rarely is
will the real dinosaur
gossip rarely is used
the real dinosaur please
rarely is used to
such users happen to
is used to circumvent
packets at an average
used to circumvent chain
the nfm also functions
to circumvent chain replication
users happen to be
at an average latency
real dinosaur please come
an average latency of
dinosaur please come forward
average latency of around
nfm also functions as
circumvent chain replication in
happen to be working
also functions as proxy
chain replication in the
to be working on
until the spring of
functions as proxy for
replication in the normal
be working on the
as proxy for process
while repairing all random
proxy for process availability
in the normal case
working on the same
repairing all random singleton
for process availability queries
all random singleton losses
on the same element
process availability queries in
the same element of
availability queries in the
a peculiar effect is
queries in the case
peculiar effect is noticeable
random singleton losses within
effect is noticeable in
same element of the
in the case where
we were deeply committed
is noticeable in figure
were deeply committed to
element of the design
the case where a
deeply committed to sunos
case where a firewall
where a firewall obstructs
a firewall obstructs the
it is clear that
firewall obstructs the free
is clear that satisfying
obstructs the free querying
clear that satisfying a
the free querying of
that satisfying a request
in that more messages
and other bsd derivatives
that more messages are
the graphs also show
more messages are delivered
graphs also show recovery
messages are delivered via
satisfying a request from
free querying of the
distributed data structures for
querying of the nodes
data structures for internet
a request from stale
also show recovery latency
are delivered via gossip
of the nodes by
at that moment its
the nodes by their
that moment its vendor
show recovery latency rising
structures for internet service
recovery latency rising gracefully
for internet service construction
latency rising gracefully with
even in the prefix
rising gracefully with the
in the prefix part
moment its vendor was
the prefix part of
request from stale data
gracefully with the increase
nodes by their peers
with the increase in
in proceedings of the
the increase in loss
its vendor was discontinuing
increase in loss burst
vendor was discontinuing the
prefix part of the
was discontinuing the operating
part of the chain
discontinuing the operating system
in loss burst length
th conference on symposium
whether in from the
s are configured with
conference on symposium on
are configured with domain
on symposium on operating
and had designated solaris
symposium on operating system
in from the cache
although the effect is
configured with domain and
the effect is also
the longer the burst
on operating system design
with domain and acl
effect is also evident
domain and acl mechanisms
or on a server
the longer it takes
on a server that
longer it takes to
a server that has
it takes to recover
and acl mechanisms to
takes to recover the
which had its root
acl mechanisms to control
server that has yet
mechanisms to control access
that has yet to
to control access to
to recover the lost
control access to the
is also evident in
access to the information
has yet to see
recover the lost packets
had its root in
also evident in the
yet to see a
an extension which is
evident in the suffix
the maelstrom configuration used
to see a delayed
its root in at
extension which is under
maelstrom configuration used is
it is more significant
see a delayed writeback
is more significant on
which is under investigation
more significant on the
t s system v
significant on the left
is under investigation is
configuration used is r
under investigation is to
on the left hand
investigation is to have
the left hand side
would be visible to
s system v as
is to have nodes
left hand side figure
to have nodes multicast
system v as the
have nodes multicast heartbeats
v as the successor
be visible to the
nodes multicast heartbeats with
where the gossip rate
visible to the user
multicast heartbeats with local
the gossip rate is
heartbeats with local node
to the user and
this event forced us
gossip rate is higher
with local node information
the user and costly
event forced us to
local node information periodically
forced us to take
because we observed this
us to take a
we observed this phenomenon
to take a step
observed this phenomenon only
take a step back
this phenomenon only with
a step back and
phenomenon only with update
this information can be
strong cache consistency is
step back and evaluate
only with update rates
information can be collected
with update rates of
cache consistency is certainly
back and evaluate our
can be collected by
and evaluate our research
be collected by the
consistency is certainly achievable
collected by the local
evaluate our research directions
is certainly achievable in
by the local nfm
our research directions and
certainly achievable in distributed
research directions and our
achievable in distributed file
s and shared in
directions and our expectations
and shared in compressed
in distributed file systems
we suspect that the
and our expectations with
shared in compressed form
our expectations with respect
in compressed form among
expectations with respect to
compressed form among the
suspect that the network
with respect to the
form among the other
that the network stack
respect to the operating
among the other nfm
to the operating systems
the network stack is
the operating systems to
network stack is more
operating systems to use
stack is more efficient
s in the organization
is more efficient in
more efficient in dealing
efficient in dealing with
in dealing with udp
if one issue in
dealing with udp packets
local system management tools
with udp packets then
system management tools can
udp packets then with
but must be implemented
one issue in our
management tools can connect
packets then with tcp
tools can connect to
then with tcp ones
issue in our discussions
with tcp ones under
in our discussions was
tcp ones under heavy
our discussions was dominant
ones under heavy load
can connect to an
must be implemented with
connect to an nfm
be implemented with synchronous
to an nfm to
it was the fact
an nfm to retrieve
implemented with synchronous rpcs
nfm to retrieve the
was the fact that
to retrieve the information
the fact that most
retrieve the information and
fact that most of
the information and set
and requires either readers
information and set trap
that most of the
and set trap conditions
we show histograms of
requires either readers or
show histograms of recovery
either readers or writers
histograms of recovery latencies
most of the operating
of recovery latencies for
of the operating systems
recovery latencies for the
the operating systems we
readers or writers to
operating systems we were
or writers to incur
systems we were looking
in distributed systems build
latencies for the two
writers to incur a
we were looking at
distributed systems build on
were looking at were
systems build on top
looking at were actually
for the two interleave
build on top of
to incur a delay
on top of a
incur a delay to
at were actually very
the two interleave configurations
were actually very old
a delay to ensure
top of a web
two interleave configurations under
of a web of
delay to ensure that
actually very old fashioned
interleave configurations under different
a web of interconnected
configurations under different burst
web of interconnected networks
under different burst lengths
to ensure that only
ensure that only the
that only the latest
only the latest version
the latest version of
delivery distribution for a
the histograms confirm the
latest version of a
we have to take
distribution for a chain
have to take network
in structure and in
to take network failure
version of a file
histograms confirm the trends
structure and in implementation
confirm the trends described
of a file is
take network failure into
the trends described above
a file is accessed
network failure into account
most of these operating
of these operating systems
packet recoveries take longer
these operating systems had
recoveries take longer from
operating systems had their
failures at network level
systems had their conception
take longer from left
had their conception in
at network level are
as we have noted
network level are in
their conception in the
level are in general
we have noted in
longer from left to
are in general related
from left to right
in general related to
left to right as
general related to crash
to right as we
have noted in section
related to crash failures
right as we increase
to crash failures of
as we increase loss
crash failures of routers
we increase loss burst
failures of routers and
increase loss burst length
of routers and gateways
s and did not
sending file updates to
and did not change
file updates to a
did not change much
updates to a server
not change much in
to a server asynchronously
change much in structure
and from top to
tier database caching for
from top to bottom
database caching for e
top to bottom as
or to severe degradation
a server asynchronously has
much in structure since
to bottom as we
in structure since then
bottom as we increase
to severe degradation of
as we increase the
server asynchronously has two
we increase the interleave
asynchronously has two potential
increase the interleave values
has two potential benefits
in international conference on
linux could be seen
severe degradation of the
could be seen as
degradation of the service
international conference on management
of the service level
conference on management of
be seen as an
on management of data
the process modifying the
the service level due
seen as an exception
service level due to
process modifying the file
illustrates the difference between
level due to network
the difference between a
modifying the file need
as an exception since
due to network congestion
an exception since it
difference between a traditional
exception since it was
the file need not
since it was developed
file need not wait
it was developed in
between a traditional fec
was developed in the
a traditional fec code
developed in the second
need not wait for
in the second half
not wait for the
consistency windows is slightly
causing minimum performance requirements
windows is slightly more
the second half of
is slightly more than
traditional fec code and
slightly more than an
wait for the write
second half of the
minimum performance requirements to
fec code and layered
performance requirements to be
code and layered interleaving
more than an order
and layered interleaving by
for the write to
layered interleaving by plotting
the write to complete
interleaving by plotting a
than an order of
requirements to be violated
an order of magnitude
the failure investigator will
and this is attributable
if the update is
this is attributable to
the update is delayed
is attributable to the
update is delayed in
but its structure mirrored
when not able to
its structure mirrored that
not able to reach
structure mirrored that of
attributable to the victim
able to reach the
is delayed in the
to the victim node
delayed in the log
mirrored that of the
to reach the node
that of the traditional
reach the node under
the victim node observe
the node under investigation
in the log for
victim node observe that
node under investigation or
of the traditional unix
under investigation or a
the traditional unix systems
node observe that the
the log for some
observe that the two
investigation or a relevant
that the two graphs
or a relevant nfm
log for some interval
and as such it
the two graphs denoting
as such it could
for some interval before
such it could be
some interval before being
two graphs denoting the
perform a path search
it could be considered
a path search to
could be considered one
path search to find
be considered one of
search to find the
graphs denoting the maximum
interval before being written
considered one of them
to find the trouble
denoting the maximum inconsistency
find the trouble spot
before being written back
the maximum inconsistency windows
the trouble spot in
maximum inconsistency windows for
the significant advances made
inconsistency windows for the
significant advances made in
windows for the victim
advances made in academic
trouble spot in the
made in academic computer
it may be superseded
consistent and scalable cache
for the victim node
and scalable cache replication
in academic computer science
scalable cache replication for
may be superseded by
spot in the network
the victim node and
cache replication for multi
victim node and for
in os research and
node and for the
os research and in
be superseded by a
and for the entire
research and in system
for the entire chain
and in system software
it uses the traceroute
in system software engineering
superseded by a later
the entire chain are
uses the traceroute technique
entire chain are identical
by a later update
the traceroute technique of
have had only minimal
traceroute technique of emitting
had only minimal impact
technique of emitting small
only minimal impact on
which means that clients
minimal impact on the
means that clients perceiving
and therefore can be
that clients perceiving significant
therefore can be omitted
of emitting small messages
impact on the design
emitting small messages with
on the design and
small messages with limited
the design and implementation
messages with limited ttl
clients perceiving significant inconsistency
can be omitted entirely
perceiving significant inconsistency are
design and implementation of
significant inconsistency are the
and implementation of commercial
inconsistency are the ones
implementation of commercial operating
are the ones that
of commercial operating systems
the ones that are
triggering icmp responses from
ones that are querying
icmp responses from routers
that are querying the
responses from routers among
these benefits come at
are querying the victim
the design of all
querying the victim node
design of all unix
the victim node while
victim node while it
from routers among the
node while it is
benefits come at the
of all unix systems
routers among the path
while it is still
come at the cost
all unix systems violates
it is still recovering
at the cost of
unix systems violates almost
if an obstruction is
is still recovering state
an obstruction is found
the cost of reduced
obstruction is found it
cost of reduced cache
is found it is
systems violates almost all
found it is reported
of reduced cache consistency
finally we performed a
it is reported to
violates almost all of
is reported to the
almost all of the
we performed a set
reported to the caller
performed a set of
all of the software
a set of experiments
of the software engineering
set of experiments to
the software engineering principles
since the version of
of experiments to determine
the version of the
experiments to determine the
version of the file
software engineering principles presented
the failure management library
engineering principles presented to
of the file stored
to determine the distribution
failure management library offers
determine the distribution of
the file stored at
principles presented to first
file stored at the
presented to first year
stored at the server
to first year s
at the server is
the distribution of messages
management library offers functionality
distribution of messages delivered
first year s computer
of messages delivered by
year s computer science
library offers functionality to
the server is inconsistent
offers functionality to keep
consistent and scalable caching
server is inconsistent during
and scalable caching in
functionality to keep the
scalable caching in multitier
messages delivered by the
to keep the obstruction
delivered by the chain
caching in multitier architectures
by the chain vs
is inconsistent during the
s computer science students
keep the obstruction under
the chain vs delivered
the obstruction under investigation
the international journal on
inconsistent during the time
international journal on very
during the time that
chain vs delivered by
obstruction under investigation and
vs delivered by gossip
journal on very large
under investigation and to
the time that the
investigation and to notify
time that the update
and to notify the
that the update remains
to notify the application
on very large data
notify the application once
very large data bases
one transient failure affects
the update remains queued
the application once the
the design is monolithic
transient failure affects the
design is monolithic with
update remains queued for
is monolithic with almost
remains queued for transmission
monolithic with almost no
application once the obstruction
with almost no modular
failure affects the wall
almost no modular structure
once the obstruction seems
the obstruction seems to
even though asynchronous writes
obstruction seems to be
though asynchronous writes in
seems to be removed
and the internal kernel
asynchronous writes in mfs
the internal kernel interfaces
the runs are eight
writes in mfs are
runs are eight times
internal kernel interfaces are
are eight times longer
in mfs are not
kernel interfaces are not
mfs are not delayed
interfaces are not strictly
are not delayed to
this way the process
eight times longer than
are not strictly enforced
not delayed to aggregate
way the process does
times longer than the
the process does not
longer than the runs
delayed to aggregate updates
process does not need
than the runs before
not strictly enforced which
does not need to
strictly enforced which introduces
not need to keep
enforced which introduces dependencies
a burst of updates
both in total experiment
which introduces dependencies on
in total experiment time
introduces dependencies on the
total experiment time and
dependencies on the actual
experiment time and time
on the actual implementation
need to keep the
the actual implementation of
burst of updates to
to keep the partitioned
actual implementation of data
of updates to a
implementation of data structures
keep the partitioned processes
time and time the
the partitioned processes under
updates to a sequence
and time the victim
to a sequence of
time the victim node
partitioned processes under investigation
the victim node is
making it impossible to
a sequence of files
it impossible to upgrade
processes under investigation but
impossible to upgrade or
sequence of files may
victim node is halted
of files may flood
to upgrade or replace
files may flood the
upgrade or replace modules
may flood the link
or replace modules without
under investigation but can
replace modules without also
flood the link to
modules without also redesigning
investigation but can wait
without also redesigning several
the link to the
but can wait until
also redesigning several other
can wait until the
redesigning several other modules
link to the server
wait until the connectivity
to the server and
until the connectivity is
the server and increase
for example to replace
the connectivity is restored
server and increase the
show the number of
and increase the delay
the number of messages
increase the delay before
number of messages delivered
the delay before updates
of messages delivered by
delay before updates towards
messages delivered by the
connectivity is restored by
delivered by the chain
is restored by simply
by the chain replication
restored by simply monitoring
the chain replication mechanism
by simply monitoring the
chain replication mechanism and
simply monitoring the trouble
replication mechanism and the
monitoring the trouble spot
before updates towards the
example to replace the
mechanism and the ones
updates towards the end
to replace the scheduler
and the ones delivered
replace the scheduler in
the ones delivered by
the scheduler in any
in case the network
scheduler in any of
case the network topology
towards the end of
ones delivered by the
in any of the
delivered by the epidemics
the end of the
improving application throughput with
any of the bsd
application throughput with enterprise
throughput with enterprise javabeans
the network topology permits
with enterprise javabeans caching
end of the burst
for each of the
of the burst are
each of the nodes
the burst are committed
of the nodes in
of the bsd s
the nodes in a
network topology permits it
any other client accessing
nodes in a chain
in international conference on
the bsd s one
international conference on distributed
other client accessing the
bsd s one needs
conference on distributed computing
again we omitted the
on distributed computing systems
s one needs to
the investigator can be
one needs to spend
investigator can be configured
needs to spend two
can be configured to
we omitted the head
client accessing the file
omitted the head of
be configured to use
the head of the
configured to use alternate
head of the chain
to use alternate paths
to spend two weeks
of the chain node
spend two weeks searching
the chain node because
two weeks searching for
chain node because its
weeks searching for all
node because its behavior
searching for all dependencies
because its behavior is
for all dependencies and
its behavior is not
cache consistency will access
all dependencies and fixing
behavior is not representative
dependencies and fixing other
consistency will access the
to reach one of
will access the stale
and fixing other sources
reach one of the
access the stale version
and in this experiment
one of the destination
in this experiment we
of the destination nfm
this experiment we have
experiment we have chains
rather than one which
at the top of
we have chains of
the top of our
have chains of length
than one which incorporates
top of our long
from cornell for example
of our long wish
one which incorporates the
cornell for example it
which incorporates the pending
for example it is
our long wish list
example it is possible
incorporates the pending update
long wish list for
it is possible to
wish list for an
is possible to construct
list for an ideal
for an ideal research
an ideal research operating
we therefore refer to
ideal research operating system
therefore refer to this
alternative routes to anywhere
refer to this as
routes to anywhere in
to this as a
were three important general
this as a hidden
three important general points
to anywhere in california
as a hidden upstudies
delivered updates by means
a hidden upstudies of
updates by means of
hidden upstudies of distributed
by means of the
upstudies of distributed file
means of the gossip
of distributed file systems
the request contains sufficient
of the gossip repair
request contains sufficient information
currency serializability for middle
the gossip repair mechanism
the design and implementation
distributed file systems have
contains sufficient information for
tier caching and replication
file systems have largely
sufficient information for the
as the nodes get
information for the nfm
the nodes get further
for the nfm to
nodes get further away
the nfm to construct
design and implementation of
nfm to construct a
systems have largely concluded
to construct a symmetric
have largely concluded that
and implementation of the
get further away from
implementation of the operating
further away from the
of the operating system
in international conference on
the operating system should
international conference on management
operating system should comply
conference on management of
largely concluded that file
away from the victim
construct a symmetric return
from the victim node
system should comply with
a symmetric return path
concluded that file date
on management of data
should comply with modern
comply with modern software
more of the messages
with modern software engineering
protocols that can exploit
modern software engineering principles
of the messages were
and the cache consistency
that can exploit this
the messages were delivered
can exploit this type
messages were delivered by
exploit this type of
were delivered by means
this type of information
delivered by means of
type of information are
by means of the
of information are under
means of the chain
information are under development
the cache consistency problem
allowing researchers to introduce
cache consistency problem caused
researchers to introduce new
latency histograms for i
because the repair mechanism
consistency problem caused by
to introduce new components
the repair mechanism relinked
problem caused by asynchronous
caused by asynchronous sharing
repair mechanism relinked the
by asynchronous sharing is
and replace core components
mechanism relinked the chain
replace core components without
asynchronous sharing is infrequent
relinked the chain and
core components without redesigning
the chain and chain
sharing is infrequent in
components without redesigning the
chain and chain replication
without redesigning the complete
is infrequent in general
and chain replication began
redesigning the complete system
chain replication began to
replication began to function
began to function normally
failure investigation of a
the speed with which
investigation of a process
speed with which the
of a process at
with which the chain
a process at the
which the chain is
process at the same
the chain is restored
at the same sub
the overall structure of
chain is restored depends
overall structure of the
a ppendix we now
is restored depends on
ppendix we now prove
structure of the operating
restored depends on the
net has always been
we now prove theorem
has always been viewed
depends on the rate
always been viewed as
on the rate of
been viewed as a
the rate of the
viewed as a reasonably
rate of the fast
as a reasonably accurate
of the operating system
writes as the hidden
as the hidden update
reasons for false suspicions
the hidden update problem
user and kernel space
for false suspicions were
and kernel space components
and on the responsiveness
false suspicions were overload
on the responsiveness of
suspicions were overload in
the responsiveness of the
cache with unbounded cache
should be designed towards
responsiveness of the failure
be designed towards the
of the failure detection
designed towards the future
the failure detection mechanism
we have identified a
with unbounded cache size
were overload in the
unbounded cache size and
have identified a class
cache size and unbounded
future development the current
size and unbounded dependency
development the current ssa
and unbounded dependency lists
overload in the receiver
identified a class of
the current ssa implementation
unbounded dependency lists implements
in the receiver os
dependency lists implements cache
a class of cache
current ssa implementation uses
class of cache consistency
should be pervasive throughout
of cache consistency scenarmobile
be pervasive throughout the
cache consistency scenarmobile file
pervasive throughout the whole
consistency scenarmobile file systems
throughout the whole system
scenarmobile file systems such
ssa implementation uses gossip
since we assume that
implementation uses gossip in
we assume that the
uses gossip in situations
assume that the transactional
gossip in situations where
that the transactional db
file systems such as
in situations where faster
which could cause high
situations where faster notifications
could cause high message
the transactional db is
where faster notifications might
transactional db is serializable
faster notifications might be
the operating system vendor
systems such as coda
cause high message loss
notifications might be helpful
the operations in an
operating system vendor should
operations in an execution
system vendor should be
in an execution of
vendor should be open
an execution of update
should be open to
or unresponsiveness due to
be open to innovation
execution of update transactions
unresponsiveness due to application
of update transactions update
due to application overload
update transactions update can
we believe that when
transactions update can be
believe that when a
our experiences in the
that when a node
rely on optimistic conios
when a node fails
on optimistic conios as
although that could be
update can be serialized
that could be seen
experiences in the past
can be serialized as
optimistic conios as being
a node fails or
could be seen as
in the past had
be serialized as some
the past had been
node fails or joins
be seen as a
conios as being of
serialized as some serial
past had been that
as some serial execution
as being of high
seen as a design
had been that vendors
it would be useful
been that vendors always
would be useful to
being of high importance
the next claim trivially
as a design error
next claim trivially follows
be useful to spread
claim trivially follows from
useful to spread the
of high importance and
that vendors always ignored
trivially follows from the
to spread the news
follows from the definition
high importance and inadequately
from the definition of
vendors always ignored important
the definition of the
spread the news as
definition of the database
importance and inadequately served
of the database dependency
the news as quickly
the database dependency list
and inadequately served by
although confident about the
news as quickly as
confident about the result
database dependency list specification
inadequately served by ex
always ignored important research
as quickly as possible
ignored important research results
one was never guaranteed
important research results and
was never guaranteed that
research results and only
never guaranteed that the
currency control to resolve
results and only followed
guaranteed that the process
and only followed very
if is a serialization
control to resolve the
is a serialization of
to resolve the conflicts
a serialization of the
that the process had
serialization of the update
the process had truly
resolve the conflicts generated
we realize that for
only followed very narrow
realize that for some
followed very narrow paths
that for some particular
very narrow paths of
process had truly crashed
narrow paths of incremental
the conflicts generated by
of the update transactions
for some particular tasks
the update transactions of
some particular tasks gossip
update transactions of an
particular tasks gossip could
transactions of an execution
tasks gossip could be
of an execution update
using the os failure
paths of incremental improvements
the os failure management
conflicts generated by hidden
gossip could be done
os failure management extensions
could be done more
generated by hidden upisting
be done more efficiently
windows nt was the
by hidden upisting mobile
at every step in
this assurance is now
nt was the only
assurance is now available
hidden upisting mobile file
we are therefore exploring
was the only operating
are therefore exploring the
the only operating system
the time needed by
therefore exploring the use
upisting mobile file systems
exploring the use of
only operating system that
time needed by the
operating system that came
the use of ip
system that came close
suppose that a complex
that came close to
that a complex engineering
came close to matching
the version dependencies of
close to matching most
use of ip multicast
to matching most of
a complex engineering dates
of ip multicast for
version dependencies of every
matching most of our
latency histograms for i
most of our requirements
dependencies of every object
needed by the failure
an alternative approach is
by the failure detector
alternative approach is to
the failure detector to
approach is to use
failure detector to come
with a handful of
detector to come to
of every object match
to come to a
is to use a
come to a result
to use a variant
to a result has
use a variant of
a result has been
a variant of callbacks
result has been greatly
variant of callbacks to
has been greatly reduced
of callbacks to design
ip multicast for dissemination
every object match those
a handful of operating
object match those stored
handful of operating systems
match those stored in
been greatly reduced in
those stored in its
callbacks to design is
greatly reduced in the
to design is maintained
stored in its dependency
multicast for dissemination of
in its dependency list
reduced in the optimistic
for dissemination of urgent
design is maintained on
dissemination of urgent information
is maintained on a
of operating systems such
of urgent information as
operating systems such as
maintained on a server
common case that the
urgent information as long
case that the node
on a server and
systems such as qnx
we first describe a
such as qnx and
first describe a routine
information as long as
describe a routine for
a server and updated
as qnx and utah
server and updated by
qnx and utah s
and updated by teams
and utah s os
updated by teams of
a routine for placing
that the node on
as long as the
the node on which
by teams of de
node on which the
routine for placing a
on which the process
for placing a read
which the process was
none of the unix
long as the physical
the process was running
as the physical nodes
process was running is
allow a client to
only transaction from a
the physical nodes are
transaction from a cache
physical nodes are not
from a cache server
nodes are not on
of the unix based
are not on a
a client to replay
was running is reachable
a cache server in
not on a public
cache server in a
on a public network
server in a serialization
the unix based operating
client to replay writes
regardless if the process
to replay writes asynchronously
if the process has
in a serialization of
a public network segment
unix based operating systems
moving average of recovery
the process has failed
average of recovery latencies
process has failed or
based operating systems came
a serialization of a
operating systems came close
but retain strong signers
systems came close to
serialization of a subset
came close to fulfilling
of a subset of
close to fulfilling our
we plan to include
to fulfilling our requirements
of recovery latencies for
has failed or not
recovery latencies for both
plan to include support
latencies for both codes
to form a serialization
to include support for
form a serialization of
include support for the
as noted before the
a serialization of both
noted before the core
the channel is configured
before the core of
serialization of both the
the core of those
the node is able
core of those operating
support for the partitioning
of those operating systems
channel is configured to
those operating systems is
of both the update
operating systems is based
node is able to
is configured to lose
is able to indicate
both the update transaction
able to indicate whether
for the partitioning of
to indicate whether or
systems is based on
indicate whether or not
configured to lose singleton
whether or not the
the echo file system
the update transaction and
the partitioning of the
update transaction and the
or not the process
transaction and the read
not the process has
to lose singleton packets
partitioning of the services
lose singleton packets randomly
the process has crashed
singleton packets randomly at
of the services by
packets randomly at a
the services by means
randomly at a loss
services by means of
at a loss rate
by means of registering
a loss rate of
in general a single
year old designs and
means of registering partition
general a single round
of registering partition function
old designs and these
registering partition function handlers
designs and these operating
partition function handlers with
site supervisors work from
and these operating systems
function handlers with a
these operating systems still
handlers with a global
supervisors work from those
trip time is sufficient
operating systems still treat
time is sufficient at
systems still treat computers
is sufficient at the
work from those designs
with a global data
and additionally lose long
still treat computers as
additionally lose long bursts
from those designs using
sufficient at the local
treat computers as single
at the local network
computers as single entities
the local network to
as single entities without
local network to get
single entities without a
lose long bursts of
entities without a coherent
those designs using mobile
network to get a
to get a result
we have implemented only
we thank larry felser
have implemented only the
thank larry felser and
implemented only the server
larry felser and his
only the server side
area case this time
the server side load
felser and his team
packets at occasional intervals
case this time is
server side load balancing
this time is a
side load balancing scheme
and his team at
time is a function
his team at autodesk
both codes are configured
we are considering ways
codes are configured with
is a function of
are configured with r
team at autodesk for
are considering ways to
a function of the
considering ways to extend
function of the level
ways to extend our
of the level of
at autodesk for their
the level of congestion
autodesk for their help
level of congestion in
for their help in
of congestion in the
to extend our approach
performing this permutation is
extend our approach for
this permutation is one
their help in understanddevices
our approach for use
congestion in the network
approach for use in
and recover all lost
in the network path
recover all lost packets
for use in settings
these supervisors read from
use in settings where
supervisors read from the
in settings where partitioning
permutation is one step
read from the server
is one step of
settings where partitioning is
one step of the
all lost packets reedsolomon
where partitioning is done
from the server and
partitioning is done on
the os extensions also
is done on the
lost packets reedsolomon uses
os extensions also improve
packets reedsolomon uses an
step of the routine
reedsolomon uses an interleave
the server and may
feet high windows nt
extensions also improve the
high windows nt looked
uses an interleave of
windows nt looked like
server and may also
we repeat this step
done on the client
repeat this step forming
on the client side
this step forming a
also improve the confidence
step forming a series
and may also ing
nt looked like the
and layered interleaving uses
looked like the proverbial
layered interleaving uses interleaves
improve the confidence in
interleaving uses interleaves of
may also ing the
like the proverbial dinosaur
forming a series of
the confidence in the
a series of permutations
confidence in the failure
side access to subservice
in the failure investigation
also ing the file
the failure investigation process
ing the file access
failure investigation process in
the file access patterns
each permutation is a
access to subservice membership
permutation is a serialization
to subservice membership information
is a serialization of
subservice membership information is
investigation process in the
file access patterns that
a closer look revealed
a serialization of update
membership information is needed
process in the wide
and consequently both have
access patterns that arise
consequently both have a
patterns that arise in
both have a maximum
that arise in collaborative
have a maximum tolerable
arise in collaborative work
a maximum tolerable burst
in collaborative work applications
maximum tolerable burst length
using the old strategy
tolerable burst length of
the old strategy of
collaborative work applications for
we are also developing
and each permutes a
are also developing a
old strategy of simply
also developing a gui
strategy of simply polling
developing a gui assisted
of simply polling a
work applications for very
closer look revealed a
each permutes a range
look revealed a truly
simply polling a process
revealed a truly modern
polling a process until
a gui assisted automated
a truly modern operating
we use a publicly
truly modern operating system
applications for very change
a process until a
permutes a range of
process until a time
use a publicly available
for very change the
gui assisted automated web
a range of the
assisted automated web service
out occurs gives much
automated web service deployment
very change the design
web service deployment tool
range of the transactions
object oriented design is
of the transactions with
a publicly available implementation
the transactions with respect
oriented design is pervasive
transactions with respect to
focused on web service
design is pervasive through
for example to reflect
is pervasive through the
example to reflect one
pervasive through the system
to reflect one of
through the system including
reflect one of the
the system including the
one of the contingencies
system including the kernel
of the contingencies large
occurs gives much less
on web service applications
gives much less confidence
with respect to the
much less confidence in
respect to the previous
the contingencies large architectural
there is a complete
publicly available implementation of
less confidence in the
available implementation of a
confidence in the result
implementation of a reed
contingencies large architectural and
is a complete distributed
to the previous step
developers could simply drop
in the result of
solomon code based on
large architectural and engineering
code based on vandermonde
architectural and engineering design
based on vandermonde matrices
and engineering design firms
the result of the
a complete distributed strategy
result of the failure
could simply drop a
of the failure investigation
complete distributed strategy with
in each step the
simply drop a wsdl
distributed strategy with at
each step the right
if no response was
step the right end
no response was received
the right end of
strategy with at its
right end of the
response was received after
end of the range
with at its core
of the range is
encountered and resolved only
was received after the
drop a wsdl service
at its core a
a wsdl service description
and resolved only as
received after the maximum
the range is earlier
after the maximum number
the code is plugged
the maximum number of
resolved only as construction
its core a distributed
range is earlier than
code is plugged into
is earlier than in
is plugged into maelstrom
core a distributed object
plugged into maelstrom instead
a distributed object technology
into maelstrom instead of
maximum number of retransmission
maelstrom instead of layered
number of retransmission is
instead of layered interleaving
distributed object technology and
and the system will
object technology and includes
earlier than in the
technology and includes a
than in the previous
only as construction proceeds
in the previous step
the system will generate
and includes a complete
showing that we can
includes a complete integration
system will generate a
a complete integration of
that we can use
complete integration of distributed
will generate a xml
integration of distributed services
as we have seen
of distributed services such
of retransmission is reached
distributed services such as
generate a xml description
we can use new
a xml description that
can use new encodings
services such as security
we have seen earlier
as one or more
xml description that can
one or more of
it was not certain
or more of the
description that can be
more of the objects
was not certain whether
of the objects is
not certain whether this
the objects is closer
high traffic can cause
use new encodings within
that can be used
new encodings within the
objects is closer to
encodings within the same
traffic can cause delays
certain whether this was
and last no but
whether this was because
within the same framework
this was because of
can cause delays in
can be used later
is closer to the
be used later on
closer to the value
used later on to
to the value read
later on to actually
the value read by
was because of network
cause delays in the
last no but least
the same framework seamlessly
on to actually deploy
value read by t
to actually deploy the
delays in the round
there is a real
actually deploy the service
because of network failure
deploy the service automatically
is a real desire
eventually we therefore reach
a real desire by
solomon code recovers all
real desire by the
host failure or process
code recovers all lost
failure or process failure
the service will be
recovers all lost packets
we therefore reach a
trip time for small
therefore reach a permutation
service will be partitioned
all lost packets with
desire by the vendor
reach a permutation where
with the new scheme
a permutation where at
the new scheme it
by the vendor to
new scheme it is
the vendor to continuously
scheme it is possible
vendor to continuously innovate
it is possible to
lost packets with roughly
to continuously innovate its
time for small rpcs
permutation where at the
is possible to distinguish
and deployed on the
possible to distinguish among
continuously innovate its operating
to distinguish among these
packets with roughly the
distinguish among these different
where at the chosen
among these different failures
innovate its operating system
at the chosen time
its operating system and
the chosen time all
operating system and the
with roughly the same
system and the overall
chosen time all read
and the overall services
additional information the full
time all read objects
roughly the same latency
all read objects are
data rpcs have a
information the full report
microsoft doesn t hesitate
read objects are at
the full report contains
objects are at their
deployed on the fly
doesn t hesitate to
on the fly on
t hesitate to incorporate
the fly on top
full report contains the
hesitate to incorporate academic
rpcs have a higher
are at their correct
fly on top of
at their correct versions
on top of the
to incorporate academic results
top of the processing
have a higher outgoing
report contains the detailed
the same latency whereas
incorporate academic results into
of the processing nodes
academic results into operating
a higher outgoing queueing
results into operating system
same latency whereas layered
contains the detailed results
latency whereas layered interleaving
higher outgoing queueing delay
whereas layered interleaving recovers
outgoing queueing delay in
layered interleaving recovers singleton
and is open for
the detailed results of
we place t there
detailed results of the
interleaving recovers singleton losses
is open for new
queueing delay in the
scaling up to turn
results of the trace
up to turn the
open for new directions
to turn the ssa
delay in the absence
recovers singleton losses almost
of the trace study
place t there to
innovation as a life
t there to obtain
as a life style
turn the ssa into
the trace study on
the ssa into a
in the absence of
trace study on the
the absence of prefetching
study on the accuracy
ssa into a full
on the accuracy and
into a full scale
a life style microsoft
a full scale platform
there to obtain the
this is due to
to obtain the desired
life style microsoft is
the accuracy and performance
singleton losses almost immediately
is due to the
obtain the desired serialization
style microsoft is not
the desired serialization of
microsoft is not conservative
losses almost immediately and
is not conservative in
due to the majority
one of the immediate
accuracy and performance of
desired serialization of the
almost immediately and exhibits
serialization of the update
to the majority of
of the immediate future
and performance of the
not conservative in its
performance of the failure
conservative in its os
of the failure detector
the majority of the
the failure detector in
majority of the competing
failure detector in the
of the competing rpcs
detector in the internet
of the update transactions
in its os development
the update transactions and
immediately and exhibits latency
update transactions and t
the competing rpcs being
the immediate future challenges
and exhibits latency spikes
immediate future challenges is
exhibits latency spikes whenever
future challenges is the
the effectiveness of its
challenges is the necessity
competing rpcs being high
is the necessity of
rpcs being high priority
the necessity of evaluating
latency spikes whenever the
necessity of evaluating a
spikes whenever the longer
of evaluating a full
whenever the longer loss
being high priority fetch
the longer loss burst
while most vendors only
longer loss burst occurs
permutation routine let be
most vendors only consider
evaluating a full raps
vendors only consider changes
a full raps of
effectiveness of its partition
full raps of racs
routine let be an
of its partition detection
raps of racs deployment
its partition detection mechanism
let be an execution
only consider changes to
be an execution of
consider changes to their
an execution of the
r elated w ork
execution of the t
these rpcs are mostly
changes to their core
multiple partitioned and cloned
to their core os
host failure measurements and
rpcs are mostly replaced
failure measurements and measurements
partitioned and cloned services
measurements and measurements of
elated w ork maelstrom
and measurements of failure
are mostly replaced by
measurements of failure detection
mostly replaced by prefetches
of failure detection for
w ork maelstrom lies
failure detection for server
and cloned services running
ork maelstrom lies in
and denote by update
cloned services running on
maelstrom lies in the
which operate at a
services running on our
their core os services
detection for server fail
core os services under
lies in the intersection
os services under extreme
in the intersection of
services under extreme market
operate at a lower
running on our tightly
denote by update the
the intersection of two
by update the projection
intersection of two research
update the projection of
under extreme market pressure
the projection of on
on our tightly coupled
projection of on the
it will be available
of two research areas
will be available later
our tightly coupled cluster
be available later this
tightly coupled cluster would
available later this year
the core of windows
later this year through
at a lower priority
two research areas that
coupled cluster would lead
research areas that have
cluster would lead to
this year through the
would lead to a
year through the cornell
lead to a series
through the cornell university
to a series of
the cornell university technical
core of windows nt
cornell university technical report
a lower priority than
of on the set
a series of other
areas that have seen
series of other issues
university technical report server
of other issues that
lower priority than store
on the set of
of windows nt has
the set of database
other issues that should
windows nt has changed
set of database update
that have seen major
of database update transactions
nt has changed significantly
issues that should be
have seen major innovations
until any point where
seen major innovations in
has changed significantly over
major innovations in the
any point where a
transaction t reads objects
that should be investigated
t reads objects o
innovations in the last
point where a concurrent
changed significantly over the
in the last decade
significantly over the past
the last decade high
over the past years
where a concurrent demand
the past years to
placement given a set
past years to accommodate
given a set of
a concurrent demand fetch
years to accommodate the
a set of services
to accommodate the demands
concurrent demand fetch rpc
accommodate the demands of
demand fetch rpc raises
the demands of modern
how to place the
demands of modern computing
fetch rpc raises their
relevant url s the
haul communication and forward
to place the clones
communication and forward error
rpc raises their priorities
url s the horus
especially the upcoming release
place the clones on
the upcoming release of
raises their priorities to
s the horus project
and forward error correction
the horus project the
on with versions v
upcoming release of windows
their priorities to the
the clones on physical
horus project the cornell
clones on physical nodes
priorities to the fetch
project the cornell cluster
on physical nodes in
the cornell cluster computing
physical nodes in order
ip variants such as
nodes in order to
variants such as compound
in order to satisfy
such as compound tcp
a comparison of fetch
order to satisfy certain
cornell cluster computing project
to satisfy certain constraints
cluster computing project werner
computing project werner vogels
data and prefetch rpcs
formerly known as windows
project werner vogels personal
and prefetch rpcs reveals
known as windows nt
werner vogels personal home
prefetch rpcs reveals the
vogels personal home page
rpcs reveals the effect
personal home page papers
reveals the effect of
home page papers on
makes that the microsoft
the effect of the
that the microsoft takes
effect of the bandwidth
caching placement deciding if
take any serialization of
placement deciding if some
any serialization of update
deciding if some services
the microsoft takes the
if some services would
microsoft takes the operating
some services would benefit
takes the operating system
services would benefit if
of the bandwidth decrease
use transmission delay to
page papers on failure
transmission delay to detect
papers on failure detection
delay to detect backed
on failure detection http
to detect backed up
one exists according to
detect backed up routers
would benefit if they
the operating system functionality
the test run with
operating system functionality to
exists according to claim
system functionality to the
replacing or supplementing packet
functionality to the next
or supplementing packet loss
benefit if they are
supplementing packet loss as
if they are fitted
packet loss as a
test run with prefetching
loss as a signal
run with prefetching performs
as a signal of
with prefetching performs a
and consider the first
prefetching performs a fetch
a signal of congestion
they are fitted with
to the next level
are fitted with response
consider the first time
fitted with response caches
data rpc to get
the first time when
while such protocols solve
first time when all
such protocols solve the
and ultimately placing the
time when all the
the advances in windows
rpc to get the
ultimately placing the cache
protocols solve the congestion
when all the objects
solve the congestion collapse
placing the cache components
the congestion collapse experienced
to get the first
congestion collapse experienced by
all the objects the
collapse experienced by conventional
get the first file
the cache components in
experienced by conventional tcp
the objects the transaction
cache components in a
objects the transaction reads
components in a smart
which triggers prefetching from
are too numerous to
in a smart way
too numerous to enumerate
triggers prefetching from its
the transaction reads are
numerous to enumerate here
transaction reads are at
prefetching from its file
reads are at a
from its file group
they range from a
location placing multiple service
range from a file
are at a version
from a file system
placing multiple service clones
because of the large
at a version at
a file system cache
a version at least
file system cache for
multiple service clones on
system cache for disconnected
of the large delay
service clones on the
the large delay between
cache for disconnected operation
version at least as
they cannot mitigate the
at least as large
large delay between file
clones on the same
cannot mitigate the longer
least as large as
on the same physical
delay between file accesses
mitigate the longer packet
which was originally developed
as large as the
the same physical node
large as the versions
was originally developed at
as the versions that
the longer packet delivery
originally developed at cmu
the versions that t
developed at cmu in
versions that t reads
at cmu in the
longer packet delivery latencies
cmu in the coda
prefetches complete entirely without
same physical node to
at this time at
packet delivery latencies caused
physical node to exploit
complete entirely without any
this time at least
in the coda project
time at least one
node to exploit fast
at least one object
entirely without any overlapping
to exploit fast ipc
delivery latencies caused by
to a remote storage
least one object read
latencies caused by packet
one object read by
caused by packet loss
object read by t
without any overlapping demand
exploit fast ipc communication
a remote storage service
any overlapping demand fetches
remote storage service that
and they do not
the last written according
they do not eliminate
last written according to
do not eliminate the
storage service that automatically
not eliminate the need
fast ipc communication as
service that automatically moves
eliminate the need for
ipc communication as opposed
that automatically moves old
over the course of
has the correct version
the need for larger
communication as opposed to
need for larger buffers
the course of the
automatically moves old data
as opposed to network
moves old data from
opposed to network messages
old data from your
for larger buffers at
data from your hard
larger buffers at end
to network messages if
course of the second
but others might not
from your hard disk
network messages if the
your hard disk to
messages if the benefits
hard disk to remote
if the benefits overweigh
disk to remote servers
of the second period
to remote servers if
the second period of
remote servers if you
second period of time
servers if you are
the benefits overweigh the
if you are running
fec has seen major
assume without loss of
benefits overweigh the cost
without loss of generality
has seen major innovations
overweigh the cost incurred
bandwidth becomes insufficient for
the cost incurred by
becomes insufficient for a
cost incurred by resource
insufficient for a prefetch
incurred by resource contention
seen major innovations in
loss of generality that
major innovations in the
for a prefetch to
by resource contention on
you are running out
resource contention on the
innovations in the last
contention on the shared
a prefetch to complete
of generality that the
are running out of
in the last fifteen
running out of disk
the last fifteen years
generality that the last
on the shared host
that the last version
prefetch to complete during
the last version written
out of disk space
last version written is
to complete during the
version written is vn
management tools developing tools
level fec was first
written is vn of
fec was first described
from tight security integration
was first described for
is vn of object
first described for high
tools developing tools that
transis a communication subsystem
vn of object on
a communication subsystem for
of object on at
communication subsystem for high
object on at step
speed wan networks as
on at step t
wan networks as early
at step t of
subsystem for high availability
developing tools that monitor
networks as early as
tools that monitor service
s delay between accesses
that monitor service properties
as the dominant security
idigest of papers of
the dominant security provider
denote by t the
monitor service properties such
by t the latest
and raisepriority rpcs are
service properties such as
t the latest time
properties such as response
raisepriority rpcs are triggered
to a complete integration
the latest time at
such as response time
latest time at which
rpcs are triggered by
a complete integration of
time at which a
complete integration of network
are triggered by the
at which a wrong
integration of network quality
triggered by the consequent
which a wrong version
of network quality of
by the consequent cache
network quality of services
the consequent cache misses
by restarting new clones
quality of services tools
not the one read
of services tools including
the one read by
as the bandwidth decreases
services tools including data
one read by t
tools including data transmission
it was applied by
including data transmission shapers
was applied by researchers
the queueing delays increase
applied by researchers in
queueing delays increase as
by researchers in the
delays increase as a
researchers in the context
increase as a proportion
in the context of
using vmm tricks virtual
and assume wlog it
vmm tricks virtual machines
assume wlog it is
as a proportion of
tricks virtual machines can
a proportion of the
virtual machines can be
proportion of the total
machines can be used
wlog it is version
can be used to
it is version vn
data transmission shapers and
of the total time
fast message ordering and
the context of atm
message ordering and membership
context of atm networks
ordering and membership using
be used to migrate
and membership using a
the total time spent
k of object on
transmission shapers and priority
used to migrate transparently
shapers and priority scheduling
total time spent on
membership using a logical
to migrate transparently a
using a logical token
time spent on prefetches
and priority scheduling and
migrate transparently a collection
priority scheduling and queuing
rather than the desired
transparently a collection of
than the desired version
a collection of services
the desired version vn
collection of services on
of services on a
and from attributed based
services on a different
from attributed based distributed
on a different physical
level fec for ip
a different physical processor
fec for ip networks
attributed based distributed component
for ip networks was
based distributed component programming
ip networks was revived
the modifying client to
distributed component programming to
networks was revived in
component programming to indexing
modifying client to flush
or provide isolation guarantees
programming to indexing support
provide isolation guarantees between
to indexing support integrated
isolation guarantees between co
we now describe a
indexing support integrated in
now describe a single
client to flush its
support integrated in the
describe a single step
integrated in the file
to flush its updates
a single step of
in the file system
single step of the
flush its updates whenever
step of the routine
its updates whenever another
updates whenever another client
whenever another client accesses
another client accesses the
client accesses the file
consider the transactions between
the ssa can be
the transactions between t
ssa can be seen
transactions between t and
can be seen as
we are witnesses of
be seen as a
are witnesses of a
between t and t
witnesses of a unique
in the context of
of a unique process
seen as a platform
the context of both
as a platform that
context of both reliable
a platform that leverages
of both reliable multicast
separates invalidating a file
both reliable multicast and
platform that leverages tradeoffs
reliable multicast and long
invalidating a file from
divide these transactions into
that leverages tradeoffs between
these transactions into three
a file from transmitting
never before have we
leverages tradeoffs between weaker
transactions into three sets
tradeoffs between weaker consistency
file from transmitting its
rizzo subsequently provided a
before have we seen
subsequently provided a working
from transmitting its update
with a compensating gossip
have we seen such
a compensating gossip repair
reliable communication in the
compensating gossip repair mechanism
transactions dependent on the
we seen such a
we have implemented a
provided a working implementation
communication in the presence
dependent on the transaction
seen such a radical
on the transaction at
have implemented a similar
for higher availability and
a working implementation of
higher availability and simplicity
such a radical overhaul
the transaction at t
a radical overhaul of
in the presence of
radical overhaul of an
the presence of failure
overhaul of an operating
implemented a similar scheme
this is an old
working implementation of a
is an old idea
acm transaction on computer
an old idea first
transaction on computer systems
old idea first explored
of an operating system
idea first explored in
a similar scheme in
implementation of a software
an operating system targeted
first explored in the
operating system targeted for
explored in the grapevine
system targeted for the
similar scheme in mfs
of a software packet
transactions on which t
targeted for the enterprise
on which t is
for the enterprise market
which t is dependent
in which an access
which an access to
an access to a
access to a file
in general this market
to a file which
general this market is
a file which has
and later in systems
this market is very
later in systems like
file which has an
market is very conservative
in systems like bayou
is very conservative and
which has an uncommitted
very conservative and not
transactions that do not
conservative and not interested
has an uncommitted update
that do not belong
and not interested in
do not belong to
an uncommitted update at
not interested in taking
not belong to either
uncommitted update at a
which offer a broad
belong to either group
offer a broad operational
interested in taking risks
a broad operational spectrum
update at a different
broad operational spectrum between
at a different client
operational spectrum between strong
a different client will
the following lemma states
however the problems of
following lemma states that
the problems of scale
maelstrom represents a natural
different client will force
lemma states that there
acid in the distributed
represents a natural evolution
in the distributed database
client will force the
states that there is
a natural evolution of
that there is no
natural evolution of these
there is no dependency
will force the writeback
is no dependency among
evolution of these ideas
no dependency among objects
management and distribution are
dependency among objects in
group membership and viewsynchronous
among objects in sets
the distributed database cases
and distribution are asking
the mfs consistency algorithm
the emphasis on applying
mfs consistency algorithm differs
membership and viewsynchronous communication
distribution are asking for
and viewsynchronous communication in
consistency algorithm differs in
emphasis on applying error
several database and distributed
viewsynchronous communication in partitionable
database and distributed systems
communication in partitionable asynchronous
on applying error correcting
in partitionable asynchronous systems
algorithm differs in its
applying error correcting codes
differs in its incorporation
error correcting codes at
are asking for radical
correcting codes at higher
and hence there is
codes at higher levels
hence there is no
at higher levels of
there is no intersection
higher levels of the
is no intersection between
levels of the software
no intersection between the
and distributed systems take
of the software stack
asking for radical solutions
the software stack has
for radical solutions to
software stack has been
intersection between the sets
stack has been accompanied
distributed systems take advantage
has been accompanied by
systems take advantage of
been accompanied by advances
take advantage of the
accompanied by advances in
advantage of the same
by advances in the
radical solutions to get
in its incorporation of
advances in the codes
solutions to get to
of the same tradeoff
to get to a
in the codes themselves
get to a computing
its incorporation of file
to a computing base
incorporation of file access
a computing base that
prior to the mid
computing base that can
for example allowing multiple
base that can bring
of file access information
example allowing multiple updates
that can bring us
allowing multiple updates to
can bring us into
multiple updates to occur
bring us into the
rather than enforce the
updates to occur simultaneously
us into the next
if they were dependent
than enforce the same
the standard encoding used
enforce the same level
standard encoding used was
into the next century
then version vn of
the same level of
encoding used was reed
to occur simultaneously at
version vn of object
same level of consistency
occur simultaneously at distinct
vn of object on
simultaneously at distinct replicas
of object on depends
at distinct replicas by
object on depends on
one of the markets
on depends on version
level of consistency for
distinct replicas by specifying
an erasure code that
replicas by specifying a
of the markets where
by specifying a maximum
depends on version vn
specifying a maximum accepted
of consistency for all
the markets where we
unreliable failure detectors for
erasure code that performs
markets where we will
a maximum accepted deviation
failure detectors for reliable
maximum accepted deviation from
consistency for all files
k of object on
where we will see
detectors for reliable distributed
accepted deviation from strong
for reliable distributed systems
deviation from strong consistency
mfs differentiates between private
we will see the
code that performs excellently
will see the main
to appear in journal
see the main competitive
appear in journal of
and this dependency is
in journal of the
differentiates between private files
that performs excellently at
the main competitive battle
this dependency is reflected
main competitive battle between
dependency is reflected in
journal of the acm
is reflected in their
competitive battle between microsoft
reflected in their t
which have recently only
performs excellently at small
battle between microsoft and
excellently at small scale
between microsoft and others
at small scale but
microsoft and others will
have recently only been
and others will be
small scale but does
others will be that
recently only been accessed
because they are unbounded
will be that of
scale but does not
be that of the
only been accessed by
that of the e
but does not scale
been accessed by a
does not scale to
accessed by a single
transaction t has read
not scale to large
t has read version
by a single client
scale to large sets
has read version vn
to large sets of
web farms with hundreds
large sets of data
tolerating a bounded number
sets of data and
farms with hundreds of
of data and error
with hundreds of nodes
a bounded number of
data and error correcting
bounded number of consistency
and error correcting symbols
which are accessed by
number of consistency violations
are accessed by multiple
which is older than
of consistency violations to
with support services for
consistency violations to increase
is older than vn
violations to increase concurrency
accessed by multiple clients
to increase concurrency of
impossibility of distributed consensus
increase concurrency of transactions
this scalability barrier resulted
support services for load
of distributed consensus with
services for load balancing
scalability barrier resulted in
enforcing cache consistency between
barrier resulted in the
distributed consensus with one
resulted in the development
cache consistency between clients
in the development of
consensus with one faulty
the development of new
with one faulty process
development of new variants
consistency between clients necessarily
the read of the
of new variants of
read of the stale
journal of the acm
new variants of low
between clients necessarily requires
of the stale version
or replication according to
the stale version vn
replication according to the
clients necessarily requires that
variants of low density
according to the need
of low density parity
necessarily requires that shared
low density parity check
requires that shared files
distributed and single image
that shared files are
and single image management
would have been detected
shared files are kept
have been detected by
files are kept highly
been detected by t
are kept highly consistent
cache and the transaction
are really pushing the
and the transaction would
but modifications to private
really pushing the envelope
modifications to private files
pushing the envelope of
to private files can
the envelope of all
private files can be
envelope of all operating
the transaction would have
of all operating systems
transaction would have been
all operating systems that
would have been aborted
files can be written
operating systems that are
our work on the
systems that are currently
can be written back
therefore the assumption is
that are currently on
the assumption is wrong
are currently on the
r van and vogels
currently on the market
be written back to
work on the ssa
and the sets are
written back to the
on the ssa is
windows nt is still
back to the server
the sets are indeed
the ssa is the
sets are indeed independent
to the server less
nt is still considered
ssa is the first
is still considered to
is the first to
still considered to be
support for highly reliable
the server less aggressively
the first to apply
considered to be the
first to apply such
to be the new
to apply such thinking
be the new kid
apply such thinking to
the new kid on
the technique of using
new kid on the
such thinking to a
kid on the block
perhaps an empty set
on the block in
technique of using file
the block in the
thinking to a cluster
block in the internet
to a cluster computing
is unrelated to sets
a cluster computing environment
of using file access
in the internet services
using file access patterns
the internet services world
file access patterns to
which are orders of
access patterns to adjust
are orders of magnitude
patterns to adjust a
acm sigops european workshop
but it is clear
we therefore switch sets
orders of magnitude faster
to adjust a cache
it is clear that
of magnitude faster than
adjust a cache consistency
is clear that the
platform was designed to
magnitude faster than reed
was designed to provide
clear that the risks
designed to provide a
a cache consistency protocol
that the risks that
to provide a cluster
solomon and much more
provide a cluster based
and much more scalable
cache consistency protocol has
the risks that are
a cluster based environment
risks that are taken
consistency protocol has been
that are taken now
protocol has been used
are taken now are
has been used in
taken now are the
been used in the
now are the right
much more scalable in
are the right moves
more scalable in input
used in the sprite
cluster based environment for
maintaining a serialization of
based environment for scalable
a serialization of update
environment for scalable internet
the right moves to
for scalable internet services
right moves to prepare
scalable internet services of
scalable in input size
in the sprite distributed
moves to prepare the
internet services of the
to prepare the operating
services of the sort
the sprite distributed operation
consider the following serialization
prepare the operating system
of the sort used
the operating system for
the sort used in
sprite distributed operation system
but require slightly more
operating system for operation
sort used in web
system for operation in
used in web servers
xi denotes a transaction
require slightly more data
denotes a transaction x
for operation in these
a transaction x in
slightly more data to
operation in these emerging
more data to be
caching proxies and transformation
data to be received
proxies and transformation proxies
to be received at
in these emerging massive
be received at the
transaction x in set
received at the decoder
x in set i
reliable multicast for distributed
these emerging massive computing
multicast for distributed interactive
service components are controlled
though in sprite changes
components are controlled by
emerging massive computing environments
are controlled by a
for distributed interactive simulation
controlled by a front
while the layered interleaving
by a front end
in sprite changes in
the layered interleaving code
a front end machine
layered interleaving code used
front end machine that
interleaving code used by
end machine that acts
code used by maelstrom
the bugs innovation comes
used by maelstrom is
sprite changes in caching
proceedings of acm sigcomm
cache consistency we proceed
machine that acts as
consistency we proceed to
by maelstrom is similar
we proceed to prove
changes in caching policy
bugs innovation comes at
that acts as a
innovation comes at a
proceed to prove theorem
comes at a price
in caching policy were
acts as a request
maelstrom is similar to
as a request dispatcher
is similar to the
caching policy were made
one of the costs
policy were made when
similar to the tornado
a request dispatcher and
of the costs of
request dispatcher and incorporates
the costs of introducing
were made when a
lt and raptor codes
made when a file
and raptor codes in
dispatcher and incorporates the
raptor codes in its
costs of introducing a
codes in its use
when a file was
of introducing a significant
a file was opened
introducing a significant amount
let be an execution
and incorporates the load
be an execution of
incorporates the load balancing
a significant amount of
the load balancing and
file was opened simultaneously
an execution of the
in its use of
significant amount of new
its use of simple
was opened simultaneously at
execution of the t
load balancing and restart
amount of new code
balancing and restart logics
opened simultaneously at different
use of simple xor
of new code is
of simple xor operations
simultaneously at different clients
new code is the
and denote by update
code is the number
denote by update the
is the number of
end processes are detected
the number of software
processes are detected to
number of software defects
it differs from them
of software defects per
while mfs uses longer
are detected to have
by update the projection
detected to have failed
software defects per lines
view synchronous communication in
defects per lines of
update the projection of
per lines of codes
synchronous communication in large
differs from them in
the remainder of this
from them in one
new processes are forked
communication in large scale
processes are forked to
lines of codes increases
are forked to take
remainder of this section
them in one very
the projection of on
forked to take over
projection of on the
of this section describes
while measurements actually let
this section describes our
measurements actually let us
section describes our consistency
in one very important
nd open broadcast workshop
of on the set
to take over the
on the set of
take over the load
the set of database
one very important aspect
set of database update
actually let us believe
of database update transactions
describes our consistency algorithm
very important aspect it
let us believe that
tacc workers can be
us believe that microsoft
workers can be composed
believe that microsoft products
can be composed to
our consistency algorithm in
important aspect it seeks
that microsoft products are
aspect it seeks to
microsoft products are quite
products are quite reliable
consistency algorithm in detail
be composed to address
are quite reliable at
composed to address more
it seeks to minimize
to address more complex
seeks to minimize the
and an evaluation of
to minimize the latency
an evaluation of its
minimize the latency between
address more complex tasks
the latency between the
evaluation of its effectiveness
quite reliable at operating
latency between the arrival
reliable at operating systems
of its effectiveness in
tacc stands for transformation
between the arrival of
tm a set of
the arrival of a
a set of readonly
its effectiveness in reducing
arrival of a packet
set of readonly transactions
effectiveness in reducing cache
increasing reliability of communication
of a packet at
reliability of communication in
a packet at the
of communication in large
packet at the send
communication in large scale
thousand lines of code
in large scale distributed
in reducing cache inconsistencies
of readonly transactions performed
ssa can be seen
readonly transactions performed through
side proxy and its
transactions performed through a
can be seen as
performed through a single
proxy and its successful
host reader writer parameter
and its successful reception
be seen as revisiting
reader writer parameter delay
seen as revisiting these
fresh code has a
as revisiting these architectural
code has a disastrous
revisiting these architectural ideas
has a disastrous effect
through a single t
a disastrous effect on
writer parameter delay between
its successful reception at
these architectural ideas in
successful reception at the
architectural ideas in conjunction
disastrous effect on this
ideas in conjunction with
parameter delay between accessing
in conjunction with chain
reception at the receive
conjunction with chain replication
effect on this number
delay between accessing modules
if the read sets
between accessing modules operations
the read sets of
accessing modules operations per
read sets of two
the outlook becomes even
sets of two transactions
modules operations per module
outlook becomes even more
operations per module delay
becomes even more worrisome
per module delay between
even more worrisome when
module delay between operations
more worrisome when we
codes such as tornado
worrisome when we realize
of two transactions include
when we realize that
two transactions include the
such as tornado encode
transactions include the same
delay between operations delay
have long supported clustered
between operations delay between
long supported clustered architectures
operations delay between accessing
we realize that microsoft
as tornado encode over
realize that microsoft is
tornado encode over a
that microsoft is not
and were the first
microsoft is not only
encode over a fixed
were the first systems
delay between accessing modules
the first systems to
between accessing modules operations
first systems to exploit
accessing modules operations per
systems to exploit the
modules operations per module
to exploit the style
over a fixed set
exploit the style of
a fixed set of
the style of partitioning
a generic architecture for
is not only introducing
generic architecture for dependable
not only introducing new
architecture for dependable distributed
only introducing new code
operations per module delay
fixed set of input
include the same object
set of input symbols
style of partitioning that
per module delay between
for dependable distributed computing
the same object o
but is also changing
of partitioning that leads
is also changing all
partitioning that leads to
also changing all of
that leads to a
changing all of its
leads to a raps
all of its old
to a raps of
of its old code
a raps of racs
module delay between operations
without treating symbols differently
we say the one
treating symbols differently based
say the one that
an automated process is
delay between operations size
symbols differently based on
raps of racs solution
differently based on their
automated process is converting
based on their sequence
between operations size of
the one that read
process is converting all
one that read a
is converting all of
operations size of external
on their sequence in
that read a larger
their sequence in the
read a larger version
converting all of the
size of external files
sequence in the data
of external files value
in the data stream
most database systems adhere
a larger version of
database systems adhere closely
all of the windows
systems adhere closely to
of the windows nt
adhere closely to the
the windows nt code
larger version of o
windows nt code to
closely to the acid
as mentioned in section
version of o depends
mentioned in section iv
of o depends on
to the acid model
o depends on the
nt code to be
depends on the other
at potentially high cost
potentially high cost in
high cost in terms
layered interleaving is unique
cost in terms of
interleaving is unique in
all transactions access the
in terms of reduced
transactions access the same
is unique in allowing
terms of reduced availability
access the same cache
of reduced availability during
unique in allowing the
reduced availability during faults
in allowing the recovery
allowing the recovery latency
a flexible group communications
and the cache is
flexible group communications system
thousand lines of code
the cache is unbounded
the recovery latency of
lines of code per
recovery latency of lost
of code per day
latency of lost packets
code per day and
cornell university technical report
per day and is
of lost packets to
day and is believed
lost packets to depend
and is believed to
discuss this problem in
is believed to catch
values are only replaced
believed to catch all
packets to depend on
to catch all pointer
are only replaced by
catch all pointer arithmetic
to depend on the
all pointer arithmetic cases
only replaced by newer
depend on the actual
replaced by newer versions
on the actual burst
the actual burst size
actual burst size experienced
an important question is
so it is easy
important question is whether
it is easy to
question is whether the
is easy to see
as opposed to the
ultimately arguing for precisely
opposed to the maximum
easy to see that
to the maximum tolerable
arguing for precisely the
the maximum tolerable burst
for precisely the weak
maximum tolerable burst size
precisely the weak update
is whether the introduced
the weak update model
tolerable burst size as
weak update model that
whether the introduced functionality
update model that we
burst size as with
the introduced functionality is
model that we adopted
to see that there
that we adopted here
size as with other
see that there are
as with other encoding
that there are no
with other encoding schemes
introduced functionality is worth
there are no cycles
functionality is worth the
are no cycles such
application servers like the
no cycles such that
servers like the j
is worth the unavoidable
cycles such that two
worth the unavoidable initial
such that two transactions
the unavoidable initial instability
that two transactions depend
c onclusion modern distributed
two transactions depend on
unavoidable initial instability that
onclusion modern distributed systems
initial instability that is
transactions depend on one
modern distributed systems are
instability that is bound
depend on one another
that is bound to
distributed systems are compelled
is bound to occur
systems are compelled by
are compelled by real
the dependency graph therefore
dependency graph therefore describes
whenever taking risks to
graph therefore describes a
taking risks to achieve
therefore describes a partial
risks to achieve major
describes a partial order
to achieve major improvements
a partial order of
world imperatives to coordinate
offer persistent state support
imperatives to coordinate across
partial order of the
to coordinate across data
order of the read
coordinate across data centers
persistent state support by
across data centers separated
there is always the
data centers separated by
state support by wrapping
centers separated by thousands
is always the down
support by wrapping soft
separated by thousands of
always the down side
by thousands of miles
by wrapping soft state
the down side that
wrapping soft state business
and we choose an
down side that there
soft state business logic
we choose an arbitrary
side that there is
packet loss cripples the
state business logic components
choose an arbitrary total
business logic components on
an arbitrary total ordering
logic components on top
arbitrary total ordering that
components on top of
total ordering that respects
on top of a
ordering that respects this
top of a relational
that there is some
of a relational or
configuration parameters for the
there is some change
parameters for the cache
a relational or object
that respects this partial
loss cripples the performance
respects this partial order
cripples the performance of
is some change of
the performance of such
for the cache consistency
some change of failure
the cache consistency evaluation
change of failure and
assume wlog the order
performance of such systems
they also target large
of failure and it
individual instances are uniformally
wlog the order is
failure and it is
and reliability and flow
scale highly available services
instances are uniformally distributed
the order is t
and it is likely
are uniformally distributed within
and hence we believe
uniformally distributed within the
control protocols designed for
it is likely that
protocols designed for lans
distributed within the listed
hence we believe they
designed for lans and
we believe they could
within the listed ranges
is likely that we
believe they could benefit
likely that we will
or the commodity internet
they could benefit from
that we will see
could benefit from ssa
the commodity internet fail
we will see a
commodity internet fail to
will see a number
internet fail to achieve
see a number of
a number of components
if the file is
number of components of
the file is shared
of components of nt
in a similar vein
components of nt coming
file is shared and
of nt coming under
optimal performance on the
nt coming under intense
is shared and no
we take an initial
coming under intense scrutiny
take an initial arbitrary
under intense scrutiny from
performance on the high
intense scrutiny from industry
an initial arbitrary serialization
scrutiny from industry and
shared and no other
from industry and academia
and no other shared
of and permute it
no other shared update
haul lambda networks linking
and permute it according
lambda networks linking data
permute it according to
networks linking data centers
framework makes it easy
other shared update is
it according to the
makes it easy to
according to the route
shared update is being
deploying new protocols is
it easy to create
to the route above
easy to create robust
the route above to
to create robust scalable
route above to place
update is being sent
new protocols is not
such as the directory
protocols is not an
as the directory services
create robust scalable services
above to place t
is not an option
the thread begins transmitting
not an option for
may become a performance
thread begins transmitting the
become a performance bottleneck
begins transmitting the update
a performance bottleneck in
ninja is arguably more
performance bottleneck in the
transmitting the update at
an option for commodity
bottleneck in the overall
option for commodity clusters
in the overall distributed
for commodity clusters where
the overall distributed operation
is arguably more flexible
the result is a
arguably more flexible than
result is a permutation
the update at the
commodity clusters where standardization
or the wide spread
more flexible than application
update at the store
flexible than application servers
the wide spread security
clusters where standardization is
wide spread security integration
where standardization is critical
than application servers in
standardization is critical for
spread security integration could
application servers in that
security integration could introduce
servers in that it
integration could introduce a
is critical for cost
could introduce a critical
critical for cost mitigation
introduce a critical dependency
if another shared update
a critical dependency on
another shared update is
critical dependency on the
shared update is being
dependency on the high
update is being written
maelstrom is an edge
in that it performs
is an edge appliance
that it performs connection
availability of the security
is being written back
an edge appliance that
we take all transactions
edge appliance that uses
take all transactions that
it performs connection management
all transactions that precede
appliance that uses forward
transactions that precede t
performs connection management and
a synchronous forward invalidation
of the security servers
synchronous forward invalidation rpc
connection management and automatically
that uses forward error
management and automatically partitions
forward invalidation rpc is
and automatically partitions and
invalidation rpc is made
automatically partitions and replicates
rpc is made to
partitions and replicates persistent
uses forward error correction
and replicates persistent state
does not depend on
is made to the
from a research point
forward error correction to
not depend on them
error correction to mask
a research point of
but the framework takes
made to the server
and place them after
to the server at
place them after t
the server at the
research point of view
the framework takes a
correction to mask packet
framework takes a different
server at the highest
takes a different tiered
at the highest priority
these problems do not
a different tiered approach
problems do not really
we call this permutation
do not really bother
different tiered approach to
to mask packet loss
tiered approach to services
mask packet loss from
approach to services based
not really bother us
and then the update
to services based on
packet loss from endto
next we place t
then the update is
the advantage of performing
services based on bases
advantage of performing research
the update is queued
of performing research on
update is queued for
performing research on a
active proxies and units
is queued for later
research on a system
queued for later high
ip throughput and latency
and represents shared state
throughput and latency by
can be placed immediately
and latency by orders
be placed immediately after
latency by orders of
placed immediately after t
by orders of magnitude
which has distribution at
orders of magnitude when
represents shared state by
of magnitude when loss
shared state by means
magnitude when loss occurs
state by means of
has distribution at its
by means of distributed
distribution at its core
means of distributed data
a forward invalidation is
maelstrom is easy to
at its core greatly
is easy to install
we place it there
easy to install and
forward invalidation is only
of distributed data structures
its core greatly outweighs
place it there to
to install and deploy
it there to form
invalidation is only made
core greatly outweighs the
is only made if
greatly outweighs the consequences
and is completely transparent
outweighs the consequences of
conclusion our paper presents
the consequences of working
our paper presents the
consequences of working with
paper presents the scalable
of working with a
presents the scalable services
working with a cutting
the scalable services architecture
is completely transparent to
with a cutting edge
is independent of t
only made if the
completely transparent to applications
a cutting edge operating
transparent to applications and
cutting edge operating system
then all its preceding
to applications and protocols
a new platform for
all its preceding transactions
applications and protocols literally
new platform for porting
and protocols literally providing
platform for porting a
made if the update
protocols literally providing reliability
for porting a large
literally providing reliability in
porting a large class
however i must admit
a large class of
if the update cannot
according to the dependency
providing reliability in an
large class of service
i must admit that
the update cannot be
to the dependency graph
reliability in an inexpensive
must admit that at
in an inexpensive box
update cannot be transmitted
oriented applications onto clusters
admit that at more
cannot be transmitted immediately
are unrelated to t
that at more then
the ssa was designed
ssa was designed to
at more then one
was designed to be
designed to be as
and are therefore located
in practice it can
are therefore located after
practice it can therefore
to be as simple
more then one occasion
therefore located after it
it can therefore be
be as simple as
then one occasion my
as simple as possible
can therefore be omitted
the permutations required are
one occasion my students
permutations required are therefore
therefore be omitted at
required are therefore after
be omitted at high
are therefore after t
and at the core
occasion my students had
at the core uses
omitted at high bandwidth
the core uses just
at high bandwidth or
core uses just two
high bandwidth or when
uses just two primitive
my students had to
just two primitive mechanisms
bandwidth or when traffic
students had to control
or when traffic is
had to control their
when traffic is low
to control their murderous
tcp chains that support
chains that support a
control their murderous intentions
that support a variant
optical domain performance monitoring
their murderous intentions towards
support a variant of
a variant of chain
murderous intentions towards the
sending a forward invalidation
all relevant update transactions
intentions towards the iis
variant of chain replication
a forward invalidation rpc
towards the iis or
forward invalidation rpc without
and gossip epidemics which
invalidation rpc without requiring
gossip epidemics which are
the iis or mts
epidemics which are used
rpc without requiring the
relevant update transactions are
iis or mts developers
update transactions are located
without requiring the modifying
which are used to
transactions are located after
are used to manage
are located after t
requiring the modifying process
the optical fiber communication
or mts developers or
optical fiber communication conference
the modifying process to
used to manage configuration
mts developers or were
to manage configuration data
developers or were they
modifying process to wait
manage configuration data and
or were they kept
configuration data and initiate
process to wait introduces
were they kept their
data and initiate repair
and therefore the permutations
and initiate repair after
they kept their good
initiate repair after failures
therefore the permutations required
kept their good spirits
the permutations required are
their good spirits by
permutations required are all
required are all after
good spirits by contemplating
are all after t
with appropriate parameter settings
spirits by contemplating the
by contemplating the horrible
the consistency maintenance algorithm
contemplating the horrible tortures
consistency maintenance algorithm a
the horrible tortures one
since in all cases
maintenance algorithm a transient
given a gossip rate
algorithm a transient inconsistency
a gossip rate that
in all cases the
gossip rate that is
all cases the permutations
horrible tortures one could
cases the permutations are
rate that is sufficiently
the permutations are after
when the server receives
tortures one could perform
the server receives a
one could perform on
server receives a forward
could perform on the
receives a forward invalidation
permutations are after t
that is sufficiently fast
perform on the person
is sufficiently fast relative
on the person that
sufficiently fast relative to
the person that had
fast relative to the
person that had designed
relative to the update
that had designed the
a forward invalidation for
to the update rates
forward invalidation for a
the update rates seen
invalidation for a shared
update rates seen in
for a shared the
rates seen in the
a shared the mfs
they do not affect
had designed the com
do not affect the
shared the mfs cache
seen in the cluster
designed the com security
not affect the correctness
the com security architecture
the mfs cache consistency
isn t quite enough
affect the correctness of
mfs cache consistency algorithm
the correctness of t
cache consistency algorithm is
windows research there are
we find that the
research there are some
consistency algorithm is intended
find that the ssa
there are some properties
algorithm is intended to
that the ssa can
we take the resulting
the ssa can rapidly
take the resulting permutation
are some properties of
ssa can rapidly and
is intended to achieve
the resulting permutation that
some properties of windows
can rapidly and automatically
properties of windows nt
resulting permutation that we
rapidly and automatically reconfigure
intended to achieve a
permutation that we call
of windows nt that
and automatically reconfigure itself
windows nt that make
to achieve a file
automatically reconfigure itself after
nt that make it
reconfigure itself after a
that make it particularly
itself after a failure
or begins receiving an
after a failure and
make it particularly suitable
and move all transactions
it particularly suitable for
begins receiving an update
particularly suitable for research
receiving an update for
suitable for research purposes
an update for a
a failure and can
move all transactions that
failure and can rapidly
all transactions that neither
update for a file
the operating system kernel
and can rapidly repair
operating system kernel for
transactions that neither t
system kernel for example
can rapidly repair data
it records the idenhigh
rapidly repair data inconsistencies
kernel for example is
repair data inconsistencies that
for example is designed
records the idenhigh degree
example is designed with
data inconsistencies that arise
is designed with extensibility
the idenhigh degree of
inconsistencies that arise during
designed with extensibility in
that arise during the
with extensibility in mind
arise during the period
idenhigh degree of consistency
depend on to right
during the period when
on to right after
to allow developers of
the period when the
allow developers of hardware
subject to the constraints
developers of hardware based
to the constraints imposed
of hardware based services
the constraints imposed by
to right after t
period when the cluster
constraints imposed by tity
new protocols and file
when the cluster configuration
protocols and file systems
the cluster configuration was
and file systems to
cluster configuration was still
imposed by tity of
where did my performance
file systems to add
configuration was still disrupted
systems to add their
by tity of the
did my performance go
the resulting permutation is
to add their functionality
tity of the writer
our goal is to
add their functionality to
goal is to make
their functionality to the
is to make the
functionality to the system
to make the software
to the system without
marks the file as
the system without much
the file as dirty
make the software available
we repeat this process
the software available to
repeat this process until
software available to a
available to a general
file as dirty and
rate limiting rears its
as dirty and issues
limiting rears its ugly
dirty and issues callbacks
rears its ugly head
and issues callbacks to
to a general user
system without much effort
a general user community
issues callbacks to file
this process until we
all kernel code is
process until we place
callbacks to file semantics
general user community in
until we place all
kernel code is developed
we place all read
code is developed following
to file semantics and
is developed following a
file semantics and the
developed following a strict
semantics and the desirability
following a strict object
and the desirability of
a strict object oriented
the desirability of minimising
this is a serialization
strict object oriented paradigm
is a serialization of
object oriented paradigm and
a serialization of the
oriented paradigm and its
serialization of the update
paradigm and its functionality
of the update transactions
desirability of minimising overhead
the update transactions in
and its functionality can
update transactions in and
its functionality can only
transactions in and all
functionality can only be
in and all read
can only be accessed
we all the clients
only be accessed through
all the clients caching
be accessed through interfaces
acknowledgments the authors are
only transactions that accessed
the authors are grateful
transactions that accessed the
authors are grateful to
that accessed the same
are grateful to the
the clients caching it
grateful to the research
none of its implementation
to the research team
accessed the same cache
the research team at
of its implementation is
research team at afrl
its implementation is visible
if one of these
team at afrl in
one of these clients
we have therefore shown
of these clients fetches
have therefore shown that
these clients fetches the
therefore shown that in
at afrl in rome
shown that in any
one of the designs
clients fetches the file
of the designs abstractions
fetches the file have
the designs abstractions of
the file have opted
that in any execution
designs abstractions of the
file have opted for
abstractions of the windows
for their help in
of the windows nt
their help in understanding
the windows nt kernel
have opted for a
in any execution of
help in understanding the
windows nt kernel i
in understanding the challenges
nt kernel i find
understanding the challenges of
kernel i find it
any execution of t
opted for a compromise
the challenges of using
i find it particularly
challenges of using service
find it particularly fascinating
for a compromise which
it particularly fascinating to
of using service oriented
particularly fascinating to work
using service oriented architectures
fascinating to work with
a compromise which results
cache the update transactions
compromise which results in
the update transactions can
to work with is
update transactions can be
a cross layer study
transactions can be serialized
cross layer study of
work with is the
layer study of packet
which results in a
service oriented architectures in
can be serialized with
with is the device
study of packet loss
results in a small
oriented architectures in large
be serialized with readonly
is the device object
serialized with readonly transactions
in a small overhead
architectures in large scale
of packet loss in
in large scale settings
with readonly transactions that
a small overhead before
readonly transactions that accessed
small overhead before the
transactions that accessed a
packet loss in all
that accessed a single
overhead before the update
and to the researchers
a device object in
to the researchers at
before the update has
accessed a single cache
device object in an
the researchers at amazon
object in an instance
the update has been
in an instance created
update has been committed
an instance created by
which means that t
instance created by driver
created by driver objects
the server sends highbut
cache implements cache serializability
server sends highbut admits
for helping us understand
which encapsulates a unit
helping us understand the
encapsulates a unit of
us understand the architectures
a unit of kernel
sends highbut admits the
understand the architectures employed
unit of kernel based
the architectures employed in
of kernel based software
highbut admits the possibility
architectures employed in very
admits the possibility of
employed in very large
whether this is a
in very large data
the possibility of a
this is a device
very large data centers
is a device driver
possibility of a transient
of a transient inconsistency
a network protocol or
network protocol or a
priority server pull rpcs
protocol or a file
server pull rpcs to
or a file system
pull rpcs to the
a file system filter
rpcs to the clients
to the clients with
the clients with outstanding
these objects have the
clients with outstanding upthe
objects have the interesting
with outstanding upthe algorithm
have the interesting property
outstanding upthe algorithm requires
the interesting property that
upthe algorithm requires information
interesting property that they
algorithm requires information about
property that they can
requires information about client
that they can be
information about client accesses
they can be attached
about client accesses in
can be attached to
client accesses in dates
be attached to other
attached to other device
to other device objects
which causes them to
causes them to raise
them to raise the
to raise the priority
and as such can
raise the priority of
as such can intercept
the priority of any
such can intercept and
priority of any store
can intercept and manipulate
intercept and manipulate all
an exercise in distributed
and manipulate all requests
exercise in distributed computing
manipulate all requests flowing
data order to divide
all requests flowing to
order to divide files
communications of the acm
to divide files according
requests flowing to and
divide files according their
flowing to and from
files according their status
to and from the
and from the original
from the original device
the original device object
either shared or unrpcs
shared or unrpcs to
or unrpcs to expedite
unrpcs to expedite transmission
this way it is
way it is relatively
a fetch rpc for
it is relatively simple
fetch rpc for an
is relatively simple to
rpc for an unshared
relatively simple to add
journal of lightwave technology
simple to add for
for an unshared file
to add for example
an unshared file shared
add for example a
for example a file
example a file system
a file system object
since the file server
file system object that
the file server always
system object that compresses
file server always assumes
object that compresses or
server always assumes that
that compresses or encrypts
always assumes that an
compresses or encrypts data
assumes that an unshared
or encrypts data before
that an unshared which
encrypts data before the
an unshared which is
data before the data
unshared which is already
before the data reaches
which is already cached
the data reaches the
is already cached by
data reaches the under
already cached by a
reaches the under laying
cached by a different
the under laying file
by a different client
under laying file system
a different client always
different client always triggers
client always triggers a
always triggers a file
triggers a file has
a file has an
to redirect disk requests
file has an uncommitted
redirect disk requests to
has an uncommitted write
disk requests to a
an uncommitted write when
requests to a replication
uncommitted write when it
to a replication volume
write when it is
when it is accessed
it is accessed by
is accessed by an
accessed by an addiserver
or to trace device
by an addiserver pull
to trace device object
trace device object interaction
device object interaction during
object interaction during development
interaction during development phases
since the server has
the server has no
server has no way
has no way of
the strict object oriented
no way of knowing
strict object oriented approach
way of knowing if
object oriented approach is
of knowing if the
oriented approach is very
knowing if the file
approach is very well
if the file has
is very well done
the file has tional
very well done from
file has tional client
well done from a
done from a design
from a design point
a design point of
design point of view
incorrect information about the
information about the status
about the status of
an architecture to support
the status of a
architecture to support scalable
status of a file
to support scalable online
style hacker s heart
support scalable online personalization
hacker s heart starts
scalable online personalization in
of a file only
s heart starts bleeding
online personalization in the
heart starts bleeding when
personalization in the web
starts bleeding when he
a file only outstanding
bleeding when he or
file only outstanding updates
the international journal on
when he or she
international journal on very
he or she realizes
journal on very large
or she realizes that
affects the efficiency of
she realizes that he
on very large data
realizes that he can
the efficiency of the
the effects of systemic
very large data bases
effects of systemic packet
efficiency of the algorithm
that he can no
of systemic packet loss
he can no longer
systemic packet loss on
can no longer do
packet loss on aggregate
no longer do a
detection of such a
loss on aggregate tcp
longer do a quick
on aggregate tcp flows
of such a misfinally
do a quick fix
inspect a few data
since updates to shared
a few data structures
updates to shared and
few data structures and
to shared and unshared
data structures and secretly
structures and secretly swivel
shared and unshared files
and secretly swivel some
ieee conference on supercomputing
secretly swivel some pointers
and unshared files are
swivel some pointers to
unshared files are writclassification
some pointers to make
files are writclassification results
pointers to make things
are writclassification results in
to make things work
writclassification results in the
make things work better
results in the file
things work better or
in the file being
work better or make
the file being marked
better or make more
file being marked as
or make more informed
being marked as shared
make more informed decisions
ten back to the
the internal kernel interfaces
back to the server
internal kernel interfaces are
to the server at
kernel interfaces are elaborate
the server at different
server at different priorities
but it appears there
it appears there are
the original order of
appears there are always
original order of the
there are always some
order of the status
are always some things
of the status of
always some things one
the status of files
some things one cannot
status of files can
things one cannot do
of files can be
one cannot do as
files can be specified
cannot do as efficient
can be specified by
do as efficient as
be specified by the
as efficient as possible
specified by the user
by the user or
the user or by
user or by applithe
or by applithe sequence
by applithe sequence of
applithe sequence of updates
sequence of updates is
in four years of
of updates is no
four years of nt
updates is no longer
years of nt kernel
is no longer entirely
of nt kernel hacking
no longer entirely preserved
nt kernel hacking only
kernel hacking only on
hacking only on one
end performance effects of
only on one occasion
performance effects of parallel
on one occasion we
effects of parallel tcp
of parallel tcp sockets
one occasion we needed
parallel tcp sockets on
occasion we needed to
tcp sockets on a
we needed to break
sockets on a lossy
or can be inferred
needed to break through
on a lossy wide
to break through the
can be inferred by
break through the standard
be inferred by the
through the standard kernel
inferred by the file
the standard kernel interface
by the file server
the file server according
file server according to
server according to how
according to how it
we wanted to add
to how it dates
wanted to add a
how it dates to
to add a fast
it dates to shared
add a fast trap
dates to shared files
a fast trap into
to shared files form
fast trap into the
epidemic algorithms for replicated
shared files form a
trap into the kernel
international parallel and distributed
into the kernel for
parallel and distributed processing
the kernel for fast
and distributed processing symposium
kernel for fast user
files form a subsequence
algorithms for replicated database
form a subsequence of
for replicated database maintenance
a subsequence of the
subsequence of the original
of the original updates
and the pages which
in proceedings of the
the pages which hold
proceedings of the sixth
pages which hold the
of the sixth annual
which hold the trap
the sixth annual acm
hold the trap dispatch
sixth annual acm symposium
the trap dispatch tables
annual acm symposium on
trap dispatch tables were
acm symposium on principles
dispatch tables were protected
symposium on principles of
tables were protected after
on principles of distributed
were protected after the
principles of distributed computing
protected after the system
after the system boot
automatic inference should incorpoas
inference should incorpoas do
should incorpoas do the
incorpoas do the updates
do the updates to
another example of what
the updates to unshared
example of what makes
updates to unshared files
of what makes windows
what makes windows nt
makes windows nt particular
windows nt particular suitable
nt particular suitable for
implicit dependenrate a heuristic
particular suitable for research
dependenrate a heuristic for
suitable for research is
a heuristic for the
for research is the
heuristic for the sharing
research is the fundamental
the performance of tcp
is the fundamental manner
for the sharing status
the fundamental manner in
the sharing status of
ip for networks with
fundamental manner in which
sharing status of new
for networks with high
manner in which advanced
networks with high bandwidth
status of new files
in which advanced distributed
which advanced distributed services
advanced distributed services are
delay products and random
distributed services are integrated
products and random loss
and a mechacies between
services are integrated into
a mechacies between file
are integrated into windows
mechacies between file updates
integrated into windows nt
between file updates are
acm transactions on networking
file updates are preserved
it allows us to
allows us to rely
since the combination of
us to rely on
the combination of nism
to rely on ubiquitous
combination of nism for
rely on ubiquitous support
of nism for converting
on ubiquitous support services
nism for converting shared
ubiquitous support services and
for converting shared files
support services and concentrate
converting shared files to
services and concentrate on
shared files to be
and concentrate on advancing
files to be unshared
concentrate on advancing the
to be unshared if
on advancing the state
be unshared if they
advancing the state of
unshared if they cease
the state of the
if they cease to
state of the art
they cease to forward
of the art where
cease to forward invalidations
the art where it
to forward invalidations and
art where it is
forward invalidations and compulsory
where it is really
invalidations and compulsory server
it is really needed
and compulsory server pull
compulsory server pull rpcs
server pull rpcs for
pull rpcs for unbe
rpcs for unbe accessed
windows nt security provides
for unbe accessed by
nt security provides a
unbe accessed by more
support for data sharing
security provides a complete
for data sharing among
accessed by more than
provides a complete set
data sharing among mobile
a complete set of
sharing among mobile users
by more than a
complete set of services
more than a single
set of services integrated
than a single client
in ieee workshop on
of services integrated into
ieee workshop on mobile
services integrated into all
workshop on mobile computing
integrated into all sections
on mobile computing systems
into all sections of
the current implemenshared files
all sections of the
current implemenshared files prevents
sections of the operating
implemenshared files prevents a
of the operating system
files prevents a client
prevents a client from
a client from accessing
client from accessing new
researchers who are developing
from accessing new versions
who are developing an
accessing new versions of
are developing an advanced
new versions of files
developing an advanced multi
versions of files tation
of files tation in
files tation in mfs
tation in mfs assumes
in mfs assumes that
node replicated transaction server
mfs assumes that every
replicated transaction server can
assumes that every new
transaction server can use
that every new file
server can use off
every new file is
new file is unshared
and monin contravention of
monin contravention of their
contravention of their update
of their update order
itors client accesses to
client accesses to a
accesses to a file
to a file according
a file according to
file according to an
a simple model and
and encryption mechanisms into
simple model and its
according to an overlapping
encryption mechanisms into their
model and its empirical
mechanisms into their system
to an overlapping series
and its empirical validation
into their system without
an overlapping series of
their system without much
system without much pain
overlapping series of time
acm sigcomm computer communication
series of time periods
sigcomm computer communication review
the use of the
of time periods to
use of the com
time periods to ensure
of the com object
periods to ensure that
the com object model
to ensure that files
com object model in
ensure that files which
object model in all
that files which are
model in all the
files which are regularly
in all the windows
which are regularly accessed
all the windows nt
are regularly accessed remain
the windows nt services
regularly accessed remain shared
windows nt services allows
nt services allows research
services allows research projects
allows research projects to
research projects to import
since the mfs file
projects to import these
the mfs file monitoring
to import these services
mfs file monitoring component
import these services in
file monitoring component op
these services in a
services in a very
in a very simple
a very simple manner
the existence of com
existence of com makes
of com makes it
com makes it trivial
makes it trivial for
it trivial for research
trivial for research projects
experimental setup erates on
for research projects to
setup erates on a
research projects to export
erates on a larger
projects to export their
on a larger time
to export their interfaces
a larger time scale
export their interfaces in
larger time scale than
their interfaces in a
time scale than the
interfaces in a language
scale than the experiments
in a language independent
than the experiments considered
a language independent manner
the experiments considered in
experiments considered in at
considered in at the
in at the start
at the start of
the start of this
the ensemble project for
start of this section
ensemble project for example
of this section we
project for example has
this section we identified
for example has developed
section we identified large
example has developed a
has developed a protocol
developed a protocol environment
a protocol environment for
scale collaborative this paper
protocol environment for distributed
environment for distributed operations
for distributed operations in
distributed operations in the
we omit its details
operations in the ml
omit its details for
in the ml programming
its details for brevity
the ml programming language
engineering design as an
congestion control for high
and by using a
design as an example
control for high bandwidth
by using a com
as an example of
using a com interface
an example of a
a com interface are
example of a scenario
com interface are the
based scalable network services
of a scenario which
interface are the services
a scenario which features
are the services offered
scenario which features when
the services offered by
which features when a
services offered by ensemble
features when a process
offered by ensemble available
when a process modifies
by ensemble available to
a process modifies a
proceedings of the sixteenth
ensemble available to c
of the sixteenth acm
process modifies a file
the sixteenth acm symposium
sixteenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
an update is scheduled
update is scheduled to
is scheduled to be
scheduled to be a
to be a high
be a high degree
a high degree of
java and vb programmers
high degree of read
this allowed the researchers
allowed the researchers to
the researchers to side
at present we have
present we have evalappended
we have evalappended to
step the time consuming
have evalappended to the
the time consuming development
evalappended to the log
time consuming development of
effective erasure codes for
consuming development of native
erasure codes for reliable
development of native language
codes for reliable computer
of native language interfaces
for reliable computer communication
and the process continues
reliable computer communication protocols
the process continues executing
it helps of course
process continues executing withuated
helps of course to
acm sigcomm computer communication
of course to have
sigcomm computer communication review
course to have all
continues executing withuated the
to have all the
executing withuated the mfs
have all the tools
withuated the mfs cache
the mfs cache consistency
mfs cache consistency algorithm
cache consistency algorithm using
consistency algorithm using a
algorithm using a synthetic
using a synthetic out
a synthetic out having
synthetic out having to
out having to wait
operating system versions and
having to wait for
system versions and their
to wait for the
versions and their source
wait for the server
and their source code
for the server to
their source code available
the server to be
server to be contacted
microsoft is very generous
is very generous to
very generous to academia
generous to academia and
to academia and makes
though we are hoping
academia and makes all
we are hoping to
and makes all their
are hoping to obtain
makes all their tools
hoping to obtain real
all their tools from
to obtain real data
their tools from operating
obtain real data from
tools from operating systems
real data from such
from operating systems to
data from such an
operating systems to compilers
from such an thread
such an thread then
an thread then checks
thread then checks the
then checks the status
including tons of documentation
checks the status of
tons of documentation as
the status of the
of documentation as well
status of the file
documentation as well as
of the file the
as well as subscriptions
the file the update
well as subscriptions to
file the update modifies
as subscriptions to the
subscriptions to the developer
to the developer network
if the environment in
the environment in the
environment in the future
on the feasibility of
available to the departments
the feasibility of software
to the departments free
feasibility of software fec
the departments free of
departments free of charge
the update is queued
universita di pisa deit
update is queued for
source code availability turned
di pisa deit technical
is queued for transmission
code availability turned out
pisa deit technical report
availability turned out to
queued for transmission at
deit technical report lr
turned out to be
for transmission at the
out to be not
transmission at the reg
to be not crucial
and was only once
was only once used
only once used to
once used to make
used to make actual
to make actual changes
make actual changes to
actual changes to the
changes to the operating
to the operating systems
von eicken et al
the ninja architecture for
the source is extremely
ninja architecture for robust
source is extremely useful
architecture for robust internet
is extremely useful as
extremely useful as additional
useful as additional documentation
scale systems and services
to examine unexpected behaviour
examine unexpected behaviour or
unexpected behaviour or to
behaviour or to provide
or to provide templates
to provide templates for
provide templates for similar
templates for similar projects
as one can perform
one can perform complete
the case for packet
can perform complete source
case for packet level
perform complete source code
for packet level fec
complete source code level
source code level debugging
code level debugging of
level debugging of all
debugging of all parts
of all parts of
all parts of the
parts of the operating
in fifth international workshop
of the operating system
fifth international workshop on
the operating system including
international workshop on protocols
operating system including the
workshop on protocols for
system including the kernel
on protocols for high
source codes helps us
codes helps us to
helps us to develop
us to develop experimental
to develop experimental services
develop experimental services faster
experimental services faster and
services faster and in
faster and in tune
and in tune with
in tune with existing
tune with existing functionality
students are free to
are free to work
free to work with
to work with the
work with the source
with the source code
the source code and
source code and are
code and are not
and are not prohibited
are not prohibited in
not prohibited in any
prohibited in any way
in any way from
any way from applying
way from applying the
from applying the knowledge
applying the knowledge they
the knowledge they gained
knowledge they gained in
they gained in their
gained in their later
in their later careers
interactions with the evil
with the evil empire
the evil empire microsoft
evil empire microsoft realizes
empire microsoft realizes the
microsoft realizes the potential
realizes the potential of
the potential of widespread
potential of widespread adoption
spatial gossip and resource
of widespread adoption of
gossip and resource location
widespread adoption of windows
and resource location protocols
adoption of windows nt
lateral error correction for
error correction for time
of windows nt for
windows nt for research
in proceedings of the
proceedings of the thirty
nt for research purposes
for research purposes and
research purposes and there
third annual acm symposium
purposes and there is
annual acm symposium on
and there is dedicated
acm symposium on theory
there is dedicated academic
symposium on theory of
is dedicated academic relations
on theory of computing
dedicated academic relations team
academic relations team whose
relations team whose single
team whose single task
whose single task it
single task it is
task it is to
it is to facilitate
is to facilitate the
fourth usenix symposium on
to facilitate the technology
usenix symposium on networked
symposium on networked systems
facilitate the technology transfer
on networked systems design
the technology transfer between
networked systems design and
technology transfer between microsoft
systems design and implementation
transfer between microsoft and
between microsoft and academia
microsoft and academia and
and academia and vice
academia and vice versa
number of rpcs average
of rpcs average time
source licensing is very
licensing is very liberal
is very liberal compared
very liberal compared to
liberal compared to other
compared to other os
to other os vendors
other os vendors and
os vendors and several
vendors and several institutions
and several institutions are
several institutions are involved
institutions are involved in
are involved in active
involved in active exchanges
in active exchanges with
active exchanges with product
exchanges with product and
with product and research
product and research groups
and research groups within
research groups within microsoft
hik j ihkj m
j ihkj m l
ihkj m l ml
m l ml cb
joint projects are in
l ml cb c
projects are in progress
ml cb c b
cb c b cbcb
c b cbcb ed
b cbcb ed f
cbcb ed f gf
joint papers are starting
ed f gf cb
papers are starting to
f gf cb c
are starting to appear
gf cb c b
starting to appear and
cb c b yx
to appear and academics
c b yx cbcb
a technique for increasing
appear and academics frequently
technique for increasing concurrency
and academics frequently present
for increasing concurrency in
academics frequently present cutting
z eded f f
frequently present cutting edge
increasing concurrency in a
present cutting edge result
concurrency in a replicated
cutting edge result to
in a replicated system
eded f f gfgf
edge result to microsoft
f f gfgf cb
result to microsoft developers
acm transactions on database
to microsoft developers and
f gfgf cb b
microsoft developers and researchers
transactions on database systems
gfgf cb b on
cb b on yxyx
b on yxyx cbb
z eded f f
gfgf c c b
an integrated experimental environment
c c b on
integrated experimental environment for
c b on yx
operating systems there is
experimental environment for distributed
systems there is a
b on yx ccb
there is a direct
on yx ccb qp
is a direct impact
environment for distributed systems
a direct impact of
for distributed systems and
direct impact of academia
distributed systems and networks
impact of academia on
of academia on microsoft
academia on microsoft products
gf cb b c
through involvement in the
cb b c onon
involvement in the strategy
b c onon yxxy
in the strategy phases
c onon yxxy cbbc
the strategy phases of
onon yxxy cbbc qpqp
strategy phases of products
phases of products as
of products as well
products as well as
as well as through
fifth usenix symposium on
well as through academic
usenix symposium on operating
z eded r f
as through academic knowledge
symposium on operating systems
through academic knowledge transfer
on operating systems design
academic knowledge transfer into
operating systems design and
knowledge transfer into products
systems design and implementation
eded r f f
transfer into products and
r f f srs
into products and design
products and design groups
microsoft also provides research
also provides research funding
provides research funding for
research funding for some
funding for some relevant
for some relevant groups
gfgf c b onon
some relevant groups and
c b onon yx
relevant groups and fellowship
adaptive distributed data management
groups and fellowship and
distributed data management with
and fellowship and research
data management with weak
fellowship and research internships
management with weak consistent
and research internships for
with weak consistent replicated
research internships for students
weak consistent replicated data
b onon yx cb
onon yx cb qp
in proceedings of the
summary four years of
four years of research
years of research on
z ed r f
of research on windows
ed r f r
research on windows nt
on windows nt have
windows nt have taught
nt have taught us
have taught us that
taught us that we
us that we made
gf invalidations and server
that we made the
acm symposium on applied
we made the right
symposium on applied computing
invalidations and server pulls
made the right choice
and server pulls mfs
the right choice in
right choice in leaving
choice in leaving the
in leaving the unix
leaving the unix behind
windows nt is an
nt is an exiting
diff synchronous average time
years ahead of its
physical layer impact upon
ahead of its competition
layer impact upon packet
impact upon packet errors
in its implementation and
its implementation and in
implementation and in the
and in the actual
in the actual services
the actual services offered
it took quite some
took quite some time
passive and active measurement
quite some time to
and active measurement workshop
some time to reach
time to reach the
to reach the same
reach the same level
the same level of
same level of knowledge
level of knowledge and
of knowledge and insight
knowledge and insight we
and insight we used
insight we used to
we used to have
used to have of
to have of unix
have of unix systems
but now that we
now that we have
that we have arrived
we have arrived at
have arrived at that
arrived at that same
at that same knowledge
that same knowledge point
is it clear that
it clear that our
clear that our research
that our research is
our research is making
aware adaptable web services
research is making progress
is making progress faster
making progress faster than
progress faster than ever
faster than ever before
in proceedings of the
working with windows nt
with windows nt requires
windows nt requires certain
nt requires certain level
th international world wide
requires certain level of
international world wide web
certain level of resilience
world wide web conference
wide web conference on
web conference on alternate
conference on alternate track
on alternate track papers
not because of flaws
alternate track papers and
because of flaws in
track papers and posters
of flaws in the
flaws in the operating
in the operating system
but because of the
because of the zealous
of the zealous attacks
the zealous attacks by
zealous attacks by colleagues
attacks by colleagues and
by colleagues and other
colleagues and other researchers
publishing papers about research
papers about research performed
about research performed on
research performed on windows
performed on windows nt
on windows nt is
windows nt is still
nt is still quite
is still quite difficult
still quite difficult as
quite difficult as many
difficult as many of
as many of our
many of our peer
of our peer still
our peer still believe
peer still believe that
still believe that no
believe that no good
that no good research
no good research can
good research can be
research can be performed
can be performed on
be performed on windows
performed on windows nt
we hope that eventually
hope that eventually the
that eventually the advanced
eventually the advanced technical
the advanced technical nature
advanced technical nature of
technical nature of the
nature of the operating
of the operating system
the operating system will
operating system will prevail
system will prevail in
will prevail in the
prevail in the discussion
and that we can
that we can have
we can have a
can have a community
have a community where
a community where research
community where research results
where research results can
research results can be
results can be shared
can be shared without
be shared without sarcasm
shared without sarcasm or
without sarcasm or the
sarcasm or the risk
or the risk of
the risk of igniting
risk of igniting yet
of igniting yet another
igniting yet another holy
yet another holy war
the university of illinois
university of illinois national
of illinois national center
illinois national center for
national center for supercomputing
center for supercomputing applications
global crossing current network
profiles for the situated
crossing current network performance
for the situated web
in proceedings of the
proceedings of the eleventh
of the eleventh international
the eleventh international conference
eleventh international conference on
international conference on world
conference on world wide
on world wide web
expert testimony of professor
testimony of professor david
of professor david j
qwest ip network statistics
van renesse and f
chain replication for supporting
replication for supporting high
for supporting high throughput
supporting high throughput and
high throughput and availability
in sixth symposium on
sixth symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
vice president of research
president of research and
of research and t
enabling scalable online personalization
uwin unix for windows
scalable online personalization on
online personalization on the
personalization on the web
the usenix windows nt
usenix windows nt workshop
in proceedings of the
nd acm conference on
acm conference on electronic
conference on electronic commerce
acm transactions on networking
an architecture for well
th edition with source
edition with source code
in symposium on operating
symposium on operating systems
on operating systems principles
a method for improving
average duration of reader
method for improving tcp
duration of reader fetch
for improving tcp performance
improving tcp performance over
tcp performance over wireless
performance over wireless links
the costs and limits
costs and limits of
and limits of availability
limits of availability for
of availability for replicated
availability for replicated services
nd ieee wireless communications
ieee wireless communications and
in proceedings of the
wireless communications and networking
proceedings of the eighteenth
communications and networking conference
of the eighteenth acm
the eighteenth acm symposium
eighteenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
an adaptive forward error
adaptive forward error correction
forward error correction protocol
the design and implementation
error correction protocol for
design and implementation of
correction protocol for end
and implementation of the
end transport of real
design and evaluation of
and evaluation of a
evaluation of a conitbased
of a conitbased continuous
a conitbased continuous consistency
conitbased continuous consistency model
continuous consistency model for
consistency model for replicated
model for replicated services
acm transactions on computer
transactions on computer systems
th international conference on
international conference on computer
conference on computer communications
on computer communications and
computer communications and networks
what s new in
s new in windows
based loss recovery for
loss recovery for reliable
recovery for reliable multicast
for reliable multicast transmission
end performance evaluation of
on onon yxyx p
onon yxyx p p
yxyx p p qpqp
z onon yxyx p
onon yxyx p p
yxyx p p qppq
th symposium on high
symposium on high performance
on high performance interconnects
z on yx p
on yx p qp
z onon yxxy p
onon yxxy p p
yxxy p p qpqp
z on yx p
on yx p qp
z time spent on
time spent on invalidations
nick vasilatos and werner
vasilatos and werner vogels
average store rpc duration
end forward error correction
do you need source
you need source with
need source with that
panel at the usenix
at the usenix windows
the usenix windows nt
usenix windows nt workshop
international zurich seminar on
zurich seminar on communications
summary in usenix login
the case for application
level network striping for
network striping for data
striping for data intensive
for data intensive applications
data intensive applications using
intensive applications using high
applications using high speed
using high speed wide
high speed wide area
speed wide area networks
unix application portability to
application portability to windows
portability to windows nt
to windows nt via
windows nt via an
nt via an alternative
v v w w
via an alternative environment
v w w ut
an alternative environment subsystem
w w ut v
w ut v wv
ieee conference on supercomputing
ut v wv ut
the usenix windows nt
usenix windows nt workshop
tsunami file transfer protocol
first international workshop on
graphs for cache consistency
international workshop on protocols
for cache consistency trace
workshop on protocols for
on protocols for fast
protocols for fast long
these graphs show various
graphs show various features
show various features of
various features of the
features of the performance
of the performance results
async denotes asynchronous invalidations
protect the future of
and none no invalidations
the future of computing
future of computing technology
diff denotes differentiated writeback
denotes differentiated writeback priorities
differentiated writeback priorities for
writeback priorities for shared
priorities for shared and
for shared and unshared
shared and unshared files
and unif denotes uniform
unif denotes uniform priorities
cc is the mfs
is the mfs cache
the mfs cache consistency
mfs cache consistency algorithm
the height of a
height of a bar
of a bar counts
a bar counts the
bar counts the number
counts the number of
the number of invalidations
the white portion counts
white portion counts the
portion counts the number
predictable high performance bulk
counts the number of
high performance bulk data
the number of server
performance bulk data transfer
our experimental setup consisting
experimental setup consisting of
setup consisting of three
consisting of three hosts
and a writer client
ieee international conference on
international conference on cluster
conference on cluster computing
the bandwidth from the
bandwidth from the reader
from the reader to
the reader to the
reader to the server
to the server was
the server was fixed
server was fixed at
and the bandwidth from
the bandwidth from the
bandwidth from the writer
from the writer to
the writer to the
writer to the server
to the server was
the server was varied
server was varied according
was varied according to
varied according to the
according to the experiment
the writer was configured
writer was configured in
was configured in one
configured in one of
in one of seven
one of seven different
of seven different ways
solomon codes and their
codes and their applications
synchronous or no invalidations
and differentiated or uniform
differentiated or uniform priorities
or uniform priorities for
uniform priorities for writing
priorities for writing back
for writing back shared
writing back shared and
back shared and unshared
shared and unshared files
the mfs concurrency control
mfs concurrency control algorithm
corresponds to asynchronous invalidations
to asynchronous invalidations with
asynchronous invalidations with differentiated
invalidations with differentiated priority
with differentiated priority for
differentiated priority for shared
priority for shared files
both clients access a
clients access a shared
access a shared repository
a shared repository of
shared repository of files
repository of files stored
of files stored on
files stored on the
stored on the file
on the file server
nat and packet mangling
and packet mangling for
packet mangling for linux
each module has a
module has a descriptor
has a descriptor file
a descriptor file and
descriptor file and a
file and a set
and a set of
module descriptor files are
descriptor files are about
kb in size and
in size and the
member files take up
files take up an
take up an average
up an average of
the total size of
total size of all
size of all the
of all the files
all the files in
the files in the
files in the collection
in the collection is
multicast routing in datagram
routing in datagram internetworks
the writer workload consists
in datagram internetworks and
writer workload consists of
datagram internetworks and extended
workload consists of the
internetworks and extended lans
consists of the writer
of the writer updating
the writer updating modules
writer updating modules in
updating modules in a
acm transactions on computers
modules in a random
transactions on computers systems
in a random order
an update to a
update to a module
to a module consists
a module consists of
module consists of a
consists of a sequence
of a sequence of
a sequence of operations
of which are reads
which are reads and
are writes to a
writes to a file
to a file in
a file in the
file in the module
consist of writes to
of writes to unshared
writes to unshared external
to unshared external files
which are each created
are each created with
each created with a
created with a unique
with a unique name
there is a pause
is a pause between
a pause between each
pause between each operation
between each operation and
each operation and a
operation and a longer
and a longer pause
a longer pause between
longer pause between updates
pause between updates to
between updates to modules
the reader workload is
reader workload is similar
but an access to
an access to a
access to a module
to a module consists
a module consists of
module consists of a
consists of a series
of a series of
a series of reads
and external files are
external files are never
files are never accessed
the configuration parameters used
configuration parameters used to
parameters used to generate
used to generate the
to generate the reader
generate the reader and
the reader and writer
reader and writer workload
and writer workload are
writer workload are listed
workload are listed in
are listed in table
performance enhancing proxies intended
the writer workload has
enhancing proxies intended to
writer workload has a
proxies intended to mitigate
workload has a nominal
intended to mitigate link
has a nominal duration
a nominal duration of
nominal duration of two
duration of two minutes
while the reader workload
the reader workload is
reader workload is extended
workload is extended to
is extended to terminate
extended to terminate at
to terminate at the
terminate at the same
at the same time
the same time as
same time as the
time as the writer
as the writer workload
the writer workload actually
writer workload actually finishes
since low bandwidth could
low bandwidth could extend
bandwidth could extend its
could extend its running
extend its running time
its running time beyond
running time beyond two
time beyond two minutes
analysis of the results
of the results figure
shows graphs of some
graphs of some selected
of some selected results
some selected results from
selected results from the
results from the experiments
while synchronous writes provide
synchronous writes provide strong
writes provide strong concurrency
provide strong concurrency control
they resulted in the
resulted in the lowest
in the lowest rate
the lowest rate of
lowest rate of completed
rate of completed writes
of completed writes in
completed writes in all
writes in all the
in all the tests
since the writer had
the writer had no
udp bandwidth measurement tool
writer had no possibility
had no possibility of
no possibility of over
lapping think time with
think time with asynchronous
time with asynchronous writeback
at all bandwidth levels
all bandwidth levels the
bandwidth levels the mfs
cc algorithm outperformed synchronous
algorithm outperformed synchronous writes
outperformed synchronous writes by
synchronous writes by at
writes by at least
and was among the
was among the options
among the options with
the options with the
options with the highest
with the highest write
the highest write throughput
this is clear from
is clear from graph
which shows the average
shows the average time
the average time to
average time to complete
time to complete store
to complete store rpcs
complete store rpcs initiated
store rpcs initiated by
rpcs initiated by the
initiated by the writer
cc outperforms all of
a scalable and tcp
outperforms all of the
all of the alternatives
friendly congestion control for
congestion control for high
this is because of
is because of the
because of the reduced
of the reduced number
the reduced number of
reduced number of invalidations
number of invalidations it
of invalidations it generates
in contrast to most
contrast to most of
to most of the
most of the other
of the other schemes
it is able to
is able to take
able to take advantage
to take advantage of
take advantage of both
advantage of both differentiated
of both differentiated writeback
pull rpcs to raise
rpcs to raise the
to raise the priority
raise the priority of
the priority of its
priority of its writes
shows the performance from
the performance from the
performance from the reader
from the reader s
the reader s perspective
while the writer is
the writer is able
writer is able to
is able to decrease
able to decrease its
to decrease its time
decrease its time spent
its time spent performing
time spent performing store
spent performing store rpcs
the reader s average
reader s average time
s average time spent
average time spent on
time spent on fetches
spent on fetches increases
on fetches increases sharply
fetches increases sharply when
increases sharply when the
sharply when the file
when the file in
the file in question
file in question must
in question must be
question must be pulled
must be pulled from
be pulled from the
pulled from the writer
this cost must be
cost must be weighed
must be weighed against
be weighed against the
weighed against the benefit
third international workshop on
against the benefit of
international workshop on protocols
the benefit of substantially
workshop on protocols for
benefit of substantially increased
on protocols for fast
of substantially increased writer
protocols for fast long
substantially increased writer throughput
differentiated writeback succeeds in
writeback succeeds in reducing
succeeds in reducing the
in reducing the time
reducing the time the
the time the reader
time the reader has
the reader has to
reader has to wait
has to wait when
to wait when accessing
wait when accessing a
when accessing a shared
accessing a shared file
show statistics for invalidations
statistics for invalidations and
for invalidations and serverpull
invalidations and serverpull rpcs
and serverpull rpcs for
serverpull rpcs for those
rpcs for those writer
for those writer configurations
those writer configurations which
writer configurations which make
configurations which make use
which make use of
make use of them
packet recovery in high
cc significantly reduces the
speed networks using coding
significantly reduces the number
networks using coding and
reduces the number of
using coding and buffer
the number of invalidations
coding and buffer management
number of invalidations it
of invalidations it must
invalidations it must transmit
it must transmit by
must transmit by putting
transmit by putting off
by putting off invalidating
putting off invalidating a
off invalidating a file
invalidating a file until
a file until it
file until it is
until it is added
it is added to
is added to the
added to the log
yet the effect of
the effect of this
effect of this policy
of this policy on
this policy on the
policy on the number
on the number of
the number of serverpull
number of serverpull rpcs
of serverpull rpcs is
serverpull rpcs is minor
which differs from mfs
cc in omitting differentiated
in omitting differentiated writeback
performance evaluation of forward
evaluation of forward error
of forward error correction
forward error correction in
makes more invalidations and
error correction in atm
more invalidations and incurs
correction in atm networks
invalidations and incurs more
and incurs more server
because its store rpcs
its store rpcs must
store rpcs must compete
rpcs must compete with
must compete with the
compete with the rpcs
with the rpcs to
the rpcs to write
rpcs to write back
to write back external
write back external files
this increases the commit
increases the commit delay
the commit delay for
commit delay for each
delay for each file
for each file and
each file and the
file and the likelihood
and the likelihood of
the likelihood of it
likelihood of it being
of it being accessed
it being accessed by
being accessed by the
accessed by the reader
by the reader while
the reader while it
reader while it is
while it is being
it is being written
is being written back
these experiments demonstrate that
experiments demonstrate that for
demonstrate that for the
that for the trace
for the trace we
the trace we have
trace we have examined
the mfs algorithm of
mfs algorithm of asynchronous
algorithm of asynchronous invalidations
of asynchronous invalidations and
asynchronous invalidations and differentiated
invalidations and differentiated writeback
and differentiated writeback is
differentiated writeback is able
writeback is able to
is able to maintain
able to maintain cache
to maintain cache consistency
maintain cache consistency between
cache consistency between the
consistency between the two
between the two clients
the two clients and
two clients and to
clients and to allow
and to allow the
to allow the writer
allow the writer to
the writer to write
writer to write back
to write back changes
write back changes to
back changes to the
changes to the stored
to the stored data
the stored data faster
stored data faster than
data faster than is
faster than is possible
than is possible with
is possible with the
possible with the alternative
with the alternative schemes
efficient erasure correcting codes
we intend to further
intend to further evaluate
to further evaluate the
ieee transactions on information
further evaluate the perfor
transactions on information theory
references mance of the
mance of the algorithm
of the algorithm to
the algorithm to determine
algorithm to determine its
to determine its effectiveness
determine its effectiveness under
its effectiveness under other
effectiveness under other workloads
and with more clients
evaluation of an adaptive
of an adaptive transport
an adaptive transport protocol
in proceedings of the
nd annual joint conference
annual joint conference of
joint conference of the
conference of the ieee
of the ieee computer
the ieee computer and
ieee computer and communications
computer and communications societies
conclusion the growing use
the growing use of
growing use of mobile
use of mobile computers
of mobile computers and
mobile computers and wireless
computers and wireless networks
and wireless networks has
wireless networks has greatly
rd annual ieee symposium
networks has greatly increased
annual ieee symposium on
has greatly increased the
ieee symposium on foundations
greatly increased the scope
symposium on foundations of
increased the scope for
on foundations of computer
the scope for adapting
foundations of computer science
scope for adapting data
for adapting data access
adapting data access to
data access to vary
ieee transactions on information
transactions on information theory
this paper has explored
paper has explored applying
has explored applying and
explored applying and j
measurements of a distributed
of a distributed file
a distributed file the
distributed file the technique
file the technique of
the technique of modeless
technique of modeless adaptation
of modeless adaptation to
modeless adaptation to a
adaptation to a distributed
to a distributed file
a distributed file system
distributed file system system
in proceedings of the
th acm symposium to
acm symposium to improve
symposium to improve its
to improve its performance
the cache manager for
cache manager for our
manager for our mfs
for our mfs on
our mfs on operating
mfs on operating systems
on operating systems principles
pacific file system incorporates
file system incorporates features
system incorporates features that
incorporates features that are
features that are not
that are not present
are not present in
not present in existing
present in existing grove
file systems for mobile
systems for mobile hosts
adaptation to bandwidth variation
to bandwidth variation through
bandwidth variation through the
variation through the use
through the use of
the use of prioritised
use of prioritised communication
o hint genercache consistency
hint genercache consistency protocol
genercache consistency protocol using
consistency protocol using file
protocol using file access
using file access information
file access information to
access information to imation
information to imation through
to imation through speculative
imation through speculative execution
in operating systems prove
operating systems prove performance
we have evaluated the
have evaluated the effect
evaluated the effect of
the effect of these
effect of these features
of these features on
these features on performance
features on performance at
on performance at varying
performance at varying bandwidth
at varying bandwidth levels
varying bandwidth levels and
bandwidth levels and under
levels and under both
and under both synthetic
under both synthetic and
both synthetic and real
including a workload emulating
a workload emulating collaborative
workload emulating collaborative data
performance measurements access with
measurements access with high
access with high read
and found that while
found that while the
that while the of
while the of automatic
the of automatic prefetching
in proceedings of the
proceedings of the isca
of the isca interadditional
the isca interadditional costs
isca interadditional costs imposed
interadditional costs imposed are
costs imposed are mostly
imposed are mostly hidden
they can have benenational
can have benenational conference
have benenational conference on
benenational conference on parallel
conference on parallel and
on parallel and distributed
parallel and distributed computfits
and distributed computfits which
distributed computfits which are
computfits which are very
which are very visible
modal nature of ing
nature of ing systems
adaptation in mfs allows
in mfs allows clients
mfs allows clients to
allows clients to adapt
clients to adapt quickly
to adapt quickly to
adapt quickly to a
quickly to a variety
to a variety of
a variety of bandwidth
variety of bandwidth conditions
of bandwidth conditions without
bandwidth conditions without substantial
conditions without substantial changes
without substantial changes in
substantial changes in operation
our evaluation has included
evaluation has included comparisons
has included comparisons of
included comparisons of mfs
comparisons of mfs to
of mfs to cache
mfs to cache manm
ager configurations corresponding to
configurations corresponding to prior
corresponding to prior work
and confirmed scale and
confirmed scale and performance
scale and performance in
and performance in a
performance in a distributed
in a distributed file
a distributed file system
acm that there are
that there are situations
there are situations in
are situations in which
situations in which mfs
in which mfs would
which mfs would outperform
mfs would outperform afs
transactions on computer systems
coda and little work
these earlier systems were
earlier systems were designed
systems were designed for
were designed for a
designed for a mobile
for a mobile environment
a mobile environment which
mobile environment which is
environment which is substantially
which is substantially different
partially connected operafrom that
connected operafrom that available
operafrom that available today
software defined networks and
mfs is able to
defined networks and gossip
is able to provide
networks and gossip protocols
able to provide tion
and gossip protocols robert
gossip protocols robert soule
protocols robert soule ken
robert soule ken birman
soule ken birman nate
ken birman nate foster
birman nate foster university
nate foster university of
foster university of lugano
university of lugano cornell
of lugano cornell university
lugano cornell university cornell
cornell university cornell university
university cornell university the
cornell university the performance
university the performance of
the performance of data
center applications are critically
applications are critically dependent
are critically dependent on
critically dependent on the
dependent on the underlying
on the underlying network
given the complexities associated
the complexities associated with
complexities associated with management
networks today typically provide
today typically provide little
typically provide little more
provide little more than
little more than best
effort packet delivery between
packet delivery between hosts
improved performance in periods
the emergence of software
performance in periods of
in periods of high
periods of high network
of high network contention
high network contention by
has created an opportunity
created an opportunity to
an opportunity to build
opportunity to build more
to build more dynamic
build more dynamic networks
more dynamic networks that
dynamic networks that can
networks that can be
that can be tailored
can be tailored precisely
be tailored precisely to
tailored precisely to the
precisely to the needs
to the needs of
the needs of applications
existing solutions for monitoring
solutions for monitoring within
for monitoring within sdns
monitoring within sdns suffer
within sdns suffer from
sdns suffer from several
suffer from several short
mofavouring cache validation and
cache validation and rpcs
validation and rpcs to
either they are inaccurate
and rpcs to retrieve
rpcs to retrieve files
to retrieve files over
retrieve files over other
due to eventual consistency
files over other bile
to eventual consistency of
over other bile computing
eventual consistency of architecture
other bile computing with
bile computing with the
computing with the rover
with the rover toolkit
ieee transactypes of traffic
we have not compared
have not compared mfs
not compared mfs with
due to limitations of
compared mfs with lbfs
to limitations of current
mfs with lbfs since
limitations of current hardware
with lbfs since tions
lbfs since tions on
since tions on computers
special issue on mobile
issue on mobile computing
their approaches are orthogonal
or too costly to
too costly to be
costly to be practical
to be practical at
be practical at scale
due to reliance on
to reliance on switch
reliance on switch forwarding
on switch forwarding rules
switch forwarding rules and
forwarding rules and centralization
we argue that gossip
argue that gossip protocols
that gossip protocols offer
gossip protocols offer an
protocols offer an ideal
offer an ideal alternative
an ideal alternative for
ideal alternative for sdn
alternative for sdn monitoring
due to their scalability
to their scalability and
their scalability and resiliency
ignored the crucial monitoring
the crucial monitoring component
crucial monitoring component that
monitoring component that aggregates
component that aggregates network
that aggregates network and
aggregates network and application
network and application state
and sends the events
sends the events to
the events to the
events to the controller
not present in the
present in the earlier
in the earlier systems
a complete system would
the earlier systems we
complete system would have
earlier systems we have
system would have a
systems we have compared
would have a closed
we have compared against
have a closed loop
we anticipate that implementing
continuously monitoring applications and
anticipate that implementing lbfs
monitoring applications and the
that implementing lbfs file
applications and the network
implementing lbfs file chunks
lbfs file chunks in
file chunks in mfs
chunks in mfs would
then adjusting sdn policies
adjusting sdn policies to
sdn policies to optimize
policies to optimize the
to optimize the use
optimize the use of
the use of resources
gossip protocols are an
protocols are an ideal
are an ideal choice
an ideal choice for
ideal choice for implementing
choice for implementing a
for implementing a wide
implementing a wide range
a wide range monitoring
wide range monitoring tasks
with a gossip protocol
each node exchanges information
node exchanges information with
exchanges information with a
information with a randomly
with a randomly selected
a randomly selected peer
randomly selected peer at
selected peer at periodic
peer at periodic intervals
further improve performance its
improve performance its performance
because it is based
it is based on
is based on periodic
based on periodic peer
and performance in a
performance in a wide
in proceedin future work
gossip s network load
we plan to investigate
s network load tends
plan to investigate the
network load tends to
to investigate the performance
load tends to be
investigate the performance of
tends to be well
the performance of ings
performance of ings of
of ings of the
ings of the first
of the first usenix
the first usenix conference
first usenix conference on
scaling linearly with system
usenix conference on file
linearly with system size
conference on file and
with system size and
on file and storage
system size and not
file and storage modeless
size and not prone
and storage modeless adaptation
and not prone to
storage modeless adaptation and
not prone to reactive
modeless adaptation and mfs
prone to reactive feedback
adaptation and mfs in
and mfs in wide
area and more web
because peers are selected
peers are selected randomly
no single node is
single node is indispensable
so tools built on
tools built on gossip
built on gossip are
on gossip are extremely
gossip are extremely tolerant
are extremely tolerant to
extremely tolerant to disruptions
tolerant to disruptions and
to disruptions and able
disruptions and able to
and able to rapidly
able to rapidly recover
to rapidly recover from
rapidly recover from failures
although individual gossip protocols
individual gossip protocols are
gossip protocols are typically
protocols are typically very
are typically very simple
as well as further
well as further evaluating
as further evaluating the
further evaluating the performance
composing multiple protocols can
evaluating the performance of
multiple protocols can lead
the performance of the
protocols can lead to
performance of the mfs
can lead to complex
of the mfs cache
lead to complex interactions
the mfs cache consistency
to complex interactions with
mfs cache consistency algorithm
complex interactions with unpredictable
interactions with unpredictable behavior
we also intend to
also intend to use
we designed the mica
framework to address this
to address this problem
mica allows programmers to
allows programmers to describe
programmers to describe gossip
to describe gossip protocols
describe gossip protocols with
gossip protocols with a
protocols with a small
disconnected operamfs to further
operamfs to further examine
to further examine the
further examine the benefits
examine the benefits achievable
and compose the protocols
the benefits achievable from
compose the protocols with
benefits achievable from the
the protocols with a
achievable from the autotion
protocols with a rich
from the autotion in
with a rich collection
the autotion in the
a rich collection of
autotion in the coda
rich collection of operators
in the coda file
collection of operators to
the coda file system
of operators to create
operators to create sophisticated
to create sophisticated protocols
create sophisticated protocols in
acm transactions on commatic
sophisticated protocols in a
transactions on commatic generation
protocols in a modular
on commatic generation of
in a modular style
commatic generation of caching
generation of caching policies
of caching policies for
caching policies for files
mica ensures that the
ensures that the composed
that the composed protocols
the composed protocols maintain
composed protocols maintain strong
robustness and convergence guarantees
in our evaluation of
our evaluation of mica
we have built monitoring
have built monitoring tasks
built monitoring tasks that
monitoring tasks that maintain
tasks that maintain a
that maintain a predictable
maintain a predictable performance
even when hundreds of
when hundreds of separate
hundreds of separate instances
of separate instances are
separate instances are deployed
instances are deployed on
are deployed on the
deployed on the same
on the same machines
a control program reacts
control program reacts to
program reacts to network
reacts to network events
and updates forwarding rules
updates forwarding rules on
forwarding rules on switches
rules on switches to
on switches to manage
switches to manage packets
building on this interface
our work on merlin
is novel among network
novel among network programming
among network programming languages
network programming languages in
programming languages in that
languages in that it
in that it determines
automated hoarding for mobile
that it determines allocations
hoarding for mobile computers
it determines allocations of
determines allocations of limited
allocations of limited network
in proceedings of the
proceedings of the sixteenth
wide resources such as
of the sixteenth acm
resources such as bandwidth
the sixteenth acm symposium
such as bandwidth and
sixteenth acm symposium on
as bandwidth and paths
acm symposium on operating
symposium on operating systems
on operating systems principles
we have used merlin
have used merlin to
used merlin to improve
merlin to improve the
to improve the latency
improve the latency of
the latency of hadoop
latency of hadoop jobs
of hadoop jobs running
hadoop jobs running in
jobs running in the
running in the presence
in the presence of
the presence of udp
presence of udp background
of udp background traffic
or prioritize classes of
prioritize classes of traffic
classes of traffic used
of traffic used for
traffic used for state
machine replication in fault
these experiments demonstrate that
experiments demonstrate that an
demonstrate that an sdn
that an sdn framework
with the correct information
the correct information as
correct information as input
acknowledgements we would like
we would like to
would like to thank
like to thank robbert
to thank robbert van
can provide automated network
provide automated network management
thank robbert van renesse
automated network management customized
network management customized to
management customized to the
customized to the needs
to the needs of
the needs of resident
needs of resident distributed
of resident distributed applications
emin gu n sirer
gu n sirer and
n sirer and paul
sirer and paul francis
while the merlin compiler
and paul francis for
the merlin compiler generates
paul francis for comments
merlin compiler generates static
francis for comments and
compiler generates static network
for comments and suggestions
generates static network configurations
comments and suggestions regarding
and suggestions regarding mfs
merlin uses a small
we also thank rimon
also thank rimon barr
runtime component to allow
component to allow for
to allow for dynamic
allow for dynamic adaptation
and kevin walsh for
kevin walsh for helpful
walsh for helpful discussions
for helpful discussions and
helpful discussions and corrections
discussions and corrections to
based approach allows this
and corrections to this
approach allows this adaptation
corrections to this paper
allows this adaptation to
this adaptation to happen
adaptation to happen safely
by providing policy language
providing policy language constructs
policy language constructs that
language constructs that can
constructs that can be
that can be automatically
can be automatically verified
implicit in the design
in the design of
the design of this
design of this runtime
of this runtime component
and sdn networks in
sdn networks in general
is the notion that
the notion that network
notion that network events
that network events are
network events are generated
events are generated in
are generated in response
generated in response to
in response to the
response to the situational
to the situational status
the situational status culled
situational status culled from
status culled from a
culled from a wide
from a wide range
a wide range of
a coherent distributed file
wide range of sources
coherent distributed file cache
distributed file cache with
file cache with directory
cache with directory write
acm transactions on computer
transactions on computer systems
packet and drop rates
user preferences for a
preferences for a particular
for a particular network
a lowbandwidth network file
lowbandwidth network file system
in proceedings of the
proceedings of the seventeenth
of the seventeenth acm
the seventeenth acm symposium
seventeenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
much of this information
of this information must
this information must be
information must be created
must be created and
be created and updated
created and updated dynamically
existing sdn frameworks have
sdn frameworks have largely
frameworks have largely closing
have largely closing the
largely closing the loop
to accommodate the ever
growing demands of cloud
demands of cloud and
of cloud and data
cloud and data center
and data center application
networks will need to
will need to become
need to become more
to become more flexible
become more flexible and
more flexible and dynamic
as networks continue to
networks continue to grow
continue to grow in
to grow in complexity
it will become increasingly
will become increasingly difficult
become increasingly difficult for
increasingly difficult for network
difficult for network operators
for network operators to
network operators to provide
operators to provide this
to provide this flexibility
provide this flexibility without
this flexibility without the
flexibility without the support
without the support of
the support of proper
support of proper tools
of proper tools and
proper tools and infrastructure
caching in the sprite
in the sprite network
the sprite network file
sprite network file system
acm transactions on computer
provide both the control
transactions on computer systems
both the control and
the control and monitoring
control and monitoring components
and monitoring components necessary
monitoring components necessary to
components necessary to automatically
necessary to automatically adapt
to automatically adapt the
automatically adapt the network
adapt the network to
the network to the
network to the needs
to the needs of
the needs of the
needs of the applications
because both systems use
both systems use a
systems use a language
they have rigorous semantics
have rigorous semantics that
rigorous semantics that can
semantics that can be
that can be formally
can be formally defined
they provide predictable operational
provide predictable operational behavior
they allow for the
allow for the rigorous
for the rigorous expression
the rigorous expression of
rigorous expression of algorithms
expression of algorithms for
of algorithms for monitoring
algorithms for monitoring or
for monitoring or managing
monitoring or managing sdn
or managing sdn networks
this work was supported
by a grant from
a grant from the
grant from the darpa
from the darpa mrc
the darpa mrc program
online measurement of large
measurement of large traffic
of large traffic aggregates
large traffic aggregates on
traffic aggregates on commodity
aggregates on commodity switches
perspectives on optimistically replicated
on optimistically replicated peer
software practice and experience
a compositional architecture for
compositional architecture for gossip
architecture for gossip protocols
informed prefetching and caching
in proceedings of the
proceedings of the fifteenth
of the fifteenth acm
the fifteenth acm symposium
fifteenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
managing the network with
the network with merlin
design and implementation of
and implementation of the
implementation of the sun
of the sun network
the sun network file
sun network file system
in proceedings of usenix
proceedings of usenix summer
of usenix summer conference
a language for provisioning
language for provisioning network
for provisioning network resources
the evolution of coda
acm transactions on computer
transactions on computer systems
software defined traffic measurement
defined traffic measurement with
traffic measurement with opensketch
determinism and asynchrony of
and asynchrony of set
asynchrony of set iterators
of set iterators to
set iterators to reduce
iterators to reduce aggregrate
to reduce aggregrate file
reduce aggregrate file i
in proceedings of the
proceedings of the sixteenth
of the sixteenth acm
the sixteenth acm symposium
sixteenth acm symposium on
acm symposium on operating
symposium on operating system
on operating system principles
file system usage in
system usage in windows
usage in windows nt
in proceedings of the
proceedings of the seventeenth
of the seventeenth acm
the seventeenth acm symposium
seventeenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
swift institute swift institute
institute swift institute working
swift institute working paper
institute working paper no
arla a free afs
a free afs client
in proceedings of the
s dilemma ittay eyal
dilemma ittay eyal publication
ittay eyal publication date
electronic copy available at
volume leases for consistency
leases for consistency in
for consistency in large
ieee transactions on knowledge
transactions on knowledge and
on knowledge and data
the miner s dilemma
knowledge and data engineering
miner s dilemma ittay
s dilemma ittay eyal
dilemma ittay eyal cornell
ittay eyal cornell university
eyal cornell university abstract
cornell university abstract an
university abstract an open
abstract an open distributed
an open distributed system
open distributed system can
distributed system can be
system can be secured
can be secured by
be secured by requiring
secured by requiring participants
by requiring participants to
requiring participants to present
participants to present proof
to present proof of
present proof of work
proof of work and
of work and rewarding
work and rewarding them
and rewarding them for
rewarding them for participation
the bitcoin digital currency
bitcoin digital currency introduced
digital currency introduced this
currency introduced this mechanism
which is adopted by
is adopted by almost
adopted by almost all
by almost all contemporary
almost all contemporary digital
all contemporary digital currencies
contemporary digital currencies and
digital currencies and related
currencies and related services
a natural process leads
natural process leads participants
process leads participants of
leads participants of such
participants of such systems
of such systems to
such systems to form
systems to form pools
where members aggregate their
members aggregate their power
aggregate their power and
their power and share
power and share the
and share the rewards
experience with bitcoin shows
with bitcoin shows that
bitcoin shows that the
shows that the largest
that the largest pools
the largest pools are
largest pools are often
pools are often open
allowing anyone to join
it has long been
has long been known
long been known that
been known that a
known that a member
that a member can
a member can sabotage
member can sabotage an
can sabotage an open
sabotage an open pool
an open pool by
open pool by seemingly
pool by seemingly joining
by seemingly joining it
seemingly joining it but
joining it but never
it but never sharing
but never sharing its
never sharing its proofs
sharing its proofs of
its proofs of work
the pool shares its
pool shares its revenue
shares its revenue with
its revenue with the
revenue with the attacker
and so each of
so each of its
each of its participants
of its participants earns
its participants earns less
we define and analyze
define and analyze a
and analyze a game
analyze a game where
a game where pools
game where pools use
where pools use some
pools use some of
use some of their
some of their participants
of their participants to
their participants to infiltrate
participants to infiltrate other
to infiltrate other pools
infiltrate other pools and
other pools and perform
pools and perform such
and perform such an
perform such an attack
with any number of
any number of pools
attacks is not a
is not a nash
not a nash equilibrium
we study the special
study the special cases
the special cases where
special cases where either
cases where either two
where either two pools
either two pools or
two pools or any
pools or any number
or any number of
any number of identical
number of identical pools
of identical pools play
identical pools play the
pools play the game
play the game and
the game and the
game and the rest
and the rest of
the rest of the
rest of the participants
of the participants are
the participants are uninvolved
in both of these
both of these cases
of these cases there
these cases there exists
cases there exists an
there exists an equilibrium
exists an equilibrium that
an equilibrium that constitutes
equilibrium that constitutes a
that constitutes a tragedy
constitutes a tragedy of
a tragedy of the
tragedy of the commons
of the commons where
the commons where the
commons where the participating
where the participating pools
the participating pools attack
participating pools attack one
pools attack one another
attack one another and
one another and earn
another and earn less
and earn less than
earn less than they
less than they would
than they would have
they would have if
would have if none
have if none had
if none had attacked
the decision whether or
decision whether or not
whether or not to
or not to attack
not to attack is
to attack is the
attack is the miner
is the miner s
the miner s dilemma
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
the game is played
game is played daily
is played daily by
played daily by the
daily by the active
by the active bitcoin
the active bitcoin pools
which apparently choose not
apparently choose not to
choose not to attack
if this balance breaks
the revenue of open
revenue of open pools
of open pools might
open pools might diminish
making them unattractive to
them unattractive to participants
is a digital currency
a digital currency that
digital currency that is
currency that is gaining
that is gaining acceptance
with an estimated market
an estimated market capitalization
estimated market capitalization of
market capitalization of over
bitcoin s security stems
s security stems from
security stems from a
stems from a robust
from a robust incentive
a robust incentive system
participants are required to
are required to provide
required to provide expensive
to provide expensive proofs
provide expensive proofs of
expensive proofs of work
and they are rewarded
they are rewarded according
are rewarded according to
rewarded according to their
according to their efforts
this architecture has proved
architecture has proved both
has proved both stable
proved both stable and
both stable and scalable
and it is used
it is used by
is used by most
used by most contemporary
by most contemporary digital
most contemporary digital currencies
contemporary digital currencies and
digital currencies and related
currencies and related services
our results apply to
results apply to all
apply to all such
to all such incentive
all such incentive systems
but we use bitcoin
we use bitcoin terminology
use bitcoin terminology and
bitcoin terminology and examples
terminology and examples since
and examples since it
examples since it serves
since it serves as
it serves as an
serves as an active
as an active and
an active and archetypal
active and archetypal example
bitcoin implements its incentive
implements its incentive systems
its incentive systems with
incentive systems with a
systems with a data
with a data structure
a data structure called
data structure called the
structure called the blockchain
the blockchain is a
blockchain is a serialization
is a serialization of
a serialization of all
serialization of all bitcoin
of all bitcoin transactions
it is a single
is a single global
a single global ledger
single global ledger maintained
global ledger maintained by
ledger maintained by an
maintained by an open
by an open distributed
an open distributed system
since anyone can join
anyone can join the
can join the open
join the open system
the open system and
open system and participate
system and participate in
and participate in maintaining
participate in maintaining the
in maintaining the blockchain
bitcoin uses a proof
uses a proof of
a proof of work
proof of work mechanism
of work mechanism to
work mechanism to deter
mechanism to deter attacks
participation requires exerting significant
requires exerting significant computational
exerting significant computational resources
a participant who proves
participant who proves she
who proves she has
proves she has exerted
she has exerted enough
has exerted enough resources
exerted enough resources with
enough resources with a
resources with a proof
with a proof of
a proof of work
proof of work is
of work is allowed
work is allowed to
is allowed to take
allowed to take a
to take a step
take a step in
a step in the
step in the protocol
in the protocol by
the protocol by generating
protocol by generating a
by generating a block
participants are compensated for
are compensated for their
compensated for their efforts
for their efforts with
their efforts with newly
efforts with newly minted
with newly minted bitcoins
the process of creating
process of creating a
of creating a block
creating a block is
a block is called
block is called mining
and the participants miners
in order to win
order to win the
to win the reward
many miners try to
miners try to generate
try to generate blocks
the system automatically adjusts
system automatically adjusts the
automatically adjusts the difficulty
adjusts the difficulty of
the difficulty of block
difficulty of block generation
such that one block
that one block is
one block is added
block is added every
minutes to the blockchain
this means that each
means that each miner
that each miner seldom
each miner seldom generates
miner seldom generates a
seldom generates a block
although its revenue may
its revenue may be
revenue may be positive
may be positive in
be positive in expectation
a miner may have
miner may have to
may have to wait
have to wait for
to wait for an
wait for an extended
for an extended period
an extended period to
extended period to create
period to create a
to create a block
create a block and
a block and earn
block and earn the
and earn the actual
earn the actual bitcoins
the miner s dilemma
miner s dilemma ittay
s dilemma ittay eyal
dilemma ittay eyal cornell
ittay eyal cornell university
miners form mining pools
eyal cornell university abstract
cornell university abstract an
university abstract an open
where all members mine
abstract an open distributed
all members mine concurrently
an open distributed system
members mine concurrently and
open distributed system can
mine concurrently and they
distributed system can be
concurrently and they share
system can be secured
and they share their
can be secured by
they share their revenue
be secured by requiring
share their revenue whenever
secured by requiring participants
their revenue whenever one
by requiring participants to
revenue whenever one of
requiring participants to present
whenever one of them
participants to present proof
one of them creates
to present proof of
of them creates a
present proof of work
them creates a block
proof of work and
of work and rewarding
work and rewarding them
and rewarding them for
rewarding them for participation
pools are typically implemented
are typically implemented as
typically implemented as a
implemented as a pool
the bitcoin digital currency
as a pool manager
bitcoin digital currency introduced
a pool manager and
digital currency introduced this
pool manager and a
currency introduced this mechanism
manager and a cohort
and a cohort of
a cohort of miners
which is adopted by
is adopted by almost
adopted by almost all
the pool manager joins
by almost all contemporary
pool manager joins the
almost all contemporary digital
manager joins the bitcoin
all contemporary digital currencies
joins the bitcoin system
contemporary digital currencies and
the bitcoin system as
digital currencies and related
bitcoin system as a
currencies and related services
system as a single
as a single miner
a natural process leads
instead of generating proof
natural process leads participants
of generating proof of
process leads participants of
generating proof of work
leads participants of such
participants of such systems
of such systems to
such systems to form
systems to form pools
it outsources the work
outsources the work to
the work to the
work to the miners
where members aggregate their
members aggregate their power
aggregate their power and
in order to evaluate
their power and share
order to evaluate the
power and share the
to evaluate the miners
and share the rewards
evaluate the miners efforts
experience with bitcoin shows
with bitcoin shows that
the pool manager accepts
bitcoin shows that the
pool manager accepts partial
shows that the largest
manager accepts partial proof
that the largest pools
accepts partial proof of
the largest pools are
partial proof of work
largest pools are often
proof of work and
pools are often open
of work and estimates
work and estimates each
and estimates each miner
estimates each miner s
allowing anyone to join
each miner s power
miner s power according
s power according to
power according to the
according to the rate
it has long been
to the rate with
has long been known
the rate with which
long been known that
rate with which it
been known that a
with which it submits
known that a member
which it submits such
that a member can
it submits such partial
a member can sabotage
submits such partial proof
member can sabotage an
such partial proof of
can sabotage an open
partial proof of work
sabotage an open pool
an open pool by
open pool by seemingly
pool by seemingly joining
by seemingly joining it
seemingly joining it but
when a miner generates
joining it but never
a miner generates a
it but never sharing
miner generates a full
but never sharing its
generates a full proof
never sharing its proofs
a full proof of
sharing its proofs of
full proof of work
its proofs of work
it sends it to
the pool shares its
sends it to the
pool shares its revenue
it to the pool
shares its revenue with
to the pool manager
its revenue with the
the pool manager which
revenue with the attacker
pool manager which publishes
manager which publishes this
which publishes this proof
publishes this proof of
and so each of
this proof of work
so each of its
proof of work to
each of its participants
of work to the
of its participants earns
work to the bitcoin
its participants earns less
to the bitcoin system
we define and analyze
the pool manager thus
define and analyze a
pool manager thus receives
and analyze a game
manager thus receives the
analyze a game where
thus receives the full
a game where pools
receives the full revenue
game where pools use
the full revenue of
where pools use some
full revenue of the
pools use some of
revenue of the block
use some of their
of the block and
some of their participants
the block and distributes
of their participants to
block and distributes it
their participants to infiltrate
and distributes it fairly
participants to infiltrate other
distributes it fairly according
to infiltrate other pools
it fairly according to
infiltrate other pools and
fairly according to its
other pools and perform
according to its members
pools and perform such
to its members power
and perform such an
perform such an attack
many of the pools
with any number of
of the pools are
any number of pools
the pools are open
pools are open they
are open they allow
open they allow any
they allow any miner
allow any miner to
any miner to join
miner to join them
to join them using
join them using a
them using a public
using a public internet
a public internet interface
attacks is not a
is not a nash
not a nash equilibrium
such open pools are
open pools are susceptible
pools are susceptible to
we study the special
are susceptible to the
study the special cases
susceptible to the classical
the special cases where
to the classical block
special cases where either
the classical block withholding
cases where either two
classical block withholding attack
where either two pools
either two pools or
two pools or any
pools or any number
or any number of
any number of identical
number of identical pools
of identical pools play
identical pools play the
pools play the game
play the game and
the game and the
game and the rest
and the rest of
the rest of the
rest of the participants
of the participants are
the participants are uninvolved
where a miner sends
a miner sends only
miner sends only partial
sends only partial proof
only partial proof of
in both of these
partial proof of work
both of these cases
proof of work to
of these cases there
of work to the
these cases there exists
work to the pool
cases there exists an
to the pool manager
there exists an equilibrium
the pool manager and
exists an equilibrium that
pool manager and discards
an equilibrium that constitutes
manager and discards full
equilibrium that constitutes a
and discards full proof
that constitutes a tragedy
discards full proof of
constitutes a tragedy of
full proof of work
a tragedy of the
tragedy of the commons
of the commons where
the commons where the
due to the partial
commons where the participating
to the partial proof
where the participating pools
the partial proof of
the participating pools attack
partial proof of work
participating pools attack one
proof of work it
pools attack one another
of work it sends
attack one another and
work it sends to
one another and earn
it sends to the
another and earn less
sends to the pool
and earn less than
earn less than they
less than they would
than they would have
they would have if
the miner is considered
would have if none
miner is considered a
have if none had
is considered a regular
if none had attacked
considered a regular pool
a regular pool member
regular pool member and
pool member and the
member and the pool
and the pool can
the pool can estimate
pool can estimate its
can estimate its power
the decision whether or
decision whether or not
whether or not to
or not to attack
not to attack is
to attack is the
attack is the miner
is the miner s
the attacker shares the
the miner s dilemma
attacker shares the revenue
shares the revenue obtained
the revenue obtained by
revenue obtained by the
an instance of the
obtained by the other
instance of the iterative
by the other pool
of the iterative prisoner
the other pool members
the iterative prisoner s
iterative prisoner s dilemma
but does not contribute
the game is played
game is played daily
is played daily by
it reduces the revenue
played daily by the
reduces the revenue of
daily by the active
the revenue of the
by the active bitcoin
revenue of the other
the active bitcoin pools
of the other members
which apparently choose not
but also its own
apparently choose not to
choose not to attack
we provide necessary background
provide necessary background on
if this balance breaks
necessary background on the
background on the bitcoin
on the bitcoin protocol
the revenue of open
revenue of open pools
of open pools might
pools and the classical
open pools might diminish
and the classical block
the classical block withholding
classical block withholding attack
block withholding attack in
withholding attack in section
making them unattractive to
attack in section ii
them unattractive to participants
and specify our model
specify our model in
our model in section
model in section iii
for a broader view
a broader view of
broader view of the
view of the protocol
of the protocol and
the protocol and ecosystem
protocol and ecosystem the
and ecosystem the reader
is a digital currency
ecosystem the reader may
a digital currency that
the reader may refer
digital currency that is
reader may refer to
currency that is gaining
may refer to the
that is gaining acceptance
refer to the survey
to the survey by
the survey by bonneau
survey by bonneau et
by bonneau et al
with an estimated market
an estimated market capitalization
in this work we
estimated market capitalization of
this work we analyze
market capitalization of over
work we analyze block
we analyze block withholding
analyze block withholding attacks
block withholding attacks among
withholding attacks among pools
a pool that employs
pool that employs the
that employs the pool
employs the pool block
the pool block withholding
pool block withholding attack
block withholding attack registers
withholding attack registers with
attack registers with the
registers with the victim
with the victim pool
the victim pool as
victim pool as a
pool as a regular
as a regular miner
it receives tasks from
receives tasks from the
tasks from the victim
from the victim pool
the victim pool and
victim pool and transfers
pool and transfers them
and transfers them to
transfers them to some
them to some of
to some of its
some of its own
of its own miners
bitcoin s security stems
s security stems from
we call these infiltrating
security stems from a
call these infiltrating miners
stems from a robust
from a robust incentive
a robust incentive system
and the mining power
the mining power spent
mining power spent by
participants are required to
power spent by a
are required to provide
spent by a pool
required to provide expensive
by a pool the
to provide expensive proofs
a pool the infiltration
provide expensive proofs of
pool the infiltration rate
expensive proofs of work
when electronic copy available
and they are rewarded
electronic copy available at
they are rewarded according
are rewarded according to
rewarded according to their
according to their efforts
this architecture has proved
architecture has proved both
has proved both stable
proved both stable and
both stable and scalable
and it is used
it is used by
is used by most
used by most contemporary
by most contemporary digital
most contemporary digital currencies
contemporary digital currencies and
digital currencies and related
currencies and related services
the attacking pool s
attacking pool s infiltrating
pool s infiltrating miners
s infiltrating miners deliver
infiltrating miners deliver partial
miners deliver partial proofs
deliver partial proofs of
partial proofs of work
the attacker transfers them
attacker transfers them to
transfers them to the
them to the victim
to the victim pool
letting the attacked pool
the attacked pool estimate
attacked pool estimate their
pool estimate their power
when the infiltrating miners
the infiltrating miners deliver
infiltrating miners deliver a
miners deliver a full
deliver a full proof
a full proof of
full proof of work
the attacking pool discards
attacking pool discards it
this attack affects the
attack affects the revenues
affects the revenues of
the revenues of the
revenues of the pools
of the pools in
the pools in several
pools in several ways
the victim pool s
victim pool s effective
pool s effective mining
s effective mining rate
our results apply to
effective mining rate is
results apply to all
mining rate is unchanged
apply to all such
to all such incentive
all such incentive systems
but its total revenue
its total revenue is
total revenue is divided
revenue is divided among
but we use bitcoin
is divided among more
divided among more miners
we use bitcoin terminology
use bitcoin terminology and
bitcoin terminology and examples
the attacker s mining
terminology and examples since
attacker s mining power
and examples since it
s mining power is
examples since it serves
mining power is reduced
since it serves as
it serves as an
serves as an active
as an active and
an active and archetypal
since some of its
active and archetypal example
some of its miners
of its miners are
its miners are used
miners are used for
are used for block
used for block withholding
bitcoin implements its incentive
implements its incentive systems
its incentive systems with
incentive systems with a
but it earns additional
systems with a data
it earns additional revenue
with a data structure
earns additional revenue through
a data structure called
additional revenue through its
data structure called the
revenue through its infiltration
structure called the blockchain
through its infiltration of
its infiltration of the
infiltration of the other
of the other pool
the blockchain is a
blockchain is a serialization
is a serialization of
a serialization of all
serialization of all bitcoin
of all bitcoin transactions
the total effective mining
total effective mining power
effective mining power in
mining power in the
it is a single
power in the system
is a single global
in the system is
a single global ledger
the system is reduced
single global ledger maintained
global ledger maintained by
ledger maintained by an
maintained by an open
by an open distributed
causing the bitcoin protocol
an open distributed system
the bitcoin protocol to
bitcoin protocol to reduce
protocol to reduce the
to reduce the difficulty
since anyone can join
anyone can join the
can join the open
taking all these factors
join the open system
all these factors into
the open system and
these factors into account
open system and participate
system and participate in
and participate in maintaining
participate in maintaining the
in maintaining the blockchain
we observe that a
observe that a pool
that a pool might
a pool might be
pool might be able
bitcoin uses a proof
might be able to
uses a proof of
be able to increase
a proof of work
able to increase its
proof of work mechanism
to increase its revenue
of work mechanism to
work mechanism to deter
increase its revenue by
mechanism to deter attacks
its revenue by attacking
revenue by attacking other
by attacking other pools
participation requires exerting significant
requires exerting significant compute
exerting significant compute resources
each pool therefore makes
pool therefore makes a
therefore makes a choice
makes a choice of
a choice of whether
a participant that proves
choice of whether to
participant that proves she
of whether to attack
that proves she has
whether to attack each
proves she has exerted
to attack each of
she has exerted enough
attack each of the
has exerted enough resources
each of the other
exerted enough resources with
of the other pools
enough resources with a
the other pools in
resources with a proof
other pools in the
with a proof of
pools in the system
a proof of work
proof of work is
of work is allowed
work is allowed to
and with what infiltration
is allowed to take
with what infiltration rate
allowed to take a
to take a step
take a step in
a step in the
step in the protocol
this gives rise to
in the protocol by
gives rise to the
the protocol by generating
rise to the pool
protocol by generating a
to the pool game
by generating a block
we specify this game
specify this game and
participants are compensated for
this game and provide
are compensated for their
game and provide initial
compensated for their efforts
and provide initial analysis
for their efforts with
provide initial analysis in
their efforts with newly
initial analysis in section
efforts with newly minted
analysis in section iv
with newly minted bitcoins
in section v we
the process of creating
section v we analyze
process of creating a
v we analyze the
of creating a block
we analyze the scenario
creating a block is
analyze the scenario where
a block is called
the scenario where exactly
block is called mining
scenario where exactly two
where exactly two of
exactly two of the
two of the pools
and the participants miners
of the pools take
the pools take part
pools take part in
take part in the
in order to win
part in the game
order to win the
in the game and
to win the reward
the game and only
game and only one
and only one can
only one can attack
one can attack the
many miners try to
can attack the other
miners try to generate
try to generate blocks
the system automatically adjusts
system automatically adjusts the
the attacker can always
automatically adjusts the difficulty
attacker can always increase
adjusts the difficulty of
can always increase its
the difficulty of block
always increase its revenue
difficulty of block generation
increase its revenue by
its revenue by attacking
such that one block
that one block is
we conclude that in
one block is added
conclude that in the
block is added every
that in the general
in the general case
minutes to the blockchain
with any number of
any number of pools
this means that each
means that each miner
that each miner seldom
each miner seldom generates
miner seldom generates a
seldom generates a block
although its revenue may
its revenue may be
revenue may be positive
may be positive in
attacks is not a
be positive in expectation
is not a nash
not a nash equilibrium
a miner may have
miner may have to
may have to wait
have to wait for
to wait for an
section vi deals with
wait for an extended
vi deals with the
for an extended period
deals with the case
an extended period to
with the case of
the case of two
extended period to create
case of two pools
period to create a
to create a block
create a block and
a block and earn
block and earn the
where each can attack
and earn the actual
each can attack the
earn the actual bitcoins
can attack the other
miners form mining pools
analysis becomes more complicated
becomes more complicated in
more complicated in two
complicated in two ways
where all members mine
all members mine concurrently
members mine concurrently and
mine concurrently and they
concurrently and they share
and they share their
they share their revenue
the revenue of each
share their revenue whenever
revenue of each pool
their revenue whenever one
of each pool affects
revenue whenever one of
each pool affects the
whenever one of them
pool affects the revenue
one of them creates
affects the revenue of
of them creates a
the revenue of the
them creates a block
revenue of the other
of the other through
the other through the
other through the infiltrating
through the infiltrating miners
pools are typically implemented
are typically implemented as
typically implemented as a
implemented as a pool
as a pool manager
we prove that for
a pool manager and
prove that for a
pool manager and a
that for a static
manager and a cohort
for a static choice
and a cohort of
a static choice of
a cohort of miners
static choice of infiltration
choice of infiltration rates
of infiltration rates the
infiltration rates the pool
rates the pool revenues
the pool manager joins
the pool revenues converge
pool manager joins the
manager joins the bitcoin
joins the bitcoin system
the bitcoin system as
bitcoin system as a
system as a single
as a single miner
once one pool changes
one pool changes its
instead of generating proof
pool changes its infiltration
of generating proof of
changes its infiltration rate
generating proof of work
its infiltration rate of
infiltration rate of the
rate of the other
it outsources the work
outsources the work to
the work to the
work to the miners
the latter may prefer
latter may prefer to
may prefer to change
prefer to change its
in order to evaluate
to change its infiltration
order to evaluate the
change its infiltration rate
to evaluate the miners
its infiltration rate of
evaluate the miners efforts
infiltration rate of the
rate of the former
the pool manager accepts
therefore the game itself
pool manager accepts partial
the game itself takes
manager accepts partial proof
game itself takes multiple
accepts partial proof of
itself takes multiple rounds
partial proof of work
takes multiple rounds to
proof of work and
multiple rounds to converge
of work and estimates
work and estimates each
and estimates each miner
estimates each miner s
each miner s power
we show analytically that
miner s power according
show analytically that the
s power according to
analytically that the game
power according to the
that the game has
according to the rate
the game has a
to the rate with
game has a single
the rate with which
has a single nash
rate with which it
a single nash equilibrium
with which it submits
single nash equilibrium and
which it submits such
nash equilibrium and numerically
it submits such partial
equilibrium and numerically study
submits such partial proof
and numerically study the
such partial proof of
numerically study the equilibrium
partial proof of work
study the equilibrium points
the equilibrium points for
equilibrium points for different
points for different pool
for different pool sizes
when a miner generates
a miner generates a
miner generates a full
for pools smaller than
generates a full proof
a full proof of
full proof of work
it sends it to
sends it to the
it to the pool
to the pool manager
the pool manager which
pool manager which publishes
manager which publishes this
at the equilibrium point
which publishes this proof
the equilibrium point both
publishes this proof of
equilibrium point both pools
this proof of work
point both pools earn
proof of work to
both pools earn less
of work to the
pools earn less than
work to the bitcoin
earn less than they
to the bitcoin system
less than they would
than they would have
they would have in
would have in the
have in the nonequilibrium
in the nonequilibrium no
the pool manager thus
pool manager thus receives
manager thus receives the
thus receives the full
receives the full revenue
the full revenue of
full revenue of the
revenue of the block
of the block and
the block and distributes
since pools can decide
block and distributes it
pools can decide to
and distributes it fairly
can decide to start
distributes it fairly according
decide to start or
it fairly according to
to start or stop
fairly according to its
start or stop attacking
according to its members
or stop attacking at
to its members power
stop attacking at any
attacking at any point
many of the pools
this can be modeled
of the pools are
can be modeled as
the pools are open
be modeled as the
pools are open they
modeled as the miner
are open they allow
as the miner s
open they allow any
the miner s dilemma
they allow any miner
miner s dilemma an
allow any miner to
s dilemma an instance
any miner to join
dilemma an instance of
miner to join them
an instance of the
to join them using
instance of the iterative
join them using a
of the iterative prisoner
them using a public
the iterative prisoner s
using a public internet
iterative prisoner s dilemma
a public internet interface
such open pools are
open pools are susceptible
pools are susceptible to
attacking is the dominant
are susceptible to the
is the dominant strategy
susceptible to the classical
the dominant strategy in
to the classical block
dominant strategy in each
the classical block withholding
strategy in each iteration
classical block withholding attack
but if the pools
if the pools can
the pools can agree
pools can agree not
can agree not to
agree not to attack
both benefit in the
benefit in the long
in the long run
where a miner sends
a miner sends only
we address in section
miner sends only partial
address in section vii
sends only partial proof
in section vii the
only partial proof of
section vii the case
partial proof of work
vii the case where
proof of work to
the case where the
of work to the
case where the participants
work to the pool
where the participants are
to the pool manager
the participants are an
the pool manager and
participants are an arbitrary
pool manager and discards
are an arbitrary number
manager and discards full
an arbitrary number of
and discards full proof
arbitrary number of identical
discards full proof of
number of identical pools
full proof of work
there exists a symmetric
due to the partial
exists a symmetric equilibrium
to the partial proof
a symmetric equilibrium in
the partial proof of
symmetric equilibrium in which
partial proof of work
equilibrium in which each
proof of work it
in which each participating
of work it sends
which each participating pool
work it sends to
each participating pool attacks
it sends to the
participating pool attacks each
sends to the pool
pool attacks each of
attacks each of the
each of the other
of the other participating
the other participating pools
the miner is considered
miner is considered a
is considered a regular
as in the minority
considered a regular pool
in the minority two
a regular pool member
regular pool member and
pool member and the
member and the pool
and the pool can
the pool can estimate
pool can estimate its
can estimate its power
here too at equilibrium
too at equilibrium all
at equilibrium all pools
equilibrium all pools earn
all pools earn less
pools earn less than
earn less than with
less than with the
than with the no
the attacker shares the
attacker shares the revenue
shares the revenue obtained
the revenue obtained by
revenue obtained by the
obtained by the other
by the other pool
the other pool members
our results imply that
results imply that block
but does not contribute
imply that block withholding
that block withholding by
block withholding by pools
withholding by pools leads
by pools leads to
it reduces the revenue
pools leads to an
reduces the revenue of
leads to an unfavorable
the revenue of the
to an unfavorable equilibrium
revenue of the other
of the other members
but also its own
due to the anonymity
to the anonymity of
the anonymity of miners
we provide necessary background
provide necessary background on
necessary background on the
a single pool might
background on the bitcoin
single pool might be
on the bitcoin protocol
pool might be tempted
might be tempted to
be tempted to attack
pools and the classical
and the classical block
leading the other pools
the classical block withholding
the other pools to
classical block withholding attack
other pools to attack
block withholding attack in
pools to attack as
withholding attack in section
to attack as well
attack in section ii
the implications might be
implications might be devastating
and specify our model
might be devastating for
specify our model in
be devastating for open
our model in section
devastating for open pools
model in section iii
if their revenues are
their revenues are reduced
for a broader view
a broader view of
broader view of the
view of the protocol
miners will prefer to
of the protocol and
will prefer to form
the protocol and ecosystem
prefer to form closed
protocol and ecosystem the
to form closed pools
and ecosystem the reader
form closed pools that
ecosystem the reader may
closed pools that cannot
the reader may refer
pools that cannot be
reader may refer to
that cannot be attacked
may refer to the
cannot be attacked in
refer to the survey
be attacked in this
to the survey by
attacked in this manner
the survey by bonneau
survey by bonneau et
by bonneau et al
though this may be
this may be conceived
may be conceived as
be conceived as bad
conceived as bad news
as bad news for
bad news for public
news for public mining
for public mining pools
on the whole it
the whole it may
whole it may be
it may be good
may be good news
be good news to
good news to the
news to the bitcoin
to the bitcoin system
in this work we
which prefers small pools
this work we analyze
work we analyze block
we analyze block withholding
analyze block withholding attacks
block withholding attacks among
we examine the practicality
withholding attacks among pools
examine the practicality of
the practicality of the
practicality of the attack
of the attack in
a pool that employs
the attack in section
pool that employs the
attack in section viii
that employs the pool
in section viii and
employs the pool block
section viii and discuss
the pool block withholding
viii and discuss implications
pool block withholding attack
and discuss implications and
block withholding attack registers
discuss implications and model
withholding attack registers with
implications and model extensions
attack registers with the
and model extensions in
registers with the victim
model extensions in section
with the victim pool
extensions in section ix
the victim pool as
victim pool as a
pool as a regular
as a regular miner
our contributions are the
it receives tasks from
contributions are the following
receives tasks from the
tasks from the victim
from the victim pool
the victim pool and
victim pool and transfers
pool and transfers them
and transfers them to
transfers them to some
them to some of
to some of its
some of its own
of its own miners
definition of the pool
of the pool game
the pool game where
pool game where pools
we call these infiltrating
game where pools in
call these infiltrating miners
where pools in a
pools in a proof
and the mining power
the mining power spent
ofwork secured system attack
mining power spent by
secured system attack one
power spent by a
system attack one another
spent by a pool
attack one another with
by a pool the
one another with a
a pool the infiltration
another with a pool
pool the infiltration rate
with a pool block
a pool block withholding
pool block withholding attack
when the attacking pool
the attacking pool s
attacking pool s infiltrating
pool s infiltrating miners
s infiltrating miners deliver
infiltrating miners deliver partial
miners deliver partial proofs
deliver partial proofs of
partial proofs of work
in the general case
the attacker transfers them
attacker transfers them to
transfers them to the
them to the victim
to the victim pool
letting the attacked pool
attacks is not an
the attacked pool estimate
is not an equilibrium
attacked pool estimate their
pool estimate their power
when the infiltrating miners
the infiltrating miners deliver
infiltrating miners deliver a
with two minority pools
miners deliver a full
two minority pools participating
deliver a full proof
a full proof of
full proof of work
the only nash equilibrium
only nash equilibrium is
nash equilibrium is when
the attacking pool discards
equilibrium is when the
attacking pool discards it
is when the pools
when the pools attack
the pools attack one
pools attack one another
this attack affects the
attack affects the revenues
affects the revenues of
the revenues of the
and both earn less
revenues of the pools
both earn less than
of the pools in
earn less than if
the pools in several
less than if none
pools in several ways
than if none had
if none had attacked
the victim pool s
victim pool s effective
miners therefore face the
pool s effective mining
therefore face the miner
s effective mining rate
face the miner s
effective mining rate is
the miner s dilemma
mining rate is unchanged
an instance of the
instance of the iterative
but its total revenue
of the iterative prisoner
its total revenue is
the iterative prisoner s
total revenue is divided
iterative prisoner s dilemma
revenue is divided among
is divided among more
divided among more miners
repeatedly choosing between attack
choosing between attack and
between attack and no
the attacker s mining
attacker s mining power
s mining power is
mining power is reduced
since some of its
some of its miners
of its miners are
its miners are used
miners are used for
are used for block
used for block withholding
with multiple pools of
multiple pools of equal
pools of equal size
of equal size there
but it earns additional
equal size there is
it earns additional revenue
size there is a
earns additional revenue through
there is a symmetric
additional revenue through its
is a symmetric nash
revenue through its infiltration
a symmetric nash equilibrium
through its infiltration of
its infiltration of the
infiltration of the other
of the other pool
where all pools earn
all pools earn less
pools earn less than
earn less than if
less than if none
than if none had
if none had attacked
the total effective mining
total effective mining power
effective mining power in
mining power in the
power in the system
in the system is
the system is reduced
causing the bitcoin protocol
the bitcoin protocol to
bitcoin protocol to reduce
inefficient equilibria for open
protocol to reduce the
equilibria for open pools
to reduce the difficulty
for open pools may
open pools may serve
pools may serve the
may serve the system
serve the system by
taking all these factors
the system by reducing
all these factors into
system by reducing their
these factors into account
by reducing their attraction
reducing their attraction and
their attraction and pushing
attraction and pushing miners
and pushing miners towards
we observe that a
pushing miners towards smaller
observe that a pool
miners towards smaller closed
that a pool might
towards smaller closed pools
a pool might be
pool might be able
might be able to
be able to increase
able to increase its
the classical block withholding
to increase its revenue
classical block withholding attack
increase its revenue by
block withholding attack is
its revenue by attacking
withholding attack is as
revenue by attacking other
attack is as old
by attacking other pools
is as old as
as old as pools
old as pools themselves
each pool therefore makes
pool therefore makes a
therefore makes a choice
but its use by
makes a choice of
its use by pools
a choice of whether
use by pools has
choice of whether to
by pools has not
of whether to attack
pools has not been
whether to attack each
has not been suggested
to attack each of
not been suggested until
attack each of the
been suggested until recently
each of the other
of the other pools
the other pools in
other pools in the
pools in the system
we overview related attacks
overview related attacks and
related attacks and prior
attacks and prior work
and prior work in
and with what infiltration
prior work in section
with what infiltration rate
work in section x
this gives rise to
and conclude with final
gives rise to the
conclude with final remarks
rise to the pool
with final remarks in
to the pool game
final remarks in section
remarks in section xi
we specify this game
specify this game and
this game and provide
game and provide initial
and provide initial analysis
provide initial analysis in
p reliminaries b itcoin
initial analysis in section
reliminaries b itcoin and
analysis in section iv
b itcoin and p
itcoin and p ooled
and p ooled m
p ooled m ining
ooled m ining bitcoin
in section v we
m ining bitcoin is
section v we analyze
ining bitcoin is a
v we analyze the
bitcoin is a distributed
we analyze the scenario
analyze the scenario where
the scenario where exactly
scenario where exactly two
where exactly two of
exactly two of the
two of the pools
of the pools take
the pools take part
pools take part in
take part in the
part in the game
in the game and
the game and only
game and only one
and only one can
only one can attack
one can attack the
can attack the other
the attacker can always
attacker can always increase
can always increase its
always increase its revenue
increase its revenue by
its revenue by attacking
we conclude that in
conclude that in the
that in the general
in the general case
with any number of
any number of pools
attacks is not a
is not a nash
not a nash equilibrium
section vi deals with
vi deals with the
deals with the case
with the case of
the case of two
case of two pools
clients use the system
use the system by
the system by issuing
system by issuing transactions
where each can attack
each can attack the
can attack the other
and the system s
the system s only
system s only task
s only task is
analysis becomes more complicated
only task is to
becomes more complicated in
task is to serialize
more complicated in two
is to serialize transactions
complicated in two ways
to serialize transactions in
serialize transactions in a
transactions in a single
in a single ledger
a single ledger and
single ledger and reject
ledger and reject transactions
the revenue of each
and reject transactions that
revenue of each pool
reject transactions that cannot
of each pool affects
transactions that cannot be
each pool affects the
that cannot be serialized
pool affects the revenue
cannot be serialized due
affects the revenue of
be serialized due to
the revenue of the
serialized due to conflicts
revenue of the other
due to conflicts with
of the other through
to conflicts with previous
the other through the
conflicts with previous transactions
other through the infiltrating
through the infiltrating miners
bitcoin transactions are protected
we prove that for
transactions are protected with
prove that for a
are protected with cryptographic
that for a static
protected with cryptographic techniques
for a static choice
with cryptographic techniques that
a static choice of
cryptographic techniques that ensure
static choice of infiltration
techniques that ensure that
choice of infiltration rates
that ensure that only
of infiltration rates the
ensure that only the
infiltration rates the pool
that only the rightful
rates the pool revenues
only the rightful owner
the pool revenues converge
the rightful owner of
rightful owner of a
owner of a bitcoin
of a bitcoin can
a bitcoin can transfer
bitcoin can transfer it
once one pool changes
one pool changes its
pool changes its infiltration
the transaction ledger is
changes its infiltration rate
transaction ledger is stored
its infiltration rate of
ledger is stored by
infiltration rate of the
is stored by a
rate of the other
stored by a network
by a network of
a network of miners
network of miners in
of miners in a
the latter may prefer
miners in a data
latter may prefer to
in a data structure
may prefer to change
a data structure caller
prefer to change its
data structure caller the
to change its infiltration
structure caller the blockchain
change its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the former
therefore the game itself
revenue for proof of
the game itself takes
for proof of work
game itself takes multiple
proof of work the
itself takes multiple rounds
of work the blockchain
takes multiple rounds to
work the blockchain records
multiple rounds to converge
the blockchain records the
blockchain records the transactions
we show analytically that
records the transactions in
show analytically that the
the transactions in units
analytically that the game
transactions in units of
that the game has
in units of blocks
the game has a
game has a single
has a single nash
a single nash equilibrium
single nash equilibrium and
nash equilibrium and numerically
dubbed the genesis block
equilibrium and numerically study
and numerically study the
numerically study the equilibrium
study the equilibrium points
is defined as part
the equilibrium points for
defined as part of
equilibrium points for different
as part of the
points for different pool
part of the protocol
for different pool sizes
a valid block contains
for pools smaller than
valid block contains the
block contains the hash
contains the hash of
the hash of the
hash of the previous
of the previous block
the hash of the
hash of the transactions
of the transactions in
the transactions in the
transactions in the current
in the current block
at the equilibrium point
the equilibrium point both
equilibrium point both pools
point both pools earn
both pools earn less
and a bitcoin address
pools earn less than
a bitcoin address which
earn less than they
bitcoin address which is
less than they would
address which is to
than they would have
which is to be
they would have in
is to be credited
would have in the
to be credited with
have in the nonequilibrium
be credited with a
in the nonequilibrium no
credited with a reward
with a reward for
a reward for generating
reward for generating the
for generating the block
any miner may add
miner may add a
may add a valid
since pools can decide
add a valid block
pools can decide to
a valid block to
can decide to start
valid block to the
decide to start or
block to the chain
to start or stop
to the chain by
start or stop attacking
or stop attacking at
stop attacking at any
attacking at any point
this can be modeled
proving that it has
can be modeled as
that it has spent
be modeled as the
it has spent a
modeled as the miner
has spent a certain
as the miner s
spent a certain amount
the miner s dilemma
a certain amount of
miner s dilemma an
certain amount of work
s dilemma an instance
amount of work and
dilemma an instance of
of work and publishing
an instance of the
work and publishing the
instance of the iterative
and publishing the block
of the iterative prisoner
publishing the block with
the iterative prisoner s
the block with the
iterative prisoner s dilemma
block with the proof
with the proof over
the proof over an
proof over an overlay
attacking is the dominant
over an overlay network
is the dominant strategy
an overlay network to
the dominant strategy in
overlay network to all
dominant strategy in each
network to all other
strategy in each iteration
to all other miners
but if the pools
when a miner creates
if the pools can
a miner creates a
the pools can agree
miner creates a block
pools can agree not
can agree not to
agree not to attack
it is compensated for
is compensated for its
compensated for its efforts
both benefit in the
for its efforts with
benefit in the long
its efforts with bitcoins
in the long run
this compensation includes a
compensation includes a per
we address in section
address in section vii
transaction fee paid by
in section vii the
fee paid by the
section vii the case
paid by the users
vii the case where
by the users electronic
the case where the
the users electronic copy
case where the participants
users electronic copy available
where the participants are
electronic copy available at
the participants are an
participants are an arbitrary
are an arbitrary number
an arbitrary number of
arbitrary number of identical
number of identical pools
there exists a symmetric
exists a symmetric equilibrium
a symmetric equilibrium in
symmetric equilibrium in which
equilibrium in which each
in which each participating
which each participating pool
each participating pool attacks
participating pool attacks each
pool attacks each of
attacks each of the
each of the other
of the other participating
the other participating pools
as in the minority
in the minority two
here too at equilibrium
too at equilibrium all
at equilibrium all pools
equilibrium all pools earn
all pools earn less
pools earn less than
earn less than with
less than with the
than with the no
whose transactions are included
and an amount of
an amount of minted
amount of minted bitcoins
of minted bitcoins that
minted bitcoins that are
bitcoins that are thus
our results imply that
that are thus introduced
results imply that block
are thus introduced into
imply that block withholding
thus introduced into the
that block withholding by
introduced into the system
block withholding by pools
withholding by pools leads
by pools leads to
pools leads to an
leads to an unfavorable
to an unfavorable equilibrium
the work which a
work which a miner
which a miner is
a miner is required
miner is required to
is required to do
required to do is
due to the anonymity
to do is to
to the anonymity of
do is to repeatedly
the anonymity of miners
is to repeatedly calculate
to repeatedly calculate a
repeatedly calculate a a
calculate a a hash
a a hash function
a single pool might
a hash function specifically
single pool might be
hash function specifically the
pool might be tempted
function specifically the sha
might be tempted to
be tempted to attack
leading the other pools
the other pools to
other pools to attack
pools to attack as
to attack as well
the implications might be
implications might be devastating
might be devastating for
be devastating for open
devastating for open pools
if their revenues are
their revenues are reduced
miners will prefer to
of a block header
will prefer to form
prefer to form closed
to form closed pools
form closed pools that
closed pools that cannot
pools that cannot be
to indicate that he
that cannot be attacked
indicate that he has
cannot be attacked in
that he has performed
be attacked in this
he has performed this
attacked in this manner
has performed this work
the miner provides a
miner provides a probabilistic
provides a probabilistic proof
though this may be
a probabilistic proof as
this may be conceived
probabilistic proof as follows
may be conceived as
be conceived as bad
conceived as bad news
as bad news for
bad news for public
the generated block has
news for public mining
generated block has a
for public mining pools
block has a nonce
has a nonce field
on the whole it
the whole it may
which can contain any
whole it may be
can contain any value
it may be good
may be good news
be good news to
good news to the
news to the bitcoin
the miner places different
to the bitcoin system
miner places different values
places different values in
different values in this
values in this field
which prefers small pools
in this field and
this field and calculates
field and calculates the
and calculates the hash
calculates the hash for
we examine the practicality
the hash for each
examine the practicality of
hash for each value
the practicality of the
practicality of the attack
of the attack in
the attack in section
attack in section viii
in section viii and
section viii and discuss
viii and discuss implications
if the result of
and discuss implications and
the result of the
discuss implications and model
result of the hash
implications and model extensions
of the hash is
and model extensions in
the hash is smaller
model extensions in section
hash is smaller than
extensions in section ix
is smaller than a
smaller than a target
than a target value
the nonce is considered
our contributions are the
nonce is considered a
contributions are the following
is considered a solution
and the block is
the block is valid
the number of attempts
definition of the pool
number of attempts to
of the pool game
of attempts to find
the pool game where
attempts to find a
pool game where pools
to find a single
game where pools in
find a single hash
where pools in a
a single hash is
pools in a proof
single hash is therefore
hash is therefore random
is therefore random with
therefore random with a
random with a geometric
ofwork secured system attack
with a geometric distribution
secured system attack one
system attack one another
attack one another with
one another with a
another with a pool
with a pool block
as each attempt is
a pool block withholding
each attempt is a
pool block withholding attack
attempt is a bernoulli
is a bernoulli trial
a bernoulli trial with
bernoulli trial with a
trial with a success
with a success probability
a success probability determined
success probability determined by
probability determined by the
determined by the target
by the target value
in the general case
at the existing huge
the existing huge hashing
existing huge hashing rates
huge hashing rates and
hashing rates and small
rates and small target
and small target values
attacks is not an
is not an equilibrium
the time to find
time to find a
to find a single
find a single hash
a single hash can
single hash can be
hash can be approximated
can be approximated by
be approximated by an
approximated by an exponential
by an exponential distribution
with two minority pools
two minority pools participating
the average time for
average time for a
the only nash equilibrium
time for a miner
only nash equilibrium is
for a miner to
nash equilibrium is when
a miner to find
equilibrium is when the
miner to find a
is when the pools
to find a solution
when the pools attack
find a solution is
the pools attack one
a solution is therefore
pools attack one another
solution is therefore proportional
is therefore proportional to
therefore proportional to its
proportional to its hashing
to its hashing rate
and both earn less
its hashing rate or
both earn less than
hashing rate or mining
earn less than if
rate or mining power
less than if none
than if none had
if none had attacked
to maintain a constant
maintain a constant rate
a constant rate of
constant rate of bitcoin
miners therefore face the
rate of bitcoin generation
therefore face the miner
face the miner s
the miner s dilemma
and as part of
as part of its
part of its defense
of its defense against
an instance of the
its defense against denial
instance of the iterative
defense against denial of
of the iterative prisoner
against denial of service
the iterative prisoner s
denial of service and
iterative prisoner s dilemma
of service and other
service and other attacks
repeatedly choosing between attack
choosing between attack and
the system normalizes the
between attack and no
system normalizes the rate
normalizes the rate of
the rate of block
rate of block generation
the protocol deterministically defines
protocol deterministically defines the
deterministically defines the target
defines the target value
with multiple pools of
the target value for
multiple pools of equal
target value for each
pools of equal size
value for each block
of equal size there
for each block according
equal size there is
each block according to
size there is a
block according to the
there is a symmetric
according to the time
is a symmetric nash
to the time required
a symmetric nash equilibrium
the time required to
time required to generate
required to generate recent
to generate recent blocks
where all pools earn
all pools earn less
pools earn less than
earn less than if
less than if none
than if none had
if none had attacked
is updated once every
inefficient equilibria for open
equilibria for open pools
blocks such that the
for open pools may
such that the average
open pools may serve
that the average time
pools may serve the
the average time for
may serve the system
average time for each
serve the system by
time for each block
the system by reducing
for each block to
system by reducing their
each block to be
by reducing their attraction
block to be found
reducing their attraction and
to be found is
their attraction and pushing
attraction and pushing miners
and pushing miners towards
pushing miners towards smaller
miners towards smaller closed
towards smaller closed pools
the classical block withholding
note that the exponential
classical block withholding attack
that the exponential distribution
block withholding attack is
the exponential distribution is
withholding attack is old
exponential distribution is memoryless
attack is old as
is old as pools
old as pools themselves
if all miners mine
all miners mine for
miners mine for block
mine for block number
but its use by
for block number b
its use by pools
use by pools has
by pools has not
once the block is
pools has not been
the block is found
has not been suggested
block is found at
not been suggested until
is found at time
been suggested until recently
found at time t
we overview related attacks
all miners switch to
overview related attacks and
miners switch to mine
related attacks and prior
switch to mine for
attacks and prior work
to mine for the
and prior work in
mine for the subsequent
prior work in section
for the subsequent block
work in section x
the subsequent block b
and conclude with final
conclude with final remarks
with final remarks in
final remarks in section
remarks in section xi
at t without changing
t without changing their
without changing their probability
changing their probability distribution
their probability distribution of
probability distribution of finding
distribution of finding a
of finding a block
p reliminaries b itcoin
finding a block after
reliminaries b itcoin and
a block after t
b itcoin and p
itcoin and p ooled
and p ooled m
p ooled m ining
ooled m ining bitcoin
m ining bitcoin is
ining bitcoin is a
bitcoin is a distributed
the probability that a
probability that a miner
that a miner i
a miner i with
miner i with mining
i with mining power
with mining power mi
mining power mi finds
power mi finds the
mi finds the next
finds the next block
the next block is
next block is its
block is its ratio
is its ratio out
its ratio out of
ratio out of the
out of the total
of the total mining
the total mining power
total mining power m
mining power m in
power m in the
m in the system
miner miner miner pool
miner miner miner pool
clients use the system
use the system by
the system by issuing
system by issuing transactions
and the system s
the system s only
and one miner mines
system s only task
one miner mines solo
s only task is
only task is to
task is to serialize
is to serialize transactions
to serialize transactions in
serialize transactions in a
pools datacenters are built
transactions in a single
datacenters are built around
in a single ledger
are built around the
a single ledger and
built around the world
single ledger and reject
ledger and reject transactions
and reject transactions that
reject transactions that cannot
transactions that cannot be
that cannot be serialized
cannot be serialized due
be serialized due to
serialized due to conflicts
due to conflicts with
to conflicts with previous
conflicts with previous transactions
bitcoin transactions are protected
mining is only profitable
transactions are protected with
is only profitable using
are protected with cryptographic
only profitable using dedicated
protected with cryptographic techniques
profitable using dedicated hardware
with cryptographic techniques that
using dedicated hardware in
cryptographic techniques that ensure
dedicated hardware in cutting
techniques that ensure that
hardware in cutting edge
that ensure that only
in cutting edge mining
ensure that only the
cutting edge mining rigs
that only the rightful
otherwise the energy costs
the energy costs exceed
energy costs exceed the
costs exceed the expected
exceed the expected revenue
although expected revenue from
expected revenue from mining
revenue from mining is
from mining is proportional
mining is proportional to
is proportional to the
proportional to the power
to the power of
the power of the
only the rightful owner
power of the mining
the rightful owner of
of the mining rigs
rightful owner of a
the mining rigs used
owner of a bitcoin
of a bitcoin can
a bitcoin can transfer
bitcoin can transfer it
a single home miner
single home miner using
home miner using a
miner using a small
the transaction ledger is
using a small rig
transaction ledger is stored
a small rig is
ledger is stored by
small rig is unlikely
is stored by a
rig is unlikely to
stored by a network
is unlikely to mine
by a network of
unlikely to mine a
a network of miners
to mine a block
network of miners in
mine a block for
of miners in a
a block for years
miners in a data
in a data structure
a data structure caller
data structure caller the
structure caller the blockchain
revenue for proof of
for proof of work
proof of work the
of work the blockchain
work the blockchain records
the blockchain records the
blockchain records the transactions
records the transactions in
the transactions in units
miners often organize themselves
transactions in units of
often organize themselves into
in units of blocks
organize themselves into mining
themselves into mining pools
dubbed the genesis block
a pool is a
pool is a group
is a group of
is defined as part
a group of miners
defined as part of
group of miners that
as part of the
of miners that share
part of the protocol
miners that share their
that share their revenues
share their revenues when
their revenues when one
a valid block contains
revenues when one of
valid block contains the
when one of them
block contains the hash
one of them successfully
contains the hash of
of them successfully mines
the hash of the
them successfully mines a
hash of the previous
successfully mines a block
of the previous block
for each block found
the hash of the
hash of the transactions
of the transactions in
the transactions in the
the revenue is distributed
transactions in the current
revenue is distributed among
in the current block
is distributed among the
distributed among the pool
among the pool members
the pool members in
pool members in proportion
and a bitcoin address
members in proportion to
a bitcoin address which
in proportion to their
bitcoin address which is
proportion to their mining
address which is to
to their mining power
which is to be
is to be credited
to be credited with
be credited with a
credited with a reward
with a reward for
a reward for generating
reward for generating the
for generating the block
the expected revenue of
expected revenue of a
revenue of a pool
of a pool member
a pool member is
any miner may add
pool member is therefore
miner may add a
member is therefore the
may add a valid
is therefore the same
add a valid block
therefore the same as
a valid block to
the same as its
valid block to the
same as its revenue
block to the chain
as its revenue had
to the chain by
its revenue had it
revenue had it mined
had it mined solo
proving that it has
due to the large
that it has spent
to the large power
it has spent a
the large power of
has spent a certain
large power of the
spent a certain amount
power of the pool
a certain amount of
certain amount of work
amount of work and
of work and publishing
it finds blocks at
work and publishing the
finds blocks at a
and publishing the block
blocks at a much
publishing the block with
at a much higher
the block with the
a much higher rate
block with the proof
with the proof over
the proof over an
proof over an overlay
and so the frequency
over an overlay network
so the frequency of
an overlay network to
the frequency of revenue
overlay network to all
frequency of revenue collection
network to all other
of revenue collection is
to all other miners
revenue collection is higher
when a miner creates
allowing for a stable
a miner creates a
for a stable daily
miner creates a block
a stable daily or
stable daily or weekly
daily or weekly income
it is compensated for
is compensated for its
compensated for its efforts
for its efforts with
its efforts with bitcoins
most pools are controlled
pools are controlled by
are controlled by a
this compensation includes a
controlled by a centralized
compensation includes a per
by a centralized pool
a centralized pool manager
transaction fee paid by
fee paid by the
paid by the users
by the users whose
the users whose transactions
miners register with the
users whose transactions are
register with the pool
whose transactions are included
with the pool manager
the pool manager and
pool manager and mine
manager and mine on
and mine on its
mine on its behalf
and an amount of
an amount of minted
amount of minted bitcoins
of minted bitcoins that
the pool manager generates
minted bitcoins that are
pool manager generates tasks
bitcoins that are thus
manager generates tasks and
that are thus introduced
generates tasks and the
are thus introduced into
tasks and the miners
thus introduced into the
and the miners search
introduced into the system
the miners search for
miners search for solutions
search for solutions based
for solutions based on
solutions based on these
the work which a
based on these tasks
work which a miner
on these tasks that
which a miner is
these tasks that can
a miner is required
tasks that can serve
miner is required to
that can serve as
is required to do
can serve as proof
required to do is
serve as proof of
to do is to
as proof of work
do is to repeatedly
is to repeatedly calculate
to repeatedly calculate a
repeatedly calculate a a
once they find a
calculate a a hash
they find a solution
a a hash function
a hash function specifically
hash function specifically the
function specifically the sha
they send it to
send it to the
it to the pool
to the pool manager
the pool manager behaves
pool manager behaves as
manager behaves as a
behaves as a single
as a single miner
a single miner in
single miner in the
miner in the bitcoin
in the bitcoin system
once it obtains a
it obtains a legitimate
obtains a legitimate block
a legitimate block from
legitimate block from one
block from one of
from one of its
one of its miners
of a block header
to indicate that he
indicate that he has
that he has performed
the block transfers the
he has performed this
block transfers the revenue
has performed this work
transfers the revenue to
the revenue to the
revenue to the control
to the control of
the control of the
the miner provides a
control of the pool
miner provides a probabilistic
of the pool manager
provides a probabilistic proof
a probabilistic proof as
probabilistic proof as follows
the pool manager then
pool manager then distributes
the generated block has
manager then distributes the
generated block has a
then distributes the revenue
block has a nonce
distributes the revenue among
has a nonce field
the revenue among the
revenue among the miners
among the miners according
the miners according to
miners according to their
which can contain any
according to their mining
can contain any value
to their mining power
the miner places different
the architecture is illustrated
miner places different values
architecture is illustrated in
places different values in
is illustrated in figure
different values in this
values in this field
in this field and
this field and calculates
in order to estimate
field and calculates the
order to estimate the
and calculates the hash
to estimate the mining
calculates the hash for
estimate the mining power
the hash for each
the mining power of
hash for each value
mining power of a
power of a miner
if the result of
the pool manager sets
the result of the
pool manager sets a
result of the hash
manager sets a partial
of the hash is
sets a partial target
the hash is smaller
a partial target for
hash is smaller than
partial target for each
is smaller than a
target for each member
smaller than a target
than a target value
the nonce is considered
nonce is considered a
is considered a solution
and the block is
the block is valid
the number of attempts
number of attempts to
of attempts to find
than the target of
attempts to find a
the target of the
to find a single
target of the bitcoin
find a single hash
of the bitcoin system
a single hash is
single hash is therefore
hash is therefore random
is therefore random with
therefore random with a
each miner is required
random with a geometric
miner is required to
with a geometric distribution
is required to send
required to send the
to send the pool
send the pool manager
the pool manager blocks
as each attempt is
pool manager blocks that
each attempt is a
manager blocks that are
attempt is a bernoulli
blocks that are correct
is a bernoulli trial
that are correct according
a bernoulli trial with
are correct according to
bernoulli trial with a
correct according to the
trial with a success
according to the partial
with a success probability
to the partial target
a success probability determined
success probability determined by
probability determined by the
determined by the target
by the target value
the partial target is
at the existing huge
partial target is chosen
the existing huge hashing
target is chosen to
existing huge hashing rates
is chosen to be
chosen to be large
huge hashing rates and
hashing rates and small
rates and small target
and small target values
such that partial solutions
that partial solutions arrive
partial solutions arrive frequently
the time to find
solutions arrive frequently enough
time to find a
arrive frequently enough for
to find a single
frequently enough for the
find a single hash
enough for the manager
a single hash can
for the manager to
single hash can be
the manager to accurately
hash can be approximated
manager to accurately estimate
can be approximated by
to accurately estimate the
be approximated by an
accurately estimate the power
approximated by an exponential
estimate the power of
by an exponential distribution
the power of the
power of the miner
the average time for
average time for a
time for a miner
for a miner to
a miner to find
miner to find a
to find a solution
find a solution is
a solution is therefore
to reduce management overhead
solution is therefore proportional
is therefore proportional to
therefore proportional to its
proportional to its hashing
to its hashing rate
as the value of
its hashing rate or
the value of bitcoin
hashing rate or mining
value of bitcoin rose
rate or mining power
bitcoin mining has become
mining has become a
to maintain a constant
has become a rapidly
maintain a constant rate
become a rapidly advancing
a constant rate of
a rapidly advancing industry
constant rate of bitcoin
rate of bitcoin generation
technological advancements lead to
advancements lead to ever
and as part of
lead to ever more
as part of its
to ever more efficient
part of its defense
ever more efficient hashing
of its defense against
more efficient hashing asics
its defense against denial
defense against denial of
against denial of service
denial of service and
of service and other
service and other attacks
the system normalizes the
system normalizes the rate
normalizes the rate of
the rate of block
rate of block generation
this is a simplification
the protocol deterministically defines
is a simplification that
protocol deterministically defines the
a simplification that is
deterministically defines the target
simplification that is sufficient
defines the target value
that is sufficient for
the target value for
is sufficient for our
target value for each
sufficient for our analysis
value for each block
for each block according
each block according to
block according to the
the intricacies of reward
according to the time
intricacies of reward systems
to the time required
of reward systems are
the time required to
reward systems are explained
time required to generate
systems are explained in
required to generate recent
to generate recent blocks
is updated once every
a notable exception is
notable exception is p
blocks such that the
such that the average
that the average time
the average time for
average time for each
time for each block
for each block to
each block to be
block to be found
to be found is
which we discuss in
we discuss in section
discuss in section ix
forks block propagation in
note that the exponential
block propagation in the
that the exponential distribution
propagation in the overlay
the exponential distribution is
in the overlay network
exponential distribution is memoryless
the overlay network takes
overlay network takes seconds
if all miners mine
all miners mine for
therefore it is possible
miners mine for block
it is possible for
mine for block number
is possible for two
for block number b
possible for two distant
for two distant miners
two distant miners to
distant miners to generate
miners to generate competing
once the block is
to generate competing blocks
the block is found
block is found at
is found at time
found at time t
both of which name
of which name the
which name the same
all miners switch to
name the same block
miners switch to mine
the same block as
switch to mine for
same block as their
to mine for the
block as their predecessor
mine for the subsequent
for the subsequent block
the subsequent block b
are rare since the
at t without changing
rare since the average
t without changing their
since the average mining
without changing their probability
the average mining interval
changing their probability distribution
average mining interval is
their probability distribution of
probability distribution of finding
distribution of finding a
of finding a block
finding a block after
a block after t
and they occur on
they occur on average
occur on average once
on average once every
the probability that a
probability that a miner
that a miner i
a miner i with
miner i with mining
i with mining power
with mining power mi
mining power mi finds
power mi finds the
mi finds the next
finds the next block
the next block is
next block is its
block is its ratio
is its ratio out
its ratio out of
ratio out of the
out of the total
the system has a
of the total mining
system has a mechanism
the total mining power
has a mechanism to
total mining power m
a mechanism to solve
mining power m in
mechanism to solve forks
power m in the
to solve forks when
m in the system
solve forks when they
forks when they do
when they do occur
causing one of the
one of the blocks
of the blocks to
miner miner miner pool
the blocks to be
blocks to be discarded
miner miner miner pool
we ignore bifurcations for
ignore bifurcations for the
bifurcations for the sake
for the sake of
the sake of simplicity
since the choice of
the choice of the
choice of the discarded
of the discarded block
the discarded block on
discarded block on bifurcation
block on bifurcation is
on bifurcation is random
one may incorporate this
may incorporate this event
incorporate this event into
this event into the
event into the probability
into the probability of
the probability of finding
probability of finding a
of finding a block
and consider instead the
consider instead the probability
instead the probability of
the probability of finding
probability of finding a
of finding a block
finding a block that
a block that is
block that is not
that is not discarded
pools often charge a
often charge a small
charge a small percentage
a small percentage of
small percentage of the
percentage of the revenue
of the revenue as
and one miner mines
the revenue as fee
one miner mines solo
we discuss in section
discuss in section ix
in section ix the
section ix the implications
ix the implications of
pools datacenters are built
the implications of such
datacenters are built around
implications of such fees
are built around the
of such fees to
built around the world
such fees to our
fees to our analysis
many pools are open
pools are open and
are open and accept
open and accept any
and accept any interested
accept any interested miner
a pool interface is
pool interface is typically
interface is typically comprised
mining is only profitable
is typically comprised of
is only profitable using
typically comprised of a
only profitable using dedicated
comprised of a web
profitable using dedicated hardware
of a web interface
using dedicated hardware in
a web interface for
dedicated hardware in cutting
web interface for registration
hardware in cutting edge
interface for registration and
in cutting edge mining
for registration and a
cutting edge mining rigs
registration and a miner
and a miner interface
a miner interface for
miner interface for the
interface for the mining
otherwise the energy costs
for the mining software
the energy costs exceed
energy costs exceed the
costs exceed the expected
exceed the expected revenue
in order to mine
order to mine for
to mine for a
mine for a pool
although expected revenue from
expected revenue from mining
revenue from mining is
from mining is proportional
a miner registers with
mining is proportional to
miner registers with the
is proportional to the
registers with the web
proportional to the power
with the web interface
to the power of
the power of the
power of the mining
of the mining rigs
the mining rigs used
supplies a bitcoin address
a bitcoin address to
bitcoin address to receive
address to receive its
to receive its future
a single home miner
receive its future shares
single home miner using
its future shares of
home miner using a
future shares of the
miner using a small
shares of the revenue
using a small rig
a small rig is
small rig is unlikely
rig is unlikely to
is unlikely to mine
and receives from the
unlikely to mine a
receives from the pool
to mine a block
from the pool credentials
mine a block for
the pool credentials for
a block for years
pool credentials for mining
then he feeds his
he feeds his credentials
feeds his credentials and
his credentials and the
credentials and the pool
and the pool s
the pool s address
pool s address to
s address to its
address to its mining
to its mining rig
miners often organize themselves
the mining rig obtains
often organize themselves into
mining rig obtains its
organize themselves into mining
rig obtains its tasks
themselves into mining pools
obtains its tasks from
its tasks from the
tasks from the pool
from the pool and
the pool and sends
pool and sends partial
and sends partial and
sends partial and full
partial and full proof
and full proof of
a pool is a
full proof of work
pool is a group
is a group of
a group of miners
group of miners that
typically with the stratum
of miners that share
with the stratum protocol
miners that share their
that share their revenues
share their revenues when
their revenues when one
revenues when one of
when one of them
one of them successfully
of them successfully mines
them successfully mines a
successfully mines a block
for each block found
as it finds blocks
the revenue is distributed
revenue is distributed among
is distributed among the
distributed among the pool
the pool manager credits
among the pool members
pool manager credits the
the pool members in
manager credits the miner
pool members in proportion
credits the miner s
members in proportion to
the miner s account
in proportion to their
miner s account according
proportion to their mining
s account according to
to their mining power
account according to its
according to its share
to its share of
its share of the
share of the work
and transfers these funds
the expected revenue of
transfers these funds either
expected revenue of a
these funds either on
revenue of a pool
funds either on request
of a pool member
either on request or
a pool member is
on request or automatically
pool member is therefore
request or automatically to
member is therefore the
or automatically to the
is therefore the same
automatically to the aforementioned
therefore the same as
to the aforementioned bitcoin
the same as its
the aforementioned bitcoin address
same as its revenue
as its revenue had
its revenue had it
revenue had it mined
had it mined solo
too big pools despite
big pools despite their
pools despite their important
despite their important role
their important role of
important role of enabling
role of enabling small
due to the large
to the large power
the large power of
large power of the
power of the pool
pools can constitute a
can constitute a threat
it finds blocks at
constitute a threat to
finds blocks at a
a threat to the
blocks at a much
threat to the bitcoin
at a much higher
to the bitcoin system
a much higher rate
the bitcoin system if
bitcoin system if their
system if their size
if their size is
their size is too
and so the frequency
size is too large
so the frequency of
the frequency of revenue
frequency of revenue collection
of revenue collection is
revenue collection is higher
if one pool controls
one pool controls the
pool controls the majority
controls the majority of
the majority of mining
allowing for a stable
majority of mining power
for a stable daily
a stable daily or
stable daily or weekly
daily or weekly income
the system becomes unstable
most pools are controlled
pools are controlled by
are controlled by a
controlled by a centralized
by a centralized pool
a centralized pool manager
miners register with the
register with the pool
with the pool manager
the pool manager and
pool manager and mine
manager and mine on
and mine on its
mine on its behalf
the pool manager generates
pool manager generates tasks
manager generates tasks and
generates tasks and the
tasks and the miners
and the miners search
the miners search for
miners search for solutions
search for solutions based
for solutions based on
solutions based on these
based on these tasks
on these tasks that
these tasks that can
tasks that can serve
warns that the system
that can serve as
that the system is
can serve as proof
the system is unstable
serve as proof of
system is unstable with
as proof of work
is unstable with even
unstable with even smaller
with even smaller pools
once they find a
they find a solution
they send it to
send it to the
it to the pool
to the pool manager
in realistic scenarios of
realistic scenarios of the
scenarios of the bitcoin
of the bitcoin system
the pool manager behaves
the bitcoin system no
pool manager behaves as
bitcoin system no pool
manager behaves as a
system no pool controls
behaves as a single
no pool controls a
as a single miner
pool controls a majority
a single miner in
controls a majority of
single miner in the
a majority of the
miner in the bitcoin
majority of the mining
in the bitcoin system
of the mining power
once it obtains a
it obtains a legitimate
obtains a legitimate block
a legitimate block from
for one day in
legitimate block from one
one day in june
block from one of
from one of its
one of its miners
the block transfers the
block transfers the revenue
transfers the revenue to
a single pool called
the revenue to the
single pool called ghash
revenue to the control
to the control of
the control of the
control of the pool
of the pool manager
the pool manager then
pool manager then distributes
manager then distributes the
then distributes the revenue
of the blocks in
distributes the revenue among
the blocks in the
the revenue among the
blocks in the bitcoin
revenue among the miners
in the bitcoin main
among the miners according
the bitcoin main chain
the miners according to
miners according to their
according to their mining
to their mining power
the bitcoin community backlashed
bitcoin community backlashed at
community backlashed at the
backlashed at the pool
the architecture is illustrated
architecture is illustrated in
is illustrated in figure
which has done nothing
has done nothing worse
in order to estimate
order to estimate the
to estimate the mining
estimate the mining power
the mining power of
mining power of a
power of a miner
the pool manager sets
pool manager sets a
manager sets a partial
sets a partial target
a partial target for
partial target for each
target for each member
done nothing worse than
nothing worse than being
worse than being extremely
than being extremely successful
io reduced its relative
than the target of
reduced its relative mining
the target of the
its relative mining power
target of the bitcoin
relative mining power and
of the bitcoin system
mining power and publicly
power and publicly committed
and publicly committed to
publicly committed to stay
committed to stay away
each miner is required
to stay away from
miner is required to
stay away from the
is required to send
required to send the
to send the pool
send the pool manager
the pool manager blocks
pool manager blocks that
manager blocks that are
blocks that are correct
that are correct according
are correct according to
correct according to the
according to the partial
to the partial target
the partial target is
partial target is chosen
block withholding and its
target is chosen to
withholding and its detection
is chosen to be
and its detection classical
chosen to be large
its detection classical block
detection classical block withholding
such that partial solutions
that partial solutions arrive
partial solutions arrive frequently
solutions arrive frequently enough
arrive frequently enough for
frequently enough for the
enough for the manager
for the manager to
the manager to accurately
manager to accurately estimate
to accurately estimate the
is an attack performed
accurately estimate the power
an attack performed by
estimate the power of
attack performed by a
the power of the
performed by a pool
power of the miner
by a pool member
a pool member against
pool member against the
member against the other
against the other pool
the other pool members
the attacking miner registers
attacking miner registers with
to reduce management overhead
miner registers with the
registers with the pool
with the pool and
the pool and apparently
as the value of
pool and apparently starts
the value of bitcoin
and apparently starts mining
value of bitcoin rose
apparently starts mining honestly
starts mining honestly it
mining honestly it regularly
honestly it regularly sends
it regularly sends the
bitcoin mining has become
regularly sends the pool
mining has become a
sends the pool partial
has become a rapidly
the pool partial proof
become a rapidly advancing
pool partial proof of
a rapidly advancing industry
partial proof of work
technological advancements lead to
advancements lead to ever
lead to ever more
to ever more efficient
ever more efficient hashing
the attacking miner sends
more efficient hashing asics
attacking miner sends only
miner sends only partial
sends only partial proof
only partial proof of
partial proof of work
if it finds a
it finds a full
finds a full solution
a full solution that
full solution that constitutes
solution that constitutes a
that constitutes a full
constitutes a full proof
a full proof of
full proof of work
proof of work it
of work it discards
work it discards the
it discards the solution
this is a simplification
is a simplification that
a simplification that is
reducing the pool s
simplification that is sufficient
the pool s total
that is sufficient for
pool s total revenue
is sufficient for our
sufficient for our analysis
the intricacies of reward
intricacies of reward systems
this attack is illustrated
of reward systems are
attack is illustrated in
reward systems are explained
is illustrated in figure
systems are explained in
the attacker does not
attacker does not change
does not change the
not change the pool
change the pool s
the pool s effective
pool s effective mining
s effective mining power
and does not affect
does not affect directly
not affect directly the
affect directly the revenue
a notable exception is
directly the revenue of
notable exception is p
the revenue of other
revenue of other pools
the attacked pool shares
attacked pool shares its
pool shares its revenue
shares its revenue with
its revenue with the
revenue with the attacker
therefore each miner earns
each miner earns less
as the same revenue
the same revenue is
same revenue is distributed
which we discuss in
revenue is distributed among
we discuss in section
is distributed among more
discuss in section ix
distributed among more miners
forks block propagation in
recall that the proof
block propagation in the
that the proof of
propagation in the overlay
the proof of work
in the overlay network
proof of work is
the overlay network takes
of work is only
overlay network takes seconds
work is only valid
is only valid for
only valid for a
valid for a specific
for a specific block
therefore it is possible
it is possible for
is possible for two
possible for two distant
as it is the
for two distant miners
it is the nonce
two distant miners to
is the nonce with
distant miners to generate
the nonce with which
miners to generate competing
nonce with which the
to generate competing blocks
with which the block
which the block s
the block s hash
block s hash is
s hash is smaller
both of which name
hash is smaller than
of which name the
is smaller than its
which name the same
smaller than its target
name the same block
the same block as
same block as their
block as their predecessor
the attacking miner cannot
attacking miner cannot use
miner cannot use it
although the term block
the term block withholding
are rare since the
term block withholding has
rare since the average
block withholding has become
since the average mining
withholding has become canonical
the average mining interval
average mining interval is
note that the block
that the block is
the block is discarded
block is discarded and
is discarded and never
discarded and never introduced
and never introduced into
never introduced into the
introduced into the system
and they occur on
into the system as
they occur on average
the system as the
occur on average once
system as the name
on average once every
as the name block
the name block withholding
name block withholding implies
miners miners miners pool
classical block withholding attack
a group of miners
the system has a
group of miners attack
system has a mechanism
of miners attack pool
has a mechanism to
a mechanism to solve
mechanism to solve forks
to solve forks when
solve forks when they
with a block withholding
forks when they do
a block withholding attack
when they do occur
denoted by a dashed
causing one of the
by a dashed red
one of the blocks
a dashed red arrow
of the blocks to
the blocks to be
blocks to be discarded
we ignore bifurcations for
ignore bifurcations for the
this attack reduces the
bifurcations for the sake
attack reduces the attacker
for the sake of
reduces the attacker s
the sake of simplicity
the attacker s revenue
attacker s revenue compared
s revenue compared to
revenue compared to solo
compared to solo mining
since the choice of
to solo mining or
the choice of the
solo mining or honest
choice of the discarded
mining or honest pool
of the discarded block
or honest pool participation
the discarded block on
discarded block on bifurcation
block on bifurcation is
on bifurcation is random
it suffers from the
suffers from the reduced
from the reduced revenue
the reduced revenue like
one may incorporate this
reduced revenue like the
may incorporate this event
revenue like the other
incorporate this event into
like the other pool
this event into the
the other pool participants
event into the probability
into the probability of
the probability of finding
probability of finding a
of finding a block
and its revenue is
its revenue is less
revenue is less than
is less than its
and consider instead the
less than its share
consider instead the probability
than its share of
instead the probability of
its share of the
the probability of finding
share of the total
probability of finding a
of the total mining
of finding a block
the total mining power
finding a block that
total mining power in
a block that is
mining power in the
block that is not
power in the system
that is not discarded
the classical block withholding
classical block withholding attack
pools often charge a
block withholding attack can
often charge a small
withholding attack can therefore
charge a small percentage
attack can therefore only
a small percentage of
can therefore only be
small percentage of the
therefore only be used
percentage of the revenue
only be used for
of the revenue as
be used for sabotage
the revenue as fee
we discuss in section
discuss in section ix
at a cost to
in section ix the
a cost to the
section ix the implications
cost to the attacker
ix the implications of
the implications of such
implications of such fees
of such fees to
such fees to our
fees to our analysis
even if a pool
if a pool detects
many pools are open
a pool detects that
pools are open and
pool detects that it
are open and accept
detects that it is
open and accept any
that it is under
and accept any interested
it is under a
accept any interested miner
is under a block
under a block withholding
a block withholding attack
a pool interface is
pool interface is typically
it might not be
interface is typically comprised
might not be able
is typically comprised of
not be able to
typically comprised of a
be able to detect
comprised of a web
able to detect which
of a web interface
to detect which of
a web interface for
detect which of its
web interface for registration
which of its registered
interface for registration and
of its registered miners
for registration and a
its registered miners are
registration and a miner
registered miners are the
and a miner interface
miners are the perpetrators
a miner interface for
miner interface for the
interface for the mining
for the mining software
a pool can estimate
pool can estimate its
in order to mine
can estimate its expected
order to mine for
estimate its expected mining
to mine for a
its expected mining power
mine for a pool
expected mining power and
mining power and its
power and its actual
and its actual mining
a miner registers with
its actual mining power
miner registers with the
actual mining power by
registers with the web
mining power by the
with the web interface
power by the rates
by the rates of
the rates of partial
rates of partial proofs
supplies a bitcoin address
of partial proofs of
a bitcoin address to
partial proofs of work
bitcoin address to receive
proofs of work and
address to receive its
of work and full
to receive its future
work and full proofs
receive its future shares
and full proofs of
its future shares of
full proofs of work
future shares of the
shares of the revenue
and receives from the
receives from the pool
from the pool credentials
the pool credentials for
supplied by its miners
pool credentials for mining
a difference above a
then he feeds his
difference above a set
he feeds his credentials
above a set confidence
feeds his credentials and
a set confidence interval
his credentials and the
set confidence interval indicates
credentials and the pool
confidence interval indicates an
and the pool s
interval indicates an attack
the pool s address
pool s address to
s address to its
address to its mining
to its mining rig
to detect whether a
detect whether a single
whether a single miner
a single miner is
single miner is attacking
miner is attacking it
the mining rig obtains
the pool must use
mining rig obtains its
pool must use a
rig obtains its tasks
must use a similar
obtains its tasks from
use a similar technique
its tasks from the
tasks from the pool
from the pool and
the pool and sends
pool and sends partial
comparing the estimated mining
and sends partial and
the estimated mining power
sends partial and full
estimated mining power of
partial and full proof
mining power of the
and full proof of
power of the attacker
full proof of work
of the attacker based
the attacker based on
attacker based on its
based on its partial
on its partial proof
typically with the stratum
its partial proof of
with the stratum protocol
partial proof of work
proof of work with
of work with the
work with the fact
with the fact it
the fact it never
fact it never supplies
it never supplies a
never supplies a full
supplies a full proof
a full proof of
full proof of work
if the attacker has
the attacker has a
attacker has a small
has a small mining
a small mining power
as it finds blocks
it will send frequent
will send frequent partial
send frequent partial proofs
frequent partial proofs of
partial proofs of work
the pool manager credits
pool manager credits the
manager credits the miner
credits the miner s
but the pool will
the miner s account
the pool will only
miner s account according
pool will only expect
s account according to
will only expect to
account according to its
only expect to see
according to its share
expect to see a
to its share of
to see a full
its share of the
see a full proof
share of the work
a full proof of
full proof of work
proof of work at
of work at very
work at very low
and transfers these funds
at very low frequency
transfers these funds either
these funds either on
funds either on request
either on request or
on request or automatically
request or automatically to
or automatically to the
automatically to the aforementioned
to the aforementioned bitcoin
it cannot obtain statistically
the aforementioned bitcoin address
cannot obtain statistically significant
obtain statistically significant results
statistically significant results that
significant results that would
results that would indicate
too big pools despite
that would indicate an
big pools despite their
would indicate an attack
pools despite their important
despite their important role
their important role of
important role of enabling
role of enabling small
an attacker can use
attacker can use multiple
can use multiple small
use multiple small block
multiple small block withholding
small block withholding miners
block withholding miners and
withholding miners and replace
pools can constitute a
miners and replace them
can constitute a threat
and replace them frequently
constitute a threat to
a threat to the
threat to the bitcoin
to the bitcoin system
the bitcoin system if
a small miner is
bitcoin system if their
system if their size
if their size is
their size is too
size is too large
a miner whose expected
if one pool controls
miner whose expected full
one pool controls the
whose expected full proof
pool controls the majority
expected full proof of
controls the majority of
full proof of work
the majority of mining
proof of work frequency
majority of mining power
of work frequency is
work frequency is yearly
the system becomes unstable
such a miner will
a miner will see
miner will see a
will see a non
negligible average daily revenue
if the attacker replaces
the attacker replaces such
attacker replaces such a
warns that the system
replaces such a small
that the system is
such a small miner
the system is unstable
a small miner every
system is unstable with
small miner every month
is unstable with even
unstable with even smaller
with even smaller pools
he will collect about
will collect about b
at the end of
the end of each
end of each month
in realistic scenarios of
the pool must decide
realistic scenarios of the
pool must decide within
scenarios of the bitcoin
must decide within this
of the bitcoin system
decide within this month
the bitcoin system no
within this month whether
bitcoin system no pool
this month whether the
system no pool controls
month whether the miner
no pool controls a
whether the miner is
pool controls a majority
the miner is an
controls a majority of
miner is an attacker
a majority of the
majority of the mining
of the mining power
and revoke its earnings
for one day in
one day in june
or just an unlucky
just an unlucky honest
an unlucky honest miner
since an honest miner
an honest miner of
honest miner of this
miner of this power
of this power is
this power is unlikely
power is unlikely to
is unlikely to find
unlikely to find a
a single pool called
to find a full
single pool called ghash
find a full proof
a full proof of
full proof of work
proof of work within
of work within a
work within a month
of the blocks in
according to the exponential
the blocks in the
to the exponential distribution
blocks in the bitcoin
in the bitcoin main
the bitcoin main chain
a pool that rejects
pool that rejects miners
that rejects miners based
the bitcoin community backlashed
rejects miners based on
bitcoin community backlashed at
miners based on this
community backlashed at the
based on this criterion
backlashed at the pool
on this criterion would
this criterion would reject
criterion would reject the
would reject the majority
reject the majority of
which has done nothing
the majority of its
has done nothing worse
majority of its honest
done nothing worse than
of its honest miners
nothing worse than being
worse than being extremely
than being extremely successful
the alternative of rejecting
alternative of rejecting small
of rejecting small miners
rejecting small miners in
small miners in general
miners in general or
in general or distributing
general or distributing revenue
io reduced its relative
or distributing revenue on
reduced its relative mining
distributing revenue on a
its relative mining power
revenue on a yearly
relative mining power and
on a yearly basis
mining power and publicly
a yearly basis contradicts
power and publicly committed
yearly basis contradicts the
and publicly committed to
basis contradicts the goal
publicly committed to stay
contradicts the goal of
committed to stay away
the goal of pooled
to stay away from
goal of pooled mining
stay away from the
m odel and s
odel and s tandard
and s tandard o
s tandard o peration
tandard o peration we
o peration we specify
peration we specify the
we specify the basic
specify the basic model
the basic model in
basic model in which
block withholding and its
model in which participants
withholding and its detection
in which participants operate
and its detection classical
which participants operate in
its detection classical block
participants operate in section
detection classical block withholding
operate in section iii
proceed to describe how
to describe how honest
describe how honest miners
how honest miners operate
honest miners operate in
miners operate in this
operate in this environment
is an attack performed
in this environment in
an attack performed by
this environment in sections
attack performed by a
environment in sections iii
performed by a pool
by a pool member
a pool member against
pool member against the
member against the other
against the other pool
the other pool members
the attacking miner registers
and how the classical
attacking miner registers with
how the classical block
miner registers with the
the classical block withholding
registers with the pool
classical block withholding attack
with the pool and
block withholding attack is
the pool and apparently
withholding attack is implemented
pool and apparently starts
attack is implemented with
and apparently starts mining
is implemented with our
apparently starts mining honestly
implemented with our model
starts mining honestly it
with our model in
mining honestly it regularly
our model in section
honestly it regularly sends
model in section iii
it regularly sends the
regularly sends the pool
sends the pool partial
the pool partial proof
pool partial proof of
partial proof of work
model the system is
the system is comprised
the attacking miner sends
system is comprised of
attacking miner sends only
is comprised of the
miner sends only partial
comprised of the bitcoin
sends only partial proof
of the bitcoin network
only partial proof of
the bitcoin network and
partial proof of work
bitcoin network and nodes
network and nodes with
and nodes with unique
nodes with unique ids
if it finds a
it finds a full
finds a full solution
and progresses in steps
a full solution that
full solution that constitutes
solution that constitutes a
that constitutes a full
a node i generates
constitutes a full proof
node i generates tasks
a full proof of
i generates tasks which
full proof of work
generates tasks which are
proof of work it
tasks which are associated
of work it discards
which are associated with
work it discards the
are associated with its
it discards the solution
associated with its id
with its id i
reducing the pool s
the pool s total
pool s total revenue
a node can work
node can work on
can work on a
work on a task
on a task for
a task for the
task for the duration
for the duration of
this attack is illustrated
the duration of a
attack is illustrated in
duration of a step
is illustrated in figure
the result of this
result of this work
of this work is
this work is a
work is a set
the attacker does not
is a set of
attacker does not change
a set of partial
does not change the
set of partial proofs
not change the pool
of partial proofs of
change the pool s
partial proofs of work
the pool s effective
proofs of work and
pool s effective mining
of work and a
s effective mining power
work and a set
and a set of
a set of full
set of full proofs
of full proofs of
and does not affect
full proofs of work
does not affect directly
not affect directly the
affect directly the revenue
directly the revenue of
the revenue of other
the number of proofs
revenue of other pools
number of proofs in
of proofs in each
proofs in each set
in each set has
each set has a
set has a poisson
has a poisson distribution
the attacked pool shares
attacked pool shares its
partial proofs with a
pool shares its revenue
proofs with a large
shares its revenue with
with a large mean
its revenue with the
a large mean and
revenue with the attacker
large mean and full
mean and full proofs
and full proofs with
full proofs with a
proofs with a small
therefore each miner earns
with a small mean
each miner earns less
nodes that work on
that work on tasks
as the same revenue
work on tasks are
the same revenue is
on tasks are called
same revenue is distributed
tasks are called a
revenue is distributed among
are called a miners
is distributed among more
distributed among more miners
miners have identical power
recall that the proof
that the proof of
the proof of work
and hence identical probabilities
proof of work is
hence identical probabilities to
of work is only
identical probabilities to generate
work is only valid
probabilities to generate proofs
is only valid for
to generate proofs of
only valid for a
generate proofs of work
valid for a specific
for a specific block
the bitcoin network pays
bitcoin network pays for
network pays for full
as it is the
pays for full proofs
it is the nonce
for full proofs of
is the nonce with
full proofs of work
the nonce with which
nonce with which the
with which the block
which the block s
the block s hash
to acquire this payoff
block s hash is
acquire this payoff an
s hash is smaller
this payoff an entity
hash is smaller than
payoff an entity publishes
is smaller than its
an entity publishes a
smaller than its target
entity publishes a task
publishes a task task
a task task and
task task and its
task and its corresponding
the attacking miner cannot
and its corresponding proof
attacking miner cannot use
its corresponding proof of
miner cannot use it
corresponding proof of work
proof of work to
of work to the
work to the network
the payoff goes to
although the term block
payoff goes to the
the term block withholding
goes to the id
term block withholding has
to the id associated
block withholding has become
the id associated with
withholding has become canonical
id associated with task
note that the block
the bitcoin protocol normalizes
that the block is
bitcoin protocol normalizes revenue
the block is discarded
protocol normalizes revenue such
block is discarded and
normalizes revenue such that
is discarded and never
revenue such that the
discarded and never introduced
such that the average
and never introduced into
that the average total
never introduced into the
the average total revenue
introduced into the system
average total revenue distributed
into the system as
total revenue distributed in
the system as the
revenue distributed in each
system as the name
distributed in each step
as the name block
in each step is
the name block withholding
each step is a
name block withholding implies
step is a constant
is a constant throughout
a constant throughout the
constant throughout the execution
throughout the execution of
the execution of the
execution of the system
miners miners miners pool
any node can transact
node can transact bitcoins
can transact bitcoins to
transact bitcoins to another
bitcoins to another node
to another node by
another node by issuing
node by issuing a
by issuing a bitcoin
issuing a bitcoin transaction
classical block withholding attack
nodes that generate tasks
that generate tasks but
a group of miners
generate tasks but outsource
group of miners attack
tasks but outsource the
of miners attack pool
but outsource the work
outsource the work are
the work are called
work are called pools
with a block withholding
a block withholding attack
pools send tasks to
send tasks to miners
tasks to miners over
to miners over the
denoted by a dashed
miners over the network
by a dashed red
a dashed red arrow
the miners receive the
miners receive the tasks
this attack reduces the
attack reduces the attacker
reduces the attacker s
and send the partial
the attacker s revenue
send the partial and
attacker s revenue compared
the partial and full
s revenue compared to
partial and full proofs
revenue compared to solo
and full proofs of
compared to solo mining
full proofs of work
to solo mining or
proofs of work to
solo mining or honest
of work to the
mining or honest pool
work to the pool
or honest pool participation
apart from working on
from working on tasks
it suffers from the
suffers from the reduced
from the reduced revenue
the reduced revenue like
reduced revenue like the
revenue like the other
like the other pool
the other pool participants
and its revenue is
its revenue is less
revenue is less than
is less than its
less than its share
than its share of
its share of the
and receipt are instantaneous
share of the total
of the total mining
the total mining power
total mining power in
mining power in the
we assume that the
power in the system
assume that the number
that the number of
the number of miners
number of miners is
this attack can therefore
of miners is large
attack can therefore only
miners is large enough
can therefore only be
therefore only be used
is large enough such
only be used for
large enough such that
be used for sabotage
enough such that mining
such that mining power
that mining power can
mining power can be
power can be split
at a cost to
can be split arbitrarily
a cost to the
be split arbitrarily without
cost to the attacker
split arbitrarily without resolution
arbitrarily without resolution constraints
even if a pool
denote the number of
if a pool detects
the number of pools
a pool detects that
number of pools with
pool detects that it
of pools with p
detects that it is
that it is under
it is under a
is under a block
under a block withholding
the total number of
a block withholding attack
total number of mining
number of mining power
of mining power in
mining power in the
power in the system
it might not be
in the system with
might not be able
the system with m
not be able to
system with m and
be able to detect
with m and the
able to detect which
m and the miners
to detect which of
and the miners participating
detect which of its
the miners participating in
which of its registered
miners participating in pool
of its registered miners
participating in pool i
its registered miners are
registered miners are the
miners are the perpetrators
a pool can estimate
pool can estimate its
can estimate its expected
estimate its expected mining
its expected mining power
expected mining power and
we use a quasistatic
mining power and its
use a quasistatic analysis
power and its actual
a quasistatic analysis where
and its actual mining
quasistatic analysis where miner
its actual mining power
analysis where miner participation
actual mining power by
where miner participation in
mining power by the
miner participation in a
power by the rates
participation in a pool
by the rates of
in a pool does
the rates of partial
a pool does not
rates of partial proofs
pool does not change
of partial proofs of
does not change over
partial proofs of work
not change over time
proofs of work and
of work and full
work and full proofs
and full proofs of
full proofs of work
solo mining a solo
mining a solo miner
a solo miner is
solo miner is a
miner is a node
supplied by its miners
is a node that
a node that generates
node that generates its
that generates its own
generates its own tasks
a difference above a
difference above a set
above a set confidence
a set confidence interval
in every step it
set confidence interval indicates
every step it generates
confidence interval indicates an
step it generates a
interval indicates an attack
it generates a task
to detect whether a
works on it for
detect whether a single
on it for the
whether a single miner
it for the duration
a single miner is
for the duration of
the duration of the
single miner is attacking
duration of the step
miner is attacking it
of the step and
the step and if
step and if it
and if it finds
if it finds a
the pool must use
it finds a full
pool must use a
finds a full proof
must use a similar
a full proof of
use a similar technique
full proof of work
it publishes this proof
comparing the estimated mining
publishes this proof of
the estimated mining power
this proof of work
estimated mining power of
proof of work to
mining power of the
of work to earn
power of the attacker
work to earn the
of the attacker based
to earn the payoff
the attacker based on
attacker based on its
based on its partial
on its partial proof
its partial proof of
partial proof of work
proof of work with
pools a pool is
of work with the
a pool is a
work with the fact
pool is a node
with the fact it
is a node that
the fact it never
a node that serves
fact it never supplies
node that serves as
it never supplies a
that serves as a
never supplies a full
serves as a coordinator
supplies a full proof
as a coordinator and
a full proof of
a coordinator and multiple
full proof of work
coordinator and multiple miners
and multiple miners can
multiple miners can register
miners can register to
can register to a
register to a pool
to a pool and
if the attacker has
a pool and work
the attacker has a
pool and work for
attacker has a small
and work for it
has a small mining
a small mining power
in every step it
every step it generates
it will send frequent
step it generates a
will send frequent partial
it generates a task
send frequent partial proofs
generates a task for
frequent partial proofs of
a task for each
partial proofs of work
task for each registered
for each registered miner
each registered miner and
registered miner and sends
miner and sends it
and sends it over
but the pool will
sends it over the
the pool will only
it over the network
pool will only expect
will only expect to
only expect to see
expect to see a
each miner receives its
to see a full
miner receives its task
see a full proof
receives its task and
a full proof of
its task and works
full proof of work
task and works on
proof of work at
and works on it
of work at very
works on it for
work at very low
on it for the
at very low frequency
it for the duration
for the duration of
the duration of the
duration of the step
at the end of
the end of the
end of the step
it cannot obtain statistically
cannot obtain statistically significant
obtain statistically significant results
statistically significant results that
the miner sends the
significant results that would
miner sends the pool
results that would indicate
sends the pool the
that would indicate an
the pool the full
would indicate an attack
pool the full and
the full and the
full and the partial
and the partial proofs
the partial proofs of
an attacker can use
partial proofs of work
attacker can use multiple
proofs of work it
can use multiple small
of work it has
use multiple small block
work it has found
multiple small block withholding
small block withholding miners
block withholding miners and
withholding miners and replace
the pool receives the
miners and replace them
pool receives the proofs
and replace them frequently
receives the proofs of
the proofs of work
proofs of work of
of work of all
work of all its
a small miner is
of all its miners
registers the partial proofs
the partial proofs of
partial proofs of work
proofs of work and
a miners whose expected
of work and publishes
miners whose expected full
work and publishes the
whose expected full proof
and publishes the full
expected full proof of
publishes the full proofs
full proof of work
proof of work frequency
of work frequency is
work frequency is yearly
it calculates its overall
calculates its overall revenue
such a miner will
a miner will see
and proceeds to distribute
miner will see a
proceeds to distribute it
will see a non
to distribute it among
distribute it among its
it among its miners
negligible average daily revenue
each miner receives revenue
miner receives revenue proportional
receives revenue proportional to
revenue proportional to its
proportional to its success
to its success in
its success in the
success in the current
in the current step
namely the ratio of
the ratio of its
ratio of its partial
of its partial proofs
its partial proofs of
partial proofs of work
proofs of work out
of work out of
work out of all
out of all partial
of all partial proofs
all partial proofs of
partial proofs of work
proofs of work the
of work the pool
work the pool received
we assume that pools
assume that pools do
that pools do not
pools do not collect
do not collect fees
not collect fees of
collect fees of the
fees of the revenue
pool fees and their
fees and their implications
and their implications on
their implications on our
implications on our analysis
if the attacker replaces
on our analysis are
the attacker replaces such
our analysis are discussed
attacker replaces such a
analysis are discussed in
replaces such a small
are discussed in section
such a small miner
discussed in section ix
a small miner every
small miner every month
he will collect about
will collect about b
block withholding miner a
withholding miner a miner
miner a miner registered
at the end of
a miner registered at
the end of each
miner registered at a
end of each month
registered at a pool
at a pool can
a pool can perform
pool can perform the
can perform the classical
the pool must decide
perform the classical block
pool must decide within
the classical block withholding
must decide within this
classical block withholding attack
decide within this month
within this month whether
this month whether the
month whether the miner
whether the miner is
an attacker miner operates
the miner is an
attacker miner operates as
miner is an attacker
miner operates as if
operates as if it
as if it worked
if it worked for
it worked for the
worked for the pool
and revoke its earnings
it receives its tasks
receives its tasks and
its tasks and works
tasks and works on
and works on them
or just an unlucky
just an unlucky honest
an unlucky honest miner
only at the end
at the end of
the end of each
end of each round
since an honest miner
of each round it
an honest miner of
each round it sends
honest miner of this
round it sends only
miner of this power
it sends only its
of this power is
sends only its partial
this power is unlikely
only its partial proofs
power is unlikely to
its partial proofs of
partial proofs of work
is unlikely to find
unlikely to find a
to find a full
find a full proof
a full proof of
and omits full proofs
full proof of work
omits full proofs of
proof of work within
full proofs of work
of work within a
proofs of work if
work within a month
of work if it
work if it had
if it had found
it had found any
the pool registers the
pool registers the miner
registers the miner s
the miner s partial
miner s partial proofs
according to the exponential
to the exponential distribution
but cannot distinguish between
cannot distinguish between miners
a pool that rejects
distinguish between miners running
pool that rejects miners
between miners running honestly
that rejects miners based
miners running honestly and
rejects miners based on
running honestly and block
miners based on this
honestly and block withholding
based on this criterion
and block withholding miners
on this criterion would
this criterion would reject
criterion would reject the
would reject the majority
reject the majority of
the implications are that
the majority of its
implications are that a
majority of its honest
are that a miner
of its honest miners
that a miner that
a miner that engages
miner that engages in
the alternative of rejecting
that engages in block
alternative of rejecting small
engages in block withholding
of rejecting small miners
in block withholding does
rejecting small miners in
block withholding does not
small miners in general
withholding does not contribute
miners in general or
does not contribute to
in general or distributing
not contribute to the
general or distributing revenue
contribute to the pool
or distributing revenue on
to the pool s
distributing revenue on a
the pool s overall
revenue on a yearly
pool s overall mining
on a yearly basis
s overall mining power
a yearly basis contradicts
yearly basis contradicts the
basis contradicts the goal
contradicts the goal of
the goal of pooled
but still shares the
goal of pooled mining
still shares the pool
shares the pool s
the pool s revenue
pool s revenue according
s revenue according to
revenue according to its
according to its sent
to its sent partial
its sent partial proofs
m odel and s
sent partial proofs of
odel and s tandard
partial proofs of work
and s tandard o
s tandard o peration
tandard o peration we
o peration we specify
to reason about a
peration we specify the
reason about a pool
we specify the basic
about a pool s
specify the basic model
a pool s efficiency
the basic model in
pool s efficiency we
basic model in which
s efficiency we define
model in which participants
efficiency we define its
in which participants operate
we define its per
which participants operate in
participants operate in section
operate in section iii
miner revenue as follows
proceed to describe how
to describe how honest
describe how honest miners
how honest miners operate
honest miners operate in
miners operate in this
operate in this environment
in this environment in
this environment in sections
environment in sections iii
the revenue density of
revenue density of a
density of a pool
of a pool is
and how the classical
a pool is the
how the classical block
pool is the ratio
the classical block withholding
is the ratio between
classical block withholding attack
the ratio between the
block withholding attack is
ratio between the average
withholding attack is implemented
between the average revenue
attack is implemented with
the average revenue a
is implemented with our
average revenue a pool
implemented with our model
revenue a pool member
with our model in
a pool member earns
our model in section
pool member earns and
model in section iii
member earns and the
earns and the average
and the average revenue
the average revenue it
average revenue it would
revenue it would have
it would have earned
would have earned as
have earned as a
earned as a solo
as a solo miner
model the system is
the system is comprised
the revenue density of
system is comprised of
revenue density of a
is comprised of the
density of a solo
comprised of the bitcoin
of a solo miner
of the bitcoin network
the bitcoin network and
bitcoin network and nodes
network and nodes with
and that of a
and nodes with unique
that of a miner
nodes with unique ids
of a miner working
a miner working with
miner working with an
working with an unattacked
with an unattacked pool
and progresses in steps
an unattacked pool are
unattacked pool are one
a node i generates
node i generates tasks
if a pool is
i generates tasks which
a pool is attacked
generates tasks which are
pool is attacked with
tasks which are associated
is attacked with block
which are associated with
attacked with block withholding
are associated with its
associated with its id
with its id i
its revenue density decreases
a node can work
node can work on
can work on a
work on a task
on a task for
a task for the
continuous analysis because our
task for the duration
analysis because our analysis
for the duration of
because our analysis will
the duration of a
our analysis will be
duration of a step
analysis will be of
will be of the
be of the average
of the average revenue
the result of this
result of this work
we will consider proofs
of this work is
will consider proofs of
this work is a
consider proofs of work
work is a set
is a set of
both full and partial
a set of partial
set of partial proofs
of partial proofs of
partial proofs of work
as continuous deterministic sizes
proofs of work and
of work and a
work and a set
and a set of
a set of full
according to their probability
set of full proofs
of full proofs of
full proofs of work
work on a task
on a task therefore
the number of proofs
a task therefore results
number of proofs in
task therefore results in
of proofs in each
therefore results in a
proofs in each set
results in a deterministic
in each set has
in a deterministic fraction
each set has a
a deterministic fraction of
set has a poisson
deterministic fraction of proof
has a poisson distribution
fraction of proof of
of proof of work
partial proofs with a
proofs with a large
with a large mean
a large mean and
large mean and full
mean and full proofs
t he p ool
and full proofs with
he p ool g
full proofs with a
p ool g ame
proofs with a small
ool g ame a
with a small mean
the pool block withholding
nodes that work on
pool block withholding attack
block withholding attack just
that work on tasks
withholding attack just as
work on tasks are
attack just as a
on tasks are called
just as a miner
tasks are called a
as a miner can
a miner can perform
miner can perform block
are called a miners
can perform block withholding
perform block withholding on
block withholding on a
withholding on a pool
on a pool j
miners have identical power
a pool i can
and hence identical probabilities
pool i can use
hence identical probabilities to
i can use some
identical probabilities to generate
can use some of
probabilities to generate proofs
use some of its
to generate proofs of
some of its mining
generate proofs of work
of its mining power
its mining power to
mining power to infiltrate
power to infiltrate a
to infiltrate a pool
the bitcoin network pays
infiltrate a pool j
bitcoin network pays for
a pool j and
network pays for full
pool j and perform
pays for full proofs
j and perform a
for full proofs of
and perform a block
full proofs of work
perform a block withholding
a block withholding attack
block withholding attack on
withholding attack on j
to acquire this payoff
acquire this payoff an
this payoff an entity
payoff an entity publishes
an entity publishes a
denote the amount of
entity publishes a task
the amount of such
publishes a task task
amount of such infiltrating
a task task and
of such infiltrating mining
task task and its
such infiltrating mining power
task and its corresponding
infiltrating mining power at
and its corresponding proof
mining power at step
its corresponding proof of
power at step t
corresponding proof of work
at step t by
proof of work to
step t by xi
of work to the
work to the network
the payoff goes to
payoff goes to the
goes to the id
to the id associated
the id associated with
id associated with task
miners working for pool
working for pool i
the bitcoin protocol normalizes
bitcoin protocol normalizes revenue
protocol normalizes revenue such
either mining honestly or
normalizes revenue such that
mining honestly or used
revenue such that the
honestly or used for
such that the average
or used for infiltrating
that the average total
used for infiltrating pool
the average total revenue
for infiltrating pool j
average total revenue distributed
total revenue distributed in
revenue distributed in each
distributed in each step
are loyal to pool
in each step is
loyal to pool i
each step is a
step is a constant
is a constant throughout
a constant throughout the
at the end of
constant throughout the execution
the end of a
throughout the execution of
end of a round
the execution of the
execution of the system
pool i aggregates its
i aggregates its revenue
any node can transact
aggregates its revenue from
node can transact bitcoins
its revenue from mining
can transact bitcoins to
revenue from mining in
transact bitcoins to another
from mining in the
bitcoins to another node
mining in the current
to another node by
in the current round
another node by issuing
the current round and
node by issuing a
current round and from
by issuing a bitcoin
round and from its
issuing a bitcoin transaction
and from its infiltration
from its infiltration in
its infiltration in the
nodes that generate tasks
infiltration in the previous
that generate tasks but
in the previous round
generate tasks but outsource
tasks but outsource the
but outsource the work
outsource the work are
the work are called
it distributes the revenue
work are called pools
distributes the revenue evenly
the revenue evenly among
revenue evenly among all
evenly among all its
pools send tasks to
among all its loyal
send tasks to miners
all its loyal miners
tasks to miners over
its loyal miners according
to miners over the
loyal miners according to
miners over the network
miners according to their
according to their partial
to their partial proofs
their partial proofs of
partial proofs of work
the miners receive the
miners receive the tasks
the pool s miners
pool s miners are
s miners are oblivious
miners are oblivious to
are oblivious to their
and send the partial
oblivious to their role
send the partial and
to their role and
the partial and full
their role and they
partial and full proofs
role and they operate
and full proofs of
and they operate as
full proofs of work
they operate as regular
proofs of work to
operate as regular honest
of work to the
as regular honest miners
work to the pool
apart from working on
from working on tasks
revenue convergence note that
convergence note that pool
and receipt are instantaneous
note that pool j
that pool j sends
pool j sends its
j sends its revenue
we assume that the
sends its revenue to
assume that the number
its revenue to infiltrators
that the number of
revenue to infiltrators from
the number of miners
to infiltrators from pool
number of miners is
infiltrators from pool i
of miners is large
from pool i at
miners is large enough
pool i at the
is large enough such
i at the end
large enough such that
at the end of
enough such that mining
the end of the
such that mining power
end of the step
that mining power can
mining power can be
power can be split
can be split arbitrarily
be split arbitrarily without
and this revenue is
split arbitrarily without resolution
this revenue is calculated
arbitrarily without resolution constraints
revenue is calculated in
is calculated in pool
calculated in pool i
in pool i at
pool i at the
denote the number of
i at the beginning
the number of pools
at the beginning of
number of pools with
the beginning of the
of pools with p
beginning of the subsequent
of the subsequent step
the total number of
total number of mining
number of mining power
if there is a
of mining power in
there is a chain
mining power in the
is a chain of
power in the system
a chain of pools
in the system with
the system with m
system with m and
with m and the
m and the miners
and the miners participating
the miners participating in
miners participating in pool
participating in pool i
we use a quasistatic
use a quasistatic analysis
a quasistatic analysis where
quasistatic analysis where miner
analysis where miner participation
where each pool infiltrates
where miner participation in
each pool infiltrates the
miner participation in a
pool infiltrates the previous
participation in a pool
infiltrates the previous one
in a pool does
a pool does not
pool does not change
the pool revenue will
does not change over
pool revenue will not
not change over time
revenue will not be
will not be static
since the revenue from
the revenue from infiltration
solo mining a solo
revenue from infiltration takes
mining a solo miner
from infiltration takes one
a solo miner is
infiltration takes one step
solo miner is a
takes one step to
miner is a node
one step to take
is a node that
step to take each
a node that generates
to take each hop
node that generates its
that generates its own
generates its own tasks
from the first step
in every step it
every step it generates
step it generates a
the revenue of pool
it generates a task
works on it for
on it for the
it for the duration
since it is only
for the duration of
it is only infiltrated
the duration of the
is only infiltrated and
duration of the step
only infiltrated and loses
of the step and
infiltrated and loses some
and loses some of
the step and if
loses some of its
step and if it
some of its revenue
and if it finds
of its revenue for
if it finds a
its revenue for pool
it finds a full
finds a full proof
a full proof of
full proof of work
starting from the second
it publishes this proof
from the second step
publishes this proof of
this proof of work
proof of work to
of work to earn
work to earn the
the revenue of pool
to earn the payoff
comprised of its own
of its own mining
pools a pool is
its own mining and
a pool is a
own mining and its
pool is a node
mining and its revenue
is a node that
and its revenue from
a node that serves
its revenue from the
node that serves as
revenue from the infiltration
that serves as a
from the infiltration of
serves as a coordinator
the infiltration of pool
as a coordinator and
a coordinator and multiple
coordinator and multiple miners
and multiple miners can
multiple miners can register
miners can register to
can register to a
register to a pool
with some revenue lost
to a pool and
some revenue lost due
a pool and work
revenue lost due to
pool and work for
lost due to its
and work for it
due to its infiltration
to its infiltration by
its infiltration by pool
in every step it
every step it generates
step it generates a
it generates a task
generates a task for
starting from the third
a task for each
from the third step
task for each registered
for each registered miner
each registered miner and
registered miner and sends
the revenue of pool
miner and sends it
and sends it over
sends it over the
it over the network
each miner receives its
miner receives its task
receives its task and
its task and works
task and works on
and works on it
works on it for
max is the longest
on it for the
is the longest chain
it for the duration
the longest chain in
for the duration of
longest chain in the
the duration of the
chain in the system
duration of the step
at the end of
the end of the
the revenue stabilizes after
end of the step
the miner sends the
miner sends the pool
sends the pool the
if there are loops
the pool the full
there are loops in
pool the full and
are loops in the
the full and the
loops in the infiltration
full and the partial
in the infiltration graph
and the partial proofs
the partial proofs of
partial proofs of work
proofs of work it
of work it has
the system will converge
work it has found
system will converge to
will converge to a
converge to a certain
to a certain revenue
the pool receives the
pool receives the proofs
receives the proofs of
as stated in the
the proofs of work
stated in the following
proofs of work of
in the following lemma
of work of all
work of all its
of all its miners
registers the partial proofs
the partial proofs of
partial proofs of work
proofs of work and
of work and publishes
work and publishes the
and publishes the full
publishes the full proofs
it calculates its overall
if infiltration rates are
calculates its overall revenue
infiltration rates are constant
and proceeds to distribute
the pool revenues converge
proceeds to distribute it
pool revenues converge to
to distribute it among
revenues converge to a
distribute it among its
converge to a limit
it among its miners
to a limit as
a limit as time
limit as time progresses
each miner receives revenue
miner receives revenue proportional
receives revenue proportional to
revenue proportional to its
proportional to its success
to its success in
its success in the
denote the revenue density
success in the current
the revenue density of
in the current step
revenue density of pool
density of pool i
of pool i at
pool i at the
i at the end
at the end of
the end of step
end of step t
namely the ratio of
of step t by
the ratio of its
step t by ri
ratio of its partial
of its partial proofs
its partial proofs of
partial proofs of work
proofs of work out
of work out of
work out of all
out of all partial
of all partial proofs
all partial proofs of
partial proofs of work
proofs of work the
and define the revenue
of work the pool
define the revenue density
work the pool received
the revenue density vector
revenue density vector r
we assume that pools
assume that pools do
that pools do not
pools do not collect
do not collect fees
not collect fees of
collect fees of the
fees of the revenue
pool fees and their
fees and their implications
and their implications on
their implications on our
implications on our analysis
on our analysis are
our analysis are discussed
analysis are discussed in
are discussed in section
discussed in section ix
block withholding miner a
withholding miner a miner
miner a miner registered
a miner registered at
miner registered at a
registered at a pool
at a pool can
a pool can perform
pool can perform the
can perform the classical
perform the classical block
the classical block withholding
classical block withholding attack
an attacker miner operates
attacker miner operates as
miner operates as if
operates as if it
as if it worked
if it worked for
it worked for the
worked for the pool
it receives its tasks
receives its tasks and
its tasks and works
tasks and works on
and works on them
the revenues at all
revenues at all pools
at all pools converge
only at the end
all pools converge as
at the end of
pools converge as follows
the end of each
end of each round
of each round it
each round it sends
round it sends only
it sends only its
sends only its partial
only its partial proofs
its partial proofs of
partial proofs of work
and omits full proofs
omits full proofs of
full proofs of work
proofs of work if
of work if it
work if it had
if it had found
it had found any
the pool registers the
pool registers the miner
registers the miner s
the miner s partial
miner s partial proofs
but cannot distinguish between
cannot distinguish between miners
distinguish between miners running
between miners running honestly
miners running honestly and
running honestly and block
honestly and block withholding
and block withholding miners
the implications are that
implications are that a
are that a miner
that a miner that
a miner that engages
miner that engages in
that engages in block
engages in block withholding
in block withholding does
block withholding does not
withholding does not contribute
does not contribute to
not contribute to the
contribute to the pool
to the pool s
the pool s overall
pool s overall mining
s overall mining power
but still shares the
still shares the pool
shares the pool s
p in every round
the pool s revenue
pool s revenue according
s revenue according to
revenue according to its
pool i uses its
according to its sent
i uses its mining
to its sent partial
uses its mining power
its sent partial proofs
its mining power of
sent partial proofs of
mining power of m
partial proofs of work
to reason about a
reason about a pool
about a pool s
a pool s efficiency
pool s efficiency we
s efficiency we define
efficiency we define its
we define its per
j used for direct
used for direct mining
for direct mining p
miner revenue as follows
and shares it among
shares it among its
it among its m
the revenue density of
revenue density of a
density of a pool
of a pool is
a pool is the
pool is the ratio
is the ratio between
the ratio between the
ratio between the average
between the average revenue
the average revenue a
average revenue a pool
all sums are over
revenue a pool member
sums are over the
a pool member earns
are over the range
pool member earns and
member earns and the
earns and the average
and the average revenue
the average revenue it
average revenue it would
revenue it would have
it would have earned
would have earned as
have earned as a
earned as a solo
as a solo miner
the revenue density of
revenue density of a
density of a solo
of a solo miner
and that of a
that of a miner
of a miner working
a miner working with
miner working with an
working with an unattacked
with an unattacked pool
an unattacked pool are
unattacked pool are one
denote the direct mining
the direct mining revenue
direct mining revenue density
mining revenue density of
revenue density of each
if a pool is
density of each pool
a pool is attacked
pool is attacked with
is attacked with block
attacked with block withholding
its revenue density decreases
which is a constant
is a constant factor
continuous analysis because our
analysis because our analysis
because our analysis will
our analysis will be
analysis will be of
will be of the
be of the average
of the average revenue
we will consider proofs
will consider proofs of
consider proofs of work
both full and partial
as continuous deterministic sizes
according to their probability
work on a task
on a task therefore
a task therefore results
task therefore results in
therefore results in a
results in a deterministic
in a deterministic fraction
a deterministic fraction of
deterministic fraction of proof
fraction of proof of
of proof of work
t he p ool
he p ool g
p ool g ame
ool g ame a
the pool block withholding
pool block withholding attack
block withholding attack just
withholding attack just as
attack just as a
just as a miner
as a miner can
the pool game in
a miner can perform
pool game in the
miner can perform block
game in the pool
can perform block withholding
in the pool game
perform block withholding on
the pool game pools
block withholding on a
pool game pools try
withholding on a pool
game pools try to
on a pool j
pools try to optimize
try to optimize their
to optimize their infiltration
optimize their infiltration rates
a pool i can
their infiltration rates of
pool i can use
infiltration rates of other
i can use some
rates of other pools
can use some of
of other pools to
use some of its
other pools to maximize
some of its mining
pools to maximize their
of its mining power
to maximize their revenue
its mining power to
mining power to infiltrate
power to infiltrate a
to infiltrate a pool
infiltrate a pool j
the overall number of
a pool j and
overall number of miners
pool j and perform
number of miners and
j and perform a
of miners and the
and perform a block
miners and the number
perform a block withholding
and the number of
a block withholding attack
the number of miners
block withholding attack on
number of miners loyal
withholding attack on j
of miners loyal to
miners loyal to each
loyal to each pool
to each pool remain
each pool remain constant
denote the amount of
pool remain constant throughout
the amount of such
remain constant throughout the
amount of such infiltrating
constant throughout the game
of such infiltrating mining
such infiltrating mining power
infiltrating mining power at
mining power at step
power at step t
time progresses in rounds
at step t by
step t by xi
let s be a
s be a constant
be a constant integer
a constant integer large
constant integer large enough
integer large enough that
large enough that revenue
enough that revenue can
that revenue can be
revenue can be approximated
can be approximated as
be approximated as its
miners working for pool
approximated as its convergence
working for pool i
as its convergence limit
either mining honestly or
mining honestly or used
in each round the
honestly or used for
each round the system
or used for infiltrating
round the system takes
used for infiltrating pool
the system takes s
for infiltrating pool j
system takes s steps
takes s steps and
s steps and then
steps and then a
are loyal to pool
and then a single
loyal to pool i
then a single pool
at the end of
the end of a
picked with a round
end of a round
pool i aggregates its
i aggregates its revenue
may change its infiltration
aggregates its revenue from
change its infiltration rates
its revenue from mining
its infiltration rates of
revenue from mining in
infiltration rates of all
from mining in the
rates of all other
mining in the current
of all other pools
in the current round
the current round and
current round and from
round and from its
the total revenue of
and from its infiltration
total revenue of each
from its infiltration in
revenue of each step
its infiltration in the
of each step is
infiltration in the previous
each step is normalized
in the previous round
step is normalized to
it distributes the revenue
distributes the revenue evenly
the revenue evenly among
revenue evenly among all
evenly among all its
among all its loyal
all its loyal miners
so the revenue per
its loyal miners according
the revenue per round
loyal miners according to
revenue per round is
miners according to their
per round is one
according to their partial
to their partial proofs
their partial proofs of
partial proofs of work
the pool taking a
pool taking a step
taking a step knows
a step knows the
step knows the rate
knows the rate of
the rate of infiltrators
the pool s miners
rate of infiltrators attacking
pool s miners are
of infiltrators attacking it
s miners are oblivious
miners are oblivious to
are oblivious to their
oblivious to their role
though not their identity
to their role and
their role and they
role and they operate
and they operate as
they operate as regular
and the revenue rates
operate as regular honest
the revenue rates of
as regular honest miners
revenue rates of each
rates of each of
of each of the
each of the other
of the other pools
this knowledge is required
knowledge is required to
is required to optimize
required to optimize a
to optimize a pool
revenue convergence note that
optimize a pool s
convergence note that pool
a pool s revenue
note that pool j
that pool j sends
pool j sends its
j sends its revenue
as we see next
sends its revenue to
its revenue to infiltrators
revenue to infiltrators from
to infiltrators from pool
infiltrators from pool i
we explain in section
from pool i at
explain in section viii
pool i at the
in section viii how
i at the end
section viii how a
at the end of
viii how a pool
the end of the
how a pool can
end of the step
a pool can technically
pool can technically obtain
can technically obtain this
technically obtain this knowledge
and this revenue is
this revenue is calculated
revenue is calculated in
is calculated in pool
calculated in pool i
in pool i at
pool i at the
general analysis recall that
i at the beginning
analysis recall that mi
at the beginning of
recall that mi is
the beginning of the
that mi is the
beginning of the subsequent
mi is the number
of the subsequent step
is the number of
the number of miners
number of miners loyal
of miners loyal to
if there is a
miners loyal to pool
there is a chain
loyal to pool i
is a chain of
a chain of pools
chain of pools of
of pools of length
where each pool infiltrates
each pool infiltrates the
pool infiltrates the next
the pool revenue will
is the number of
pool revenue will not
the number of miners
revenue will not be
number of miners used
will not be static
of miners used by
miners used by pool
used by pool i
by pool i to
pool i to infiltrate
since the revenue from
i to infiltrate pool
the revenue from infiltration
to infiltrate pool j
revenue from infiltration takes
infiltrate pool j at
from infiltration takes one
pool j at step
infiltration takes one step
j at step t
takes one step to
one step to take
step to take each
to take each hop
the mining rate of
mining rate of pool
rate of pool i
of pool i is
pool i is therefore
i is therefore the
max is the longest
is therefore the number
is the longest chain
therefore the number of
the longest chain in
the number of its
longest chain in the
number of its loyal
chain in the system
of its loyal miners
its loyal miners minus
loyal miners minus the
miners minus the miners
minus the miners it
the revenue stabilizes after
the miners it uses
miners it uses for
it uses for infiltration
if there are loops
there are loops in
this effective mining rate
are loops in the
effective mining rate is
loops in the infiltration
mining rate is divided
in the infiltration graph
rate is divided by
is divided by the
divided by the total
by the total mining
the system will converge
the total mining rate
system will converge to
total mining rate in
will converge to a
mining rate in the
converge to a certain
rate in the system
to a certain revenue
namely the number of
as stated in the
the number of all
stated in the following
number of all miners
in the following lemma
of all miners that
all miners that do
miners that do not
that do not engage
do not engage in
not engage in block
engage in block withholding
denote the direct mining
the direct mining rate
direct mining rate of
mining rate of pool
rate of pool i
of pool i at
if infiltration rates are
pool i at step
infiltration rates are constant
i at step t
at step t by
step t by pp
t by pp mi
by pp mi j
the pool revenues converge
denote the revenue density
the revenue density of
revenue density of pool
density of pool i
of pool i at
pool i at the
i at the end
at the end of
the end of step
end of step t
of step t by
step t by ri
and define the revenue
define the revenue density
the revenue density vector
revenue density vector r
k the revenue of
the revenue of pool
revenue of pool i
of pool i in
pool i in step
i in step t
in step t taken
step t taken through
t taken through infiltration
taken through infiltration from
through infiltration from pool
infiltration from pool j
from pool j s
pool j s revenue
j s revenue in
s revenue in step
revenue in step t
pool i distributes this
i distributes this revenue
distributes this revenue among
this revenue among its
revenue among its mi
p in every round
i members loyal and
members loyal and infiltrators
pool i uses its
i uses its mining
uses its mining power
define the p p
its mining power of
the p p infiltration
mining power of m
p p infiltration matrix
p infiltration matrix by
infiltration matrix by its
matrix by its i
j used for direct
used for direct mining
for direct mining p
and shares it among
i ij the revenue
shares it among its
ij the revenue density
it among its m
the revenue density of
revenue density of pool
density of pool i
of pool i at
pool i at the
i at the end
at the end of
the end of step
end of step t
of step t is
step t is its
t is its revenue
is its revenue from
its revenue from direct
revenue from direct mining
from direct mining together
direct mining together with
mining together with its
together with its revenue
with its revenue from
its revenue from infiltrated
all sums are over
revenue from infiltrated pools
sums are over the
are over the range
divided by the number
by the number of
the number of its
number of its loyal
of its loyal miners
its loyal miners together
loyal miners together with
miners together with block
withholding infiltrators that attack
infiltrators that attack it
denote the direct mining
the direct mining revenue
direct mining revenue density
mining revenue density of
revenue density of each
density of each pool
which is a constant
is a constant factor
and the revenue vector
the revenue vector at
revenue vector at step
vector at step t
at step t is
step t is hereinafter
t is hereinafter we
is hereinafter we move
p the revenue of
hereinafter we move to
the revenue of pool
we move to a
revenue of pool i
move to a static
of pool i in
to a static state
pool i in step
a static state analysis
i in step t
static state analysis and
in step t taken
state analysis and omit
step t taken through
analysis and omit the
t taken through infiltration
and omit the t
taken through infiltration from
omit the t argument
through infiltration from pool
the t argument in
infiltration from pool j
t argument in the
from pool j s
argument in the expressions
pool j s revenue
j s revenue in
s revenue in step
revenue in step t
pool i distributes this
i distributes this revenue
distributes this revenue among
this revenue among its
revenue among its mi
i members loyal and
members loyal and infiltrators
define the p p
the p p infiltration
p p infiltration matrix
p infiltration matrix by
infiltration matrix by its
since the row sums
matrix by its i
the row sums of
row sums of the
sums of the infiltration
of the infiltration matrix
the infiltration matrix are
infiltration matrix are smaller
matrix are smaller than
are smaller than one
its largest eigenvalue is
largest eigenvalue is smaller
eigenvalue is smaller than
i ij and the
ij and the revenue
recall that difficulty is
and the revenue vector
that difficulty is only
the revenue vector at
difficulty is only adjusted
revenue vector at step
is only adjusted periodically
vector at step t
at step t is
step t is r
and there are transient
there are transient effects
are transient effects that
transient effects that are
effects that are not
that are not covered
are not covered by
not covered by this
covered by this stable
we discuss this in
discuss this in section
this in section viii
miners miners miners the
miners miners the revenue
miners the revenue its
the revenue its infiltrators
revenue its infiltrators obtained
its infiltrators obtained from
infiltrators obtained from pool
in the pool game
the pool game pools
pool game pools try
game pools try to
pools try to optimize
try to optimize their
to optimize their infiltration
optimize their infiltration rates
their infiltration rates of
infiltration rates of other
rates of other pools
of other pools to
other pools to maximize
pools to maximize their
to maximize their revenue
the overall number of
the revenue per loyal
overall number of miners
revenue per loyal pool
number of miners and
of miners and the
miners and the number
miner is therefore r
and the number of
the number of miners
number of miners loyal
of miners loyal to
miners loyal to each
loyal to each pool
to each pool remain
each pool remain constant
pool remain constant throughout
remain constant throughout the
constant throughout the game
time progresses in rounds
let s be a
s be a constant
be a constant integer
a constant integer large
constant integer large enough
integer large enough that
controls its infiltration rate
large enough that revenue
its infiltration rate of
enough that revenue can
infiltration rate of pool
that revenue can be
revenue can be approximated
can be approximated as
be approximated as its
approximated as its convergence
as its convergence limit
in each round the
each round the system
round the system takes
the system takes s
system takes s steps
takes s steps and
s steps and then
steps and then a
and then a single
then a single pool
and will choose the
will choose the value
choose the value that
picked with a round
the value that maximizes
value that maximizes the
that maximizes the revenue
maximizes the revenue density
may change its infiltration
change its infiltration rates
its infiltration rates of
infiltration rates of all
rates of all other
of all other pools
on the first round
the total revenue of
the first round of
total revenue of each
first round of the
revenue of each step
round of the pool
of each step is
of the pool game
each step is normalized
step is normalized to
the value of r
is maximized at a
maximized at a single
at a single point
a single point in
single point in the
point in the feasible
so the revenue per
in the feasible range
the revenue per round
revenue per round is
per round is one
the pool taking a
pool taking a step
taking a step knows
a step knows the
step knows the rate
knows the rate of
the rate of infiltrators
rate of infiltrators attacking
of infiltrators attacking it
though not their identity
cannot not react to
and the revenue rates
not react to pool
the revenue rates of
revenue rates of each
rates of each of
of each of the
each of the other
of the other pools
this point is the
point is the stable
is the stable state
this knowledge is required
the stable state of
knowledge is required to
stable state of the
is required to optimize
state of the system
required to optimize a
to optimize a pool
optimize a pool s
a pool s revenue
and we denote the
we denote the value
denote the value of
the value of x
as we see next
we explain in section
explain in section viii
in section viii how
section viii how a
viii how a pool
how a pool can
a pool can technically
pool can technically obtain
can technically obtain this
technically obtain this knowledge
general analysis recall that
analysis recall that mi
recall that mi is
that mi is the
mi is the number
is the number of
the number of miners
number of miners loyal
of miners loyal to
miners loyal to pool
loyal to pool i
and the values of
the values of the
values of the corresponding
of the corresponding revenues
the corresponding revenues of
corresponding revenues of the
revenues of the pools
of the pools with
the pools with r
is the number of
the number of miners
number of miners used
of miners used by
miners used by pool
used by pool i
by pool i to
pool i to infiltrate
i to infiltrate pool
to infiltrate pool j
infiltrate pool j at
substituting the stable value
pool j at step
the stable value x
j at step t
the mining rate of
mining rate of pool
rate of pool i
of pool i is
we obtain the revenues
obtain the revenues of
pool i is therefore
the revenues of the
i is therefore the
revenues of the two
is therefore the number
of the two pools
therefore the number of
the number of its
number of its loyal
all are given in
of its loyal miners
are given in figure
its loyal miners minus
loyal miners minus the
miners minus the miners
minus the miners it
the miners it uses
miners it uses for
it uses for infiltration
this effective mining rate
effective mining rate is
to simplify the expressions
mining rate is divided
rate is divided by
is divided by the
divided by the total
by the total mining
the total mining rate
total mining rate in
mining rate in the
rate in the system
namely the number of
the number of all
number of all miners
of all miners that
all miners that do
miners that do not
that do not engage
do not engage in
not engage in block
engage in block withholding
no attack if no
attack if no pool
if no pool engages
no pool engages in
pool engages in block
engages in block withholding
denote the direct mining
the direct mining rate
direct mining rate of
mining rate of pool
rate of pool i
of pool i at
pool i at step
i at step t
at step t by
step t by pp
t by pp mi
by pp mi j
and we have i
each miner s revenue
miner s revenue is
s revenue is proportional
revenue is proportional to
is proportional to its
proportional to its power
be it in a
it in a pool
k the revenue density
in a pool or
the revenue density of
a pool or working
revenue density of pool
pool or working solo
density of pool i
of pool i at
pool i at the
i at the end
at the end of
the end of step
end of step t
o ne attacker we
of step t is
ne attacker we begin
step t is its
attacker we begin our
t is its revenue
we begin our analysis
is its revenue from
begin our analysis with
its revenue from direct
our analysis with a
revenue from direct mining
analysis with a simplified
from direct mining together
with a simplified game
direct mining together with
a simplified game of
mining together with its
simplified game of two
together with its revenue
game of two pools
with its revenue from
its revenue from infiltrated
revenue from infiltrated pools
divided by the number
by the number of
the number of its
number of its loyal
of its loyal miners
its loyal miners together
loyal miners together with
miners together with block
withholding infiltrators that attack
infiltrators that attack it
miners outside both pools
outside both pools mine
both pools mine solo
or with closed pools
with closed pools that
closed pools that do
pools that do not
that do not attack
do not attack and
not attack and cannot
attack and cannot be
and cannot be attacked
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
the dashed red arrow
dashed red arrow indicates
red arrow indicates that
arrow indicates that x
s mining power infiltrates
mining power infiltrates pool
with a block withholding
a block withholding attack
hereinafter we move to
we move to a
move to a static
does not engage in
to a static state
not engage in block
a static state analysis
engage in block withholding
static state analysis and
state analysis and omit
analysis and omit the
and omit the t
all of its m
omit the t argument
the t argument in
t argument in the
argument in the expressions
loyal miners work on
miners work on its
work on its behalf
on the other hand
the other hand does
since the row sums
other hand does not
the row sums of
hand does not employ
row sums of the
does not employ x
sums of the infiltration
of the infiltration matrix
the infiltration matrix are
infiltration matrix are smaller
matrix are smaller than
are smaller than one
its largest eigenvalue is
largest eigenvalue is smaller
of its loyal miners
eigenvalue is smaller than
and its direct mining
according to the perron
its direct mining power
direct mining power is
mining power is only
power is only m
the revenues at all
revenues at all pools
at all pools converge
all pools converge as
pools converge as follows
the bitcoin system normalizes
bitcoin system normalizes these
system normalizes these rates
normalizes these rates by
these rates by the
rates by the total
by the total number
the total number of
total number of miners
number of miners that
of miners that publish
miners that publish full
that publish full proofs
namely all miners but
all miners but x
the pools direct revenues
pools direct revenues are
direct revenues are therefore
revenues are therefore m
the pool game if
pool game if no
game if no pool
if no pool engages
no pool engages in
pool engages in block
engages in block withholding
and we have i
divides its revenue among
its revenue among its
revenue among its loyal
among its loyal miners
its loyal miners and
loyal miners and the
miners and the miners
and the miners that
the miners that infiltrated
miners that infiltrated it
its revenue density is
revenue density is therefore
density is therefore r
each miner s revenue
miner s revenue is
s revenue is proportional
revenue is proportional to
is proportional to its
proportional to its power
be it in a
it in a pool
in a pool or
a pool or working
pool or working solo
recall that difficulty is
that difficulty is only
difficulty is only adjusted
is only adjusted periodically
and there are transient
there are transient effects
are transient effects that
transient effects that are
effects that are not
that are not covered
are not covered by
not covered by this
covered by this stable
we discuss this in
discuss this in section
this in section viii
miners miners miners a
controls its infiltration rate
its infiltration rate of
infiltration rate of pool
and will choose the
will choose the value
choose the value that
the value that maximizes
value that maximizes the
that maximizes the revenue
maximizes the revenue density
on the first round
the first round of
first round of the
round of the pool
of the pool game
the value of r
game progress bitcoin network
progress bitcoin network figure
is maximized at a
maximized at a single
at a single point
a single point in
single point in the
point in the feasible
in the feasible range
we obtain the expression
obtain the expression for
the expression for r
cannot not react to
not react to pool
this point is the
point is the stable
is the stable state
the stable state of
stable state of the
state of the system
and we denote the
we denote the value
denote the value of
the value of x
and the values of
the values of the
values of the corresponding
of the corresponding revenues
divides its revenue among
the corresponding revenues of
corresponding revenues of the
its revenue among its
revenues of the pools
revenue among its registered
of the pools with
among its registered miners
the pools with r
the revenue includes both
revenue includes both its
includes both its direct
both its direct mining
its direct mining revenue
direct mining revenue and
mining revenue and b
substituting the stable value
the stable value x
numerical analysis we analyze
analysis we analyze this
we analyze this game
analyze this game numerically
this game numerically by
game numerically by finding
numerically by finding the
by finding the x
we obtain the revenues
obtain the revenues of
the revenues of the
revenues of the two
of the two pools
all are given in
are given in figure
and substituting this value
substituting this value for
this value for r
to simplify the expressions
we vary the sizes
vary the sizes of
the sizes of the
sizes of the pools
of the pools through
the pools through the
pools through the entire
through the entire feasible
the entire feasible range
entire feasible range and
feasible range and depict
range and depict the
and depict the optimal
depict the optimal x
and the corresponding revenues
the corresponding revenues in
corresponding revenues in figure
each point in each
point in each graph
in each graph represents
each graph represents the
graph represents the equilibrium
represents the equilibrium point
the equilibrium point of
equilibrium point of a
point of a game
of a game with
a game with the
game with the corresponding
with the corresponding m
o ne attacker we
ne attacker we begin
attacker we begin our
we begin our analysis
where we normalize m
begin our analysis with
our analysis with a
analysis with a simplified
with a simplified game
a simplified game of
simplified game of two
game of two pools
the top right half
top right half of
right half of the
half of the range
of the range in
the range in all
range in all graphs
in all graphs is
all graphs is not
graphs is not feasible
as the sum of
the sum of m
we use this range
use this range as
this range as a
range as a reference
as a reference color
and we use a
we use a dashed
miners outside both pools
use a dashed line
outside both pools mine
a dashed line to
both pools mine solo
dashed line to show
line to show the
to show the bound
show the bound between
or with closed pools
the bound between this
with closed pools that
bound between this value
closed pools that do
between this value within
pools that do not
this value within the
that do not attack
value within the feasible
do not attack and
within the feasible range
not attack and cannot
attack and cannot be
and cannot be attacked
a shows the optimal
shows the optimal infiltration
the optimal infiltration rate
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
in the entire feasible
the entire feasible range
entire feasible range we
feasible range we see
range we see that
we see that pool
the dashed red arrow
dashed red arrow indicates
red arrow indicates that
chooses a strictly positive
arrow indicates that x
a strictly positive value
strictly positive value for
positive value for x
s mining power infiltrates
mining power infiltrates pool
the revenue of pool
with a block withholding
a block withholding attack
is depicted in figure
b and in the
does not engage in
and in the entire
not engage in block
in the entire feasible
engage in block withholding
the entire feasible region
entire feasible region it
feasible region it is
region it is strictly
all of its m
it is strictly larger
is strictly larger than
loyal miners work on
miners work on its
work on its behalf
which the pool would
the pool would have
pool would have gotten
would have gotten without
have gotten without attacking
on the other hand
the other hand does
other hand does not
hand does not employ
does not employ x
of its loyal miners
and its direct mining
its direct mining power
direct mining power is
mining power is only
power is only m
c depicts the revenue
depicts the revenue of
the revenue of pool
which is strictly smaller
is strictly smaller than
the bitcoin system normalizes
bitcoin system normalizes these
system normalizes these rates
in the entire range
normalizes these rates by
these rates by the
rates by the total
by the total number
the total number of
total number of miners
number of miners that
of miners that publish
miners that publish full
note that the total
that publish full proofs
that the total system
the total system mining
total system mining power
system mining power is
namely all miners but
mining power is reduced
all miners but x
power is reduced when
is reduced when pool
chooses to infiltrate pool
the pools direct revenues
pools direct revenues are
direct revenues are therefore
revenues are therefore m
the revenue of third
revenue of third parties
miners not in either
not in either pool
therefore pays for the
pays for the increased
for the increased revenue
the increased revenue of
increased revenue of its
revenue of its attacker
of its attacker and
its attacker and everyone
attacker and everyone else
and everyone else in
everyone else in the
else in the system
implications to the general
to the general case
the general case consider
divides its revenue among
general case consider the
its revenue among its
case consider the case
revenue among its loyal
consider the case of
among its loyal miners
the case of p
its loyal miners and
case of p pools
loyal miners and the
miners and the miners
and the miners that
the miners that infiltrated
miners that infiltrated it
for any choice of
any choice of the
choice of the pools
of the pools sizes
its revenue density is
the pools sizes m
revenue density is therefore
density is therefore r
at least one pool
least one pool will
one pool will choose
pool will choose to
will choose to perform
choose to perform block
to perform block withholding
divides its revenue among
its revenue among its
revenue among its registered
among its registered miners
the revenue includes both
revenue includes both its
includes both its direct
both its direct mining
its direct mining revenue
direct mining revenue and
mining revenue and the
revenue and the revenue
and the revenue its
the revenue its infiltrators
revenue its infiltrators obtained
its infiltrators obtained from
infiltrators obtained from pool
the revenue per loyal
revenue per loyal pool
miner is therefore r
we obtain the expression
obtain the expression for
the expression for r
we analyze this game
analyze this game numerically
this game numerically by
game numerically by finding
numerically by finding the
by finding the x
and substituting this value
substituting this value for
this value for r
we vary the sizes
vary the sizes of
the sizes of the
sizes of the pools
of the pools through
the pools through the
pools through the entire
through the entire feasible
the entire feasible range
entire feasible range and
feasible range and depict
range and depict the
and depict the optimal
depict the optimal x
and the corresponding revenues
the corresponding revenues in
corresponding revenues in figure
each point in each
point in each graph
in each graph represents
each graph represents the
graph represents the equilibrium
represents the equilibrium point
the equilibrium point of
equilibrium point of a
point of a game
of a game with
a game with the
game with the corresponding
with the corresponding m
stable state where only
state where only pool
where we normalize m
the top right half
top right half of
right half of the
half of the range
of the range in
the range in all
range in all graphs
in all graphs is
all graphs is not
graphs is not feasible
as the sum of
the sum of m
we use this range
use this range as
this range as a
range as a reference
as a reference color
two pools where one
pools where one infiltrates
and we use a
where one infiltrates the
we use a dashed
one infiltrates the other
use a dashed line
a dashed line to
dashed line to show
line to show the
optimal infiltration rate x
to show the bound
show the bound between
the bound between this
bound between this value
between this value within
this value within the
value within the feasible
within the feasible range
a shows the optimal
shows the optimal infiltration
the optimal infiltration rate
in the entire feasible
as a function of
the entire feasible range
a function of pool
entire feasible range we
function of pool sizes
feasible range we see
range we see that
we see that pool
chooses a strictly positive
a strictly positive value
strictly positive value for
positive value for x
the revenue of pool
and the lines in
is depicted in figure
b and in the
and in the entire
in the entire feasible
the entire feasible region
entire feasible region it
feasible region it is
region it is strictly
it is strictly larger
show the revenue density
is strictly larger than
the revenue density of
which the pool would
the pool would have
pool would have gotten
would have gotten without
have gotten without attacking
in a system with
a system with p
system with p pools
is not an equilibrium
assume towards negation this
towards negation this is
negation this is not
this is not the
is not the case
c depicts the revenue
depicts the revenue of
the revenue of pool
which is strictly smaller
is strictly smaller than
in the entire range
is an equilibrium point
now consider a setting
consider a setting with
a setting with only
setting with only pools
note that the total
that the total system
the total system mining
total system mining power
system mining power is
mining power is reduced
power is reduced when
is reduced when pool
and treat the other
chooses to infiltrate pool
treat the other pools
the other pools as
other pools as independent
pools as independent miners
this is the setting
is the setting analyzed
the setting analyzed above
setting analyzed above and
analyzed above and we
the revenue of third
above and we have
revenue of third parties
and we have seen
we have seen there
have seen there that
seen there that pool
miners not in either
not in either pool
can increase its revenue
increase its revenue by
its revenue by performing
revenue by performing a
by performing a block
performing a block withholding
a block withholding attack
block withholding attack on
withholding attack on pool
s infiltration rate by
infiltration rate by x
therefore pays for the
pays for the increased
take this values back
for the increased revenue
this values back to
the increased revenue of
values back to the
increased revenue of its
back to the setting
revenue of its attacker
to the setting at
of its attacker and
the setting at hand
its attacker and everyone
setting at hand with
attacker and everyone else
at hand with p
and everyone else in
hand with p pools
everyone else in the
else in the system
the revenue of pool
is better when x
implications to the general
to the general case
the general case consider
general case consider the
case consider the case
consider the case of
the case of p
case of p pools
for any choice of
any choice of the
choice of the pools
of the pools sizes
the pools sizes m
at least one pool
least one pool will
one pool will choose
pool will choose to
will choose to perform
choose to perform block
to perform block withholding
in a system with
a system with p
system with p pools
name size discusfish antpool
size discusfish antpool ghash
io btchine btcguild eligius
is not an equilibrium
btchine btcguild eligius others
assume towards negation this
towards negation this is
negation this is not
this is not the
is not the case
is an equilibrium point
now consider a setting
consider a setting with
a setting with only
setting with only pools
and treat the other
treat the other pools
the other pools as
other pools as independent
pools as independent miners
this is the setting
is the setting analyzed
the setting analyzed above
setting analyzed above and
analyzed above and we
above and we have
and we have seen
we have seen there
have seen there that
seen there that pool
can increase its revenue
increase its revenue by
its revenue by performing
revenue by performing a
by performing a block
performing a block withholding
a block withholding attack
block withholding attack on
withholding attack on pool
s infiltration rate by
infiltration rate by x
take this values p
this values p m
the six largest open
six largest open pool
largest open pool sizes
open pool sizes as
pool sizes as of
sizes as of january
their optimal infiltration rates
of each pool as
each pool as a
pool as a fraction
as a fraction of
a fraction of its
fraction of its size
if it attacked all
it attacked all others
attacked all others without
all others without reciprocation
and their revenue density
their revenue density when
revenue density when attacking
can improve its revenue
improve its revenue by
its revenue by attacking
revenue by attacking pool
attacks is not an
is not an equilibrium
not an equilibrium point
case as a test
as a test case
we take the pool
take the pool distribution
the pool distribution in
pool distribution in january
we analyze the cases
analyze the cases where
the cases where each
cases where each of
where each of the
each of the pools
of the pools attacks
the pools attacks all
pools attacks all other
attacks all other open
all other open pools
stable state where only
all of which behave
state where only pool
of which behave honestly
note that attacking all
that attacking all pools
attacking all pools with
all pools with force
pools with force proportional
with force proportional to
force proportional to their
proportional to their size
to their size yields
their size yields the
size yields the same
yields the same results
the same results as
same results as attacking
results as attacking a
as attacking a single
attacking a single pool
a single pool of
single pool of their
pool of their aggregate
of their aggregate size
plugging in the numbers
in the numbers into
the numbers into the
numbers into the analysis
into the analysis above
the analysis above shows
analysis above shows that
above shows that a
shows that a larger
that a larger pool
a larger pool needs
larger pool needs to
pool needs to use
needs to use a
to use a smaller
use a smaller ratio
a smaller ratio of
two pools where one
smaller ratio of its
pools where one infiltrates
ratio of its mining
where one infiltrates the
of its mining power
one infiltrates the other
its mining power for
mining power for infiltration
power for infiltration and
for infiltration and can
optimal infiltration rate x
infiltration and can increase
and can increase its
can increase its revenue
increase its revenue density
its revenue density more
revenue density more than
density more than a
more than a small
than a small pool
achieves its optimum attack
its optimum attack rate
optimum attack rate at
as a function of
a function of pool
function of pool sizes
of the pool s
the pool s mining
pool s mining power
increasing its revenue by
its revenue by almost
this amounts to a
amounts to a daily
and the lines in
to a daily revenue
a daily revenue increase
daily revenue increase of
revenue increase of b
show the revenue density
the revenue density of
back to the setting
to the setting at
the setting at hand
setting at hand with
at hand with p
hand with p pools
usd at the exchange
at the exchange rate
the exchange rate on
the revenue of pool
exchange rate on that
rate on that date
is better when x
this represents a considerable
represents a considerable increase
a considerable increase of
considerable increase of the
increase of the pools
of the pools net
the pools net revenue
for the smallest pool
the attack is much
attack is much less
is much less profitable
to reach the optimum
reach the optimum it
the optimum it needs
optimum it needs almost
it needs almost a
needs almost a third
almost a third of
a third of its
third of its power
of its power for
its power for attacking
power for attacking but
for attacking but increases
attacking but increases its
but increases its revenue
increases its revenue density
its revenue density by
revenue density by merely
can improve its revenue
improve its revenue by
its revenue by attacking
revenue by attacking pool
attacks is not an
is not an equilibrium
not an equilibrium point
case as a test
as a test case
we take the pool
take the pool distribution
the pool distribution in
pool distribution in january
two attacking pools system
we analyze the cases
analyze the cases where
the cases where each
cases where each of
where each of the
each of the pools
of the pools attacks
the pools attacks all
pools attacks all other
attacks all other open
all other open pools
as a function of
a function of pool
function of pool sizes
all of which behave
of which behave honestly
note that attacking all
that attacking all pools
attacking all pools with
all pools with force
pools with force proportional
with force proportional to
force proportional to their
proportional to their size
to their size yields
their size yields the
size yields the same
yields the same results
the same results as
same results as attacking
results as attacking a
as attacking a single
attacking a single pool
a single pool of
single pool of their
pool of their aggregate
of their aggregate size
plugging in the numbers
in the numbers into
the numbers into the
numbers into the analysis
into the analysis above
the analysis above shows
analysis above shows that
above shows that a
shows that a larger
that a larger pool
a larger pool needs
larger pool needs to
pool needs to use
needs to use a
to use a smaller
use a smaller ratio
a smaller ratio of
smaller ratio of its
ratio of its mining
of its mining power
its mining power for
mining power for infiltration
power for infiltration and
for infiltration and can
infiltration and can increase
and can increase its
can increase its revenue
increase its revenue density
its revenue density more
revenue density more than
density more than a
more than a small
than a small pool
achieves its optimum attack
its optimum attack rate
optimum attack rate at
of the pool s
the pool s mining
pool s mining power
t wo p ools
wo p ools we
increasing its revenue by
p ools we proceed
its revenue by almost
ools we proceed to
we proceed to analyze
proceed to analyze the
to analyze the case
analyze the case where
the case where two
case where two pools
where two pools may
two pools may attack
pools may attack each
this amounts to a
may attack each other
amounts to a daily
attack each other and
to a daily revenue
each other and the
a daily revenue increase
other and the other
daily revenue increase of
and the other miners
revenue increase of b
the other miners mine
other miners mine solo
again we have pool
usd at the exchange
controls its infiltration rate
at the exchange rate
its infiltration rate x
the exchange rate on
exchange rate on that
rate on that date
this represents a considerable
represents a considerable increase
a considerable increase of
considerable increase of the
increase of the pools
of the pools net
the pools net revenue
also controls its infiltration
for the smallest pool
controls its infiltration rate
its infiltration rate x
the attack is much
attack is much less
is much less profitable
to reach the optimum
reach the optimum it
the optimum it needs
this scenario is illustrated
optimum it needs almost
scenario is illustrated in
it needs almost a
is illustrated in figure
needs almost a third
almost a third of
a third of its
third of its power
the total mining power
of its power for
total mining power in
its power for attacking
mining power in the
power for attacking but
power in the system
for attacking but increases
in the system is
attacking but increases its
the system is m
but increases its revenue
system is m x
increases its revenue density
its revenue density by
revenue density by merely
the direct revenues r
of the pools from
the pools from mining
pools from mining are
from mining are their
mining are their effective
are their effective mining
their effective mining rates
without infiltrating mining power
divided by the total
by the total mining
the total mining rate
name size discusfish antpool
size discusfish antpool ghash
io btchine btcguild eligius
btchine btcguild eligius others
the total revenue of
total revenue of each
revenue of each pool
of each pool is
each pool is its
pool is its direct
is its direct mining
its direct mining revenue
two pools infiltrating each
pools infiltrating each other
and the infiltration revenue
the infiltration revenue from
infiltration revenue from the
revenue from the previous
from the previous round
which is the attacked
is the attacked pool
the attacked pool s
attacked pool s total
pool s total revenue
s total revenue multiplied
total revenue multiplied by
revenue multiplied by its
multiplied by its infiltration
by its infiltration rate
the pool s total
pool s total revenue
s total revenue is
total revenue is divided
revenue is divided among
is divided among its
divided among its loyal
among its loyal miners
its loyal miners and
loyal miners and miners
miners and miners that
and miners that infiltrated
miners that infiltrated it
at stable state this
stable state this is
state this is r
the six largest open
six largest open pool
largest open pool sizes
open pool sizes as
pool sizes as of
sizes as of january
we obtain the following
obtain the following closed
the following closed expressions
following closed expressions for
closed expressions for each
we express the revenues
express the revenues as
the revenues as functions
revenues as functions of
as functions of x
their optimal infiltration rates
of each pool as
each pool as a
pool as a fraction
as a fraction of
a fraction of its
fraction of its size
if it attacked all
it attacked all others
attacked all others without
all others without reciprocation
and their revenue density
their revenue density when
revenue density when attacking
t wo p ools
wo p ools we
p ools we proceed
ools we proceed to
we proceed to analyze
proceed to analyze the
to analyze the case
analyze the case where
the case where two
case where two pools
where two pools may
two pools may attack
pools may attack each
may attack each other
attack each other and
each other and the
other and the other
and the other miners
the other miners mine
other miners mine solo
again we have pool
controls its infiltration rate
its infiltration rate x
also controls its infiltration
controls its infiltration rate
its infiltration rate x
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
the total mining power
total mining power in
mining power in the
power in the system
in the system is
the system is m
system is m x
the direct revenues r
of the pools from
the pools from mining
pools from mining are
from mining are their
mining are their effective
are their effective mining
their effective mining rates
each pool controls only
pool controls only its
controls only its own
only its own infiltration
its own infiltration rate
in each round of
each round of the
round of the pool
of the pool game
each pool will optimize
pool will optimize its
will optimize its infiltration
optimize its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the other
two attacking pools system
acts at step t
it optimizes its revenue
optimizes its revenue with
its revenue with r
as a function of
a function of pool
function of pool sizes
acts at step t
it optimizes its revenue
optimizes its revenue with
its revenue with x
two pools infiltrating each
pools infiltrating each other
divided by the total
by the total mining
the total mining rate
an equilibrium exists where
equilibrium exists where neither
exists where neither pool
can improve its revenue
improve its revenue by
its revenue by changing
revenue by changing its
by changing its infiltration
changing its infiltration rate
any pair of values
pair of values x
such that arg maxx
the total revenue of
total revenue of each
revenue of each pool
of each pool is
each pool is its
pool is its direct
is its direct mining
its direct mining revenue
and the infiltration revenue
the infiltration revenue from
infiltration revenue from the
revenue from the previous
from the previous round
which is the attacked
is the attacked pool
the attacked pool s
attacked pool s total
pool s total revenue
s total revenue multiplied
total revenue multiplied by
revenue multiplied by its
multiplied by its infiltration
by its infiltration rate
the pool s total
pool s total revenue
s total revenue is
total revenue is divided
revenue is divided among
is divided among its
divided among its loyal
among its loyal miners
its loyal miners and
loyal miners and miners
miners and miners that
and miners that infiltrated
miners that infiltrated it
at stable state this
stable state this is
state this is r
the feasible region for
feasible region for the
region for the pool
for the pool sizes
the pool sizes is
pool sizes is m
we obtain the following
obtain the following closed
the following closed expressions
following closed expressions for
closed expressions for each
we express the revenues
express the revenues as
the revenues as functions
revenues as functions of
as functions of x
the revenue function for
revenue function for ri
function for ri is
for ri is concave
ri is concave in
is concave in xi
concave in xi for
in xi for all
xi for all feasible
for all feasible values
all feasible values of
feasible values of the
values of the variables
therefore the solutions for
the solutions for equations
are unique and are
unique and are either
and are either at
are either at the
either at the borders
at the borders of
the borders of the
borders of the feasible
of the feasible region
the feasible region or
feasible region or where
region or where ri
from section v we
section v we know
v we know that
we know that no
attack is not an
is not an equilibrium
not an equilibrium point
since each pool can
each pool can increase
pool can increase its
can increase its revenue
increase its revenue by
its revenue by choosing
revenue by choosing a
by choosing a strictly
choosing a strictly positive
a strictly positive infiltration
strictly positive infiltration rate
is not a solution
not a solution to
a solution to equations
nash equilibrium therefore exists
equilibrium therefore exists with
therefore exists with x
each pool controls only
pool controls only its
controls only its own
only its own infiltration
its own infiltration rate
in each round of
each round of the
round of the pool
of the pool game
each pool will optimize
pool will optimize its
will optimize its infiltration
optimize its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the other
acts at step t
it optimizes its revenue
optimizes its revenue with
its revenue with x
using symbolic computation tools
we see that there
see that there is
that there is a
there is a single
is a single pair
a single pair of
single pair of values
pair of values for
of values for which
values for which equation
holds for any feasible
for any feasible choice
any feasible choice of
feasible choice of m
numerical analysis a numerical
analysis a numerical analysis
a numerical analysis confirms
numerical analysis confirms these
analysis confirms these observations
we simulate the pool
simulate the pool game
the pool game for
pool game for a
game for a range
for a range of
a range of pool
range of pool sizes
for each choice of
each choice of pool
choice of pool sizes
acts at step t
we start the simulation
start the simulation when
the simulation when both
simulation when both pools
it optimizes its revenue
when both pools do
optimizes its revenue with
both pools do not
its revenue with x
pools do not infiltrate
do not infiltrate each
not infiltrate each other
and the revenue densities
the revenue densities are
revenue densities are r
at each round one
each round one pool
round one pool chooses
one pool chooses its
pool chooses its optimal
chooses its optimal infiltration
its optimal infiltration rate
an equilibrium exists where
optimal infiltration rate based
equilibrium exists where neither
infiltration rate based on
exists where neither pool
rate based on the
based on the pool
on the pool sizes
the pool sizes and
pool sizes and the
sizes and the rate
and the rate with
the rate with which
can improve its revenue
rate with which it
improve its revenue by
with which it is
its revenue by changing
which it is infiltrated
revenue by changing its
by changing its infiltration
changing its infiltration rate
and we calculate the
we calculate the revenue
calculate the revenue after
the revenue after convergence
revenue after convergence with
after convergence with equation
any pair of values
pair of values x
recall the players in
the players in the
players in the pool
in the pool game
the pool game are
pool game are chosen
game are chosen with
are chosen with the
such that arg maxx
chosen with the round
with the round robin
the round robin policy
so the pools take
the pools take turns
and we let the
we let the game
let the game run
the game run until
game run until convergence
the results are illustrated
results are illustrated in
are illustrated in figure
each run with some
run with some m
values results in a
results in a single
in a single point
a single point in
single point in each
point in each graph
in each graph in
each graph in figure
we depict the infiltration
depict the infiltration rates
the infiltration rates of
infiltration rates of both
rates of both pools
of both pools x
b and the pools
and the pools revenue
the pools revenue densities
pools revenue densities r
for each choice of
each choice of m
the values of x
are the points in
the points in each
points in each of
in each of the
each of the graphs
of the graphs with
the graphs with the
graphs with the respective
with the respective coordinates
j graphs we draw
graphs we draw a
we draw a border
draw a border around
a border around the
border around the region
around the region where
the region where there
region where there is
where there is no
attack by i in
the feasible region for
by i in equilibrium
feasible region for the
region for the pool
for the pool sizes
the pool sizes is
pool sizes is m
for the ri graphs
the ri graphs we
ri graphs we draw
graphs we draw a
we draw a line
draw a line around
a line around the
line around the region
around the region where
the region where the
region where the revenue
where the revenue is
the revenue is the
revenue is the same
is the same as
the same as in
same as in the
as in the no
we first observe that
first observe that only
observe that only in
that only in extreme
only in extreme cases
in extreme cases a
extreme cases a pool
cases a pool does
a pool does not
the revenue function for
pool does not attack
revenue function for ri
does not attack its
function for ri is
not attack its counterpart
for ri is concave
ri is concave in
is concave in xi
concave in xi for
in xi for all
xi for all feasible
for all feasible values
all feasible values of
feasible values of the
at equilibrium a pool
values of the variables
equilibrium a pool will
a pool will refrain
pool will refrain from
will refrain from attacking
refrain from attacking only
from attacking only if
attacking only if the
only if the other
if the other pool
the other pool is
other pool is larger
pool is larger than
is larger than about
of the total mining
the total mining power
therefore the solutions for
the solutions for equations
we observe that a
observe that a pool
that a pool improves
a pool improves its
pool improves its revenue
improves its revenue compared
are unique and are
its revenue compared to
unique and are either
revenue compared to the
and are either at
compared to the no
are either at the
either at the borders
at the borders of
the borders of the
borders of the feasible
of the feasible region
the feasible region or
feasible region or where
attacks scenario only when
region or where ri
scenario only when it
only when it controls
when it controls a
it controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the total
of the total mining
the total mining power
these are the small
are the small triangular
the small triangular regions
small triangular regions in
triangular regions in figures
from section v we
section v we know
v we know that
we know that no
attack is not an
is not an equilibrium
not an equilibrium point
in the rest of
the rest of the
rest of the space
since each pool can
each pool can increase
the trapezoids in the
pool can increase its
trapezoids in the figures
can increase its revenue
increase its revenue by
its revenue by choosing
revenue by choosing a
the revenue of the
revenue of the pool
by choosing a strictly
of the pool is
choosing a strictly positive
the pool is inferior
a strictly positive infiltration
pool is inferior compared
strictly positive infiltration rate
is inferior compared to
inferior compared to the
compared to the no
the prisoner s dilemma
prisoner s dilemma in
s dilemma in a
dilemma in a healthy
in a healthy bitcoin
a healthy bitcoin environment
where neither pool controls
neither pool controls a
pool controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the mining
of the mining power
both pools will earn
pools will earn less
will earn less at
earn less at equilibrium
less at equilibrium than
at equilibrium than if
equilibrium than if both
than if both pools
if both pools ran
is not a solution
both pools ran without
not a solution to
pools ran without attacking
a solution to equations
we can analyze in
can analyze in this
analyze in this case
in this case a
this case a game
case a game where
a game where each
game where each pool
where each pool chooses
each pool chooses either
pool chooses either to
chooses either to attack
either to attack and
nash equilibrium therefore exists
to attack and optimize
equilibrium therefore exists with
attack and optimize its
therefore exists with x
and optimize its revenue
or to refrain from
to refrain from attacking
without loss of generality
as we have seen
we have seen in
have seen in section
seen in section v
can increase its revenue
increase its revenue above
does attack but pool
we denote the revenue
denote the revenue of
the revenue of pool
the exact value of
exact value of r
depends on the values
on the values of
the values of m
but it is always
it is always smaller
is always smaller than
always smaller than one
as we have seen
we have seen above
does choose to attack
but does not surpass
does not surpass one
the game is summarized
game is summarized in
is summarized in figure
this is the classical
is the classical prisoner
the classical prisoner s
classical prisoner s dilemma
attack is the dominant
is the dominant strategy
using symbolic computation tools
chooses to attack or
to attack or not
we see that there
see that there is
that there is a
there is a single
the revenue of pool
is a single pair
a single pair of
single pair of values
pair of values for
of values for which
is larger when attacking
values for which equation
larger when attacking than
when attacking than when
attacking than when refraining
than when refraining from
when refraining from attack
holds for any feasible
and the same for
for any feasible choice
the same for xxx
any feasible choice of
same for xxx xxx
feasible choice of m
for xxx xxx pool
no attack xxx pool
numerical analysis a numerical
analysis a numerical analysis
a numerical analysis confirms
numerical analysis confirms these
analysis confirms these observations
we simulate the pool
simulate the pool game
the pool game for
pool game for a
game for a range
for a range of
a range of pool
range of pool sizes
for each choice of
each choice of pool
choice of pool sizes
we start the simulation
start the simulation when
the simulation when both
simulation when both pools
when both pools do
both pools do not
pools do not infiltrate
do not infiltrate each
not infiltrate each other
and the revenue densities
the revenue densities are
revenue densities are r
at each round one
each round one pool
round one pool chooses
one pool chooses its
pool chooses its optimal
chooses its optimal infiltration
its optimal infiltration rate
optimal infiltration rate based
infiltration rate based on
rate based on the
based on the pool
on the pool sizes
the pool sizes and
pool sizes and the
sizes and the rate
and the rate with
the rate with which
rate with which it
with which it is
which it is infiltrated
and we calculate the
we calculate the revenue
calculate the revenue after
the revenue after convergence
revenue after convergence with
after convergence with equation
recall the players in
the players in the
players in the pool
in the pool game
the pool game are
pool game are chosen
game are chosen with
are chosen with the
chosen with the round
with the round robin
the round robin policy
so the pools take
the pools take turns
and we let the
we let the game
let the game run
prisoner s dilemma for
the game run until
s dilemma for two
game run until convergence
dilemma for two pools
the results are illustrated
results are illustrated in
the revenue density of
are illustrated in figure
revenue density of each
density of each pool
of each pool is
each pool is determined
pool is determined by
is determined by the
determined by the decision
by the decision of
each run with some
the decision of both
run with some m
decision of both pools
of both pools whether
both pools whether to
pools whether to attack
whether to attack or
to attack or not
the dominant strategy of
dominant strategy of each
strategy of each player
values results in a
of each player is
results in a single
each player is to
in a single point
player is to attack
a single point in
single point in each
point in each graph
in each graph in
each graph in figure
however the payoff of
the payoff of both
payoff of both would
of both would be
both would be larger
would be larger if
be larger if they
larger if they both
we depict the infiltration
if they both refrain
depict the infiltration rates
they both refrain from
the infiltration rates of
both refrain from attacking
infiltration rates of both
rates of both pools
of both pools x
at equilibrium of this
equilibrium of this attack
when both pools attack
the revenue of each
revenue of each pool
of each pool is
each pool is smaller
pool is smaller than
is smaller than its
smaller than its revenue
b and the pools
than its revenue if
and the pools revenue
its revenue if neither
the pools revenue densities
revenue if neither pool
pools revenue densities r
if neither pool attacked
the game is not
game is not played
is not played once
for each choice of
where each pool can
each choice of m
each pool can change
pool can change its
can change its strategy
change its strategy between
its strategy between attack
strategy between attack and
between attack and no
the values of x
the pools can agree
to refrain from attacking
and in each round
in each round a
each round a pool
round a pool can
a pool can detect
pool can detect whether
can detect whether it
detect whether it is
whether it is being
it is being attacked
is being attacked and
being attacked and deduce
attacked and deduce that
and deduce that the
deduce that the other
that the other pool
are the points in
the other pool is
the points in each
other pool is violating
points in each of
pool is violating the
in each of the
is violating the agreement
each of the graphs
of the graphs with
the graphs with the
graphs with the respective
with the respective coordinates
cooperation where neither pool
where neither pool attacks
neither pool attacks is
j graphs we draw
pool attacks is a
graphs we draw a
attacks is a possible
we draw a border
is a possible stable
draw a border around
a possible stable state
a border around the
border around the region
around the region where
the region where there
region where there is
where there is no
attack by i in
by i in equilibrium
for the ri graphs
the ri graphs we
ri graphs we draw
graphs we draw a
we draw a line
draw a line around
a line around the
line around the region
around the region where
the region where the
region where the revenue
where the revenue is
the revenue is the
revenue is the same
is the same as
the same as in
same as in the
as in the no
despite the fact that
the fact that the
fact that the single
that the single nash
the single nash equilibrium
single nash equilibrium in
nash equilibrium in every
equilibrium in every round
in every round is
every round is to
round is to attack
we first observe that
first observe that only
observe that only in
that only in extreme
only in extreme cases
in extreme cases a
extreme cases a pool
case as an example
cases a pool does
as an example we
a pool does not
an example we take
pool does not attack
example we take again
does not attack its
we take again the
not attack its counterpart
take again the pool
again the pool sizes
the pool sizes shown
pool sizes shown in
sizes shown in figure
at equilibrium a pool
equilibrium a pool will
a pool will refrain
pool will refrain from
and study the case
will refrain from attacking
study the case where
refrain from attacking only
the case where the
from attacking only if
case where the two
attacking only if the
where the two largest
only if the other
the two largest pools
if the other pool
the other pool is
other pool is larger
pool is larger than
is larger than about
the optimal infiltration rates
of the total mining
out of the total
the total mining power
of the total system
the total system mining
total system mining power
we observe that a
observe that a pool
that a pool improves
a pool improves its
pool improves its revenue
improves its revenue compared
its revenue compared to
revenue compared to the
compared to the no
attacks scenario only when
scenario only when it
only when it controls
when it controls a
and the pools would
it controls a strict
the pools would lose
controls a strict majority
a strict majority of
strict majority of the
majority of the total
of the total mining
the total mining power
these are the small
are the small triangular
the small triangular regions
small triangular regions in
triangular regions in figures
compared to the no
in the rest of
the rest of the
rest of the space
the trapezoids in the
trapezoids in the figures
q i dentical p
the revenue of the
i dentical p ools
revenue of the pool
dentical p ools let
of the pool is
p ools let there
the pool is inferior
ools let there be
pool is inferior compared
let there be q
is inferior compared to
there be q pools
inferior compared to the
be q pools of
compared to the no
q pools of identical
pools of identical size
of identical size that
identical size that engage
size that engage in
that engage in block
engage in block withholding
in block withholding against
block withholding against one
withholding against one another
the prisoner s dilemma
prisoner s dilemma in
s dilemma in a
other miners neither attack
dilemma in a healthy
miners neither attack nor
in a healthy bitcoin
neither attack nor are
a healthy bitcoin environment
attack nor are being
nor are being attacked
where neither pool controls
neither pool controls a
in this case there
pool controls a strict
this case there exists
controls a strict majority
case there exists a
a strict majority of
there exists a symmetric
strict majority of the
exists a symmetric equilibrium
majority of the mining
of the mining power
both pools will earn
without loss of generality
pools will earn less
will earn less at
earn less at equilibrium
a step of pool
less at equilibrium than
at equilibrium than if
equilibrium than if both
than if both pools
if both pools ran
both pools ran without
pools ran without attacking
it controls its attack
controls its attack rates
its attack rates each
attack rates each of
rates each of the
each of the other
we can analyze in
of the other pools
can analyze in this
analyze in this case
in this case a
this case a game
and due to symmetry
case a game where
due to symmetry they
a game where each
to symmetry they are
game where each pool
symmetry they are all
where each pool chooses
they are all the
each pool chooses either
are all the same
pool chooses either to
chooses either to attack
either to attack and
to attack and optimize
attack and optimize its
and optimize its revenue
or to refrain from
to refrain from attacking
the attack rate of
attack rate of pool
without loss of generality
against any other pool
as we have seen
we have seen in
have seen in section
seen in section v
each of the other
of the other pools
the other pools can
other pools can attack
pools can attack its
can attack its peers
attack its peers as
its peers as well
can increase its revenue
all attack rates by
increase its revenue above
attack rates by all
rates by all attackers
by all attackers are
all attackers are identical
does attack but pool
the attack rate of
attack rate of any
rate of any pool
of any pool other
any pool other than
we denote the revenue
denote the revenue of
the revenue of pool
against any other pool
the exact value of
exact value of r
depends on the values
on the values of
the values of m
but it is always
it is always smaller
is always smaller than
the direct revenue of
always smaller than one
direct revenue of each
revenue of each of
of each of the
each of the other
as we have seen
of the other pools
we have seen above
similarly denote by r
does choose to attack
the revenue densities of
revenue densities of pool
but does not surpass
does not surpass one
the game is summarized
game is summarized in
is summarized in figure
are instantiated to mi
this is the classical
is the classical prisoner
the classical prisoner s
classical prisoner s dilemma
attack is the dominant
is the dominant strategy
chooses to attack or
to attack or not
the revenue of pool
is larger when attacking
larger when attacking than
when attacking than when
attacking than when refraining
than when refraining from
when refraining from attack
and the same for
the same for pool
at equilibrium of this
equilibrium of this attack
when both pools attack
the revenue of each
revenue of each pool
of each pool is
each pool is smaller
pool is smaller than
is smaller than its
smaller than its revenue
than its revenue if
its revenue if neither
revenue if neither pool
if neither pool attacked
the game is not
game is not played
is not played once
where each pool can
each pool can change
pool can change its
can change its strategy
change its strategy between
its strategy between attack
strategy between attack and
between attack and no
the pools can agree
to refrain from attacking
and in each round
in each round xxx
each round xxx xxx
round xxx xxx pool
no attack xxx pool
prisoner s dilemma for
s dilemma for two
dilemma for two pools
the revenue density of
revenue density of each
density of each pool
of each pool is
each pool is determined
pool is determined by
is determined by the
determined by the decision
by the decision of
the decision of both
decision of both pools
of both pools whether
both pools whether to
pools whether to attack
whether to attack or
to attack or not
the dominant strategy of
dominant strategy of each
strategy of each player
of each player is
each player is to
player is to attack
however the payoff of
the payoff of both
payoff of both would
of both would be
both would be larger
would be larger if
be larger if they
and solving we obtain
larger if they both
solving we obtain a
if they both refrain
we obtain a single
they both refrain from
obtain a single expression
both refrain from attacking
a single expression for
single expression for any
expression for any ri
a pool can detect
pool can detect whether
since in the symmetric
can detect whether it
in the symmetric case
detect whether it is
the symmetric case we
whether it is being
symmetric case we have
it is being attacked
case we have r
is being attacked and
being attacked and deduce
attacked and deduce that
and deduce that the
deduce that the other
that the other pool
the other pool is
other pool is violating
pool is violating the
is violating the agreement
the expression is shown
expression is shown in
is shown in equation
cooperation where neither pool
where neither pool attacks
neither pool attacks is
pool attacks is a
attacks is a possible
is a possible stable
a possible stable state
given any value of
any value of q
value of q and
of q and mi
despite the fact that
the fact that the
fact that the single
that the single nash
the single nash equilibrium
single nash equilibrium in
nash equilibrium in every
equilibrium in every round
the feasible range of
in every round is
feasible range of the
every round is to
range of the infiltration
round is to attack
of the infiltration rates
the infiltration rates is
case as an example
as an example we
an example we take
example we take again
we take again the
take again the pool
within this range ri
again the pool sizes
this range ri is
the pool sizes shown
range ri is continuous
pool sizes shown in
sizes shown in figure
and concave in x
and study the case
study the case where
the case where the
case where the two
where the two largest
the two largest pools
the optimal infiltration rates
the optimal point for
optimal point for pool
out of the total
of the total system
the total system mining
total system mining power
since the function is
the function is concave
and the pools would
function is concave the
the pools would lose
is concave the equation
concave the equation yields
the equation yields a
equation yields a single
yields a single feasible
a single feasible solution
which is a function
is a function of
a function of the
function of the attack
of the attack rates
the attack rates of
attack rates of the
rates of the other
of the other pools
compared to the no
q i dentical p
i dentical p ools
dentical p ools let
p ools let there
ools let there be
to find a symmetric
let there be q
find a symmetric equilibrium
there be q pools
be q pools of
q pools of identical
pools of identical size
of identical size that
identical size that engage
size that engage in
that engage in block
engage in block withholding
in block withholding against
block withholding against one
withholding against one another
other miners neither attack
miners neither attack nor
neither attack nor are
attack nor are being
nor are being attacked
in this case there
this case there exists
case there exists a
there exists a symmetric
exists a symmetric equilibrium
without loss of generality
and obtain a single
obtain a single feasible
a step of pool
a single feasible solution
the equilibrium infiltration rate
equilibrium infiltration rate and
infiltration rate and the
it controls its attack
rate and the matching
controls its attack rates
and the matching revenues
its attack rates each
the matching revenues are
attack rates each of
matching revenues are shown
rates each of the
revenues are shown in
each of the other
are shown in equation
of the other pools
and due to symmetry
due to symmetry they
to symmetry they are
symmetry they are all
they are all the
are all the same
the attack rate of
as in the two
attack rate of pool
against any other pool
the revenue at the
revenue at the symmetric
at the symmetric equilibrium
each of the other
the symmetric equilibrium is
of the other pools
symmetric equilibrium is inferior
the other pools can
equilibrium is inferior to
other pools can attack
is inferior to the
pools can attack its
inferior to the no
can attack its peers
attack its peers as
its peers as well
all attack rates by
attack rates by all
rates by all attackers
by all attackers are
all attackers are identical
up our analysis addresses
the attack rate of
our analysis addresses the
attack rate of any
analysis addresses the eventual
rate of any pool
addresses the eventual revenue
of any pool other
the eventual revenue of
any pool other than
eventual revenue of the
revenue of the pools
against any other pool
assuming the mining difficulty
the mining difficulty is
mining difficulty is set
difficulty is set based
is set based on
set based on the
based on the effective
on the effective mining
the effective mining power
not including mining power
including mining power used
mining power used for
power used for withholding
difficulty is updated only
is updated only periodically
updated only periodically every
the direct revenue of
direct revenue of each
revenue of each of
of each of the
each of the other
of the other pools
similarly denote by r
when mining power in
the revenue densities of
mining power in the
revenue densities of pool
power in the system
in the system is
the system is regularly
system is regularly increasing
which has been true
has been true for
been true for the
true for the majority
for the majority of
the majority of bitcoin
majority of bitcoin s
of bitcoin s history
are instantiated to mi
no adjustment may be
adjustment may be necessary
if an attacker purchases
an attacker purchases new
attacker purchases new mining
purchases new mining hardware
new mining hardware and
mining hardware and employs
hardware and employs it
and employs it directly
employs it directly for
it directly for block
directly for block withholding
this mining power is
mining power is never
power is never included
is never included in
never included in the
included in the difficulty
in the difficulty calculation
the difficulty calculation the
difficulty calculation the system
calculation the system is
the system is never
system is never aware
is never aware of
never aware of it
the difficulty is therefore
difficulty is therefore already
is therefore already correctly
therefore already correctly calculated
already correctly calculated and
correctly calculated and the
calculated and the attack
and the attack is
the attack is profitable
attack is profitable immediately
if the mining power
the mining power is
mining power is static
the attack becomes profitable
attack becomes profitable only
becomes profitable only after
profitable only after the
only after the bitcoin
after the bitcoin system
the bitcoin system has
bitcoin system has normalized
system has normalized the
has normalized the revenues
normalized the revenues by
the revenues by adjusting
revenues by adjusting difficulty
the revenue of an
revenue of an attacking
of an attacking pool
an attacking pool is
attacking pool is reduced
pool is reduced due
is reduced due to
reduced due to the
due to the reduction
to the reduction in
the reduction in block
reduction in block generation
in block generation of
block generation of both
generation of both the
of both the attacking
both the attacking and
the attacking and attacked
attacking and attacked pools
symmetric case we have
case we have r
the expression is shown
expression is shown in
is shown in equation
given any value of
any value of q
value of q and
of q and mi
the feasible range of
feasible range of the
range of the infiltration
of the infiltration rates
the infiltration rates is
within this range ri
this range ri is
range ri is continuous
and concave in x
the optimal point for
optimal point for pool
since the function is
the function is concave
function is concave the
is concave the equation
concave the equation yields
the equation yields a
equation yields a single
yields a single feasible
a single feasible solution
which is a function
is a function of
a function of the
function of the attack
of the attack rates
the attack rates of
attack rates of the
rates of the other
of the other pools
to find a symmetric
find a symmetric equilibrium
expression for ri in
for ri in a
ri in a system
in a system with
a system with pools
system with pools of
with pools of equal
pools of equal size
and obtain a single
obtain a single feasible
a single feasible solution
the equilibrium infiltration rate
equilibrium infiltration rate and
infiltration rate and the
rate and the matching
and the matching revenues
the matching revenues are
matching revenues are shown
revenues are shown in
are shown in equation
as in the two
the revenue at the
revenue at the symmetric
at the symmetric equilibrium
q mi q mi
the symmetric equilibrium is
symmetric equilibrium is inferior
equilibrium is inferior to
is inferior to the
inferior to the no
up our analysis addresses
our analysis addresses the
analysis addresses the eventual
addresses the eventual revenue
the eventual revenue of
eventual revenue of the
revenue of the pools
assuming the mining difficulty
the mining difficulty is
mining difficulty is set
difficulty is set based
is set based on
set based on the
based on the effective
on the effective mining
the effective mining power
not including mining power
including mining power used
mining power used for
power used for withholding
difficulty is updated only
is updated only periodically
updated only periodically every
when mining power in
mining power in the
power in the system
in the system is
the system is regularly
system is regularly increasing
which has been true
has been true for
been true for the
true for the majority
for the majority of
the majority of bitcoin
majority of bitcoin s
of bitcoin s history
no adjustment may be
adjustment may be necessary
q symmetric equilibrium values
symmetric equilibrium values for
equilibrium values for a
values for a system
for a system of
a system of q
if an attacker purchases
system of q pools
an attacker purchases new
of q pools of
attacker purchases new mining
q pools of equal
purchases new mining hardware
pools of equal sizes
new mining hardware and
mining hardware and employs
hardware and employs it
and employs it directly
employs it directly for
it directly for block
directly for block withholding
this mining power is
countermeasures in order to
mining power is never
in order to choose
power is never included
order to choose its
is never included in
to choose its optimal
never included in the
choose its optimal infiltration
included in the difficulty
its optimal infiltration rate
in the difficulty calculation
the difficulty calculation the
difficulty calculation the system
calculation the system is
a pool has to
the system is never
pool has to know
system is never aware
has to know the
is never aware of
to know the rate
never aware of it
know the rate at
the rate at which
rate at which it
at which it is
which it is attacked
the difficulty is therefore
difficulty is therefore already
is therefore already correctly
therefore already correctly calculated
and the revenue density
already correctly calculated and
the revenue density of
correctly calculated and the
revenue density of potential
calculated and the attack
density of potential victim
and the attack is
of potential victim pools
the attack is profitable
attack is profitable immediately
a pool can estimate
pool can estimate the
can estimate the rate
estimate the rate with
if the mining power
the rate with which
the mining power is
rate with which it
mining power is static
with which it is
which it is attacked
it is attacked by
is attacked by comparing
the attack becomes profitable
attacked by comparing the
attack becomes profitable only
by comparing the rates
becomes profitable only after
comparing the rates of
profitable only after the
the rates of partial
only after the bitcoin
rates of partial and
after the bitcoin system
of partial and full
the bitcoin system has
partial and full proofs
bitcoin system has normalized
and full proofs of
system has normalized the
full proofs of work
has normalized the revenues
proofs of work it
normalized the revenues by
of work it receives
the revenues by adjusting
work it receives from
revenues by adjusting difficulty
it receives from its
receives from its miners
as explained in section
the revenue of an
explained in section ii
revenue of an attacking
of an attacking pool
an attacking pool is
attacking pool is reduced
pool is reduced due
is reduced due to
reduced due to the
in order to estimate
due to the reduction
order to estimate the
to the reduction in
to estimate the revenue
the reduction in block
estimate the revenue densities
reduction in block generation
the revenue densities of
in block generation of
revenue densities of the
block generation of both
densities of the other
generation of both the
of the other pools
of both the attacking
both the attacking and
the attacking and attacked
attacking and attacked pools
a pool can use
pool can use one
can use one of
use one of two
one of two methods
pool knowledge and r
pools often publish this
often publish this data
publish this data to
this data to demonstrate
data to demonstrate their
to demonstrate their honesty
demonstrate their honesty to
their honesty to their
honesty to their miners
a pool can infiltrate
pool can infiltrate each
can infiltrate each of
infiltrate each of the
each of the other
of the other pools
the other pools with
other pools with some
pools with some nominal
with some nominal probing
some nominal probing mining
nominal probing mining power
probing mining power and
mining power and measure
power and measure the
and measure the revenue
measure the revenue density
the revenue density directly
revenue density directly by
density directly by monitoring
directly by monitoring the
by monitoring the probe
monitoring the probe s
the probe s rewards
probe s rewards from
s rewards from the
rewards from the pool
as in the case
in the case of
the case of classical
case of classical block
of classical block withholding
classical block withholding explained
block withholding explained in
withholding explained in section
explained in section ii
a pool might detect
pool might detect that
might detect that it
detect that it is
that it is being
it is being attacked
but cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners is
its miners is the
miners is the attacker
therefore a pool cannot
a pool cannot block
pool cannot block or
cannot block or punish
block or punish withholding
or punish withholding miners
various techniques can be
techniques can be used
can be used to
be used to encourage
used to encourage miners
to encourage miners to
encourage miners to submit
miners to submit full
to submit full blocks
a pool can pay
pool can pay a
can pay a bonus
pay a bonus for
a bonus for submitting
bonus for submitting a
for submitting a full
submitting a full proof
a full proof of
full proof of work
this would increase the
and solving we obtain
would increase the revenue
solving we obtain a
increase the revenue of
we obtain a single
the revenue of the
obtain a single expression
revenue of the miner
a single expression for
of the miner that
single expression for any
the miner that found
expression for any ri
miner that found a
that found a block
found a block while
a block while reducing
since in the in
block while reducing the
in the in order
while reducing the revenue
the in order to
reducing the revenue of
in order to choose
the revenue of the
order to choose its
revenue of the other
to choose its optimal
of the other miners
choose its optimal infiltration
the other miners from
its optimal infiltration rate
other miners from this
miners from this block
a pool has to
pool has to know
has to know the
to know the rate
know the rate at
the rate at which
rate at which it
at which it is
while the average revenue
which it is attacked
the average revenue of
average revenue of each
revenue of each miner
of each miner would
each miner would stay
and the revenue density
miner would stay the
the revenue density of
would stay the same
revenue density of potential
density of potential victim
of potential victim pools
small miners will suffer
miners will suffer from
will suffer from higher
suffer from higher variance
a pool can estimate
from higher variance in
pool can estimate the
higher variance in revenue
can estimate the rate
estimate the rate with
the rate with which
rate with which it
another approach is to
with which it is
approach is to introduce
which it is attacked
is to introduce a
it is attacked by
to introduce a joining
is attacked by comparing
introduce a joining fee
attacked by comparing the
a joining fee by
by comparing the rates
joining fee by paying
comparing the rates of
fee by paying new
the rates of partial
by paying new miners
rates of partial and
paying new miners less
of partial and full
new miners less for
partial and full proofs
miners less for their
and full proofs of
less for their work
full proofs of work
for their work until
proofs of work it
their work until they
of work it receives
work until they have
work it receives from
until they have established
it receives from its
they have established a
receives from its miners
have established a reputation
established a reputation with
a reputation with the
reputation with the pool
as explained in section
explained in section ii
miners that seek flexibility
that seek flexibility may
seek flexibility may not
flexibility may not accept
may not accept this
not accept this policy
accept this policy and
this policy and choose
in order to estimate
policy and choose another
order to estimate the
and choose another pool
to estimate the revenue
estimate the revenue densities
the revenue densities of
revenue densities of the
densities of the other
of the other pools
the pool can use
a pool can use
pool can use a
pool can use one
can use a honeypot
can use one of
use a honeypot trap
use one of two
a honeypot trap by
one of two methods
honeypot trap by sending
trap by sending the
by sending the miners
sending the miners tasks
the miners tasks which
miners tasks which it
tasks which it knows
which it knows will
it knows will result
knows will result in
will result in a
result in a full
in a full proof
a full proof of
full proof of work
if a miner fails
a miner fails to
miner fails to submit
fails to submit the
to submit the full
submit the full proof
the full proof of
full proof of work
proof of work it
of work it is
work it is tagged
it is tagged as
is tagged as an
tagged as an attacker
to prevent the attacker
prevent the attacker from
the attacker from learning
attacker from learning them
the honeypot tasks have
honeypot tasks have to
tasks have to be
have to be regularly
to be regularly refreshed
pools can also incorporate
can also incorporate out
also incorporate out of
incorporate out of band
out of band mechanisms
of band mechanisms to
band mechanisms to deter
mechanisms to deter attacks
such as verifying the
as verifying the identity
verifying the identity of
the identity of miners
identity of miners or
of miners or using
miners or using trusted
or using trusted computing
using trusted computing technologies
that assure no block
assure no block withholding
no block withholding is
block withholding is taking
withholding is taking place
this would require miners
would require miners to
require miners to use
miners to use specialized
to use specialized hardware
use specialized hardware and
specialized hardware and software
an overhead miners may
overhead miners may not
miners may not accept
there is no known
is no known silver
no known silver bullet
all these techniques reduce
these techniques reduce the
techniques reduce the pool
reduce the pool s
the pool s attractiveness
pool s attractiveness and
s attractiveness and deter
attractiveness and deter miners
block withholding recycling we
withholding recycling we assume
recycling we assume that
we assume that the
assume that the infiltrating
that the infiltrating miners
the infiltrating miners are
infiltrating miners are loyal
miners are loyal to
are loyal to the
loyal to the attacker
some of the pool
of the pool s
the pool s members
pool s members may
s members may be
members may be disloyal
may be disloyal infiltrators
when sending disloyal miners
sending disloyal miners to
disloyal miners to perform
miners to perform block
to perform block withholding
perform block withholding at
block withholding at other
withholding at other pools
an attacker takes a
attacker takes a significant
takes a significant risk
can use a loyal
use a loyal miner
a loyal miner w
loyal miner w to
miner w to infiltrate
w to infiltrate pool
thinking the miner is
the miner is loyal
miner is loyal to
is loyal to it
might use it to
expression for ri in
use it to attack
for ri in a
it to attack pool
ri in a system
in a system with
a system with pools
system with pools of
with pools of equal
pools of equal size
the miner m can
miner m can perform
m can perform honest
can perform honest mining
perform honest mining for
honest mining for pool
rather than withhold its
than withhold its blocks
and not return any
not return any revenue
return any revenue to
any revenue to pool
it will take its
will take its share
take its share of
its share of pool
which thinks the miner
thinks the miner is
the miner is loyal
miner is loyal to
is loyal to it
and deliver it back
deliver it back to
it back to pool
to avoid such a
avoid such a risk
a pool needs a
pool needs a sufficient
needs a sufficient number
a sufficient number of
sufficient number of verified
number of verified miners
of verified miners miners
verified miners miners that
miners miners that it
miners that it knows
that it knows to
it knows to be
knows to be loyal
q mi q mi
the optimal infiltration rate
optimal infiltration rate may
infiltration rate may be
rate may be as
may be as high
be as high as
of the pool size
but this is only
this is only in
is only in extreme
only in extreme cases
in extreme cases when
extreme cases when pools
cases when pools are
when pools are large
for practical pool sizes
a pool may need
pool may need up
may need up to
of its mining power
its mining power for
mining power for infiltration
pools typically have loyal
typically have loyal mining
have loyal mining power
loyal mining power either
mining power either run
power either run directly
either run directly by
run directly by the
directly by the pool
by the pool owners
the pool owners or
pool owners or sold
owners or sold as
or sold as a
sold as a service
as a service but
a service but run
service but run on
but run on the
run on the pool
on the pool owners
the pool owners hardware
q symmetric equilibrium values
however the size of
symmetric equilibrium values for
the size of this
equilibrium values for a
size of this mining
values for a system
of this mining power
for a system of
this mining power is
a system of q
mining power is considered
system of q pools
power is considered a
of q pools of
is considered a trade
q pools of equal
considered a trade secret
pools of equal sizes
a trade secret and
trade secret and is
secret and is not
and is not published
often publish this data
publish this data to
this data to demonstrate
data to demonstrate their
to demonstrate their honesty
demonstrate their honesty to
their honesty to their
honesty to their miners
block withholding in practice
withholding in practice long
in practice long term
practice long term block
long term block withholding
term block withholding attacks
block withholding attacks are
withholding attacks are difficult
attacks are difficult to
are difficult to hide
since miners using an
miners using an attacked
using an attacked pool
an attacked pool would
attacked pool would notice
pool would notice the
would notice the reduced
notice the reduced revenue
the reduced revenue density
such attacks are rarely
attacks are rarely reported
and we can therefore
we can therefore conclude
can therefore conclude that
therefore conclude that they
conclude that they are
that they are indeed
they are indeed rare
a recent exception is
recent exception is an
exception is an attack
is an attack on
an attack on the
attack on the eligius
on the eligius pool
the eligius pool performed
eligius pool performed in
pool performed in may
performed in may and
in may and june
a pool can infiltrate
pool can infiltrate each
can infiltrate each of
infiltrate each of the
each of the other
of the other pools
the other pools with
other pools with some
pools with some nominal
with some nominal probing
some nominal probing mining
nominal probing mining power
probing mining power and
mining power and measure
power and measure the
and measure the revenue
measure the revenue density
the revenue density directly
revenue density directly by
density directly by monitoring
directly by monitoring the
by monitoring the probe
monitoring the probe s
the probe s rewards
probe s rewards from
s rewards from the
rewards from the pool
block withholding recycling we
withholding recycling we assume
recycling we assume that
bitcoin before detecting the
we assume that the
before detecting the attack
assume that the infiltrating
that the infiltrating miners
the infiltrating miners are
infiltrating miners are loyal
at which point payouts
miners are loyal to
which point payouts to
are loyal to the
point payouts to the
loyal to the attacker
payouts to the attackers
to the attackers were
the attackers were blocked
the attackers continued the
attackers continued the attack
some of the pool
of the pool s
the pool s members
pool s members may
s members may be
members may be disloyal
may be disloyal infiltrators
when sending disloyal miners
sending disloyal miners to
disloyal miners to perform
miners to perform block
to perform block withholding
more bitcoin before realizing
perform block withholding at
bitcoin before realizing they
block withholding at other
before realizing they were
withholding at other pools
realizing they were not
they were not receiving
were not receiving their
not receiving their payout
an attacker takes a
attacker takes a significant
takes a significant risk
the reasons the attack
reasons the attack was
the attack was so
attack was so easily
was so easily subverted
so easily subverted is
easily subverted is the
subverted is the limited
is the limited efforts
can use a loyal
the limited efforts of
use a loyal miner
limited efforts of the
a loyal miner w
efforts of the attackers
loyal miner w to
of the attackers to
miner w to infiltrate
the attackers to hide
w to infiltrate pool
attackers to hide themselves
they have only used
have only used two
only used two payout
used two payout addresses
two payout addresses to
payout addresses to collect
addresses to collect their
to collect their payouts
thinking the miner is
the miner is loyal
miner is loyal to
is loyal to it
and so it was
so it was possible
it was possible for
might use it to
was possible for the
use it to attack
possible for the alert
it to attack pool
for the alert pool
the alert pool manager
alert pool manager to
pool manager to cluster
manager to cluster the
to cluster the attacking
the miner m can
cluster the attacking miners
miner m can perform
the attacking miners and
m can perform honest
attacking miners and obtain
can perform honest mining
miners and obtain a
perform honest mining for
and obtain a statistically
honest mining for pool
obtain a statistically significant
a statistically significant proof
statistically significant proof of
significant proof of their
proof of their wrongdoing
rather than withhold its
than withhold its blocks
it is unknown whether
is unknown whether this
and not return any
unknown whether this was
not return any revenue
whether this was a
return any revenue to
this was a classical
any revenue to pool
was a classical block
a classical block withholding
classical block withholding attack
with the goal of
the goal of sabotage
it will take its
or a more elaborate
will take its share
a more elaborate scheme
take its share of
its share of pool
to verify the effectiveness
verify the effectiveness of
the effectiveness of block
effectiveness of block withholding
of block withholding for
block withholding for profit
which thinks the miner
thinks the miner is
the miner is loyal
miner is loyal to
is loyal to it
and deliver it back
deliver it back to
it back to pool
to avoid such a
avoid such a risk
implemented an experimental bitcoin
an experimental bitcoin test
experimental bitcoin test network
a pool needs a
bitcoin test network and
pool needs a sufficient
test network and demonstrated
needs a sufficient number
network and demonstrated the
a sufficient number of
and demonstrated the practicality
sufficient number of verified
demonstrated the practicality of
number of verified miners
the practicality of the
of verified miners miners
practicality of the attack
verified miners miners that
miners miners that it
miners that it knows
that it knows to
it knows to be
knows to be loyal
bitcoin s health large
the optimal infiltration rate
s health large pools
optimal infiltration rate may
health large pools hinder
infiltration rate may be
large pools hinder bitcoin
rate may be as
pools hinder bitcoin s
may be as high
hinder bitcoin s distributed
be as high as
bitcoin s distributed nature
s distributed nature as
distributed nature as they
nature as they put
as they put a
they put a lot
put a lot of
a lot of mining
lot of mining power
of mining power in
mining power in the
of the pool size
power in the hands
in the hands of
the hands of a
hands of a few
of a few pool
but this is only
a few pool managers
this is only in
is only in extreme
only in extreme cases
in extreme cases when
extreme cases when pools
cases when pools are
when pools are large
this has been mostly
has been mostly addressed
been mostly addressed by
mostly addressed by community
for practical pool sizes
addressed by community pressure
by community pressure on
community pressure on miners
pressure on miners to
on miners to avoid
miners to avoid forming
to avoid forming large
avoid forming large pools
a pool may need
pool may need up
may need up to
of its mining power
its mining power for
mining power for infiltration
however such recommendations had
such recommendations had only
recommendations had only had
had only had limited
only had limited success
pools typically have loyal
and mining is still
typically have loyal mining
mining is still dominated
have loyal mining power
is still dominated by
loyal mining power either
still dominated by a
mining power either run
dominated by a small
power either run directly
by a small number
either run directly by
a small number of
run directly by the
small number of large
directly by the pool
number of large pools
by the pool owners
the pool owners or
pool owners or sold
owners or sold as
as a characteristic example
or sold as a
sold as a service
as a service but
a service but run
in the period of
service but run on
the period of november
but run on the
run on the pool
on the pool owners
the pool owners hardware
three pools generated over
of the proofs of
the proofs of work
however the size of
the size of this
size of this mining
of this mining power
this mining power is
mining power is considered
power is considered a
is considered a trade
considered a trade secret
a trade secret and
trade secret and is
secret and is not
and is not published
the fact that block
fact that block withholding
countermeasures as in the
that block withholding attacks
as in the case
block withholding attacks are
in the case of
withholding attacks are rarely
the case of classical
attacks are rarely observed
case of classical block
are rarely observed may
of classical block withholding
rarely observed may indicate
classical block withholding explained
observed may indicate that
block withholding explained in
may indicate that the
withholding explained in section
indicate that the active
explained in section ii
that the active pools
the active pools have
active pools have reached
pools have reached an
have reached an implicit
reached an implicit or
an implicit or explicit
implicit or explicit agreement
a pool might detect
or explicit agreement not
pool might detect that
explicit agreement not to
might detect that it
agreement not to attack
detect that it is
not to attack one
that it is being
to attack one another
it is being attacked
but cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners is
an attacked pool cannot
its miners is the
attacked pool cannot detect
miners is the attacker
pool cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners are
therefore a pool cannot
its miners are attacking
a pool cannot block
miners are attacking it
pool cannot block or
cannot block or punish
block or punish withholding
or punish withholding miners
let alone which pool
alone which pool controls
which pool controls the
pool controls the miners
various techniques can be
at some point a
techniques can be used
some point a pool
can be used to
point a pool might
be used to encourage
a pool might miscalculate
used to encourage miners
pool might miscalculate and
to encourage miners to
might miscalculate and decide
encourage miners to submit
miscalculate and decide to
miners to submit full
and decide to try
to submit full blocks
decide to try to
to try to increase
try to increase its
to increase its revenue
a pool can pay
pool can pay a
can pay a bonus
pay a bonus for
one pool might be
a bonus for submitting
pool might be enough
bonus for submitting a
might be enough to
for submitting a full
be enough to break
submitting a full proof
enough to break the
a full proof of
to break the agreement
full proof of work
possibly leading to a
leading to a constant
this would increase the
to a constant rate
would increase the revenue
a constant rate of
increase the revenue of
constant rate of attacks
the revenue of the
rate of attacks among
revenue of the miner
of attacks among pools
of the miner that
attacks among pools and
the miner that found
among pools and a
miner that found a
pools and a reduced
that found a block
and a reduced revenue
found a block while
a block while reducing
block while reducing the
while reducing the revenue
if open pools reach
reducing the revenue of
open pools reach a
the revenue of the
pools reach a state
revenue of the other
reach a state where
of the other miners
a state where their
the other miners from
state where their revenue
other miners from this
where their revenue density
miners from this block
their revenue density is
revenue density is reduced
density is reduced due
is reduced due to
reduced due to attacks
while the average revenue
the average revenue of
average revenue of each
revenue of each miner
of each miner would
miners will leave them
each miner would stay
will leave them in
miner would stay the
leave them in favor
would stay the same
them in favor of
in favor of other
favor of other available
of other available options
small miners will suffer
miners will suffer from
will suffer from higher
suffer from higher variance
miners of sufficient size
from higher variance in
of sufficient size can
higher variance in revenue
sufficient size can mine
size can mine solo
another approach is to
smaller miners can form
approach is to introduce
miners can form private
is to introduce a
can form private pools
to introduce a joining
form private pools with
introduce a joining fee
private pools with closed
a joining fee by
pools with closed access
joining fee by paying
fee by paying new
by paying new miners
paying new miners less
limited to trusted participants
new miners less for
miners less for their
less for their work
for their work until
such a change may
their work until they
a change may be
work until they have
change may be in
until they have established
may be in favor
they have established a
be in favor of
have established a reputation
in favor of bitcoin
established a reputation with
favor of bitcoin as
a reputation with the
of bitcoin as a
reputation with the pool
bitcoin as a whole
since they require such
miners that seek flexibility
they require such intimate
that seek flexibility may
require such intimate trust
seek flexibility may not
flexibility may not accept
may not accept this
not accept this policy
private pools are likely
accept this policy and
pools are likely to
this policy and choose
are likely to be
policy and choose another
likely to be smaller
and choose another pool
and form a fine
form a fine grained
a fine grained distribution
fine grained distribution of
the pool can use
grained distribution of mining
pool can use a
can use a honeypot
distribution of mining power
use a honeypot trap
of mining power with
a honeypot trap by
mining power with many
honeypot trap by sending
power with many small
trap by sending the
with many small pools
by sending the miners
many small pools and
sending the miners tasks
small pools and solo
the miners tasks which
pools and solo miners
miners tasks which it
tasks which it knows
which it knows will
it knows will result
knows will result in
will result in a
result in a full
in a full proof
a full proof of
full proof of work
a pool may engage
pool may engage in
may engage in an
engage in an attack
in an attack against
an attack against another
attack against another pool
against another pool not
another pool not to
if a miner fails
pool not to increase
a miner fails to
not to increase its
miner fails to submit
to increase its absolute
fails to submit the
increase its absolute revenue
to submit the full
submit the full proof
the full proof of
full proof of work
proof of work it
of work it is
but rather to attract
work it is tagged
rather to attract miners
it is tagged as
to attract miners by
is tagged as an
attract miners by temporarily
tagged as an attacker
miners by temporarily increasing
by temporarily increasing its
temporarily increasing its revenue
increasing its revenue relative
to prevent the attacker
its revenue relative to
prevent the attacker from
revenue relative to a
the attacker from learning
relative to a competing
attacker from learning them
to a competing pool
the honeypot tasks have
honeypot tasks have to
tasks have to be
recent work has investigated
have to be regularly
work has investigated the
to be regularly refreshed
has investigated the motivation
investigated the motivation of
the motivation of pools
motivation of pools to
of pools to utilize
pools to utilize part
to utilize part of
pools can also incorporate
utilize part of their
can also incorporate out
part of their resources
also incorporate out of
of their resources towards
incorporate out of band
their resources towards sabotage
out of band mechanisms
resources towards sabotage attacks
of band mechanisms to
towards sabotage attacks against
band mechanisms to deter
sabotage attacks against each
mechanisms to deter attacks
attacks against each other
such as verifying the
as verifying the identity
verifying the identity of
the identity of miners
identity of miners or
of miners or using
miners or using trusted
or using trusted computing
using trusted computing technologies
that assure no block
assure no block withholding
no block withholding is
block withholding is taking
withholding is taking place
this would require miners
the model of those
would require miners to
model of those works
require miners to use
of those works is
miners to use specialized
those works is different
to use specialized hardware
works is different from
use specialized hardware and
is different from the
specialized hardware and software
different from the pool
from the pool game
the pool game model
pool game model in
an overhead miners may
game model in two
overhead miners may not
model in two major
miners may not accept
in two major ways
two major ways a
major ways a sabotage
ways a sabotage attack
a sabotage attack does
sabotage attack does not
attack does not transfer
does not transfer revenue
there is no known
not transfer revenue from
is no known silver
transfer revenue from victim
no known silver bullet
revenue from victim to
from victim to attacker
all these techniques reduce
these techniques reduce the
techniques reduce the pool
and migrating miners switch
reduce the pool s
migrating miners switch to
the pool s attractiveness
miners switch to less
pool s attractiveness and
switch to less attacked
s attractiveness and deter
to less attacked pools
attractiveness and deter miners
changing pool sizes and
pool sizes and hence
sizes and hence revenues
and hence revenues until
hence revenues until convergence
block withholding in practice
withholding in practice long
in practice long term
practice long term block
the model is parametrized
long term block withholding
model is parametrized by
term block withholding attacks
is parametrized by the
block withholding attacks are
parametrized by the cost
withholding attacks are difficult
by the cost of
attacks are difficult to
the cost of the
are difficult to hide
cost of the attack
of the attack and
the attack and by
attack and by the
and by the mobility
since miners using an
by the mobility of
miners using an attacked
the mobility of the
using an attacked pool
mobility of the miners
an attacked pool would
attacked pool would notice
pool would notice the
would notice the reduced
notice the reduced revenue
and the analysis demonstrates
the reduced revenue density
the analysis demonstrates that
analysis demonstrates that when
demonstrates that when considering
that when considering only
when considering only sabotage
considering only sabotage attacks
only sabotage attacks there
sabotage attacks there are
such attacks are rarely
attacks there are regions
attacks are rarely reported
there are regions where
are regions where no
and we can therefore
we can therefore conclude
attack is the best
can therefore conclude that
is the best strategy
therefore conclude that they
conclude that they are
that they are indeed
they are indeed rare
the miner s dilemma
miner s dilemma is
s dilemma is therefore
dilemma is therefore not
a recent exception is
is therefore not manifested
recent exception is an
therefore not manifested in
exception is an attack
not manifested in that
is an attack on
manifested in that model
an attack on the
attack on the eligius
on the eligius pool
the eligius pool performed
eligius pool performed in
pool competition for miners
pool performed in may
competition for miners is
performed in may and
for miners is an
in may and june
miners is an incentive
is an incentive in
an incentive in and
incentive in and of
in and of its
and of its own
of its own for
its own for mutual
own for mutual attacks
and a pool may
a pool may therefore
pool may therefore choose
may therefore choose to
therefore choose to perform
choose to perform block
to perform block withholding
perform block withholding even
block withholding even if
withholding even if its
even if its revenue
if its revenue would
its revenue would increase
revenue would increase only
would increase only after
increase only after the
only after the next
after the next difficult
the next difficult adjustment
the two models are
two models are therefore
models are therefore complementary
bitcoin before detecting the
before detecting the attack
the analysis of their
analysis of their combination
of their combination is
their combination is left
at which point payouts
combination is left for
which point payouts to
is left for future
point payouts to the
left for future work
payouts to the attackers
to the attackers were
the attackers were blocked
the attackers continued the
attackers continued the attack
we assumed in our
assumed in our analysis
in our analysis that
our analysis that pools
analysis that pools do
that pools do not
pools do not charge
more bitcoin before realizing
do not charge fees
bitcoin before realizing they
not charge fees from
before realizing they were
charge fees from their
realizing they were not
fees from their members
they were not receiving
from their members since
were not receiving their
their members since such
not receiving their payout
members since such fees
since such fees are
such fees are typically
fees are typically nominal
the reasons the attack
reasons the attack was
the attack was so
attack was so easily
was so easily subverted
so easily subverted is
easily subverted is the
subverted is the limited
is the limited efforts
the limited efforts of
limited efforts of the
efforts of the attackers
of the attackers to
the attackers to hide
attackers to hide themselves
of a pool s
a pool s revenue
they have only used
have only used two
only used two payout
used two payout addresses
two payout addresses to
payout addresses to collect
addresses to collect their
to collect their payouts
and so it was
so it was possible
it was possible for
was possible for the
possible for the alert
the model can be
for the alert pool
model can be extended
the alert pool manager
can be extended to
alert pool manager to
be extended to include
pool manager to cluster
extended to include pools
manager to cluster the
to include pools fees
to cluster the attacking
cluster the attacking miners
the attacking miners and
attacking miners and obtain
fees would add a
miners and obtain a
would add a friction
and obtain a statistically
add a friction element
obtain a statistically significant
a friction element to
a statistically significant proof
friction element to the
statistically significant proof of
element to the flow
significant proof of their
to the flow of
proof of their wrongdoing
the flow of revenue
flow of revenue among
of revenue among infiltrated
revenue among infiltrated and
among infiltrated and infiltrating
it is unknown whether
infiltrated and infiltrating pools
is unknown whether this
unknown whether this was
whether this was a
this was a classical
was a classical block
a classical block withholding
classical block withholding attack
with the goal of
the goal of sabotage
would change to take
change to take into
to take into account
or a more elaborate
take into account a
a more elaborate scheme
into account a pool
account a pool fee
a pool fee of
pool fee of f
fee of f pp
to verify the effectiveness
of f pp ri
verify the effectiveness of
the effectiveness of block
effectiveness of block withholding
of block withholding for
block withholding for profit
implemented an experimental bitcoin
an experimental bitcoin test
experimental bitcoin test network
bitcoin test network and
test network and demonstrated
network and demonstrated the
and demonstrated the practicality
demonstrated the practicality of
the practicality of the
practicality of the attack
bitcoin s health large
s health large pools
health large pools hinder
large pools hinder bitcoin
pools hinder bitcoin s
hinder bitcoin s distributed
bitcoin s distributed nature
s distributed nature as
distributed nature as they
nature as they put
as they put a
they put a lot
put a lot of
a lot of mining
lot of mining power
of mining power in
mining power in the
power in the hands
in the hands of
the hands of a
hands of a few
of a few pool
a few pool managers
this has been mostly
has been mostly addressed
been mostly addressed by
mostly addressed by community
addressed by community pressure
by community pressure on
community pressure on miners
pressure on miners to
on miners to avoid
miners to avoid forming
to avoid forming large
avoid forming large pools
a pool with a
pool with a fee
with a fee of
a fee of f
fee of f is
of f is a
f is a less
is a less attractive
a less attractive target
less attractive target for
attractive target for block
target for block withholding
since the attacker s
however such recommendations had
the attacker s revenue
such recommendations had only
attacker s revenue is
recommendations had only had
s revenue is reduced
had only had limited
revenue is reduced by
only had limited success
is reduced by f
and mining is still
however it is also
mining is still dominated
it is also less
is still dominated by
is also less attractive
still dominated by a
also less attractive for
dominated by a small
less attractive for miners
by a small number
attractive for miners in
a small number of
for miners in general
small number of large
number of large pools
trading off the two
off the two for
as a characteristic example
the two for best
two for best protection
for best protection is
best protection is left
in the period of
protection is left for
the period of november
is left for future
left for future work
as part of the
part of the treatment
of the treatment of
the treatment of the
treatment of the miner
r elated w ork
elated w ork a
the block withholding attack
block withholding attack the
three pools generated over
withholding attack the danger
attack the danger of
the danger of a
danger of a block
of a block withholding
a block withholding attack
block withholding attack is
withholding attack is as
attack is as old
is as old as
as old as bitcoin
old as bitcoin pools
of the proofs of
the proofs of work
the attack was described
attack was described by
was described by rosenfeld
the fact that block
fact that block withholding
that block withholding attacks
block withholding attacks are
withholding attacks are rarely
attacks are rarely observed
are rarely observed may
rarely observed may indicate
observed may indicate that
may indicate that the
indicate that the active
that the active pools
the active pools have
active pools have reached
as pools were becoming
pools have reached an
pools were becoming a
have reached an implicit
were becoming a dominant
reached an implicit or
becoming a dominant player
an implicit or explicit
a dominant player in
implicit or explicit agreement
dominant player in the
or explicit agreement not
player in the bitcoin
explicit agreement not to
in the bitcoin world
agreement not to attack
not to attack one
to attack one another
the paper described the
paper described the standard
described the standard attack
used by a miner
an attacked pool cannot
by a miner to
attacked pool cannot detect
a miner to sabotage
pool cannot detect which
miner to sabotage a
cannot detect which of
to sabotage a pool
detect which of its
sabotage a pool at
which of its miners
a pool at the
of its miners are
pool at the cost
its miners are attacking
at the cost of
miners are attacking it
the cost of reducing
cost of reducing its
of reducing its own
let alone which pool
reducing its own revenue
alone which pool controls
which pool controls the
pool controls the miners
a more general view
more general view of
at some point a
general view of fairness
some point a pool
view of fairness in
point a pool might
of fairness in proof
a pool might miscalculate
fairness in proof of
pool might miscalculate and
in proof of work
might miscalculate and decide
proof of work schemes
miscalculate and decide to
of work schemes was
and decide to try
work schemes was discussed
decide to try and
schemes was discussed in
to try and increase
try and increase its
and increase its revenue
one pool might be
pool might be enough
might be enough to
be enough to break
enough to break the
to break the agreement
possibly leading to a
leading to a constant
to a constant rate
a constant rate of
constant rate of attacks
rate of attacks among
of attacks among pools
attacks among pools and
among pools and a
pools and a reduced
and a reduced revenue
in the context of
the context of the
if open pools reach
context of the hashcash
open pools reach a
of the hashcash system
pools reach a state
reach a state where
a state where their
state where their revenue
where their revenue density
their revenue density is
revenue density is reduced
density is reduced due
is reduced due to
reduced due to attacks
miners will leave them
will leave them in
leave them in favor
them in favor of
in favor of other
early work did not
favor of other available
work did not address
of other available options
did not address the
not address the possibility
address the possibility of
the possibility of pools
miners of sufficient size
possibility of pools infiltrating
of sufficient size can
of pools infiltrating other
sufficient size can mine
pools infiltrating other pools
size can mine solo
infiltrating other pools for
other pools for block
pools for block withholding
smaller miners can form
miners can form private
can form private pools
form private pools with
private pools with closed
pools with closed access
limited to trusted participants
such a change may
a change may be
change may be in
may be in favor
be in favor of
in favor of bitcoin
favor of bitcoin as
of bitcoin as a
bitcoin as a whole
experimentally demonstrate that block
since they require such
demonstrate that block withholding
they require such intimate
that block withholding can
require such intimate trust
block withholding can increase
withholding can increase the
can increase the attacker
increase the attacker s
private pools are likely
the attacker s revenue
pools are likely to
are likely to be
likely to be smaller
they do not address
do not address the
not address the question
and form a fine
address the question of
form a fine grained
the question of mutual
a fine grained distribution
question of mutual attacks
fine grained distribution of
grained distribution of mining
distribution of mining power
of mining power with
mining power with many
power with many small
with many small pools
many small pools and
small pools and solo
pools and solo miners
have recently noted that
recently noted that a
noted that a pool
that a pool can
a pool can increase
pool can increase its
can increase its overall
a pool may engage
increase its overall revenue
pool may engage in
its overall revenue with
may engage in an
overall revenue with block
engage in an attack
revenue with block withholding
in an attack against
with block withholding if
an attack against another
block withholding if all
attack against another pool
withholding if all other
against another pool not
if all other mining
another pool not to
all other mining is
pool not to increase
other mining is performed
not to increase its
mining is performed by
to increase its absolute
is performed by honest
increase its absolute revenue
performed by honest pools
but rather to attract
we consider the general
rather to attract miners
consider the general case
to attract miners by
the general case where
attract miners by temporarily
general case where not
miners by temporarily increasing
case where not all
by temporarily increasing its
where not all mining
temporarily increasing its revenue
not all mining is
increasing its revenue relative
all mining is performed
its revenue relative to
mining is performed through
revenue relative to a
is performed through public
relative to a competing
performed through public pools
to a competing pool
and analyze situations where
analyze situations where pools
recent work has investigated
situations where pools can
work has investigated the
where pools can attack
has investigated the motivation
pools can attack one
investigated the motivation of
can attack one another
the motivation of pools
motivation of pools to
of pools to utilize
pools to utilize part
the discrepancy between the
to utilize part of
discrepancy between the calculations
utilize part of their
between the calculations of
part of their resources
of their resources towards
their resources towards sabotage
resources towards sabotage attacks
towards sabotage attacks against
sabotage attacks against each
attacks against each other
for the special case
the special case analyzed
special case analyzed there
case analyzed there and
analyzed there and our
there and our results
and our results can
our results can be
results can be explained
can be explained by
be explained by the
explained by the strong
by the strong approximations
the strong approximations in
strong approximations in that
approximations in that work
we calculate exactly how
calculate exactly how infiltrating
exactly how infiltrating miners
the model of those
how infiltrating miners reduce
model of those works
infiltrating miners reduce the
of those works is
miners reduce the revenue
those works is different
reduce the revenue density
works is different from
the revenue density of
is different from the
revenue density of the
different from the pool
density of the infiltrated
from the pool game
of the infiltrated pool
the pool game model
pool game model in
game model in two
model in two major
in two major ways
two major ways a
major ways a sabotage
temporary block withholding in
ways a sabotage attack
block withholding in the
a sabotage attack does
withholding in the block
sabotage attack does not
in the block withholding
attack does not transfer
the block withholding attack
does not transfer revenue
block withholding attack discussed
not transfer revenue from
withholding attack discussed in
transfer revenue from victim
attack discussed in this
revenue from victim to
discussed in this work
from victim to attacker
in this work the
this work the withheld
work the withheld blocks
the withheld blocks are
withheld blocks are never
and migrating miners switch
blocks are never published
migrating miners switch to
miners switch to less
switch to less attacked
to less attacked pools
blocks can be withheld
changing pool sizes and
can be withheld temporarily
pool sizes and hence
sizes and hence revenues
and hence revenues until
hence revenues until convergence
not following the bitcoin
following the bitcoin protocol
the model is parametrized
to improve an attacker
model is parametrized by
improve an attacker s
is parametrized by the
an attacker s revenue
parametrized by the cost
by the cost of
the cost of the
cost of the attack
of the attack and
a miner or a
the attack and by
miner or a pool
attack and by the
or a pool can
and by the mobility
a pool can perform
by the mobility of
pool can perform a
the mobility of the
can perform a selfish
mobility of the miners
perform a selfish mining
a selfish mining attack
and the analysis demonstrates
the analysis demonstrates that
analysis demonstrates that when
demonstrates that when considering
that when considering only
when considering only sabotage
considering only sabotage attacks
only sabotage attacks there
sabotage attacks there are
attacks there are regions
there are regions where
are regions where no
with selfish mining the
attack is the best
selfish mining the attacker
is the best strategy
mining the attacker increases
the attacker increases its
attacker increases its revenue
the miner s dilemma
increases its revenue by
miner s dilemma is
its revenue by temporarily
s dilemma is therefore
revenue by temporarily withholding
dilemma is therefore not
by temporarily withholding its
is therefore not manifested
temporarily withholding its blocks
therefore not manifested in
withholding its blocks and
not manifested in that
its blocks and publishing
manifested in that model
blocks and publishing them
and publishing them in
publishing them in response
them in response to
pool competition for miners
in response to block
competition for miners is
response to block publication
for miners is an
to block publication by
miners is an incentive
block publication by other
is an incentive in
publication by other pools
an incentive in and
by other pools and
incentive in and of
other pools and miners
in and of its
and of its own
of its own for
its own for mutual
own for mutual attacks
this attack is independent
attack is independent of
is independent of the
and a pool may
independent of the block
a pool may therefore
of the block withholding
pool may therefore choose
the block withholding attack
may therefore choose to
block withholding attack we
therefore choose to perform
withholding attack we discuss
choose to perform block
attack we discuss here
to perform block withholding
we discuss here and
perform block withholding even
discuss here and the
block withholding even if
here and the two
withholding even if its
and the two can
even if its revenue
the two can be
if its revenue would
two can be performed
its revenue would increase
can be performed in
revenue would increase only
be performed in concert
would increase only after
increase only after the
only after the next
after the next difficult
the next difficult adjustment
an attacker can also
attacker can also perform
can also perform a
also perform a double
perform a double spending
the two models are
a double spending attack
two models are therefore
double spending attack as
models are therefore complimentary
spending attack as follows
the analysis of their
analysis of their combination
of their combination is
their combination is left
combination is left for
is left for future
left for future work
he intentionally generates two
intentionally generates two conflicting
generates two conflicting transactions
we assumed in our
places one in a
assumed in our analysis
one in a block
in our analysis that
in a block it
our analysis that pools
a block it withholds
analysis that pools do
that pools do not
pools do not charge
do not charge fees
and publishes the other
not charge fees from
publishes the other transaction
charge fees from their
fees from their members
from their members since
their members since such
after the recipient sees
members since such fees
the recipient sees the
since such fees are
recipient sees the published
such fees are typically
sees the published transaction
fees are typically nominal
the attacker publishes the
attacker publishes the withheld
publishes the withheld block
the withheld block to
withheld block to revoke
block to revoke the
to revoke the former
revoke the former transaction
of a pool s
this attack is performed
a pool s revenue
attack is performed by
is performed by miners
performed by miners or
by miners or pools
miners or pools against
or pools against service
pools against service providers
against service providers that
service providers that accept
providers that accept bitcoin
and it not directly
it not directly related
not directly related to
directly related to this
related to this work
the model can be
model can be extended
can be extended to
be extended to include
extended to include pools
to include pools fees
block withholding defense most
withholding defense most crypto
fees would add a
currencies use a proof
would add a friction
add a friction element
a friction element to
friction element to the
element to the flow
to the flow of
the flow of revenue
work architecture similar to
flow of revenue among
architecture similar to bitcoin
of revenue among infiltrated
revenue among infiltrated and
among infiltrated and infiltrating
infiltrated and infiltrating pools
where finding proof of
finding proof of work
proof of work is
of work is the
work is the result
is the result of
the result of solution
result of solution guessing
of solution guessing and
solution guessing and checking
would change to take
change to take into
all of the algorithms
to take into account
of the algorithms we
take into account a
the algorithms we are
into account a pool
algorithms we are aware
account a pool fee
we are aware of
a pool fee of
are aware of are
pool fee of f
aware of are susceptible
fee of f pp
of are susceptible to
of f pp ri
are susceptible to the
susceptible to the block
to the block withholding
the block withholding attack
as in all of
in all of them
all of them the
of them the miner
them the miner can
the miner can check
miner can check whether
can check whether she
check whether she found
whether she found a
she found a full
found a full or
a full or a
full or a partial
or a partial proof
a partial proof of
partial proof of work
prominent examples are litecoin
it is possible to
is possible to use
possible to use an
to use an alternative
use an alternative proof
an alternative proof of
alternative proof of work
proof of work mechanism
of work mechanism in
work mechanism in which
mechanism in which miners
in which miners would
which miners would not
miners would not be
would not be able
not be able to
be able to distinguish
able to distinguish partial
to distinguish partial from
distinguish partial from full
partial from full proofs
from full proofs of
full proofs of work
a pool with a
pool with a fee
with a fee of
a fee of f
fee of f is
of f is a
f is a less
is a less attractive
a less attractive target
less attractive target for
attractive target for block
target for block withholding
since the attacker s
the attacker s revenue
attacker s revenue is
s revenue is reduced
revenue is reduced by
is reduced by f
however it is also
it is also less
is also less attractive
also less attractive for
less attractive for miners
attractive for miners in
for miners in general
trading off the two
off the two for
the two for best
two for best protection
for best protection is
best protection is left
protection is left for
is left for future
left for future work
as part of the
part of the treatment
of the treatment of
the treatment of the
treatment of the miner
such a solution could
a solution could reduce
solution could reduce or
could reduce or remove
reduce or remove the
or remove the danger
remove the danger of
the danger of block
danger of block withholding
r elated w ork
elated w ork a
the block withholding attack
making such a change
block withholding attack the
such a change may
withholding attack the danger
a change may not
attack the danger of
change may not be
the danger of a
may not be in
danger of a block
not be in the
of a block withholding
be in the interest
a block withholding attack
in the interest of
block withholding attack is
the interest of the
withholding attack is as
interest of the community
attack is as old
is as old as
as old as bitcoin
old as bitcoin pools
or even its potential
the attack was described
attack was described by
was described by rosenfeld
could lead to a
lead to a reduction
to a reduction of
a reduction of pool
reduction of pool sizes
as explained in section
explained in section ix
decentralized pools although most
pools although most pools
although most pools use
most pools use a
pools use a centralized
use a centralized manager
a prominent exception is
as pools were becoming
prominent exception is p
pools were becoming a
were becoming a dominant
becoming a dominant player
a dominant player in
pool a distributed pool
dominant player in the
a distributed pool architecture
player in the bitcoin
distributed pool architecture with
in the bitcoin world
pool architecture with no
architecture with no central
with no central manager
the paper described the
paper described the standard
described the standard attack
used by a miner
by a miner to
a miner to sabotage
miner to sabotage a
to sabotage a pool
sabotage a pool at
a pool at the
pool at the cost
at the cost of
the cost of reducing
but the question of
cost of reducing its
the question of whether
of reducing its own
question of whether a
reducing its own revenue
of whether a pool
whether a pool is
a pool is run
pool is run by
a more general view
is run by a
more general view of
run by a centralized
general view of fairness
by a centralized manager
view of fairness in
a centralized manager or
of fairness in proof
centralized manager or with
fairness in proof of
manager or with a
in proof of work
or with a decentralized
proof of work schemes
with a decentralized architecture
of work schemes was
a decentralized architecture is
work schemes was discussed
decentralized architecture is almost
schemes was discussed in
architecture is almost immaterial
is almost immaterial for
almost immaterial for the
immaterial for the attack
for the attack we
the attack we describe
pool group can be
group can be infiltrated
can be infiltrated and
be infiltrated and attacked
pool code can be
code can be changed
can be changed to
be changed to support
in the context of
changed to support attacks
the context of the
to support attacks against
context of the hashcash
support attacks against other
of the hashcash system
attacks against other pools
on the other hand
pool can be used
can be used by
be used by groups
used by groups of
by groups of miners
groups of miners to
early work did not
of miners to easily
work did not address
miners to easily form
did not address the
to easily form closed
not address the possibility
easily form closed pools
address the possibility of
the possibility of pools
possibility of pools infiltrating
of pools infiltrating other
these do not accept
pools infiltrating other pools
do not accept untrusted
infiltrating other pools for
not accept untrusted miners
other pools for block
pools for block withholding
and are therefore protected
are therefore protected against
therefore protected against block
protected against block withholding
c onclusion we explored
onclusion we explored a
we explored a block
explored a block withholding
a block withholding attack
block withholding attack among
withholding attack among bitcoin
attack among bitcoin mining
experimentally demonstrate that block
among bitcoin mining pools
demonstrate that block withholding
bitcoin mining pools an
that block withholding can
mining pools an attack
block withholding can increase
pools an attack that
withholding can increase the
an attack that is
can increase the attacker
attack that is possible
increase the attacker s
that is possible in
the attacker s revenue
is possible in any
possible in any similar
in any similar system
any similar system that
they do not address
similar system that rewards
do not address the
system that rewards for
not address the question
that rewards for proof
address the question of
rewards for proof of
the question of mutual
for proof of work
question of mutual attacks
such systems are gaining
systems are gaining popularity
running most digital currencies
most digital currencies and
digital currencies and related
currencies and related services
we observe that no
have recently noted that
recently noted that a
noted that a pool
that a pool can
a pool can increase
attacks is not a
pool can increase its
is not a nash
can increase its overall
not a nash equilibrium
increase its overall revenue
its overall revenue with
overall revenue with block
revenue with block withholding
if none of the
with block withholding if
none of the other
block withholding if all
of the other pools
withholding if all other
the other pools attack
if all other mining
all other mining is
other mining is performed
mining is performed by
is performed by honest
a pool can increase
performed by honest pools
pool can increase its
can increase its revenue
increase its revenue by
its revenue by attacking
we consider the general
revenue by attacking the
consider the general case
by attacking the others
the general case where
general case where not
case where not all
where not all mining
not all mining is
when two pools can
all mining is performed
two pools can attack
mining is performed through
pools can attack each
is performed through public
can attack each other
performed through public pools
they face a version
and analyze situations where
face a version of
analyze situations where pools
a version of the
situations where pools can
where pools can attack
pools can attack one
version of the prisoner
can attack one another
of the prisoner s
the prisoner s dilemma
the discrepancy between the
discrepancy between the calculations
if one pool chooses
between the calculations of
one pool chooses to
pool chooses to attack
the victim s revenue
victim s revenue is
s revenue is reduced
and it can retaliate
it can retaliate by
can retaliate by attacking
and our results for
retaliate by attacking and
our results for the
by attacking and increase
results for the special
attacking and increase its
for the special case
and increase its revenue
the special case analyzed
special case analyzed there
case analyzed there can
analyzed there can be
there can be explained
can be explained by
be explained by the
explained by the strong
by the strong approximations
the strong approximations in
strong approximations in that
approximations in that work
at nash equilibrium both
nash equilibrium both earn
equilibrium both earn less
both earn less than
earn less than they
less than they would
than they would have
they would have if
would have if neither
have if neither attacked
we calculate exactly how
calculate exactly how infiltrating
exactly how infiltrating miners
how infiltrating miners reduce
with multiple pools of
infiltrating miners reduce the
multiple pools of equal
miners reduce the revenue
pools of equal size
reduce the revenue density
of equal size a
the revenue density of
equal size a similar
revenue density of the
size a similar situation
density of the infiltrated
a similar situation arises
of the infiltrated pool
similar situation arises with
situation arises with a
arises with a symmetric
with a symmetric equilibrium
temporary block withholding in
the fact that block
block withholding in the
fact that block withholding
withholding in the block
that block withholding is
in the block withholding
block withholding is not
the block withholding attack
withholding is not common
block withholding attack discussed
is not common may
withholding attack discussed in
not common may be
attack discussed in this
common may be explained
discussed in this work
may be explained by
in this work the
be explained by modeling
this work the withheld
explained by modeling the
work the withheld blocks
by modeling the attack
the withheld blocks are
modeling the attack decisions
withheld blocks are never
the attack decisions as
blocks are never published
attack decisions as an
decisions as an iterative
as an iterative prisoner
an iterative prisoner s
iterative prisoner s dilemma
blocks can be withheld
can be withheld temporarily
we argue that the
not following the bitcoin
argue that the situation
following the bitcoin protocol
that the situation is
the situation is unstable
situation is unstable since
is unstable since the
unstable since the attack
to improve an attacker
since the attack can
improve an attacker s
the attack can be
an attacker s revenue
attack can be done
can be done anonymously
a miner or a
miner or a pool
or a pool can
a pool can perform
pool can perform a
can perform a selfish
one pool may decide
perform a selfish mining
pool may decide to
a selfish mining attack
may decide to increase
decide to increase its
to increase its revenue
increase its revenue and
its revenue and drag
revenue and drag the
and drag the others
drag the others to
the others to attack
others to attack as
to attack as well
ending with a reduced
with a reduced revenue
a reduced revenue for
reduced revenue for all
with selfish mining the
selfish mining the attacker
mining the attacker increases
the inferior revenue would
the attacker increases its
inferior revenue would push
attacker increases its revenue
revenue would push miners
increases its revenue by
would push miners to
its revenue by temporarily
push miners to join
revenue by temporarily withholding
miners to join private
by temporarily withholding its
to join private pools
temporarily withholding its blocks
withholding its blocks and
its blocks and publishing
blocks and publishing them
which can verify that
and publishing them in
can verify that their
publishing them in response
verify that their registered
them in response to
that their registered miners
in response to block
their registered miners do
response to block publication
registered miners do not
to block publication by
miners do not withhold
block publication by other
do not withhold blocks
publication by other pools
by other pools and
other pools and miners
this would lead to
would lead to smaller
lead to smaller pools
this attack is independent
attack is independent of
is independent of the
and so ultimately to
independent of the block
so ultimately to a
of the block withholding
ultimately to a better
the block withholding attack
to a better environment
block withholding attack we
a better environment for
withholding attack we discuss
better environment for bitcoin
attack we discuss here
environment for bitcoin as
we discuss here and
for bitcoin as a
discuss here and the
bitcoin as a whole
here and the two
and the two can
the two can be
two can be performed
can be performed in
be performed in concert
for their valuable advice
an attacker can also
attacker can also perform
can also perform a
the author is grateful
also perform a double
author is grateful to
perform a double spending
is grateful to ken
a double spending attack
grateful to ken birman
double spending attack as
spending attack as follows
emin gu n sirer
and the paper shepherd
he intentionally generates two
the paper shepherd joseph
intentionally generates two conflicting
paper shepherd joseph bonneau
generates two conflicting transactions
places one in a
one in a block
in a block it
a block it withholds
and publishes the other
publishes the other transaction
after the recipient sees
the recipient sees the
recipient sees the published
sees the published transaction
the attacker publishes the
attacker publishes the withheld
publishes the withheld block
the withheld block to
withheld block to revoke
block to revoke the
to revoke the former
revoke the former transaction
peer electronic cash system
this attack is performed
attack is performed by
is performed by miners
performed by miners or
by miners or pools
miners or pools against
or pools against service
pools against service providers
against service providers that
service providers that accept
providers that accept bitcoin
and it not directly
it not directly related
not directly related to
directly related to this
related to this work
block withholding defense most
withholding defense most crypto
currencies use a proof
ebay s paypal unit
s paypal unit to
work architecture similar to
paypal unit to start
architecture similar to bitcoin
unit to start accepting
to start accepting bitcoin
start accepting bitcoin payments
where finding proof of
finding proof of work
proof of work is
of work is the
work is the result
is the result of
the result of solution
result of solution guessing
of solution guessing and
solution guessing and checking
all of the algorithms
of the algorithms we
the algorithms we are
algorithms we are aware
we are aware of
are aware of are
aware of are susceptible
of are susceptible to
are susceptible to the
susceptible to the block
to the block withholding
the block withholding attack
as in all of
in all of them
all of them the
of them the miner
them the miner can
the miner can check
miner can check whether
can check whether she
check whether she found
whether she found a
google adds bitcoin currency
she found a full
adds bitcoin currency conversion
found a full or
bitcoin currency conversion to
a full or a
currency conversion to search
full or a partial
or a partial proof
a partial proof of
partial proof of work
prominent examples are litecoin
it is possible to
is possible to use
possible to use an
to use an alternative
use an alternative proof
an alternative proof of
alternative proof of work
proof of work mechanism
of work mechanism in
work mechanism in which
mechanism in which miners
in which miners would
which miners would not
miners would not be
would not be able
not be able to
be able to distinguish
able to distinguish partial
to distinguish partial from
distinguish partial from full
partial from full proofs
from full proofs of
full proofs of work
such a solution could
a solution could reduce
solution could reduce or
could reduce or remove
reduce or remove the
or remove the danger
remove the danger of
the danger of block
danger of block withholding
making such a change
such a change may
a change may not
change may not be
may not be in
not be in the
be in the interest
in the interest of
the interest of the
interest of the community
or even its potential
could lead to a
lead to a reduction
to a reduction of
a reduction of pool
reduction of pool sizes
as explained in section
explained in section ix
decentralized pools although most
pools although most pools
although most pools use
most pools use a
pools use a centralized
use a centralized manager
a prominent exception is
prominent exception is p
pool a distributed pool
a distributed pool architecture
distributed pool architecture with
pool architecture with no
architecture with no central
with no central manager
but the question of
the question of whether
question of whether a
of whether a pool
whether a pool is
a pool is run
pool is run by
is run by a
run by a centralized
by a centralized manager
a centralized manager or
centralized manager or with
manager or with a
or with a decentralized
with a decentralized architecture
a decentralized architecture is
decentralized architecture is almost
architecture is almost immaterial
is almost immaterial for
almost immaterial for the
immaterial for the attack
repurposing bitcoin work for
for the attack we
bitcoin work for data
the attack we describe
work for data preservation
in proceedings of the
proceedings of the ieee
of the ieee symposium
the ieee symposium on
ieee symposium on security
pool group can be
symposium on security and
group can be infiltrated
on security and privacy
can be infiltrated and
be infiltrated and attacked
pool code can be
code can be changed
can be changed to
be changed to support
changed to support attacks
to support attacks against
support attacks against other
attacks against other pools
on the other hand
pool can be used
can be used by
be used by groups
used by groups of
by groups of miners
groups of miners to
of miners to easily
miners to easily form
to easily form closed
easily form closed pools
namecoin dns dotbit project
these do not accept
do not accept untrusted
not accept untrusted miners
and are therefore protected
are therefore protected against
therefore protected against block
protected against block withholding
c onclusion we explored
onclusion we explored a
we explored a block
explored a block withholding
a block withholding attack
block withholding attack among
withholding attack among bitcoin
attack among bitcoin mining
among bitcoin mining pools
bitcoin mining pools an
mining pools an attack
pools an attack that
an attack that is
attack that is possible
that is possible in
is possible in any
possible in any similar
in any similar system
any similar system that
similar system that rewards
system that rewards for
that rewards for proof
rewards for proof of
for proof of work
such systems are gaining
systems are gaining popularity
running most digital currencies
most digital currencies and
digital currencies and related
currencies and related services
a next generation smart
next generation smart contract
we observe that no
attacks is not a
is not a nash
not a nash equilibrium
if none of the
none of the other
of the other pools
the other pools attack
a pool can increase
pool can increase its
can increase its revenue
increase its revenue by
its revenue by attacking
revenue by attacking the
by attacking the others
when two pools can
two pools can attack
pools can attack each
can attack each other
they face a version
face a version of
a version of the
version of the prisoner
of the prisoner s
the prisoner s dilemma
if one pool chooses
one pool chooses to
pool chooses to attack
the victim s revenue
victim s revenue is
s revenue is reduced
and it can retaliate
it can retaliate by
can retaliate by attacking
retaliate by attacking and
by attacking and increase
attacking and increase its
and increase its revenue
at nash equilibrium both
nash equilibrium both earn
equilibrium both earn less
both earn less than
earn less than they
less than they would
than they would have
they would have if
would have if neither
have if neither attacked
with multiple pools of
multiple pools of equal
pools of equal size
of equal size a
equal size a similar
size a similar situation
a similar situation arises
similar situation arises with
situation arises with a
arises with a symmetric
with a symmetric equilibrium
analysis of bitcoin pooled
of bitcoin pooled mining
bitcoin pooled mining reward
the fact that block
pooled mining reward systems
fact that block withholding
that block withholding is
block withholding is not
withholding is not common
is not common may
not common may be
common may be explained
may be explained by
be explained by modeling
explained by modeling the
by modeling the attack
modeling the attack decisions
the attack decisions as
attack decisions as an
decisions as an iterative
as an iterative prisoner
an iterative prisoner s
iterative prisoner s dilemma
we argue that the
argue that the situation
that the situation is
the situation is unstable
situation is unstable since
is unstable since the
unstable since the attack
since the attack can
the attack can be
attack can be done
can be done anonymously
one pool may decide
pool may decide to
may decide to increase
decide to increase its
to increase its revenue
increase its revenue and
its revenue and drag
revenue and drag the
and drag the others
drag the others to
the others to attack
others to attack as
to attack as well
ending with a reduced
with a reduced revenue
a reduced revenue for
reduced revenue for all
the inferior revenue would
inferior revenue would push
revenue would push miners
would push miners to
push miners to join
miners to join private
to join private pools
which can verify that
can verify that their
verify that their registered
that their registered miners
their registered miners do
registered miners do not
miners do not withhold
do not withhold blocks
this would lead to
would lead to smaller
lead to smaller pools
and so ultimately to
so ultimately to a
ultimately to a better
to a better environment
a better environment for
better environment for bitcoin
environment for bitcoin as
for bitcoin as a
bitcoin as a whole
for their valuable advice
the author is grateful
author is grateful to
is grateful to ken
grateful to ken birman
research perspectives on bitcoin
perspectives on bitcoin and
on bitcoin and secondgeneration
bitcoin and secondgeneration cryptocurrencies
in ieee symposium on
ieee symposium on security
symposium on security and
emin gu n sirer
on security and privacy
and the paper shepherd
the paper shepherd joseph
paper shepherd joseph bonneau
peer electronic cash system
ebay s paypal unit
s paypal unit to
paypal unit to start
unit to start accepting
to start accepting bitcoin
start accepting bitcoin payments
google adds bitcoin currency
adds bitcoin currency conversion
bitcoin currency conversion to
currency conversion to search
information propagation in the
propagation in the bitcoin
in the bitcoin network
th ieee international conference
ieee international conference on
international conference on peer
bitcoin and the age
and the age of
the age of bespoke
age of bespoke silicon
in proceedings of the
international conference on compilers
architectures and synthesis for
and synthesis for embedded
synthesis for embedded systems
into the bitcoin mines
repurposing bitcoin work for
bitcoin work for data
work for data preservation
in proceedings of the
proceedings of the ieee
of the ieee symposium
the ieee symposium on
ieee symposium on security
symposium on security and
on security and privacy
namecoin dns dotbit project
a next generation smart
next generation smart contract
analysis of bitcoin pooled
of bitcoin pooled mining
bitcoin pooled mining reward
pooled mining reward systems
research perspectives on bitcoin
perspectives on bitcoin and
on bitcoin and secondgeneration
bitcoin and secondgeneration cryptocurrencies
in ieee symposium on
ieee symposium on security
symposium on security and
on security and privacy
how a mining monopoly
a mining monopoly can
mining monopoly can attack
monopoly can attack bitcoin
information propagation in the
propagation in the bitcoin
in the bitcoin network
majority is not enough
bitcoin mining is vulnerable
th ieee international conference
ieee international conference on
international conference on peer
in financial cryptography and
financial cryptography and data
cryptography and data security
bitcoin and the age
and the age of
the age of bespoke
age of bespoke silicon
in proceedings of the
international conference on compilers
architectures and synthesis for
and synthesis for embedded
synthesis for embedded systems
cooperative equilibrium for supergames
the review of economic
review of economic studies
into the bitcoin mines
term competition a game
io bitcoin mining pool
how a mining monopoly
a mining monopoly can
mining monopoly can attack
monopoly can attack bitcoin
kncminer bitcoin mining cloud
bitcoin mining cloud mining
majority is not enough
bitcoin mining is vulnerable
in financial cryptography and
financial cryptography and data
cryptography and data security
an authorization architecture for
authorization architecture for trustworthy
architecture for trustworthy computing
in proceedings of the
proceedings of the twenty
third acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
cooperative equilibrium for supergames
the review of economic
review of economic studies
term competition a game
on power splitting games
power splitting games in
splitting games in distributed
games in distributed computation
the case of bitcoin
case of bitcoin pooled
of bitcoin pooled mining
weekly bitcoin network statistics
io bitcoin mining pool
theoretic analysis of ddos
analysis of ddos attacks
of ddos attacks against
ddos attacks against bitcoin
attacks against bitcoin mining
against bitcoin mining pools
in workshop on bitcoin
workshop on bitcoin research
when bitcoin mining pools
bitcoin mining pools run
mining pools run dry
in workshop on bitcoin
workshop on bitcoin research
comparison of mining pools
kncminer bitcoin mining cloud
bitcoin mining cloud mining
comparison of mining pools
hashcash amortizable publicly auditable
amortizable publicly auditable cost
an authorization architecture for
authorization architecture for trustworthy
architecture for trustworthy computing
in proceedings of the
proceedings of the twenty
third acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
hashcash a denial of
a denial of service
denial of service counter
on subversive miner strategies
subversive miner strategies and
miner strategies and block
strategies and block withholding
and block withholding attack
block withholding attack in
withholding attack in bitcoin
attack in bitcoin digital
in bitcoin digital currency
how to disincentivize large
to disincentivize large bitcoin
disincentivize large bitcoin mining
large bitcoin mining pools
on power splitting games
power splitting games in
splitting games in distributed
games in distributed computation
the case of bitcoin
case of bitcoin pooled
of bitcoin pooled mining
weekly bitcoin network statistics
theoretic analysis of ddos
analysis of ddos attacks
of ddos attacks against
ddos attacks against bitcoin
attacks against bitcoin mining
against bitcoin mining pools
in workshop on bitcoin
workshop on bitcoin research
when bitcoin mining pools
bitcoin mining pools run
mining pools run dry
in workshop on bitcoin
workshop on bitcoin research
comparison of mining pools
comparison of mining pools
hashcash amortizable publicly auditable
amortizable publicly auditable cost
hashcash a denial of
a denial of service
denial of service counter
on subversive miner strategies
subversive miner strategies and
miner strategies and block
strategies and block withholding
and block withholding attack
block withholding attack in
withholding attack in bitcoin
attack in bitcoin digital
in bitcoin digital currency
how incentivize large bitcoin
incentivize large bitcoin mining
large bitcoin mining http
transparent error correction for
error correction for lambda
correction for lambda networks
for lambda networks mahesh
lambda networks mahesh balakrishnan
abstract the global network
the global network of
global network of datacenters
network of datacenters is
of datacenters is emerging
datacenters is emerging as
is emerging as an
emerging as an important
as an important distributed
an important distributed systems
important distributed systems paradigm
distributed systems paradigm commodity
systems paradigm commodity clusters
paradigm commodity clusters running
commodity clusters running high
speed lambda networks across
lambda networks across hundreds
networks across hundreds of
across hundreds of milliseconds
hundreds of milliseconds of
of milliseconds of network
milliseconds of network latency
packet loss on long
haul networks can cripple
networks can cripple application
can cripple application performance
cripple application performance a
application performance a loss
performance a loss rate
a loss rate of
is sufficient to reduce
sufficient to reduce tcp
ip throughput by an
throughput by an order
by an order of
an order of magnitude
order of magnitude on
of magnitude on a
maelstrom is an edge
is an edge appliance
an edge appliance that
edge appliance that masks
appliance that masks packet
that masks packet loss
masks packet loss transparently
packet loss transparently and
loss transparently and quickly
transparently and quickly from
and quickly from inter
aggregating traffic for high
speed encoding and using
encoding and using a
and using a new
using a new forward
a new forward error
new forward error correction
forward error correction scheme
error correction scheme to
correction scheme to handle
scheme to handle bursty
to handle bursty loss
introduction the emergence of
the emergence of commodity
emergence of commodity clusters
of commodity clusters and
commodity clusters and datacenters
clusters and datacenters has
and datacenters has enabled
datacenters has enabled a
has enabled a new
enabled a new class
a new class of
new class of globally
class of globally distributed
of globally distributed highperformance
globally distributed highperformance applications
distributed highperformance applications that
highperformance applications that coordinate
applications that coordinate over
that coordinate over vast
coordinate over vast geographical
over vast geographical distances
a financial firm s
financial firm s new
firm s new york
s new york city
new york city datacenter
york city datacenter may
city datacenter may receive
datacenter may receive real
time updates from a
updates from a stock
from a stock exchange
a stock exchange in
stock exchange in switzerland
conduct financial transactions with
financial transactions with banks
transactions with banks in
with banks in asia
cache data in london
data in london for
in london for locality
london for locality and
for locality and mirror
locality and mirror it
and mirror it to
mirror it to kansas
it to kansas for
to kansas for disaster
to interconnect these bandwidth
hungry datacenters across the
datacenters across the globe
organizations are increasingly deploying
are increasingly deploying private
increasingly deploying private lambda
deploying private lambda networks
raw bandwidth is ubiquitous
bandwidth is ubiquitous and
is ubiquitous and cheaply
ubiquitous and cheaply available
and cheaply available in
cheaply available in the
available in the form
in the form of
the form of existing
form of existing dark
of existing dark fiber
running and maintaining high
free networks over this
networks over this fiber
over this fiber is
this fiber is difficult
fiber is difficult and
is difficult and expensive
capacity optical links are
optical links are almost
links are almost never
are almost never congested
they drop packets for
drop packets for numerous
packets for numerous reasons
for numerous reasons dirty
for example and in
example and in different
and in different patterns
ranging from singleton drops
from singleton drops to
singleton drops to extended
drops to extended bursts
congestion loss has been
loss has been observed
has been observed on
been observed on long
haul networks as well
ms w n s
w n s e
n s e figure
example lambda network tional
lambda network tional lambdarail
as has its crippling
has its crippling effect
its crippling effect on
crippling effect on commodity
effect on commodity protocols
motivating research into loss
resistant data transfer protocols
Thread 0 results back
conservative flow control mechanisms
flow control mechanisms designed
control mechanisms designed to
mechanisms designed to deal
designed to deal with
to deal with the
deal with the systematic
with the systematic congestion
the systematic congestion of
systematic congestion of the
congestion of the commodity
of the commodity internet
the commodity internet react
commodity internet react too
internet react too sharply
react too sharply to
too sharply to ephemeral
sharply to ephemeral loss
to ephemeral loss on
ephemeral loss on over
provisioned links a single
links a single packet
a single packet loss
single packet loss in
packet loss in ten
loss in ten thousand
in ten thousand is
ten thousand is enough
thousand is enough to
is enough to reduce
enough to reduce tcp
ip throughput to a
throughput to a third
to a third over
a third over a
and one in a
one in a thousand
in a thousand drops
a thousand drops it
thousand drops it by
drops it by an
it by an order
by an order of
an order of magnitude
1247 time applications are impacted
applications are impacted by
are impacted by the
impacted by the reliance
by the reliance of
the reliance of reliability
reliance of reliability mechanisms
of reliability mechanisms on
reliability mechanisms on acknowledgments
mechanisms on acknowledgments and
on acknowledgments and retransmissions
limiting the latency of
the latency of packet
latency of packet recovery
of packet recovery to
packet recovery to at
recovery to at least
to at least the
at least the round
least the round trip
the round trip time
if delivery is sequenced
each lost packet acts
lost packet acts as
packet acts as a
1203 acts as a virtual
as a virtual road
block in the fifo
in the fifo channel
the fifo channel until
fifo channel until it
channel until it is
until it is recovered
resistant protocols is not
protocols is not an
is not an alternative
not an alternative in
an alternative in corporate
alternative in corporate datacenters
where standardization is the
standardization is the key
is the key to
the key to low
key to low and
to low and predictable
low and predictable maintenance
and predictable maintenance costs
nei this work was
this work was supported
work was supported in
was supported in part
supported in part by
in part by grants
part by grants from
by grants from afosr
1221 ther is eliminating loss
is eliminating loss events
eliminating loss events on
loss events on a
events on a network
on a network that
a network that could
network that could nsf
that could nsf and
could nsf and intel
nsf and intel corporation
span thousands of miles
there is a need
is a need to
a need to link
need to link loss
side appliance locations of
appliance locations of packet
locations of packet loss
of packet loss receive
side appliance receiver buffer
appliance receiver buffer overflow
1259 local recovery receiving end
kernel code no dropped
code no dropped packets
no dropped packets figure
maelstrom communication path mask
communication path mask loss
path mask loss on
mask loss on the
loss on the link
because recovery delays for
recovery delays for lost
delays for lost packets
for lost packets translate
lost packets translate into
packets translate into dramatic
translate into dramatic reductions
into dramatic reductions in
dramatic reductions in application
because applications and os
1323 applications and os networking
and os networking stacks
os networking stacks in
networking stacks in commodity
stacks in commodity datacenters
in commodity datacenters cannot
commodity datacenters cannot be
datacenters cannot be rewritten
cannot be rewritten from
be rewritten from scratch
is a promising solution
a promising solution for
promising solution for reliability
solution for reliability over
for reliability over long
packet recovery latency is
recovery latency is independent
latency is independent of
is independent of the
independent of the rtt
of the rtt of
the rtt of the
rtt of the link
while fec codes have
fec codes have been
1240 codes have been used
have been used for
been used for decades
used for decades within
for decades within link
faster commodity processors have
commodity processors have enabled
processors have enabled packet
level fec at end
1213 end fec is very
fec is very attractive
is very attractive for
very attractive for inter
easy to deploy and
to deploy and customize
and does not require
does not require specialized
not require specialized equipment
require specialized equipment in
specialized equipment in the
equipment in the network
in the network linking
the network linking the
network linking the datacenters
host fec has two
fec has two major
has two major issues
two major issues first
it s not transparent
requiring modification of the
modification of the end
1314 it s not necessarily
s not necessarily rapid
fec works best over
works best over high
stable traffic rates and
traffic rates and performs
rates and performs poorly
and performs poorly if
performs poorly if the
poorly if the data
if the data rate
the data rate in
data rate in the
rate in the channel
in the channel is
the channel is low
channel is low and
is low and sporadic
as in a single
in a single end
1233 we present the maelstrom
present the maelstrom error
the maelstrom error correction
maelstrom error correction appliance
error correction appliance a
correction appliance a rack
appliance a rack of
a rack of proxies
rack of proxies residing
of proxies residing between
proxies residing between a
residing between a datacenter
between a datacenter and
a datacenter and its
datacenter and its wan
and its wan link
maelstrom encodes fec packets
encodes fec packets over
fec packets over traffic
packets over traffic flowing
over traffic flowing through
traffic flowing through it
flowing through it and
through it and routes
it and routes them
and routes them to
routes them to a
them to a corresponding
to a corresponding appliance
a corresponding appliance at
1239 corresponding appliance at the
appliance at the destination
at the destination datacenter
which decodes them and
decodes them and recovers
them and recovers lost
and recovers lost data
maelstrom is completely transparent
is completely transparent it
completely transparent it does
transparent it does not
it does not require
does not require modification
not require modification of
require modification of end

host software and is
software and is agnostic
and is agnostic to
is agnostic to the
agnostic to the network
to the network connecting
the network connecting the
network connecting the datacenter
it eliminates the dependence
eliminates the dependence of
the dependence of fec
dependence of fec recovery
of fec recovery latency
fec recovery latency on
recovery latency on the
latency on the data
on the data rate
the data rate in
data rate in any
rate in any single
in any single node
node channel by encoding
channel by encoding over
by encoding over the
encoding over the aggregated
over the aggregated traffic
the aggregated traffic leaving
aggregated traffic leaving the
traffic leaving the datacenter
maelstrom uses a new
uses a new encoding
a new encoding scheme
new encoding scheme called
encoding scheme called layered
scheme called layered interleaving
designed especially for time
sensitive packet recovery in
packet recovery in the
recovery in the presence
in the presence of
the presence of bursty
presence of bursty loss
the contributions of this
contributions of this paper
of this paper are
this paper are as
paper are as follows
end fec for long
distance communication between datacenters
and argue that the
argue that the rate
that the rate sensitivity
the rate sensitivity of
rate sensitivity of fec
sensitivity of fec codes
of fec codes and
fec codes and the
codes and the opacity
and the opacity of
the opacity of their
opacity of their implementations
of their implementations present
their implementations present major
implementations present major obstacles
present major obstacles to
major obstacles to their
obstacles to their usage
a gateway appliance that
gateway appliance that transparently
appliance that transparently aggregates
that transparently aggregates traffic
transparently aggregates traffic and
aggregates traffic and encodes
traffic and encodes over
and encodes over the
encodes over the resulting
over the resulting high
we describe layered interleaving
a new fec scheme
new fec scheme used
fec scheme used by
scheme used by maelstrom
used by maelstrom where
by maelstrom where for
maelstrom where for constant
where for constant encoding
for constant encoding overhead
constant encoding overhead the
encoding overhead the latency
overhead the latency of
the latency of packet
latency of packet recovery
of packet recovery degrades
packet recovery degrades gracefully
recovery degrades gracefully as
degrades gracefully as losses
gracefully as losses get
as losses get burstier
we discuss implementation considerations
we built two versions
built two versions of
two versions of maelstrom
one runs in user
runs in user mode
while the other runs
the other runs within
other runs within the
runs within the linux
within the linux kernel
we evaluate maelstrom on
evaluate maelstrom on emulab
and show that it
show that it provides
that it provides near
it provides near lossless
provides near lossless tcp
ip throughput and latency
throughput and latency over
and latency over lossy
latency over lossy links
and recovers packets with
recovers packets with latency
packets with latency independent
with latency independent of
latency independent of the
independent of the rtt
of the rtt of
the rtt of the
rtt of the link
of the link and
the link and the
link and the rate
and the rate in
the rate in any
rate in any single
in any single channel
model our focus is
our focus is on
focus is on pairs
is on pairs of
on pairs of geographically
pairs of geographically distant
of geographically distant datacenters
geographically distant datacenters that
distant datacenters that coordinate
datacenters that coordinate with
that coordinate with each
coordinate with each other
with each other in
each other in real
this has long been
has long been a
long been a critical
been a critical distributed
a critical distributed computing
critical distributed computing paradigm
distributed computing paradigm in
computing paradigm in application
paradigm in application domains
in application domains such
application domains such as
domains such as finance
such as finance and
as finance and aerospace
similar requirements are arising
requirements are arising across
are arising across the
arising across the board
across the board as
the board as globalized
board as globalized enterprises
as globalized enterprises rely
globalized enterprises rely on
enterprises rely on networks
rely on networks for
on networks for high
speed communication and collaboration
the most general case
most general case of
general case of inter
cluster communication is one
communication is one where
is one where any
one where any node
where any node in
any node in one
node in one cluster
in one cluster can
one cluster can communicate
cluster can communicate with
can communicate with any
communicate with any node
with any node in
any node in the
node in the other
in the other cluster
we make no assumptions
make no assumptions about
no assumptions about the
assumptions about the type
about the type of
the type of traffic
type of traffic flowing
of traffic flowing through
traffic flowing through the
flowing through the link
critical applications could send
applications could send dynamically
could send dynamically generated
send dynamically generated real
time data such as
data such as stock
such as stock quotes
financial transactions and battleground
transactions and battleground location
and battleground location updates
while enterprise applications could
enterprise applications could send
applications could send voip
could send voip streams
ssh sessions and synchronous
sessions and synchronous file
and synchronous file updates
synchronous file updates between
file updates between offices
packet loss typically occurs
loss typically occurs at
typically occurs at two
occurs at two points
at two points in
two points in an
points in an end
end communication path between
communication path between two
path between two datacenters
as shown in figure
area network connecting them
network connecting them and
connecting them and at
them and at the
and at the receiving
at the receiving end
loss in the lambda
in the lambda link
the lambda link can
lambda link can occur
link can occur for
can occur for many
occur for many reasons
dirty or degraded fiber
malfunctioning or misconfigured equipment
low receiver power and
receiver power and burst
power and burst switching
and burst switching contention
burst switching contention are
switching contention are some
contention are some reasons
loss can also occur
can also occur at
also occur at receiving
occur at receiving endhosts
at receiving endhosts within
receiving endhosts within the
endhosts within the destination
within the destination datacenter
these are usually cheap
are usually cheap commodity
usually cheap commodity machines
cheap commodity machines prone
commodity machines prone to
machines prone to temporary
prone to temporary overloads
to temporary overloads that
temporary overloads that cause
overloads that cause packets
that cause packets to
cause packets to be
packets to be dropped
to be dropped by
be dropped by the
dropped by the kernel
by the kernel in
the kernel in bursts
this loss mode occurs
loss mode occurs with
mode occurs with udp
based traffic but not
traffic but not with
but not with tcp
which advertises receiver windows
advertises receiver windows to
receiver windows to prevent
windows to prevent end
what are typical loss
are typical loss rates
typical loss rates on
loss rates on long
one source of information
source of information is
of information is teragrid
an optical network interconnecting
optical network interconnecting major
network interconnecting major supercomputing
interconnecting major supercomputing sites
major supercomputing sites in
supercomputing sites in the
sites in the us
teragrid has a monitoring
has a monitoring framework
a monitoring framework within
monitoring framework within which
framework within which ten
within which ten sites
which ten sites periodically
ten sites periodically send
sites periodically send each
periodically send each other
gbps streams of udp
streams of udp packets
of udp packets and
udp packets and measure
packets and measure the
and measure the resulting
measure the resulting loss
the resulting loss rate
each site measures the
site measures the loss
measures the loss rate
the loss rate to
loss rate to every
rate to every other
to every other site
every other site once
other site once an
site once an hour
resulting in a total
in a total of
loss rate measurements collected
rate measurements collected across
measurements collected across the
collected across the network
across the network every
the network every hour
of all such measurements
all such measurements were
such measurements were over
of them were over
after eliminating a single
eliminating a single site
that dropped incoming packets
dropped incoming packets steadily
incoming packets steadily at
packets steadily at a
steadily at a rate
at a rate of
of the remainder were
the remainder were over
these numbers reflect the
numbers reflect the loss
reflect the loss rate
the loss rate experienced
loss rate experienced for
rate experienced for udp
experienced for udp traffic
for udp traffic on
udp traffic on an
traffic on an end
end path and may
path and may not
and may not generalize
may not generalize to
not generalize to tcp
generalize to tcp packets
we do not know
do not know if
not know if packets
know if packets were
if packets were dropped
packets were dropped within
were dropped within the
dropped within the optical
within the optical network
the optical network or
optical network or at
network or at intermediate
or at intermediate devices
at intermediate devices within
intermediate devices within either
devices within either datacenter
though it s unlikely
it s unlikely that
s unlikely that they
unlikely that they were
that they were dropped
they were dropped at
were dropped at the
dropped at the end
many of the mea
surements lost just one
lost just one or
just one or two
one or two packets
or two packets whereas
two packets whereas kernel
nic losses are known
losses are known to
are known to be
known to be bursty
loss occurred on paths
occurred on paths where
on paths where levels
paths where levels of
where levels of optical
levels of optical link
of optical link utilization
were consistently lower than
ruling out congestion as
out congestion as a
congestion as a possible
as a possible cause
a conclusion supported by
conclusion supported by dialogue
supported by dialogue with
by dialogue with the
dialogue with the network
with the network administrators
points are provided by
are provided by the
provided by the back
bone networks of tier
global crossing reports average
crossing reports average loss
reports average loss rates
average loss rates between
on four of its
four of its six
of its six inter
haul links for the
links for the month
for the month of
the month of december
qwest reports loss rates
reports loss rates of
in either direction on
either direction on its
direction on its trans
pacific link for the
link for the same
for the same month
we expect privately managed
expect privately managed lambdas
privately managed lambdas to
managed lambdas to exhibit
lambdas to exhibit higher
to exhibit higher loss
exhibit higher loss rates
higher loss rates due
loss rates due to
rates due to the
due to the inherent
to the inherent trade
equipment quality and cost
as well as the
well as the difficulty
as the difficulty of
the difficulty of performing
difficulty of performing routine
of performing routine maintenance
performing routine maintenance on
routine maintenance on longdistance
maintenance on longdistance links
end paths as dropping
paths as dropping packets
as dropping packets at
dropping packets at rates
packets at rates of
to capture a wide
capture a wide range
a wide range of
wide range of deployed
range of deployed networks
existing reliability options tcp
ip is the default
is the default reliable
the default reliable communication
default reliable communication option
reliable communication option for
communication option for contemporary
option for contemporary networked
for contemporary networked applications
exclusive embeddings in commodity
embeddings in commodity operating
in commodity operating systems
commodity operating systems and
operating systems and networking
systems and networking apis
most applications requiring reliable
applications requiring reliable communication
requiring reliable communication over
reliable communication over any
communication over any form
over any form of
any form of network
form of network use
of network use tcp
the problem with commodity
problem with commodity tcp
ip uses positive acknowledgments
uses positive acknowledgments and
positive acknowledgments and retransmissions
acknowledgments and retransmissions to
and retransmissions to ensure
retransmissions to ensure reliability
to ensure reliability the
ensure reliability the sender
reliability the sender buffers
the sender buffers packets
sender buffers packets until
buffers packets until their
packets until their receipt
until their receipt is
their receipt is acknowledged
receipt is acknowledged by
is acknowledged by the
acknowledged by the receiver
and resends if an
resends if an acknowledgment
if an acknowledgment is
an acknowledgment is not
acknowledgment is not received
is not received within
not received within some
received within some time
within some time period
a lost packet is
lost packet is received
packet is received in
is received in the
received in the form
in the form of
the form of a
form of a retransmission
of a retransmission that
a retransmission that arrives
retransmission that arrives no
that arrives no earlier
arrives no earlier than
rtts after the original
after the original send
the original send event
the sender has to
sender has to buffer
has to buffer each
to buffer each packet
buffer each packet until
each packet until it
packet until it s
until it s acknowledged
rtt in lossless operation
and it has to
it has to perform
has to perform additional
to perform additional work
perform additional work to
additional work to retransmit
work to retransmit the
to retransmit the packet
retransmit the packet if
the packet if it
packet if it does
if it does not
it does not receive
does not receive the
not receive the acknowledgment
any packets that arrive
packets that arrive with
that arrive with higher
arrive with higher sequence
with higher sequence numbers
higher sequence numbers than
sequence numbers than that
numbers than that of
than that of a
that of a lost
of a lost packet
a lost packet must
lost packet must be
packet must be queued
must be queued while
be queued while the
queued while the receiver
while the receiver waits
the receiver waits for
receiver waits for the
waits for the lost
for the lost packet
the lost packet to
lost packet to arrive
throughput financial banking application
financial banking application running
banking application running in
application running in a
running in a datacenter
in a datacenter in
a datacenter in new
datacenter in new york
in new york city
sending updates to a
updates to a sister
to a sister site
a sister site in
sister site in switzerland
the rtt value between
rtt value between these
value between these two
between these two centers
these two centers is
two centers is typically
in the case of
the case of a
case of a lost
of a lost packet
all packets received within
packets received within the
milliseconds between the original
between the original packet
the original packet send
original packet send and
packet send and the
send and the a
h ets are generated
ets are generated from
are generated from alternate
generated from alternate disjoint
from alternate disjoint sub
streams of data rather
of data rather than
data rather than from
rather than from consecutive
than from consecutive packets
with an interleave index
an interleave index of
the encoder would a
g create correction packets
create correction packets separately
correction packets separately from
packets separately from three
separately from three disjoint
from three disjoint sub
the first containing data
first containing data packets
containing data packets numbered
data packets numbered a
packets numbered a c
numbered a c e
a c e g
c e g x
e g x x
the second with data
second with data packets
with data packets numb
data packets numb d
packets numb d f
numb d f h
d f h x
f h x x
h x x bered
and the third with
the third with data
third with data b
interleaving adds burst tolerance
adds burst tolerance to
burst tolerance to fec
tolerance to fec but
to fec but exacerbates
fec but exacerbates its
but exacerbates its sensitivfigure
separate encoding for ity
encoding for ity to
for ity to sending
ity to sending rate
to sending rate with
sending rate with an
rate with an interleave
with an interleave index
an interleave index of
interleave index of i
index of i and
of i and an
i and an encoding
and an encoding rate
an encoding rate of
the sender would have
sender would have to
would have to wait
have to wait for
to wait for odd
wait for odd and
for odd and even
odd and even packets
and even packets i
packets before sending any
before sending any redundancy
sending any redundancy information
receipt of its retransmission
of its retransmission have
its retransmission have to
retransmission have to be
have to be buffered
to be buffered at
be buffered at the
buffered at the rethese
at the rethese two
the rethese two obstacles
rethese two obstacles to
two obstacles to using
obstacles to using fec
to using fec in
using fec in time
tings rate sensitivity and
rate sensitivity and burst
sensitivity and burst susceptibility
and burst susceptibility are
burst susceptibility are innotice
susceptibility are innotice that
are innotice that for
innotice that for this
that for this commonplace
for this commonplace scenario
the loss of terlinked
loss of terlinked through
of terlinked through the
terlinked through the tuning
through the tuning knobs
an interleave of i
interleave of i and
of i and a
i and a single
and a single packet
a single packet stops
single packet stops all
packet stops all traffic
stops all traffic in
all traffic in the
traffic in the channel
in the channel to
the channel to the
channel to the apa
to the apa rate
the apa rate of
provides tolerance to a
tolerance to a burst
to a burst of
a burst of up
burst of up to
of up to c
up to c i
to c i plication
c i plication for
i plication for a
plication for a seventh
for a seventh of
a seventh of a
seventh of a second
a sequence of such
sequence of such consecutive
of such consecutive packets
the burst tolerance of
burst tolerance of blocks
tolerance of blocks can
of blocks can have
blocks can have devastating
can have devastating effect
have devastating effect on
devastating effect on a
effect on a high
throughput an fec code
an fec code can
fec code can be
code can be changed
can be changed by
be changed by modulating
changed by modulating either
by modulating either the
modulating either the c
either the c system
the c system where
c system where every
system where every spare
where every spare cycle
every spare cycle counts
in applior the i
applior the i parameters
increasing c enhances burst
c enhances burst tolercations
enhances burst tolercations with
burst tolercations with many
tolercations with many fine
a lost packet ance
lost packet ance at
packet ance at the
ance at the cost
at the cost of
the cost of network
cost of network and
of network and encoding
network and encoding overhead
potencan potentially trigger a
potentially trigger a butterfly
trigger a butterfly effect
a butterfly effect of
butterfly effect of missed
effect of missed deadtially
of missed deadtially worsening
missed deadtially worsening the
deadtially worsening the packet
worsening the packet loss
the packet loss experienced
packet loss experienced and
loss experienced and reducing
experienced and reducing lines
and reducing lines along
reducing lines along a
lines along a distributed
along a distributed workflow
increasing i trades off
i trades off recovery
trades off recovery periods
off recovery periods market
recovery periods market crashes
periods market crashes at
market crashes at stock
crashes at stock exchanges
christmas latency for better
latency for better burst
for better burst tolerance
better burst tolerance without
burst tolerance without adding
tolerance without adding overhead
without adding overhead sales
adding overhead sales at
overhead sales at online
sales at online stores
winter storms at air
traffic control as mentioned
for higher values of
higher values of i
the encoder has to
encoder has to centers
has to centers overloaded
to centers overloaded networks
centers overloaded networks and
overloaded networks and end
hosts can exhibit wait
can exhibit wait for
exhibit wait for more
wait for more data
for more data packets
more data packets to
data packets to be
packets to be transmitted
to be transmitted before
be transmitted before it
transmitted before it can
before it can continuous
it can continuous packet
can continuous packet loss
with each lost packet
each lost packet driving
lost packet driving the
packet driving the send
driving the send error
the send error correction
send error correction packets
system further and further
further and further out
and further out of
further out of sync
out of sync with
of sync with respect
sync with respect to
with respect to its
respect to its importantly
once the fec encoding
the fec encoding is
fec encoding is parameterized
encoding is parameterized real
with a rate and
a rate and an
rate and an interleave
and an interleave to
an interleave to tolerate
interleave to tolerate a
to tolerate a certain
tolerate a certain burst
a certain burst sensitive
certain burst sensitive flow
burst sensitive flow control
ip is unable to
is unable to distinguish
unable to distinguish length
to distinguish length b
to between ephemeral loss
between ephemeral loss modes
ephemeral loss modes due
loss modes due to
modes due to transient
due to transient contolerate
to transient contolerate a
transient contolerate a burst
contolerate a burst of
a burst of length
all losses occurring gestion
or dirty fiber and
dirty fiber and persistent
fiber and persistent in
and persistent in bursts
persistent in bursts of
in bursts of size
bursts of size less
of size less than
size less than or
less than or equal
than or equal to
or equal to b
equal to b are
to b are recovered
b are recovered with
are recovered with congestion
the loss of one
loss of one packet
of one packet out
one packet out of
packet out of ten
out of ten thousand
of ten thousand is
ten thousand is sufficient
thousand is sufficient to
is sufficient to reduce
sufficient to reduce tcp
ip throughput to a
throughput to a third
to a third of
a third of its
third of its the
of its the same
its the same latency
the same latency and
same latency and this
latency and this latency
and this latency depends
this latency depends on
latency depends on the
depends on the i
on the i palossless
the i palossless maximum
if one packet is
one packet is lost
packet is lost out
is lost out of
lost out of a
out of a thousand
we d like to
d like to parameterize
like to parameterize the
to parameterize the encoding
parameterize the encoding to
the encoding to tolerate
encoding to tolerate a
to tolerate a maximum
tolerate a maximum burst
a maximum burst length
maximum burst length and
burst length and then
length and then have
and then have recovthroughput
then have recovthroughput collapses
have recovthroughput collapses to
recovthroughput collapses to a
collapses to a thirtieth
to a thirtieth of
a thirtieth of the
thirtieth of the maximum
ery latency depend on
latency depend on the
depend on the actual
on the actual burstiness
the actual burstiness of
actual burstiness of the
burstiness of the loss
at the same time
we would like the
would like the encoding
like the encoding to
the encoding to have
encoding to have a
fec constant rate for
constant rate for network
rate for network provisioning
for network provisioning and
network provisioning and stability
an fec scheme is
fec scheme is required
scheme is required where
is required where latency
required where latency of
where latency of fec
latency of fec encoders
of fec encoders are
fec encoders are typically
encoders are typically parameterized
are typically parameterized with
typically parameterized with an
recovery degrades gracefully as
degrades gracefully as losses
gracefully as losses get
as losses get burstier
even tuple for each
tuple for each outgoing
for each outgoing sequence
each outgoing sequence of
outgoing sequence of r
sequence of r data
of r data packets
a as the encoding
as the encoding overhead
the encoding overhead stays
encoding overhead stays constant
c data and error
data and error correction
and error correction packets
error correction packets are
correction packets are sent
redundancy information cannot be
information cannot be generated
cannot be generated and
be generated and sent
generated and sent until
and sent until all
sent until all r
until all r data
all r data packets
r data packets are
data packets are available
packets are available for
are available for sending
the latency of packet
latency of packet recovery
of packet recovery is
packet recovery is determined
recovery is determined by
is determined by the
determined by the rate
by the rate at
the rate at which
rate at which the
at which the sender
which the sender transmits
the sender transmits data
generating error correction packets
maelstrom design and implemenfrom
design and implemenfrom less
and implemenfrom less than
implemenfrom less than r
less than r data
than r data packets
r data packets at
data packets at the
packets at the sender
at the sender is
the sender is not
sender is not a
is not a viable
not a viable tation
a viable tation option
viable tation option even
tation option even though
option even though the
even though the data
though the data rate
the data rate in
data rate in this
rate in this channel
in this channel is
this channel is low
or network could be
network could be operating
could be operating at
be operating at near
operating at near full
at near full capacity
near full capacity with
full capacity with data
capacity with data from
with data from other
data from other senders
we describe the maelstrom
describe the maelstrom appliance
the maelstrom appliance as
maelstrom appliance as a
appliance as a single
as a single machine
a single machine fec
single machine fec is
machine fec is also
fec is also very
is also very susceptible
also very susceptible to
very susceptible to bursty
susceptible to bursty losses
we will show how
will show how more
show how more machines
how more machines can
more machines can be
machines can be added
can be added to
be added to terleaving
is a standard encoding
a standard encoding technique
standard encoding technique used
encoding technique used the
technique used the appliance
used the appliance to
the appliance to balance
appliance to balance encoding
to balance encoding load
balance encoding load and
encoding load and scale
load and scale to
and scale to multo
scale to multo combat
to multo combat bursty
multo combat bursty loss
where error correction pack
tiple gigabits per second
gigabits per second of
per second of traffic
a b c d
b c d x
c d x x
d x x e
x x e f
x e f g
e f g h
f g h x
g h x x
h x x appliance
lan mtu lambda jumbo
mtu lambda jumbo mtu
lambda jumbo mtu recipe
jumbo mtu recipe list
repair packets are injected
packets are injected into
are injected into stream
injected into stream transparently
basic mechanism the basic
mechanism the basic operation
the basic operation of
basic operation of maelstrom
operation of maelstrom is
of maelstrom is shown
maelstrom is shown in
is shown in figure
it intercepts outgoing data
intercepts outgoing data packets
outgoing data packets and
data packets and routes
packets and routes them
and routes them to
routes them to the
them to the destination
to the destination datacenter
generating and injecting fec
and injecting fec repair
injecting fec repair packets
fec repair packets into
repair packets into the
packets into the stream
into the stream in
the stream in their
stream in their wake
a repair packet consists
repair packet consists of
packet consists of a
consists of a recipe
of a recipe list
a recipe list of
recipe list of data
list of data packet
of data packet identifiers
data packet identifiers and
packet identifiers and fec
identifiers and fec information
and fec information generated
fec information generated from
information generated from these
generated from these packets
in the example in
the example in figure
this information is a
information is a simple
is a simple xor
the size of the
size of the xor
of the xor is
the xor is equal
xor is equal to
is equal to the
equal to the mtu
to the mtu of
the mtu of the
mtu of the datacenter
of the datacenter network
and to avoid fragmentation
to avoid fragmentation of
avoid fragmentation of repair
fragmentation of repair packets
of repair packets we
repair packets we require
packets we require that
we require that the
require that the mtu
that the mtu of
the mtu of the
mtu of the long
haul network be set
network be set to
be set to a
set to a slightly
to a slightly larger
a slightly larger value
this requirement is usually
requirement is usually satisfied
is usually satisfied in
usually satisfied in practical
satisfied in practical deployments
since gigabit links very
gigabit links very often
links very often use
very often use jumbo
often use jumbo frames
use jumbo frames of
jumbo frames of up
frames of up to
while lan networks have
lan networks have standard
networks have standard mtus
have standard mtus of
at the receiving datacenter
the appliance examines incoming
appliance examines incoming repair
examines incoming repair packets
incoming repair packets and
repair packets and uses
packets and uses them
and uses them to
uses them to recover
them to recover missing
to recover missing data
recover missing data packets
the data packet is
data packet is injected
packet is injected transparently
is injected transparently into
injected transparently into the
transparently into the stream
into the stream to
the stream to the
stream to the receiving
to the receiving end
recovered data packets will
data packets will typically
packets will typically arrive
will typically arrive out
but this behavior is
this behavior is expected
behavior is expected by
is expected by communication
expected by communication stacks
by communication stacks designed
communication stacks designed for
stacks designed for the
designed for the commodity
for the commodity internet
flow control while relaying
control while relaying tcp
maelstrom has two flow
has two flow control
two flow control modes
the appliance routes packets
appliance routes packets through
routes packets through without
packets through without modification
control between the endhosts
the appliance acts as
appliance acts as a
acts as a tcp
terminating connections and sending
connections and sending back
and sending back acks
sending back acks immediately
back acks immediately before
acks immediately before relaying
immediately before relaying data
before relaying data on
relaying data on appliance
this is particularly useful
is particularly useful for
particularly useful for applications
useful for applications with
for applications with short
lived flows that need
flows that need to
that need to ramp
need to ramp up
to ramp up throughput
ramp up throughput quickly
up throughput quickly and
throughput quickly and avoid
quickly and avoid the
and avoid the slow
start effects of tcp
ip on a long
on a long link
the performance advantages of
performance advantages of splitting
advantages of splitting longdistance
of splitting longdistance connections
splitting longdistance connections into
longdistance connections into multiple
connections into multiple hops
into multiple hops are
multiple hops are well
hops are well known
and orthogonal to this
orthogonal to this work
we are primarily interested
are primarily interested in
primarily interested in isolating
interested in isolating the
in isolating the impact
isolating the impact of
the impact of rapid
impact of rapid and
of rapid and transparent
rapid and transparent recovery
and transparent recovery of
transparent recovery of lost
recovery of lost packets
of lost packets by
lost packets by maelstrom
packets by maelstrom on
by maelstrom on tcp
rather than the buffering
than the buffering and
the buffering and slow
start avoidance benefits of
avoidance benefits of generic
benefits of generic performance
in the remainder of
the remainder of the
remainder of the paper
we describe maelstrom with
describe maelstrom with end
while maelstrom respects end
end flow control connections
or splits them and
splits them and implements
them and implements its
and implements its own
implements its own proxy
proxy flow control as
flow control as described
control as described above
it is not designed
is not designed for
not designed for routinely
designed for routinely congested
for routinely congested networks
the addition of fec
addition of fec under
of fec under tcp
ip flow control allows
flow control allows it
control allows it to
allows it to steal
it to steal bandwidth
to steal bandwidth from
steal bandwidth from other
bandwidth from other competing
from other competing flows
other competing flows running
competing flows running without
flows running without fec
running without fec in
without fec in the
fec in the link
though maintaining fairness versus
maintaining fairness versus similarly
fairness versus similarly fec
friendliness with conventional tcp
ip flows is not
flows is not a
is not a primary
not a primary protocol
a primary protocol design
primary protocol design goal
protocol design goal on
design goal on over
which are often dedicated
are often dedicated to
often dedicated to specific
dedicated to specific highvalue
to specific highvalue applications
we see evidence for
see evidence for this
evidence for this assertion
for this assertion in
this assertion in the
assertion in the routine
in the routine use
the routine use of
routine use of parallel
use of parallel flows
and udp blast protocols
both in commercial deployments
in commercial deployments and
commercial deployments and by
deployments and by researchers
and by researchers seeking
by researchers seeking to
researchers seeking to transfer
seeking to transfer large
to transfer large amounts
transfer large amounts of
large amounts of data
amounts of data over
of data over high
layered interleaving in layered
interleaving in layered interleaving
an fec protocol with
fec protocol with rate
is produced by running
produced by running c
by running c multiple
running c multiple instances
c multiple instances of
multiple instances of an
fec protocol simultaneously with
protocol simultaneously with increasing
simultaneously with increasing interleave
with increasing interleave indices
increasing interleave indices i
three instances of an
the first instance with
first instance with interleave
instance with interleave i
the second with interleave
second with interleave i
and the third with
the third with interleave
third with interleave i
fec encoding is simply
encoding is simply an
is simply an xor
simply an xor of
an xor of the
xor of the r
of the r data
the r data packets
r data packets hence
in layered interleaving each
layered interleaving each data
interleaving each data packet
each data packet is
data packet is included
packet is included in
is included in c
included in c xors
each of which is
of which is generated
which is generated at
is generated at different
generated at different interleaves
at different interleaves from
different interleaves from the
interleaves from the original
from the original data
the original data stream
as we shall describe
we shall describe shortly
ensures that the c
that the c xors
the c xors containing
c xors containing a
xors containing a data
containing a data packet
a data packet do
data packet do not
packet do not have
do not have any
not have any other
data packet in common
the resulting protocol effectively
resulting protocol effectively has
protocol effectively has a
effectively has a rate
has a rate of
with each xor generated
each xor generated from
xor generated from r
generated from r data
from r data packets
r data packets and
data packets and each
packets and each data
and each data packet
each data packet included
data packet included in
packet included in c
included in c xors
illustrates layered interleaving for
layered interleaving for a
standard fec schemes can
fec schemes can be
schemes can be made
can be made resistant
be made resistant to
made resistant to a
resistant to a certain
to a certain loss
a certain loss burst
certain loss burst length
loss burst length at
burst length at the
length at the cost
at the cost of
the cost of increased
cost of increased recovery
of increased recovery latency
increased recovery latency for
recovery latency for all
latency for all lost
for all lost packets
including smaller bursts and
smaller bursts and singleton
bursts and singleton drops
layered interleaving provides graceful
interleaving provides graceful degradation
provides graceful degradation in
graceful degradation in the
degradation in the face
in the face of
the face of bursty
face of bursty loss
of bursty loss for
bursty loss for constant
loss for constant encoding
for constant encoding overhead
constant encoding overhead singleton
encoding overhead singleton random
overhead singleton random losses
singleton random losses are
random losses are recovered
losses are recovered as
are recovered as quickly
recovered as quickly as
as quickly as possible
by xors generated with
xors generated with an
generated with an interleave
with an interleave of
and each successive layer
each successive layer of
successive layer of xors
layer of xors generated
of xors generated at
xors generated at a
generated at a higher
at a higher interleave
a higher interleave catches
higher interleave catches larger
interleave catches larger bursts
catches larger bursts missed
larger bursts missed by
bursts missed by the
missed by the previous
by the previous layer
the implementation of this
implementation of this algorithm
of this algorithm is
this algorithm is simple
algorithm is simple and
is simple and shown
simple and shown in
and shown in figure
a set of repair
set of repair bins
of repair bins is
repair bins is maintained
bins is maintained for
is maintained for each
maintained for each layer
with i bins for
i bins for a
bins for a layer
for a layer with
a layer with interleave
layer with interleave i
a repair bin consists
repair bin consists of
bin consists of a
consists of a partially
of a partially constructed
a partially constructed repair
partially constructed repair packet
an xor and the
xor and the recipe
and the recipe list
the recipe list of
recipe list of identifiers
list of identifiers of
of identifiers of data
identifiers of data packets
of data packets that
data packets that compose
packets that compose the
that compose the xor
each intercepted data packet
intercepted data packet is
data packet is added
packet is added to
is added to each
added to each layer
to each layer where
each layer where adding
layer where adding to
where adding to a
adding to a layer
to a layer simply
a layer simply means
layer simply means choosing
simply means choosing a
means choosing a repair
choosing a repair bin
a repair bin from
repair bin from the
bin from the layer
from the layer s
the layer s set
incrementally updating the xor
updating the xor with
the xor with the
xor with the new
with the new data
the new data packet
and adding the data
adding the data packet
the data packet s
data packet s header
packet s header to
s header to the
header to the recipe
to the recipe list
a counter is incremented
counter is incremented as
is incremented as each
incremented as each data
as each data packet
each data packet arrives
data packet arrives at
packet arrives at the
arrives at the appliance
and choosing the repair
choosing the repair bin
the repair bin from
repair bin from the
bin from the layer
from the layer s
the layer s set
layer s set is
s set is done
set is done by
is done by taking
done by taking the
by taking the modulo
taking the modulo of
the modulo of the
modulo of the counter
of the counter with
the counter with the
counter with the number
with the number of
the number of bins
number of bins in
of bins in each
bins in each layer
for a layer with
a layer with interleave
the xth intercepted packet
xth intercepted packet is
intercepted packet is added
packet is added to
is added to the
when a repair bin
a repair bin fills
repair bin fills up
bin fills up its
fills up its recipe
up its recipe list
its recipe list contains
recipe list contains r
list contains r data
contains r data packets
r data packets it
data packets it fires
a repair packet is
repair packet is generated
packet is generated consisting
is generated consisting of
generated consisting of the
consisting of the xor
of the xor and
the xor and the
xor and the recipe
and the recipe list
the recipe list and
recipe list and is
list and is scheduled
and is scheduled for
is scheduled for sending
while the repair bin
the repair bin is
repair bin is re
initialized with an empty
with an empty recipe
an empty recipe list
empty recipe list and
recipe list and blank
list and blank xor
incoming repair packets are
repair packets are processed
packets are processed as
are processed as follows
if all the data
all the data packets
the data packets contained
data packets contained in
packets contained in the
contained in the repair
in the repair s
the repair s recipe
repair s recipe list
s recipe list have
recipe list have been
list have been received
have been received successfully
the repair packet is
repair packet is discarded
if the repair s
the repair s recipe
repair s recipe list
s recipe list contains
recipe list contains a
list contains a single
contains a single missing
a single missing data
single missing data packet
recovery can occur immediately
can occur immediately by
occur immediately by combining
immediately by combining the
by combining the xor
combining the xor in
the xor in the
xor in the repair
in the repair with
the repair with layer
layer with interleave of
the other successfully received
other successfully received data
successfully received data packets
if the repair contains
the repair contains multiple
repair contains multiple missing
contains multiple missing data
multiple missing data packets
it cannot be used
cannot be used immediately
be used immediately for
used immediately for recovery
immediately for recovery it
for recovery it is
recovery it is instead
it is instead stored
is instead stored in
instead stored in a
stored in a table
in a table that
a table that maps
table that maps missing
that maps missing data
maps missing data packets
missing data packets to
data packets to repair
packets to repair packets
whenever a data packet
a data packet is
data packet is subsequently
packet is subsequently received
is subsequently received or
subsequently received or recovered
this table is checked
table is checked to
is checked to see
checked to see if
to see if any
see if any xors
if any xors now
any xors now have
xors now have singleton
now have singleton losses
have singleton losses due
singleton losses due to
losses due to the
due to the presence
to the presence of
the presence of the
presence of the new
of the new packet
the new packet and
new packet and can
packet and can be
and can be used
can be used for
be used for recovering
used for recovering other
for recovering other missing
recovering other missing packets
xors received from different
received from different layers
from different layers interact
different layers interact to
layers interact to recover
interact to recover missing
to recover missing data
recover missing data packets
since an xor received
an xor received at
xor received at a
received at a higher
at a higher interleave
a higher interleave can
higher interleave can recover
interleave can recover a
can recover a packet
recover a packet that
a packet that makes
packet that makes an
that makes an earlier
makes an earlier xor
an earlier xor at
earlier xor at a
xor at a lower
at a lower interleave
a lower interleave usable
lower interleave usable hence
though layered interleaving is
layered interleaving is equivalent
interleaving is equivalent to
is equivalent to c
equivalent to c different
instances in terms of
in terms of overhead
terms of overhead and
of overhead and design
its recovery power is
recovery power is much
power is much higher
is much higher and
much higher and comes
higher and comes close
and comes close to
comes close to standard
second set of rsized
set of rsized xors
of rsized xors staggered
rsized xors staggered start
xors staggered start xors
comparison of packet recovery
of packet recovery probability
optimizations staggered start for
staggered start for rate
limiting in the naive
in the naive implementation
the naive implementation of
naive implementation of the
implementation of the layered
of the layered interleaving
the layered interleaving algorithm
repair packets are transmitted
packets are transmitted as
are transmitted as soon
transmitted as soon as
as soon as repair
soon as repair bins
as repair bins fill
repair bins fill and
bins fill and allow
fill and allow them
and allow them to
allow them to be
them to be constructed
all the repair bins
the repair bins in
repair bins in a
bins in a layer
in a layer fill
a layer fill in
layer fill in quick
fill in quick succession
the arrival of packets
will successively fill the
successively fill the four
fill the four repair
the four repair bins
four repair bins in
repair bins in layer
this behavior leads to
behavior leads to a
leads to a large
to a large number
a large number of
large number of repair
number of repair packets
of repair packets being
repair packets being generated
packets being generated and
being generated and sent
generated and sent within
and sent within a
sent within a short
within a short period
a short period of
short period of time
which results in undesirable
results in undesirable overhead
in undesirable overhead and
undesirable overhead and traffic
overhead and traffic spikes
we would like to
would like to rate
limit transmissions of repair
transmissions of repair packets
of repair packets to
repair packets to one
packets to one for
to one for every
one for every r
for every r data
every r data packets
this problem is fixed
problem is fixed by
is fixed by staggering
fixed by staggering the
by staggering the starting
staggering the starting sizes
the starting sizes of
starting sizes of the
sizes of the bins
analogous to the starting
to the starting positions
the starting positions of
starting positions of runners
positions of runners in
of runners in a
runners in a sprint
the very first time
very first time bin
first time bin number
time bin number x
bin number x in
number x in a
x in a layer
in a layer of
a layer of interleave
layer of interleave i
of interleave i fires
it does so at
does so at size
so at size x
at size x mod
size x mod r
the first repair bin
first repair bin in
repair bin in the
bin in the second
in the second layer
the second layer with
second layer with interleave
would fire at size
the second would fire
second would fire at
would fire at size
for the first i
the first i data
first i data packets
i data packets added
data packets added to
packets added to a
added to a layer
to a layer with
a layer with interleave
layer with interleave i
r fire immediately with
fire immediately with just
immediately with just one
with just one packet
just one packet in
one packet in them
for the next i
the next i data
next i data packets
i data packets added
r fire immediately with
fire immediately with two
immediately with two data
with two data packets
two data packets in
data packets in them
and so on until
so on until r
on until r i
until r i data
r i data packets
i data packets have
data packets have been
packets have been added
have been added to
been added to the
added to the layer
to the layer and
the layer and all
layer and all bins
and all bins have
all bins have fired
bins have fired exactly
have fired exactly once
all bins fire at
bins fire at size
fire at size r
now that they have
that they have been
they have been staggered
have been staggered at
been staggered at the
staggered at the start
r fire for any
fire for any i
for any i data
any i data packets
the outlined scheme works
outlined scheme works when
scheme works when i
works when i is
when i is greater
i is greater than
is greater than or
greater than or equal
than or equal to
or equal to r
as is usually the
is usually the case
if i is smaller
i is smaller than
is smaller than r
the bin with index
bin with index x
with index x fires
index x fires at
the initial firing sizes
initial firing sizes would
firing sizes would be
for the first bin
the first bin and
for the second bin
if r and i
r and i are
and i are not
i are not integral
are not integral multiples
not integral multiples of
integral multiples of each
multiples of each other
limiting still works but
still works but is
works but is slightly
but is slightly less
is slightly less effective
slightly less effective due
less effective due to
effective due to rounding
due to rounding errors
delaying xors in the
xors in the naive
in the naive implementation
repair packets are transmitted
packets are transmitted as
are transmitted as soon
transmitted as soon as
as soon as they
soon as they are
as they are generated
this results in the
results in the repair
in the repair packet
the repair packet leaving
repair packet leaving immediately
packet leaving immediately after
leaving immediately after the
immediately after the last
after the last data
the last data packet
last data packet that
data packet that was
packet that was added
that was added to
was added to it
which lowers burst tolerance
lowers burst tolerance if
burst tolerance if the
tolerance if the repair
if the repair packet
the repair packet was
repair packet was generated
packet was generated at
was generated at interleave
generated at interleave i
the resulting protocol can
resulting protocol can tolerate
protocol can tolerate a
can tolerate a burst
tolerate a burst of
a burst of i
burst of i lost
of i lost data
i lost data packets
lost data packets excluding
data packets excluding the
packets excluding the repair
but the burst could
the burst could swallow
burst could swallow both
could swallow both the
swallow both the repair
both the repair and
the repair and the
repair and the last
and the last data
the last data packet
last data packet in
data packet in it
packet in it as
in it as they
it as they are
as they are not
they are not separated
are not separated by
not separated by the
separated by the requisite
by the requisite interleave
the solution to this
solution to this is
to this is simple
this is simple delay
is simple delay sending
simple delay sending the
delay sending the repair
sending the repair packet
the repair packet generated
repair packet generated by
packet generated by a
generated by a repair
by a repair bin
a repair bin until
repair bin until the
bin until the next
until the next time
the next time a
next time a data
time a data packet
a data packet is
data packet is added
packet is added to
is added to the
added to the now
to the now empty
the now empty bin
which happens i packets
happens i packets later
i packets later and
packets later and introduces
later and introduces the
and introduces the required
introduces the required interleave
the required interleave between
required interleave between the
interleave between the repair
between the repair packet
the repair packet and
repair packet and the
packet and the last
and the last data
the last data packet
last data packet included
data packet included in
packet included in it
notice that although transmitting
that although transmitting the
although transmitting the xor
transmitting the xor immediately
the xor immediately results
xor immediately results in
immediately results in faster
results in faster recovery
doing so also reduces
so also reduces the
also reduces the probability
reduces the probability of
the probability of a
probability of a lost
of a lost packet
a lost packet being
lost packet being recovered
off results in a
results in a minor
in a minor control
a minor control knob
minor control knob permitting
control knob permitting us
knob permitting us to
permitting us to balance
us to balance speed
to balance speed against
balance speed against burst
speed against burst tolerance
our default configuration is
default configuration is to
configuration is to transmit
is to transmit the
to transmit the xor
transmit the xor immediately
envelope analysis to start
analysis to start with
we note that no
note that no two
that no two repair
no two repair packets
two repair packets generated
repair packets generated at
packets generated at different
generated at different interleaves
at different interleaves i
will have more than
have more than one
more than one data
than one data packet
one data packet in
data packet in common
packet in common as
in common as long
common as long as
as long as the
long as the least
as the least common
the least common multiple
of the interleaves is
the interleaves is greater
interleaves is greater than
is greater than r
greater than r i
pairings of repair bins
of repair bins in
repair bins in two
bins in two different
in two different layers
two different layers with
different layers with interleaves
layers with interleaves i
a good rule of
good rule of thumb
rule of thumb is
of thumb is to
thumb is to select
is to select interleaves
to select interleaves that
select interleaves that are
interleaves that are relatively
that are relatively prime
are relatively prime to
relatively prime to maximize
prime to maximize their
to maximize their lcm
and also ensure that
also ensure that the
ensure that the larger
that the larger interleave
the larger interleave is
larger interleave is greater
interleave is greater than
is greater than r
let us assume that
us assume that packets
assume that packets are
that packets are dropped
packets are dropped with
are dropped with uniform
given a lost data
a lost data packet
what is the probability
is the probability that
the probability that we
probability that we can
that we can recover
we can recover it
we can recover a
can recover a data
recover a data packet
a data packet if
data packet if at
packet if at least
if at least one
at least one of
least one of the
one of the c
of the c xors
the c xors containing
c xors containing it
xors containing it is
containing it is re
local recovery for receiver
recovery for receiver loss
for receiver loss ceived
receiver loss ceived correctly
loss ceived correctly and
ceived correctly and usable
all the other data
the other data packets
other data packets in
data packets in it
packets in it have
in it have also
it have also been
have also been received
also been received correctly
the probability of in
probability of in the
of in the absence
in the absence of
the absence of intelligent
absence of intelligent flow
of intelligent flow control
intelligent flow control mechanisms
flow control mechanisms like
control mechanisms like which
mechanisms like which is
like which is simply
the probability of a
probability of a received
of a received tcp
inexpensive xor being unusable
xor being unusable is
being unusable is the
unusable is the complement
hosts can be easily
can be easily overwhelmed
be easily overwhelmed and
easily overwhelmed and drop
overwhelmed and drop packets
and drop packets during
drop packets during traffic
packets during traffic spikes
during traffic spikes or
traffic spikes or cpu
the probability x of
probability x of a
x of a sent
of a sent xor
a sent xor being
sent xor being nance
xor being nance tasks
being nance tasks like
nance tasks like garbage
tasks like garbage collection
reliable applicationdropped or unusable
applicationdropped or unusable is
or unusable is the
unusable is the sum
is the sum of
the sum of the
sum of the probability
of the probability that
the probability that it
probability that it level
that it level protocols
it level protocols layered
level protocols layered over
protocols layered over udp
layered over udp for
over udp for reliable
udp for reliable multiwas
for reliable multiwas dropped
reliable multiwas dropped and
multiwas dropped and the
dropped and the probability
and the probability that
the probability that it
probability that it was
that it was received
it was received and
was received and cast
or high speed data
high speed data transfer
would ordinarily go back
ordinarily go back to
go back to the
back to the sender
to the sender to
the sender to retrieve
sender to retrieve the
to retrieve the lost
retrieve the lost packet
even though it was
though it was dropped
it was dropped at
was dropped at the
dropped at the receiver
at the receiver after
the receiver after since
receiver after since it
after since it is
since it is easy
it is easy to
is easy to ensure
easy to ensure that
to ensure that no
ensure that no two
that no two xors
no two xors share
two xors share covering
xors share covering the
share covering the entire
covering the entire geographical
the entire geographical distance
more than one data
than one data packet
the usability probabilities of
usability probabilities of the
probabilities of the maelstrom
of the maelstrom proxy
the maelstrom proxy acts
maelstrom proxy acts as
proxy acts as a
acts as a local
as a local packet
a local packet cache
stordifferent xors are independent
the probability of all
probability of all ing
of all ing incoming
all ing incoming packets
ing incoming packets for
incoming packets for a
packets for a short
for a short period
a short period of
short period of time
period of time and
of time and prothe
time and prothe c
and prothe c xors
prothe c xors being
c xors being dropped
xors being dropped or
being dropped or unusable
dropped or unusable is
or unusable is xc
viding hooks that allow
hooks that allow protocols
that allow protocols to
allow protocols to first
protocols to first query
to first query the
first query the cache
query the cache the
the cache the probability
cache the probability of
the probability of correctly
probability of correctly receiving
of correctly receiving at
correctly receiving at least
receiving at least one
at least one usable
least one usable to
one usable to locate
usable to locate missing
to locate missing packets
locate missing packets before
missing packets before sending
packets before sending retransmission
before sending retransmission xor
sending retransmission xor is
the probability of recovrequests
probability of recovrequests back
of recovrequests back to
recovrequests back to the
back to the sender
future versions of maelstrom
versions of maelstrom ering
of maelstrom ering the
maelstrom ering the lost
ering the lost data
the lost data packet
lost data packet is
which expands to could
expands to could potentially
to could potentially use
could potentially use knowledge
potentially use knowledge of
use knowledge of protocol
knowledge of protocol internals
of protocol internals to
by intercepting and this
intercepting and this closed
form formula only gives
formula only gives us
only gives us a
gives us a lower
us a lower bound
a lower bound satisfying
lower bound satisfying retransmission
bound satisfying retransmission requests
satisfying retransmission requests sent
retransmission requests sent by
requests sent by the
sent by the receiver
by the receiver in
the receiver in on
receiver in on the
in on the recovery
on the recovery probability
since the xor usability
the xor usability for
or by resending packets
by resending packets when
resending packets when acmula
packets when acmula does
when acmula does not
acmula does not factor
does not factor in
not factor in the
factor in the probability
in the probability of
the probability of the
probability of the other
of the other data
the other data knowledgments
other data knowledgments are
data knowledgments are not
knowledgments are not observed
are not observed within
not observed within a
observed within a certain
within a certain time
a certain time period
certain time period in
time period in an
period in an ack
packets in the xor
in the xor being
the xor being dropped
xor being dropped and
being dropped and recovered
we extend the analysis
extend the analysis to
the analysis to bursty
analysis to bursty losses
if the lost data
the lost data packet
lost data packet was
data packet was part
packet was part of
was part of a
part of a loss
of a loss burst
a loss burst of
loss burst of size
burst of size b
repair packets generated at
packets generated at interleaves
generated at interleaves less
at interleaves less than
interleaves less than b
less than b are
than b are dropped
b are dropped or
are dropped or useless
dropped or useless with
or useless with high
useless with high probability
and we can discount
we can discount them
probability of recovering the
of recovering the data
recovering the data packet
the data packet is
data packet is then
is the number of
the number of xors
number of xors generated
of xors generated at
xors generated at interleaves
generated at interleaves greater
at interleaves greater than
interleaves greater than b
the formulae derived for
formulae derived for xor
derived for xor usability
for xor usability still
xor usability still hold
since packet losses with
packet losses with more
losses with more than
with more than b
more than b intervening
than b intervening packets
b intervening packets between
intervening packets between them
packets between them have
between them have independent
them have independent probability
there is only correlation
is only correlation within
only correlation within the
correlation within the bursts
how does this compare
does this compare to
this compare to traditional
codes such as reed
c repair packets are
repair packets are generated
packets are generated and
are generated and sent
generated and sent for
and sent for every
sent for every r
for every r data
every r data packets
and the correct delivery
the correct delivery of
correct delivery of any
delivery of any r
of any r of
any r of the
r of the r
c packets transmitted is
packets transmitted is sufficient
transmitted is sufficient to
is sufficient to reconstruct
sufficient to reconstruct the
to reconstruct the original
reconstruct the original r
the original r data
original r data packets
given a lost data
a lost data packet
we can recover it
can recover it if
recover it if at
it if at least
if at least r
at least r packets
least r packets are
r packets are received
packets are received correctly
are received correctly in
received correctly in the
correctly in the encoding
in the encoding set
the encoding set of
encoding set of r
c data and repair
data and repair packets
and repair packets that
repair packets that the
packets that the lost
that the lost packet
the lost packet belongs
lost packet belongs to
the probability of recovering
probability of recovering a
of recovering a lost
recovering a lost packet
a lost packet is
lost packet is equivalent
packet is equivalent to
is equivalent to the
equivalent to the probability
to the probability of
the probability of losing
probability of losing c
or less packets from
less packets from the
packets from the total
from the total r
since the number of
the number of other
number of other lost
of other lost packets
other lost packets in
lost packets in the
packets in the xor
in the xor is
the xor is a
xor is a random
is a random variable
a random variable y
random variable y and
variable y and has
y and has a
and has a binomial
has a binomial distribution
a binomial distribution with
binomial distribution with parameters
is the summation z
the summation z c
we plot the recovery
plot the recovery probability
the recovery probability curves
recovery probability curves for
probability curves for layered
curves for layered interleaving
for layered interleaving and
layered interleaving and reed
solomon against uniformly random
against uniformly random loss
uniformly random loss rate
note that the curves
that the curves are
the curves are very
curves are very close
are very close to
very close to each
close to each other
especially in the loss
in the loss range
the loss range of
loss range of interest
range of interest between
implementation details we initially
details we initially implemented
we initially implemented and
initially implemented and evaluated
implemented and evaluated maelstrom
and evaluated maelstrom as
evaluated maelstrom as a
maelstrom as a user
performance turned out to
turned out to be
out to be limited
to be limited by
be limited by copying
limited by copying and
by copying and context
and we subsequently reimplemented
we subsequently reimplemented the
subsequently reimplemented the system
reimplemented the system as
the system as a
system as a module
as a module that
a module that runs
module that runs within
that runs within the
runs within the linux
at an encoding rate
an encoding rate of
the experimental prototype of
experimental prototype of the
prototype of the kernel
of the kernel version
the kernel version reaches
kernel version reaches output
version reaches output speeds
reaches output speeds close
output speeds close to
gigabit per second of
per second of combined
second of combined data
of combined data and
combined data and fec
data and fec traffic
limited only by the
only by the capacity
by the capacity of
the capacity of the
capacity of the outbound
of the outbound network
the outbound network card
lambda networks are already
networks are already reaching
are already reaching speeds
already reaching speeds of
and higher speeds are
higher speeds are a
speeds are a certainty
are a certainty down
a certainty down the
certainty down the road
we envision maelstrom as
envision maelstrom as a
maelstrom as a small
as a small rack
style cluster of blade
each acting as an
acting as an individual
as an individual proxy
traffic would be distributed
would be distributed over
be distributed over such
distributed over such a
over such a rack
such a rack by
a rack by partitioning
rack by partitioning the
by partitioning the address
partitioning the address space
the address space of
address space of the
space of the remote
of the remote datacenter
the remote datacenter and
remote datacenter and routing
datacenter and routing different
and routing different segments
routing different segments of
different segments of the
segments of the space
of the space through
the space through distinct
space through distinct maelstrom
through distinct maelstrom appliance
distinct maelstrom appliance pairs
we plan to experiment
plan to experiment with
to experiment with such
experiment with such configurations
which would also permit
would also permit us
also permit us to
permit us to explore
us to explore faulttolerance
to explore faulttolerance issues
if a maelstrom blade
a maelstrom blade fails
and to support load
balancing schemes that might
schemes that might vary
that might vary the
might vary the ip
vary the ip address
the ip address space
ip address space partitioning
address space partitioning dynamically
space partitioning dynamically to
partitioning dynamically to spread
dynamically to spread the
to spread the encoding
spread the encoding load
the encoding load over
encoding load over multiple
load over multiple machines
we present the implementation
present the implementation and
the implementation and performance
implementation and performance of
and performance of a
performance of a single
the kernel implementation is
kernel implementation is a
implementation is a module
is a module for
a module for linux
with hooks into the
hooks into the kernel
into the kernel packet
the kernel packet filter
maelstrom proxies work in
proxies work in pairs
one on each side
on each side of
each side of the
side of the long
of the long haul
the long haul link
each proxy acts both
proxy acts both as
acts both as an
both as an ingress
as an ingress and
an ingress and egress
ingress and egress temporarily
in case all but
case all but one
all but one of
but one of the
one of the missing
of the missing packets
the missing packets are
missing packets are router
packets are router at
are router at the
router at the same
at the same time
the same time since
same time since they
time since they handle
since they handle duplex
they handle duplex traffic
handle duplex traffic in
duplex traffic in received
traffic in received later
in received later or
received later or recovered
later or recovered through
or recovered through other
recovered through other xors
allowing the following manner
the recovery of the
recovery of the remaining
of the remaining missing
the remaining missing packet
remaining missing packet from
missing packet from this
packet from this xor
in practice we stored
practice we stored data
we stored data and
stored data and xor
data and xor packets
and xor packets in
xor packets in dou
packets in dou the
in dou the egress
dou the egress router
the egress router captures
egress router captures ip
router captures ip packets
captures ip packets and
ip packets and creates
packets and creates re
ble buffered red black
buffered red black trees
red black trees for
byte packets and dundant
packets and dundant fec
and dundant fec packets
the original ip packets
original ip packets are
entries this occupies around
routed through unaltered as
through unaltered as they
unaltered as they would
as they would have
they would have been
would have been at
have been at the
been at the send
the repair bins in
repair bins in the
bins in the layered
in the layered interoriginally
the redundant packets are
redundant packets are then
packets are then forwarded
are then forwarded leaving
then forwarded leaving scheme
forwarded leaving scheme store
leaving scheme store incrementally
scheme store incrementally computed
store incrementally computed xors
incrementally computed xors and
computed xors and to
xors and to the
and to the remote
to the remote ingress
the remote ingress router
remote ingress router via
ingress router via a
router via a udp
via a udp channel
lists of data packet
of data packet headers
without the data packet
the data packet payloads
resulting in low storage
in low storage overheads
low storage overheads for
storage overheads for each
overheads for each layer
for each layer the
each layer the ingress
layer the ingress router
the ingress router captures
ingress router captures and
router captures and stores
captures and stores ip
and stores ip packets
stores ip packets that
ip packets that rise
packets that rise linearly
that rise linearly with
rise linearly with the
linearly with the value
with the value of
the value of the
value of the interleave
the coming from the
coming from the direction
from the direction of
the direction of the
direction of the egress
of the egress router
upon memory footprint for
memory footprint for a
footprint for a long
running proxy was around
proxy was around receipt
was around receipt of
around receipt of a
receipt of a redundant
of a redundant packet
an ip packet is
ip packet is recov
mb in our experiments
ered if there is
if there is an
there is an opportunity
is an opportunity to
an opportunity to do
opportunity to do so
redundant packets that can
packets that can be
that can be used
can be used at
be used at a
used at a later
at a later time
a later time are
later time are stored
if the redundant packet
the redundant packet is
redundant packet is useless
packet is useless it
is useless it is
useless it is immediately
it is immediately dis
other performance enhancing roles
performance enhancing roles carded
upon recovery the ip
recovery the ip packet
the ip packet is
ip packet is sent
packet is sent through
is sent through maelstrom
sent through maelstrom appliances
through maelstrom appliances can
maelstrom appliances can optionally
appliances can optionally aggregate
can optionally aggregate small
optionally aggregate small suba
aggregate small suba raw
small suba raw socket
suba raw socket to
raw socket to its
socket to its intended
to its intended destination
kilobyte packets from different
packets from different flows
from different flows into
different flows into larger
flows into larger ones
into larger ones for
larger ones for using
ones for using fec
for using fec requires
using fec requires that
fec requires that each
requires that each data
that each data packet
each data packet have
data packet have a
packet have a unique
have a unique better
a unique better communication
unique better communication efficiency
better communication efficiency over
communication efficiency over the
efficiency over the long
distance identifier that the
identifier that the receiver
that the receiver can
the receiver can use
receiver can use to
can use to keep
use to keep track
to keep track of
keep track of re
in split flow control
split flow control mode
flow control mode they
control mode they can
mode they can ceived
they can ceived data
can ceived data packets
ceived data packets and
data packets and to
packets and to identify
and to identify missing
to identify missing data
identify missing data packets
missing data packets perform
data packets perform send
side buffering of in
flight data for multiin
data for multiin a
for multiin a repair
multiin a repair packet
if we had access
we had access to
had access to end
we gigabyte flows that
gigabyte flows that exceed
flows that exceed the
that exceed the sending
exceed the sending end
host s buffercould have
s buffercould have added
buffercould have added a
have added a header
added a header to
a header to each
header to each packet
to each packet with
each packet with a
packet with a unique
with a unique ing
a unique ing capacity
maelstrom appliances can act
appliances can act as
can act as mulsequence
act as mulsequence number
we intercept traffic trans
appliances send multicast packparently
send multicast packparently and
multicast packparently and need
packparently and need to
and need to route
need to route it
to route it without
route it without modification
it without modification or
without modification or addi
ets to each other
to each other across
each other across the
other across the long
we identify ip multicast
to spread them within
spread them within their
them within their datacenters
ip packets by a
packets by a tuple
by a tuple consisting
a tuple consisting of
tuple consisting of the
consisting of the source
of the source and
the source and des
appliances can take on
can take on other
take on other existing
on other existing roles
other existing roles in
existing roles in the
roles in the tination
in the tination ip
the tination ip address
size of the ip
of the ip datacenter
acting as security and
as security and vpn
security and vpn gateways
and vpn gateways and
vpn gateways and as
gateways and as header
and as header plus
as header plus data
and a checksum over
a checksum over the
checksum over the ip
over the ip data
the ip data pay
conventional performance enhancing proxies
the checksum over the
checksum over the payload
over the payload is
the payload is necessary
payload is necessary since
is necessary since the
necessary since the ip
since the ip identification
the ip identification field
ip identification field is
identification field is only
bits long and a
long and a single
and a single pair
a single pair of
single pair of end
hosts communicating at high
communicating at high speeds
at high speeds will
evaluation use the same
use the same identifier
the same identifier for
same identifier for different
identifier for different data
for different data packets
different data packets within
data packets within a
packets within a fairly
within a fairly short
a fairly short interval
fairly short interval unless
short interval unless the
interval unless the checksum
unless the checksum is
the checksum is added
checksum is added to
is added to we
added to we evaluated
to we evaluated maelstrom
we evaluated maelstrom on
evaluated maelstrom on the
maelstrom on the emulab
on the emulab testbed
the emulab testbed at
emulab testbed at utah
testbed at utah differentiate
at utah differentiate between
utah differentiate between them
for all the experiments
we used a dumbbell
used a dumbbell topoltifiers
a dumbbell topoltifiers result
dumbbell topoltifiers result in
topoltifiers result in garbled
result in garbled recovery
in garbled recovery by
garbled recovery by maelstrom
an event ogy of
event ogy of two
ogy of two clusters
of two clusters of
two clusters of nodes
clusters of nodes connected
of nodes connected via
nodes connected via routing
connected via routing nodes
via routing nodes which
routing nodes which will
nodes which will be
which will be caught
will be caught by
be caught by higher
caught by higher level
by higher level checksums
higher level checksums designed
level checksums designed with
checksums designed with a
designed with a high
latency link in between
link in between them
designed to emto deal
to emto deal with
emto deal with tranmission
deal with tranmission errors
with tranmission errors on
tranmission errors on commodity
errors on commodity networks
on commodity networks ulate
commodity networks ulate the
networks ulate the setup
ulate the setup in
the setup in figure
and ran the proxy
ran the proxy code
the proxy code on
proxy code on and
code on and hence
on and hence does
and hence does not
hence does not have
does not have significant
not have significant consequences
have significant consequences unless
significant consequences unless the
consequences unless the routers
shows the performance of
the performance of the
performance of the kernel
of the kernel version
the kernel version at
kernel version at gigabit
version at gigabit speeds
the remainder of the
remainder of the graphs
of the graphs it
the graphs it occurs
graphs it occurs frequently
the kernel version of
kernel version of maelstrom
version of maelstrom can
of maelstrom can generate
maelstrom can generate up
can generate up to
generate up to a
up to a show
to a show the
a show the performance
show the performance of
the performance of the
performance of the user
space version at slower
version at slower gigabit
at slower gigabit per
slower gigabit per second
gigabit per second of
per second of data
second of data and
of data and fec
data and fec traffic
to emulate the mtu
emulate the mtu difference
the mtu difference between
mtu difference between the
difference between the longput
between the longput data
the longput data rate
longput data rate depending
data rate depending on
rate depending on the
depending on the encoding
on the encoding rate
haul link and the
link and the datacenter
and the datacenter network
we were able to
were able to saturate
able to saturate the
to saturate the outgoing
saturate the outgoing card
the outgoing card at
outgoing card at set
card at set an
at set an mtu
set an mtu of
bytes on the network
on the network connecting
the network connecting the
network connecting the rates
connecting the rates as
the rates as high
rates as high as
with cpu overload occurring
cpu overload occurring at
overload occurring at end
hosts to the proxy
to the proxy and
the proxy and an
proxy and an mtu
and an mtu of
where each incoming data
each incoming data packet
incoming data packet had
data packet had to
packet had to be
had to be xored
to be xored long
haul link between proxies
the only exception is
only exception is figure
where we maintained equal
we maintained equal mtus
maintained equal mtus of
throughput metrics at the
metrics at the receive
incoming data packets are
data packets are buffered
packets are buffered so
are buffered so that
buffered so that they
so that they can
that they can be
they can be used
can be used in
be used in conjunction
used in conjunction with
in conjunction with figures
show that commodity tcp
ip throughxors to recover
throughxors to recover missing
to recover missing data
recover missing data packets
any received put collapses
received put collapses in
put collapses in the
collapses in the presence
in the presence of
the presence of non
and xor that is
xor that is missing
that is missing more
is missing more than
missing more than one
more than one data
than one data packet
one data packet is
data packet is stored
packet is stored that
is stored that maelstrom
stored that maelstrom successfully
that maelstrom successfully masks
maelstrom successfully masks loss
successfully masks loss and
masks loss and prevents
loss and prevents this
ip no loss maelstrom
no loss maelstrom no
loss maelstrom no loss
maelstrom no loss maelstrom
tcp no loss maelstrom
no loss maelstrom no
loss maelstrom no loss
maelstrom no loss maelstrom
one way link latency
way latency collapse from
latency collapse from occurring
shows the performance of
the performance of the
performance of the user
space version on a
mbps link and figure
shows the kernel version
the kernel version on
kernel version on a
the experiment in each
experiment in each case
in each case involves
each case involves running
case involves running iperf
flows from one node
from one node to
one node to another
node to another across
to another across the
another across the long
distance link with and
link with and without
with and without intermediary
and without intermediary maelstrom
without intermediary maelstrom proxies
intermediary maelstrom proxies and
maelstrom proxies and measuring
proxies and measuring obtained
and measuring obtained throughput
measuring obtained throughput while
obtained throughput while varying
throughput while varying loss
while varying loss rate
left graph on each
graph on each figure
the error bars on
error bars on the
bars on the graphs
on the graphs to
the graphs to the
graphs to the left
to the left are
the left are standard
left are standard errors
are standard errors of
standard errors of the
errors of the throughput
of the throughput over
the throughput over ten
throughput over ten runs
ip s cache of
s cache of tuning
cache of tuning parameters
of tuning parameters to
tuning parameters to allow
parameters to allow for
to allow for repeatable
allow for repeatable results
the clients in the
clients in the experiment
in the experiment are
the experiment are running
experiment are running tcp
ip reno on a
reno on a linux
the maelstrom parameters used
maelstrom parameters used are
parameters used are r
space version involved running
version involved running a
involved running a single
second iperf flow from
iperf flow from one
flow from one node
from one node to
one node to another
node to another with
to another with and
another with and without
with and without maelstrom
and without maelstrom running
without maelstrom running on
maelstrom running on the
running on the routers
on the routers and
the routers and measuring
routers and measuring throughput
and measuring throughput while
measuring throughput while varying
throughput while varying the
while varying the random
varying the random loss
the random loss rate
random loss rate on
loss rate on the
rate on the link
on the link and
the link and the
link and the one
to test the kernel
test the kernel version
the kernel version at
kernel version at gigabit
version at gigabit speeds
we ran eight parallel
ran eight parallel iperf
eight parallel iperf flows
parallel iperf flows from
iperf flows from one
flows from one node
from one node to
one node to another
node to another for
the curves obtained from
curves obtained from the
obtained from the two
from the two versions
the two versions are
two versions are almost
versions are almost identical
we present both to
present both to show
both to show that
to show that the
show that the kernel
that the kernel version
the kernel version successfully
kernel version successfully scales
version successfully scales up
successfully scales up the
scales up the performance
up the performance of
the performance of the
performance of the user
space version to hundreds
version to hundreds of
to hundreds of megabits
hundreds of megabits of
of megabits of traffic
megabits of traffic per
of traffic per second
we show how tcp
ip performance degrades on
performance degrades on a
ms link as the
link as the loss
as the loss rate
the loss rate is
loss rate is increased
rate is increased from
maelstrom masks loss up
masks loss up to
without significant throughput degradation
with the kernel version
the kernel version achieving
kernel version achieving two
version achieving two orders
achieving two orders of
two orders of magnitude
orders of magnitude higher
of magnitude higher throughput
magnitude higher throughput that
higher throughput that conventional
throughput that conventional tcp
the graphs on the
graphs on the right
on the right side
the right side of
right side of figures
ip throughput declining on
throughput declining on a
declining on a link
on a link of
a link of increasing
link of increasing length
of increasing length when
increasing length when subjected
length when subjected to
when subjected to uniform
subjected to uniform loss
to uniform loss rates
uniform loss rates of
the top line in
top line in the
line in the graphs
in the graphs is
the graphs is the
graphs is the performance
is the performance of
the performance of tcp
ip without loss and
without loss and provides
loss and provides an
and provides an upper
provides an upper bound
an upper bound for
upper bound for performance
bound for performance on
for performance on the
performance on the link
space and kernel versions
maelstrom masks packet loss
masks packet loss and
packet loss and tracks
loss and tracks the
and tracks the lossless
tracks the lossless line
the lossless line closely
lagging only when the
only when the link
when the link latency
the link latency is
link latency is low
latency is low and
is low and tcp
ip s throughput is
s throughput is very
throughput is very high
ip to attain very
to attain very high
attain very high speeds
very high speeds on
high speeds on the
speeds on the gi
way delivery latency against
delivery latency against loss
latency against loss rate
packet delivery latencies gabit
delivery latencies gabit link
we had to set
had to set the
to set the mtu
set the mtu of
the mtu of the
mtu of the entire
of the entire path
the entire path to
entire path to be
path to be the
to be the maximum
which meant that the
meant that the longhaul
that the longhaul link
the longhaul link had
longhaul link had the
link had the same
had the same mtu
the same mtu as
same mtu as the
mtu as the inter
this resulted in the
resulted in the fragmentation
in the fragmentation of
the fragmentation of repair
fragmentation of repair packets
of repair packets sent
repair packets sent over
packets sent over udp
sent over udp on
over udp on the
udp on the long
haul link into two
link into two ip
into two ip packet
two ip packet fragments
since the loss of
the loss of a
loss of a single
of a single fragment
a single fragment resulted
single fragment resulted in
fragment resulted in the
resulted in the loss
in the loss of
the loss of the
loss of the repair
we observed a higher
observed a higher loss
a higher loss rate
higher loss rate for
loss rate for repairs
rate for repairs than
for repairs than for
repairs than for data
than for data packets
we expect performance to
expect performance to be
performance to be better
to be better on
be better on a
better on a network
on a network where
a network where the
network where the mtu
where the mtu of
the mtu of the
mtu of the long
haul link is truly
link is truly larger
is truly larger than
truly larger than the
larger than the mtu
than the mtu within
the mtu within each
mtu within each cluster
latency metrics to measure
metrics to measure the
to measure the latency
measure the latency effects
the latency effects of
latency effects of tcp
mbps stream between two
stream between two nodes
between two nodes over
two nodes over a
and simultaneously ran a
mbps flow alongside on
flow alongside on the
alongside on the same
on the same link
the same link to
same link to simulate
link to simulate a
to simulate a real
time stream combined with
stream combined with other
combined with other intercluster
with other intercluster traffic
shows the average delivery
the average delivery latency
average delivery latency of
level packets in the
as loss rates go
loss rates go up
shows the same scenario
the same scenario with
same scenario with a
scenario with a constant
with a constant uniformly
a constant uniformly random
constant uniformly random loss
uniformly random loss rate
random loss rate of
and varying oneway latency
maelstrom s delivery latency
s delivery latency is
delivery latency is almost
latency is almost exactly
is almost exactly equal
almost exactly equal to
exactly equal to the
equal to the one
way latency on the
latency on the link
ip takes more than
takes more than twice
more than twice as
than twice as long
twice as long once
as long once one
way latencies go past
plots delivery latency against
delivery latency against message
latency against message identifier
the spikes in latency
spikes in latency are
in latency are triggered
latency are triggered by
are triggered by losses
triggered by losses that
by losses that lead
losses that lead to
that lead to packets
lead to packets piling
to packets piling up
packets piling up at
piling up at the
up at the receiver
a key point is
key point is that
point is that we
is that we are
that we are plotting
we are plotting the
are plotting the delivery
plotting the delivery latency
the delivery latency of
delivery latency of all
latency of all packets
not just lost ones
ip delays correctly received
delays correctly received packets
correctly received packets while
received packets while waiting
packets while waiting for
while waiting for missing
waiting for missing packets
for missing packets sequenced
missing packets sequenced earlier
packets sequenced earlier by
sequenced earlier by the
earlier by the sender
by the sender the
the sender the effect
sender the effect of
the effect of this
effect of this is
of this is shown
this is shown in
is shown in figure
where single packet losses
single packet losses cause
packet losses cause spikes
losses cause spikes in
cause spikes in delivery
spikes in delivery latency
in delivery latency that
delivery latency that last
latency that last for
that last for hundreds
last for hundreds of
for hundreds of packets
the low data rate
low data rate in
data rate in the
rate in the flow
in the flow of
the flow of roughly
kb packets per rtt
packets per rtt makes
per rtt makes tcp
ip flow control delays
flow control delays at
control delays at the
delays at the sender
at the sender unlikely
given that the congestion
that the congestion control
the congestion control algorithm
congestion control algorithm is
control algorithm is reno
which implements fast recovery
implements fast recovery and
fast recovery and halves
recovery and halves the
and halves the congestion
halves the congestion window
the congestion window on
congestion window on packet
window on packet loss
on packet loss rather
packet loss rather than
loss rather than resetting
rather than resetting it
than resetting it completely
the maelstrom configuration used
maelstrom configuration used is
relatively prime interleaves offer
prime interleaves offer better
interleaves offer better performance
offer better performance r
layered interleaving and bursty
interleaving and bursty loss
and bursty loss thus
bursty loss thus far
loss thus far we
thus far we have
far we have shown
we have shown how
have shown how maelstrom
shown how maelstrom effectively
how maelstrom effectively hides
maelstrom effectively hides loss
effectively hides loss from
hides loss from tcp
ip for packets dropped
for packets dropped with
packets dropped with uniform
dropped with uniform randomness
we examine the performance
examine the performance of
the performance of the
performance of the layered
of the layered interleaving
the layered interleaving algorithm
showing how different parameterizations
how different parameterizations handle
different parameterizations handle bursty
parameterizations handle bursty loss
handle bursty loss patterns
we use a loss
use a loss model
a loss model where
loss model where packets
model where packets are
where packets are dropped
packets are dropped in
are dropped in bursts
dropped in bursts of
in bursts of fixed
bursts of fixed length
allowing us to study
us to study the
to study the impact
study the impact of
the impact of burst
impact of burst length
of burst length on
burst length on performance
the link has a
link has a one
ms and a loss
and a loss rate
a loss rate of
where it is varied
mbps flow of udp
flow of udp packets
of udp packets is
udp packets is sent
packets is sent over
is sent over it
we show that our
show that our observation
that our observation in
our observation in section
is correct for high
correct for high loss
for high loss rates
high loss rates if
loss rates if the
rates if the interleaves
if the interleaves are
the interleaves are relatively
interleaves are relatively prime
performance improves substantially when
improves substantially when loss
substantially when loss rates
when loss rates are
loss rates are high
rates are high and
are high and losses
high and losses are
and losses are bursty
the graph plots the
graph plots the percentage
plots the percentage of
the percentage of lost
percentage of lost packets
of lost packets successfully
lost packets successfully recovered
packets successfully recovered on
successfully recovered on the
recovered on the y
axis against an x
axis of loss rates
of loss rates on
loss rates on a
rates on a log
on a log scale
the maelstrom configuration used
maelstrom configuration used is
configuration used is r
we show the ability
show the ability of
the ability of layered
ability of layered interleaving
of layered interleaving to
layered interleaving to provide
interleaving to provide gracefully
to provide gracefully degrading
provide gracefully degrading performance
gracefully degrading performance in
degrading performance in the
performance in the face
in the face of
the face of bursty
face of bursty loss
we plot the percentage
plot the percentage of
the percentage of lost
percentage of lost packets
of lost packets successfully
lost packets successfully recovered
packets successfully recovered against
successfully recovered against the
recovered against the length
against the length of
the length of loss
length of loss bursts
of loss bursts for
loss bursts for two
bursts for two different
for two different sets
two different sets of
different sets of interleaves
and in the bottom
in the bottom graph
the bottom graph we
bottom graph we plot
graph we plot the
we plot the average
plot the average latency
the average latency at
average latency at which
latency at which the
at which the packets
which the packets were
the packets were recovered
recovery latency is defined
latency is defined as
is defined as the
defined as the difference
as the difference between
the difference between the
difference between the eventual
between the eventual delivery
the eventual delivery time
eventual delivery time of
delivery time of the
time of the recovered
of the recovered packet
the recovered packet and
recovered packet and the
packet and the one
way latency of the
latency of the link
we confirmed that the
confirmed that the emulab
that the emulab link
the emulab link had
emulab link had almost
link had almost no
had almost no jitter
almost no jitter on
no jitter on correctly
jitter on correctly delivered
on correctly delivered packets
way latency an accurate
latency an accurate estimate
an accurate estimate of
accurate estimate of expected
estimate of expected lossless
of expected lossless delivery
expected lossless delivery time
increasing the interleaves results
the interleaves results in
interleaves results in much
results in much higher
in much higher recovery
much higher recovery percentages
higher recovery percentages at
recovery percentages at large
percentages at large burst
at large burst sizes
but percentage of packets
percentage of packets recovered
percentage of packets recovered
layered interleaving recovery percentage
interleaving recovery percentage and
recovery percentage and latency
percentage and latency comes
and latency comes at
latency comes at the
comes at the cost
at the cost of
the cost of higher
cost of higher recovery
of higher recovery latency
set of interleaves catches
of interleaves catches almost
interleaves catches almost all
catches almost all packets
almost all packets in
all packets in an
packets in an extended
in an extended burst
an extended burst of
packets at an average
at an average latency
an average latency of
average latency of around
while repairing all random
repairing all random singleton
all random singleton losses
random singleton losses within
the graphs also show
graphs also show recovery
also show recovery latency
show recovery latency rising
recovery latency rising gracefully
latency rising gracefully with
rising gracefully with the
gracefully with the increase
with the increase in
the increase in loss
increase in loss burst
in loss burst length
the longer the burst
the longer it takes
longer it takes to
it takes to recover
takes to recover the
to recover the lost
recover the lost packets
the maelstrom configuration used
maelstrom configuration used is
configuration used is r
we show histograms of
show histograms of recovery
histograms of recovery latencies
of recovery latencies for
recovery latencies for the
latencies for the two
for the two interleave
the two interleave configurations
two interleave configurations under
interleave configurations under different
configurations under different burst
under different burst lengths
the histograms confirm the
histograms confirm the trends
confirm the trends described
the trends described above
packet recoveries take longer
recoveries take longer from
take longer from left
longer from left to
from left to right
left to right as
to right as we
right as we increase
as we increase loss
we increase loss burst
increase loss burst length
and from top to
from top to bottom
top to bottom as
to bottom as we
bottom as we increase
as we increase the
we increase the interleave
increase the interleave values
illustrates the difference between
the difference between a
difference between a traditional
between a traditional fec
a traditional fec code
traditional fec code and
fec code and layered
code and layered interleaving
and layered interleaving by
layered interleaving by plotting
interleaving by plotting a
element moving average of
moving average of recovery
average of recovery latencies
of recovery latencies for
recovery latencies for both
latencies for both codes
the channel is configured
channel is configured to
is configured to lose
configured to lose singleton
to lose singleton packets
lose singleton packets randomly
singleton packets randomly at
packets randomly at a
randomly at a loss
at a loss rate
a loss rate of
and additionally lose long
additionally lose long bursts
lose long bursts of
packets at occasional intervals
both codes recovery latency
reed solomon layered interleaving
solomon versus layered interleaving
versus layered interleaving are
layered interleaving are configured
interleaving are configured with
are configured with r
and recover all lost
recover all lost packets
all lost packets reed
solomon uses an interleave
uses an interleave of
and layered interleaving uses
layered interleaving uses interleaves
interleaving uses interleaves of
and consequently both have
consequently both have a
both have a maximum
have a maximum tolerable
a maximum tolerable burst
maximum tolerable burst length
tolerable burst length of
we use a publicly
use a publicly available
a publicly available implementation
publicly available implementation of
available implementation of a
implementation of a reed
solomon code based on
code based on vandermonde
based on vandermonde matrices
the code is plugged
code is plugged into
is plugged into maelstrom
plugged into maelstrom instead
into maelstrom instead of
maelstrom instead of layered
instead of layered interleaving
showing that we can
that we can use
we can use new
can use new encodings
use new encodings within
new encodings within the
encodings within the same
within the same framework
the same framework seamlessly
solomon code recovers all
code recovers all lost
recovers all lost packets
all lost packets with
lost packets with roughly
packets with roughly the
with roughly the same
roughly the same latency
the same latency whereas
same latency whereas layered
latency whereas layered interleaving
whereas layered interleaving recovers
layered interleaving recovers singleton
interleaving recovers singleton losses
recovers singleton losses almost
singleton losses almost immediately
losses almost immediately and
almost immediately and exhibits
immediately and exhibits latency
and exhibits latency spikes
exhibits latency spikes whenever
latency spikes whenever the
spikes whenever the longer
whenever the longer loss
the longer loss burst
longer loss burst occurs
related work a significant
work a significant body
a significant body of
significant body of work
body of work on
of work on application
work on application and
on application and tcp
ip performance over high
distance networks exists in
networks exists in the
exists in the context
in the context of
the context of high
the use of parallel
use of parallel sockets
of parallel sockets for
parallel sockets for higher
sockets for higher throughput
for higher throughput in
higher throughput in the
throughput in the face
in the face of
the face of non
congestion loss was proposed
loss was proposed in
was proposed in psockets
a number of protocols
number of protocols have
of protocols have been
protocols have been suggested
have been suggested as
been suggested as replacements
suggested as replacements for
as replacements for tcp
ip in such settings
in such settings xcp
are a few but
a few but all
few but all require
but all require modifications
all require modifications to
require modifications to end
or the intervening network
some approaches seek to
approaches seek to differentiate
seek to differentiate between
to differentiate between congestion
differentiate between congestion and
between congestion and non
maelstrom is a transparent
is a transparent performance
a transparent performance enhancing
transparent performance enhancing proxy
as defined in rfc
numerous implementations of peps
implementations of peps exist
of peps exist for
peps exist for improving
exist for improving tcp
for improving tcp performance
improving tcp performance on
tcp performance on satellite
but we are not
we are not aware
are not aware of
not aware of any
aware of any peps
of any peps that
any peps that use
peps that use fec
that use fec to
use fec to mask
fec to mask errors
to mask errors on
mask errors on long
based fec for reliable
fec for reliable communication
for reliable communication was
reliable communication was first
communication was first explored
was first explored by
first explored by rizzo
suggested the use of
the use of fec
use of fec for
of fec for tcp
ip retransmissions over aggregated
retransmissions over aggregated traffic
over aggregated traffic within
aggregated traffic within an
traffic within an overlay
within an overlay network
an overlay network in
overlay network in the
network in the commodity
in the commodity internet
uses fec for real
modulating the rate of
the rate of encoding
rate of encoding adaptively
the use of end
host fec under tcp
ip has been explored
has been explored in
a multitude of different
multitude of different fec
of different fec encodings
different fec encodings exist
fec encodings exist in
encodings exist in literature
they can broadly be
can broadly be categorized
broadly be categorized into
be categorized into optimal
categorized into optimal erasure
into optimal erasure codes
optimal erasure codes and
erasure codes and near
known optimal code is
optimal code is reed
which we described previously
we described previously as
described previously as generating
previously as generating c
as generating c repair
generating c repair packets
c repair packets from
repair packets from r
packets from r source
from r source packets
any r of the
r of the resulting
of the resulting r
c packets can be
packets can be used
can be used to
be used to reconstruct
used to reconstruct the
to reconstruct the r
reconstruct the r source
the r source packets
optimal codes such as
codes such as tornado
such as tornado and
as tornado and lt
off encoding speed for
encoding speed for large
speed for large data
for large data sizes
large data sizes against
data sizes against a
sizes against a loss
against a loss of
a loss of optimality
loss of optimality the
of optimality the receiver
optimality the receiver needs
the receiver needs to
receiver needs to receive
needs to receive slightly
to receive slightly more
receive slightly more than
slightly more than r
more than r source
than r source or
r source or repair
source or repair packets
or repair packets to
repair packets to regenerate
packets to regenerate the
to regenerate the original
regenerate the original r
the original r data
original r data packets
optimal codes are extremely
codes are extremely fast
are extremely fast for
extremely fast for encoding
fast for encoding over
for encoding over large
encoding over large sets
over large sets of
large sets of data
sets of data but
of data but not
data but not of
but not of significant
not of significant importance
of significant importance for
significant importance for real
since optimal codes perform
optimal codes perform equally
codes perform equally well
perform equally well with
equally well with small
well with small data
with small data sizes
of particular relevance are
particular relevance are growth
relevance are growth codes
which use multiple encoding
use multiple encoding rates
multiple encoding rates for
encoding rates for different
rates for different overhead
for different overhead levels
layered interleaving uses multiple
interleaving uses multiple interleaves
uses multiple interleaves for
multiple interleaves for different
interleaves for different burst
for different burst resilience
different burst resilience levels
burst resilience levels without
resilience levels without modulating
levels without modulating the
without modulating the encoding
modulating the encoding rate
the effect of random
effect of random losses
of random losses on
random losses on tcp
ip has been studied
has been studied in
been studied in depth
studied in depth by
in depth by lakshman
padhye s analytical model
provides a means to
a means to gauge
means to gauge the
to gauge the impact
gauge the impact of
the impact of packet
impact of packet loss
of packet loss on
packet loss on tcp
while most published studies
most published studies of
published studies of packet
studies of packet loss
of packet loss are
packet loss are based
loss are based on
are based on the
based on the commodity
on the commodity internet
the commodity internet rather
commodity internet rather than
internet rather than highspeed
rather than highspeed lambda
than highspeed lambda links
study the sprint backbone
the sprint backbone and
sprint backbone and make
backbone and make two
and make two observations
make two observations that
two observations that could
observations that could be
that could be explained
could be explained by
be explained by non
links are rarely loaded
are rarely loaded at
rarely loaded at more
loaded at more than
of capacity and b
packet reordering events occur
reordering events occur for
events occur for some
occur for some flows
possibly indicating packet loss
indicating packet loss followed
packet loss followed by
loss followed by retransmissions
future work scaling maelstrom
work scaling maelstrom to
scaling maelstrom to multiple
maelstrom to multiple gigabits
to multiple gigabits per
multiple gigabits per second
gigabits per second of
per second of traffic
second of traffic will
of traffic will require
traffic will require small
will require small rack
style clusters of tens
clusters of tens of
of tens of machines
tens of machines to
of machines to distribute
machines to distribute encoding
to distribute encoding load
distribute encoding load over
we need to design
need to design intelligent
to design intelligent load
over mechanisms for such
mechanisms for such a
for such a scheme
we have described layered
have described layered interleaving
described layered interleaving with
layered interleaving with fixed
and the next step
the next step in
next step in extending
step in extending this
in extending this protocol
extending this protocol is
this protocol is to
protocol is to make
is to make it
to make it adaptive
changing interleaves and rate
interleaves and rate as
and rate as loss
rate as loss patterns
as loss patterns in
loss patterns in the
patterns in the link
in the link change
conclusion modern distributed systems
modern distributed systems are
distributed systems are compelled
systems are compelled by
are compelled by real
world imperatives to coordinate
imperatives to coordinate across
to coordinate across datacenters
coordinate across datacenters separated
across datacenters separated by
latency histograms for i
latency histograms for i
packet loss cripples the
loss cripples the performance
cripples the performance notes
the performance notes of
performance notes of such
notes of such systems
and reliability and flow
are increasingly popular and
increasingly popular and designed
popular and designed for
and designed for lans
designed for lans and
or the commodity internet
the commodity internet fail
commodity internet fail to
internet fail to used
fail to used for
to used for applications
used for applications such
for applications such as
applications such as efficiently
such as efficiently distributing
as efficiently distributing bulk
efficiently distributing bulk data
achieve optimal performance on
optimal performance on the
performance on the high
it is not obvious
is not obvious that
not obvious that these
obvious that these have
that these have utility
these have utility in
have utility in real
time communi lambda networks
communi lambda networks linking
lambda networks linking datacenters
protocols is not an
is not an option
not an option for
an option for commodity
option for commodity clusters
for commodity clusters where
commodity clusters where standardization
clusters where standardization is
where standardization is critical
standardization is critical for
is critical for cost
critical for cost mitigation
maelstrom is an edge
is an edge appliance
an edge appliance that
edge appliance that uses
appliance that uses forward
that uses forward error
uses forward error correction
forward error correction references
error correction references to
correction references to mask
references to mask packet
to mask packet loss
mask packet loss from
packet loss from end
global crossing current network
crossing current network performance
ip throughput and latency
throughput and latency by
and latency by orders
latency by orders of
by orders of magninetwork
last tude when loss
tude when loss occurs
maelstrom is easy to
is easy to install
easy to install and
to install and accessed
install and accessed feb
and is completely transparent
is completely transparent to
completely transparent to applications
transparent to applications and
qwest ip network statistics
protocols literally providing reliability
literally providing reliability in
providing reliability in an
reliability in an inexpennet
acknowledgments we would like
we would like to
would like to thank
like to thank our
to thank our shepherd
thank our shepherd robert
our shepherd robert morris
shepherd robert morris and
robert morris and the
morris and the other
and the other reviewers
the other reviewers for
other reviewers for extensive
reviewers for extensive comments
for extensive comments that
extensive comments that significantly
comments that significantly shaped
that significantly shaped the
significantly shaped the final
shaped the final version
the final version of
final version of the
version of the paper
vidhyashankar venkataraman and vivek
venkataraman and vivek vishnumurthy
and vivek vishnumurthy provided
vivek vishnumurthy provided useful
vishnumurthy provided useful comments
tom boures provided valuable
boures provided valuable insight
provided valuable insight into
valuable insight into the
insight into the quality
into the quality of
the quality of existing
quality of existing fiber
of existing fiber links
stanislav shalunov provided information
shalunov provided information on
provided information on loss
information on loss rates
on loss rates on
loss rates on internet
and paul wefel gave
paul wefel gave us
wefel gave us access
gave us access to
us access to teragrid
access to teragrid loss
to teragrid loss measurements
nat and packet mangling
and packet mangling for
packet mangling for linux
lateral error correction for
error correction for timecritical
correction for timecritical multicast
fourth usenix symposium on
usenix symposium on networked
symposium on networked systems
on networked systems design
networked systems design and
systems design and implementation
performance enhancing proxies intended
enhancing proxies intended to
proxies intended to mitigate
intended to mitigate link
enhanced loss differentiation algorithms
loss differentiation algorithms for
differentiation algorithms for use
algorithms for use in
for use in tcp
use in tcp sources
in tcp sources over
tcp sources over heterogeneous
sources over heterogeneous wireless
over heterogeneous wireless networks
ieee global telecommunications conference
flow aggregation for enhanced
aggregation for enhanced tcp
for enhanced tcp over
enhanced tcp over wide
tcp over wide area
over wide area wireless
vice president of research
president of research and
of research and t
multicast routing in datagram
routing in datagram internetworks
in datagram internetworks and
datagram internetworks and extended
internetworks and extended lans
level traffic measurements from
traffic measurements from the
measurements from the sprint
from the sprint ip
the sprint ip backbone
a transport protocol for
transport protocol for grid
protocol for grid computing
journal of grid computing
optical domain performance monitoring
optical fiber communication conference
end performance effects of
performance effects of parallel
effects of parallel tcp
of parallel tcp sockets
parallel tcp sockets on
tcp sockets on a
sockets on a lossy
on a lossy wide
the effects of systemic
effects of systemic packet
of systemic packet loss
systemic packet loss on
packet loss on aggregate
loss on aggregate tcp
on aggregate tcp flows
ieee conference on supercomputing
predictable high performance bulk
high performance bulk data
performance bulk data transfer
ieee international conference on
international conference on cluster
conference on cluster computing
the case for packet
case for packet level
for packet level fec
proceedings of the tc
fifth international workshop on
international workshop on protocols
workshop on protocols for
on protocols for high
gigabit ethernet on commodity
ethernet on commodity systems
where did my performance
did my performance go
rate limiting rears its
limiting rears its ugly
rears its ugly head
isn t quite enough
modified tcp congestion avoidance
tcp congestion avoidance algorithm
physical layer impact upon
layer impact upon packet
impact upon packet errors
passive and active measurement
and active measurement workshop
maximizing sensor network data
sensor network data persistence
in proceedings of acm
proceedings of acm sigcomm
congestion control for high
control for high bandwidth
and protocols for computer
protocols for computer communications
journal of lightwave technology
a cross layer study
cross layer study of
layer study of packet
study of packet loss
of packet loss in
packet loss in all
the performance of tcp
ip for networks with
for networks with high
networks with high bandwidth
delay products and random
products and random loss
acm transactions on networking
rd annual ieee symposium
annual ieee symposium on
ieee symposium on foundations
symposium on foundations of
on foundations of computer
foundations of computer science
end forward error correction
international zurich seminar on
zurich seminar on communications
rateless codes and big
codes and big downloads
paritybased loss recovery for
loss recovery for reliable
recovery for reliable multicast
for reliable multicast transmission
in proceedings of the
proceedings of the acm
of the acm sigcomm
a simple model and
simple model and its
model and its empirical
and its empirical validation
an adaptive forward error
adaptive forward error correction
forward error correction protocol
error correction protocol for
correction protocol for end
computer communications and networks
th international conference on
businesses see the light
effective erasure codes for
erasure codes for reliable
codes for reliable computer
for reliable computer communication
reliable computer communication protocols
on the feasibility of
the feasibility of software
feasibility of software fec
the case for application
level network striping for
network striping for data
striping for data intensive
for data intensive applications
data intensive applications using
intensive applications using high
applications using high speed
using high speed wide
high speed wide area
speed wide area networks
ieee conference on supercomputing
google s secret plans
s secret plans for
secret plans for all
plans for all that
for all that dark
all that dark fiber
an overlay based architecture
overlay based architecture for
based architecture for enhancing
architecture for enhancing internet
for enhancing internet qos
first usenix symposium on
usenix symposium on networked
symposium on networked systems
on networked systems design
networked systems design and
systems design and implementation
udp bandwidth measurement tool
a tcp performance enhancing
tcp performance enhancing proxy
performance enhancing proxy for
enhancing proxy for satellite
proxy for satellite links
proceedings of the second
of the second international
the second international ifip
networking conference on networking
conference on networking technologies
performance of computer and
of computer and communication
computer and communication networks
and mobile and wireless
mobile and wireless communications
tsunami file transfer protocol
workshop on protocols for
on protocols for fast
protocols for fast longdistance
for fast longdistance networks
the university of illinois
university of illinois national
of illinois national center
illinois national center for
national center for supercomputing
center for supercomputing applications
an integrated experimental environment
integrated experimental environment for
experimental environment for distributed
environment for distributed systems
for distributed systems and
distributed systems and networks
of the fifth symposium
the fifth symposium on
fifth symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
solomon codes and their
codes and their applications
Thread 1 results back
1848 1786 1843 1896 1907 1869 1785 1889 1843 1865 
Thread 2 results back
784 807 746 764 804 835 847 721 765 796 
Thread 3 results back
739 726 656 714 707 702 733 728 696 699 
Thread 4 results back
613 606 600 611 618 555 657 613 644 590 
Thread 5 results back
587 577 582 544 556 563 584 563 586 604 
Thread 6 results back
394 421 429 411 377 446 404 376 409 412 
Thread 7 results back
337 375 379 374 378 332 376 344 388 344 
Thread 8 results back
558 546 507 501 537 541 523 521 535 490 
Thread 9 results back
434 445 411 417 433 467 412 380 444 445 
the: 7744
of: 4121
a: 3489
to: 3267
and: 3193
in: 2417
is: 1914
for: 1353
that: 1296
with: 990
on: 965
are: 940
we: 925
as: 917
it: 771
by: 745
be: 695
this: 681
data: 659
pool: 659
s: 654
an: 631
at: 630
can: 574
system: 559
its: 497
from: 483
not: 466
or: 452
r: 429
which: 418
each: 404
file: 401
all: 377
systems: 372
m: 368
if: 362
figure: 357
x: 343
one: 338
time: 335
nodes: 332
pools: 325
revenue: 325
t: 325
packets: 320
rate: 320
other: 317
cache: 310
but: 309
our: 291
have: 289
work: 287
i: 282
performance: 281
such: 271
when: 268
loss: 258
p: 258
miners: 257
has: 252
bandwidth: 251
packet: 244
c: 243
network: 242
their: 236
will: 232
attack: 230
block: 230
mining: 230
j: 228
these: 223
than: 222
only: 221
end: 220
use: 220
they: 218
more: 216
node: 209
bitcoin: 204
no: 204
high: 203
number: 202
services: 200
latency: 197
b: 196
may: 193
transactions: 192
would: 192
server: 190
two: 188
where: 188
update: 187
power: 182
between: 180
used: 177
based: 174
d: 173
over: 171
any: 170
different: 169
distributed: 166
miner: 164
new: 164
single: 164
also: 162
client: 161
some: 161
large: 159
tcp: 159
was: 157
web: 157
since: 153
objects: 152
application: 150
ip: 150
service: 150
using: 149
updates: 146
e: 144
protocol: 144
them: 144
set: 140
read: 139
access: 138
applications: 137
process: 137
files: 134
transaction: 133
maelstrom: 132
traffic: 132
there: 131
operating: 130
gossip: 129
however: 129
into: 129
section: 129
withholding: 129
rates: 128
example: 127
mfs: 127
so: 127
communication: 124
consistency: 124
both: 122
same: 122
size: 122
object: 121
priorities: 120
repair: 120
even: 119
peer: 119
throughput: 119
chain: 118
g: 116
control: 114
failure: 114
information: 113
while: 113
first: 112
recovery: 112
were: 112
results: 111
database: 110
protocols: 110
case: 109
acm: 106
link: 106
low: 106
therefore: 106
then: 105
without: 105
rpcs: 104
small: 104
clients: 103
writes: 103
networks: 102
could: 101
second: 101
ms: 100
rpc: 99
do: 98
many: 98
asynchronous: 97
writeback: 97
log: 96
model: 96
within: 96
group: 95
send: 95
does: 94
proof: 94
most: 93
up: 93
memory: 92
state: 91
user: 91
average: 90
content: 90
version: 90
level: 89
order: 89
back: 87
been: 87
support: 87
less: 86
through: 85
windows: 85
available: 84
groups: 84
long: 84
out: 84
see: 84
after: 83
another: 83
approach: 83
fec: 83
full: 83
how: 83
against: 82
architecture: 82
infiltration: 82
message: 82
o: 82
disk: 81
k: 81
messages: 81
need: 81
qsm: 81
about: 80
kb: 80
multicast: 80
sender: 80
uses: 80
management: 79
n: 79
q: 79
way: 79
delivery: 78
total: 78
disks: 77
experiments: 77
possible: 77
write: 77
design: 76
higher: 76
delay: 75
increase: 75
layer: 75
local: 75
research: 75
scale: 75
upload: 75
computer: 74
f: 74
implementation: 74
might: 74
source: 74
analysis: 73
burst: 73
live: 73
probability: 73
workloads: 73
accesses: 72
because: 72
every: 72
lost: 72
solution: 71
cost: 70
due: 70
step: 70
v: 70
value: 70
equilibrium: 69
like: 69
multiple: 69
manager: 68
per: 68
priority: 68
well: 68
list: 67
overhead: 67
computing: 66
load: 66
running: 66
cornell: 65
http: 65
mechanism: 65
opportunistic: 65
run: 65
should: 65
under: 65
attacking: 64
cluster: 64
operations: 64
proceedings: 64
servers: 64
show: 64
shown: 64
test: 64
attacks: 63
layered: 63
much: 63
paper: 63
partial: 63
received: 63
stream: 63
attacker: 62
dependency: 62
kernel: 62
point: 62
solutions: 62
event: 61
l: 61
maximum: 61
must: 61
scheme: 61
shows: 61
sizes: 61
code: 60
game: 60
interleave: 60
prefetching: 60
proofs: 60
replication: 60
result: 60
round: 60
storage: 60
us: 60
perform: 59
sending: 59
very: 59
inconsistency: 58
once: 58
provide: 58
threshold: 58
users: 58
workload: 58
flow: 57
scalable: 57
sent: 57
similar: 57
streaming: 57
being: 56
conference: 56
symposium: 56
download: 55
nt: 55
problem: 55
random: 55
receiver: 55
reduce: 55
requests: 55
until: 55
before: 54
correct: 54
factor: 54
global: 54
graph: 54
interleaving: 54
larger: 54
open: 54
processes: 54
range: 54
retrieved: 54
among: 53
auditing: 53
caching: 53
cannot: 53
h: 53
scenario: 53
center: 52
fetch: 52
mode: 52
real: 52
synchronous: 52
take: 52
transactional: 52
according: 51
form: 51
ieee: 51
increasing: 51
internet: 51
make: 51
present: 51
reads: 51
xor: 51
able: 50
algorithm: 50
current: 50
had: 50
inconsistencies: 50
mobile: 50
store: 50
components: 49
contention: 49
either: 49
existing: 49
hence: 49
mechanisms: 49
mi: 49
now: 49
three: 49
whether: 49
encoding: 48
general: 48
host: 48
implemented: 48
own: 48
prefetch: 48
recovered: 48
reliable: 48
values: 48
although: 47
important: 47
pp: 47
side: 47
w: 47
behavior: 46
execution: 46
fixed: 46
function: 46
generated: 46
graphs: 46
operation: 46
platform: 46
request: 46
speed: 46
th: 46
consider: 45
designed: 45
shared: 45
significant: 45
university: 45
victim: 45
window: 45
attacked: 44
blocks: 44
com: 44
community: 44
delays: 44
density: 44
error: 44
future: 44
hosted: 44
kbps: 44
left: 44
pages: 44
smaller: 44
standard: 44
wide: 44
appliance: 43
changes: 43
component: 43
costs: 43
events: 43
fig: 43
here: 43
makes: 43
ratio: 43
required: 43
right: 43
thus: 43
y: 43
allows: 42
amount: 42
change: 42
developers: 42
distribution: 42
experiment: 42
just: 42
often: 42
rather: 42
scalability: 42
seen: 42
start: 42
tasks: 42
uniform: 42
what: 42
cloud: 41
effect: 41
mafs: 41
missing: 41
numbers: 41
optimal: 41
reduced: 41
simple: 41
ssa: 41
strategy: 41
across: 40
address: 40
detection: 40
down: 40
further: 40
given: 40
hosts: 40
lower: 40
next: 40
non: 40
receive: 40
sends: 40
software: 40
token: 40
typically: 40
allow: 39
caches: 39
cases: 39
congestion: 39
directly: 39
entire: 39
increases: 39
independent: 39
interface: 39
length: 39
original: 39
overheads: 39
part: 39
structure: 39
times: 39
compared: 38
described: 38
direct: 38
during: 38
microsoft: 38
region: 38
require: 38
revenues: 38
world: 38
accessed: 37
al: 37
birman: 37
centers: 37
codes: 37
effective: 37
enough: 37
et: 37
improve: 37
losses: 37
membership: 37
provides: 37
xors: 37
better: 36
clusters: 36
consistent: 36
describe: 36
expected: 36
fact: 36
fast: 36
loyal: 36
previous: 36
related: 36
relative: 36
techniques: 36
today: 36
types: 36
adaptation: 35
additional: 35
almost: 35
commodity: 35
environment: 35
https: 35
international: 35
last: 35
links: 35
longer: 35
minimum: 35
needs: 35
org: 35
performed: 35
proxy: 35
reliability: 35
still: 35
though: 35
above: 34
acid: 34
earlier: 34
evaluation: 34
factors: 34
injection: 34
interleaves: 34
ken: 34
levels: 34
managed: 34
percentage: 34
remote: 34
sets: 34
several: 34
virtual: 34
www: 34
constant: 33
denote: 33
limited: 33
note: 33
overall: 33
particular: 33
receiving: 33
top: 33
working: 33
assume: 32
become: 32
clustered: 32
detect: 32
find: 32
including: 32
period: 32
replicated: 32
scenarios: 32
seconds: 32
space: 32
stable: 32
table: 32
technologies: 32
technology: 32
those: 32
trace: 32
versions: 32
added: 31
ensure: 31
evaluate: 31
finally: 31
follows: 31
immediately: 31
invalidations: 31
least: 31
mb: 31
overlay: 31
prediction: 31
principles: 31
receivers: 31
requires: 31
runs: 31
sirp: 31
target: 31
udp: 31
achieve: 30
adaptive: 30
amazon: 30
auditors: 30
collaboration: 30
correction: 30
dropped: 30
good: 30
incoming: 30
lists: 30
members: 30
performs: 30
policy: 30
recent: 30
ri: 30
schemes: 30
security: 30
share: 30
third: 30
usenix: 30
z: 30
associated: 29
availability: 29
close: 29
commit: 29
complete: 29
delivered: 29
edu: 29
head: 29
key: 29
later: 29
platforms: 29
pull: 29
receives: 29
recover: 29
reducing: 29
science: 29
settings: 29
task: 29
varying: 29
xi: 29
best: 28
configuration: 28
core: 28
dilemma: 28
feasible: 28
implements: 28
issues: 28
making: 28
never: 28
obtain: 28
occur: 28
others: 28
repository: 28
resulting: 28
style: 28
tools: 28
transport: 28
type: 28
area: 27
async: 27
build: 27
building: 27
cached: 27
capacity: 27
collection: 27
failures: 27
following: 27
forward: 27
framework: 27
increased: 27
instance: 27
major: 27
mbps: 27
needed: 27
neighbors: 27
nov: 27
participants: 27
reader: 27
resources: 27
solo: 27
speedup: 27
stored: 27
tm: 27
vn: 27
writer: 27
abort: 26
basic: 26
becomes: 26
benefit: 26
bin: 26
bins: 26
certain: 26
channel: 26
classical: 26
common: 26
consumption: 26
controls: 26
discuss: 26
entry: 26
fault: 26
haul: 26
instead: 26
means: 26
mostly: 26
online: 26
os: 26
solomon: 26
sources: 26
tolerance: 26
vol: 26
allowing: 25
backend: 25
bursts: 25
bursty: 25
choice: 25
conditions: 25
considered: 25
contribution: 25
copy: 25
cs: 25
difficulty: 25
distance: 25
estimate: 25
figures: 25
flows: 25
found: 25
goal: 25
hardware: 25
invalidation: 25
machines: 25
observed: 25
properties: 25
queue: 25
rain: 25
reduces: 25
report: 25
spent: 25
split: 25
takes: 25
transmission: 25
abstract: 24
algorithms: 24
around: 24
blockchain: 24
cause: 24
closed: 24
committed: 24
contrast: 24
correctly: 24
corresponding: 24
critical: 24
datacenters: 24
demand: 24
developed: 24
done: 24
equal: 24
experimental: 24
front: 24
having: 24
idea: 24
individual: 24
infiltrating: 24
knowledge: 24
limit: 24
lock: 24
logs: 24
ny: 24
observe: 24
oriented: 24
peers: 24
place: 24
processing: 24
strategies: 24
streams: 24
structured: 24
too: 24
view: 24
again: 23
approaches: 23
called: 23
choose: 23
create: 23
datacenter: 23
detected: 23
duration: 23
include: 23
layers: 23
likely: 23
majority: 23
member: 23
monitoring: 23
ones: 23
powered: 23
product: 23
reed: 23
sufficient: 23
sync: 23
traditional: 23
unix: 23
ways: 23
workshop: 23
york: 23
alternative: 22
always: 22
avoid: 22
built: 22
certification: 22
connected: 22
consequently: 22
context: 22
defined: 22
dependencies: 22
development: 22
efficient: 22
generate: 22
handle: 22
he: 22
made: 22
maintain: 22
mtu: 22
net: 22
occurs: 22
off: 22
optical: 22
parameters: 22
patterns: 22
popular: 22
problems: 22
revision: 22
starts: 22
via: 22
who: 22
wireless: 22
bandwidths: 21
buffers: 21
centralized: 21
configurations: 21
contains: 21
dynamic: 21
easily: 21
easy: 21
equation: 21
etc: 21
garbage: 21
hand: 21
hash: 21
identical: 21
iii: 21
index: 21
let: 21
life: 21
line: 21
mashup: 21
milliseconds: 21
old: 21
path: 21
private: 21
project: 21
proxies: 21
reasons: 21
response: 21
short: 21
significantly: 21
social: 21
staleness: 21
video: 21
vogels: 21
wait: 21
writing: 21
aggregate: 20
analyze: 20
architectures: 20
benefits: 20
buffering: 20
changing: 20
choosing: 20
consists: 20
four: 20
generates: 20
google: 20
grep: 20
honest: 20
inter: 20
interest: 20
interfaces: 20
library: 20
machine: 20
manner: 20
minibrowser: 20
multi: 20
none: 20
potentially: 20
presence: 20
proc: 20
quality: 20
queued: 20
racs: 20
rapidly: 20
references: 20
respectively: 20
simply: 20
site: 20
stale: 20
together: 20
traces: 20
updated: 20
usa: 20
usage: 20
yet: 20
actually: 19
adding: 19
appropriate: 19
clear: 19
convergence: 19
course: 19
currently: 19
digital: 19
expect: 19
explained: 19
extended: 19
extremely: 19
faster: 19
features: 19
inconsistent: 19
investigation: 19
issue: 19
kind: 19
know: 19
mine: 19
month: 19
natural: 19
networking: 19
om: 19
partition: 19
periods: 19
potential: 19
propagation: 19
proposed: 19
query: 19
quickly: 19
re: 19
recipe: 19
reply: 19
sequence: 19
serializability: 19
soc: 19
speeds: 19
subscribers: 19
taken: 19
towards: 19
transfer: 19
transient: 19
upon: 19
whereas: 19
works: 19
active: 18
aggregation: 18
aware: 18
background: 18
bad: 18
chooses: 18
cpu: 18
databases: 18
difficult: 18
divided: 18
drop: 18
earn: 18
effectiveness: 18
employ: 18
eventually: 18
exchange: 18
failed: 18
feb: 18
fiber: 18
foreground: 18
generation: 18
get: 18
gigabit: 18
heavy: 18
history: 18
identify: 18
includes: 18
initial: 18
itself: 18
known: 18
lambda: 18
latencies: 18
logging: 18
moreover: 18
nash: 18
neither: 18
noted: 18
participating: 18
propose: 18
publish: 18
queries: 18
repositories: 18
roundtrip: 18
sigcomm: 18
specific: 18
study: 18
subversion: 18
summary: 18
switching: 18
synthetic: 18
tokens: 18
topics: 18
unique: 18
varied: 18
various: 18
vary: 18
actual: 17
automatically: 17
chosen: 17
coda: 17
communications: 17
developer: 17
device: 17
devices: 17
don: 17
early: 17
enabled: 17
environments: 17
errors: 17
experience: 17
focus: 17
fraction: 17
functionality: 17
grows: 17
highest: 17
highly: 17
hosting: 17
ii: 17
impact: 17
implement: 17
infrastructure: 17
lines: 17
maintains: 17
modified: 17
module: 17
necessary: 17
offer: 17
partitioning: 17
periodically: 17
products: 17
progress: 17
projects: 17
ran: 17
raps: 17
reach: 17
remain: 17
setting: 17
sharing: 17
simultaneous: 17
specifically: 17
standards: 17
subservice: 17
successfully: 17
supported: 17
switch: 17
symmetric: 17
term: 17
transmitted: 17
van: 17
variety: 17
years: 17
acts: 16
already: 16
axis: 16
believe: 16
buffer: 16
bytes: 16
call: 16
chainsaw: 16
clustering: 16
compare: 16
configured: 16
conflicts: 16
connectivity: 16
contents: 16
conventional: 16
created: 16
define: 16
demonstrate: 16
difference: 16
efficacy: 16
examples: 16
fees: 16
few: 16
ghash: 16
go: 16
hard: 16
illustrated: 16
implications: 16
indeed: 16
infiltrate: 16
integration: 16
io: 16
kinds: 16
lead: 16
limiting: 16
linux: 16
little: 16
main: 16
market: 16
measurements: 16
modes: 16
operate: 16
options: 16
page: 16
parallel: 16
physical: 16
points: 16
prisoner: 16
publishes: 16
registered: 16
requirements: 16
serialization: 16
simulation: 16
simultaneously: 16
status: 16
strong: 16
sub: 16
subsystem: 16
themselves: 16
timestamp: 16
topic: 16
transparently: 16
typical: 16
accessing: 15
adapt: 15
applied: 15
arrive: 15
atp: 15
attempt: 15
bar: 15
bc: 15
comparison: 15
containing: 15
contribute: 15
corba: 15
department: 15
describes: 15
diff: 15
edge: 15
effects: 15
exists: 15
fire: 15
gc: 15
greater: 15
idle: 15
included: 15
infiltrated: 15
info: 15
june: 15
latter: 15
linear: 15
maintaining: 15
namely: 15
november: 15
oms: 15
optimize: 15
outgoing: 15
paths: 15
performing: 15
practice: 15
predictable: 15
programming: 15
regions: 15
regular: 15
renesse: 15
represents: 15
respond: 15
sense: 15
sirer: 15
slightly: 15
slow: 15
statistics: 15
stores: 15
supercomputing: 15
teragrid: 15
thousands: 15
tier: 15
underlying: 15
uniformly: 15
whole: 15
accept: 14
addition: 14
arise: 14
balancing: 14
bounded: 14
channels: 14
class: 14
combined: 14
commits: 14
conclusion: 14
concurrency: 14
currency: 14
decrease: 14
deliver: 14
destination: 14
detects: 14
differentiated: 14
directory: 14
dissemination: 14
distinct: 14
drops: 14
engineering: 14
entries: 14
exactly: 14
explore: 14
fail: 14
fifo: 14
financial: 14
finding: 14
growing: 14
guarantees: 14
handling: 14
help: 14
improves: 14
infiltrators: 14
integrated: 14
interested: 14
involves: 14
malicious: 14
modern: 14
option: 14
perfect: 14
policies: 14
prevent: 14
previously: 14
prior: 14
program: 14
providing: 14
published: 14
question: 14
relatively: 14
sabotage: 14
search: 14
singleton: 14
soon: 14
spread: 14
starting: 14
temporarily: 14
thread: 14
tolerate: 14
turn: 14
useful: 14
xj: 14
zookeeper: 14
achieved: 13
add: 13
afs: 13
annual: 13
avg: 13
balance: 13
bound: 13
collaborative: 13
collect: 13
compile: 13
completely: 13
computation: 13
concurrent: 13
consisting: 13
constraints: 13
decreases: 13
depends: 13
determine: 13
determined: 13
did: 13
digests: 13
discarded: 13
dominant: 13
dynamically: 13
embedded: 13
epidemic: 13
exception: 13
eyal: 13
face: 13
far: 13
field: 13
free: 13
frequently: 13
fundamental: 13
generating: 13
gives: 13
grained: 13
growth: 13
his: 13
hit: 13
instances: 13
intended: 13
interactive: 13
interval: 13
intervals: 13
introduction: 13
join: 13
lack: 13
location: 13
magnitude: 13
measure: 13
mentioned: 13
missed: 13
modeless: 13
nfm: 13
normal: 13
notice: 13
ntfs: 13
overview: 13
paradigm: 13
positive: 13
proportional: 13
provided: 13
public: 13
radient: 13
receipt: 13
registers: 13
relevant: 13
remains: 13
researchers: 13
robust: 13
rtt: 13
semantics: 13
setup: 13
shares: 13
situations: 13
special: 13
static: 13
structures: 13
subscribe: 13
thousand: 13
tool: 13
track: 13
trade: 13
tree: 13
unbounded: 13
written: 13
aborted: 12
academic: 12
acceptable: 12
account: 12
accurate: 12
balakrishnan: 12
base: 12
below: 12
ca: 12
capable: 12
caused: 12
challenges: 12
classes: 12
conclude: 12
copies: 12
creating: 12
cumulative: 12
date: 12
decentralized: 12
decide: 12
dedicated: 12
definition: 12
delayed: 12
despite: 12
efficiency: 12
element: 12
enterprise: 12
facts: 12
fairly: 12
footprint: 12
generally: 12
half: 12
hashcash: 12
html: 12
ing: 12
interactions: 12
introduced: 12
iv: 12
ix: 12
jan: 12
java: 12
keep: 12
leads: 12
lfs: 12
li: 12
limitations: 12
locking: 12
maintained: 12
near: 12
obtained: 12
opportunity: 12
oracle: 12
ordering: 12
orders: 12
otherwise: 12
overlap: 12
particularly: 12
past: 12
practical: 12
primary: 12
purposes: 12
push: 12
reason: 12
recently: 12
redundant: 12
rescue: 12
review: 12
roles: 12
roughly: 12
sort: 12
specify: 12
spikes: 12
stack: 12
subset: 12
taking: 12
technique: 12
ten: 12
tms: 12
unif: 12
whenever: 12
you: 12
achieving: 11
acknowledgments: 11
activity: 11
advance: 11
aggregated: 11
argue: 11
authors: 11
automated: 11
basis: 11
begin: 11
callback: 11
complex: 11
converge: 11
crash: 11
deal: 11
deployed: 11
detail: 11
details: 11
detecting: 11
discussion: 11
energy: 11
ensures: 11
equivalent: 11
evict: 11
fa: 11
fee: 11
fetches: 11
fetching: 11
finds: 11
flexible: 11
focused: 11
heterogeneous: 11
hot: 11
hundreds: 11
identifiers: 11
illustrates: 11
implementing: 11
improvements: 11
incorporates: 11
increasingly: 11
indicate: 11
insufficient: 11
interact: 11
introduce: 11
involved: 11
ithaca: 11
largest: 11
layout: 11
linearly: 11
logged: 11
maintenance: 11
measurement: 11
metadata: 11
modal: 11
moving: 11
name: 11
orkut: 11
osdi: 11
pair: 11
parameter: 11
partitioned: 11
prefetches: 11
privacy: 11
processed: 11
prove: 11
providers: 11
randomly: 11
readers: 11
realistic: 11
recovers: 11
replace: 11
replicas: 11
requiring: 11
responsible: 11
retransmission: 11
role: 11
routine: 11
sample: 11
scheduling: 11
sensitive: 11
sep: 11
separate: 11
serve: 11
simplicity: 11
stock: 11
strictly: 11
subsequent: 11
supporting: 11
supports: 11
true: 11
trusted: 11
try: 11
unlikely: 11
unshared: 11
valid: 11
ve: 11
white: 11
whose: 11
xml: 11
accuracy: 10
ack: 10
additionally: 10
along: 10
appear: 10
arg: 10
assumption: 10
asynchronously: 10
becoming: 10
bitcoins: 10
bottleneck: 10
cc: 10
cdn: 10
check: 10
checks: 10
compares: 10
conflict: 10
constructed: 10
continuous: 10
dec: 10
decision: 10
decisions: 10
degenerate: 10
degree: 10
depend: 10
desired: 10
detailed: 10
discussed: 10
distinguish: 10
distributes: 10
effectively: 10
efforts: 10
elements: 10
enable: 10
enhancing: 10
epidemics: 10
especially: 10
evaluated: 10
eventual: 10
examine: 10
expensive: 10
experienced: 10
fairness: 10
false: 10
final: 10
fine: 10
forms: 10
give: 10
gracefully: 10
ideal: 10
improving: 10
infiltrates: 10
injected: 10
ipc: 10
isn: 10
journal: 10
language: 10
leverage: 10
map: 10
maps: 10
mesh: 10
methods: 10
microbenchmarks: 10
minutes: 10
miss: 10
networked: 10
nevertheless: 10
news: 10
novel: 10
overlapping: 10
paxos: 10
pending: 10
possibility: 10
presented: 10
presents: 10
proceed: 10
pushing: 10
rapid: 10
really: 10
recall: 10
remainder: 10
reported: 10
reports: 10
representing: 10
rest: 10
return: 10
rise: 10
robbert: 10
router: 10
routes: 10
routing: 10
runtime: 10
sampling: 10
scales: 10
segment: 10
situation: 10
studies: 10
subject: 10
success: 10
synchrony: 10
tail: 10
team: 10
technical: 10
tests: 10
theorem: 10
think: 10
thresholds: 10
throughout: 10
tion: 10
transparent: 10
unlike: 10
unstable: 10
usually: 10
utility: 10
variant: 10
visible: 10
volume: 10
widely: 10
zone: 10
achieves: 9
advantages: 9
alarm: 9
allowed: 9
appliances: 9
apply: 9
assigned: 9
assigns: 9
assumed: 9
attackers: 9
august: 9
behave: 9
beneficial: 9
break: 9
causing: 9
central: 9
changed: 9
co: 9
commercial: 9
companies: 9
comparing: 9
competing: 9
compute: 9
computers: 9
confidence: 9
connections: 9
continue: 9
curves: 9
daily: 9
default: 9
degradation: 9
depending: 9
deterministic: 9
developing: 9
dirty: 9
discards: 9
disconnected: 9
domain: 9
ec: 9
ee: 9
efficiently: 9
eliminate: 9
en: 9
entirely: 9
execute: 9
explicit: 9
explored: 9
expression: 9
fails: 9
fashion: 9
fd: 9
force: 9
forming: 9
forwarding: 9
frequency: 9
fully: 9
functions: 9
grant: 9
grow: 9
gw: 9
hide: 9
hierarchy: 9
hold: 9
id: 9
ideally: 9
identifier: 9
importance: 9
incentive: 9
inexpensive: 9
infocom: 9
initially: 9
intel: 9
investigate: 9
iperf: 9
iterative: 9
john: 9
kept: 9
knows: 9
leaving: 9
loads: 9
lose: 9
lossless: 9
lowest: 9
maximize: 9
media: 9
merlin: 9
middle: 9
middleware: 9
minor: 9
modifications: 9
modify: 9
modules: 9
nsdi: 9
owner: 9
pattern: 9
permutation: 9
places: 9
plan: 9
profitable: 9
programmer: 9
prone: 9
proportion: 9
quite: 9
reached: 9
reading: 9
records: 9
reflect: 9
respect: 9
retry: 9
ricochet: 9
rings: 9
risk: 9
rounds: 9
rw: 9
sampled: 9
sd: 9
sec: 9
segments: 9
selected: 9
self: 9
session: 9
shall: 9
showing: 9
sigmod: 9
sosp: 9
specialized: 9
steps: 9
susceptible: 9
terms: 9
threads: 9
tolerant: 9
topology: 9
transfers: 9
transformation: 9
transitions: 9
transmitting: 9
trip: 9
ttl: 9
unacknowledged: 9
unless: 9
upcall: 9
vi: 9
viii: 9
want: 9
werner: 9
academia: 8
accordingly: 8
activities: 8
adds: 8
advantage: 8
affect: 8
affects: 8
afrl: 8
aggregates: 8
allocation: 8
amounts: 8
api: 8
arbitrary: 8
arrays: 8
arxiv: 8
aspects: 8
attributes: 8
auditor: 8
automatic: 8
away: 8
backup: 8
behind: 8
beyond: 8
breaks: 8
buffered: 8
byte: 8
cbcb: 8
challenge: 8
charge: 8
checking: 8
clock: 8
collected: 8
combine: 8
come: 8
competition: 8
compromised: 8
concurrently: 8
confirm: 8
congested: 8
connecting: 8
consecutive: 8
contributing: 8
coordinator: 8
corresponds: 8
creates: 8
currencies: 8
dark: 8
david: 8
de: 8
degrades: 8
densities: 8
deploy: 8
deployment: 8
detectors: 8
differs: 8
dogecoin: 8
drag: 8
driven: 8
earns: 8
eligius: 8
employed: 8
engage: 8
equations: 8
equipment: 8
essentially: 8
ever: 8
exact: 8
executed: 8
exist: 8
extensions: 8
external: 8
extreme: 8
favor: 8
filesystem: 8
gib: 8
greatly: 8
header: 8
histograms: 8
honestly: 8
ideas: 8
improvement: 8
input: 8
insight: 8
interaction: 8
jgroups: 8
largely: 8
leader: 8
leading: 8
leave: 8
lemma: 8
light: 8
limits: 8
litecoin: 8
look: 8
mashups: 8
masks: 8
massive: 8
match: 8
max: 8
mc: 8
measuring: 8
method: 8
minimize: 8
misbehaving: 8
mixed: 8
modeled: 8
models: 8
modification: 8
move: 8
neighbor: 8
nominal: 8
nor: 8
notification: 8
notifications: 8
oct: 8
offers: 8
ordered: 8
papers: 8
participation: 8
payoff: 8
perhaps: 8
perturbed: 8
placed: 8
played: 8
plot: 8
portion: 8
prioritised: 8
purpose: 8
put: 8
react: 8
recovering: 8
refer: 8
refrain: 8
replaced: 8
reservation: 8
reservations: 8
retransmissions: 8
returned: 8
reward: 8
robin: 8
sdn: 8
sections: 8
senders: 8
september: 8
series: 8
serves: 8
similarly: 8
simulate: 8
sink: 8
sm: 8
solve: 8
sometimes: 8
span: 8
specification: 8
specified: 8
stacks: 8
staggered: 8
stepwise: 8
strict: 8
subsequently: 8
substituting: 8
suitable: 8
surprisingly: 8
timer: 8
turns: 8
twice: 8
unusable: 8
verify: 8
views: 8
wang: 8
weak: 8
weather: 8
weekly: 8
wiki: 8
ws: 8
xc: 8
aborting: 7
abstraction: 7
acceptors: 7
acknowledged: 7
air: 7
apache: 7
applying: 7
architectural: 7
arises: 7
array: 7
attractive: 7
belongs: 7
big: 7
broadcast: 7
bsd: 7
byzantine: 7
calculate: 7
card: 7
causes: 7
cb: 7
characteristics: 7
cisco: 7
claim: 7
cleaning: 7
cleanup: 7
clearly: 7
closer: 7
collapse: 7
communities: 7
completion: 7
complexity: 7
concept: 7
conflicting: 7
connection: 7
considering: 7
consistently: 7
construct: 7
contemporary: 7
contributions: 7
cooperative: 7
counter: 7
creation: 7
dashed: 7
december: 7
decoupling: 7
degraded: 7
delaying: 7
demers: 7
deploying: 7
dept: 7
derived: 7
designs: 7
deter: 7
determining: 7
display: 7
disrupt: 7
doesn: 7
doing: 7
dolev: 7
downstream: 7
easier: 7
elapsed: 7
electronic: 7
eliminated: 7
eliminates: 7
employs: 7
empty: 7
emulab: 7
enabling: 7
equally: 7
everything: 7
exchanges: 7
experiences: 7
exploit: 7
exponential: 7
extend: 7
feature: 7
feedback: 7
feeds: 7
fires: 7
fit: 7
follow: 7
furthermore: 7
gaining: 7
gray: 7
guarantee: 7
handles: 7
hour: 7
huge: 7
ignored: 7
image: 7
implementations: 7
importantly: 7
incoherent: 7
incorporate: 7
inferior: 7
introduces: 7
inventory: 7
isis: 7
isolation: 7
january: 7
joseph: 7
keys: 7
latest: 7
lbfs: 7
located: 7
locations: 7
ma: 7
mahesh: 7
mapping: 7
mica: 7
mines: 7
ml: 7
mod: 7
modeling: 7
modifying: 7
motivation: 7
multicasts: 7
nature: 7
negligible: 7
nothing: 7
nsf: 7
oblivious: 7
observation: 7
obvious: 7
october: 7
operator: 7
optimistic: 7
overloaded: 7
partitions: 7
percentile: 7
persistent: 7
plus: 7
poorly: 7
population: 7
pre: 7
prefer: 7
press: 7
prime: 7
programs: 7
propagated: 7
prototype: 7
publishing: 7
rack: 7
rarely: 7
rc: 7
reaches: 7
record: 7
reflects: 7
regarding: 7
register: 7
regularly: 7
relaying: 7
rely: 7
repeated: 7
represent: 7
represented: 7
requesting: 7
resistant: 7
restart: 7
retailer: 7
retrieve: 7
rich: 7
route: 7
routers: 7
san: 7
savings: 7
scaling: 7
seamlessly: 7
seek: 7
sharply: 7
she: 7
simplify: 7
simulations: 7
simulator: 7
sites: 7
socket: 7
sockets: 7
springer: 7
stop: 7
storing: 7
subservices: 7
substantially: 7
successful: 7
timeout: 7
tradeoff: 7
trans: 7
transition: 7
transmit: 7
treat: 7
treated: 7
trees: 7
trust: 7
twenty: 7
u: 7
ubiquitous: 7
unaware: 7
unchanged: 7
useless: 7
utilization: 7
validation: 7
variation: 7
vendor: 7
vendors: 7
versus: 7
vii: 7
violating: 7
wan: 7
year: 7
yield: 7
yields: 7
yu: 7
accommodate: 6
achievable: 6
acknowledgement: 6
act: 6
acting: 6
addressed: 6
addresses: 6
adjustment: 6
administrators: 6
affected: 6
afosr: 6
agreement: 6
alternatives: 6
analyzed: 6
apparently: 6
appropriately: 6
argument: 6
arrives: 6
assumptions: 6
atomic: 6
averages: 6
avoids: 6
bars: 6
begins: 6
berkeley: 6
bonneau: 6
bottom: 6
boundaries: 6
broadly: 6
bullet: 6
california: 6
calls: 6
catch: 6
checkpoint: 6
checksum: 6
chen: 6
closely: 6
clouds: 6
clr: 6
coherent: 6
combination: 6
combines: 6
comes: 6
command: 6
comprised: 6
comput: 6
concave: 6
conducted: 6
conjunction: 6
consensus: 6
conservative: 6
considerable: 6
contain: 6
controlled: 6
coordinate: 6
copying: 6
corporation: 6
costly: 6
coupled: 6
crashed: 6
cross: 6
curve: 6
customize: 6
darpa: 6
dates: 6
db: 6
debian: 6
denotes: 6
dependent: 6
deployments: 6
description: 6
detector: 6
determines: 6
develop: 6
digest: 6
discusfish: 6
disjoint: 6
disseminate: 6
divides: 6
document: 6
draw: 6
druschel: 6
durability: 6
earth: 6
ed: 6
effort: 6
egress: 6
eliminating: 6
email: 6
erasure: 6
established: 6
expressions: 6
facebook: 6
feasibility: 6
feed: 6
fifth: 6
fill: 6
focuses: 6
forced: 6
forks: 6
former: 6
foundation: 6
frame: 6
france: 6
gbps: 6
generic: 6
hashing: 6
heartbeat: 6
hidden: 6
histories: 6
hop: 6
huang: 6
imposed: 6
improved: 6
inc: 6
indicates: 6
industry: 6
ingress: 6
intensive: 6
intercepted: 6
intermediate: 6
issued: 6
issuing: 6
kncminer: 6
krzysztof: 6
lacking: 6
lamport: 6
lan: 6
lans: 6
lcm: 6
ledger: 6
loaded: 6
locally: 6
logical: 6
lt: 6
luu: 6
manage: 6
master: 6
matching: 6
maxx: 6
mean: 6
measured: 6
min: 6
mission: 6
modifies: 6
moment: 6
moves: 6
mp: 6
multicasting: 6
my: 6
naturally: 6
nd: 6
nearly: 6
necessarily: 6
noble: 6
nonce: 6
normalizes: 6
notion: 6
numbered: 6
numerical: 6
numerous: 6
occurring: 6
older: 6
operators: 6
optimized: 6
oscillatory: 6
ostrowski: 6
outlined: 6
outperforms: 6
output: 6
overload: 6
pareto: 6
parties: 6
passive: 6
pdf: 6
perfectly: 6
permit: 6
perspective: 6
phase: 6
play: 6
pooled: 6
possibly: 6
powerful: 6
predict: 6
prefix: 6
price: 6
primarily: 6
procedure: 6
produced: 6
publicly: 6
publisher: 6
pulls: 6
punish: 6
questions: 6
queuing: 6
qwest: 6
reachable: 6
red: 6
reduction: 6
redundancy: 6
reject: 6
repeatedly: 6
replay: 6
replicate: 6
resource: 6
resulted: 6
returns: 6
reveals: 6
rewards: 6
rig: 6
ring: 6
rj: 6
rules: 6
samples: 6
satyanarayanan: 6
say: 6
seattle: 6
seems: 6
select: 6
sensitivity: 6
serialized: 6
six: 6
slowly: 6
snapshot: 6
solving: 6
somewhat: 6
sorts: 6
standardized: 6
states: 6
straightforward: 6
stratum: 6
suggested: 6
summarize: 6
sun: 6
super: 6
supplies: 6
switzerland: 6
synchronization: 6
targeted: 6
tat: 6
thank: 6
theory: 6
timeouts: 6
tit: 6
toolkit: 6
tracking: 6
transmits: 6
trigger: 6
trying: 6
txnid: 6
ultimately: 6
understand: 6
unfortunately: 6
unreliable: 6
usability: 6
usable: 6
validate: 6
variability: 6
variations: 6
vast: 6
vector: 6
vldb: 6
welsh: 6
why: 6
withheld: 6
won: 6
workers: 6
worse: 6
xxx: 6
yahoo: 6
zhang: 6
zhu: 6
ability: 5
absence: 5
absolute: 5
acknowledgements: 5
acknowledgment: 5
acl: 5
adapting: 5
adjusting: 5
ago: 5
agree: 5
ahead: 5
allocated: 5
anyone: 5
append: 5
approximate: 5
arbitrarily: 5
arguably: 5
arrival: 5
assuming: 5
atkin: 5
atomicity: 5
attempts: 5
author: 5
avoiding: 5
award: 5
backed: 5
band: 5
behalf: 5
behaves: 5
belong: 5
bit: 5
bits: 5
blocking: 5
brevity: 5
brewer: 5
broken: 5
broker: 5
buildings: 5
bus: 5
calculated: 5
calculates: 5
capture: 5
carry: 5
catches: 5
caught: 5
chains: 5
cheap: 5
cheriton: 5
classified: 5
cloned: 5
collapses: 5
comments: 5
communicate: 5
communicates: 5
compose: 5
concern: 5
concerns: 5
consequence: 5
considerations: 5
constitutes: 5
constrained: 5
consume: 5
consuming: 5
contact: 5
continuously: 5
coolstreaming: 5
cope: 5
count: 5
counts: 5
crashes: 5
credentials: 5
crossing: 5
customers: 5
danny: 5
datagram: 5
day: 5
dealing: 5
defense: 5
demands: 5
demonstrated: 5
denial: 5
denoted: 5
depict: 5
describing: 5
df: 5
dialog: 5
direction: 5
division: 5
dramatic: 5
dsn: 5
edition: 5
eferences: 5
eight: 5
elaborate: 5
elated: 5
embedding: 5
emerging: 5
employing: 5
encourage: 5
encryption: 5
enforce: 5
ephemeral: 5
estimated: 5
ethernet: 5
exceed: 5
except: 5
exhibit: 5
explain: 5
explicitly: 5
exploiting: 5
exploring: 5
expressed: 5
falls: 5
faults: 5
faulty: 5
filtering: 5
firing: 5
flexibility: 5
forces: 5
forwarded: 5
frames: 5
freebsd: 5
frequent: 5
gap: 5
generality: 5
geo: 5
geographical: 5
gigabits: 5
gribble: 5
grid: 5
ground: 5
gu: 5
hacker: 5
health: 5
hierarchical: 5
highperformance: 5
hints: 5
hooks: 5
human: 5
identification: 5
illustrate: 5
imagine: 5
implicit: 5
implies: 5
inaccurate: 5
incorrect: 5
incrementally: 5
incurs: 5
independently: 5
informatik: 5
informatique: 5
innovation: 5
instantly: 5
integrating: 5
interesting: 5
interference: 5
internal: 5
interoperability: 5
invalidate: 5
investigated: 5
investigator: 5
iptv: 5
isps: 5
ittay: 5
johnson: 5
joining: 5
joins: 5
katz: 5
kleinberg: 5
lakshmi: 5
languages: 5
layouts: 5
learn: 5
leases: 5
lengths: 5
lightweight: 5
linking: 5
liu: 5
locality: 5
locks: 5
logic: 5
looking: 5
lossy: 5
mar: 5
marketing: 5
mask: 5
messaging: 5
metrics: 5
minibrowsers: 5
minority: 5
monitors: 5
monthly: 5
moved: 5
mutual: 5
national: 5
normally: 5
ntroduction: 5
observations: 5
obtains: 5
occasional: 5
occurred: 5
offered: 5
omit: 5
omitted: 5
onclusion: 5
onon: 5
optimization: 5
optimizations: 5
optimizes: 5
organization: 5
organizations: 5
organized: 5
originally: 5
orthogonal: 5
outside: 5
overcome: 5
pairs: 5
partially: 5
passed: 5
pause: 5
pay: 5
pays: 5
peerto: 5
people: 5
percentages: 5
permitting: 5
personal: 5
pf: 5
phenomenon: 5
placement: 5
plots: 5
poison: 5
positives: 5
precisely: 5
predictor: 5
predictors: 5
probabilistic: 5
proceeds: 5
progresses: 5
property: 5
proprietary: 5
protected: 5
proved: 5
punished: 5
quick: 5
raise: 5
rare: 5
raw: 5
rd: 5
reaching: 5
regardless: 5
release: 5
reliance: 5
remaining: 5
remove: 5
repairs: 5
repeat: 5
requested: 5
requirement: 5
resilience: 5
resolve: 5
respects: 5
responsiveness: 5
restrictions: 5
reveal: 5
rizzo: 5
road: 5
robustness: 5
satisfactory: 5
satisfied: 5
save: 5
saving: 5
scheduled: 5
schneider: 5
seem: 5
sees: 5
selecting: 5
sensors: 5
separated: 5
separately: 5
sequenced: 5
serializable: 5
sessions: 5
shard: 5
shards: 5
signal: 5
simulated: 5
sized: 5
slack: 5
slower: 5
sophisticated: 5
soule: 5
speculative: 5
sprint: 5
stated: 5
stay: 5
studied: 5
submit: 5
substantial: 5
subsystems: 5
suffer: 5
sum: 5
summarized: 5
suspicion: 5
switched: 5
switches: 5
tech: 5
tell: 5
temporary: 5
texture: 5
thinking: 5
tightly: 5
timely: 5
timestamps: 5
tocs: 5
topologies: 5
tracks: 5
transform: 5
transformations: 5
trap: 5
treating: 5
trend: 5
trends: 5
triggers: 5
tune: 5
tuning: 5
turned: 5
unable: 5
unexpected: 5
unit: 5
unpredictable: 5
untrusted: 5
updating: 5
upper: 5
ut: 5
utilisation: 5
verifying: 5
viewed: 5
volatile: 5
vs: 5
waiting: 5
walk: 5
wall: 5
wants: 5
win: 5
wired: 5
writers: 5
ycsb: 5
yx: 5
ab: 4
abbadi: 4
ac: 4
accepted: 4
acks: 4
action: 4
actions: 4
adopted: 4
advanced: 4
advances: 4
agrawal: 4
alone: 4
alongside: 4
alternate: 4
alvisi: 4
amir: 4
amortizable: 4
analogous: 4
andrew: 4
answer: 4
antpool: 4
applicable: 4
approximated: 4
april: 4
archive: 4
arrow: 4
aspect: 4
assign: 4
assumes: 4
athey: 4
awkward: 4
bahack: 4
ballots: 4
banking: 4
behaviour: 4
benchmark: 4
bernstein: 4
biersack: 4
bifurcations: 4
bitcointalk: 4
blade: 4
blast: 4
blend: 4
blocked: 4
blogspot: 4
border: 4
boxes: 4
brief: 4
briefly: 4
broadcasts: 4
broader: 4
bulk: 4
burstier: 4
calculator: 4
callbacks: 4
caller: 4
capitalization: 4
captures: 4
carefully: 4
certainly: 4
charts: 4
chat: 4
city: 4
clean: 4
clones: 4
closes: 4
cms: 4
collecting: 4
collector: 4
combining: 4
coming: 4
comparable: 4
compensated: 4
compiles: 4
completed: 4
complicated: 4
componentized: 4
composition: 4
comprehensive: 4
compromise: 4
conduct: 4
confirms: 4
consequences: 4
consist: 4
contained: 4
continued: 4
converges: 4
cooperation: 4
correlated: 4
correlation: 4
courtois: 4
crucial: 4
cryptography: 4
cutting: 4
cycle: 4
danger: 4
das: 4
debugging: 4
decades: 4
decided: 4
declining: 4
deep: 4
deferred: 4
defines: 4
demonstrates: 4
desktop: 4
devastating: 4
di: 4
differences: 4
differentiate: 4
differently: 4
directed: 4
directions: 4
directories: 4
disaster: 4
discovery: 4
discussions: 4
disloyal: 4
disrupted: 4
disruption: 4
distant: 4
distribute: 4
distributions: 4
double: 4
ease: 4
ebay: 4
economic: 4
editor: 4
educause: 4
elsewhere: 4
emin: 4
emulate: 4
encoder: 4
encodes: 4
endhosts: 4
enforcing: 4
engages: 4
engineer: 4
enhanced: 4
enormous: 4
enter: 4
envelope: 4
epi: 4
eprint: 4
esb: 4
evenly: 4
evicting: 4
evidence: 4
evil: 4
ex: 4
examines: 4
exchanged: 4
exclusive: 4
executing: 4
existence: 4
export: 4
exposed: 4
extensive: 4
faber: 4
faced: 4
familiar: 4
february: 4
filter: 4
firewalls: 4
five: 4
fixing: 4
flowing: 4
flush: 4
flushes: 4
focusing: 4
followed: 4
formula: 4
foster: 4
fourth: 4
fragmentation: 4
francis: 4
francisco: 4
freedman: 4
friendly: 4
gain: 4
games: 4
gateways: 4
gathered: 4
gets: 4
globally: 4
goes: 4
going: 4
graceful: 4
grants: 4
grateful: 4
grossklags: 4
hackingdistributed: 4
hakim: 4
heartbeats: 4
heavily: 4
helps: 4
hint: 4
holds: 4
home: 4
honeypot: 4
hope: 4
horus: 4
hweather: 4
identified: 4
identifying: 4
identity: 4
ids: 4
ignore: 4
images: 4
impacted: 4
impossible: 4
inaccessible: 4
incorporating: 4
incurred: 4
incurring: 4
inform: 4
initiated: 4
initiative: 4
inquiry: 4
integral: 4
integrate: 4
intelligent: 4
intend: 4
interacts: 4
interrupted: 4
intervening: 4
intrinsically: 4
introducing: 4
invalidated: 4
invalidating: 4
isbn: 4
javascript: 4
jboss: 4
jelasity: 4
joint: 4
jose: 4
july: 4
jumbo: 4
jxta: 4
kaashoek: 4
keeping: 4
keidar: 4
kermarrec: 4
kj: 4
korn: 4
lacks: 4
lakshman: 4
laszka: 4
leaders: 4
learning: 4
leaves: 4
letting: 4
leveraging: 4
libraries: 4
lies: 4
listed: 4
lived: 4
ll: 4
logsim: 4
longdistance: 4
looked: 4
lru: 4
maid: 4
malfunctioning: 4
managing: 4
marked: 4
matched: 4
matrix: 4
maximizes: 4
measures: 4
merely: 4
methodology: 4
miles: 4
military: 4
miller: 4
mind: 4
minimal: 4
minted: 4
minute: 4
misconfigured: 4
misses: 4
mix: 4
mixture: 4
mobility: 4
modulating: 4
monitor: 4
monopoly: 4
moore: 4
msg: 4
mtus: 4
naive: 4
nak: 4
namecoin: 4
narrow: 4
netfilter: 4
normalized: 4
notable: 4
notify: 4
numerically: 4
obstacles: 4
obtaining: 4
offering: 4
ools: 4
operates: 4
optimum: 4
organofcorti: 4
ork: 4
outstanding: 4
owners: 4
ownership: 4
packages: 4
parameterized: 4
participate: 4
parts: 4
patient: 4
paul: 4
payments: 4
payout: 4
payouts: 4
peak: 4
penalty: 4
peps: 4
periodic: 4
permacoin: 4
permutations: 4
person: 4
perspectives: 4
pfldnet: 4
phenomena: 4
php: 4
pi: 4
picked: 4
pictures: 4
placing: 4
player: 4
plotting: 4
podc: 4
poll: 4
polling: 4
positions: 4
practicality: 4
predicted: 4
preferred: 4
preprint: 4
pressure: 4
prevents: 4
pricing: 4
primitives: 4
principle: 4
probabilities: 4
probably: 4
prominent: 4
promising: 4
protect: 4
provisioned: 4
provisioning: 4
pub: 4
publication: 4
pulled: 4
purely: 4
qi: 4
qp: 4
quantities: 4
quantum: 4
querying: 4
readset: 4
reality: 4
realize: 4
reasonable: 4
reference: 4
reflected: 4
regional: 4
rejoin: 4
relation: 4
relations: 4
reliably: 4
removed: 4
reno: 4
repairing: 4
replacement: 4
replicating: 4
repo: 4
reserved: 4
residing: 4
resilient: 4
resolution: 4
resolved: 4
responding: 4
responses: 4
retailers: 4
retransmit: 4
rev: 4
revoke: 4
rigs: 4
rk: 4
robert: 4
root: 4
rosenfeld: 4
routed: 4
rover: 4
rowstron: 4
rule: 4
safety: 4
saturate: 4
saw: 4
scan: 4
secondary: 4
secret: 4
secure: 4
secured: 4
seeks: 4
selective: 4
selfish: 4
separates: 4
sequences: 4
sequentially: 4
sha: 4
shasha: 4
shenker: 4
shift: 4
shut: 4
silver: 4
situational: 4
sixteenth: 4
smalltalk: 4
smart: 4
smr: 4
sold: 4
spanning: 4
spun: 4
srm: 4
standardization: 4
statistically: 4
steadily: 4
steady: 4
stress: 4
stronger: 4
strongly: 4
students: 4
subjected: 4
subsection: 4
successes: 4
suffers: 4
sums: 4
suspected: 4
symmetry: 4
synchronized: 4
tackle: 4
tailored: 4
technological: 4
tens: 4
terminology: 4
terrain: 4
terry: 4
tested: 4
theoretic: 4
things: 4
threaded: 4
took: 4
tornado: 4
touched: 4
towsley: 4
traced: 4
tradeoffs: 4
trading: 4
translate: 4
travel: 4
treats: 4
tremendous: 4
trial: 4
truly: 4
tuple: 4
understanding: 4
undesirable: 4
units: 4
unknown: 4
unusual: 4
upstream: 4
usd: 4
usual: 4
utilities: 4
vahdat: 4
valuable: 4
variable: 4
variants: 4
varies: 4
vfs: 4
viable: 4
vice: 4
visual: 4
von: 4
vulnerable: 4
waits: 4
walsh: 4
washington: 4
weakly: 4
weatherspoon: 4
weight: 4
wish: 4
withhold: 4
worked: 4
worst: 4
worth: 4
writeset: 4
wrong: 4
xk: 4
xkj: 4
yearly: 4
your: 4
abadi: 3
aborts: 3
accepting: 3
accepts: 3
accountable: 3
accumulated: 3
accusations: 3
acidrain: 3
acknowledge: 3
acquire: 3
actively: 3
adapts: 3
adequate: 3
adjust: 3
advancing: 3
advantageous: 3
advertisements: 3
afec: 3
affecting: 3
aggregating: 3
agnostic: 3
aguilera: 3
aimed: 3
aircraft: 3
alan: 3
albeit: 3
alberta: 3
album: 3
alert: 3
alerts: 3
alleviate: 3
amenable: 3
analytical: 3
analytically: 3
anomaly: 3
anything: 3
app: 3
apparent: 3
appears: 3
ar: 3
areas: 3
aren: 3
argued: 3
arising: 3
arla: 3
assertion: 3
assess: 3
assigning: 3
assignment: 3
association: 3
assure: 3
attribute: 3
auditable: 3
aug: 3
authorization: 3
avatars: 3
avoided: 3
backbone: 3
balancer: 3
baltimore: 3
banks: 3
bases: 3
basically: 3
batch: 3
bayou: 3
beginning: 3
bianchini: 3
black: 3
boards: 3
bone: 3
boston: 3
boures: 3
breaking: 3
bring: 3
browser: 3
builds: 3
busy: 3
calling: 3
cambridge: 3
camera: 3
cap: 3
care: 3
carries: 3
categories: 3
chandra: 3
characteristic: 3
checked: 3
children: 3
chronous: 3
chubby: 3
churn: 3
circumvent: 3
claims: 3
clement: 3
closing: 3
colleagues: 3
colorado: 3
column: 3
combinations: 3
commands: 3
commerce: 3
commonly: 3
commun: 3
communicating: 3
company: 3
compatible: 3
compete: 3
competitive: 3
compilers: 3
compiling: 3
completes: 3
composed: 3
compound: 3
comprises: 3
compulsory: 3
computational: 3
computed: 3
con: 3
conceived: 3
concentrate: 3
concluded: 3
conclusions: 3
condition: 3
configurable: 3
confirmed: 3
conservation: 3
conserve: 3
consideration: 3
constructing: 3
construction: 3
consumed: 3
consumes: 3
continues: 3
convinced: 3
convoy: 3
cooperate: 3
coordinates: 3
coordination: 3
copper: 3
corbett: 3
corfu: 3
corporate: 3
correcting: 3
correctness: 3
correlate: 3
criterion: 3
culler: 3
culprit: 3
cumulus: 3
curious: 3
custer: 3
custom: 3
customer: 3
customized: 3
cycles: 3
dahlin: 3
dangers: 3
davis: 3
ddos: 3
deadline: 3
deadlines: 3
deals: 3
decade: 3
deciding: 3
decker: 3
decreasing: 3
deering: 3
degrade: 3
demonstrating: 3
dependable: 3
designers: 3
desire: 3
determinism: 3
deviation: 3
dialogue: 3
differentiation: 3
dis: 3
discover: 3
discrepancy: 3
disruptions: 3
disruptive: 3
disseminated: 3
distributing: 3
dns: 3
documentation: 3
documents: 3
dollars: 3
dominated: 3
dos: 3
drawn: 3
driver: 3
dropping: 3
drpm: 3
dying: 3
economics: 3
eded: 3
edward: 3
eicken: 3
el: 3
elastic: 3
elastras: 3
election: 3
electrical: 3
elegant: 3
else: 3
emergence: 3
emotional: 3
empire: 3
encodings: 3
encouraging: 3
ending: 3
endpoint: 3
endto: 3
enhances: 3
ensuring: 3
enterprises: 3
entities: 3
entity: 3
essay: 3
essential: 3
evaluates: 3
evaluating: 3
eventing: 3
evident: 3
evolution: 3
evolved: 3
exacerbates: 3
excellent: 3
excluding: 3
executes: 3
expands: 3
expelled: 3
experimentally: 3
experimented: 3
expires: 3
explorer: 3
exposes: 3
extends: 3
extension: 3
extent: 3
extra: 3
extracted: 3
fascinating: 3
fewer: 3
fg: 3
fields: 3
fifteenth: 3
finite: 3
firm: 3
flash: 3
flat: 3
fledged: 3
flight: 3
folder: 3
folders: 3
forest: 3
format: 3
formation: 3
franklin: 3
freeloaders: 3
french: 3
friend: 3
fs: 3
ganesh: 3
gargamel: 3
gather: 3
geographically: 3
gf: 3
gfgf: 3
goals: 3
gossiped: 3
government: 3
gps: 3
graphically: 3
great: 3
greatest: 3
grids: 3
grossman: 3
gt: 3
guaranteed: 3
gui: 3
gummadi: 3
guo: 3
gurumurthi: 3
hall: 3
handlers: 3
handley: 3
happen: 3
happy: 3
hauser: 3
haven: 3
heap: 3
helland: 3
helping: 3
hibernator: 3
hierarchically: 3
hierarchies: 3
highspeed: 3
homogeneous: 3
howard: 3
hypothesis: 3
ibm: 3
icdcs: 3
ics: 3
ignores: 3
ignoring: 3
il: 3
immersed: 3
implicitly: 3
impose: 3
imposes: 3
incentives: 3
income: 3
incorporated: 3
incorrectly: 3
incremental: 3
incremented: 3
incur: 3
indiana: 3
indicating: 3
informed: 3
inherits: 3
initiate: 3
innovations: 3
inside: 3
insights: 3
instability: 3
instantaneous: 3
institute: 3
intent: 3
interacting: 3
intercept: 3
intercepting: 3
intercepts: 3
interconnect: 3
interconnected: 3
internals: 3
internetworks: 3
interplay: 3
intervene: 3
inversion: 3
irregular: 3
iteration: 3
jbosscache: 3
jim: 3
jitter: 3
keeps: 3
kenneth: 3
knowing: 3
kuenning: 3
landscape: 3
laptops: 3
larson: 3
late: 3
lateral: 3
lesson: 3
linkage: 3
linked: 3
lions: 3
lloyd: 3
logically: 3
london: 3
looks: 3
loop: 3
losing: 3
lot: 3
luby: 3
mainframe: 3
mainsoft: 3
mainwin: 3
malkhi: 3
malo: 3
managers: 3
marian: 3
markets: 3
marks: 3
mashed: 3
matter: 3
mazie: 3
mckusick: 3
meanwhile: 3
memcached: 3
michael: 3
microbenchmark: 3
mid: 3
migration: 3
minimizing: 3
mirror: 3
mitigate: 3
modular: 3
montresor: 3
motivated: 3
motivates: 3
mountain: 3
movies: 3
multithreaded: 3
nat: 3
native: 3
neighborhood: 3
ninja: 3
nonetheless: 3
noticeable: 3
null: 3
observing: 3
obstruction: 3
occasionally: 3
odel: 3
oneway: 3
onto: 3
opened: 3
operational: 3
opposed: 3
optimizing: 3
optionally: 3
organize: 3
orientation: 3
ousterhout: 3
outbound: 3
outdated: 3
overflows: 3
overlapped: 3
overloads: 3
overwhelmed: 3
pacific: 3
padhye: 3
pai: 3
paid: 3
parameterize: 3
participant: 3
passing: 3
paying: 3
payload: 3
pc: 3
pedone: 3
penalties: 3
perceived: 3
percent: 3
perez: 3
personalities: 3
personalization: 3
pervasive: 3
peter: 3
phone: 3
pinheiro: 3
pisa: 3
players: 3
pleisch: 3
poisson: 3
polls: 3
poor: 3
popek: 3
popularity: 3
portions: 3
pose: 3
posed: 3
positioning: 3
prabhakaran: 3
prebuilt: 3
precedence: 3
predominate: 3
preferentially: 3
prefetched: 3
presentation: 3
preserved: 3
president: 3
preventing: 3
principal: 3
probing: 3
processor: 3
produce: 3
productivity: 3
programmers: 3
promise: 3
propagate: 3
properly: 3
protection: 3
proves: 3
provider: 3
psockets: 3
publishers: 3
punishment: 3
purchases: 3
pushed: 3
putting: 3
qpqp: 3
quanta: 3
queueing: 3
queues: 3
raises: 3
ramp: 3
ranging: 3
rao: 3
raptor: 3
reacting: 3
readonly: 3
realizing: 3
reasoning: 3
recipient: 3
recognize: 3
recommendations: 3
reconstruct: 3
recoveries: 3
reflecting: 3
rejoins: 3
relate: 3
relates: 3
released: 3
releases: 3
remarkably: 3
removing: 3
replaces: 3
replacing: 3
replayed: 3
replica: 3
replies: 3
representation: 3
representative: 3
res: 3
reserve: 3
resort: 3
resp: 3
respective: 3
responds: 3
restarting: 3
restored: 3
restricted: 3
retain: 3
retransmitted: 3
retrieves: 3
revisions: 3
rewarding: 3
rfc: 3
rises: 3
risks: 3
safely: 3
saint: 3
satisfies: 3
satisfy: 3
satisfying: 3
scaled: 3
scene: 3
school: 3
scope: 3
script: 3
semantic: 3
sensor: 3
separation: 3
sequential: 3
served: 3
seventeenth: 3
seventh: 3
severe: 3
sharded: 3
shepherd: 3
showed: 3
sight: 3
simpler: 3
simplest: 3
sinfonia: 3
situated: 3
sixth: 3
sleep: 3
slight: 3
smallest: 3
soft: 3
song: 3
sorrosal: 3
sound: 3
spanner: 3
spare: 3
spatial: 3
specifications: 3
speculatively: 3
splitstream: 3
splitting: 3
sporadic: 3
spot: 3
sprite: 3
sr: 3
ssrn: 3
stability: 3
standardize: 3
started: 3
stays: 3
stems: 3
streamed: 3
struggled: 3
subnet: 3
subscriber: 3
substrate: 3
successive: 3
suddenly: 3
sufficiently: 3
suggests: 3
suite: 3
supplied: 3
surprising: 3
suspicions: 3
symbolic: 3
symbols: 3
synchronously: 3
sys: 3
syst: 3
tables: 3
tacc: 3
tagging: 3
talk: 3
tape: 3
targets: 3
taylor: 3
teams: 3
television: 3
tends: 3
terminating: 3
testing: 3
text: 3
thin: 3
thinks: 3
thirty: 3
thomson: 3
threat: 3
tight: 3
tiled: 3
tolerable: 3
ton: 3
tput: 3
tr: 3
traditionally: 3
train: 3
transferred: 3
transferring: 3
transmissions: 3
triggered: 3
triggering: 3
trivial: 3
trouble: 3
truncation: 3
tsunami: 3
tudor: 3
tudorm: 3
turning: 3
uk: 3
unacceptable: 3
unavailable: 3
unblocks: 3
uncommittable: 3
undetected: 3
unexpectedly: 3
unfairly: 3
unmanaged: 3
unperturbed: 3
unrelated: 3
utah: 3
utilize: 3
uwin: 3
validated: 3
valuation: 3
variables: 3
variance: 3
verified: 3
verlag: 3
viewing: 3
vigfusson: 3
visualization: 3
vt: 3
wake: 3
walli: 3
wanted: 3
warns: 3
watch: 3
wefel: 3
wei: 3
whatever: 3
widespread: 3
winner: 3
wisdom: 3
wobber: 3
worlds: 3
worry: 3
wv: 3
yxyx: 3
zero: 3
zhao: 3
zurich: 3
abandon: 2
abc: 2
abilene: 2
abstractions: 2
academics: 2
acceptance: 2
accessible: 2
accomplished: 2
accordance: 2
accounting: 2
accumulating: 2
accurately: 2
accusation: 2
accused: 2
acquisition: 2
adam: 2
addison: 2
addressing: 2
adjusted: 2
adjusts: 2
administrative: 2
adopt: 2
advancements: 2
advent: 2
adversary: 2
advertises: 2
advice: 2
advocated: 2
aegis: 2
affinity: 2
aforementioned: 2
age: 2
agents: 2
aggregator: 2
aggressive: 2
aict: 2
aim: 2
ajax: 2
akamai: 2
alaska: 2
alberto: 2
albums: 2
alive: 2
alleviating: 2
allocates: 2
allocating: 2
alloscomp: 2
alternatively: 2
altruistic: 2
ame: 2
amortizes: 2
amounting: 2
analyzes: 2
anchorage: 2
anderson: 2
andresen: 2
anomalies: 2
anonymity: 2
anonymously: 2
anti: 2
anticipate: 2
antony: 2
apart: 2
apis: 2
appealing: 2
appeared: 2
appends: 2
applicationindependent: 2
approximately: 2
approximation: 2
approximations: 2
apr: 2
archetypal: 2
argues: 2
arguing: 2
arithmetic: 2
arose: 2
arraystructured: 2
arrived: 2
art: 2
article: 2
articles: 2
asia: 2
asics: 2
asks: 2
asp: 2
aspx: 2
assists: 2
assurance: 2
astonishingly: 2
asynch: 2
atm: 2
attach: 2
attached: 2
attain: 2
attempted: 2
attempting: 2
attestation: 2
attract: 2
attraction: 2
attractiveness: 2
audio: 2
aumann: 2
authentication: 2
automate: 2
autonomous: 2
autotuning: 2
avoidance: 2
ba: 2
baa: 2
babaoglu: 2
bach: 2
backlashed: 2
bailey: 2
baker: 2
ban: 2
barb: 2
barr: 2
barrier: 2
bast: 2
basu: 2
began: 2
behaved: 2
behaving: 2
belonging: 2
benjamin: 2
berlin: 2
bernoulli: 2
besides: 2
bespoke: 2
bhargava: 2
bifurcation: 2
billion: 2
binary: 2
binomial: 2
birrell: 2
bitcoinfoundation: 2
bjornstad: 2
blank: 2
bloomberg: 2
blow: 2
blumenthal: 2
boils: 2
bolton: 2
bonus: 2
borders: 2
box: 2
boycott: 2
bridge: 2
brings: 2
brokerage: 2
bronson: 2
browsers: 2
bruijn: 2
btcguild: 2
btchine: 2
buf: 2
bulpin: 2
burden: 2
burstiness: 2
business: 2
businesses: 2
buterin: 2
butterfly: 2
bypass: 2
caja: 2
calculation: 2
calculations: 2
calvin: 2
came: 2
canada: 2
candidates: 2
canonical: 2
capabilities: 2
carey: 2
carolina: 2
carrera: 2
cash: 2
castro: 2
casual: 2
casually: 2
category: 2
cation: 2
cdns: 2
cease: 2
ceases: 2
ceived: 2
census: 2
centralization: 2
century: 2
certainty: 2
cfm: 2
challenging: 2
chance: 2
characterise: 2
cheaply: 2
checkout: 2
checksums: 2
chemical: 2
chicago: 2
chief: 2
china: 2
chowdhry: 2
cidr: 2
circle: 2
circulate: 2
circulates: 2
circumstances: 2
cited: 2
clark: 2
click: 2
cloudviews: 2
coarse: 2
coexist: 2
coherence: 2
cohort: 2
colarelli: 2
colocated: 2
color: 2
combat: 2
comer: 2
committing: 2
commons: 2
communicated: 2
compelled: 2
compensate: 2
compensation: 2
complement: 2
composing: 2
computes: 2
concentrated: 2
concert: 2
conclusive: 2
confident: 2
confined: 2
connect: 2
cons: 2
considerably: 2
considers: 2
constitute: 2
constraint: 2
contacted: 2
contexts: 2
contract: 2
contradicts: 2
controlling: 2
conversion: 2
converted: 2
converting: 2
cooling: 2
cooper: 2
cording: 2
corner: 2
correspond: 2
countermeasures: 2
counterpart: 2
covered: 2
covering: 2
cox: 2
cpus: 2
credited: 2
credits: 2
cripple: 2
cripples: 2
criticism: 2
croquet: 2
crypto: 2
cryptocurrencies: 2
cryptographic: 2
cryptology: 2
ct: 2
cubic: 2
cypherspace: 2
cz: 2
damage: 2
dan: 2
dangerous: 2
daniel: 2
dast: 2
datasets: 2
datta: 2
days: 2
dbms: 2
dce: 2
dd: 2
deadlocks: 2
dealbook: 2
deceased: 2
decodes: 2
deduce: 2
deeper: 2
deeply: 2
defanti: 2
defects: 2
defer: 2
degradations: 2
degrading: 2
deleting: 2
deliberately: 2
deliberation: 2
delivering: 2
delta: 2
demanding: 2
dentical: 2
dependence: 2
depicted: 2
depicts: 2
deplist: 2
deplistcurr: 2
derive: 2
descriptor: 2
designing: 2
deterministically: 2
deviate: 2
devise: 2
dfreedman: 2
didn: 2
differentiable: 2
diminish: 2
dinosaur: 2
diot: 2
disabled: 2
disadvantage: 2
disadvantages: 2
discount: 2
disincentivize: 2
disrupting: 2
disseminates: 2
dissertation: 2
distances: 2
distinction: 2
diverse: 2
divide: 2
dividing: 2
doi: 2
dok: 2
dominate: 2
dot: 2
dotbit: 2
doubt: 2
downloaded: 2
downloads: 2
downside: 2
drives: 2
driving: 2
dry: 2
ds: 2
dubbed: 2
dugan: 2
dumbbell: 2
duplex: 2
duplicating: 2
dutta: 2
eagerly: 2
earned: 2
earnings: 2
ebling: 2
echo: 2
ecoop: 2
ecosystem: 2
eigenvalue: 2
eighteenth: 2
einar: 2
einstein: 2
elmore: 2
embeddings: 2
emphasis: 2
empirical: 2
enables: 2
encapsulate: 2
encapsulated: 2
encoders: 2
encounter: 2
encountered: 2
encrypted: 2
endhost: 2
ends: 2
ensemble: 2
ent: 2
enters: 2
envision: 2
equate: 2
equilibria: 2
era: 2
ered: 2
esbs: 2
escriva: 2
esign: 2
establishing: 2
estimates: 2
ethereum: 2
ethereumwhitepaper: 2
ets: 2
european: 2
eurosys: 2
ev: 2
eva: 2
eve: 2
eventbased: 2
everyone: 2
eviction: 2
evictions: 2
evolve: 2
exabytes: 2
exceeds: 2
exceptionally: 2
excessively: 2
executions: 2
exerted: 2
exerting: 2
exhibits: 2
expectation: 2
expectations: 2
expedite: 2
explains: 2
explores: 2
exponentially: 2
exports: 2
express: 2
expurging: 2
extensibility: 2
extremes: 2
eyes: 2
facilitate: 2
facto: 2
fair: 2
fall: 2
falling: 2
farms: 2
faulttolerance: 2
featuring: 2
fekete: 2
felser: 2
felten: 2
feng: 2
ferguson: 2
fetched: 2
fills: 2
finer: 2
finished: 2
finishes: 2
fired: 2
firewalling: 2
firoiu: 2
fits: 2
fix: 2
fl: 2
flag: 2
flexibly: 2
fluctuations: 2
fluid: 2
flushed: 2
fold: 2
forbes: 2
forcing: 2
forgo: 2
formats: 2
formulae: 2
forrestv: 2
forth: 2
foundations: 2
fox: 2
fragment: 2
fragments: 2
fraleigh: 2
frameworks: 2
fred: 2
fresh: 2
friction: 2
friedman: 2
friendliness: 2
frobenius: 2
fundamentally: 2
funded: 2
funds: 2
furman: 2
gained: 2
gaps: 2
garbled: 2
gateway: 2
gehrke: 2
generalize: 2
generations: 2
genesis: 2
geometric: 2
ghz: 2
gibbs: 2
gibson: 2
gigabyte: 2
github: 2
glick: 2
globalcrossing: 2
globe: 2
gossiper: 2
gossips: 2
gotten: 2
gr: 2
gradient: 2
gradually: 2
granted: 2
grapevine: 2
grasp: 2
greene: 2
griner: 2
guerraoui: 2
guesses: 2
guessing: 2
gupta: 2
guruprasad: 2
habel: 2
hackers: 2
halfway: 2
halted: 2
handful: 2
hands: 2
happens: 2
harder: 2
harley: 2
harm: 2
hashrate: 2
headers: 2
healthy: 2
heidelberg: 2
height: 2
held: 2
helpful: 2
hereinafter: 2
heterogenous: 2
hey: 2
hibler: 2
hiccups: 2
hides: 2
highlight: 2
highvalue: 2
hinder: 2
histogram: 2
hits: 2
hoarding: 2
hobor: 2
holy: 2
homepage: 2
honesty: 2
honeyman: 2
hops: 2
hotcloud: 2
huitema: 2
hundred: 2
hungry: 2
hurdle: 2
hurwitz: 2
huston: 2
iacr: 2
ic: 2
iciw: 2
icmp: 2
identities: 2
idit: 2
ie: 2
ifip: 2
ih: 2
ij: 2
ill: 2
illinois: 2
im: 2
imagined: 2
immaterial: 2
immediate: 2
immersion: 2
imperatives: 2
imperfect: 2
imply: 2
imposing: 2
impractical: 2
impulse: 2
incorporation: 2
indices: 2
indirection: 2
inefficiency: 2
inefficient: 2
infer: 2
influence: 2
influenced: 2
infrastructures: 2
ingrid: 2
ings: 2
inherent: 2
ining: 2
initialized: 2
initiates: 2
injecting: 2
insertion: 2
inspect: 2
install: 2
installed: 2
instantiated: 2
institutions: 2
instruction: 2
instructs: 2
integer: 2
intentionally: 2
interconnecting: 2
interconnection: 2
interconnects: 2
interix: 2
intermediary: 2
interpret: 2
intersection: 2
intervention: 2
intimate: 2
intricacies: 2
invalid: 2
investment: 2
invoke: 2
invokes: 2
ipdps: 2
iptps: 2
irish: 2
iscussion: 2
island: 2
italy: 2
itcoin: 2
ith: 2
ity: 2
izs: 2
james: 2
javabeans: 2
jimenez: 2
joglekar: 2
jonsson: 2
jsp: 2
juels: 2
justify: 2
kandemir: 2
kansas: 2
kapritsos: 2
karlsson: 2
katabi: 2
kazar: 2
kemme: 2
keycurr: 2
kharif: 2
kiawah: 2
kilper: 2
kim: 2
kimsas: 2
kjkj: 2
knob: 2
knobs: 2
kojo: 2
kroll: 2
krzys: 2
kurose: 2
labelled: 2
labs: 2
lagged: 2
lagging: 2
lake: 2
lambdarail: 2
lambdas: 2
landing: 2
landolsi: 2
laptop: 2
lastly: 2
lastop: 2
launching: 2
laying: 2
le: 2
lease: 2
legitimate: 2
leigh: 2
lepreau: 2
leskovec: 2
leslie: 2
leverages: 2
levy: 2
lightly: 2
lightwave: 2
likewise: 2
lin: 2
liskov: 2
literally: 2
literature: 2
lm: 2
locate: 2
lockstep: 2
longest: 2
longhaul: 2
loops: 2
loosely: 2
louise: 2
lowering: 2
lowers: 2
lows: 2
ltd: 2
luck: 2
lundqvist: 2
lynch: 2
lyon: 2
madden: 2
madhow: 2
magharei: 2
mance: 2
mandatory: 2
mangling: 2
manifested: 2
manipulate: 2
manually: 2
march: 2
marshaling: 2
martinez: 2
matrices: 2
matthews: 2
mature: 2
maximal: 2
maximized: 2
maya: 2
md: 2
mdcc: 2
meant: 2
megabits: 2
memoryless: 2
menees: 2
metacdn: 2
micro: 2
microsystems: 2
migrating: 2
milestone: 2
mined: 2
minimising: 2
minimizes: 2
minus: 2
mirroring: 2
miscalculate: 2
mismatched: 2
mistakenly: 2
mit: 2
mitigated: 2
mitigation: 2
mlml: 2
modem: 2
moderately: 2
modest: 2
modulo: 2
mohr: 2
montenegro: 2
monterey: 2
moshe: 2
mrc: 2
mst: 2
multigrep: 2
multiples: 2
multiplied: 2
multithreading: 2
muri: 2
muthitacharoen: 2
myriad: 2
nakamoto: 2
named: 2
names: 2
naming: 2
nandi: 2
narayanan: 2
naughton: 2
navathe: 2
ncsa: 2
ne: 2
nec: 2
needham: 2
negation: 2
neil: 2
nejdl: 2
newbold: 2
newer: 2
newly: 2
ngan: 2
nic: 2
nichols: 2
nishtala: 2
nity: 2
nlanr: 2
nonequilibrium: 2
nonnenmacher: 2
nontransactional: 2
normalization: 2
normalize: 2
normalizing: 2
normed: 2
notably: 2
notes: 2
notifies: 2
notifying: 2
noting: 2
nutshell: 2
nytimes: 2
obsolete: 2
obviously: 2
occasion: 2
occupies: 2
odd: 2
offices: 2
ofwork: 2
ole: 2
olympics: 2
omi: 2
omits: 2
ool: 2
ooled: 2
op: 2
opacity: 2
opening: 2
operated: 2
opportunities: 2
opt: 2
opted: 2
ordinarily: 2
organizational: 2
organizing: 2
originate: 2
orities: 2
oscillates: 2
ostar: 2
ourselves: 2
outages: 2
outs: 2
outsource: 2
outsources: 2
overcast: 2
overflow: 2
overlays: 2
overqos: 2
pairings: 2
pam: 2
panacea: 2
par: 2
paradigms: 2
parameshwaran: 2
parameterizations: 2
parametrized: 2
parity: 2
park: 2
parno: 2
pass: 2
pathway: 2
patterson: 2
payloads: 2
paypal: 2
pcb: 2
pdcs: 2
pdfs: 2
penalised: 2
pentium: 2
peration: 2
perfor: 2
peris: 2
permits: 2
permitted: 2
perpetrators: 2
perron: 2
petersen: 2
ph: 2
phanishayee: 2
phases: 2
physically: 2
picture: 2
piggybacked: 2
piling: 2
pipeline: 2
pipelines: 2
pitfalls: 2
plague: 2
plays: 2
plication: 2
plugged: 2
plugging: 2
poolattacks: 2
popper: 2
port: 2
porto: 2
ports: 2
poses: 2
position: 2
powersaving: 2
pplive: 2
practically: 2
preceding: 2
precise: 2
precludes: 2
predecessor: 2
predefined: 2
predetermined: 2
predictive: 2
predicts: 2
preferable: 2
prefers: 2
preiss: 2
preliminary: 2
premise: 2
presenting: 2
preservation: 2
preserve: 2
preserving: 2
prevail: 2
prevention: 2
primitive: 2
prioritising: 2
prioritization: 2
prioritize: 2
prioritizing: 2
privately: 2
probabilistically: 2
probe: 2
problematic: 2
processors: 2
produces: 2
professor: 2
profile: 2
profiler: 2
profit: 2
projection: 2
promote: 2
proper: 2
proposals: 2
pros: 2
proving: 2
pseudo: 2
pullbased: 2
pulling: 2
pulse: 2
purchase: 2
purchasing: 2
pure: 2
pursue: 2
pushes: 2
pvldb: 2
qhuang: 2
qin: 2
qmi: 2
qos: 2
quasistatic: 2
quicksilver: 2
quote: 2
race: 2
racticalities: 2
radc: 2
radical: 2
radio: 2
raised: 2
ramakrishnan: 2
ramamritham: 2
randomness: 2
ranges: 2
rank: 2
rateless: 2
rational: 2
ratios: 2
reacts: 2
readily: 2
ready: 2
realizes: 2
rears: 2
reasonably: 2
reception: 2
reciprocation: 2
recognition: 2
recompute: 2
reconciliation: 2
recycling: 2
redesigned: 2
redesigning: 2
reductions: 2
referred: 2
refraining: 2
refreshed: 2
regard: 2
registration: 2
reimplemented: 2
reissue: 2
reissued: 2
rejaie: 2
rejected: 2
rejecting: 2
rejects: 2
relaxed: 2
relay: 2
relevance: 2
relied: 2
relies: 2
reliminaries: 2
relying: 2
remarks: 2
remotely: 2
removes: 2
rendering: 2
rep: 2
repaired: 2
repeatable: 2
repetitions: 2
reporting: 2
repurposing: 2
reputation: 2
requisite: 2
resending: 2
resends: 2
reserves: 2
resident: 2
resolutions: 2
respecting: 2
responsive: 2
restarted: 2
retaliate: 2
retried: 2
retries: 2
reverse: 2
reviewers: 2
revisiting: 2
rewarded: 2
rewritten: 2
reykjavik: 2
reynolds: 2
ricci: 2
rightful: 2
rigid: 2
rigorous: 2
rigorously: 2
rimon: 2
rising: 2
rivalry: 2
roberts: 2
rohrs: 2
rome: 2
roots: 2
rose: 2
rosenblum: 2
ross: 2
rounding: 2
routinely: 2
row: 2
rp: 2
rsized: 2
rt: 2
rtts: 2
ruling: 2
runners: 2
rvr: 2
sabul: 2
safe: 2
saha: 2
said: 2
sake: 2
sales: 2
satellite: 2
saxena: 2
scans: 2
scatter: 2
scattered: 2
scheduler: 2
schedules: 2
sci: 2
scientist: 2
scratch: 2
scsi: 2
seamless: 2
secondgeneration: 2
seda: 2
seeking: 2
seemingly: 2
seldom: 2
seltzer: 2
seminar: 2
senior: 2
sensible: 2
sept: 2
serial: 2
serialize: 2
serially: 2
serious: 2
serverlets: 2
serverpull: 2
settle: 2
shape: 2
shapley: 2
sharp: 2
sheds: 2
shelby: 2
shell: 2
shi: 2
shieh: 2
shifts: 2
shokrollahi: 2
shortcut: 2
shortly: 2
sidebotham: 2
sigact: 2
signs: 2
sigops: 2
sigurbjornsson: 2
silicon: 2
silverlight: 2
simplification: 2
simplified: 2
simulating: 2
singh: 2
sinks: 2
sister: 2
sivakumar: 2
slashdot: 2
slashes: 2
slows: 2
slush: 2
smooth: 2
soar: 2
soars: 2
soas: 2
societies: 2
society: 2
solaris: 2
solely: 2
solheim: 2
solid: 2
solved: 2
something: 2
son: 2
sonic: 2
sons: 2
soper: 2
sourceforge: 2
south: 2
sovran: 2
specialists: 2
speedups: 2
spend: 2
spending: 2
splits: 2
spreads: 2
spreitzer: 2
srs: 2
st: 2
stabilizes: 2
staggering: 2
standalone: 2
stands: 2
stat: 2
statement: 2
station: 2
statqwest: 2
stats: 2
steal: 2
stefan: 2
stephen: 2
stocks: 2
stoller: 2
stops: 2
stories: 2
storms: 2
story: 2
stripe: 2
striping: 2
sturgis: 2
styles: 2
su: 2
subgroup: 2
submits: 2
submitted: 2
submitting: 2
subscribed: 2
subversive: 2
subverted: 2
succession: 2
successively: 2
sudden: 2
suffice: 2
suggest: 2
suggestions: 2
suited: 2
summation: 2
sundr: 2
supergame: 2
supergames: 2
supervisors: 2
supply: 2
suppose: 2
sure: 2
surpass: 2
surprise: 2
survey: 2
susceptibility: 2
suspect: 2
sustain: 2
swallow: 2
swanson: 2
swapping: 2
swift: 2
swinehart: 2
swiss: 2
sybil: 2
synchronize: 2
synthesis: 2
systematic: 2
systemic: 2
tablets: 2
tagged: 2
tailer: 2
tandard: 2
tango: 2
tardos: 2
tation: 2
tauber: 2
tc: 2
technically: 2
tempted: 2
tend: 2
termed: 2
testbed: 2
tgperf: 2
theimer: 2
thick: 2
thing: 2
thirtieth: 2
thumb: 2
tiered: 2
ties: 2
tional: 2
tions: 2
tirumala: 2
toappliance: 2
tock: 2
tods: 2
tolerates: 2
tolerating: 2
topeer: 2
topologically: 2
totally: 2
touch: 2
touches: 2
toueg: 2
tough: 2
toy: 2
tp: 2
tracing: 2
tracked: 2
trades: 2
tragedy: 2
tranmission: 2
transact: 2
transcoded: 2
transforming: 2
trapezoids: 2
treatment: 2
tremel: 2
triangular: 2
tricky: 2
tries: 2
trivially: 2
trol: 2
trsu: 2
trustworthy: 2
tuft: 2
tuned: 2
tv: 2
twentieth: 2
twofold: 2
ugly: 2
umich: 2
un: 2
unaltered: 2
unattacked: 2
unattractive: 2
uncommitable: 2
uncommitted: 2
unexplored: 2
unfavorable: 2
uninvolved: 2
uniquely: 2
united: 2
unlucky: 2
unnecessarily: 2
unnecessary: 2
unreachable: 2
unresponsive: 2
uploading: 2
urgent: 2
userspace: 2
validating: 2
vancouver: 2
vandermeer: 2
vandermonde: 2
vasek: 2
vcurr: 2
vein: 2
venkataramani: 2
ver: 2
verby: 2
versioned: 2
vicinity: 2
viewers: 2
violations: 2
virtualized: 2
visibility: 2
visited: 2
vko: 2
volumes: 2
vpn: 2
wakeup: 2
walks: 2
wallace: 2
war: 2
warehouse: 2
warship: 2
watching: 2
wattenhofer: 2
weakens: 2
weaker: 2
weaknesses: 2
websphere: 2
welch: 2
wesley: 2
west: 2
whereby: 2
whom: 2
wicker: 2
wider: 2
width: 2
wiley: 2
williams: 2
willing: 2
willner: 2
winter: 2
withholds: 2
witnessed: 2
wizkid: 2
wlog: 2
wo: 2
wolfgang: 2
wong: 2
words: 2
workflow: 2
worsening: 2
wrapping: 2
wrongdoing: 2
wvwv: 2
xie: 2
xored: 2
xp: 2
xth: 2
yang: 2
ymir: 2
yxxy: 2
zoom: 2
aaron: 1
abbreviations: 1
abilalso: 1
absorbs: 1
abstracts: 1
abu: 1
accompanied: 1
accomplish: 1
accomplishing: 1
accounted: 1
accumulate: 1
aceves: 1
acheive: 1
acheived: 1
acls: 1
acmula: 1
acomplish: 1
acquires: 1
acquiring: 1
acthe: 1
activated: 1
actuators: 1
acwe: 1
adamic: 1
adaptable: 1
adapted: 1
adaptively: 1
adaptivity: 1
addi: 1
addiserver: 1
additive: 1
addressable: 1
adelaide: 1
adhere: 1
adjacent: 1
administers: 1
admit: 1
admits: 1
adoption: 1
ads: 1
advertise: 1
advertised: 1
adya: 1
aelstrom: 1
aerospace: 1
af: 1
affirmative: 1
afford: 1
afforded: 1
afraid: 1
afterward: 1
agenda: 1
agent: 1
ager: 1
aggregat: 1
aggregrate: 1
aggressively: 1
aggressiveness: 1
agreements: 1
ahnn: 1
aid: 1
aims: 1
airplane: 1
ak: 1
akkus: 1
alarms: 1
albatross: 1
albrecht: 1
alegre: 1
alexander: 1
alfetching: 1
allavena: 1
allegedly: 1
alleviated: 1
alleviates: 1
allo: 1
alloc: 1
allocations: 1
allthingsdistributed: 1
alof: 1
alpha: 1
altogether: 1
altrustic: 1
am: 1
amar: 1
ambitious: 1
america: 1
amortized: 1
ample: 1
amplify: 1
amsden: 1
analogy: 1
analyse: 1
analyst: 1
analytics: 1
ance: 1
anceaume: 1
anddrop: 1
andersen: 1
andre: 1
andreas: 1
ann: 1
anne: 1
annie: 1
annotated: 1
announce: 1
announcement: 1
announces: 1
annoyingly: 1
annually: 1
anonymous: 1
answered: 1
answers: 1
anticipated: 1
antipolis: 1
antonio: 1
anytime: 1
anyway: 1
anywhere: 1
ap: 1
apa: 1
appeal: 1
appendix: 1
applaud: 1
appleton: 1
appli: 1
applicationdropped: 1
appliit: 1
applior: 1
applithe: 1
approaching: 1
approximates: 1
apps: 1
apthe: 1
arbor: 1
architects: 1
archival: 1
archives: 1
argus: 1
arisen: 1
armies: 1
arranging: 1
arrivals: 1
artifact: 1
artificial: 1
ase: 1
aside: 1
ask: 1
asking: 1
assembling: 1
assist: 1
assisted: 1
associates: 1
associating: 1
astrolabe: 1
aswhen: 1
asynbandwidth: 1
asynchrony: 1
asynmicrobenchmarks: 1
asynmobile: 1
asynqueue: 1
ata: 1
atomically: 1
atr: 1
att: 1
attaches: 1
attaching: 1
attar: 1
attention: 1
attr: 1
attracted: 1
attributable: 1
attributed: 1
atypical: 1
audit: 1
audits: 1
australia: 1
authoritative: 1
authorized: 1
autodesk: 1
automation: 1
autotion: 1
autowriteback: 1
autumn: 1
ava: 1
availto: 1
avatar: 1
awaiting: 1
awareness: 1
axes: 1
azim: 1
backgound: 1
backgrounds: 1
backlog: 1
backlogs: 1
backnt: 1
backups: 1
bakalova: 1
balancers: 1
ballance: 1
ballot: 1
banaei: 1
bandcontain: 1
bandhowever: 1
bandwhile: 1
bandwidthdelay: 1
bandwidthsensitive: 1
banff: 1
barcelona: 1
bare: 1
barracuda: 1
barriers: 1
baseline: 1
bastion: 1
batched: 1
batches: 1
batching: 1
batkin: 1
battle: 1
battlefield: 1
battleground: 1
bayeux: 1
bcc: 1
bcq: 1
became: 1
befriended: 1
behren: 1
beijing: 1
belief: 1
believed: 1
beloved: 1
benchmarking: 1
benchmarks: 1
benenational: 1
benoit: 1
bered: 1
berkeleydb: 1
bernd: 1
bershad: 1
bership: 1
bert: 1
bertier: 1
bhattacharjee: 1
biggest: 1
bile: 1
bill: 1
billed: 1
billing: 1
bills: 1
bindel: 1
binds: 1
bio: 1
bitcoinmines: 1
bk: 1
blades: 1
blame: 1
ble: 1
bleeding: 1
blending: 1
blogs: 1
boa: 1
board: 1
body: 1
bold: 1
bologna: 1
bond: 1
bonding: 1
bonn: 1
book: 1
boosting: 1
boot: 1
borisov: 1
bortnikov: 1
boss: 1
bostic: 1
bother: 1
bottlenecks: 1
bought: 1
boundary: 1
bounds: 1
boys: 1
bq: 1
br: 1
brahms: 1
brazil: 1
breakthrough: 1
bregni: 1
breslau: 1
brian: 1
bridging: 1
bright: 1
british: 1
broad: 1
broberg: 1
brokers: 1
brought: 1
bruno: 1
budget: 1
budgets: 1
buffercould: 1
bug: 1
buggy: 1
bugs: 1
builders: 1
burdens: 1
bureau: 1
burgess: 1
buried: 1
burrows: 1
busnel: 1
button: 1
buyer: 1
buying: 1
buys: 1
cabrera: 1
cacheable: 1
cacheserializability: 1
caise: 1
cal: 1
calability: 1
camargos: 1
cameras: 1
cancelled: 1
candidate: 1
cannes: 1
cantwell: 1
capability: 1
cappuccino: 1
captured: 1
caratti: 1
carded: 1
cardinality: 1
cardoso: 1
career: 1
careers: 1
careful: 1
caribbean: 1
carl: 1
carried: 1
carrier: 1
carrying: 1
cart: 1
carzaniga: 1
cas: 1
cascades: 1
cast: 1
castor: 1
catalog: 1
catastrophe: 1
catastrophic: 1
cated: 1
categorized: 1
cations: 1
causal: 1
cbb: 1
cbbc: 1
cbqpcb: 1
ccb: 1
ccdf: 1
cdf: 1
cdrom: 1
ceives: 1
cell: 1
centered: 1
ceremony: 1
certify: 1
certifying: 1
cess: 1
chained: 1
chainlink: 1
chair: 1
chakka: 1
chakravorty: 1
challenger: 1
chang: 1
changtao: 1
chapman: 1
characterised: 1
chawathe: 1
cheat: 1
checkouts: 1
chenchu: 1
cheslack: 1
chicken: 1
chiefly: 1
chien: 1
chinese: 1
ching: 1
chockler: 1
choke: 1
chose: 1
chow: 1
christened: 1
christmas: 1
chronously: 1
chrony: 1
chu: 1
chuck: 1
chunk: 1
chunks: 1
cincilla: 1
circuitous: 1
circulation: 1
circumvented: 1
circumvents: 1
citation: 1
cites: 1
cities: 1
clara: 1
clarity: 1
cleaned: 1
cleanly: 1
clearer: 1
clements: 1
clientserver: 1
clocks: 1
clone: 1
closest: 1
cloudifying: 1
clutter: 1
cmu: 1
codaniques: 1
coded: 1
coding: 1
coexistence: 1
coexists: 1
coherency: 1
coincide: 1
collaborate: 1
collaborating: 1
collapsing: 1
collateral: 1
collects: 1
collusions: 1
columbia: 1
comings: 1
comitting: 1
comm: 1
commatic: 1
commence: 1
commences: 1
commentary: 1
commenting: 1
commercially: 1
commonplace: 1
communal: 1
communi: 1
commutative: 1
comp: 1
compact: 1
comparably: 1
comparaour: 1
comparative: 1
comparisons: 1
compelling: 1
compensating: 1
competitors: 1
compiler: 1
complementary: 1
complementing: 1
complexities: 1
complimentary: 1
comply: 1
compositional: 1
compressed: 1
compresses: 1
comprising: 1
compromises: 1
compromising: 1
computationally: 1
computfits: 1
comsium: 1
concentrates: 1
concentration: 1
conception: 1
conceptually: 1
concludes: 1
concrete: 1
concurby: 1
concuruses: 1
conditioned: 1
conext: 1
configure: 1
conform: 1
conios: 1
conitbased: 1
conjecture: 1
connec: 1
connectionless: 1
conner: 1
consequent: 1
conserving: 1
consisted: 1
consisupdate: 1
consortium: 1
constantly: 1
constituent: 1
constrain: 1
constructs: 1
consulting: 1
consumer: 1
consumers: 1
contacting: 1
contally: 1
contemplate: 1
contemplated: 1
contemplating: 1
contending: 1
conthe: 1
contingencies: 1
contolerate: 1
contractors: 1
contravention: 1
contributes: 1
controller: 1
controversy: 1
convenience: 1
convention: 1
converged: 1
converging: 1
conversely: 1
converts: 1
conveyed: 1
convoys: 1
cooperating: 1
coordinated: 1
coordinating: 1
coordinators: 1
copied: 1
coping: 1
cops: 1
cornelldeveloped: 1
corr: 1
corrected: 1
corrections: 1
correspondingly: 1
corroborated: 1
corrupted: 1
cotton: 1
counters: 1
counting: 1
couple: 1
crashing: 1
crawl: 1
credit: 1
credo: 1
crete: 1
crippling: 1
criteria: 1
critically: 1
crossroads: 1
crowcroft: 1
csd: 1
cstr: 1
culled: 1
cumulatively: 1
customised: 1
customizability: 1
customizable: 1
customization: 1
customizing: 1
customuserserviceapp: 1
cutler: 1
cuts: 1
cybercaf: 1
cyrus: 1
czerwinski: 1
dallas: 1
danielsson: 1
danilov: 1
dantzig: 1
dat: 1
datagrams: 1
dataset: 1
datastores: 1
daunting: 1
dave: 1
davoli: 1
dazzling: 1
dc: 1
dead: 1
deadlock: 1
deadly: 1
deadtially: 1
dean: 1
debatable: 1
debate: 1
debated: 1
debilitating: 1
debris: 1
debugger: 1
declare: 1
declaring: 1
declines: 1
decode: 1
decoder: 1
decoding: 1
decoupled: 1
decouples: 1
decreased: 1
defend: 1
deferplications: 1
deferrable: 1
defers: 1
defgh: 1
defining: 1
definitions: 1
degrees: 1
deit: 1
delegation: 1
delete: 1
deleted: 1
delivers: 1
demanded: 1
demise: 1
demonstration: 1
denning: 1
dennis: 1
denoting: 1
dep: 1
depart: 1
departments: 1
dependalso: 1
dependenrate: 1
depsa: 1
depth: 1
dequeued: 1
der: 1
dered: 1
deregistered: 1
derivative: 1
derivatives: 1
derives: 1
deriving: 1
des: 1
descending: 1
deserver: 1
deshow: 1
designated: 1
designating: 1
designer: 1
desirability: 1
desirable: 1
desktops: 1
destabilize: 1
destinations: 1
detailing: 1
deterioration: 1
determinants: 1
detrimental: 1
dev: 1
developerhours: 1
deviations: 1
devised: 1
devlin: 1
devoted: 1
devoting: 1
dewitt: 1
dexa: 1
dhs: 1
dht: 1
diamond: 1
dictionaries: 1
diego: 1
dies: 1
differany: 1
differential: 1
differentiates: 1
differentiating: 1
differenwith: 1
differing: 1
diffs: 1
dimensions: 1
dimov: 1
ding: 1
directing: 1
directs: 1
disable: 1
disables: 1
disappearance: 1
disappeared: 1
disastrous: 1
disbut: 1
discard: 1
disconnections: 1
disconnects: 1
discontinuing: 1
discotheque: 1
discounts: 1
discovered: 1
discusses: 1
discussing: 1
disguise: 1
disinclined: 1
disjoing: 1
dislike: 1
dismiss: 1
dispatch: 1
dispatcher: 1
dispatching: 1
displayed: 1
displaying: 1
displays: 1
dispools: 1
disregarded: 1
dissatisfied: 1
disseminating: 1
distill: 1
distorted: 1
diverges: 1
diversion: 1
diversity: 1
dll: 1
dlls: 1
documented: 1
dol: 1
domains: 1
dominating: 1
donet: 1
door: 1
dou: 1
doubled: 1
douceur: 1
doug: 1
downgraded: 1
downtime: 1
dozen: 1
dr: 1
drain: 1
drained: 1
drawbacks: 1
drawing: 1
draws: 1
drift: 1
drifting: 1
drive: 1
drivers: 1
drone: 1
duals: 1
ducing: 1
dummynet: 1
dundant: 1
dunn: 1
duplicates: 1
dur: 1
durably: 1
durations: 1
dwarf: 1
dx: 1
dynamics: 1
ear: 1
eastham: 1
economies: 1
ecution: 1
edd: 1
edges: 1
edit: 1
editors: 1
edits: 1
eds: 1
eduardo: 1
educational: 1
edutella: 1
eed: 1
efficacies: 1
eg: 1
egemen: 1
egg: 1
ekin: 1
elasticity: 1
elect: 1
electric: 1
electricity: 1
electronics: 1
eleventh: 1
eliability: 1
elicit: 1
eliciting: 1
elkin: 1
embark: 1
embody: 1
embrace: 1
embraces: 1
emerged: 1
emerges: 1
emitting: 1
emmanuelle: 1
empted: 1
emto: 1
emulating: 1
encapsulates: 1
encod: 1
encode: 1
encompass: 1
encourages: 1
encrypt: 1
encrypts: 1
endeavor: 1
endowment: 1
endpoints: 1
endtransaction: 1
endtransport: 1
enemy: 1
enforced: 1
engine: 1
engineers: 1
enlarge: 1
enlarges: 1
enlarging: 1
enputing: 1
entail: 1
entering: 1
entitled: 1
entropy: 1
enumerate: 1
episodes: 1
epositories: 1
epstein: 1
equeation: 1
equipped: 1
erally: 1
erates: 1
erent: 1
ering: 1
erodes: 1
erred: 1
errorprone: 1
ery: 1
eschewing: 1
esprit: 1
establish: 1
establishes: 1
etup: 1
eugster: 1
evalappended: 1
eventoriented: 1
everyday: 1
everywhere: 1
evocative: 1
evolves: 1
evolving: 1
exacerbating: 1
exaggerated: 1
examined: 1
excellently: 1
excess: 1
exchanging: 1
excitement: 1
exclusively: 1
exec: 1
execusystem: 1
executable: 1
exemplifies: 1
exercise: 1
exhibitthe: 1
existed: 1
exited: 1
exiting: 1
expects: 1
expedited: 1
expense: 1
experiencing: 1
expert: 1
expire: 1
explanation: 1
explanatory: 1
exploits: 1
exponentiated: 1
exporting: 1
expose: 1
exposition: 1
expunged: 1
expurge: 1
exsmart: 1
exspecified: 1
extending: 1
extensible: 1
extensively: 1
extracting: 1
extracts: 1
facilitates: 1
facilitating: 1
facing: 1
factory: 1
failing: 1
failuredetectio: 1
failwhen: 1
faithful: 1
faloutsos: 1
falsely: 1
faltered: 1
famous: 1
farber: 1
farewell: 1
farm: 1
farnoush: 1
farther: 1
fascination: 1
fashioned: 1
fastest: 1
featured: 1
federal: 1
federica: 1
feel: 1
feels: 1
feet: 1
feldman: 1
fell: 1
fellow: 1
fellowship: 1
felt: 1
ferred: 1
ferris: 1
ffs: 1
fic: 1
fidelity: 1
fifteen: 1
figured: 1
fikes: 1
filing: 1
filled: 1
films: 1
filtered: 1
filters: 1
finance: 1
findings: 1
finegrained: 1
finergrained: 1
finish: 1
fiorano: 1
firewall: 1
firms: 1
fisher: 1
fitted: 1
fitting: 1
fixes: 1
flavors: 1
flaws: 1
flickr: 1
flood: 1
flooding: 1
fluctuating: 1
fluke: 1
flushing: 1
fly: 1
focs: 1
football: 1
forcibly: 1
forecast: 1
foregoing: 1
foremost: 1
foresee: 1
forgoing: 1
fork: 1
forked: 1
formal: 1
formally: 1
formed: 1
formerly: 1
fort: 1
fortune: 1
forwards: 1
founder: 1
fractions: 1
franke: 1
frans: 1
freed: 1
freenix: 1
freeze: 1
freshness: 1
fricano: 1
friends: 1
friendship: 1
frightening: 1
frontend: 1
frost: 1
ftcs: 1
fugal: 1
fulfilling: 1
fulfillment: 1
functional: 1
fund: 1
funding: 1
furniture: 1
furthest: 1
gabit: 1
gabriel: 1
gallager: 1
garbinato: 1
garcia: 1
gates: 1
gathering: 1
gauge: 1
gauthier: 1
gave: 1
gb: 1
gbit: 1
gcheap: 1
geambasu: 1
generalized: 1
genercache: 1
generous: 1
geneva: 1
genit: 1
genuinely: 1
geodistributed: 1
geoff: 1
geoffrey: 1
gershinsky: 1
gestion: 1
getting: 1
ghemawat: 1
gi: 1
gian: 1
giardullo: 1
gifford: 1
gilbert: 1
ginting: 1
ginza: 1
gis: 1
gist: 1
giving: 1
glade: 1
glance: 1
glitches: 1
globalized: 1
globecom: 1
goel: 1
gold: 1
goldberg: 1
googles: 1
gov: 1
governed: 1
governmental: 1
grade: 1
gradual: 1
grande: 1
granting: 1
granularity: 1
graphical: 1
grc: 1
gree: 1
greece: 1
grepwe: 1
griffioen: 1
grimm: 1
grips: 1
grochowski: 1
grounds: 1
groundwork: 1
grove: 1
gruber: 1
grunwald: 1
guadelope: 1
gubarev: 1
guha: 1
guis: 1
gunnar: 1
gunnars: 1
gurevich: 1
gurus: 1
guy: 1
guyadec: 1
hacked: 1
hacking: 1
hadoop: 1
haifa: 1
halem: 1
halt: 1
halts: 1
halves: 1
hampering: 1
hanan: 1
handing: 1
handled: 1
handler: 1
handoff: 1
handurukande: 1
hang: 1
hansell: 1
happened: 1
haridasan: 1
haridasana: 1
harmful: 1
harnessing: 1
harpaz: 1
hartman: 1
harwood: 1
hasn: 1
hawaii: 1
hazard: 1
hazards: 1
headquarters: 1
heard: 1
heart: 1
heartbeatmonitor: 1
heat: 1
heavyweight: 1
hegde: 1
hegedu: 1
heidemann: 1
heiser: 1
helen: 1
hellerstein: 1
helped: 1
henceforth: 1
her: 1
herein: 1
hersonissos: 1
hesitate: 1
heterogeneity: 1
heuristic: 1
heuristics: 1
hiding: 1
highassurance: 1
highbandwidth: 1
highbut: 1
highlights: 1
highlyavailable: 1
highpower: 1
highquality: 1
hik: 1
hill: 1
him: 1
himself: 1
hisgen: 1
hjelm: 1
hochschild: 1
holbrook: 1
holder: 1
holding: 1
holte: 1
homes: 1
homomorphic: 1
honolulu: 1
honored: 1
hoon: 1
hopcroft: 1
hoping: 1
horizontal: 1
horn: 1
horrible: 1
hospital: 1
hotice: 1
hotly: 1
hotnets: 1
hotzone: 1
hours: 1
howa: 1
hpca: 1
hreshold: 1
hrs: 1
hsieh: 1
htm: 1
hu: 1
huazhong: 1
huberman: 1
hungary: 1
hurricane: 1
hurting: 1
hyder: 1
hyper: 1
ically: 1
icccn: 1
iceland: 1
icomp: 1
icons: 1
icpads: 1
icsoc: 1
idempotence: 1
iden: 1
idenhigh: 1
identically: 1
idigest: 1
ied: 1
igniting: 1
ignorance: 1
ihkj: 1
iis: 1
ilability: 1
illegal: 1
illusion: 1
imaginable: 1
imation: 1
imc: 1
imlocal: 1
immature: 1
immersive: 1
impacts: 1
implememted: 1
implemenfrom: 1
implemenshared: 1
implementapackages: 1
implosion: 1
implying: 1
import: 1
imported: 1
imporwriteback: 1
imposition: 1
impossibility: 1
imprecise: 1
impressive: 1
improv: 1
inadequacy: 1
inadequate: 1
inadequately: 1
inapplicable: 1
inappropriate: 1
inbound: 1
incentivize: 1
inception: 1
inclusive: 1
incompatible: 1
incomplete: 1
incon: 1
inconsisto: 1
incorpoas: 1
increasess: 1
incredibly: 1
incrementing: 1
indefinitely: 1
independence: 1
indexing: 1
indicators: 1
indictment: 1
indirect: 1
indirectly: 1
indispensable: 1
individinterference: 1
individuals: 1
indranil: 1
induced: 1
industrystandard: 1
inefficiencies: 1
inevitable: 1
inexpennet: 1
inf: 1
infect: 1
infected: 1
infection: 1
infectious: 1
inference: 1
inferred: 1
inflate: 1
inflexibility: 1
inflight: 1
informa: 1
informatics: 1
informing: 1
informs: 1
infrequent: 1
infused: 1
inherited: 1
inhibit: 1
inhibiting: 1
inicontention: 1
initialised: 1
initialize: 1
initiating: 1
initiation: 1
inject: 1
injects: 1
inner: 1
innetwork: 1
innotice: 1
innovate: 1
inprocess: 1
inputs: 1
insecure: 1
insensitive: 1
inseparable: 1
inserted: 1
inserts: 1
inspection: 1
inspired: 1
instruct: 1
instructed: 1
instructing: 1
instructions: 1
instrument: 1
instrumented: 1
instrumenting: 1
int: 1
integers: 1
integrity: 1
intellection: 1
intellectual: 1
intelligence: 1
intem: 1
intense: 1
intensity: 1
intention: 1
intentions: 1
interadditional: 1
intercluster: 1
interdependence: 1
interests: 1
interfere: 1
interferes: 1
interject: 1
interlinked: 1
intermittent: 1
intermittently: 1
internally: 1
internships: 1
interoriginally: 1
interpreted: 1
interpreting: 1
interprocess: 1
interrogates: 1
interrupt: 1
interrupts: 1
interspersed: 1
intervenallows: 1
intra: 1
intractable: 1
intrapartition: 1
intrusion: 1
intrusions: 1
intuitively: 1
invaluable: 1
invariant: 1
invest: 1
investigations: 1
invisible: 1
invocation: 1
invocations: 1
involve: 1
involvement: 1
involving: 1
iperfthe: 1
ipto: 1
irections: 1
irregularity: 1
irregularly: 1
irrelevant: 1
irrespectively: 1
isca: 1
isola: 1
isolate: 1
isolated: 1
isolating: 1
israel: 1
istemi: 1
istva: 1
itcc: 1
items: 1
iterators: 1
ities: 1
itors: 1
iyengar: 1
jacobson: 1
jade: 1
jain: 1
janne: 1
jannotti: 1
jansch: 1
jared: 1
jari: 1
je: 1
jerian: 1
jesi: 1
jian: 1
jiang: 1
jin: 1
jini: 1
jit: 1
jiun: 1
jk: 1
jmc: 1
jms: 1
job: 1
jobs: 1
joined: 1
jones: 1
jong: 1
jorge: 1
jostling: 1
jr: 1
judicious: 1
julkunen: 1
jump: 1
jumpy: 1
juni: 1
junqueira: 1
justice: 1
justification: 1
kallman: 1
kalogeras: 1
kamilmani: 1
kaminsky: 1
kamra: 1
kanthak: 1
karamanolis: 1
karels: 1
karp: 1
kashani: 1
katti: 1
kay: 1
kde: 1
keidl: 1
keith: 1
keller: 1
kempe: 1
kent: 1
kerberos: 1
kernels: 1
kernilized: 1
kevin: 1
keyboard: 1
khan: 1
khorlin: 1
kib: 1
kick: 1
kicking: 1
kicks: 1
kid: 1
kilobyte: 1
kilobytes: 1
kirk: 1
kistler: 1
kit: 1
kk: 1
kleiman: 1
kliot: 1
kloc: 1
knights: 1
knowledgments: 1
kodali: 1
kogan: 1
korhonen: 1
koskela: 1
kostic: 1
kouznetsov: 1
kr: 1
kramer: 1
kraska: 1
krishnakumar: 1
krishnamurthy: 1
kristjan: 1
kristjanvj: 1
krohn: 1
kubiatowicz: 1
kulkarni: 1
kumar: 1
kupfer: 1
kwiatkowski: 1
la: 1
laboratories: 1
laboratory: 1
lacked: 1
ladis: 1
lafayette: 1
lag: 1
lags: 1
laid: 1
laing: 1
lamb: 1
land: 1
landlord: 1
lands: 1
landscapes: 1
lapping: 1
larry: 1
lasting: 1
lauderdale: 1
launch: 1
law: 1
lay: 1
layed: 1
layering: 1
lazy: 1
leaks: 1
learned: 1
learners: 1
leasing: 1
lecture: 1
led: 1
lee: 1
leff: 1
legends: 1
lenient: 1
lenz: 1
lesser: 1
lets: 1
lever: 1
levin: 1
libdeh: 1
liberal: 1
licensing: 1
lie: 1
lied: 1
lieu: 1
lighter: 1
likelihood: 1
limitation: 1
linden: 1
lindsay: 1
linearizable: 1
linger: 1
linkages: 1
lion: 1
listen: 1
listening: 1
littered: 1
liveness: 1
lives: 1
livestreaming: 1
livny: 1
lkjj: 1
ln: 1
lo: 1
localized: 1
localizes: 1
lockfree: 1
logarithmic: 1
logarithmically: 1
logics: 1
login: 1
logstructured: 1
lombard: 1
longput: 1
longrunning: 1
lookup: 1
loose: 1
loses: 1
loudifying: 1
louisiana: 1
lowand: 1
lowbandwidth: 1
lowerfile: 1
lowmfs: 1
lowney: 1
lowpower: 1
lpdc: 1
lr: 1
lugano: 1
luna: 1
luo: 1
lying: 1
lyles: 1
maarten: 1
mach: 1
macrobenchmarks: 1
maffeis: 1
magazine: 1
maglaris: 1
magnetic: 1
magnified: 1
magninetwork: 1
mahajan: 1
maheshwari: 1
mailing: 1
mailoth: 1
mainly: 1
mainteconsequently: 1
mak: 1
maki: 1
malloth: 1
man: 1
mandated: 1
mandreoli: 1
manipulates: 1
manm: 1
mann: 1
mao: 1
marandi: 1
marchukov: 1
marcon: 1
margo: 1
marie: 1
marin: 1
mario: 1
markoff: 1
markus: 1
marrying: 1
marshal: 1
martignon: 1
maryland: 1
marzullo: 1
mash: 1
mashing: 1
masking: 1
mass: 1
massachussetts: 1
matches: 1
materials: 1
matically: 1
matskin: 1
matt: 1
maxcontiguous: 1
maxim: 1
maximizing: 1
maymounkov: 1
mazieres: 1
mazon: 1
mbit: 1
mcauliffe: 1
mcelroy: 1
mckenney: 1
mea: 1
meaning: 1
meaningfully: 1
meantime: 1
mechacies: 1
medians: 1
mediarich: 1
mediately: 1
medical: 1
meet: 1
meetings: 1
megabytes: 1
megastore: 1
meirong: 1
melnik: 1
mem: 1
memcache: 1
memcopy: 1
memoryrelated: 1
men: 1
mendel: 1
menus: 1
mer: 1
merchant: 1
merging: 1
meta: 1
metaphor: 1
miami: 1
miao: 1
mib: 1
migrate: 1
mika: 1
mike: 1
mikhail: 1
mile: 1
milestones: 1
millions: 1
mimic: 1
mindset: 1
minh: 1
minimise: 1
minimised: 1
minimized: 1
minitransactions: 1
minjun: 1
minneapolis: 1
minnesota: 1
minobrowser: 1
mirrored: 1
mirrors: 1
misbehavior: 1
misfinally: 1
miskin: 1
mislove: 1
misra: 1
mistakes: 1
mitigates: 1
mitigating: 1
mitzenmacher: 1
mixes: 1
mmcn: 1
moderate: 1
modewell: 1
modularity: 1
mofavouring: 1
mohan: 1
moll: 1
moments: 1
monetary: 1
monin: 1
monnet: 1
mono: 1
monolithic: 1
monotonically: 1
moon: 1
morning: 1
morris: 1
mostlyreads: 1
motes: 1
motivating: 1
motivations: 1
mounted: 1
mouse: 1
movement: 1
mpi: 1
mplementation: 1
mscorwks: 1
msgs: 1
msiegen: 1
msn: 1
mts: 1
mulsequence: 1
multiframed: 1
multigigabit: 1
multiin: 1
multimedia: 1
multiplexing: 1
multispeed: 1
multitier: 1
multitude: 1
multiversioning: 1
multiwas: 1
multo: 1
mummert: 1
murderous: 1
music: 1
mutexes: 1
mvs: 1
mwaura: 1
na: 1
naaman: 1
nagle: 1
nahrstedt: 1
naively: 1
naks: 1
namespace: 1
nance: 1
napper: 1
narada: 1
nary: 1
nate: 1
nats: 1
naval: 1
navigate: 1
navy: 1
nawab: 1
nca: 1
ndi: 1
neatly: 1
necessity: 1
needing: 1
needless: 1
needlessly: 1
negative: 1
negatively: 1
negligibly: 1
negotiate: 1
nei: 1
neighboring: 1
nelson: 1
ness: 1
netecon: 1
neting: 1
neufeld: 1
newarr: 1
newscasts: 1
nextgeneration: 1
nfs: 1
ngas: 1
nicely: 1
niche: 1
nick: 1
night: 1
nikolov: 1
nimble: 1
ninth: 1
nishimura: 1
nishita: 1
nism: 1
nization: 1
noisy: 1
nomad: 1
nonblockingtransport: 1
noncongestion: 1
nondeterministic: 1
nonempty: 1
nossdav: 1
noteworthy: 1
notified: 1
notoriously: 1
nowadays: 1
np: 1
npapers: 1
nsfc: 1
ntserver: 1
num: 1
numb: 1
numeric: 1
nutanong: 1
nygren: 1
obeyed: 1
obeys: 1
obfuscates: 1
objective: 1
objectivity: 1
objectoriented: 1
obligation: 1
obliging: 1
observable: 1
observes: 1
obsessively: 1
obsoleted: 1
obstacle: 1
obstructs: 1
occurrence: 1
ofc: 1
offenders: 1
offerings: 1
officially: 1
offline: 1
offset: 1
oforder: 1
ogy: 1
oltp: 1
omitting: 1
oneanother: 1
ongoing: 1
ontology: 1
onwards: 1
opearting: 1
openafs: 1
opennt: 1
opens: 1
opensketch: 1
operafrom: 1
operamfs: 1
operat: 1
operatencies: 1
opposing: 1
opposition: 1
optimality: 1
optimally: 1
optimisation: 1
optimisations: 1
optimise: 1
optimised: 1
optimistically: 1
optional: 1
orchestrating: 1
orderings: 1
organised: 1
origin: 1
originated: 1
originating: 1
originator: 1
ority: 1
orks: 1
orleans: 1
orma: 1
ormance: 1
ortributed: 1
orts: 1
oscillate: 1
oscillating: 1
ost: 1
otivation: 1
ource: 1
ous: 1
outcontent: 1
outlook: 1
outof: 1
outperform: 1
outperformed: 1
outright: 1
outweighs: 1
overcomes: 1
overhaul: 1
overlaid: 1
overlayed: 1
overloading: 1
overpredict: 1
overprediction: 1
overreach: 1
overrequest: 1
overrequesting: 1
oversight: 1
oversold: 1
overweigh: 1
overwritten: 1
owing: 1
owned: 1
ozalp: 1
ozsu: 1
pa: 1
pack: 1
package: 1
packparently: 1
packs: 1
pain: 1
pairing: 1
paleczny: 1
pallickara: 1
palossless: 1
pan: 1
panel: 1
pang: 1
panning: 1
pans: 1
paolo: 1
papazoglou: 1
parallelising: 1
parallelism: 1
parallelized: 1
parallelizing: 1
parameterizing: 1
parent: 1
parents: 1
paritybased: 1
parliament: 1
parsa: 1
partitionable: 1
partners: 1
party: 1
passes: 1
pastry: 1
pat: 1
paterson: 1
patin: 1
patino: 1
pavlo: 1
pdc: 1
peculiar: 1
peek: 1
peep: 1
peking: 1
penalized: 1
pennsylvania: 1
penzo: 1
perceive: 1
perceiving: 1
percentiles: 1
perception: 1
perdichizzi: 1
perf: 1
performances: 1
perience: 1
periments: 1
permission: 1
permute: 1
permutes: 1
permuting: 1
perobject: 1
persisted: 1
persistence: 1
persisting: 1
personalize: 1
personalized: 1
personally: 1
pertaining: 1
perturbances: 1
perturbation: 1
perturbations: 1
perv: 1
pervasively: 1
pervasiveness: 1
petko: 1
petrov: 1
pfhsn: 1
phani: 1
philadelphia: 1
philosophical: 1
phones: 1
phpmyadmin: 1
physician: 1
pianese: 1
picconi: 1
picking: 1
picks: 1
piece: 1
pieces: 1
piles: 1
pirahesh: 1
pittsburgh: 1
pivotal: 1
plain: 1
planes: 1
planned: 1
planning: 1
plans: 1
plants: 1
plasma: 1
plat: 1
plausible: 1
please: 1
plentiful: 1
plotted: 1
pluggable: 1
plugins: 1
pn: 1
podcasts: 1
pointer: 1
pointers: 1
poirier: 1
police: 1
political: 1
portability: 1
portal: 1
porting: 1
portob: 1
portray: 1
posix: 1
post: 1
postava: 1
posted: 1
posters: 1
postponed: 1
postponing: 1
potencan: 1
potholes: 1
powell: 1
powerhouse: 1
powering: 1
powers: 1
powersavings: 1
ppendix: 1
practices: 1
pratt: 1
pray: 1
preallocating: 1
precede: 1
precious: 1
precision: 1
preclude: 1
predetermining: 1
predictability: 1
predicting: 1
predictions: 1
predominant: 1
predominantly: 1
preempted: 1
preexisting: 1
preferences: 1
prefetchthe: 1
preguica: 1
preparation: 1
prepare: 1
prepared: 1
prepares: 1
preprocessing: 1
pressing: 1
presume: 1
pretend: 1
pretending: 1
pretends: 1
prevailing: 1
prevalent: 1
previewer: 1
previwhen: 1
prices: 1
prifetched: 1
priin: 1
primaldual: 1
princehouse: 1
priorispeedup: 1
prioritized: 1
priortwo: 1
prito: 1
priviledges: 1
privileged: 1
pro: 1
probed: 1
probes: 1
procedures: 1
proceedin: 1
professional: 1
profiled: 1
profiles: 1
profiling: 1
programmed: 1
progressed: 1
prohibited: 1
prohibitive: 1
prohibitively: 1
prohibits: 1
projected: 1
proliferating: 1
prometheus: 1
prominently: 1
promised: 1
promotional: 1
promptly: 1
pronounced: 1
propagates: 1
propagating: 1
propel: 1
propgated: 1
proportionally: 1
proposal: 1
proposes: 1
prothe: 1
prototypes: 1
protruding: 1
proverbial: 1
provers: 1
provisions: 1
provoke: 1
proximity: 1
prudently: 1
pruned: 1
ptions: 1
publications: 1
publishsubscribe: 1
pubsub: 1
punishing: 1
purchased: 1
purdue: 1
putation: 1
puter: 1
puts: 1
puzar: 1
pvalues: 1
pvm: 1
pvt: 1
qnx: 1
qppq: 1
qu: 1
quadrant: 1
quadrants: 1
qualities: 1
quantified: 1
quantity: 1
quarterman: 1
quarters: 1
quasi: 1
quema: 1
questionable: 1
quinlan: 1
quired: 1
quorum: 1
quotes: 1
raab: 1
races: 1
rachid: 1
racing: 1
radar: 1
radi: 1
rago: 1
raid: 1
rails: 1
raincloud: 1
raisepriority: 1
raising: 1
rameter: 1
ramifications: 1
randomised: 1
ranks: 1
ratnasamy: 1
ratner: 1
rayfield: 1
rbudp: 1
rchitecture: 1
reaction: 1
reactive: 1
readiness: 1
readwrite: 1
realistically: 1
realities: 1
realization: 1
realtime: 1
reardon: 1
reboot: 1
rebuilt: 1
recast: 1
rechecks: 1
recipients: 1
recite: 1
reclamation: 1
recode: 1
recommendation: 1
recommended: 1
recommends: 1
reconfigurable: 1
reconfiguration: 1
reconfigure: 1
reconfiguring: 1
reconnect: 1
reconstruction: 1
recorded: 1
recov: 1
recovrequests: 1
recovthroughput: 1
recurrence: 1
recursive: 1
recursively: 1
redesign: 1
redirect: 1
redirected: 1
redirecting: 1
redisplaying: 1
reedsolomon: 1
referenced: 1
referring: 1
refers: 1
refines: 1
reflectsan: 1
refuse: 1
reg: 1
regenerate: 1
registering: 1
registry: 1
regularity: 1
reid: 1
reiher: 1
reimplementing: 1
relational: 1
relationship: 1
relationships: 1
relayed: 1
religion: 1
relinked: 1
remained: 1
removal: 1
ren: 1
rename: 1
rency: 1
render: 1
renderers: 1
renders: 1
rendezvous: 1
renessea: 1
renewed: 1
rently: 1
reordering: 1
replacements: 1
replicates: 1
reportedly: 1
repre: 1
reprefetch: 1
representa: 1
reproduced: 1
rescuer: 1
researcher: 1
resembles: 1
resend: 1
resetting: 1
reside: 1
resides: 1
resiliency: 1
resolves: 1
resolving: 1
resorting: 1
respected: 1
restarts: 1
restrict: 1
restructured: 1
resumed: 1
retained: 1
retaining: 1
retains: 1
rethese: 1
rethink: 1
retriev: 1
retrieving: 1
reusability: 1
reusable: 1
reuse: 1
reused: 1
revalidate: 1
revealed: 1
revealing: 1
reverts: 1
revisited: 1
revived: 1
revoked: 1
revolution: 1
rewind: 1
rexford: 1
rhee: 1
ricardo: 1
ride: 1
righteous: 1
rio: 1
rive: 1
rlogin: 1
ro: 1
roads: 1
rockell: 1
rocky: 1
rodrigues: 1
rodriguez: 1
rolig: 1
roll: 1
rollback: 1
rolled: 1
rollout: 1
room: 1
rooted: 1
roselli: 1
rotating: 1
rotations: 1
rough: 1
roundrobin: 1
roussel: 1
roy: 1
rss: 1
ru: 1
rubenstein: 1
ruichuan: 1
rush: 1
rushed: 1
rx: 1
saab: 1
sacrificing: 1
saikat: 1
saito: 1
sakoda: 1
salt: 1
sambamurthy: 1
samet: 1
sandber: 1
sankaran: 1
santa: 1
sarana: 1
sarcasm: 1
saroiu: 1
sata: 1
satpep: 1
saturated: 1
saturates: 1
saturating: 1
saturation: 1
savage: 1
saying: 1
says: 1
scaleable: 1
scarce: 1
scenarmobile: 1
scenes: 1
schedule: 1
schematic: 1
schiper: 1
schizophrenic: 1
schlosser: 1
schmidt: 1
schroeder: 1
schuh: 1
schultz: 1
sciascia: 1
scott: 1
screen: 1
screenshots: 1
scripting: 1
scripts: 1
scrutiny: 1
sdns: 1
seagate: 1
searchers: 1
searching: 1
searing: 1
sears: 1
secretly: 1
seeing: 1
seely: 1
seemed: 1
selec: 1
selection: 1
selectively: 1
selfinterested: 1
selforganizing: 1
semanticweb: 1
senses: 1
sensitivfigure: 1
sentative: 1
separating: 1
sequencing: 1
ser: 1
serialised: 1
sericola: 1
serverless: 1
servicing: 1
serving: 1
setceiver: 1
setups: 1
seven: 1
severely: 1
shacham: 1
shaded: 1
shah: 1
shahabi: 1
shalunov: 1
shao: 1
shaped: 1
shapers: 1
shapiro: 1
sharding: 1
shayee: 1
shed: 1
shelf: 1
shenghua: 1
shielding: 1
shim: 1
shipping: 1
shirriff: 1
shop: 1
shopping: 1
shoring: 1
shortcomings: 1
shorter: 1
shouldn: 1
shraer: 1
shrideep: 1
shtml: 1
shupp: 1
shutdown: 1
si: 1
sidebar: 1
siegenthaler: 1
siena: 1
sig: 1
sigkdd: 1
sigmetrics: 1
signature: 1
signed: 1
signers: 1
significance: 1
signing: 1
silberstein: 1
silently: 1
similarities: 1
similarity: 1
simon: 1
simulaneous: 1
simulates: 1
singhai: 1
sintek: 1
sishim: 1
sistencies: 1
sitaraman: 1
sits: 1
sivasubramaniam: 1
sive: 1
sjsu: 1
skepticism: 1
sky: 1
skyrocketing: 1
slash: 1
slay: 1
sleeps: 1
slide: 1
slip: 1
slowdowns: 1
sluggish: 1
smartphone: 1
smith: 1
smoothly: 1
snapshots: 1
snooping: 1
soa: 1
socc: 1
sock: 1
softway: 1
solicited: 1
solves: 1
somefound: 1
sonicmq: 1
sonicsoftware: 1
sooner: 1
sophia: 1
sorted: 1
sought: 1
spain: 1
spanningtree: 1
spans: 1
spared: 1
spawned: 1
speaking: 1
speaks: 1
speci: 1
specializes: 1
specificity: 1
specifies: 1
specifying: 1
spectrum: 1
speech: 1
spends: 1
spielman: 1
spiked: 1
spinning: 1
spirits: 1
spix: 1
splay: 1
splitx: 1
sponse: 1
sporting: 1
sports: 1
sprays: 1
spring: 1
squash: 1
squirrelmail: 1
sridharan: 1
srrs: 1
srsr: 1
ssh: 1
stabilizing: 1
stadrops: 1
stafford: 1
stand: 1
standardizing: 1
stanford: 1
stanislav: 1
stanton: 1
startup: 1
starved: 1
starving: 1
statemachine: 1
statems: 1
stationary: 1
statistic: 1
stead: 1
steen: 1
steep: 1
steer: 1
steere: 1
stepping: 1
stipulating: 1
sto: 1
stochastic: 1
stocking: 1
stodolsky: 1
stoica: 1
stor: 1
stordifferent: 1
straight: 1
street: 1
strengths: 1
stretagy: 1
strike: 1
strikes: 1
strikingly: 1
strings: 1
stripped: 1
strongest: 1
stronglytraces: 1
structuring: 1
studying: 1
stumbled: 1
stylistic: 1
suba: 1
subing: 1
subintervals: 1
subj: 1
subkilobyte: 1
submission: 1
subnetworks: 1
subordinate: 1
subramanian: 1
subscribes: 1
subscription: 1
subscriptions: 1
subsections: 1
subsequence: 1
subservicecontrol: 1
subserviceprocess: 1
substandard: 1
substitute: 1
substreams: 1
subtitles: 1
subtransactions: 1
succeeds: 1
successor: 1
sue: 1
suffix: 1
suggestive: 1
sul: 1
summarise: 1
summarised: 1
summarizes: 1
summarizing: 1
summer: 1
sunos: 1
sup: 1
superbowl: 1
superceded: 1
superfluous: 1
superimpose: 1
superior: 1
superlinearly: 1
supersede: 1
superseded: 1
supervisory: 1
supplementing: 1
supposed: 1
suppressing: 1
surely: 1
surements: 1
surge: 1
surplus: 1
surrounding: 1
surtani: 1
survivors: 1
suryanarayana: 1
suspended: 1
sussman: 1
sw: 1
swart: 1
swivel: 1
swws: 1
sympo: 1
syn: 1
synchro: 1
synchronise: 1
synchronizing: 1
systraditional: 1
szeged: 1
szymaniak: 1
tablet: 1
tag: 1
tags: 1
tailor: 1
tains: 1
talking: 1
talks: 1
tam: 1
tamma: 1
tan: 1
tance: 1
tanin: 1
tao: 1
tapped: 1
tapping: 1
tari: 1
taught: 1
tdi: 1
te: 1
technetwork: 1
technicalsessions: 1
technion: 1
technologists: 1
telecommunications: 1
telemetry: 1
templates: 1
tempt: 1
tems: 1
tency: 1
tended: 1
tension: 1
tent: 1
tentative: 1
tention: 1
terleaving: 1
terlinked: 1
terminal: 1
terminate: 1
terminated: 1
testimony: 1
textures: 1
thanks: 1
thefly: 1
ther: 1
thereafter: 1
thereby: 1
thorsten: 1
thrashing: 1
threading: 1
threetier: 1
throughputs: 1
throughxors: 1
tial: 1
tiate: 1
tib: 1
ticast: 1
ticipant: 1
ticker: 1
ticular: 1
tied: 1
tightrope: 1
timecritical: 1
timeframe: 1
timeline: 1
timers: 1
timescales: 1
timesharing: 1
timo: 1
tination: 1
tings: 1
tiple: 1
titles: 1
tity: 1
tively: 1
tivity: 1
todd: 1
todisincentivize: 1
toend: 1
toknow: 1
tokyo: 1
tolercations: 1
tom: 1
tone: 1
tons: 1
toplas: 1
topoltifiers: 1
tortures: 1
touted: 1
traceroute: 1
traf: 1
trafficshaping: 1
trailing: 1
tranasctions: 1
transactionally: 1
transactypes: 1
transcoding: 1
transformed: 1
transis: 1
transit: 1
transitional: 1
translated: 1
translates: 1
translation: 1
translators: 1
translucence: 1
transportation: 1
transporting: 1
travels: 1
treatments: 1
tri: 1
trials: 1
tricks: 1
tried: 1
trillion: 1
trim: 1
trips: 1
truncate: 1
truncated: 1
truong: 1
tsatalos: 1
ttls: 1
tude: 1
tudy: 1
tunable: 1
tung: 1
tuples: 1
turing: 1
tus: 1
tweb: 1
twelth: 1
twin: 1
twitter: 1
twotier: 1
tx: 1
txcache: 1
txn: 1
typed: 1
typwrite: 1
ual: 1
ubicomm: 1
ubiquitously: 1
ublcs: 1
uc: 1
ucb: 1
ufrgs: 1
ular: 1
ulate: 1
ultrareliable: 1
unacceptably: 1
unavoidable: 1
unbe: 1
uncertain: 1
unclustered: 1
unconstrained: 1
uncontrolled: 1
uncorrelated: 1
underdog: 1
undergo: 1
underlies: 1
underneath: 1
underperform: 1
understandable: 1
understanddevices: 1
understands: 1
understood: 1
undertake: 1
undertaken: 1
underutilisation: 1
underway: 1
undesired: 1
undisturbed: 1
unencrypted: 1
unflattering: 1
unfortunate: 1
unidirectional: 1
unifies: 1
uniformally: 1
unilaterally: 1
unintended: 1
uninterference: 1
unites: 1
univ: 1
univerisity: 1
universal: 1
universe: 1
universita: 1
unjustified: 1
unlink: 1
unlinking: 1
unmodified: 1
unnoticed: 1
unparalleled: 1
unrealistic: 1
unreasonable: 1
unrecoverable: 1
unreserved: 1
unresilient: 1
unresolved: 1
unresponsiveness: 1
unrpcs: 1
unspecified: 1
unsuitable: 1
untouched: 1
unusually: 1
unwilling: 1
upare: 1
upcalls: 1
upcan: 1
upcations: 1
upcoming: 1
upgrade: 1
upgrades: 1
upisting: 1
uploads: 1
upreader: 1
upson: 1
upstudies: 1
upthe: 1
upwidth: 1
ures: 1
urgently: 1
url: 1
urls: 1
usages: 1
usdoj: 1
usefully: 1
usermakes: 1
uservisible: 1
utilising: 1
utilized: 1
utilizes: 1
utilizing: 1
utrsut: 1
utt: 1
uture: 1
uut: 1
uutt: 1
validations: 1
vanilla: 1
vanishes: 1
var: 1
variances: 1
vasilatos: 1
vb: 1
vectored: 1
vehicles: 1
veitch: 1
velenis: 1
venkataraman: 1
vercurr: 1
verification: 1
versa: 1
vertical: 1
victims: 1
videos: 1
vidhyashankar: 1
viding: 1
viewer: 1
viewsynchronous: 1
violated: 1
violates: 1
viral: 1
vironment: 1
virtually: 1
virtue: 1
vishnumurthy: 1
visibly: 1
vision: 1
visit: 1
visiting: 1
vista: 1
visualize: 1
visualizing: 1
vital: 1
vivek: 1
vlo: 1
vmm: 1
vms: 1
voelker: 1
vogel: 1
voip: 1
vollset: 1
voluntary: 1
vrable: 1
wa: 1
waived: 1
wallach: 1
wans: 1
warp: 1
wasn: 1
wasteful: 1
wastes: 1
wasting: 1
watches: 1
wave: 1
wcnc: 1
weaken: 1
weakness: 1
webfs: 1
weblogs: 1
webtier: 1
weeks: 1
weighed: 1
welldefined: 1
weng: 1
wes: 1
westerlund: 1
wg: 1
whatsnew: 1
whatsoever: 1
wheeler: 1
whereupon: 1
whiteboard: 1
whitepaper: 1
whithout: 1
wholefile: 1
wicom: 1
widens: 1
wieloch: 1
wilma: 1
windowsnt: 1
winnie: 1
wires: 1
withuated: 1
witnesses: 1
wolf: 1
wonder: 1
woo: 1
woodford: 1
worker: 1
worries: 1
worrisome: 1
worthwhile: 1
wouldn: 1
wrapped: 1
wraps: 1
writclassification: 1
writeaccesses: 1
writeinvalidations: 1
writequirement: 1
writeserver: 1
writetive: 1
writewrite: 1
wrote: 1
wscompatible: 1
wsdl: 1
wspds: 1
wstransactions: 1
wu: 1
xaxis: 1
xcp: 1
xiao: 1
xisting: 1
xperimental: 1
xu: 1
xyx: 1
yaghmazadeh: 1
yann: 1
yaxes: 1
yee: 1
yielded: 1
yin: 1
ylianttila: 1
youtube: 1
yuanchao: 1
yuanyuan: 1
yum: 1
yushprakh: 1
zahorjan: 1
zdonik: 1
zeal: 1
zealous: 1
zelenka: 1
zephyr: 1
zettabyte: 1
zhen: 1
zhenqi: 1
zhou: 1
zhuang: 1
zoomed: 1
zooming: 1
zooms: 1
zou: 1
zuck: 1
zwilling: 1
