web technologies can web
technologies can web services
can web services scale
web services scale up
cornell university i n
university i n the
i n the past
only major internet players
major internet players such
internet players such as
players such as amazon
implementing high performance multicast
high performance multicast in
and google were interested
performance multicast in a
google were interested in
multicast in a managed
were interested in deploying
in a managed environment
interested in deploying large
a managed environment krzysztof
managed environment krzysztof ostrowski
environment krzysztof ostrowski cornell
krzysztof ostrowski cornell university
ostrowski cornell university ken
cornell university ken birman
university ken birman cornell
ken birman cornell university
birman cornell university abstract
cornell university abstract motes
university abstract motes end
this is changing rapidly
is changing rapidly all
transparent error correction for
changing rapidly all sorts
an adaptive distributed file
user application development using
rapidly all sorts of
adaptive distributed file system
application development using c
all sorts of companies
error correction for communication
distributed file system for
sorts of companies and
file system for mobile
correction for communication between
system for mobile hosts
of companies and governmental
for mobile hosts benjamin
for communication between data
companies and governmental organizations
communication between data centers
mobile hosts benjamin atkin
between data centers mahesh
hosts benjamin atkin and
data centers mahesh balakrishnan
benjamin atkin and kenneth
and governmental organizations are
atkin and kenneth p
governmental organizations are suddenly
the company s own
organizations are suddenly looking
company s own products
are suddenly looking towards
s own products are
suddenly looking towards web
own products are still
products are still implemented
looking towards web services
are still implemented primarily
towards web services as
still implemented primarily in
birman department of computer
implemented primarily in unmanaged
web services as a
primarily in unmanaged c
department of computer science
services as a platform
of computer science cornell
as a platform that
computer science cornell university
a platform that might
platform that might support
that might support a
might support a wide
support a wide range
a wide range of
wide range of demanding
range of demanding applications
by building xyx in
building xyx in the
xyx in the recommended
in the recommended manner
examples of such systems
of such systems include
such systems include big
systems include big banking
we found ourselves breaking
include big banking and
found ourselves breaking new
big banking and brokerage
ourselves breaking new ground
banking and brokerage data
and brokerage data centers
edu abstract mfs using
abstract mfs using file
the multicast protocols employed
mfs using file access
online service centers for
using file access traces
service centers for companies
file access traces from
multicast protocols employed by
access traces from windows
centers for companies that
traces from windows nt
protocols employed by qsm
from windows nt and
for companies that operate
windows nt and unix
employed by qsm were
companies that operate on
by qsm were designed
that operate on a
qsm were designed for
operate on a global
were designed for performance
on a global scale
designed for performance and
and a synthetic workload
for performance and scalability
a synthetic workload designed
synthetic workload designed to
workload designed to emulate
systems to operate critical
designed to emulate sharing
incorporating a mixture of
to operate critical infrastructures
a mixture of new
to emulate sharing patterns
mixture of new ideas
operate critical infrastructures like
emulate sharing patterns seen
of new ideas and
critical infrastructures like electric
new ideas and ideas
sharing patterns seen in
ideas and ideas drawn
infrastructures like electric power
and ideas drawn from
patterns seen in mobility
ideas drawn from prior
like electric power and
drawn from prior systems
seen in mobility is
electric power and transportation
in mobility is a
mobility is a critical
is a critical feature
a critical feature of
critical feature of computer
feature of computer systems
and government and military
government and military systems
the aspects on which
and military systems responsible
aspects on which we
abstract the global network
military systems responsible for
and while collaborative engineering
on which we focus
systems responsible for everything
while collaborative engineering systems
the global network of
which we focus here
responsible for everything from
we focus here reflect
global network of data
focus here reflect architectural
for everything from intelligence
here reflect architectural responses
everything from intelligence gathering
reflect architectural responses to
from intelligence gathering to
architectural responses to scheduling
network of data centers
responses to scheduling delays
intelligence gathering to issuing
of data centers is
wireless networks are common
gathering to issuing social
data centers is emerging
to issuing social security
centers is emerging as
issuing social security checks
is emerging as an
overheads associated with threads
emerging as an important
most applications that run
as an important distributed
applications that run on
an important distributed systems
this emerging trend presents
that run on existing
emerging trend presents developers
and costs arising in
run on existing work
trend presents developers with
important distributed systems paradigm
presents developers with a
on existing work in
distributed systems paradigm commodity
developers with a new
existing work in cache
with a new challenge
costs arising in the
work in cache management
systems paradigm commodity clusters
arising in the memory
paradigm commodity clusters running
in the memory management
commodity clusters running high
the memory management subsystem
building web services solutions
in cache management for
web services solutions that
cache management for mobile
services solutions that scale
management for mobile file
for mobile file systems
over the period during
mobile file systems mobile
the period during which
file systems mobile hosts
period during which qsm
systems mobile hosts lack
during which qsm was
mobile hosts lack flexible
which qsm was developed
hosts lack flexible mechanisms
a scalable system is
lack flexible mechanisms for
speed lambda networks across
scalable system is one
lambda networks across hundreds
flexible mechanisms for data
networks across hundreds of
mechanisms for data access
system is one that
for data access in
across hundreds of milliseconds
data access in an
hundreds of milliseconds of
access in an en
is one that can
of milliseconds of network
one that can flexibly
milliseconds of network latency
that can flexibly accommodate
these had pervasive consequences
can flexibly accommodate growth
flexibly accommodate growth in
accommodate growth in its
packet loss on long
growth in its client
in its client base
forcing us to redesign
us to redesign and
to redesign and recode
redesign and recode one
haul networks can cripple
and recode one layer
networks can cripple the
such systems typically run
recode one layer of
can cripple the performance
systems typically run on
one layer of the
cripple the performance of
typically run on a
layer of the system
the performance of applications
run on a clustered
of the system after
performance of applications and
on a clustered computer
the system after another
of applications and protocols
a clustered computer or
applications and protocols a
clustered computer or in
and protocols a loss
computer or in a
protocols a loss rate
or in a large
a loss rate as
in a large data
loss rate as low
a large data center
rate as low as
large data center and
the original system was
data center and must
original system was multithreaded
center and must be
and must be able
must be able to
be able to handle
able to handle high
to handle high loads
handle high loads or
high loads or sudden
o calls and was
loads or sudden demand
calls and was rather
or sudden demand bursts
and was rather casual
sudden demand bursts and
was rather casual about
demand bursts and a
rather casual about buffering
bursts and a vast
casual about buffering and
is sufficient to reduce
about buffering and caching
and a vast number
incorporates mechanisms for making
a vast number of
sufficient to reduce tcp
mechanisms for making efficient
vast number of users
for making efficient vironment
the current system is
making efficient vironment with
current system is single
efficient vironment with large
ip throughput by an
vironment with large and
throughput by an order
with large and frequent
by an order of
large and frequent variations
an order of magnitude
and frequent variations in
order of magnitude on
they must reliably respond
of magnitude on a
frequent variations in network
must reliably respond even
variations in network connec
reliably respond even in
respond even in the
even in the event
in the event of
the event of failures
use of available bandwidth
event of failures or
of failures or reconfiguration
and obsessively minimizes memory
obsessively minimizes memory consumption
it has mostly focused
has mostly focused on
mostly focused on tivity
maelstrom is an edge
is an edge appliance
managed and automate as
an edge appliance that
and automate as many
edge appliance that masks
automate as many routine
appliance that masks packet
as many routine services
that masks packet loss
performs well and is
many routine services such
well and is stable
masks packet loss transparently
and is stable at
routine services such as
is stable at high
in collaborative work adapting
services such as backups
stable at high data
collaborative work adapting existing
such as backups and
packet loss transparently and
as backups and component
work adapting existing systems
backups and component upgrades
loss transparently and quickly
and component upgrades as
adapting existing systems to
component upgrades as possible
transparently and quickly from
at high data rates
and quickly from inter
existing systems to cope
systems to cope with
to cope with periods
cope with periods of
many settings also require
with periods of low
large scale and under
periods of low bandwidth
scale and under stress
settings also require security
also require security against
require security against attempted
aggregating traffic for high
security against attempted intrusions
against attempted intrusions and
the finished system achieves
attempted intrusions and distributed
finished system achieves extremely
intrusions and distributed denial
system achieves extremely high
speed encoding and using
particularly when wireless and
achieves extremely high performance
encoding and using a
when wireless and wired
extremely high performance with
and using a new
wireless and wired users
using a new forward
high performance with relatively
a new forward error
performance with relatively modest
new forward error correction
with relatively modest cpu
and wired users share
forward error correction scheme
relatively modest cpu and
error correction scheme to
modest cpu and memory
wired users share in
cpu and memory loads
correction scheme to handle
users share in a
scheme to handle bursty
share in a style
to handle bursty loss
in a style which
a style which we
style which we will
although our paper is
which we will refer
our paper is not
we will refer to
paper is not about
will refer to as
is not about setting
refer to as modal
not about setting performance
to as modal adaptation
about setting performance records
setting performance records the
performance records the absolute
records the absolute numbers
the absolute numbers are
absolute numbers are good
when files or databases
qsm outperforms the multicast
the second builds on
outperforms the multicast platforms
second builds on the
the multicast platforms we
builds on the first
multicast platforms we ve
on the first and
we describe some techniques
the first and supports
platforms we ve worked
describe some techniques bandwidth
first and supports a
some techniques bandwidth is
we ve worked with
techniques bandwidth is high
and supports a way
ve worked with in
supports a way to
worked with in the
a way to build
with in the past
way to build scripts
in the past systems
to build scripts of
the past systems that
build scripts of simpler
past systems that run
the application communicates normally
systems that run in
scripts of simpler transactions
that run in unmanaged
run in unmanaged settings
when for adapting data
for adapting data access
this paper won t
some might argue that
paper won t tell
adapting data access to
might argue that all
i ntroduction t a
argue that all reliability
data access to network
that all reliability needs
ntroduction t a conference
all reliability needs can
access to network variability
reliability needs can be
t a conference version
needs can be recast
won t tell the
to network variability in
t tell the blow
can be recast in
network variability in the
be recast in terms
a conference version of
recast in terms of
variability in the context
conference version of this
in terms of transactions
version of this paper
in the context of
of this paper appeared
this paper appeared in
the context of bandwidth
paper appeared in nsdi
context of bandwidth falls
of bandwidth falls below
bandwidth falls below a
falls below a threshold
the past three decades
we use qsm in
past three decades have
use qsm in a
three decades have seen
qsm in a series
decades have seen one
in a series of
have seen one failed
a series of experiments
seen one failed attempt
series of experiments that
the application enters a
one failed attempt after
application enters a lowmfs
failed attempt after another
of experiments that highlight
attempt after another to
experiments that highlight fundamental
after another to build
that highlight fundamental factors
another to build everything
to build everything over
fifth usenix symposium on
build everything over a
usenix symposium on networked
everything over a database
symposium on networked systems
over a database system
these reveal linkages between
a client cache manager
reveal linkages between achievable
on networked systems design
client cache manager for
networked systems design and
linkages between achievable performance
and it s now
cache manager for a
it s now clear
between achievable performance and
s now clear that
achievable performance and the
now clear that many
performance and the costs
clear that many kinds
and the costs and
that many kinds of
the costs and characteristics
many kinds of systems
costs and characteristics of
systems design and implementation
and characteristics of the
kinds of systems just
characteristics of the managed
of systems just don
of the managed framework
systems just don t
manager for a distributed
just don t match
for a distributed file
don t match the
a distributed file system
doing so sheds light
t match the model
so sheds light on
sheds light on the
light on the challenges
on the challenges of
these intrinsically distributed systems
the challenges of working
we bandwidth mode in
intrinsically distributed systems make
challenges of working in
bandwidth mode in which
of working in a
distributed systems make use
working in a kind
systems make use of
mode in which communication
in a kind of
make use of direct
a kind of environment
use of direct communication
in which communication is
of direct communication between
kind of environment that
direct communication between programs
of environment that will
communication between programs via
environment that will be
between programs via the
that will be more
programs via the trans
which communication is restricted
ms index terms data
will be more and
communication is restricted or
be more and more
index terms data centers
more and more prevalent
current web services standards
and more prevalent in
web services standards have
more prevalent in years
services standards have many
prevalent in years to
standards have many critical
in years to come
have many critical limitations
is restricted or deshow
restricted or deshow how
or deshow how mfs
our insights should be
deshow how mfs is
insights should be of
how mfs is able
today s web services
should be of value
s web services standards
be of value to
web services standards seem
of value to developers
services standards seem to
value to developers of
standards seem to answer
to developers of other
seem to answer these
developers of other high
to answer these needs
he emergence of commodity
mfs is able to
emergence of commodity clusters
is able to adapt
of commodity clusters and
able to adapt to
performance communication and event
commodity clusters and data
to adapt to widely
clusters and data centers
adapt to widely varying
a more probing analysis
and data centers has
more probing analysis reveals
to widely varying bandwidth
data centers has enabled
probing analysis reveals many
widely varying bandwidth ferred
centers has enabled a
analysis reveals many critical
has enabled a new
reveals many critical limitations
enabled a new class
a new class of
new class of globally
class of globally distributed
of globally distributed highperformance
globally distributed highperformance applications
we propose a new
distributed highperformance applications that
propose a new positioning
highperformance applications that coordinate
a new positioning of
applications that coordinate over
the major web services
that coordinate over vast
major web services standards
coordinate over vast geographical
web services standards dealing
an application has a
services standards dealing with
over vast geographical distances
standards dealing with reliability
application has a small
new positioning of multicast
has a small number
positioning of multicast technology
a small number of
small number of levels
number of levels through
as an extension of
of levels through the
an extension of the
a financial firm s
levels through the use
financial firm s new
through the use of
extension of the component
firm s new york
of the component integration
s new york city
the component integration features
new york city data
component integration features of
york city data center
integration features of the
city data center may
features of the microsoft
data center may receive
reliability provides for reliable
center may receive real
the use of modeless
provides for reliable handoff
use of modeless adaptation
net managed runtime environment
for reliable handoff between
reliable handoff between a
time updates from a
handoff between a client
updates from a stock
between a client system
from a stock exchange
a client system and
a stock exchange in
client system and a
stock exchange in switzerland
and evaluate the possible
system and a queuing
and a queuing system
evaluate the possible modes
a queuing system residing
although we started with
the possible modes and
we started with a
conduct financial transactions with
started with a sophisticated
possible modes and chooses
with a sophisticated multicast
financial transactions with banks
a sophisticated multicast protocol
modes and chooses the
queuing system residing between
transactions with banks in
system residing between the
with banks in asia
residing between the client
and chooses the appropriate
experiments reveal a series
between the client and
reveal a series of
chooses the appropriate one
a series of problematic
the client and some
series of problematic interactions
cache data in london
of problematic interactions between
client and some service
problematic interactions between its
data in london for
interactions between its high
the appropriate one based
in london for locality
london for locality and
appropriate one based on
for locality and mirror
one based on the
locality and mirror it
based on the benefit
and mirror it to
the standard isn t
processing logic and the
standard isn t nearly
logic and the properties
isn t nearly as
and the properties of
t nearly as comprehensive
the properties of the
nearly as comprehensive as
mirror it to kansas
as comprehensive as the
on the benefit of
comprehensive as the name
it to kansas for
the benefit of mechanisms
to kansas for disaster
properties of the managed
as the name implies
of the managed framework
benefit of mechanisms for
of mechanisms for improving
mechanisms for improving file
for improving file system
improving file system performance
to interconnect these bandwidth
it s limited to
file system performance currently
s limited to pipelines
system performance currently available
limited to pipelines that
performance currently available bandwidth
hungry data centers across
to pipelines that include
data centers across the
pipelines that include queuing
centers across the globe
that include queuing subsystems
we addressed these and
addressed these and achieved
these and achieved high
and achieved high performance
achieved high performance by
organizations are increasingly deploying
high performance by making
are increasingly deploying private
performance by making some
increasingly deploying private lambda
by making some unusual
deploying private lambda networks
in the coda file
making some unusual architectural
reliability boils down to
some unusual architectural decisions
the coda file and
boils down to a
coda file and cache
down to a few
raw bandwidth is ubiquitous
to a few options
file and cache consistency
a few options that
bandwidth is ubiquitous and
and cache consistency using
is ubiquitous and cheaply
few options that a
cache consistency using microbenchmarks
which we distill into
ubiquitous and cheaply available
we distill into general
consistency using microbenchmarks and
options that a client
and cheaply available in
distill into general insights
cheaply available in the
that a client can
available in the form
using microbenchmarks and file
in the form of
a client can use
the form of existing
microbenchmarks and file system
form of existing dark
client can use to
of existing dark fiber
and file system system
component integration environments such
can use to tell
integration environments such as
use to tell the
environments such as microsoft
to tell the queuing
tell the queuing system
the queuing system whether
queuing system whether or
system whether or not
running and maintaining high
whether or not to
or not to reissue
not to reissue a
to reissue a request
ee have become widely
reissue a request if
have become widely popular
a request if a
become widely popular with
request if a failure
widely popular with application
if a failure occurs
popular with application developers
free networks over this
networks over this fiber
over this fiber is
this fiber is difficult
fiber is difficult and
and a way to
is difficult and expensive
who benefit from standardized
a way to timestamp
benefit from standardized memory
way to timestamp requests
from standardized memory management
to timestamp requests so
timestamp requests so that
requests so that a
so that a service
the cache manager operates
that a service can
cache manager operates in
a service can detect
capacity optical links are
service can detect duplicates
manager operates in either
optical links are almost
operates in either a
links are almost never
in either a stronglytraces
are almost never congested
transactions actually consists of
and performance analysis tools
actually consists of two
they drop packets for
performance analysis tools that
drop packets for numerous
analysis tools that operate
packets for numerous reasons
consists of two side
for numerous reasons dirty
tools that operate across
that operate across component
operate across component boundaries
this paper describes quicksilver
paper describes quicksilver scalable
describes quicksilver scalable multicast
one is aimed at
is aimed at applications
aimed at applications that
at applications that perform
applications that perform database
that perform database transactions
perform database transactions with
database transactions with the
transactions with the usual
with the usual acid
which affects the policy
affects the policy for
the policy for writing
a new multicast platform
policy for writing changes
new multicast platform designed
for writing changes to
multicast platform designed to
writing changes to files
platform designed to achieve
changes to files back
designed to achieve high
to files back to
to achieve high performance
files back to the
achieve high performance in
back to the server
high performance in managed
performance in managed environments
memoryrelated overheads and phenomena
modal adaptation schemes are
overheads and phenomena related
adaptation schemes are well
and phenomena related to
phenomena related to scheduling
or the remote procedure
related to scheduling are
the remote procedure call
to scheduling are shown
remote procedure call and
scheduling are shown to
procedure call and that
are shown to dominate
call and that can
shown to dominate the
and that can t
to dominate the behavior
that can t tolerate
dominate the behavior of
can t tolerate delay
the behavior of the
behavior of the system
introduction in which changes
these systems lack databases
in which changes in
systems lack databases clean
we discuss techniques that
lack databases clean separation
discuss techniques that helped
databases clean separation of
techniques that helped us
clean separation of stored
that helped us to
which changes in bandwidth
separation of stored data
helped us to alleviate
of stored data from
us to alleviate these
stored data from code
for example and in
changes in bandwidth are
example and in different
to alleviate these problems
and in different patterns
in bandwidth are relatively
bandwidth are relatively predictable
and any attempt to
any attempt to force
and argue that they
attempt to force them
ranging from singleton drops
to force them into
argue that they reveal
force them into that
from singleton drops to
them into that model
that they reveal general
into that model results
such as switching network
that model results in
singleton drops to extended
they reveal general principles
model results in unacceptable
reveal general principles applicable
results in unacceptable loss
general principles applicable to
in unacceptable loss of
principles applicable to other
unacceptable loss of performance
applicable to other kinds
drops to extended bursts
as switching network access
to other kinds of
switching network access from
other kinds of high
intrinsically distributed systems are
network access from an
distributed systems are common
access from an ethernet
from an ethernet to
an ethernet to a
ethernet to a modem
and web services will
web services will need
rate protocols and applications
services will need to
protocols and applications in
will need to support
and applications in managed
need to support them
applications in managed settings
but mobility is now
mobility is now an
is now an major
now an major feature
an major feature of
the existing reliability options
major feature of computer
introduction a component integration
feature of computer systems
a component integration revolution
existing reliability options simply
component integration revolution is
reliability options simply don
integration revolution is transforming
options simply don t
revolution is transforming the
simply don t address
is transforming the development
don t address the
transforming the development of
t address the requirement
over the not as
noncongestion loss has been
the development of desktop
loss has been observed
development of desktop applications
has been observed on
the not as appropriate
been observed on long
a lesson from the
not as appropriate in
lesson from the past
platforms such as windows
from the past what
as appropriate in for
the past what sorts
haul networks as well
appropriate in for wireless
past what sorts of
in for wireless networks
what sorts of scaling
sorts of scaling and
of scaling and reliability
scaling and reliability features
ee promote an application
and reliability features are
promote an application development
reliability features are lacking
an application development style
features are lacking in
in which bandwidth past
application development style in
are lacking in web
development style in which
lacking in web services
which bandwidth past decade
in web services standards
style in which components
web services standards today
in which components are
which components are implemented
components are implemented independently
are implemented independently and
implemented independently and heavily
a good example is
independently and heavily reused
good example is data
example is data replication
held devices capable of
building a server that
a server that scales
devices capable of wireless
server that scales to
by standardizing memory management
that scales to handle
standardizing memory management and
capable of wireless availability
scales to handle load
memory management and type
to handle load often
of wireless availability is
handle load often requires
management and type checking
load often requires replicating
wireless availability is less
often requires replicating data
requires replicating data on
availability is less predictable
replicating data on multiple
these platforms enable safe
is less predictable and
data on multiple nodes
platforms enable safe and
less predictable and varies
enable safe and efficient
on multiple nodes of
predictable and varies over
multiple nodes of a
safe and efficient cross
nodes of a cluster
and varies over a
varies over a larger
over a larger possible
a larger possible network
larger possible network access
avoiding overheads associated with
another example is guaranteed
possible network access have
overheads associated with protection
network access have become
example is guaranteed real
access have become common
associated with protection boundaries
and wireless networks are
a company that buys
wireless networks are range
company that buys a
the inadequacy of commodity
that buys a cluster
inadequacy of commodity tcp
buys a cluster probably
a cluster probably wants
cluster probably wants to
probably wants to guarantee
ip in high bandwidthdelay
the notion of insufficient
in high bandwidthdelay product
wants to guarantee that
notion of insufficient bandwidth
high bandwidthdelay product networks
our project is interested
bandwidthdelay product networks is
of insufficient bandwidth can
to guarantee that some
project is interested in
product networks is extensively
insufficient bandwidth can vary
guarantee that some service
is interested in leveraging
networks is extensively documented
bandwidth can vary dependalso
that some service will
interested in leveraging these
some service will be
can vary dependalso proliferating
service will be responsive
in leveraging these benefits
will be responsive enough
leveraging these benefits to
be responsive enough to
these benefits to help
responsive enough to keep
benefits to help developers
enough to keep its
to help developers implement
to keep its customers
help developers implement robust
applications that run on
keep its customers happy
developers implement robust and
its customers happy even
that run on hosts
customers happy even when
implement robust and scalable
run on hosts in
happy even when demand
robust and scalable computing
even when demand is
on hosts in wireless
and scalable computing services
when demand is high
hosts in wireless neting
scalable computing services that
in wireless neting on
computing services that will
wireless neting on how
services that will run
the missing technologies don
that will run on
neting on how much
will run on clusters
missing technologies don t
run on clusters or
technologies don t stop
on clusters or in
don t stop there
clusters or in datacenters
on how much data
how much data the
much data the application
data the application is
early users of our
the application is trying
users of our platform
application is trying to
of our platform are
cycle services that can
our platform are creating
services that can launch
is trying to send
that can launch an
platform are creating applications
can launch an application
are creating applications in
launch an application on
creating applications in areas
an application on demand
applications in areas such
application on demand or
in areas such as
on demand or restart
areas such as parallelized
demand or restart a
such as parallelized data
or restart a failed
as parallelized data mining
ip has three major
so that works must
restart a failed component
has three major problems
that works must cope
event stream filtering software
three major problems when
works must cope with
major problems when used
or load balancers and
problems when used over
and scalable web services
when used over such
load balancers and technology
used over such networks
must cope with constraints
balancers and technology to
and technology to automate
cope with constraints on
technology to automate management
developers of clustered services
to automate management of
of clustered services need
automate management of a
clustered services need reliable
management of a machine
services need reliable multicast
of a machine cluster
need reliable multicast protocols
a machine cluster running
reliable multicast protocols for
machine cluster running web
multicast protocols for data
ip suffers throughput collapse
protocols for data replication
suffers throughput collapse if
cluster running web services
throughput collapse if the
running web services applications
collapse if the network
with constraints on access
if the network is
and in light of
the network is even
constraints on access to
in light of our
network is even slightly
on access to data
light of our broader
is even slightly prone
access to data that
of our broader goal
even slightly prone to
working groups within the
to data that are
groups within the world
slightly prone to packet
our broader goal of
prone to packet loss
data that are genit
within the world wide
broader goal of leveraging
the world wide web
that are genit may
goal of leveraging the
world wide web consortium
of leveraging the power
are genit may make
leveraging the power and
conservative flow control mechanisms
the power and component
genit may make sense
power and component integration
flow control mechanisms designed
and component integration features
may make sense to
control mechanisms designed to
component integration features of
mechanisms designed to deal
integration features of a
designed to deal with
features of a managed
make sense to adjust
of a managed framework
to deal with the
sense to adjust network
deal with the systematic
to adjust network usage
with the systematic congestion
adjust network usage when
the systematic congestion of
the multicast technology must
systematic congestion of the
multicast technology must run
congestion of the commodity
technology must run in
the primary organization developing
network usage when the
must run in a
usage when the bandwidth
primary organization developing web
when the bandwidth erally
run in a managed
of the commodity internet
organization developing web services
the commodity internet react
developing web services standards
commodity internet react too
in a managed setting
internet react too sharply
the bandwidth erally not
react too sharply to
bandwidth erally not present
erally not present in
but little is known
not present in wired
little is known about
not one is addressing
is known about highperformance
one is addressing these
known about highperformance protocols
is addressing these kinds
about highperformance protocols in
addressing these kinds of
present in wired networks
highperformance protocols in managed
these kinds of issues
protocols in managed environments
a similar dynamic played
it is interesting to
similar dynamic played out
is interesting to realize
distance from a base
interesting to realize that
dynamic played out in
to realize that although
played out in the
realize that although microsoft
out in the early
that although microsoft pro
from a base stadrops
ms w n s
a base stadrops by
w n s e
base stadrops by half
n s e fig
this research was supported
research was supported by
was supported by afrl
rather than just when
if with additional support
than just when it
with additional support from
just when it falls
additional support from afosr
when it falls to
it falls to modem
example lambda network ephemeral
lambda network ephemeral loss
network ephemeral loss on
server computing was touted
ephemeral loss on over
computing was touted as
was touted as the
touted as the next
as the next big
the next big thing
provisioned links a single
links a single packet
a single packet in
single packet in ten
a silver bullet to
packet in ten thousand
silver bullet to solve
in ten thousand is
bullet to solve every
ten thousand is enough
to solve every problem
thousand is enough to
contention with other hosts
solve every problem related
with other hosts or
every problem related to
is enough to reduce
problem related to older
enough to reduce tcp
related to older mainframe
other hosts or processes
department of computer science
to older mainframe and
hosts or processes on
older mainframe and batch
ip throughput to a
mainframe and batch systems
or processes on the
throughput to a third
processes on the same
to a third over
on the same host
a third over a
companies rushed to move
rushed to move everything
to move everything from
move everything from mainframe
everything from mainframe settings
from mainframe settings to
mainframe settings to client
selecting a mode according
a mode according to
mode according to the
according to the available
to the available bandwidth
and one in a
the available bandwidth can
one in a thousand
available bandwidth can uninterference
in a thousand drops
there were notable successes
a thousand drops it
thousand drops it by
drops it by an
it by an order
by an order of
an order of magnitude
but it quickly became
and switching between different
it quickly became apparent
switching between different wireless
quickly became apparent that
between different wireless media
became apparent that the
different wireless media all
apparent that the early
wireless media all necessarily
that the early platforms
media all necessarily constrain
the early platforms were
all necessarily constrain communication
early platforms were strikingly
time or interactive applications
platforms were strikingly immature
or interactive applications are
interactive applications are impacted
applications are impacted by
are impacted by the
processes needed to be
impacted by the reliance
needed to be automated
since it ignores what
to be automated and
by the reliance of
be automated and standardized
the reliance of reliability
it ignores what data
reliance of reliability mechanisms
of reliability mechanisms on
ignores what data compound
reliability mechanisms on acknowledgments
and the early generations
mechanisms on acknowledgments and
the early generations of
what data compound the
on acknowledgments and retransmissions
early generations of client
data compound the variability
compound the variability in
the variability in network
limiting the latency of
server systems cost a
variability in network performance
the latency of packet
systems cost a fortune
latency of packet recovery
cost a fortune to
of packet recovery to
in network performance to
packet recovery to at
a fortune to build
recovery to at least
network performance to which
the embedding of qsm
to at least the
embedding of qsm into
performance to which apthe
of qsm into windows
at least the round
to which apthe application
least the round trip
qsm into windows yielded
which apthe application actually
required armies of systems
into windows yielded an
armies of systems administrators
windows yielded an unexpected
of systems administrators and
yielded an unexpected benefit
systems administrators and specialists
apthe application actually wants
the round trip time
application actually wants to
actually wants to send
it enables what we
and were extremely insecure
enables what we are
wants to send over
what we are calling
to send over the
we are calling live
send over the network
are calling live distributed
the total cost of
calling live distributed objects
total cost of ownership
cost of ownership proved
of ownership proved to
if delivery is sequenced
ownership proved to be
as the term suggests
proved to be unexpectedly
deferplications must adapt if
to be unexpectedly and
must adapt if they
be unexpectedly and unacceptably
adapt if they are
these are abstract data
if they are to
are abstract data types
unexpectedly and unacceptably high
they are to perform
abstract data types in
are to perform well
data types in which
each lost packet acts
types in which content
lost packet acts as
in which content evolves
packet acts as a
which content evolves over
acts as a virtual
content evolves over time
as a virtual road
the lesson of the
lesson of the client
ring writing back all
when an application binds
writing back all modifications
block in the fifo
an application binds to
in the fifo channel
application binds to a
the fifo channel until
binds to a live
fifo channel until it
server era is that
back all modifications to
to a live object
channel until it is
era is that incomplete
until it is recovered
all modifications to files
is that incomplete platforms
that incomplete platforms can
modifications to files may
the current state of
incomplete platforms can t
current state of the
to files may not
state of the object
platforms can t support
of the object is
can t support major
the object is imported
files may not be
object is imported and
ip requires massive buffers
is imported and the
may not be a
imported and the object
requires massive buffers at
and the object can
massive buffers at the
the object can send
not be a sensible
buffers at the communicating
object can send and
be a sensible this
can send and receive
my concern is that
send and receive updates
at the communicating endhosts
a sensible this paper
the communicating endhosts to
and receive updates at
communicating endhosts to fully
receive updates at high
concern is that the
sensible this paper focuses
is that the web
updates at high data
that the web services
at high data rates
the web services community
endhosts to fully exploit
web services community is
to fully exploit the
services community is about
fully exploit the bandwidth
community is about to
an object could be
this paper focuses on
object could be a
exploit the bandwidth of
could be a place
the bandwidth of a
be a place in
bandwidth of a long
a place in a
paper focuses on adaptation
is about to face
place in a game
about to face the
in a game like
to face the same
a game like second
face the same problem
game like second life
focuses on adaptation techniques
on adaptation techniques for
even in the absence
platform developers are racing
in the absence of
developers are racing forward
adaptation techniques for management
are racing forward at
the absence of packet
techniques for management policy
absence of packet loss
racing forward at top
for management policy if
forward at top speed
management policy if those
policy if those are
if those are the
jostling for position with
those are the only
for position with ever
are the only messages
resistant alternatives to tcp
the only messages available
position with ever more
only messages available to
with ever more exaggerated
live objects are a
ever more exaggerated claims
objects are a natural
messages available to send
ip is not feasible
are a natural and
is not feasible in
a natural and powerful
not feasible in corporate
while closing their eyes
feasible in corporate data
natural and powerful idea
in corporate data centers
closing their eyes to
their eyes to the
eyes to the dangerous
to the dangerous potholes
of data accessed and
and we plan to
the dangerous potholes in
where standardization is the
data accessed and modified
we plan to pursue
accessed and modified by
plan to pursue the
dangerous potholes in the
to pursue the concept
potholes in the road
pursue the concept in
in the road ahead
the concept in future
and modified by mobile
standardization is the key
modified by mobile hosts
is the key to
concept in future work
the key to low
architectural standards for scalability
key to low and
standards for scalability to
to low and predictable
for scalability to properly
low and predictable maintenance
scalability to properly address
and predictable maintenance costs
we investigate we describe
to properly address scalability
investigate we describe mfs
this use of qsm
properly address scalability in
use of qsm raises
address scalability in web
of qsm raises performance
scalability in web services
qsm raises performance and
neither is eliminating loss
raises performance and scalability
is eliminating loss events
performance and scalability issues
eliminating loss events on
and scalability issues beyond
loss events on a
scalability issues beyond the
events on a network
issues beyond the ones
on a network that
beyond the ones seen
a network that could
the ones seen in
we need more than
ones seen in our
network that could span
seen in our original
need more than a
in our original target
that could span thousands
our original target domain
a flexible cache adaptation
more than a long
could span thousands of
than a long list
span thousands of miles
a long list of
flexible cache adaptation in
long list of reliability
cache adaptation in the
list of reliability and
adaptation in the context
we leave detailed discussion
in the context of
leave detailed discussion of
the context of mfs
detailed discussion of the
of reliability and management
discussion of the idea
reliability and management standards
of the idea for
there is a need
the idea for the
is a need to
idea for the future
a need to mask
a client cache manager
we need a new
need to mask loss
need a new methodology
to mask loss on
a new methodology suitable
qsm has been available
new methodology suitable for
has been available for
methodology suitable for supporting
been available for free
suitable for supporting a
available for free download
for supporting a scalable
for free download since
supporting a scalable data
free download since mid
a scalable data center
mask loss on the
client cache manager for
scalable data center architecture
loss on the link
cache manager for a
on the link from
manager for a manager
the link from the
for a manager for
link from the commodity
a manager for a
from the commodity protocols
manager for a distributed
the commodity protocols running
for a distributed file
commodity protocols running at
a distributed file system
protocols running at end
distributed file system client
and it has a
it has a number
which differs from distributed
and to do so
has a number of
to do so rapidly
a number of users
do so rapidly and
along with pat helland
so rapidly and transparently
with pat helland and
differs from distributed file
pat helland and dennis
most working on clustered
helland and dennis shasha
working on clustered computing
from distributed file system
because recovery delays for
recovery delays for lost
delays for lost packets
recommends that developers think
for lost packets translate
we concentrate on distributed
lost packets translate into
that developers think in
packets translate into dramatic
one large project is
translate into dramatic reductions
large project is pairing
into dramatic reductions in
project is pairing qsm
dramatic reductions in application
is pairing qsm with
concentrate on distributed file
developers think in terms
pairing qsm with high
think in terms of
on distributed file systraditional
in terms of a
terms of a reliable
distributed file systraditional cache
of a reliable arraystructured
a reliable arraystructured partitioned
speed event stream filtering
reliable arraystructured partitioned service
file systraditional cache manager
event stream filtering and
systraditional cache manager design
stream filtering and data
cache manager design in
because applications and os
manager design in two
applications and os networking
design in two important
and os networking stacks
filtering and data mining
os networking stacks in
and data mining system
implemented as a set
data mining system to
in two important respects
mining system to obtain
as a set of
networking stacks in commodity
a set of reliable
system to obtain a
set of reliable arraystructured
to obtain a scalable
stacks in commodity data
of reliable arraystructured clustered
in commodity data centers
reliable arraystructured clustered servers
commodity data centers cannot
data centers cannot be
centers cannot be rewritten
cannot be rewritten from
be rewritten from scratch
hosted service capable of
tems because systems in
service capable of handling
capable of handling very
because systems in this
of handling very high
handling very high event
systems in this area
this architecture offers scalability
very high event rates
architecture offers scalability and
in this area are
offers scalability and reliability
scalability and reliability at
this area are highly
and reliability at two
reliability at two levels
area are highly developed
are highly developed and
group used for system
highly developed and have
the top level uses
used for system management
top level uses some
developed and have mfs
side appliance receiver buffer
for system management service
appliance receiver buffer overflow
and have mfs uses
level uses some sort
system management service b
uses some sort of
have mfs uses an
some sort of application
management service b x
mfs uses an rpc
service b x y
local recovery locations of
b x y z
recovery locations of packet
x y z x
locations of packet loss
y z x y
of packet loss receive
z x y z
uses an rpc library
specific key to partition
x y z x
key to partition the
an rpc library supporting
to partition the service
side appliance receiving end
y z x y
partition the service into
z x y z
rpc library supporting priorities
x y z a
the service into subservices
y z a b
library supporting priorities to
z a b service
a b service c
supporting priorities to enable
b service c a
the lower level implements
priorities to enable modewell
lower level implements subservices
service c a b
level implements subservices using
c a b w
to enable modewell understood
implements subservices using groups
a b w figure
enable modewell understood semantics
subservices using groups of
using groups of programs
maelstrom communication path forward
groups of programs that
communication path forward error
of programs that run
path forward error correction
programs that run on
that run on multiple
run on multiple machines
if sets of components
although the techniques we
sets of components are
the techniques we describe
perhaps in a cluster
is a promising solution
techniques we describe less
of components are replicated
we describe less adaptation
a promising solution for
in a cluster computer
promising solution for reliability
solution for reliability over
the associated multicast groups
for reliability over long
associated multicast groups overlap
multicast groups overlap hierarchically
the groups replicate data
groups replicate data so
replicate data so that
data so that each
the foregoing is the
so that each can
foregoing is the primary
that each can handle
is the primary use
each can handle any
the primary use scenario
can handle any incoming
primary use scenario for
handle any incoming query
use scenario for qsm
any incoming query for
incoming query for its
query for its range
for its range within
its range within the
range within the keys
which allocates available bandwidth
but may not be
packet recovery latency is
may not be the
recovery latency is independent
not be the only
allocates available bandwidth based
enabling updates to reach
latency is independent of
updates to reach all
available bandwidth based should
to reach all the
be the only one
bandwidth based should be
reach all the replicas
based should be broadly
is independent of the
should be broadly applicable
independent of the rtt
be broadly applicable in
one could imagine an
broadly applicable in other
could imagine an approach
applicable in other application
imagine an approach to
in other application environments
an approach to laying
of the rtt of
approach to laying out
the rtt of the
a raps that an
to laying out components
rtt of the link
laying out components on
raps that an e
out components on a
on the types of
components on a cluster
the types of messages
on a cluster that
types of messages being
a cluster that would
tailer such as amazon
cluster that would result
of messages being sent
while fec codes have
such as amazon might
fec codes have been
that would result in
as amazon might use
would result in irregular
amazon might use to
result in irregular layouts
might use to personalize
in irregular layouts of
by assigning priorities such
use to personalize a
codes have been used
irregular layouts of groups
assigning priorities such as
to personalize a product
have been used for
priorities such as caching
personalize a product recommendation
such as caching dynamic
qsm can support such
been used for decades
as caching dynamic internet
can support such layouts
used for decades within
depending on the customer
caching dynamic internet content
for decades within link
dynamic internet content or
on the customer s
internet content or caching
the customer s profile
at least to a
content or caching to
least to a degree
or caching to improve
caching to improve appropriately
the service ranks matching
service ranks matching products
but for reasons of
ranks matching products differently
for reasons of brevity
matching products differently to
reasons of brevity the
products differently to maximize
of brevity the discussion
differently to maximize the
brevity the discussion in
to maximize the chance
the discussion in the
faster commodity processors have
maximize the chance of
discussion in the remainder
the chance of a
commodity processors have enabled
chance of a purchase
processors have enabled packet
in the remainder of
the remainder of the
remainder of the paper
such as retrieving files
of the paper focuses
level fec at end
the paper focuses on
if the product is
paper focuses on regular
can the performance of
the performance of interactions
hierarchically structured communication groups
performance of interactions with
structured communication groups with
of interactions with web
communication groups with extensive
interactions with web services
groups with extensive and
as shown in figure
with extensive and regular
extensive and regular overlap
we evaluate proceed concurrently
initial users of our
the service assigns the
evaluate proceed concurrently with
users of our system
service assigns the search
of our system haven
assigns the search request
our system haven t
the search request to
system haven t had
search request to the
haven t had any
request to the racs
t had any difficulty
to the racs handling
had any difficulty with
the racs handling all
any difficulty with this
racs handling all ds
difficulty with this constraint
proceed concurrently with background
concurrently with background activities
with background activities such
knowing qsm is particularly
qsm is particularly effective
background activities such as
is particularly effective with
such as the customer
activities such as writing
as the customer s
particularly effective with regular
such as writing the
the customer s name
end fec is very
customer s name are
as writing the authors
effective with regular layouts
fec is very attractive
s name are equally
is very attractive for
name are equally plausible
very attractive for communication
writing the authors were
they just design to
attractive for communication between
the authors were supported
just design to favor
for communication between data
authors were supported in
design to favor regularity
communication between data centers
the load balancer then
were supported in part
load balancer then routes
supported in part by
balancer then routes the
in part by darpa
then routes the request
part by darpa under
usage cases architecture reliable
routes the request to
cases architecture reliable multicast
the request to the
by darpa under afrl
easy to deploy and
darpa under afrl grant
to deploy and customize
under afrl grant radc
request to the appropriate
architecture reliable multicast is
to the appropriate program
reliable multicast is a
the appropriate program for
multicast is a mature
appropriate program for processing
afrl grant radc back
and does not require
is a mature area
does not require specialized
grant radc back changes
not require specialized equipment
program for processing in
require specialized equipment in
for processing in this
specialized equipment in the
but a review of
equipment in the network
processing in this case
a review of prior
in the network linking
under the assurance that
the network linking the
review of prior systems
the assurance that if
of prior systems convinced
network linking the data
prior systems convinced us
linking the data centers
with support for this
assurance that if bandwidth
systems convinced us that
that if bandwidth becomes
convinced us that no
if bandwidth becomes f
support for this basic
us that no existing
for this basic layout
that no existing system
endhost fec has two
no existing system would
fec has two major
existing system would work
has two major issues
system would work well
two major issues first
would work well in
it s possible to
work well in the
s possible to tackle
well in the scenarios
possible to tackle a
in the scenarios targeted
to tackle a wide
the scenarios targeted by
tackle a wide range
scenarios targeted by our
a wide range of
targeted by our project
wide range of secondary
it s not transparent
range of secondary issues
this forced us to
requiring modification of the
forced us to build
modification of the end
us to build a
to build a new
we could create standards
build a new system
could create standards for
a new system that
create standards for a
new system that combines
standards for a self
system that combines features
that combines features from
combines features from a
features from a number
managed raps of racs
from a number of
a number of prior
number of prior systems
it s not necessarily
or for one that
s not necessarily rapid
for one that guarantees
our decision not to
one that guarantees real
decision not to use
not to use some
fec works best over
to use some existing
works best over high
use some existing multicast
some existing multicast system
existing multicast system reflects
multicast system reflects a
such a basic architecture
system reflects a number
a basic architecture is
reflects a number of
basic architecture is effectively
a number of issues
stable traffic rates and
architecture is effectively a
traffic rates and performs
is effectively a framework
rates and performs poorly
effectively a framework to
and performs poorly if
a framework to resolve
performs poorly if the
framework to resolve other
most prior multicast systems
to resolve other related
poorly if the data
prior multicast systems were
if the data rate
resolve other related issues
the data rate in
multicast systems were designed
data rate in the
systems were designed to
rate in the channel
were designed to replicate
in the channel is
designed to replicate state
the channel is low
to replicate state within
channel is low and
replicate state within just
is low and sporadic
state within just a
group replication web services
within just a single
replication web services currently
just a single group
web services currently lacks
a single group at
services currently lacks support
single group at a
currently lacks support for
group at a time
and by afosr under
lacks support for building
by afosr under muri
support for building scalable
afosr under muri grant
for example a single
under muri grant f
example a single distributed
for building scalable services
a single distributed service
the architecture makes it
as in a single
architecture makes it easy
in a single end
makes it easy to
some don t support
it easy to build
don t support multiple
easy to build a
t support multiple groups
to build a single
support multiple groups at
multiple groups at all
node server that responds
server that responds to
while others have overheads
that responds to requests
others have overheads linear
responds to requests from
have overheads linear in
to requests from some
overheads linear in the
requests from some set
we present the maelstrom
linear in the number
present the maelstrom error
in the number of
from some set of
the number of groups
the maelstrom error correction
some set of clients
number of groups to
maelstrom error correction appliance
of groups to which
error correction appliance a
groups to which a
correction appliance a rack
to which a node
appliance a rack of
which a node belongs
but there s no
a rack of proxies
there s no way
rack of proxies residing
s no way to
of proxies residing between
no way to turn
proxies residing between a
way to turn that
residing between a data
to turn that single
we looked at jgroups
turn that single server
between a data center
that single server into
a data center and
single server into a
data center and its
server into a racs
center and its wan
into a racs or
and its wan link
a racs or turn
racs or turn a
or turn a set
turn a set of
a set of racs
set of racs into
of racs into a
racs into a raps
a component of the
component of the jboss
of the jboss platform
the jboss platform which
jboss platform which runs
platform which runs in
which runs in a
runs in a managed
it would be easy
in a managed java
would be easy to
a managed java framework
maelstrom encodes fec packets
be easy to bridge
encodes fec packets over
easy to bridge the
fec packets over traffic
to bridge the gap
packets over traffic flowing
bridge the gap if
jgroups wasn t designed
the gap if vendors
over traffic flowing through
gap if vendors and
traffic flowing through it
wasn t designed to
if vendors and platform
flowing through it and
vendors and platform builders
t designed to support
and platform builders wanted
designed to support large
platform builders wanted to
through it and routes
builders wanted to do
to support large numbers
it and routes them
wanted to do so
and routes them to
support large numbers of
routes them to a
rather than the foreground
large numbers of overlapping
than the foreground ones
numbers of overlapping groups
them to a corresponding
to a corresponding appliance
structured partitioned service reliable
a corresponding appliance at
partitioned service reliable array
corresponding appliance at the
and if configured to
appliance at the destination
if configured to do
additional support from microsoft
at the destination data
configured to do so
support from microsoft research
the destination data center
from microsoft research and
microsoft research and from
research and from the
and from the intel
which decodes them and
from the intel corporation
decodes them and recovers
there has been a
them and recovers lost
has been a great
and recovers lost data
been a great deal
a great deal of
great deal of work
deal of work on
of work on p
maelstrom is completely transparent
is completely transparent it
completely transparent it does
p pubsub and content
transparent it does not
x y z search
it does not require
y z search for
does not require modification
z search for digital
not require modification of
search for digital camera
require modification of end
for digital camera figure
pubsub and content delivery
application programs background processing
and content delivery platforms
content delivery platforms in
host software and is
delivery platforms in recent
software and is agnostic
platforms in recent years
and is agnostic to
example of raps of
programs background processing incoming
is agnostic to the
of raps of racs
agnostic to the network
often oriented towards content
background processing incoming traffic
oriented towards content filtering
to the network connecting
towards content filtering in
the network connecting the
the service assigns a
network connecting the data
service assigns a digital
connecting the data centers
processing incoming traffic cache
content filtering in document
assigns a digital camera
incoming traffic cache consistency
a digital camera search
filtering in document streams
digital camera search request
traffic cache consistency demand
it eliminates the dependence
camera search request to
eliminates the dependence of
search request to the
the dependence of fec
a good example is
dependence of fec recovery
request to the clustered
of fec recovery latency
to the clustered server
fec recovery latency on
the clustered server handling
cache consistency demand fetch
clustered server handling all
recovery latency on the
good example is siena
latency on the data
consistency demand fetch access
server handling all ds
on the data rate
demand fetch access monitoring
a system that has
the data rate in
fetch access monitoring prefetch
system that has become
data rate in any
access monitoring prefetch outgoing
that has become popular
and a load balancer
has become popular in
a load balancer routes
become popular in wan
monitoring prefetch outgoing traffic
popular in wan settings
rate in any single
load balancer routes it
prefetch outgoing traffic synchronous
balancer routes it to
in any single node
outgoing traffic synchronous writeback
routes it to the
it to the appropriate
traffic synchronous writeback update
to the appropriate process
synchronous writeback update logging
writeback update logging asynchronous
update logging asynchronous writeback
old and familiar technologies
node channel by encoding
and familiar technologies the
channel by encoding over
logging asynchronous writeback mfs
systems in this class
by encoding over the
in this class incur
encoding over the aggregated
this class incur steep
over the aggregated traffic
class incur steep overheads
asynchronous writeback mfs server
familiar technologies the most
the aggregated traffic leaving
technologies the most standard
aggregated traffic leaving the
incur steep overheads associated
writeback mfs server adaptive
the most standard form
traffic leaving the data
steep overheads associated with
mfs server adaptive rpc
most standard form of
server adaptive rpc library
overheads associated with content
adaptive rpc library mfs
standard form of system
rpc library mfs cache
form of system support
leaving the data center
of system support for
library mfs cache manager
system support for building
associated with content filtering
support for building a
mfs cache manager will
for building a raps
cache manager will be
building a raps of
manager will be penalised
a raps of racs
will be penalised first
raps of racs would
maelstrom uses a new
of racs would draw
uses a new encoding
racs would draw on
a new encoding scheme
would draw on virtual
messages often follow circuitous
new encoding scheme called
often follow circuitous routes
encoding scheme called layered
follow circuitous routes from
scheme called layered interleaving
circuitous routes from source
modeless adaptation using prioritised
draw on virtual synchrony
routes from source to
adaptation using prioritised communication
from source to destination
designed especially for time
using prioritised communication also
prioritised communication also allows
communication also allows mfs
sensitive packet recovery in
group computing model developed
packet recovery in the
computing model developed at
also allows mfs to
model developed at cornell
in high performance settings
allows mfs to be
developed at cornell in
recovery in the presence
mfs to be more
at cornell in the
these factors would degrade
to be more flexible
factors would degrade the
in the presence of
would degrade the performance
be more flexible in
the presence of bursty
degrade the performance of
more flexible in response
presence of bursty loss
the performance of the
flexible in response to
performance of the replicated
in response to bandwidth
of the replicated application
response to bandwidth variations
maelstrom s positioning as
to bandwidth variations than
s and used today
bandwidth variations than would
and used today to
s positioning as a
used today to run
variations than would be
today to run the
the spread multicast system
to run the new
spread multicast system implements
run the new york
positioning as a network
multicast system implements lightweight
than would be possible
as a network appliance
would be possible with
a network appliance reflects
be possible with a
network appliance reflects the
possible with a modal
the new york and
with a modal scheme
new york and swiss
system implements lightweight groups
appliance reflects the physical
york and swiss stock
reflects the physical infrastructure
and swiss stock exchange
the physical infrastructure of
swiss stock exchange systems
physical infrastructure of modern
infrastructure of modern data
of modern data centers
modern data centers clean
the french air traffic
data centers clean insertion
french air traffic control
mfs incorporates a new
air traffic control system
centers clean insertion points
incorporates a new cache
clean insertion points for
insertion points for proxy
a new cache consistency
points for proxy devices
and the us navy
new cache consistency algorithm
the us navy s
for proxy devices exist
cache consistency algorithm to
proxy devices exist on
us navy s aegis
consistency algorithm to efficiently
devices exist on the
the groups seen by
algorithm to efficiently provide
exist on the high
groups seen by applications
to efficiently provide a
seen by applications are
efficiently provide a high
by applications are an
provide a high degree
ibm s websphere platform
a high degree of
s websphere platform and
speed lambda links that
websphere platform and the
lambda links that interconnect
platform and the windows
links that interconnect individual
and the windows vista
that interconnect individual data
the windows vista clustering
interconnect individual data centers
windows vista clustering system
individual data centers to
vista clustering system also
data centers to each
clustering system also use
centers to each other
system also use versions
high degree of consistency
applications are an illusion
degree of consistency for
also use versions of
of consistency for access
maelstrom can operate as
consistency for access to
can operate as either
there is really only
operate as either a
is really only one
as either a passive
use versions of the
for access to shared
really only one use
either a passive or
only one use of
a passive or active
versions of the model
access to shared files
one use of qsm
passive or active device
use of qsm in
or active device on
of qsm in our
active device on these
qsm in our target
device on these links
although developers can t
in our target settings
developers can t access
which is required for
our target settings gives
is required for collaborative
target settings gives rise
of the three problems
settings gives rise to
the three problems of
gives rise to potentially
three problems of tcp
rise to potentially large
required for collaborative work
can t access the
for collaborative work applications
t access the internal
to potentially large numbers
access the internal mechanisms
potentially large numbers of
the internal mechanisms directly
large numbers of overlapping
numbers of overlapping communication
of overlapping communication groups
maelstrom solves the first
the rest of this
solves the first two
rest of this paper
the other popular standard
of this paper is
other popular standard uses
the first two throughput
as we have seen
this paper is organised
popular standard uses a
paper is organised as
standard uses a state
first two throughput collapse
the primary goal is
is organised as follows
two throughput collapse and
primary goal is to
machine approach to guarantee
goal is to support
approach to guarantee stronger
is to support data
to guarantee stronger durability
to support data replication
throughput collapse and realtime
support data replication in
collapse and realtime recovery
data replication in scalable
leslie lamport s paxos
and realtime recovery delays
lamport s paxos algorithm
realtime recovery delays while
describes the mfs design
recovery delays while operating
the mfs design and
delays while operating as
which is implemented in
in which sets of
while operating as a
which sets of components
is implemented in scalable
mfs design and differences
operating as a passive
sets of components are
as a passive device
of components are interconnected
a passive device that
components are interconnected and
passive device that does
design and differences from
implemented in scalable file
and differences from existing
in scalable file systems
are interconnected and cooperate
scalable file systems and
device that does not
file systems and other
that does not intervene
systems and other ultrareliable
does not intervene in
and other ultrareliable server
not intervene in the
other ultrareliable server designs
intervene in the critical
interconnected and cooperate to
differences from existing distributed
in the critical communication
from existing distributed and
and cooperate to perform
existing distributed and mobile
the critical communication path
distributed and mobile file
one architecture could support
and mobile file systems
cooperate to perform requests
architecture could support both
could support both of
support both of these
both of these powerful
of these powerful technologies
as well as giving
well as giving an
a natural option would
maelstrom handles the additional
natural option would be
handles the additional problem
option would be to
as giving an overview
components sets are normally
giving an overview of
would be to offer
an overview of the
be to offer them
the additional problem of
sets are normally colocated
additional problem of massive
to offer them in
overview of the mfs
problem of massive buffering
of the mfs rpc
when a service is
the mfs rpc library
a service is replicated
of massive buffering requirements
offer them in the
massive buffering requirements as
them in the context
buffering requirements as well
in the context of
the context of ws
each of its constituent
of its constituent components
its constituent components will
constituent components will need
at the cost of
components will need to
the cost of adding
will need to replicate
cost of adding a
need to replicate its
of adding a point
describes the use of
adding a point of
to replicate its portion
the use of prioritised
replicate its portion of
a point of failure
its portion of the
use of prioritised communication
point of failure in
of prioritised communication in
portion of the service
of failure in the
if you re replicating
prioritised communication in mfs
of the service state
communication in mfs and
you re replicating data
in mfs and experiments
re replicating data within
failure in the network
if qsm is used
replicating data within some
mfs and experiments to
in the network path
and experiments to evaluate
data within some form
experiments to evaluate its
within some form of
qsm is used to
to evaluate its effectiveness
the contributions of this
is used to disseminate
some form of group
contributions of this paper
used to disseminate updates
of this paper are
this paper are as
paper are as follows
you can just as
can just as easily
this results in a
just as easily imagine
results in a pattern
as easily imagine that
in a pattern of
easily imagine that it
presents and explains experimental
a pattern of communication
imagine that it has
pattern of communication groups
and explains experimental results
of communication groups that
that it has a
explains experimental results for
end fec for long
it has a subject
communication groups that are
has a subject name
experimental results for the
groups that are exactly
results for the mfs
that are exactly overlapped
distance communication between data
a subject name in
for the mfs prefetching
communication between data centers
the mfs prefetching mechanism
each replicated component will
subject name in a
replicated component will have
name in a publish
component will have one
will have one or
have one or more
and argue that the
one or more associated
argue that the rate
or more associated groups
that the rate sensitivity
advantages with this type
the rate sensitivity of
with this type of
does the same for
rate sensitivity of fec
the same for the
sensitivity of fec codes
same for the cache
of fec codes and
for the cache consistency
fec codes and the
delivering update streams to
codes and the opacity
update streams to its
and the opacity of
the cache consistency algorithm
this type of process
streams to its replicas
the opacity of their
opacity of their implementations
of their implementations present
their implementations present major
implementations present major obstacles
present major obstacles to
major obstacles to their
obstacles to their usage
a datacenter will typically
datacenter will typically host
data can be anything
will typically host many
typically host many services
concludes and describes future
a gateway appliance that
and describes future work
gateway appliance that transparently
each with a disjoint
appliance that transparently aggregates
with a disjoint set
that transparently aggregates traffic
a disjoint set of
transparently aggregates traffic and
disjoint set of components
aggregates traffic and encodes
traffic and encodes over
and encodes over the
encodes over the resulting
over the resulting high
and often deployed on
often deployed on disjoint
deployed on disjoint sets
on disjoint sets of
disjoint sets of nodes
we describe layered interleaving
in cases where two
the most important part
cases where two services
most important part of
where two services are
important part of mfs
a new fec scheme
w e b te
new fec scheme used
part of mfs is
fec scheme used by
of mfs is the
scheme used by maelstrom
e b te c
used by maelstrom where
mfs is the cache
by maelstrom where for
is the cache manager
maelstrom where for constant
b te c h
where for constant encoding
two services are co
for constant encoding overhead
te c h n
constant encoding overhead the
c h n o
encoding overhead the latency
h n o l
overhead the latency of
n o l o
the latency of packet
which intercepts file system
located on the same
o l o g
latency of packet recovery
l o g i
of packet recovery degrades
o g i e
packet recovery degrades gracefully
intercepts file system operations
on the same node
file system operations from
recovery degrades gracefully as
g i e s
system operations from application
we ll still see
i e s concerns
operations from application programs
ll still see heavy
degrades gracefully as losses
e s concerns experience
from application programs and
s concerns experience with
gracefully as losses get
concerns experience with corba
as losses get burstier
still see heavy overlap
application programs and resolves
experience with corba even
programs and resolves them
with corba even good
and resolves them into
corba even good ideas
resolves them into accesses
even good ideas can
we discuss implementation considerations
good ideas can be
them into accesses to
but unless the degree
into accesses to its
unless the degree of
ideas can be used
we built two versions
accesses to its local
the degree of replication
to its local mfs
degree of replication is
its local mfs cache
built two versions of
can be used in
of replication is identical
local mfs cache or
two versions of maelstrom
mfs cache or rpcs
be used in ways
cache or rpcs to
there may be two
or rpcs to a
may be two cases
rpcs to a server
one runs in user
used in ways that
runs in user mode
in ways that developers
nodes that host both
ways that developers dislike
that host both services
the cache manager has
that developers dislike and
cache manager has a
developers dislike and ultimately
manager has a number
dislike and ultimately reject
while the other runs
has a number of
and hence both sets
a number of components
hence both sets of
the other runs within
both sets of qsm
other runs within the
a good example of
sets of qsm groups
those in solid boxes
runs within the linux
in solid boxes are
within the linux kernel
solid boxes are part
good example of this
boxes are part of
are part of the
example of this occurred
we evaluate maelstrom on
part of the core
evaluate maelstrom on emulab
of the core system
and nodes that just
of this occurred when
nodes that just host
that just host one
this occurred when the
just host one of
those in dashed boxes
host one of them
in dashed boxes are
occurred when the corba
dashed boxes are optional
when the corba community
boxes are optional extensions
the corba community decided
are optional extensions which
corba community decided to
optional extensions which are
cluster management systems use
extensions which are described
management systems use groups
which are described in
systems use groups for
are described in subsequent
use groups for purposes
described in subsequent sections
community decided to tackle
and show that it
decided to tackle replication
groups for purposes other
to tackle replication for
show that it provides
tackle replication for fault
for purposes other than
replication for fault tolerance
purposes other than component
that it provides near
for fault tolerance but
other than component replication
mfs overview mfs differs
it provides near lossless
fault tolerance but then
overview mfs differs from
tolerance but then stumbled
such as tracking node
but then stumbled by
as tracking node status
provides near lossless tcp
mfs differs from earlier
then stumbled by presenting
differs from earlier mobile
stumbled by presenting the
tracking node status and
by presenting the technology
ip throughput and latency
presenting the technology to
throughput and latency over
the technology to developers
node status and launching
technology to developers in
status and launching applications
to developers in a
and latency over lossy
from earlier mobile file
developers in a way
earlier mobile file systems
in a way that
latency over lossy links
these groups will span
mobile file systems in
a way that was
file systems in adjusting
way that was much
systems in adjusting to
that was much too
groups will span large
was much too limiting
will span large numbers
much too limiting for
span large numbers of
in adjusting to changing
and recovers packets with
adjusting to changing network
large numbers of nodes
to changing network conditions
recovers packets with latency
changing network conditions using
packets with latency independent
network conditions using modeless
with latency independent of
conditions using modeless adaptation
perhaps the entire cluster
too limiting for general
latency independent of the
limiting for general use
independent of the rtt
of the rtt of
such groups overlap with
it comprises a core
groups overlap with everything
comprises a core client
the rtt of the
rtt of the link
of the link and
the result is an
tolerance mechanism is based
result is an environment
the link and the
is an environment in
link and the rate
an environment in which
and the rate in
environment in which there
the rate in any
mechanism is based on
rate in any single
and a number of
in any single channel
in which there will
is based on the
a number of subsystems
which there will be
number of subsystems that
there will be a
based on the virtual
of subsystems that perform
on the virtual synchrony
subsystems that perform different
the virtual synchrony model
m odel loss model
will be a hierarchy
that perform different kinds
perform different kinds of
but the programming tools
packet loss typically occurs
the programming tools built
loss typically occurs at
programming tools built over
typically occurs at two
different kinds of adaptation
occurs at two points
tools built over this
at two points in
built over this model
two points in an
over this model prevent
points in an end
this model prevent developers
and can be selectively
model prevent developers from
can be selectively enabled
prevent developers from using
developers from using threads
end communication path between
communication path between two
path between two data
between two data centers
qsm is highly effective
is highly effective in
highly effective in supporting
shows the structure of
as shown in figure
guis or other direct
the structure of the
effective in supporting this
or other direct end
in supporting this style
structure of the system
supporting this style of
this style of use
area network connecting them
network connecting them and
connecting them and at
in this section we
them and at the
this section we describe
and at the receiving
section we describe the
at the receiving end
we describe the core
describe the core system
recover in y inter
while subsequent sections do
loss in the lambda
subsequent sections do the
in the lambda link
or even prebuilt libraries
sections do the same
region protocol y intra
do the same for
the lambda link can
the same for the
lambda link can occur
same for the three
in the corba approach
link can occur for
for the three main
can occur for many
the three main subsystems
occur for many reasons
consisting of a small
of a small set
a small set of
a developer who obeys
small set of servers
developer who obeys this
set of servers to
who obeys this long
of servers to which
we begin with an
obeys this long list
begin with an overview
servers to which client
with an overview of
to which client systems
this long list of
dirty or degraded fiber
long list of constraints
which client systems connect
list of constraints can
an overview of mobile
of constraints can do
overview of mobile file
constraints can do lockstep
of mobile file system
mobile file system design
can do lockstep replication
file system design and
do lockstep replication of
level multicast is vectored
lockstep replication of a
multicast is vectored through
replication of a program
is vectored through a
system design and the
malfunctioning or misconfigured equipment
design and the relation
vectored through a server
and the relation of
of a program for
the relation of mfs
a program for tolerance
relation of mfs to
program for tolerance of
of mfs to previous
for tolerance of hardware
which multicasts it to
tolerance of hardware faults
multicasts it to its
mfs to previous work
low receiver power and
it to its peers
receiver power and burst
power and burst switching
and burst switching contention
burst switching contention are
switching contention are some
then briefly describe the
contention are some reasons
briefly describe the adaptive
these filter the ordered
describe the adaptive rpc
filter the ordered multicast
the adaptive rpc library
the ordered multicast stream
adaptive rpc library used
ordered multicast stream and
rpc library used in
multicast stream and relay
library used in mfs
stream and relay messages
the scheme doesn t
and relay messages back
scheme doesn t protect
relay messages back out
doesn t protect against
messages back out to
and the current mfs
back out to receivers
the current mfs implementation
t protect against software
this approach can support
approach can support huge
can support huge numbers
support huge numbers of
huge numbers of groups
numbers of groups with
of groups with irregular
groups with irregular overlap
developers regard the standard
with irregular overlap patterns
regard the standard as
the standard as rigid
standard as rigid and
as rigid and limited
but the servers are
the servers are a
mfs design and related
servers are a point
they need fault tolerance
are a point of
design and related work
a point of contention
and related work the
related work the core
but not in this
work the core of
not in this very
the core of mfs
in this very narrow
and the indirect communication
core of mfs follows
the indirect communication pathway
this very narrow form
indirect communication pathway introduces
of mfs follows a
communication pathway introduces potentially
mfs follows a design
pathway introduces potentially high
follows a design common
introduces potentially high latencies
a design common to
design common to many
systems like the isis
common to many mobile
like the isis toolkit
to many mobile file
these considerations convinced us
many mobile file systems
considerations convinced us that
convinced us that a
us that a new
popular during the early
that a new system
during the early and
a new system was
the early and mid
new system was needed
loss can also occur
can also occur at
qsm implements a approach
also occur at receiving
implements a approach similar
occur at receiving end
a approach similar to
approach similar to spread
similar to spread s
to spread s lightweight
spread s lightweight group
hosts within the destination
s lightweight group abstraction
within the destination data
the destination data center
also used virtual synchrony
but without a separate
used virtual synchrony but
without a separate server
virtual synchrony but had
these are usually cheap
a separate server group
are usually cheap commodity
synchrony but had fewer
usually cheap commodity machines
but had fewer limitations
cheap commodity machines prone
we define a region
commodity machines prone to
define a region of
they supported many of
a region of overlap
supported many of the
region of overlap to
many of the mechanisms
of overlap to be
of the mechanisms needed
overlap to be a
the mechanisms needed to
to be a set
mechanisms needed to build
be a set of
needed to build and
a set of nodes
machines prone to temporary
set of nodes with
to build and manage
prone to temporary overloads
build and manage a
of nodes with approximately
to temporary overloads that
nodes with approximately the
and manage a raps
temporary overloads that cause
manage a raps of
overloads that cause packets
which use techniques such
that cause packets to
a raps of racs
use techniques such as
with approximately the same
cause packets to be
techniques such as wholefile
packets to be dropped
approximately the same group
to be dropped by
and their successes have
be dropped by the
such as wholefile caching
the same group membership
their successes have clearly
dropped by the kernel
successes have clearly demonstrated
by the kernel in
have clearly demonstrated the
the kernel in bursts
clearly demonstrated the model
and update logging combined
demonstrated the model s
update logging combined with
the model s effectiveness
logging combined with asynchronous
combined with asynchronous writes
isis is no longer
is no longer available
under the assumptions of
no longer available as
to cope with disconnections
the assumptions of section
cope with disconnections or
longer available as a
with disconnections or intermittent
available as a product
this loss mode occurs
disconnections or intermittent connectivity
loss mode occurs with
mode occurs with udp
yet many critical systems
our cluster should be
many critical systems continue
cluster should be nicely
critical systems continue to
should be nicely tiled
systems continue to use
be nicely tiled by
continue to use isis
nicely tiled by regions
the design of mfs
based traffic but not
design of mfs is
traffic but not with
of mfs is closest
but not with tcp
mfs is closest in
based solutions or other
is closest in structure
solutions or other virtual
qsm uses regions for
or other virtual synchrony
closest in structure to
other virtual synchrony implementations
uses regions for multicast
in structure to that
which advertises receiver windows
regions for multicast dissemination
advertises receiver windows to
structure to that of
receiver windows to prevent
for multicast dissemination and
to that of coda
windows to prevent end
multicast dissemination and for
machine approach as used
dissemination and for recovery
approach as used in
and for recovery of
as used in the
for recovery of lost
what are typical loss
used in the paxos
recovery of lost packets
are typical loss rates
in the paxos algorithm
typical loss rates on
the paxos algorithm is
employing different protocols for
loss rates on long
paxos algorithm is also
different protocols for each
algorithm is also becoming
protocols for each purpose
is also becoming more
also becoming more popular
the answer to this
protocol node x recover
answer to this question
the key insight is
node x recover in
key insight is that
x recover in x
to this question is
insight is that these
recover in x region
is that these successes
in x region figure
this question is surprisingly
that these successes use
question is surprisingly hard
these successes use similar
is surprisingly hard to
successes use similar ideas
use similar ideas but
similar ideas but in
ideas but in ways
hierarchical recovery in qsm
but in ways very
in ways very different
ways very different from
very different from what
different from what the
a group spans multiple
from what the corba
group spans multiple regions
what the corba fault
a host acting as
each region has an
host acting as a
region has an associated
acting as a client
has an associated structure
as a client of
what we need today
a client of an
an associated structure of
client of an mfs
associated structure of token
we need today is
of an mfs file
structure of token rings
an mfs file system
need today is a
mfs file system runs
file system runs a
today is a modern
system runs a user
is a modern revisiting
a modern revisiting of
modern revisiting of this
revisiting of this technology
to recover from packet
recover from packet loss
of this technology that
this technology that draws
which receives file system
technology that draws on
qsm uses a hierarchical
that draws on group
uses a hierarchical structure
receives file system operations
draws on group communication
file system operations intercepted
on group communication but
system operations intercepted by
a hierarchical structure of
group communication but packages
hierarchical structure of token
operations intercepted by a
structure of token rings
intercepted by a kernel
communication but packages it
by a kernel module
but packages it in
packages it in a
we considered using other
it in a way
considered using other structures
in a way that
interacting with the vfs
a way that developers
with the vfs layer
way that developers perceive
the vfs layer of
that developers perceive as
vfs layer of the
developers perceive as solving
but token rings produce
layer of the local
perceive as solving their
of the local file
token rings produce a
the local file system
rings produce a more
as solving their most
produce a more predictable
solving their most pressing
a more predictable traffic
their most pressing scalability
more predictable traffic pattern
most pressing scalability problems
we adopt the same
pressing scalability problems and
adopt the same approach
scalability problems and that
the same approach to
problems and that flexibly
same approach to intercepting
and that flexibly matches
the importance of this
that flexibly matches their
importance of this will
flexibly matches their preferred
of this will become
matches their preferred styles
this will become clear
their preferred styles and
will become clear later
approach to intercepting vfs
preferred styles and tools
to intercepting vfs operations
intercepting vfs operations as
vfs operations as lbfs
other kinds of persistent
kinds of persistent objects
the basic structure is
basic structure is illustrated
structure is illustrated in
making use of the
is illustrated in figure
use of the kernel
of the kernel module
the kernel module provided
kernel module provided as
module provided as part
provided as part of
as part of the
the user simply designs
part of the arla
at the highest level
of the arla afs
user simply designs a
the arla afs client
simply designs a data
designs a data structure
qsm circulates tokens around
a data structure and
circulates tokens around sets
data structure and employs
tokens around sets of
structure and employs multicast
around sets of regions
and employs multicast technology
employs multicast technology to
multicast technology to transmit
technology to transmit updates
to transmit updates to
aggregating information that can
transmit updates to the
information that can be
updates to the group
that can be used
to the group members
can be used by
be used by a
used by a group
by a group sender
which apply them in
the cache manager maintains
apply them in the
cache manager maintains a
them in the same
a group sender to
in the same order
manager maintains a cache
group sender to retransmit
maintains a cache of
sender to retransmit packets
a cache of recently
the same order everywhere
to retransmit packets that
retransmit packets that were
packets that were missed
that were missed by
were missed by entire
accessed mfs files on
missed by entire regions
mfs files on the
files on the local
on the local disk
can be done on
be done on any
done on any desired
on any desired copy
of lost packets fig
when a vfs operation
a vfs operation is
vfs operation is intercepted
operation is intercepted for
is intercepted for a
a token circulates to
intercepted for a file
token circulates to provide
for a file that
examples of updates include
loss rates on teragrid
a file that is
circulates to provide loss
of updates include a
to provide loss recovery
updates include a stock
provide loss recovery at
include a stock trade
loss recovery at the
a stock trade or
recovery at the level
stock trade or stock
file that is not
trade or stock market
that is not in
or stock market quote
is not in the
at the level of
rates on teragrid determine
not in the cache
the level of nodes
a new object detected
level of nodes belonging
new object detected by
of nodes belonging to
object detected by radar
perhaps because such links
nodes belonging to the
it is retrieved in
detected by radar in
is retrieved in full
by radar in an
retrieved in full from
radar in an air
in full from the
belonging to the region
full from the appropriate
in an air traffic
from the appropriate server
an air traffic control
because such links are
air traffic control system
such links are a
links are a relatively
and the vfs operation
a communication to or
are a relatively recent
if regions become large
communication to or from
the vfs operation is
a relatively recent addition
vfs operation is then
to or from an
operation is then resumed
or from an aircraft
relatively recent addition to
qsm partitions them into
recent addition to the
partitions them into smaller
addition to the networking
or the addition of
to the networking landscape
the addition of a
the networking landscape and
addition of a node
them into smaller rings
of a node to
networking landscape and their
a node to a
mfs uses the writeback
node to a distributed
landscape and their ownership
to a distributed data
this is illustrated in
a distributed data structure
is illustrated in figure
distributed data structure containing
and their ownership is
data structure containing an
their ownership is still
structure containing an index
ownership is still mostly
containing an index of
is still mostly restricted
close semantics first implemented
still mostly restricted to
in the experiments reported
an index of pending
mostly restricted to commercial
index of pending orders
restricted to commercial organizations
of pending orders in
to commercial organizations disinclined
pending orders in an
commercial organizations disinclined to
the experiments reported in
semantics first implemented in
orders in an online
first implemented in the
in an online warehouse
implemented in the andrew
experiments reported in this
organizations disinclined to reveal
in the andrew file
reported in this paper
the andrew file system
data replication can be
disinclined to reveal such
replication can be remarkably
to reveal such information
no token ring ever
can be remarkably cheap
token ring ever grows
ring ever grows larger
ever grows larger than
grows larger than about
one source of information
with modern technology and
source of information is
modern technology and small
of information is teragrid
technology and small updates
and the system uses
the system uses single
system uses single and
uses single and two
when a dirty file
a dirty file is
dirty file is closed
computer chrony service can
chrony service can run
service can run at
can run at rates
an optical network interconnecting
run at rates well
optical network interconnecting major
the entire file contents
we plan to experiment
at rates well in
plan to experiment with
rates well in excess
to experiment with larger
well in excess of
entire file contents are
network interconnecting major supercomputing
file contents are transferred
interconnecting major supercomputing sites
contents are transferred to
major supercomputing sites in
are transferred to the
supercomputing sites in the
transferred to the server
experiment with larger configurations
sites in the us
with larger configurations and
larger configurations and will
configurations and will work
and will work with
will work with deeper
work with deeper hierarchies
teragrid has a monitoring
has a monitoring framework
a monitoring framework within
monitoring framework within which
the qsm recovery protocol
framework within which ten
qsm recovery protocol uses
within which ten sites
recovery protocol uses tokens
which ten sites periodically
protocol uses tokens to
though scheme for minimising
ten sites periodically send
scheme for minimising bandwidth
sites periodically send each
uses tokens to track
periodically send each other
tokens to track message
for minimising bandwidth utilisation
to track message status
minimising bandwidth utilisation when
bandwidth utilisation when transferring
gbps streams of udp
utilisation when transferring files
streams of udp packets
when transferring files is
ordered updates per second
of udp packets and
transferring files is not
udp packets and measure
files is not used
packets and measure the
is not used in
and measure the resulting
not used in mfs
measure the resulting loss
even if an update
the resulting loss rate
if an update requires
an update requires a
update requires a large
requires a large message
although it is orthogonal
it is orthogonal to
the token carries ack
is orthogonal to mfs
token carries ack and
it s possible to
carries ack and nak
orthogonal to mfs adaptation
s possible to maintain
ack and nak information
possible to maintain rates
to mfs adaptation and
to maintain rates of
mfs adaptation and could
maintain rates of thousands
adaptation and could be
rates of thousands per
and could be added
of thousands per second
aggregated over the nodes
thousands per second on
each site measures the
per second on typical
over the nodes below
could be added to
the nodes below each
be added to further
site measures the loss
second on typical hardware
nodes below each ring
added to further improve
measures the loss rate
to further improve performance
the virtual synchrony and
the loss rate to
virtual synchrony and statemachine
loss rate to every
token rings avoid the
rate to every other
rings avoid the kinds
to every other site
avoid the kinds of
synchrony and statemachine models
the kinds of ack
the server that stores
every other site once
server that stores a
and statemachine models show
that stores a file
statemachine models show how
stores a file is
models show how a
nak implosion problems with
other site once an
implosion problems with which
site once an hour
problems with which reliable
show how a tremendous
with which reliable multicast
a file is responsible
how a tremendous range
which reliable multicast protocols
a tremendous range of
reliable multicast protocols traditionally
tremendous range of application
multicast protocols traditionally have
range of application requirements
protocols traditionally have struggled
file is responsible for
resulting in a total
is responsible for maintaining
of application requirements can
responsible for maintaining the
application requirements can map
but problems of their
requirements can map down
problems of their own
can map down to
for maintaining the mutual
in a total of
maintaining the mutual consistency
map down to a
the mutual consistency of
down to a rigorously
mutual consistency of the
to a rigorously precise
if a message is
a rigorously precise execution
consistency of the copies
rigorously precise execution model
a message is lost
of the copies cached
loss rate measurements collected
the copies cached by
rate measurements collected across
copies cached by clients
the sender may not
measurements collected across the
which in turn can
sender may not find
in turn can be
may not find out
it records which clients
not find out for
records which clients cache
turn can be used
which clients cache the
can be used to
clients cache the file
be used to validate
find out for quite
used to validate a
out for quite a
to validate a platform
for quite a while
collected across the network
across the network every
the network every hour
and is responsible for
because the models have
is responsible for notifying
the models have formal
responsible for notifying them
models have formal specifications
for notifying them of
this isn t a
notifying them of changes
isn t a major
t a major issue
shows that between nov
a major issue because
you can test the
major issue because most
can test the correctness
issue because most message
test the correctness of
because most message losses
the correctness of an
most message losses can
mfs implements a variation
correctness of an implementation
message losses can be
implements a variation of
losses can be corrected
a variation of the
can be corrected locally
and even use theorem
variation of the scheme
even use theorem provers
of the scheme used
use theorem provers to
the scheme used by
through cooperation among receivers
scheme used by coda
theorem provers to assist
provers to assist developers
to assist developers in
assist developers in testing
the basic idea is
developers in testing their
basic idea is to
when a file is
in testing their most
a file is retrieved
testing their most critical
file is retrieved from
idea is to perform
is retrieved from the
is to perform recovery
retrieved from the server
to perform recovery as
their most critical application
perform recovery as locally
most critical application components
recovery as locally as
as locally as possible
the server issues a
server issues a limited
one reason that we
reason that we lack
that we lack this
we lack this sort
lack this sort of
this sort of support
sort of support today
obliging it to inform
of support today is
it to inform the
if a message is
to inform the client
support today is that
inform the client through
a message is available
the client through a
message is available within
of all such measurements
is available within the
all such measurements were
available within the same
such measurements were over
within the same token
client through a callback
today is that vendors
through a callback if
is that vendors and
a callback if another
the same token ring
callback if another host
that vendors and platform
if another host modifies
vendors and platform developers
another host modifies the
and platform developers worry
host modifies the file
platform developers worry that
some process that has
developers worry that these
process that has a
worry that these forms
that has a a
that these forms of
has a a a
these forms of replication
if the callback promise
forms of replication haven
a a a c
of replication haven t
a a c ac
replication haven t achieved
a c ac ab
the callback promise expires
haven t achieved huge
c ac ab abc
callback promise expires without
t achieved huge market
promise expires without a
achieved huge market success
expires without a callback
of them were over
without a callback being
ac ab abc bc
a callback being issued
ab abc bc b
as the experience with
abc bc b c
the experience with corba
bc b c b
experience with corba sidebar
b c b figure
with corba sidebar describes
the client must revalidate
client must revalidate the
must revalidate the file
revalidate the file before
the common object request
the file before using
common object request broker
file before using it
groups overlap to form
object request broker architecture
overlap to form regions
request broker architecture offers
after eliminating a single
broker architecture offers a
eliminating a single site
the cache consistency algorithm
nodes belong to the
architecture offers a fault
belong to the same
cache consistency algorithm is
to the same region
consistency algorithm is described
the same region if
algorithm is described in
same region if they
that dropped incoming packets
region if they have
dropped incoming packets steadily
if they have similar
incoming packets steadily at
they have similar group
packets steadily at a
have similar group membership
steadily at a rate
is described in more
tolerant groups mechanism that
at a rate of
groups mechanism that was
described in more detail
mechanism that was based
in more detail in
that was based on
more detail in section
was based on the
qsm currently uses an
based on the virtual
currently uses an unreliable
on the virtual synchrony
uses an unreliable ip
the virtual synchrony model
an unreliable ip multicast
since a single group
a single group may
single group may span
group may span multiple
the corba standard is
may span multiple regions
corba standard is widely
standard is widely viewed
is widely viewed as
widely viewed as rigid
viewed as rigid and
adaptive rpc library the
as rigid and limited
to send to group
rpc library the fundamental
send to group g
library the fundamental difference
i believe that the
the fundamental difference between
believe that the corba
fundamental difference between mfs
that the corba community
of the remainder were
difference between mfs and
a node multicasts a
the corba community erred
between mfs and other
corba community erred by
mfs and other file
community erred by embedding
the remainder were over
node multicasts a message
and other file systems
erred by embedding a
multicasts a message to
by embedding a powerful
a message to each
embedding a powerful solution
message to each of
a powerful solution into
other file systems we
powerful solution into a
to each of the
file systems we have
solution into a tool
systems we have described
into a tool mismatched
we have described is
a tool mismatched to
have described is in
tool mismatched to developer
described is in the
each of the regions
is in the communication
of the regions separately
in the communication between
mismatched to developer needs
the communication between the
communication between the cache
between the cache manager
the cache manager and
cache manager and servers
web services move beyond
services move beyond corba
move beyond corba in
beyond corba in many
corba in many ways
while lbfs uses a
lbfs uses a variant
uses a variant of
a variant of the
variant of the nfs
but the corba community
of the nfs rpc
our approach makes it
the corba community s
approach makes it easy
the nfs rpc protocol
makes it easy to
corba community s failed
it easy to aggregate
community s failed effort
these numbers may look
easy to aggregate messages
numbers may look small
s failed effort to
may look small in
to aggregate messages across
look small in absolute
aggregate messages across different
small in absolute terms
messages across different groups
failed effort to implement
effort to implement virtual
to implement virtual synchrony
but they are sufficient
implement virtual synchrony carries
they are sufficient to
virtual synchrony carries an
are sufficient to bring
synchrony carries an important
sufficient to bring tcp
carries an important lesson
an important lesson to
important lesson to current
if a node has
lesson to current researchers
a node has two
ip throughput crashing down
node has two messages
uses a customised rpc
has two messages to
throughput crashing down on
any technology offered to
crashing down on high
technology offered to developers
two messages to send
offered to developers must
messages to send to
to developers must support
unlike coda s rpc
to send to a
developers must support the
send to a pair
must support the programming
to a pair of
support the programming styles
a pair of groups
the programming styles they
pair of groups g
programming styles they prefer
conventional wisdom states that
the rpc used in
wisdom states that optical
rpc used in mfs
management policies a scalable
used in mfs incorporates
policies a scalable services
which overlap in region
a scalable services architecture
in mfs incorporates novel
scalable services architecture for
mfs incorporates novel features
services architecture for building
incorporates novel features to
architecture for building raps
novel features to allow
for building raps of
states that optical links
building raps of racs
that optical links do
raps of racs alone
optical links do not
of racs alone isn
links do not drop
overlap in region r
do not drop packets
racs alone isn t
features to allow it
alone isn t enough
to allow it to
then while transmitting to
allow it to adapt
while transmitting to r
it to adapt to
grade optical equipment is
to adapt to network
optical equipment is configured
adapt to network variability
equipment is configured to
scale systems that will
the node can batch
systems that will likely
node can batch these
that will likely soon
can batch these messages
will likely soon rely
batch these messages together
likely soon rely on
is configured to shut
the mfs rpc library
soon rely on standardized
mfs rpc library is
configured to shut down
rpc library is implemented
rely on standardized web
library is implemented on
on standardized web services
is implemented on top
standardized web services including
apps send to a
web services including global
send to a send
services including global banks
to shut down beyond
implemented on top of
to a send to
shut down beyond bit
a send to b
down beyond bit error
the entire us air
on top of the
send to b group
beyond bit error rates
entire us air force
top of the adaptive
to b group senders
bit error rates of
b group senders a
of the adaptive transport
group senders a b
and the supervisory control
senders a b c
the adaptive transport protocol
a b c region
the supervisory control and
b c region senders
supervisory control and data
c region senders a
control and data acquisition
region senders a ab
and data acquisition systems
senders a ab ac
data acquisition systems that
a ab ac abc
acquisition systems that operate
ab ac abc b
systems that operate the
ac abc b c
that operate the us
in discussing mfs rpc
one out of a
abc b c bc
operate the us power
out of a trillion
we give an overview
b c bc region
the us power grid
c bc region leader
us power grid will
bc region leader figure
power grid will also
of a trillion bits
give an overview of
grid will also require
an overview of the
will also require policies
overview of the parts
of the parts of
also require policies to
the parts of atp
to multicast to a
parts of atp which
multicast to a group
the reliability of the
of atp which are
reliability of the lambda
atp which are most
of the lambda network
which are most relevant
require policies to manage
are most relevant to
the lambda network is
qsm sends a copy
lambda network is clearly
sends a copy to
network is clearly not
a copy to each
is clearly not equal
copy to each of
clearly not equal to
most relevant to mfs
policies to manage security
to each of the
not equal to the
to manage security keys
each of the underlying
equal to the sum
of the underlying regions
to the sum of
the sum of its
sum of its optical
atp and its design
of its optical parts
and its design motivations
its design motivations have
design motivations have been
motivations have been described
partition leader token intrapartition
have been described in
leader token intrapartition token
been described in more
token intrapartition token partition
described in more detail
intrapartition token partition figure
in more detail in
it s less reliable
more detail in our
automated tools for monitoring
detail in our earlier
tools for monitoring large
s less reliable by
for monitoring large complex
less reliable by orders
monitoring large complex systems
reliable by orders of
large complex systems will
a hierarchy of token
in our earlier work
by orders of magnitude
complex systems will be
hierarchy of token rings
systems will be needed
will be needed as
be needed as well
applications and protocols such
and protocols such as
protocols such as tcp
researchers must think about
must think about how
the hypothesis underlying atp
ip which expect extreme
naks ack through upcalls
which expect extreme reliability
think about how monitoring
hypothesis underlying atp is
about how monitoring and
underlying atp is that
expect extreme reliability from
atp is that adapting
extreme reliability from the
is that adapting to
how monitoring and management
that adapting to network
monitoring and management policies
adapting to network variation
and management policies in
to network variation by
management policies in different
network variation by structuring
reliability from the high
variation by structuring applications
policies in different organizations
by structuring applications according
qsm is also registered
structuring applications according to
is also registered as
applications according to modes
also registered as a
according to modes is
registered as a shell
to modes is not
as a shell extension
in different organizations should
speed network are instead
different organizations should talk
network are instead subjected
organizations should talk to
are instead subjected to
making it possible to
should talk to one
modes is not always
instead subjected to unexpectedly
is not always appropriate
subjected to unexpectedly high
it possible to access
talk to one another
possible to access the
to one another when
to access the communication
and can sometimes lead
access the communication subsystem
to unexpectedly high loss
the communication subsystem directly
unexpectedly high loss rates
communication subsystem directly from
can sometimes lead to
one another when web
subsystem directly from the
another when web services
directly from the windows
when web services interactions
from the windows gui
web services interactions cross
sometimes lead to poor
these numbers reflect the
lead to poor performance
numbers reflect the loss
services interactions cross boundaries
reflect the loss rate
the loss rate specifically
loss rate specifically experienced
rate specifically experienced by
specifically experienced by udp
these are tough problems
experienced by udp traffic
shows the results of
by udp traffic on
the user can store
udp traffic on an
user can store a
traffic on an end
can store a shortcut
but they can be
store a shortcut to
they can be solved
a shortcut to a
the results of an
shortcut to a qsm
results of an experiment
to a qsm stream
of an experiment in
end path and may
a qsm stream in
an experiment in which
at cornell we recently
qsm stream in the
experiment in which modeless
stream in the file
path and may not
cornell we recently developed
in which modeless adaptation
in the file system
and may not generalize
we recently developed astrolabe
may not generalize to
which modeless adaptation over
not generalize to tcp
modeless adaptation over atp
generalize to tcp packets
a scalable technology for
adaptation over atp achieves
scalable technology for distributed
over atp achieves higher
technology for distributed monitoring
atp achieves higher bandwidth
for distributed monitoring and
click to attach a
distributed monitoring and control
to attach a previewer
we do not know
attach a previewer or
achieves higher bandwidth utilisation
a previewer or a
do not know if
monitoring and control that
not know if packets
and control that has
know if packets were
control that has attracted
previewer or a viewer
if packets were dropped
or a viewer to
packets were dropped within
that has attracted tremendous
were dropped within the
has attracted tremendous interest
dropped within the optical
attracted tremendous interest and
higher bandwidth utilisation than
a viewer to an
bandwidth utilisation than we
viewer to an event
utilisation than we will
tremendous interest and attention
than we will concentrate
to an event stream
we will concentrate on
within the optical network
will concentrate on a
the optical network or
concentrate on a system
optical network or at
on a system with
network or at intermediate
a system with a
or at intermediate devices
system with a single
researchers at other institutions
the overall architecture is
at other institutions are
overall architecture is summarized
other institutions are working
architecture is summarized in
institutions are working on
is summarized in figure
are working on other
with a single server
at intermediate devices within
working on other promising
intermediate devices within either
on other promising solutions
devices within either data
within either data center
mfs is designed to
is designed to support
the system is single
calability isn t just
designed to support multiple
isn t just a
though it s unlikely
to support multiple mfs
t just a technology
it s unlikely that
support multiple mfs file
s unlikely that they
multiple mfs file servers
unlikely that they were
that they were dropped
it s also a
they were dropped at
s also a mindset
were dropped at the
also a mindset with
we use a windows
a mindset with ramifications
use a windows i
mindset with ramifications at
modal adaptation modeless adaptation
with ramifications at many
dropped at the end
ramifications at many levels
henceforth referred to as
to ensure true scalability
referred to as an
to as an i
many of the measurements
of the measurements lost
true bandwidth bandwidth used
the measurements lost just
web services platforms must
measurements lost just one
services platforms must begin
lost just one or
platforms must begin to
to collect all asynchronous
just one or two
must begin to standardize
collect all asynchronous i
begin to standardize application
one or two packets
to standardize application architectures
or two packets whereas
standardize application architectures that
two packets whereas kernel
application architectures that promote
including notifications of any
architectures that promote reliability
notifications of any received
that promote reliability and
of any received messages
nic losses are known
promote reliability and interoperability
losses are known to
reliability and interoperability when
are known to be
and interoperability when developers
known to be bursty
interoperability when developers build
when developers build systems
developers build systems of
build systems of systems
work with intrinsically distributed
a single core thread
with intrinsically distributed programs
single core thread synchronously
intrinsically distributed programs that
core thread synchronously polls
distributed programs that don
thread synchronously polls the
programs that don t
synchronously polls the i
that don t fit
don t fit a
t fit a transactional
fit a transactional model
o queue to retrieve
queue to retrieve incoming
to retrieve incoming messages
and must provide responsiveness
loss occurred on paths
must provide responsiveness guarantees
occurred on paths where
provide responsiveness guarantees to
on paths where levels
responsiveness guarantees to their
the core thread also
paths where levels of
core thread also maintains
where levels of optical
thread also maintains an
guarantees to their users
also maintains an alarm
levels of optical link
maintains an alarm queue
of optical link utilization
applications with these sorts
with these sorts of
implemented as a splay
these sorts of requirements
as a splay tree
sorts of requirements are
of requirements are already
requirements are already in
are already in the
already in the pipeline
in the pipeline and
the pipeline and even
pipeline and even more
and even more of
even more of them
more of them are
of them are on
and a request queue
were consistently lower than
them are on drawing
are on drawing boards
on drawing boards in
drawing boards in government
implemented as a lockfree
as a lockfree queue
a lockfree queue with
lockfree queue with cas
for requests from the
ruling out congestion as
the only option for
out congestion as a
only option for the
congestion as a possible
option for the web
as a possible cause
for the web services
the web services community
web services community is
services community is to
community is to take
a conclusion supported by
is to take on
the core thread polls
to take on the
conclusion supported by dialogue
core thread polls all
supported by dialogue with
thread polls all queues
by dialogue with the
polls all queues in
dialogue with the network
all queues in a
take on the challenge
queues in a round
with the network administrators
if they do so
robin fashion and processes
fashion and processes the
and processes the events
processes the events sequentially
solutions will be readily
will be readily available
events of the same
of the same type
the same type are
web services are going
same type are processed
services are going to
type are processed in
are going to be
are processed in batches
going to be the
what are some possible
to be the ubiquitous
are some possible causes
be the ubiquitous platform
some possible causes for
the ubiquitous platform technology
up to the limit
ubiquitous platform technology for
to the limit determined
platform technology for next
the limit determined by
possible causes for such
limit determined by a
causes for such high
determined by a quantum
generation critical computing systems
for such high loss
such high loss rates
high loss rates on
loss rates on teragrid
and we ve no
we ve no one
ve no one but
no one but ourselves
one but ourselves to
a likely hypothesis is
but ourselves to blame
likely hypothesis is device
ourselves to blame if
hypothesis is device clutter
to blame if these
is device clutter the
blame if these systems
device clutter the critical
if these systems don
clutter the critical communication
these systems don t
the critical communication path
systems don t work
critical communication path between
don t work properly
communication path between nodes
there is no limit
path between nodes in
is no limit for
between nodes in different
no limit for local
do we really want
limit for local push
nodes in different data
we really want to
in different data centers
true bandwidth bandwidth used
really want to create
pull data sender inter
different data centers is
want to create a
data centers is littered
to create a world
centers is littered with
create a world in
is littered with multiple
a world in which
pull region partition figure
world in which minor
littered with multiple electronic
in which minor computer
with multiple electronic devices
which minor computer glitches
minor computer glitches shut
recovery inside and across
computer glitches shut down
inside and across partitions
glitches shut down massive
each of which represents
shut down massive critical
of which represents a
down massive critical applications
which represents a potential
copy will forward it
massive critical applications and
will forward it to
critical applications and in
forward it to the
represents a potential point
applications and in which
a potential point of
it to the process
and in which hackers
potential point of failure
to the process missing
in which hackers can
the process missing the
which hackers can readily
process missing the message
another possibility is that
hackers can readily disrupt
possibility is that such
can readily disrupt access
is that such loss
readily disrupt access to
that such loss rates
disrupt access to banking
such loss rates may
access to banking records
loss rates may be
qsm implements a scheme
rates may be typical
implements a scheme originally
may be typical for
a scheme originally proposed
air traffic control systems
scheme originally proposed by
be typical for any
originally proposed by zhao
typical for any large
and even shut down
even shut down the
shut down the power
down the power grid
scale network where the
network where the cost
where the cost of
the cost of immediately
time is running out
cost of immediately detecting
of immediately detecting and
immediately detecting and fixing
detecting and fixing failures
and fixing failures is
current halfway solutions will
even in a large
halfway solutions will tempt
in a large ring
fixing failures is prohibitively
solutions will tempt developers
failures is prohibitively high
will tempt developers to
tempt developers to embark
no more than five
developers to embark on
more than five nodes
to embark on a
than five nodes cache
embark on a path
five nodes cache any
on a path that
nodes cache any given
a path that will
we found through dialogue
cache any given message
path that will soon
found through dialogue with
that will soon lead
through dialogue with the
will soon lead many
dialogue with the administrators
qsm also uses this
soon lead many of
also uses this idea
lead many of them
uses this idea at
many of them into
with the administrators that
this idea at the
the administrators that the
of them into real
administrators that the steady
them into real trouble
that the steady loss
idea at the level
the steady loss rate
at the level of
steady loss rate experienced
the level of partitions
loss rate experienced by
the entire industry clients
rate experienced by the
experienced by the indiana
by the indiana university
each message is cached
the indiana university site
message is cached in
indiana university site was
is cached in a
university site was due
cached in a single
site was due to
and vendors as well
in a single partition
vendors as well as
was due to a
as well as the
due to a faulty
well as the government
to a faulty line
as the government have
a faulty line card
the government have a
government have a shared
have a shared obligation
a shared obligation to
shared obligation to make
if some partition is
obligation to make web
some partition is missing
to make web services
partition is missing a
make web services better
is missing a message
and the measurements showed
the measurements showed that
measurements showed that the
showed that the error
s ken birman is
that the error persisting
the partition caching it
ken birman is a
the error persisting over
birman is a professor
error persisting over at
is a professor in
partition caching it steps
a professor in the
caching it steps in
professor in the department
it steps in to
in the department of
persisting over at least
the department of computer
steps in to resend
department of computer science
in to resend it
of computer science at
over at least a
computer science at cornell
at least a three
science at cornell university
least a three month
a three month period
contact him at ken
if an entire region
modal versus modeless adaptation
an entire region is
versus modeless adaptation with
entire region is missing
modeless adaptation with atp
points for loss rates
region is missing a
for loss rates on
is missing a message
loss rates on high
the left graph shows
left graph shows performance
graph shows performance with
shows performance with modal
the sender becomes involved
performance with modal adaptation
sender becomes involved and
becomes involved and re
haul networks are provided
networks are provided by
are provided by the
and the right graph
provided by the back
the right graph shows
right graph shows a
graph shows a scheme
qsm tokens also carry
shows a scheme in
bone networks of tier
tokens also carry other
department of computer engineering
also carry other information
a scheme in which
scheme in which there
san jose state university
in which there are
including data used to
global crossing reports average
which there are four
crossing reports average loss
there are four classes
reports average loss rates
are four classes of
average loss rates between
data used to perform
four classes of messages
used to perform rate
classes of messages being
to perform rate control
of messages being sent
perform rate control and
messages being sent simultaneously
rate control and information
control and information used
and information used to
information used to trigger
used to trigger garbage
to trigger garbage collection
the lowest line corresponds
lowest line corresponds to
the overall system configuration
line corresponds to the
overall system configuration is
corresponds to the highest
system configuration is managed
to the highest priority
configuration is managed by
is managed by what
managed by what we
by what we call
what we call the
we call the configuration
call the configuration management
the configuration management service
dark horizontal lines represent
horizontal lines represent operating
lines represent operating modes
represent operating modes on
operating modes on the
modes on the left
on four of its
four of its six
of its six inter
and the highest priority
which handles join and
the highest priority of
handles join and leave
highest priority of data
join and leave requests
priority of data being
of data being sent
data being sent during
being sent during a
haul links for the
sent during a second
links for the month
during a second on
for the month of
a second on the
the month of december
and uses these to
second on the right
uses these to generate
these to generate a
to generate a sequence
generate a sequence of
a sequence of membership
the modeless scheme achieves
sequence of membership views
modeless scheme achieves higher
of membership views for
scheme achieves higher utilisation
membership views for each
views for each multicast
the cms also determines
cms also determines and
also determines and continuously
determines and continuously updates
and continuously updates region
continuously updates region boundaries
maintains sequences of region
sequences of region views
of region views for
region views for each
mb of data sent
views for each region
qwest reports loss rates
because it always has
and tracks the mapping
it always has messages
reports loss rates of
always has messages to
tracks the mapping from
has messages to send
the mapping from group
mapping from group views
from group views to
group views to region
views to region views
while the modal scheme
the modal scheme is
modal scheme is dependent
scheme is dependent on
is dependent on a
the cms runs on
dependent on a rapid
cms runs on a
on a rapid and
runs on a single
a rapid and accurate
on a single node
rapid and accurate estimate
and accurate estimate of
accurate estimate of the
estimate of the available
but we intend to
of the available bandwidth
we intend to replace
the available bandwidth in
intend to replace this
available bandwidth in order
to replace this with
bandwidth in order to
replace this with a
in order to select
this with a state
order to select its
to select its correct
select its correct operating
in either direction on
its correct operating mode
either direction on its
machine replicated version in
direction on its trans
replicated version in the
version in the future
in the future to
the future to eliminate
future to eliminate the
pacific link for the
to eliminate the risk
link for the same
eliminate the risk of
for the same month
the risk of single
in the longer term
the longer term we
longer term we will
term we will move
we will move to
will move to a
move to a hierarchically
to a hierarchically structured
a hierarchically structured cms
these graphs are reproduced
graphs are reproduced from
we expect privately managed
expect privately managed lambdas
privately managed lambdas to
managed lambdas to exhibit
lambdas to exhibit higher
to exhibit higher loss
exhibit higher loss rates
higher loss rates due
loss rates due to
rates due to the
due to the inherent
to the inherent tradeoff
the inherent tradeoff between
inherent tradeoff between fiber
an equivalent modal scheme
equipment quality and cost
alarm queue application thread
other experiments have shown
queue application thread operating
experiments have shown that
application thread operating system
have shown that modeless
thread operating system kernel
shown that modeless adaptation
operating system kernel implementation
that modeless adaptation can
system kernel implementation qsm
modeless adaptation can achieve
kernel implementation qsm qsm
adaptation can achieve improvements
implementation qsm qsm request
can achieve improvements of
qsm qsm request queue
qsm request queue core
request queue core thread
queue core thread i
cloudifying source code repositories
as well as the
o queue socket figure
well as the difficulty
as the difficulty of
the difficulty of performing
difficulty of performing routine
how much does it
of performing routine maintenance
much does it cost
performing routine maintenance on
qsm uses a single
routine maintenance on longdistance
maintenance on longdistance links
michael siegenthaler hakim weatherspoon
siegenthaler hakim weatherspoon dept
with a core thread
of computer science cornell
a core thread that
computer science cornell university
core thread that controls
science cornell university msiegen
thread that controls three
and it is possible
that controls three queues
it is possible to
is possible to construct
possible to construct cases
end paths as dropping
to construct cases in
paths as dropping packets
construct cases in which
as dropping packets at
cases in which the
dropping packets at rates
in which the improvement
packets at rates of
which the improvement is
the improvement is even
improvement is even greater
of computer science cornell
computer science cornell university
science cornell university hweather
work on adaptation in
on adaptation in mobile
and requests from the
adaptation in mobile file
requests from the possibly
in mobile file systems
from the possibly multithreaded
mobile file systems has
the possibly multithreaded application
file systems has generally
systems has generally relied
has generally relied on
edu abstract cloud computing
generally relied on modal
when we set out
relied on modal schemes
abstract cloud computing provides
we set out to
cloud computing provides us
set out to implement
computing provides us with
out to implement qsm
provides us with general
us with general purpose
with general purpose storage
to capture a wide
general purpose storage and
capture a wide range
our intent was to
purpose storage and server
intent was to leverage
a wide range of
was to leverage the
storage and server hosting
wide range of deployed
and server hosting platforms
range of deployed networks
server hosting platforms at
to leverage the component
hosting platforms at a
leverage the component integration
platforms at a reasonable
the component integration tools
at a reasonable price
component integration tools available
integration tools available on
but our evaluation of
tools available on the
e xisting r eliability
available on the windows
xisting r eliability o
on the windows platform
r eliability o ptions
we explore the possibility
our evaluation of atp
eliability o ptions tcp
evaluation of atp demonstrated
explore the possibility of
we didn t expect
of atp demonstrated that
the possibility of tapping
atp demonstrated that it
didn t expect that
demonstrated that it could
t expect that co
that it could also
ip is the default
possibility of tapping these
is the default reliable
it could also improve
the default reliable communication
of tapping these resources
default reliable communication option
could also improve the
reliable communication option for
tapping these resources for
communication option for contemporary
also improve the performance
existence with the managed
these resources for the
with the managed environment
improve the performance of
the managed environment would
the performance of file
managed environment would require
performance of file system
environment would require any
resources for the purpose
would require any special
option for contemporary networked
require any special architectural
for contemporary networked applications
any special architectural features
for the purpose of
the purpose of hosting
purpose of hosting source
we discuss the implementation
qsm is implemented much
of hosting source code
discuss the implementation of
hosting source code repositories
exclusive embeddings in commodity
the implementation of modeless
is implemented much like
implementation of modeless adaptation
implemented much like any
of modeless adaptation in
embeddings in commodity operating
modeless adaptation in mfs
source code repositories for
in commodity operating systems
code repositories for individual
commodity operating systems and
adaptation in mfs further
repositories for individual projects
in mfs further in
for individual projects as
operating systems and networking
individual projects as well
the system is coded
mfs further in section
systems and networking apis
projects as well as
system is coded in
as well as entire
is coded in c
well as entire open
as entire open source
entire open source communities
atp is implemented at
is implemented at user
most applications requiring reliable
implemented at user level
applications requiring reliable communication
requiring reliable communication over
reliable communication over any
an analysis of storage
communication over any form
on top of kernel
analysis of storage costs
over any form of
top of kernel udp
of storage costs is
any form of network
storage costs is presented
form of network use
of network use tcp
it has a message
and a complete hosting
a complete hosting solution
complete hosting solution is
oriented interface for communication
hosting solution is built
solution is built and
is built and evaluated
built and evaluated as
and evaluated as a
evaluated as a proof
in which messages of
which messages of an
messages of an arbitrary
of an arbitrary size
ip has three major
an arbitrary size can
has three major problems
arbitrary size can be
three major problems when
size can be reliably
major problems when used
can be reliably transmitted
problems when used over
be reliably transmitted with
when used over high
reliably transmitted with their
transmitted with their boundaries
with their boundaries preserved
i ntroduction the advent
their boundaries preserved at
boundaries preserved at the
ntroduction the advent of
preserved at the receiver
the advent of cloud
at the receiver s
advent of cloud computing
the receiver s side
of cloud computing has
cloud computing has brought
to interface to the
computing has brought us
interface to the native
an application can send
has brought us a
to the native windows
brought us a dazzling
the native windows asynchronous
application can send a
throughput collapse in lossy
can send a message
collapse in lossy networks
send a message synchronously
native windows asynchronous i
us a dazzling array
a message synchronously or
a dazzling array of
message synchronously or asynchronously
dazzling array of public
array of public computing
of public computing services
ip is unable to
public computing services that
is unable to distinguish
computing services that can
unable to distinguish between
in the latter case
and is accessible from
to distinguish between ephemeral
services that can be
distinguish between ephemeral loss
is accessible from any
between ephemeral loss modes
that can be instantly
the latter case the
ephemeral loss modes due
can be instantly tapped
loss modes due to
latter case the sender
be instantly tapped by
modes due to transient
windows understands qsm to
due to transient congestion
understands qsm to be
instantly tapped by anyone
qsm to be the
tapped by anyone with
to be the handler
by anyone with a
be the handler for
anyone with a credit
case the sender provides
the handler for operations
the sender provides a
handler for operations on
sender provides a function
for operations on new
provides a function to
with a credit card
a function to be
a credit card number
function to be executed
operations on new kind
to be executed when
on new kind of
be executed when transmission
new kind of event
executed when transmission of
users are spared from
when transmission of the
are spared from having
kind of event stream
spared from having to
transmission of the message
from having to invest
of the message completes
having to invest in
or bad fiber and
to invest in expensive
bad fiber and persistent
invest in expensive infrastructure
fiber and persistent congestion
in expensive infrastructure such
and the send operation
expensive infrastructure such as
an application can obtain
the send operation itself
the loss of one
send operation itself is
loss of one packet
application can obtain handles
of one packet out
can obtain handles from
one packet out of
obtain handles from these
packet out of ten
handles from these qsm
operation itself is non
infrastructure such as servers
out of ten thousand
of ten thousand is
ten thousand is sufficient
thousand is sufficient to
is sufficient to reduce
sufficient to reduce tcp
and can then invoke
this is similar to
can then invoke methods
is similar to the
then invoke methods on
similar to the queued
invoke methods on those
to the queued rpc
methods on those handles
the queued rpc developed
on those handles to
queued rpc developed for
those handles to send
rpc developed for rover
handles to send events
ip throughput to a
and cooling equipment because
throughput to a third
cooling equipment because the
to a third of
incoming messages are delivered
equipment because the service
a third of its
because the service provider
third of its lossless
messages are delivered application
the service provider takes
are delivered application requests
of its lossless maximum
service provider takes care
provider takes care of
takes care of these
care of these and
of these and amortizes
if one packet is
these and amortizes the
one packet is lost
atp also allows the
and amortizes the cost
packet is lost out
also allows the sender
o event representing a
allows the sender to
is lost out of
the sender to attach
amortizes the cost across
sender to attach a
the cost across many
to attach a priority
cost across many clients
attach a priority to
event representing a received
lost out of a
representing a received packet
out of a thousand
a received packet is
achieving efficiency through economies
received packet is retrieved
efficiency through economies of
packet is retrieved for
through economies of scale
is retrieved for a
throughput collapses to a
retrieved for a given
collapses to a thirtieth
for a given socket
to a thirtieth of
a priority to each
companies are realizing that
priority to each message
a thirtieth of the
are realizing that it
the socket is drained
realizing that it no
socket is drained to
to control the order
is drained to minimize
control the order in
drained to minimize the
thirtieth of the maximum
that it no longer
the order in which
it no longer makes
order in which the
no longer makes sense
in which the queued
the root cause of
which the queued messages
root cause of throughput
the queued messages are
cause of throughput collapse
queued messages are transmitted
of throughput collapse is
to minimize the probability
longer makes sense to
throughput collapse is tcp
makes sense to build
minimize the probability of
sense to build and
messages are queued at
to build and manage
are queued at the
build and manage all
ip s fundamental reliance
and manage all of
the probability of loss
queued at the sender
s fundamental reliance on
manage all of their
fundamental reliance on loss
all of their own
reliance on loss as
at the sender according
several aspects of the
the sender according to
on loss as a
of their own infrastructure
aspects of the architecture
sender according to their
of the architecture are
according to their receivers
loss as a signal
the architecture are noteworthy
and services in the
architecture are noteworthy because
services in the cloud
are noteworthy because of
and each queue is
noteworthy because of their
as a signal of
in the cloud are
each queue is ordered
because of their performance
a signal of congestion
of their performance implications
the cloud are quickly
queue is ordered by
cloud are quickly becoming
is ordered by priority
are quickly becoming popular
while recent approaches have
recent approaches have sought
messages of the same
approaches have sought to
of the same priority
have sought to replace
the same priority within
sought to replace loss
same priority within a
to replace loss with
priority within a queue
replace loss with delay
within a queue are
that software development projects
a queue are transmitted
software development projects will
queue are transmitted in
development projects will turn
loss with delay as
qsm assigns priorities to
are transmitted in first
projects will turn to
with delay as a
will turn to cloud
delay as a congestion
turn to cloud computing
as a congestion signal
assigns priorities to different
to cloud computing to
priorities to different types
cloud computing to store
to different types of
computing to store their
different types of i
to store their master
store their master code
their master code repositories
atp also allows a
either on a project
also allows a sender
the basic idea is
allows a sender to
basic idea is that
a sender to specify
idea is that when
sender to specify a
is that when an
to specify a send
that when an i
specify a send timeout
a send timeout for
project basis or as
send timeout for a
basis or as part
or to specifically identify
timeout for a message
to specifically identify loss
or as part of
specifically identify loss caused
as part of a
identify loss caused by
part of a larger
loss caused by non
which causes the transmission
we retrieve all events
causes the transmission to
retrieve all events from
the transmission to be
all events from the
transmission to be suspended
events from the i
to be suspended if
of a larger migration
be suspended if it
a larger migration of
suspended if it expires
larger migration of a
migration of a sourceforge
determine the type of
the type of each
so that the sender
that the sender can
the sender can react
sender can react to
can react to it
and then place it
even small code repositories
then place it in
small code repositories represent
place it in an
code repositories represent a
older variants prominently reno
repositories represent a huge
an analogous mechanism is
it in an appropriate
analogous mechanism is available
represent a huge investment
mechanism is available for
a huge investment of
variants prominently reno remain
in an appropriate priority
prominently reno remain ubiquitously
an appropriate priority queue
reno remain ubiquitously deployed
huge investment of developerhours
is available for receive
available for receive operations
so the need to
the need to store
the system processes queued
besides detecting when a
need to store this
system processes queued events
recovery delays for real
processes queued events in
detecting when a remote
to store this data
queued events in priority
when a remote host
store this data durably
events in priority order
a remote host is
this data durably and
remote host is inaccessible
data durably and reliably
durably and reliably is
ip uses positive acknowledgments
and reliably is obvious
uses positive acknowledgments and
send timeouts do not
positive acknowledgments and retransmissions
timeouts do not play
acknowledgments and retransmissions to
less obvious are the
do not play a
obvious are the shortcomings
not play a major
are the shortcomings of
play a major role
the shortcomings of traditional
and retransmissions to ensure
by prioritizing incoming i
retransmissions to ensure reliability
shortcomings of traditional storage
to ensure reliability the
a major role in
ensure reliability the sender
major role in mfs
of traditional storage systems
reliability the sender buffers
the sender buffers packets
sender buffers packets until
buffers packets until their
packets until their receipt
an additional use for
until their receipt is
additional use for timeouts
their receipt is acknowledged
use for timeouts would
receipt is acknowledged by
for timeouts would be
is acknowledged by the
timeouts would be to
acknowledged by the receiver
would be to detect
be to detect prefetches
to detect prefetches which
detect prefetches which are
and by prioritizing control
prefetches which are not
and resends if an
which are not making
by prioritizing control packets
are not making progress
resends if an acknowledgment
not making progress and
if an acknowledgment is
making progress and reissue
an acknowledgment is not
progress and reissue a
acknowledgment is not received
and reissue a prefetch
is not received within
reissue a prefetch for
not received within some
a prefetch for a
received within some time
prefetch for a different
within some time period
for a different file
protect against data loss
prioritizing control packets over
control packets over data
packets over data we
over data we reduce
but they are neither
data we reduce delays
they are neither cheap
we reduce delays in
are neither cheap nor
a lost packet is
reduce delays in reacting
lost packet is received
delays in reacting to
neither cheap nor simple
packet is received in
in reacting to packet
is received in the
reacting to packet loss
received in the form
to packet loss or
in the form of
atp administers priorities by
especially when developers and
administers priorities by deriving
when developers and server
priorities by deriving an
developers and server administrators
by deriving an estimate
and server administrators are
deriving an estimate for
server administrators are geographically
packet loss or other
the form of a
an estimate for the
form of a retransmission
loss or other control
of a retransmission that
estimate for the bandwidth
a retransmission that arrives
for the bandwidth available
retransmission that arrives no
the bandwidth available between
administrators are geographically spread
that arrives no earlier
bandwidth available between the
we will see that
available between the sender
will see that this
between the sender and
see that this slashes
the sender and receiver
that this slashes system
arrives no earlier than
are geographically spread thin
in order to minimise
order to minimise the
to minimise the transmission
minimise the transmission delay
the pros and cons
the transmission delay when
pros and cons of
we focus on the
and cons of using
transmission delay when a
cons of using threads
rtts after the original
focus on the costs
of using threads in
delay when a new
using threads in eventoriented
when a new message
threads in eventoriented systems
a new message is
in eventoriented systems are
on the costs of
eventoriented systems are hotly
new message is sent
the costs of moving
the sender has to
systems are hotly debated
costs of moving source
sender has to buffer
of moving source code
has to buffer each
atp uses a form
to buffer each packet
uses a form of
moving source code repositories
buffer each packet until
source code repositories to
each packet until it
a form of rate
packet until it s
code repositories to the
threads turned out to
repositories to the cloud
turned out to be
to the cloud as
out to be a
until it s acknowledged
the cloud as an
to be a bad
cloud as an example
be a bad idea
as an example of
each second is divided
an example of moving
second is divided into
example of moving services
is divided into twenty
of moving services in
although we used threads
moving services in general
rtt in lossless operation
divided into twenty send
we used threads rather
services in general to
used threads rather casually
in general to the
threads rather casually in
general to the cloud
into twenty send periods
rather casually in the
and it has to
casually in the first
twenty send periods of
in the first year
it has to perform
especially collaborative open source
the first year of
has to perform additional
collaborative open source projects
to perform additional work
first year of our
perform additional work to
year of our effort
additional work to retransmit
such an endeavor includes
work to retransmit the
an endeavor includes many
to retransmit the packet
endeavor includes many costs
retransmit the packet if
that version of the
the packet if it
and at most one
packet if it does
the most critical of
version of the system
if it does not
twentieth of the available
it does not receive
of the available bandwidth
does not receive the
the available bandwidth is
not receive the acknowledgment
most critical of which
of the system was
critical of which is
available bandwidth is used
of which is storage
bandwidth is used during
which is storage since
is used during a
the system was annoyingly
is storage since that
used during a single
storage since that is
during a single send
since that is the
a single send period
system was annoyingly process
any packets that arrive
that is the simplest
was annoyingly process requests
is the simplest and
without such a constraint
the simplest and likely
annoyingly process requests incoming
packets that arrive with
simplest and likely first
process requests incoming control
and likely first component
atp would send as
that arrive with higher
would send as much
likely first component to
send as much data
first component to be
as much data as
component to be moved
much data as it
arrive with higher sequence
requests incoming control outgoing
with higher sequence numbers
data as it could
higher sequence numbers than
incoming control outgoing control
sequence numbers than that
control outgoing control outgoing
numbers than that of
outgoing control outgoing data
than that of a
control outgoing data feed
that of a lost
outgoing data feed sink
of a lost packet
data feed sink limit
a lost packet must
feed sink limit sending
we set an agenda
sink limit sending rate
lost packet must be
limit sending rate limit
set an agenda for
sending rate limit concurrency
packet must be queued
rate limit concurrency limit
an agenda for demonstrating
limit concurrency limit window
must be queued while
as it could on
be queued while the
it could on receipt
queued while the receiver
could on receipt of
while the receiver waits
concurrency limit window size
the receiver waits for
limit window size figure
receiver waits for the
on receipt of a
waits for the lost
receipt of a low
for the lost packet
agenda for demonstrating the
the lost packet to
for demonstrating the financial
lost packet to arrive
demonstrating the financial storage
the financial storage and
in a pull protocol
financial storage and computing
a pull protocol a
storage and computing costs
and this data could
and computing costs of
this data could then
computing costs of moving
data could then be
costs of moving source
could then be buffered
of moving source code
throughput financial banking application
moving source code repositories
then be buffered at
registers the intent to
be buffered at an
financial banking application running
source code repositories to
banking application running in
code repositories to the
application running in a
buffered at an intermediate
the intent to send
repositories to the cloud
running in a data
at an intermediate link
in a data center
intent to send with
a data center in
to send with a
data center in new
in section ii we
center in new york
delaying the transmission of
section ii we explain
the transmission of any
send with a sink
in new york city
with a sink that
transmission of any high
ii we explain what
a sink that may
we explain what it
sending updates to a
explain what it means
updates to a sister
priority message which might
sink that may be
what it means to
that may be controlled
message which might be
may be controlled by
to a sister site
which might be sent
it means to store
be controlled by a
means to store a
controlled by a policy
a sister site in
might be sent later
to store a code
by a policy limiting
store a code repository
a policy limiting the
sister site in switzerland
a code repository in
the disadvantage of this
policy limiting the send
disadvantage of this scheme
limiting the send rate
code repository in the
the rtt value between
repository in the cloud
rtt value between these
in the cloud and
value between these two
the cloud and why
between these two centers
cloud and why there
these two centers is
of this scheme is
two centers is typically
when the sink is
and why there are
the sink is ready
why there are cost
sink is ready to
this scheme is that
there are cost advantages
scheme is that heavy
are cost advantages to
is ready to send
is that heavy contention
cost advantages to doing
that heavy contention at
advantages to doing so
heavy contention at the
it issues an upcall
contention at the sender
at the sender may
the sender may delay
section iii is a
sender may delay a
iii is a case
may delay a new
is a case study
delay a new message
a case study on
a new message by
case study on using
new message by as
study on using amazon
message by as much
on using amazon s
by as much as
using amazon s s
app elements of the
in the case of
elements of the protocol
the case of a
of the protocol stack
to host some popular
the protocol stack f
host some popular open
case of a lost
some popular open source
of a lost packet
popular open source communities
regardless of its priority
all packets received within
o events according to
and includes a cost
events according to priorities
includes a cost analysis
this inefficiency of the
packets received within the
inefficiency of the atp
according to priorities incoming
of the atp implementation
to priorities incoming data
the atp implementation is
priorities incoming data policy
in section iv we
incoming data policy get
atp implementation is most
data policy get messages
section iv we present
policy get messages pre
iv we present an
implementation is most visible
we present an implementation
is most visible when
present an implementation that
milliseconds or more between
most visible when there
or more between the
visible when there is
an implementation that ties
when there is contention
implementation that ties subversion
there is contention between
that ties subversion to
more between the original
o events process timer
between the original packet
events process timer events
is contention between different
process timer events register
contention between different priorities
timer events register to
between different priorities at
events register to send
different priorities at high
register to send app
priorities at high bandwidth
to send app app
the original packet send
send app app f
ties subversion to s
original packet send and
packet send and the
send and the receipt
and the receipt of
the receipt of its
receipt of its retransmission
of its retransmission have
its retransmission have to
retransmission have to be
have to be buffered
to be buffered at
be buffered at the
end servers running on
buffered at the receiver
mfs implementation the version
servers running on amazon
implementation the version of
running on amazon s
the version of mfs
on amazon s ec
one can think of
version of mfs described
can think of qsm
of mfs described in
think of qsm as
the loss of a
of qsm as a
and using yahoo s
qsm as a collection
using yahoo s zookeeper
mfs described in this
loss of a single
described in this paper
yahoo s zookeeper for
in this paper is
s zookeeper for consistency
this paper is implemented
of a single packet
paper is implemented in
as a collection of
is implemented in c
a single packet stops
in section v we
single packet stops all
section v we evaluate
implemented in c and
v we evaluate the
in c and runs
we evaluate the performance
c and runs on
evaluate the performance of
and runs on freebsd
the performance of this
packet stops all traffic
a collection of protocol
stops all traffic in
performance of this solution
all traffic in the
collection of protocol stacks
traffic in the channel
of protocol stacks in
in the channel to
protocol stacks in which
and in section vi
stacks in which components
in section vi we
in which components act
the channel to the
section vi we address
channel to the application
vi we address related
to the application for
we address related work
the application for a
both the client and
which components act as
the client and server
components act as both
client and server have
act as both feeds
application for a seventh
and server have multiple
as both feeds and
server have multiple threads
both feeds and as
have multiple threads to
c loudifying s ource
multiple threads to cope
loudifying s ource r
threads to cope with
for a seventh of
to cope with simultaneous
a seventh of a
cope with simultaneous file
feeds and as sinks
s ource r epositories
seventh of a second
ource r epositories in
with simultaneous file system
r epositories in a
simultaneous file system requests
epositories in a revision
in a revision control
a revision control system
the overall structure is
a sequence of such
and the rpc library
sequence of such blocks
the rpc library has
a master copy of
rpc library has its
master copy of the
library has its own
copy of the source
has its own thread
of the source code
of such blocks can
overall structure is of
such blocks can have
structure is of a
blocks can have devastating
is of a forest
can have devastating effect
therefore there are two
of a forest of
there are two mandatory
a forest of trees
have devastating effect on
is stored in a
are two mandatory thread
devastating effect on a
two mandatory thread context
effect on a high
stored in a logically
mandatory thread context switches
in a logically centralized
thread context switches on
a logically centralized repository
context switches on any
throughput system where every
switches on any message
system where every spare
o was to reduce
where every spare cycle
each developer checks out
was to reduce staleness
every spare cycle counts
on any message send
developer checks out and
to reduce staleness by
checks out and then
any message send or
out and then keeps
message send or receive
and then keeps a
send or receive operation
reduce staleness by postponing
in applications with many
then keeps a working
staleness by postponing the
keeps a working copy
applications with many fine
as we shall describe
by postponing the creation
we shall describe in
a working copy on
postponing the creation of
working copy on his
shall describe in subsequent
the creation of control
copy on his machine
a lost packet can
on his machine that
lost packet can potentially
his machine that mirrors
describe in subsequent sections
creation of control messages
packet can potentially trigger
of control messages until
machine that mirrors the
control messages until the
that mirrors the repository
some subsystems have additional
messages until the time
subsystems have additional threads
can potentially trigger a
have additional threads to
until the time when
additional threads to carry
the developer edits files
threads to carry out
developer edits files in
to carry out background
the time when transmission
potentially trigger a butterfly
time when transmission is
trigger a butterfly effect
when transmission is actually
a butterfly effect of
transmission is actually about
butterfly effect of missed
is actually about to
carry out background processing
edits files in his
effect of missed deadlines
files in his working
actually about to take
in his working copy
about to take place
his working copy and
of missed deadlines along
working copy and periodically
missed deadlines along a
copy and periodically commits
our experiments were conducted
and periodically commits the
deadlines along a distributed
periodically commits the changes
along a distributed workflow
commits the changes back
experiments were conducted with
the changes back to
were conducted with a
changes back to the
conducted with a default
back to the repository
with a default client
time information is more
a default client cache
information is more accurate
default client cache size
and updates his working
client cache size of
updates his working copy
overloaded networks and end
his working copy to
and this makes qsm
working copy to reflect
this makes qsm more
copy to reflect the
makes qsm more stable
to reflect the changes
hosts can exhibit continuous
reflect the changes made
can exhibit continuous packet
the changes made by
exhibit continuous packet loss
changes made by other
made by other developers
an unintended benefit is
unintended benefit is that
benefit is that the
with each lost packet
is that the pull
each commit is assigned
that the pull architecture
commit is assigned a
each lost packet driving
the pull architecture slashes
lost packet driving the
pull architecture slashes buffering
packet driving the system
architecture slashes buffering and
driving the system further
is assigned a unique
the system further and
slashes buffering and memory
system further and further
buffering and memory overheads
further and further out
rpcs with priorities mfs
and further out of
with priorities mfs rpcs
further out of sync
priorities mfs rpcs are
out of sync with
mfs rpcs are implemented
of sync with respect
the repository maintains complete
sync with respect to
rpcs are implemented on
repository maintains complete history
with respect to its
are implemented on top
respect to its real
implemented on top of
as we shall demonstrate
maintains complete history so
on top of atp
complete history so at
top of atp in
history so at any
turns out to have
so at any point
of atp in the
at any point in
atp in the natural
out to have an
any point in time
to have an enormous
in the natural way
point in time it
have an enormous impact
in time it is
an enormous impact on
massive buffering needs for
enormous impact on performance
buffering needs for high
time it is possible
needs for high throughput
it is possible to
for high throughput applications
is possible to check
in qsm each element
possible to check out
an rpc request constitutes
qsm each element of
rpc request constitutes one
each element of a
request constitutes one message
to check out a
element of a protocol
check out a working
ip uses fixed size
of a protocol stack
uses fixed size buffers
and its reply another
fixed size buffers at
out a working copy
size buffers at receivers
a protocol stack acts
buffers at receivers to
protocol stack acts as
at receivers to prevent
stack acts as a
receivers to prevent overflows
acts as a feed
priorities are used to
as a feed that
a working copy for
a feed that has
are used to differentiate
working copy for any
used to differentiate types
copy for any specified
the sender never pushes
for any specified version
to differentiate types of
any specified version number
sender never pushes more
feed that has data
never pushes more unacknowledged
that has data to
differentiate types of rpcs
pushes more unacknowledged data
types of rpcs to
storing a repository in
has data to send
a repository in the
of rpcs to improve
repository in the cloud
more unacknowledged data into
in the cloud eliminates
unacknowledged data into the
the cloud eliminates worries
data into the network
cloud eliminates worries of
into the network than
eliminates worries of data
or a sink that
rpcs to improve performance
the network than the
worries of data loss
network than the receiver
of data loss due
than the receiver is
data loss due to
the receiver is capable
loss due to hardware
receiver is capable of
due to hardware failure
is capable of holding
a sink that can
sink that can send
that can send it
but issues of access
or those which would
issues of access control
those which would cause
of access control and
the size of the
access control and consistency
which would cause an
size of the fluctuating
control and consistency must
of the fluctuating window
and consistency must still
would cause an interactive
the fluctuating window at
consistency must still be
fluctuating window at the
and many play both
cause an interactive client
must still be addressed
window at the sender
many play both roles
at the sender is
an interactive client to
the sender is bounded
interactive client to block
sender is bounded by
authorized users should be
is bounded by the
users should be able
bounded by the size
should be able to
are given high priority
be able to commit
by the size of
able to commit new
the size of the
to commit new versions
size of the buffer
commit new versions of
rpcs for background activities
new versions of files
of the buffer at
versions of files to
the buffer at the
of files to the
such as writing back
files to the repository
rather than creating a
as writing back files
than creating a message
writing back files to
creating a message and
back files to the
buffer at the receiver
a message and handing
but not edit existing
message and handing it
not edit existing history
and handing it down
files to the server
handing it down to
it down to the
down to the sink
users expect the repository
expect the repository to
the repository to be
repository to be consistent
a feed registers the
to be consistent and
are performed at low
be consistent and for
performed at low priority
consistent and for any
feed registers the intent
the quantity of inflight
registers the intent to
and for any changes
quantity of inflight unacknowledged
the intent to send
of inflight unacknowledged data
for any changes they
inflight unacknowledged data has
any changes they make
unacknowledged data has to
intent to send a
data has to be
to send a message
has to be extremely
send a message with
to be extremely high
a message with the
so that they do
changes they make not
be extremely high for
message with the sink
that they do not
they make not to
extremely high for the
they do not slow
make not to be
the message can be
not to be pre
do not slow down
high for the flow
message can be created
for the flow to
can be created at
the flow to saturate
be created at this
not slow down high
flow to saturate the
created at this time
to saturate the network
at this time and
even in the face
this time and buffered
in the face of
time and buffered in
the face of cloud
and buffered in the
since the size of
buffered in the feed
the size of the
face of cloud services
size of the receiver
shows the priority levels
of cloud services that
the priority levels for
of the receiver window
priority levels for different
the receiver window limits
levels for different types
receiver window limits the
for different types of
window limits the sending
different types of rpcs
limits the sending envelope
cloud services that offer
but the creation may
services that offer lesser
the creation may also
that offer lesser guarantees
it plays a major
creation may also be
assigning priorities to rpcs
may also be postponed
priorities to rpcs allows
also be postponed until
to rpcs allows mfs
for these reasons we
rpcs allows mfs to
be postponed until the
allows mfs to adapt
these reasons we do
mfs to adapt to
postponed until the time
plays a major role
until the time when
a major role in
the time when the
major role in determining
time when the sink
role in determining tcp
when the sink polls
to adapt to bandwidth
reasons we do not
adapt to bandwidth variation
the sink polls the
to bandwidth variation in
we do not expect
bandwidth variation in a
sink polls the feed
do not expect that
the default receiver buffer
not expect that clients
default receiver buffer sizes
polls the feed for
receiver buffer sizes in
the feed for messages
buffer sizes in many
feed for messages to
sizes in many standard
for messages to transmit
in many standard tcp
expect that clients will
variation in a straightforward
that clients will be
in a straightforward way
clients will be directly
will be directly using
the sink determines its
be directly using the
sink determines its readiness
directly using the cloud
determines its readiness to
using the cloud storage
its readiness to send
the cloud storage api
readiness to send based
cloud storage api anytime
to send based on
storage api anytime soon
send based on a
all rpcs complete quickly
ip implementations are in
based on a control
implementations are in the
on a control policy
are in the range
but that they will
with or without priorities
that they will contact
in the range of
they will contact one
the range of tens
will contact one of
range of tens of
contact one of a
of tens of kilobytes
one of a set
of a set of
a set of front
and consequently inadequate receiver
consequently inadequate receiver buffering
end servers that are
inadequate receiver buffering is
servers that are responsible
receiver buffering is the
that are responsible for
buffering is the first
are responsible for enforcing
when the socket at
responsible for enforcing access
the socket at the
for enforcing access control
is the first hurdle
socket at the root
the first hurdle faced
at the root of
first hurdle faced by
the root of the
hurdle faced by most
root of the tree
faced by most practical
of the tree is
by most practical deployments
and pushing the data
the tree is ready
pushing the data into
tree is ready for
a natural solution is
is ready for transmission
natural solution is to
the data into the
solution is to increase
data into the cloud
is to increase the
corresponding rpc types fetch
messages will be recursively
rpc types fetch attributes
to increase the size
will be recursively pulled
these might consist of
be recursively pulled from
might consist of virtualized
recursively pulled from the
consist of virtualized server
pulled from the tree
of virtualized server instances
from the tree of
virtualized server instances in
the tree of protocol
server instances in the
tree of protocol stack
instances in the cloud
of protocol stack components
callbacks fetch file data
increase the size of
the size of the
size of the receiver
of the receiver buffers
or traditional physical machines
traditional physical machines owned
directory contents write back
physical machines owned by
contents write back directory
machines owned by the
write back directory and
owned by the community
back directory and metadata
feeds that no longer
directory and metadata updates
that no longer have
in many cases the
and metadata updates write
many cases the receiving
but in either case
cases the receiving end
metadata updates write back
no longer have data
updates write back shared
longer have data to
write back shared files
have data to send
host may not have
data to send are
back shared files write
in either case their
shared files write back
to send are automatically
files write back unshared
send are automatically deregistered
write back unshared files
either case their local
back unshared files prefetch
may not have the
case their local storage
not have the spare
unshared files prefetch file
have the spare memory
their local storage systems
the spare memory capacity
files prefetch file data
spare memory capacity to
prefetch file data section
memory capacity to buffer
local storage systems are
capacity to buffer the
storage systems are allowed
to buffer the entire
systems are allowed to
buffer the entire bandwidth
are allowed to be
sharing and priority i
allowed to be cheap
to be cheap and
be cheap and unresilient
cheap and unresilient against
delay product of the
and unresilient against hardware
product of the long
unresilient against hardware failure
and prone to oscillatory
another consideration with any
prone to oscillatory throughput
consideration with any hosting
the need for larger
with any hosting solution
independently and may compete
to oscillatory throughput when
need for larger buffers
oscillatory throughput when scaled
for larger buffers is
any hosting solution is
throughput when scaled up
larger buffers is orthogonal
hosting solution is resource
buffers is orthogonal to
solution is resource provisioning
is orthogonal to the
by making writes asynchronous
when we decided to
orthogonal to the flow
we decided to take
to the flow control
decided to take control
the flow control mechanisms
open source communities with
to take control over
flow control mechanisms used
source communities with limited
update logging pushes read
communities with limited budgets
control mechanisms used within
with limited budgets and
mechanisms used within tcp
limited budgets and private
take control over event
budgets and private enterprises
control over event processing
and private enterprises that
over event processing order
write contention into the
private enterprises that are
ip and impacts all
contention into the future
enterprises that are increasingly
and impacts all variants
we also eliminated multithreading
that are increasingly cost
impacts all variants equally
to occur at the
occur at the next
at the next log
the next log flush
sensitive may well prefer
may well prefer to
well prefer to pay
prefer to pay just
grained scheduling eliminated convoy
to pay just for
the designers of little
pay just for the
designers of little work
just for the resources
of little work incorporated
for the resources they
little work incorporated a
the resources they use
work incorporated a low
scheduling eliminated convoy behavior
fec fec encoders are
eliminated convoy behavior and
fec encoders are typically
rather than trying to
convoy behavior and oscillatory
level priority mechanism at
than trying to budget
behavior and oscillatory throughput
encoders are typically parameterized
and oscillatory throughput of
are typically parameterized with
priority mechanism at the
trying to budget in
oscillatory throughput of the
to budget in advance
mechanism at the ip
budget in advance what
throughput of the sort
typically parameterized with an
of the sort that
in advance what they
the sort that can
advance what they are
at the ip packet
sort that can disrupt
the ip packet level
what they are going
ip packet level to
they are going to
packet level to further
that can disrupt reliable
level to further reduce
are going to need
to further reduce interference
can disrupt reliable multicast
further reduce interference between
disrupt reliable multicast systems
reduce interference between writeback
reliable multicast systems when
cloud computing makes this
multicast systems when they
tuple for each outgoing
systems when they run
interference between writeback traffic
when they run at
between writeback traffic and
they run at high
writeback traffic and other
run at high data
traffic and other network
at high data rates
for each outgoing sequence
computing makes this a
each outgoing sequence of
makes this a possibility
outgoing sequence of r
high data rates on
and other network traffic
sequence of r data
other network traffic sent
of r data packets
network traffic sent by
and increased competition among
data rates on a
traffic sent by the
increased competition among providers
rates on a large
competition among providers of
on a large scale
among providers of commodity
sent by the client
providers of commodity services
a total of r
of commodity services will
commodity services will ensure
services will ensure that
will ensure that prices
ensure that prices are
c data and error
the last aspect relates
data and error correction
last aspect relates to
and error correction packets
aspect relates to the
error correction packets are
relates to the creation
correction packets are sent
to the creation of
packets are sent over
the creation of new
are sent over the
creation of new messages
sent over the channel
that prices are reasonable
particularly by qsm itself
priority levels for mfs
levels for mfs rpcs
readers who have implemented
c ase s tudy
who have implemented multicast
redundancy information cannot be
have implemented multicast protocols
symbolic names are given
information cannot be generated
implemented multicast protocols will
cannot be generated and
names are given for
be generated and sent
are given for the
generated and sent until
given for the priority
and sent until all
multicast protocols will know
sent until all r
protocols will know that
until all r data
will know that most
all r data packets
know that most existing
by far the most
that most existing systems
far the most popular
most existing systems are
the most popular general
r data packets are
most popular general purpose
data packets are available
popular general purpose cloud
packets are available for
general purpose cloud storage
existing systems are push
purpose cloud storage service
are available for sending
cloud storage service today
for the priority levels
storage service today is
service today is amazon
today is amazon s
is amazon s s
listed from highest to
some layer initiates a
from highest to lowest
layer initiates a new
highest to lowest priority
the latency of packet
initiates a new message
latency of packet recovery
a new message at
of packet recovery is
we chose to use
packet recovery is determined
the third column gives
recovery is determined by
new message at will
is determined by the
third column gives the
determined by the rate
chose to use this
by the rate at
column gives the section
to use this as
gives the section in
use this as a
the section in which
and lower layers then
section in which the
this as a basis
in which the corresponding
lower layers then buffer
which the corresponding rpc
layers then buffer that
the corresponding rpc types
then buffer that message
the rate at which
as a basis for
corresponding rpc types are
buffer that message until
rate at which the
a basis for cost
at which the sender
that message until it
rpc types are described
message until it can
types are described in
basis for cost studies
which the sender transmits
for cost studies and
the sender transmits data
cost studies and for
are described in detail
studies and for the
until it can be
and for the implementation
it can be sent
for the implementation of
the implementation of our
generating error correction packets
implementation of our system
error correction packets from
this makes sense under
correction packets from less
makes sense under the
packets from less than
sense under the assumption
from less than r
under the assumption that
less than r data
is an appealing choice
the assumption that senders
an appealing choice because
asynchronous writeback though it
appealing choice because amazon
writeback though it reduces
assumption that senders often
than r data packets
that senders often generate
though it reduces bandwidth
senders often generate bursts
r data packets at
choice because amazon also
data packets at the
because amazon also offers
often generate bursts of
it reduces bandwidth consumption
amazon also offers the
packets at the sender
generate bursts of packets
at the sender is
also offers the ec
the sender is not
update logging is fundamentally
sender is not a
logging is fundamentally unsuitable
is not a viable
is fundamentally unsuitable for
not a viable option
fundamentally unsuitable for use
a viable option even
unsuitable for use at
viable option even though
the communication subsystem can
option even though the
so it is possible
even though the data
communication subsystem can smooth
for use at high
subsystem can smooth the
use at high bandwidth
can smooth the traffic
though the data rate
it is possible to
the data rate in
is possible to use
data rate in this
possible to use their
rate in this channel
since it imposes a
to use their services
it imposes a delay
smooth the traffic flow
in this channel is
the traffic flow and
this channel is low
traffic flow and keep
imposes a delay on
use their services as
a delay on transmitting
flow and keep the
their services as a
and keep the network
services as a complete
delay on transmitting updates
as a complete hosting
on transmitting updates to
a complete hosting solution
transmitting updates to the
complete hosting solution with
updates to the server
hosting solution with low
keep the network interface
solution with low latency
the network interface busy
with low latency access
low latency access to
latency access to storage
systems using update logging
using update logging must
update logging must therefore
one consequence is that
logging must therefore switch
consequence is that messages
must therefore switch to
is that messages can
therefore switch to a
that messages can linger
switch to a synchronous
messages can linger for
to a synchronous writes
can linger for a
a synchronous writes when
linger for a while
synchronous writes when bandwidth
for a while before
writes when bandwidth is
a while before they
when bandwidth is high
while before they are
before they are sent
h a b c
a b c d
b c d x
with a threshold controlling
c d x x
a threshold controlling switches
d x x e
not only does this
x x e f
the cost analysis is
x e f g
cost analysis is based
e f g h
analysis is based on
f g h x
is based on real
g h x x
threshold controlling switches between
only does this increase
controlling switches between the
h x x a
switches between the two
x x a c
between the two modes
does this increase memory
x a c b
world traces taken from
this increase memory consumption
traces taken from the
a c b e
the mode switch also
c b e d
taken from the subversion
mode switch also changes
from the subversion repositories
but if a message
the subversion repositories of
if a message contains
subversion repositories of popular
a message contains current
repositories of popular open
message contains current state
of popular open source
contains current state information
b e d a
switch also changes the
popular open source projects
also changes the semantics
changes the semantics of
the semantics of the
that state may be
semantics of the file
state may be stale
of the file system
may be stale by
subversion represents each revision
be stale by the
represents each revision in
stale by the time
each revision in a
g g x x
by the time it
g x x f
the time it s
x x f h
time it s sent
x f h x
revision in a repository
and the developers of
f h x x
the developers of coda
in a repository s
developers of coda have
a repository s history
h x x b
in contrast to this
of coda have noted
contrast to this usual
coda have noted that
regardless of how many
have noted that undetected
of how many changes
noted that undetected mode
to this usual approach
that undetected mode changes
how many changes it
undetected mode changes can
many changes it contains
mode changes can surprise
changes can surprise the
qsm implements a pull
can surprise the user
implements a pull architecture
surprise the user in
the user in undesirable
user in undesirable ways
the first for data
evaluation evaluation of qsm
as a diff against
evaluation of qsm could
a diff against previous
of qsm could pursue
diff against previous revisions
qsm could pursue many
could pursue many directions
and the second for
separate encoding for odd
costs of the domain
encoding for odd and
of the domain crossing
the second for meta
the domain crossing between
such as cache inconsistencies
domain crossing between the
for odd and even
crossing between the application
as cache inconsistencies arising
data such as the
cache inconsistencies arising due
such as the author
between the application and
odd and even packets
inconsistencies arising due to
and even packets could
arising due to unexpectedly
even packets could be
the application and qsm
packets could be operating
due to unexpectedly delayed
could be operating at
and other revision properties
be operating at near
to unexpectedly delayed writes
operating at near full
protocol design and scalability
at near full capacity
near full capacity with
full capacity with data
our cost analysis is
capacity with data from
rather than relying on
with data from other
and interactions between protocol
cost analysis is based
interactions between protocol properties
analysis is based on
than relying on a
is based on the
relying on a modal
based on the sizes
on a modal adaptation
on the sizes of
between protocol properties and
the sizes of these
protocol properties and the
sizes of these files
properties and the managed
data from other senders
a modal adaptation scheme
of these files and
modal adaptation scheme incorporating
these files and the
adaptation scheme incorporating a
files and the time
fec is also very
and the time at
is also very susceptible
the time at which
also very susceptible to
time at which each
very susceptible to bursty
at which each revision
susceptible to bursty losses
which each revision was
scheme incorporating a transition
and the managed framework
each revision was committed
incorporating a transition to
a transition to update
transition to update logging
to update logging when
here we focus on
update logging when bandwidth
looking up the size
we focus on the
logging when bandwidth is
up the size of
focus on the latter
when bandwidth is low
the size of these
size of these special
of these special files
our goal is to
mfs uses a modeless
these special files is
goal is to arrive
uses a modeless asynchronous
special files is only
a modeless asynchronous writeback
is to arrive at
modeless asynchronous writeback mechanism
files is only possible
to arrive at a
is only possible if
arrive at a deep
only possible if one
at a deep understanding
possible if one has
which is active at
if one has filesystem
is active at all
one has filesystem level
is a standard encoding
has filesystem level access
a standard encoding technique
a deep understanding of
standard encoding technique used
filesystem level access to
encoding technique used to
deep understanding of the
active at all bandwidth
understanding of the performance
at all bandwidth levels
level access to the
technique used to combat
access to the disk
used to combat bursty
to the disk on
to combat bursty loss
the disk on which
just as with update
of the performance limits
disk on which the
the performance limits of
on which the repository
where error correction packets
which the repository is
performance limits of qsm
as with update logging
limits of qsm when
the repository is stored
of qsm when operating
error correction packets are
qsm when operating at
correction packets are generated
when operating at high
packets are generated from
when an application performs
are generated from alternate
so we had to
generated from alternate disjoint
an application performs an
operating at high data
application performs an operation
at high data rates
performs an operation that
from alternate disjoint sub
we had to use
high data rates with
had to use subversion
data rates with large
to use subversion s
rates with large numbers
streams of data rather
with large numbers of
of data rather than
large numbers of overlapping
data rather than from
numbers of overlapping groups
rather than from consecutive
an operation that changes
use subversion s mirroring
than from consecutive packets
subversion s mirroring capability
operation that changes a
for reasons of brevity
that changes a file
s mirroring capability to
mirroring capability to fetch
capability to fetch revisions
to fetch revisions from
fetch revisions from the
such as a write
revisions from the network
with an interleave index
as a write or
an interleave index of
a write or metadata
we are unable to
write or metadata update
are unable to undertake
accessible repository and replay
unable to undertake a
repository and replay them
to undertake a detailed
and replay them against
undertake a detailed analysis
replay them against a
a detailed analysis of
the encoder would create
detailed analysis of oscillatory
them against a local
analysis of oscillatory phenomena
against a local copy
of oscillatory phenomena in
encoder would create correction
create directory and so
oscillatory phenomena in this
would create correction packets
directory and so on
create correction packets separately
doing this also implicitly
phenomena in this paper
correction packets separately from
this also implicitly gives
packets separately from three
also implicitly gives us
separately from three disjoint
implicitly gives us the
also called convoys and
gives us the log
called convoys and broadcast
us the log of
the update is then
the log of timestamps
update is then passed
log of timestamps indicating
is then passed to
of timestamps indicating when
then passed to the
timestamps indicating when each
passed to the writeback
indicating when each revision
to the writeback subsystem
when each revision was
from three disjoint sub
convoys and broadcast storms
each revision was committed
which sends it to
sends it to the
it to the server
these plague many multicast
to the server when
plague many multicast and
the server when there
many multicast and pub
the first containing data
server when there is
first containing data packets
when there is sufficient
containing data packets numbered
there is sufficient bandwidth
thus it is possible
it is possible to
is possible to calculate
possible to calculate the
to calculate the bandwidth
asynchronous writeback therefore only
writeback therefore only delays
therefore only delays updates
event prioritization eliminated such
only delays updates when
prioritization eliminated such problems
delays updates when there
eliminated such problems in
updates when there is
such problems in the
when there is foreground
problems in the configurations
there is foreground traffic
in the configurations tested
the configurations tested by
transaction costs of pushing
configurations tested by our
costs of pushing the
tested by our experiments
of pushing the two
when bandwidth is high
pushing the two files
the two files for
two files for each
files for each revision
for each revision into
each revision into s
the performance of asynchronous
performance of asynchronous writeback
of asynchronous writeback should
asynchronous writeback should be
writeback should be comparable
should be comparable to
be comparable to purely
comparable to purely synchronous
to purely synchronous writes
based on amazon s
on varying numbers of
on amazon s current
varying numbers of nodes
amazon s current pricing
s current pricing structure
but when bandwidth is
when bandwidth is insufficient
we ll find that
shown in table i
ll find that the
find that the experiments
asynchronous writes will improve
that the experiments have
writes will improve the
the experiments have a
will improve the performance
experiments have a pattern
improve the performance non
table i a mazon
i a mazon s
a mazon s s
in scenario after scenario
the second with data
second with data packets
with data packets numbered
the performance of qsm
performance of qsm is
of qsm is ultimately
an implementation without priorities
qsm is ultimately limited
implementation without priorities will
is ultimately limited by
without priorities will result
ultimately limited by overheads
priorities will result in
limited by overheads associated
will result in the
by overheads associated with
result in the completion
overheads associated with memory
in the completion times
associated with memory management
the completion times for
with memory management in
completion times for all
memory management in the
times for all rpcs
management in the managed
for all rpcs increasing
in the managed environment
all rpcs increasing uniformly
when priorities are used
the more memory in
more memory in use
a backlog of low
the higher the overheads
priority rpcs will accumulate
higher the overheads of
the overheads of the
overheads of the memory
of the memory management
while the time taken
the memory management subsystem
the time taken for
memory management subsystem and
time taken for high
management subsystem and the
subsystem and the more
and the more cpu
the more cpu time
more cpu time it
cpu time it consumes
priority rpcs to complete
rpcs to complete will
to complete will increase
complete will increase more
will increase more gradually
leaving less time for
less time for qsm
time for qsm to
for qsm to run
our design is based
design is based on
is based on the
these aren t just
based on the assumption
aren t just garbage
on the assumption that
t just garbage collection
the assumption that when
and the third with
just garbage collection costs
the third with data
assumption that when bandwidth
third with data packets
that when bandwidth is
with data packets numbered
when bandwidth is low
every aspect of memory
aspect of memory management
of memory management gets
memory management gets expensive
an assignment of differentiated
assignment of differentiated priorities
of differentiated priorities will
and the costs grow
differentiated priorities will improve
the costs grow linearly
priorities will improve the
costs grow linearly in
will improve the response
grow linearly in the
improve the response times
linearly in the amount
the response times for
in the amount of
response times for interactive
the amount of memory
not included in the
times for interactive tasks
amount of memory in
included in the analysis
of memory in use
in the analysis is
the analysis is the
analysis is the cost
if a task which
is the cost of
a task which predominantly
the cost of fetching
task which predominantly performs
cost of fetching data
when qsm runs flat
of fetching data out
which predominantly performs reads
fetching data out of
data out of s
predominantly performs reads executes
performs reads executes in
reads executes in parallel
executes in parallel to
to be served to
in parallel to a
be served to clients
parallel to a task
cpu cycles are a
to a task which
cycles are a precious
a task which performs
are a precious commodity
task which performs many
this cost will vary
which performs many writes
cost will vary depending
will vary depending on
vary depending on how
depending on how much
on how much caching
how much caching is
much caching is done
minimizing the memory footprint
caching is done on
the memory footprint turns
is done on the
memory footprint turns out
done on the front
footprint turns out to
the first task will
turns out to be
first task will receive
out to be the
task will receive a
to be the key
will receive a higher
be the key to
receive a higher share
the key to high
a higher share of
key to high performance
higher share of the
share of the bandwidth
interleaving adds burst tolerance
adds burst tolerance to
burst tolerance to fec
all results reported here
tolerance to fec but
results reported here come
to fec but exacerbates
reported here come from
fec but exacerbates its
here come from experiments
many applications have patterns
come from experiments on
but exacerbates its sensitivity
applications have patterns of
from experiments on a
have patterns of interactive
exacerbates its sensitivity to
patterns of interactive file
its sensitivity to sending
of interactive file access
sensitivity to sending rate
interactive file access involving
to sending rate with
file access involving both
sending rate with an
and dedicated servers potentially
access involving both reads
dedicated servers potentially having
involving both reads and
rate with an interleave
servers potentially having much
with an interleave index
potentially having much more
an interleave index of
having much more due
interleave index of i
much more due to
index of i and
more due to inexpensive
of i and an
due to inexpensive sata
i and an encoding
to inexpensive sata disks
and an encoding rate
cluster of pentium iii
an encoding rate of
both reads and writes
it is not unreasonable
is not unreasonable to
not unreasonable to assume
unreasonable to assume that
to assume that a
assume that a cache
compiling source files involves
that a cache hit
source files involves interspersed
a cache hit rate
files involves interspersed reads
cache hit rate of
involves interspersed reads and
hit rate of close
interspersed reads and writes
rate of close to
the sender would have
sender would have to
would have to wait
have to wait for
to wait for i
but does not issue
does not issue concurrent
not issue concurrent rpcs
connected into a single
issue concurrent rpcs frequently
into a single broadcast
a single broadcast domain
single broadcast domain using
broadcast domain using a
domain using a switched
such an application will
an application will have
application will have improved
will have improved read
have improved read performance
improved read performance when
read performance when there
performance when there is
when there is contention
there is contention with
is contention with other
packets before sending any
contention with other applications
before sending any redundancy
sending any redundancy information
nodes run windows server
but will correspondingly be
will correspondingly be penalised
these two obstacles to
correspondingly be penalised on
two obstacles to using
be penalised on writes
obstacles to using fec
public subversion repositories of
to using fec in
using fec in time
subversion repositories of the
this does not match
repositories of the debian
does not match our
of the debian linux
not match our design
the debian linux community
match our design goal
sensitive settings rate sensitivity
our design goal of
debian linux community amount
design goal of having
settings rate sensitivity and
linux community amount to
rate sensitivity and burst
community amount to a
goal of having interactive
amount to a total
sensitivity and burst susceptibility
to a total of
and burst susceptibility are
a total of only
burst susceptibility are interlinked
susceptibility are interlinked through
are interlinked through the
interlinked through the tuning
through the tuning knobs
read applications obtain a
applications obtain a larger
obtain a larger share
a larger share of
larger share of bandwidth
an interleave of i
our benchmark is an
interleave of i and
benchmark is an nary
the only outgoing bandwidth
we have implemented two
of i and a
have implemented two solutions
i and a rate
implemented two solutions to
and a rate of
two solutions to this
only outgoing bandwidth costs
solutions to this problem
outgoing bandwidth costs are
linked to the qsm
bandwidth costs are then
to the qsm library
costs are then to
based on making writes
are then to to
on making writes asynchronous
then to to replace
running in the same
to to replace failed
provides tolerance to a
to replace failed frontend
tolerance to a burst
in the same process
replace failed frontend servers
to a burst of
failed frontend servers or
used in several existing
a burst of up
in several existing systems
burst of up to
frontend servers or to
several existing systems and
servers or to synchronize
existing systems and incorporated
or to synchronize replicas
systems and incorporated in
to synchronize replicas if
and incorporated in mfs
synchronize replicas if more
incorporated in mfs for
of up to c
in mfs for the
replicas if more than
mfs for the purposes
if more than one
for the purposes of
more than one is
the purposes of comparison
than one is in
up to c i
one is in use
to c i consecutive
c i consecutive packets
in the case of
the case of ec
which is new to
is new to mfs
the burst tolerance of
burst tolerance of an
an alternative approach is
tolerance of an fec
alternative approach is to
at the maximum possible
approach is to retain
the maximum possible rate
is to retain synchronous
the bandwidth costs are
of an fec code
bandwidth costs are actually
to retain synchronous writes
costs are actually waived
an fec code can
are actually waived and
fec code can be
actually waived and the
code can be changed
waived and the user
can be changed by
and the user then
be changed by modulating
but assign priorities according
changed by modulating either
the user then pays
by modulating either the
user then pays only
modulating either the c
then pays only for
either the c or
the majority of the
the c or the
majority of the figures
c or the i
of the figures include
or the i parameters
assign priorities according to
pays only for the
priorities according to some
only for the traffic
according to some notion
for the traffic between
to some notion of
the traffic between the
some notion of relative
traffic between the front
notion of relative importance
increasing c enhances burst
of relative importance of
c enhances burst tolerance
relative importance of processes
enhances burst tolerance at
end servers and their
burst tolerance at the
servers and their clients
tolerance at the cost
but these intervals are
at the cost of
these intervals are sometimes
the cost of network
table ii shows the
cost of network and
existing operating systems and
of network and encoding
operating systems and applications
network and encoding overhead
systems and applications generally
ii shows the cost
and applications generally do
shows the cost of
applications generally do not
the cost of using
generally do not provide
cost of using s
intervals are sometimes so
potentially worsening the packet
are sometimes so small
worsening the packet loss
sometimes so small that
do not provide this
so small that they
not provide this information
small that they may
the packet loss experienced
that they may not
packet loss experienced and
they may not always
loss experienced and reducing
may not always be
so we have not
not always be visible
we have not investigated
experienced and reducing throughput
for a number of
have not investigated it
a number of individual
not investigated it further
growing cost of memory
number of individual open
cost of memory allocation
of individual open source
individual open source projects
the cache manager s
increasing i trades off
cache manager s writeback
i trades off recovery
manager s writeback thread
as well as an
s writeback thread divides
well as an aggregate
trades off recovery latency
as an aggregate for
writeback thread divides updates
an aggregate for the
thread divides updates into
off recovery latency for
divides updates into metadata
recovery latency for better
updates into metadata operations
latency for better burst
for better burst tolerance
better burst tolerance without
burst tolerance without adding
tolerance without adding overhead
such as directory modifications
without adding overhead as
as directory modifications and
adding overhead as mentioned
directory modifications and file
repositories of the debian
modifications and file status
of the debian community
and file status changes
for higher values of
higher values of i
also shown is an
shown is an estimate
is an estimate for
an estimate for the
estimate for the apache
the encoder has to
for the apache software
the two types of
the apache software foundation
encoder has to wait
two types of operations
has to wait for
types of operations are
to wait for more
of operations are queued
apache has taken the
operations are queued and
wait for more data
are queued and replayed
has taken the unusual
queued and replayed to
for more data packets
and replayed to the
taken the unusual approach
replayed to the server
throughput as a function
to the server separately
as a function of
more data packets to
a function of the
the unusual approach of
function of the number
data packets to be
of the number of
unusual approach of using
packets to be transmitted
approach of using a
the number of nodes
of using a single
to be transmitted before
using a single repository
so that a metadata
a single repository for
that a metadata rpc
single repository for all
be transmitted before it
a metadata rpc can
transmitted before it can
metadata rpc can proceed
before it can send
repository for all of
it can send error
for all of its
can send error correction
rpc can proceed in
all of its projects
send error correction packets
can proceed in parallel
proceed in parallel with
in parallel with a
parallel with a file
both public and restricted
with a file writeback
due to access control
once the fec encoding
to access control restrictions
when an rpc from
the fec encoding is
an rpc from a
access control restrictions on
rpc from a particular
control restrictions on some
from a particular queue
restrictions on some paths
a particular queue completes
fec encoding is parameterized
processor utilization as a
encoding is parameterized with
utilization as a function
is parameterized with a
as a function of
parameterized with a rate
a function of the
with a rate and
function of the multicast
we say that the
of the multicast rate
a rate and an
subversion s mirroring tool
rate and an interleave
s mirroring tool was
and an interleave to
mirroring tool was unable
an interleave to tolerate
tool was unable to
interleave to tolerate a
was unable to create
to tolerate a certain
say that the update
tolerate a certain burst
that the update has
a certain burst length
the update has been
certain burst length b
update has been committed
unable to create local
has been committed at
to create local copy
been committed at the
committed at the server
the complete log of
complete log of timestamps
the next update is
next update is then
update is then dequeued
is then dequeued and
memory overheads on the
overheads on the sender
on the sender we
how much does it
update logging an asynchronous
much does it cost
the sender we begin
logging an asynchronous rpc
sender we begin by
an asynchronous rpc for
we begin by showing
asynchronous rpc for it
begin by showing that
rpc for it is
description monthly storage bandwidth
by showing that memory
monthly storage bandwidth in
for it is initiated
storage bandwidth in bandwidth
showing that memory overhead
bandwidth in bandwidth out
that memory overhead at
to tolerate a burst
memory overhead at the
tolerate a burst of
separating the small update
a burst of length
the small update logging
overhead at the sender
in bandwidth out per
at the sender is
the sender is a
which is implemented in
sender is a central
is implemented in some
is a central to
implemented in some mobile
a central to throughput
in some mobile file
some mobile file sys
metadata rpcs from file
rpcs from file writes
from file writes allows
file writes allows remote
writes allows remote clients
allows remote clients to
shows throughput in messages
remote clients to see
clients to see statems
s in experiments with
all losses occurring in
losses occurring in bursts
occurring in bursts of
in bursts of size
senders multicasting to a
bursts of size less
multicasting to a varying
to a varying number
of size less than
a varying number of
reads apache software foundation
size less than or
apache software foundation debian
varying number of receivers
less than or equal
software foundation debian linux
than or equal to
foundation debian linux community
or equal to b
all of which belong
equal to b are
of which belong to
to b are recovered
which belong to a
b are recovered with
belong to a single
are recovered with the
to a single group
recovered with the same
with the same latency
the same latency and
same latency and this
with a single sender
latency and this latency
and this latency depends
this latency depends on
latency depends on the
depends on the i
no rate limit was
on the i parameter
rate limit was used
tus changes to files
the sender has more
changes to files without
sender has more work
to files without having
has more work to
files without having to
more work to do
without having to wait
work to do than
we d like to
to do than the
having to wait for
d like to parameterize
to wait for intervening
do than the receivers
wait for intervening writequirement
than the receivers and
like to parameterize the
the receivers and on
for intervening writequirement that
to parameterize the encoding
receivers and on our
intervening writequirement that processes
and on our clusters
parameterize the encoding to
writequirement that processes wait
the encoding to tolerate
that processes wait for
encoding to tolerate a
processes wait for writes
to tolerate a maximum
isn t fast enough
tolerate a maximum burst
t fast enough to
a maximum burst length
fast enough to saturate
rather than sending an
enough to saturate the
than sending an back
to saturate the network
sending an back traffic
maximum burst length and
burst length and then
length and then have
and then have recovery
then have recovery latency
a similar motivation underlies
have recovery latency depend
similar motivation underlies the
recovery latency depend on
motivation underlies the cache
latency depend on the
underlies the cache consisupdate
depend on the actual
the cache consisupdate to
on the actual burstiness
cache consisupdate to the
the actual burstiness of
consisupdate to the server
actual burstiness of the
to the server as
burstiness of the loss
the server as soon
server as soon as
as soon as a
soon as a file
as a file is
a file is closed
at the same time
we report the highest
report the highest combined
the highest combined send
highest combined send rate
the cache manager tency
combined send rate that
cache manager tency scheme
we would like the
manager tency scheme for
send rate that the
tency scheme for high
would like the encoding
rate that the system
like the encoding to
that the system could
the encoding to have
the system could sustain
encoding to have a
system could sustain without
scheme for high read
could sustain without developing
to have a constant
sustain without developing backlogs
have a constant rate
without developing backlogs at
a constant rate for
developing backlogs at the
constant rate for network
write contention environments we
rate for network provisioning
backlogs at the senders
for network provisioning and
contention environments we logs
network provisioning and stability
environments we logs the
we logs the update
logs the update and
why does performance decrease
the update and periodically
does performance decrease with
update and periodically flushes
performance decrease with the
and periodically flushes logged
decrease with the number
periodically flushes logged updates
an fec scheme is
with the number of
fec scheme is required
the number of receivers
flushes logged updates to
scheme is required where
logged updates to the
is required where latency
updates to the describe
required where latency of
to the describe in
where latency of recovery
the describe in section
latency of recovery degrades
of recovery degrades gracefully
let s focus on
recovery degrades gracefully as
s focus on a
degrades gracefully as losses
gracefully as losses get
as losses get burstier
the chief complexity in
chief complexity in implementing
even as the encoding
complexity in implementing asynchronous
as the encoding overhead
in implementing asynchronous writeserver
the encoding overhead stays
encoding overhead stays constant
these systems enable logging
systems enable logging when
enable logging when bandwidth
logging when bandwidth is
shows that whereas receivers
when bandwidth is low
that whereas receivers are
whereas receivers are not
receivers are not cpu
to improve read performance
improve read performance and
read performance and reduce
performance and reduce write
and reduce write traffic
reduce write traffic by
and loss rates in
write traffic by aggregat
loss rates in this
rates in this experiment
back lies in resolving
lies in resolving dependencies
in resolving dependencies between
resolving dependencies between metadata
dependencies between metadata operations
between metadata operations ing
the sender is saturated
metadata operations ing updates
operations ing updates to
ing updates to the
updates to the same
and hence is the
to the same file
hence is the bottleneck
the same file in
same file in the
size of repository stored
file in the log
of repository stored in
in the log before
repository stored in s
the log before they
running this test again
log before they are
this test again in
before they are transmitted
test again in a
again in a profiler
in a profiler reveals
a profiler reveals that
and updates to the
profiler reveals that the
updates to the same
reveals that the percentage
to the same file
that the percentage of
so we based our
the percentage of time
we based our analysis
percentage of time spent
based our analysis on
of time spent in
our analysis on that
time spent in qsm
analysis on that along
spent in qsm code
on that along with
end flow control x
in qsm code is
flow control x appliance
qsm code is decreasing
control x appliance appliance
that along with the
a file may be
along with the assumption
file may be created
with the assumption each
x appliance appliance end
the assumption each revision
whereas more and more
assumption each revision data
more and more time
each revision data file
and more time is
revision data file would
more time is spent
data file would be
update logging separates communication
time is spent in
logging separates communication with
is spent in mscorwks
separates communication with the
communication with the server
with the server into
the server into modified
server into modified and
into modified and closed
and the length of
the length of the
length of the metadata
of the metadata queue
the metadata queue may
metadata queue may two
queue may two distinct
kib and each revision
may two distinct streams
and each revision property
each revision property file
updates to files and
to files and directories
split flow control fig
and all be enough
all be enough to
be enough to mean
enough to mean that
to mean that the
mean that the file
that the file update
the averages observed for
the file update would
flow control options in
file update would be
control options in maelstrom
update would be initiated
averages observed for the
would be initiated first
shows that the main
observed for the other
that the main culprit
for the other repositories
the main culprit behind
the other repositories in
main culprit behind the
other repositories in table
culprit behind the increase
repositories in table ii
behind the increase of
the increase of overhead
these two types of
increase of overhead is
two types of communication
of overhead is a
types of communication are
overhead is a figure
table ii m ost
of communication are scheduled
lan mtu lambda jumbo
communication are scheduled this
mtu lambda jumbo mtu
ii m ost recent
are scheduled this case
m ost recent monthly
scheduled this case the
ost recent monthly cost
this case the file
lambda jumbo mtu recipe
recent monthly cost of
jumbo mtu recipe list
monthly cost of storing
the percentages of the
cost of storing repositories
percentages of the profiler
of storing repositories in
case the file update
storing repositories in s
the file update must
of the profiler samples
file update must wait
the profiler samples taken
profiler samples taken from
samples taken from qsm
taken from qsm and
for individual projects and
from qsm and clr
qsm and clr dlls
individual projects and entire
projects and entire communities
and entire communities software
a file may be
entire communities software project
communities software project squirrelmail
software project squirrelmail phpmyadmin
project squirrelmail phpmyadmin subversion
test activity gc grep
squirrelmail phpmyadmin subversion mono
activity gc grep compile
phpmyadmin subversion mono kde
gc grep compile grep
subversion mono kde hosting
grep compile grep write
mono kde hosting community
compile grep write read
memory allocation and garbage
kde hosting community debian
grep write read compile
hosting community debian linux
write read compile read
community debian linux community
read compile read write
debian linux community apache
compile read write gw
linux community apache software
read write gw rc
community apache software foundation
write gw rc rw
allocation and garbage collection
gw rc rw synchronous
apache software foundation monthly
and garbage collection overheads
software foundation monthly cost
garbage collection overheads on
rc rw synchronous uniform
collection overheads on the
rw synchronous uniform priorities
overheads on the sender
on the sender node
the former grows by
and the latter by
this configuration is typical
configuration is typical of
is typical of the
typical of the host
of the host environment
the host environment expected
host environment expected for
environment expected for our
expected for our target
for our target applications
repair packets are injected
packets are injected into
are injected into stream
injected into stream transparently
into stream transparently iv
m aelstrom d esign
aelstrom d esign and
of the overhead is
d esign and i
the overhead is the
esign and i mplementation
overhead is the allocation
and i mplementation we
is the allocation of
i mplementation we describe
the allocation of byte
mplementation we describe the
allocation of byte arrays
we describe the maelstrom
of byte arrays to
describe the maelstrom appliance
byte arrays to send
the maelstrom appliance as
arrays to send in
maelstrom appliance as a
to send in the
appliance as a single
send in the application
as a single machine
a single machine later
we will show how
will show how more
show how more machines
how more machines can
more machines can be
machines can be added
can be added to
be added to the
added to the appliance
to the appliance to
the appliance to balance
appliance to balance encoding
to balance encoding load
balance encoding load and
encoding load and scale
load and scale to
and scale to multiple
scale to multiple gigabits
to multiple gigabits per
multiple gigabits per second
gigabits per second of
per second of traffic
even for the fairly
for the fairly large
the fairly large apache
fairly large apache software
large apache software foundation
basic mechanism the basic
mechanism the basic operation
the basic operation of
basic operation of maelstrom
the current cost of
operation of maelstrom is
current cost of using
of maelstrom is shown
cost of using s
maelstrom is shown in
is shown in figure
of time is spent
time is spent exclusively
is spent exclusively on
for storage is less
spent exclusively on copying
storage is less than
exclusively on copying memory
on copying memory in
copying memory in the
memory in the clr
it intercepts outgoing data
intercepts outgoing data packets
outgoing data packets and
data packets and routes
packets and routes them
it is very unlikely
and routes them to
routes them to the
even though we used
is very unlikely that
them to the destination
very unlikely that any
though we used our
unlikely that any vendor
we used our own
to the destination data
that any vendor could
the destination data center
used our own scatter
any vendor could provide
vendor could provide a
could provide a traditional
generating and injecting fec
gather serialization scheme that
and injecting fec repair
serialization scheme that efficiently
provide a traditional storage
scheme that efficiently uses
injecting fec repair packets
that efficiently uses scatter
fec repair packets into
a traditional storage solution
repair packets into the
traditional storage solution consisting
packets into the stream
storage solution consisting of
into the stream in
solution consisting of scsi
the stream in their
consisting of scsi disks
stream in their wake
of scsi disks and
scsi disks and tape
disks and tape backup
and tape backup at
tape backup at this
backup at this price
a repair packet consists
repair packet consists of
the increase in the
packet consists of a
increase in the memory
consists of a recipe
the amount of s
of a recipe list
in the memory allocation
a recipe list of
the memory allocation overhead
recipe list of data
memory allocation overhead and
storage required of course
list of data packet
required of course increases
allocation overhead and the
of course increases each
of data packet identifiers
course increases each month
overhead and the activity
increases each month as
data packet identifiers and
each month as the
and the activity of
month as the repository
packet identifiers and fec
as the repository grows
the activity of the
identifiers and fec information
activity of the garbage
and fec information generated
of the garbage collector
fec information generated from
the garbage collector are
but as shown in
garbage collector are caused
as shown in figure
collector are caused by
information generated from these
are caused by the
generated from these packets
caused by the increasing
by the increasing memory
the increasing memory usage
the increase is roughly
in the example in
increase is roughly linear
the example in figure
as developer productivity remains
developer productivity remains constant
reflectsan increase of the
increase of the average
this information is a
of the average number
information is a simple
the average number of
the cost of storage
average number of multicasts
cost of storage is
number of multicasts pending
of storage is declining
of multicasts pending completion
storage is declining exponentially
is a simple xor
the size of the
size of the xor
of the xor is
the xor is equal
so if amazon s
xor is equal to
if amazon s pricing
is equal to the
amazon s pricing stays
equal to the mtu
s pricing stays competitive
to the mtu of
the mtu of the
a copy is kept
mtu of the data
copy is kept by
of the data center
is kept by the
the data center network
kept by the sender
by the sender for
the sender for possible
sender for possible loss
term trend is towards
for possible loss recovery
trend is towards lower
is towards lower costs
and to avoid fragmentation
notice that memory consumption
to avoid fragmentation of
additional costs will be
that memory consumption grows
costs will be incurred
avoid fragmentation of repair
will be incurred for
memory consumption grows nearly
be incurred for front
fragmentation of repair packets
of repair packets we
repair packets we require
packets we require that
times faster than the
we require that the
faster than the number
require that the mtu
than the number of
that the mtu of
the number of messages
the mtu of the
number of messages pending
mtu of the long
for the case of
of messages pending acknowledgement
the case of ec
haul network be set
network be set to
if we freeze the
be set to a
we freeze the sender
set to a slightly
freeze the sender process
to a slightly larger
the sender process and
a slightly larger value
sender process and inspect
a standard machine instance
process and inspect the
standard machine instance is
and inspect the contents
machine instance is billed
inspect the contents of
instance is billed at
the contents of the
this requirement is easily
contents of the managed
requirement is easily satisfied
of the managed heap
is easily satisfied in
easily satisfied in practice
we find that the
since gigabit links very
find that the number
gigabit links very often
that the number of
links very often use
the number of objects
very often use jumbo
number of objects in
often use jumbo frames
of objects in memory
use jumbo frames of
objects in memory is
jumbo frames of up
in memory is more
frames of up to
memory is more than
is more than twice
plus data transfer of
more than twice the
than twice the number
twice the number of
the number of multicasts
number of multicasts pending
of multicasts pending acknowledgement
although some of these
some of these have
of these have already
these have already been
have already been acknowledged
per gib in and
they haven t yet
haven t yet been
t yet been garbage
yet been garbage collected
while lan networks have
the growing amount of
lan networks have standard
growing amount of unacknowledged
networks have standard mtus
amount of unacknowledged data
have standard mtus of
of unacknowledged data is
unacknowledged data is caused
data is caused by
is caused by the
caused by the increase
by the increase of
the increase of the
increase of the average
discounts are available if
of the average time
are available if data
the average time to
available if data transfer
average time to acknowledge
if data transfer exceeds
time to acknowledge a
to acknowledge a message
at the receiving data
the receiving data center
and the instance cost
the instance cost may
the appliance examines incoming
instance cost may be
appliance examines incoming repair
cost may be reduced
examines incoming repair packets
may be reduced to
incoming repair packets and
repair packets and uses
packets and uses them
and uses them to
this grows because of
uses them to recover
grows because of the
them to recover missing
because of the increasing
to recover missing data
of the increasing time
recover missing data packets
the increasing time to
increasing time to circulate
time to circulate a
to circulate a token
circulate a token around
a token around the
token around the region
around the region for
per hour by paying
the region for purposes
hour by paying a
region for purposes of
the data packet is
for purposes of state
data packet is injected
purposes of state aggregation
packet is injected transparently
is injected transparently into
injected transparently into the
transparently into the stream
into the stream to
the stream to the
stream to the receiving
to the receiving end
the time to acknowledge
year reservation fee in
time to acknowledge is
reservation fee in advance
recovered data packets will
to acknowledge is only
data packets will typically
acknowledge is only slightly
packets will typically arrive
is only slightly higher
will typically arrive out
only slightly higher than
this gives an amortized
slightly higher than the
gives an amortized monthly
higher than the expected
an amortized monthly cost
amortized monthly cost of
order at the end
s to wait until
to wait until the
wait until the next
until the next token
and hence it is
the next token round
hence it is vital
it is vital that
is vital that packets
plus the roundtrip time
vital that packets be
that packets be recovered
packets be recovered by
be recovered by the
as we scale up
recovered by the appliance
as we show in
by the appliance extremely
we show in the
the appliance extremely quickly
show in the next
appliance extremely quickly to
in the next section
extremely quickly to avoid
roundtrip time becomes dominant
quickly to avoid triggering
to avoid triggering mechanisms
avoid triggering mechanisms in
one instance should be
triggering mechanisms in commodity
instance should be enough
these experiments show that
should be enough for
mechanisms in commodity stacks
be enough for almost
in commodity stacks that
enough for almost any
commodity stacks that interpret
experiments show that the
for almost any individual
stacks that interpret out
almost any individual project
show that the critical
any individual project or
that the critical factor
individual project or moderately
the critical factor determining
project or moderately sized
critical factor determining performance
or moderately sized community
factor determining performance is
order arrival as congestion
determining performance is the
arrival as congestion in
performance is the time
as congestion in the
is the time needed
congestion in the network
the time needed for
time needed for the
needed for the system
usage patterns in addition
for the system to
patterns in addition to
the system to aggregate
in addition to getting
system to aggregate state
addition to getting a
flow control while relaying
to aggregate state over
to getting a grasp
control while relaying tcp
aggregate state over regions
getting a grasp of
a grasp of the
grasp of the costs
of the costs involved
the costs involved in
costs involved in moving
involved in moving a
in moving a repository
maelstrom has two flow
they shed light on
has two flow control
shed light on a
two flow control modes
light on a mechanism
moving a repository to
on a mechanism that
a repository to s
a mechanism that links
mechanism that links latency
that links latency to
links latency to throughput
via increased memory consumption
it is important to
increased memory consumption and
is important to understand
memory consumption and the
important to understand the
consumption and the resulting
to understand the usage
and the resulting increase
understand the usage patterns
the resulting increase in
resulting increase in allocation
illustrates these two modes
increase in allocation and
in allocation and garbage
especially the rate at
allocation and garbage collection
the rate at which
and garbage collection overheads
rate at which commits
at which commits take
which commits take place
since achieving the consistency
achieving the consistency properties
the consistency properties that
consistency properties that developers
properties that developers expect
that developers expect will
developers expect will require
ms increase in latency
expect will require a
will require a consistency
require a consistency layer
a consistency layer to
consistency layer to be
layer to be built
the appliance treats tcp
to be built in
be built in front
built in front of
in front of s
ip packets as conventional
mb increase in memory
packets as conventional ip
increase in memory consumption
as conventional ip packets
conventional ip packets and
ip packets and routes
packets and routes them
it is crucial that
and routes them through
is crucial that any
routes them through without
can inflate overheads by
crucial that any such
them through without modification
that any such layer
any such layer be
such layer be able
layer be able to
be able to handle
able to handle the
to handle the load
handle the load of
control to proceed between
the load of commits
to proceed between the
proceed between the end
the critical statistic to
critical statistic to consider
statistic to consider is
to consider is the
consider is the number
is the number of
the number of simultaneous
number of simultaneous commits
and degrade the throughput
degrade the throughput by
for centralized revision control
ip s semantics are
centralized revision control system
s semantics are not
revision control system such
semantics are not modified
control system such as
system such as subversion
when the sending endhost
each commit is assigned
the sending endhost receives
commit is assigned a
sending endhost receives an
is assigned a unique
endhost receives an acknowledgment
one way to alleviate
way to alleviate the
to alleviate the problem
alleviate the problem we
it can assume that
can assume that the
assume that the receiving
that the receiving end
and any change to
ve identified could be
any change to a
identified could be to
change to a versioned
could be to reduce
host successfully received the
be to reduce the
successfully received the message
to reduce the latency
to a versioned file
reduce the latency of
a versioned file is
the latency of state
versioned file is stored
latency of state aggregation
file is stored as
is stored as a
stored as a diff
as a diff against
a diff against its
so that it grows
diff against its previous
that it grows sub
against its previous version
maelstrom functions as a
functions as a passive
as a passive device
a commit must be
commit must be rejected
must be rejected if
snooping outgoing and incoming
be rejected if any
outgoing and incoming traffic
this might be achieved
rejected if any of
might be achieved by
and incoming traffic at
if any of the
be achieved by using
incoming traffic at the
achieved by using a
any of the versioned
by using a deeper
traffic at the data
using a deeper hierarchy
of the versioned files
a deeper hierarchy of
at the data center
deeper hierarchy of rings
the versioned files that
the data center s
versioned files that it
data center s edge
files that it touches
center s edge its
and by letting tokens
that it touches have
s edge its failure
by letting tokens in
edge its failure does
letting tokens in each
its failure does not
tokens in each of
it touches have been
failure does not disrupt
touches have been changed
does not disrupt the
have been changed in
not disrupt the flow
been changed in an
disrupt the flow of
in each of these
the flow of packets
changed in an earlier
each of these rings
flow of packets between
of these rings circulate
in an earlier revision
of packets between the
an earlier revision that
packets between the two
these rings circulate independently
between the two data
earlier revision that the
the two data centers
revision that the developer
that the developer performing
the developer performing the
this would create a
developer performing the commit
would create a more
performing the commit was
create a more complex
the commit was unaware
a more complex structure
commit was unaware of
but aggregation latency would
aggregation latency would grow
this ensures that every
latency would grow logarithmically
side appliance acts as
would grow logarithmically rather
appliance acts as a
grow logarithmically rather than
acts as a tcp
ensures that every conflict
logarithmically rather than linearly
that every conflict gets
every conflict gets resolved
conflict gets resolved by
gets resolved by a
is reducing state aggregation
resolved by a human
reducing state aggregation latency
by a human before
state aggregation latency the
terminating connections and sending
a human before becoming
aggregation latency the only
human before becoming part
connections and sending back
before becoming part of
latency the only option
becoming part of the
and sending back acks
part of the repository
sending back acks immediately
of the repository s
back acks immediately before
the repository s state
acks immediately before relaying
we evaluated two alternative
immediately before relaying data
evaluated two alternative approaches
before relaying data on
relaying data on appliance
but found that neither
exclusive locking is required
found that neither can
locking is required on
that neither can substitute
is required on commits
neither can substitute for
can substitute for lowering
split mode is extremely
substitute for lowering the
mode is extremely useful
for lowering the latency
is extremely useful when
lowering the latency of
extremely useful when endhosts
the latency of the
useful when endhosts have
latency of the recovery
taking a loose definition
of the recovery state
when endhosts have limited
the recovery state aggregation
a loose definition of
endhosts have limited buffering
loose definition of simultaneous
have limited buffering capacity
definition of simultaneous to
our first approach varies
of simultaneous to be
first approach varies the
simultaneous to be within
since it allows the
to be within one
it allows the receive
be within one minute
approach varies the rate
varies the rate of
the rate of aggregation
rate of aggregation by
side appliance to buffer
the apache repository had
appliance to buffer incoming
apache repository had a
to buffer incoming data
repository had a maximum
buffer incoming data over
had a maximum of
of aggregation by increasing
incoming data over the
aggregation by increasing the
data over the highspeed
by increasing the rate
over the highspeed long
increasing the rate at
simultaneous commits and the
the rate at which
commits and the debian
rate at which tokens
and the debian community
at which tokens are
which tokens are released
ignoring for now that
it also mitigates tcp
for now that their
now that their use
that their use of
start effects for short
separate repositories allows for
this helps only up
repositories allows for finergrained
helps only up to
allows for finergrained locking
only up to a
up to a point
maelstrom has to operate
has to operate as
an aggregate maximum of
to operate as an
operate as an active
as an active device
inserted into the critical
into the critical communication
in determining these numbers
the critical communication path
determining these numbers we
critical communication path its
these numbers we filtered
communication path its failure
numbers we filtered out
path its failure disconnects
we filtered out any
its failure disconnects the
filtered out any sequences
failure disconnects the communication
more than one aggregation
out any sequences of
than one aggregation is
disconnects the communication path
one aggregation is underway
any sequences of multiple
aggregation is underway at
the communication path between
sequences of multiple commits
is underway at a
communication path between the
of multiple commits by
path between the two
underway at a time
between the two data
multiple commits by the
the two data centers
commits by the same
and successive tokens perform
by the same author
successive tokens perform redundant
the same author during
tokens perform redundant work
same author during a
author during a one
during a one minute
while maelstrom respects endto
a one minute period
one minute period since
minute period since those
processing all these tokens
period since those were
end flow control connections
all these tokens is
since those were likely
these tokens is costly
those were likely sequential
were likely sequential rather
or splits them and
likely sequential rather than
splits them and implements
sequential rather than simultaneous
them and implements its
rather than simultaneous and
and implements its own
than simultaneous and do
implements its own proxy
simultaneous and do nor
and do nor represent
do nor represent the
nor represent the common
represent the common case
proxy flow control as
flow control as described
the average rates were
s decreases the amount
control as described above
decreases the amount of
the amount of unacknowledged
amount of unacknowledged data
of unacknowledged data by
it is not designed
is not designed for
not designed for routinely
designed for routinely congested
for routinely congested networks
the addition of fec
addition of fec under
of fec under tcp
but increases throughput by
increases throughput by less
throughput by less than
ip flow control allows
flow control allows it
control allows it to
allows it to steal
it to steal bandwidth
to steal bandwidth from
steal bandwidth from other
bandwidth from other competing
from other competing flows
other competing flows running
so exclusive locking for
competing flows running without
exclusive locking for commits
flows running without fec
locking for commits should
running without fec in
for commits should not
without fec in the
commits should not pose
fec in the link
time spent allocating byte
should not pose any
spent allocating byte arrays
not pose any scalability
allocating byte arrays in
pose any scalability problems
byte arrays in the
any scalability problems in
though maintaining fairness versus
scalability problems in a
arrays in the application
problems in a typical
maintaining fairness versus similarly
in a typical environment
fairness versus similarly fec
we did not consider
did not consider the
not consider the rate
consider the rate of
the rate of read
rate of read operations
of read operations because
read operations because clients
operations because clients updating
because clients updating their
clients updating their working
updating their working copies
memory used on sender
used on sender and
on sender and the
sender and the number
or reading from the
and the number of
reading from the repository
the number of multicast
number of multicast requests
of multicast requests in
multicast requests in progress
friendliness with conventional tcp
do not require a
not require a lock
ip flows is not
flows is not a
the debian community today
is not a primary
debian community today uses
not a primary protocol
community today uses only
a primary protocol design
today uses only a
primary protocol design goal
uses only a single
protocol design goal on
only a single subversion
design goal on over
a single subversion server
token roundtrip time and
roundtrip time and an
time and an average
and an average time
an average time to
and the apache foundation
average time to acknowledge
the apache foundation has
time to acknowledge a
apache foundation has a
to acknowledge a message
foundation has a master
has a master server
a master server plus
which are often dedicated
master server plus a
are often dedicated to
server plus a european
often dedicated to specific
plus a european mirror
dedicated to specific highvalue
to specific highvalue applications
primarily for latency reasons
we see evidence for
see evidence for this
varying token circulation rate
evidence for this assertion
for this assertion in
this assertion in the
assertion in the routine
in the routine use
we expect that most
the routine use of
expect that most communities
routine use of parallel
that most communities will
use of parallel flows
most communities will have
communities will have at
will have at most
have at most a
at most a handful
most a handful of
a handful of front
our second approach increased
second approach increased the
approach increased the amount
increased the amount of
the amount of feedback
amount of feedback to
of feedback to the
feedback to the sender
and udp blast protocols
achieving consistency amazon s
in our base implementation
consistency amazon s infrastructure
amazon s infrastructure is
s infrastructure is built
infrastructure is built on
is built on the
each aggregate ack contains
built on the principle
aggregate ack contains a
on the principle of
ack contains a single
the principle of eventual
contains a single value
principle of eventual consistency
a single value maxcontiguous
representing the maximum number
the maximum number such
maximum number such that
number such that messages
such that messages with
that messages with this
messages with this and
with this and all
this and all lower
and does not directly
and all lower numbers
does not directly support
all lower numbers are
not directly support the
lower numbers are stable
directly support the locking
numbers are stable in
support the locking required
are stable in the
the locking required for
stable in the region
locking required for revision
required for revision control
to increase the amount
originally developed to run
increase the amount of
developed to run the
the amount of feedback
to run the company
run the company s
the company s own
company s own online
both in commercial deployments
s own online store
we permit ack to
in commercial deployments and
permit ack to contain
commercial deployments and by
ack to contain up
deployments and by researchers
to contain up to
the system preferred availability
contain up to k
and by researchers seeking
system preferred availability over
by researchers seeking to
up to k numeric
researchers seeking to transfer
to k numeric ranges
preferred availability over consistency
seeking to transfer large
availability over consistency because
to transfer large amounts
over consistency because downtime
transfer large amounts of
consistency because downtime translated
large amounts of data
because downtime translated directly
amounts of data over
downtime translated directly into
of data over high
translated directly into lost
directly into lost revenue
customers may opt to
may opt to shop
opt to shop elsewhere
to shop elsewhere or
shop elsewhere or to
layered interleaving in layered
elsewhere or to simply
interleaving in layered interleaving
or to simply forgo
to simply forgo impulse
simply forgo impulse purchases
forgo impulse purchases that
an fec protocol with
impulse purchases that they
fec protocol with rate
purchases that they didn
that they didn t
they didn t really
didn t really need
t really need anyway
an inconsistent shopping cart
is produced by running
produced by running c
by running c multiple
running c multiple instances
c multiple instances of
multiple instances of an
could be resolved by
be resolved by heuristics
resolved by heuristics or
by heuristics or user
intervention at checkout time
it is well known
fec protocol simultaneously with
is well known that
protocol simultaneously with increasing
well known that consistency
simultaneously with increasing interleave
the system can now
with increasing interleave indices
known that consistency and
increasing interleave indices i
system can now cleanup
that consistency and availability
can now cleanup message
now cleanup message sequences
consistency and availability cannot
cleanup message sequences that
message sequences that have
and availability cannot both
sequences that have as
that have as gaps
availability cannot both be
cannot both be achieved
both be achieved simultaneously
be achieved simultaneously in
messages that are still
achieved simultaneously in any
that are still unstable
simultaneously in any real
in any real network
any real network where
real network where hosts
network where hosts or
where hosts or entire
hosts or entire subnetworks
in the experiment shown
or entire subnetworks are
the experiment shown in
entire subnetworks are sometimes
experiment shown in figures
subnetworks are sometimes unreachable
are sometimes unreachable due
sometimes unreachable due to
unreachable due to connectivity
due to connectivity losses
we set k to
set k to the
if a cloud service
k to the number
a cloud service is
to the number of
cloud service is designed
the number of partitions
service is designed to
is designed to provide
designed to provide high
to provide high availability
provide high availability but
high availability but an
availability but an application
but an application instead
while the amount of
an application instead requires
the amount of acknowledged
application instead requires perfect
amount of acknowledged data
instead requires perfect consistency
of acknowledged data is
acknowledged data is reduced
data is reduced by
additional software infrastructure is
software infrastructure is required
infrastructure is required to
is required to bridge
required to bridge the
to bridge the gap
for revision control it
revision control it makes
control it makes sense
it makes sense to
makes sense to adopt
sense to adopt eventual
to adopt eventual consistency
adopt eventual consistency for
and the overall throughput
eventual consistency for read
the overall throughput is
consistency for read operations
overall throughput is actually
throughput is actually lower
is actually lower because
actually lower because token
lower because token processing
since at worst an
because token processing becomes
at worst an earlier
token processing becomes more
worst an earlier revision
processing becomes more costly
an earlier revision will
earlier revision will fig
the system becomes unstable
system architecture be returned
notice the large variances
the large variances in
large variances in figure
if the user is
the user is aware
through some other channel
that a newer version
a newer version should
newer version should exist
because our flow control
our flow control scheme
based on limiting the
three instances of an
on limiting the amount
he can retry and
limiting the amount of
can retry and expect
the amount of unacknowledged
retry and expect that
amount of unacknowledged data
and expect that version
expect that version to
that version to be
version to be available
to be available within
be available within a
available within a short
within a short timeframe
while the sender can
the sender can cleanup
sender can cleanup any
can cleanup any portion
cleanup any portion of
any portion of the
portion of the message
of the message sequence
the first instance with
first instance with interleave
perfect consistency is required
instance with interleave i
receivers have to deliver
consistency is required and
have to deliver in
is required and a
to deliver in fifo
required and a locking
deliver in fifo order
and a locking layer
a locking layer must
locking layer must be
layer must be built
must be built to
the amount of data
be built to support
amount of data they
built to support this
of data they cache
data they cache is
they cache is larger
the second with interleave
second with interleave i
this may result in
may result in a
and this reduces their
result in a commit
this reduces their ability
in a commit being
reduces their ability to
a commit being rejected
their ability to accept
commit being rejected if
ability to accept incoming
being rejected if consensus
to accept incoming traffic
rejected if consensus cannot
if consensus cannot be
consensus cannot be reached
notice the linkage to
the linkage to memory
and the third with
but shouldn t be
the third with interleave
shouldn t be a
third with interleave i
t be a problem
be a problem because
a problem because code
the growth in memory
problem because code changes
growth in memory occurs
because code changes are
in memory occurs on
code changes are usually
memory occurs on the
changes are usually not
occurs on the receivers
are usually not impulse
usually not impulse decisions
not impulse decisions and
impulse decisions and the
decisions and the commit
but the pattern is
and the commit can
the pattern is similar
the commit can be
pattern is similar to
commit can be retried
is similar to what
can be retried later
similar to what we
to what we saw
what we saw earlier
merely having more cached
d esign as a
having more cached data
esign as a proof
more cached data is
cached data is enough
data is enough to
is enough to slow
enough to slow them
to slow them down
fec encoding is simply
encoding is simply an
is simply an xor
simply an xor of
an xor of the
xor of the r
of the r data
the r data packets
token roundtrip time increases
r data packets hence
in layered interleaving each
a tool for integrating
layered interleaving each data
tool for integrating subversion
interleaving each data packet
for integrating subversion with
each data packet is
integrating subversion with s
data packet is included
this delays state aggregation
packet is included in
is included in c
included in c xors
increases pending messages and
pending messages and reduces
messages and reduces throughput
each of which is
of which is generated
which is generated at
vn is colocated with
is generated at different
is colocated with subversion
generated at different interleaves
colocated with subversion and
at different interleaves from
with subversion and inserts
different interleaves from the
subversion and inserts a
interleaves from the original
and inserts a layer
from the original data
inserts a layer between
the original data stream
a layer between subversion
layer between subversion and
between subversion and s
as we shall describe
we shall describe shortly
as shown in figure
ensures that the c
that the c xors
the c xors containing
more aggressive cleanup with
c xors containing a
aggressive cleanup with o
for simplicity we did
xors containing a data
simplicity we did not
containing a data packet
we did not modify
a data packet do
did not modify the
data packet do not
not modify the subversion
packet do not have
modify the subversion server
do not have any
feedback in the token
not have any other
in the token and
have any other data
the token and in
any other data packet
token and in acks
the subversion server in
other data packet in
subversion server in any
data packet in common
server in any way
the resulting protocol effectively
resulting protocol effectively has
protocol effectively has a
effectively has a rate
has a rate of
vn is responsible for
is responsible for receiving
responsible for receiving event
more work with o
for receiving event notifications
receiving event notifications from
event notifications from subversion
notifications from subversion and
from subversion and transferring
subversion and transferring data
and transferring data between
transferring data between the
data between the local
between the local disk
the local disk on
and lower rates despite
local disk on the
lower rates despite saving
disk on the ec
rates despite saving on
with each xor generated
despite saving on memory
performance of mfs priorities
each xor generated from
of mfs priorities and
xor generated from r
mfs priorities and writeback
generated from r data
priorities and writeback schemes
from r data packets
r data packets and
data packets and each
packets and each data
and each data packet
each test consists of
each data packet included
test consists of two
data packet included in
consists of two concurrent
packet included in c
of two concurrent processes
included in c xors
vn at the start
memory overheads on the
at the start and
two concurrent processes executing
the start and end
overheads on the receiver
start and end of
concurrent processes executing different
on the receiver the
processes executing different workloads
and end of each
the receiver the reader
end of each commit
illustrates layered interleaving for
receiver the reader may
layered interleaving for a
the reader may doubt
mean times to completion
reader may doubt that
times to completion are
may doubt that memory
to completion are shown
doubt that memory overhead
completion are shown with
that memory overhead on
are shown with standard
memory overhead on receivers
shown with standard deviations
overhead on receivers is
vn acquires and releases
on receivers is the
acquires and releases locks
receivers is the real
and releases locks using
is the real issue
releases locks using yahoo
locks using yahoo s
using yahoo s open
yahoo s open source
three different policies for
s open source zookeeper
different policies for writing
open source zookeeper lock
policies for writing back
source zookeeper lock service
for writing back files
considering that their cpus
writing back files are
that their cpus are
back files are listed
their cpus are half
the difficulty achieving consistency
difficulty achieving consistency with
achieving consistency with a
under uniform or differentiated
consistency with a service
uniform or differentiated priorities
with a service such
a service such as
service such as amazon
such as amazon s
reads take precedence over
as amazon s s
take precedence over writes
stems from the fact
from the fact that
values in bold are
the fact that files
in bold are of
can increasing memory consumption
fact that files pushed
increasing memory consumption affect
bold are of particular
memory consumption affect a
are of particular significance
consumption affect a half
that files pushed into
files pushed into the
pushed into the storage
into the storage cloud
note that elapsed times
the storage cloud do
that elapsed times for
storage cloud do not
elapsed times for write
cloud do not simultaneously
times for write workloads
do not simultaneously become
for write workloads give
not simultaneously become available
we performed an experiment
simultaneously become available on
performed an experiment with
become available on all
write workloads give the
available on all service
workloads give the time
on all service endpoints
give the time until
the time until the
time until the process
until the process running
standard fec schemes can
the process running the
if a file is
fec schemes can be
a file is overwritten
process running the workload
schemes can be made
running the workload finishes
can be made resistant
be made resistant to
different clients may read
made resistant to a
clients may read back
resistant to a certain
not when the log
to a certain loss
when the log is
in which we vary
the log is flushed
may read back different
which we vary the
read back different versions
we vary the number
a certain loss burst
vary the number of
certain loss burst length
this is shown in
the number of receivers
is shown in figure
loss burst length at
number of receivers that
burst length at the
of receivers that cache
length at the cost
receivers that cache a
and even the same
that cache a copy
at the cost of
even the same client
the cost of increased
cache a copy of
cost of increased recovery
a copy of each
the same client may
copy of each message
of increased recovery latency
modified and then deleted
increased recovery latency for
same client may see
recovery latency for all
client may see the
latency for all lost
may see the old
for all lost packets
which requires the file
see the old version
replication factor in figure
the old version if
requires the file update
old version if it
the file update rpc
version if it suddenly
including smaller bursts and
if it suddenly switches
smaller bursts and singleton
it suddenly switches to
bursts and singleton drops
file update rpc to
suddenly switches to speaking
update rpc to be
switches to speaking with
rpc to be cancelled
to speaking with a
to be cancelled if
speaking with a different
be cancelled if it
increasing this value results
cancelled if it is
this value results in
if it is still
with a different s
it is still in
value results in a
is still in transmission
layered interleaving provides graceful
still in transmission when
results in a linear
interleaving provides graceful degradation
in a linear increase
in transmission when the
a linear increase of
transmission when the remove
linear increase of memory
when the remove rpc
increase of memory usage
the remove rpc is
of memory usage on
remove rpc is initiated
memory usage on receivers
provides graceful degradation in
the file will always
graceful degradation in the
file will always be
degradation in the face
an update to a
will always be internally
update to a file
in the face of
to a file will
always be internally consistent
a file will supersede
the face of bursty
file will supersede any
if memory overheads were
face of bursty loss
memory overheads were not
will supersede any previous
overheads were not a
supersede any previous queued
were not a significant
any previous queued updates
not a significant issue
of bursty loss for
a significant issue on
since put and get
bursty loss for constant
put and get operations
significant issue on half
and get operations are
loss for constant encoding
get operations are atomic
for constant encoding overhead
compiles the entire mfs
constant encoding overhead singleton
the entire mfs file
encoding overhead singleton random
but its contents may
overhead singleton random losses
entire mfs file system
singleton random losses are
mfs file system and
random losses are recovered
file system and its
losses are recovered as
its contents may not
are recovered as quickly
system and its rpc
we would expect performance
contents may not reflect
would expect performance to
and its rpc library
expect performance to remain
may not reflect expectations
recovered as quickly as
not reflect expectations that
as quickly as possible
performance to remain unchanged
reflect expectations that the
expectations that the client
that the client formed
the client formed based
by xors generated with
client formed based on
xors generated with an
formed based on other
generated with an interleave
based on other files
with an interleave of
on other files and
we see a dramatic
other files and out
files and out of
files and directories comprising
and out of band
out of band communication
and each successive layer
linear increase of the
each successive layer of
increase of the token
successive layer of xors
of the token roundtrip
layer of xors generated
vn works around the
the token roundtrip time
works around the consistency
of xors generated at
around the consistency problem
xors generated at a
the consistency problem by
generated at a higher
consistency problem by storing
a slow increase of
problem by storing the
slow increase of the
by storing the number
at a higher interleave
storing the number of
increase of the number
none of the files
the number of the
of the files are
number of the latest
the files are initially
of the number of
a higher interleave catches
the number of messages
files are initially in
number of messages pending
higher interleave catches larger
of messages pending ack
are initially in the
messages pending ack on
initially in the cache
pending ack on the
interleave catches larger bursts
of the latest revision
catches larger bursts missed
the latest revision into
larger bursts missed by
latest revision into zookeeper
bursts missed by the
this workload performs an
ack on the sender
workload performs an intensive
missed by the previous
performs an intensive pattern
by the previous layer
an intensive pattern of
intensive pattern of reads
pattern of reads and
and a sharp decrease
of reads and writes
a sharp decrease in
reads and writes files
sharp decrease in throughput
even if multiple files
the implementation of this
if multiple files were
and writes files without
multiple files were changed
implementation of this algorithm
writes files without raising
of this algorithm is
files were changed by
this algorithm is simple
were changed by the
algorithm is simple and
changed by the client
is simple and shown
files without raising the
simple and shown in
without raising the issue
and shown in figure
raising the issue of
is represented by subversion
the issue of concurrent
represented by subversion has
issue of concurrent accesses
by subversion has a
subversion has a single
the underlying mechanism is
has a single file
underlying mechanism is as
a single file containing
mechanism is as follows
single file containing binary
a topic we tackle
file containing binary diffs
topic we tackle in
containing binary diffs against
a set of repair
binary diffs against earlier
we tackle in section
diffs against earlier revisions
the increased activity of
set of repair bins
increased activity of the
of repair bins is
activity of the garbage
repair bins is maintained
a revision is never
of the garbage collector
revision is never changed
bins is maintained for
is never changed after
is maintained for each
never changed after the
maintained for each layer
changed after the fact
the garbage collector and
garbage collector and allocation
collector and allocation overheads
with i bins for
and allocation overheads slow
i bins for a
allocation overheads slow the
bins for a layer
overheads slow the system
for a layer with
slow the system down
a layer with interleave
the system down and
layer with interleave i
system down and processing
end server attempting to
performance evaluation of these
down and processing of
evaluation of these workloads
a repair bin consists
server attempting to fetch
repair bin consists of
attempting to fetch a
bin consists of a
to fetch a revision
consists of a partially
we classified grep and
fetch a revision i
classified grep and read
a revision i from
grep and read as
and processing of the
and read as foreground
processing of the incoming
read as foreground workloads
of the incoming packets
revision i from s
the incoming packets and
of a partially constructed
incoming packets and tokens
a partially constructed repair
packets and tokens takes
and compile and write
will receive either the
and tokens takes more
partially constructed repair packet
compile and write as
receive either the one
and write as background
either the one true
write as background workloads
tokens takes more time
an xor and the
xor and the recipe
and the recipe list
the recipe list of
four combined workloads were
recipe list of identifiers
although the effect is
list of identifiers of
or a missing file
of identifiers of data
the effect is not
combined workloads were then
effect is not significant
identifiers of data packets
is not significant when
of data packets that
not significant when considering
data packets that compose
significant when considering a
packets that compose the
when considering a single
that compose the xor
considering a single node
workloads were then generated
a missing file error
were then generated by
a single node in
then generated by running
single node in isolation
generated by running a
each intercepted data packet
by running a foreground
missing file error if
running a foreground and
intercepted data packet is
file error if i
a foreground and a
error if i was
data packet is added
if i was posted
foreground and a background
packet is added to
i was posted so
is added to each
was posted so recently
a token must visit
posted so recently that
added to each layer
so recently that it
and a background workload
to each layer where
a background workload concurrently
token must visit all
recently that it has
must visit all nodes
that it has not
visit all nodes in
each layer where adding
all nodes in a
we denote these as
nodes in a region
denote these as gc
in a region to
layer where adding to
a region to aggregate
where adding to a
region to aggregate the
adding to a layer
to aggregate the recovery
to a layer simply
aggregate the recovery state
a layer simply means
layer simply means choosing
simply means choosing a
means choosing a repair
choosing a repair bin
and delays are cumulative
a repair bin from
repair bin from the
bin from the layer
from the layer s
the layer s set
qsm is configured so
incrementally updating the xor
is configured so that
updating the xor with
configured so that five
the xor with the
so that five nodes
xor with the new
that five nodes in
with the new data
five nodes in each
the new data packet
nodes in each region
in each region cache
each region cache each
region cache each packet
and adding the data
adding the data packet
the data packet s
if half the nodes
data packet s header
half the nodes in
packet s header to
the nodes in a
s header to the
header to the recipe
to the recipe list
a counter is incremented
counter is incremented as
is incremented as each
incremented as each data
as each data packet
each data packet arrives
data packet arrives at
packet arrives at the
arrives at the appliance
node region cache each
region cache each figure
three types of rpcs
types of rpcs predominate
and choosing the repair
choosing the repair bin
the repair bin from
repair bin from the
bin from the layer
from the layer s
fetches of file data
the layer s set
layer s set is
s set is done
set is done by
and store operations for
is done by taking
store operations for files
done by taking the
by taking the modulo
taking the modulo of
the modulo of the
in descending order of
modulo of the counter
descending order of priority
of the counter with
the counter with the
counter with the number
with the number of
the number of bins
the aim of the
number of bins in
of bins in each
aim of the experiments
bins in each layer
of the experiments was
varying the number of
the experiments was to
the number of caching
experiments was to demonstrate
number of caching replicas
for a layer with
of caching replicas per
a layer with interleave
caching replicas per message
was to demonstrate that
replicas per message in
to demonstrate that priorities
per message in a
demonstrate that priorities improve
that priorities improve the
priorities improve the performance
improve the performance of
the performance of the
performance of the foreground
of the foreground workloads
the xth intercepted packet
xth intercepted packet is
intercepted packet is added
packet is added to
the four combined workloads
is added to the
four combined workloads were
combined workloads were executed
workloads were executed on
were executed on top
as the replication factor
executed on top of
the replication factor increasess
on top of mfs
top of mfs configured
of mfs configured with
mfs configured with either
configured with either synchronous
the sender s flow
with either synchronous writes
sender s flow control
end servers are equivalent
s flow control policy
servers are equivalent and
flow control policy kicks
are equivalent and clients
update logging or asynchronous
equivalent and clients may
logging or asynchronous writeback
control policy kicks in
and clients may interact
when a repair bin
clients may interact with
a repair bin fills
may interact with any
the update logging mechanism
repair bin fills up
update logging mechanism was
interact with any of
logging mechanism was configured
with any of them
and the system goes
bin fills up its
mechanism was configured to
fills up its recipe
was configured to delay
up its recipe list
configured to delay flushing
its recipe list contains
to delay flushing an
recipe list contains r
delay flushing an update
list contains r data
flushing an update for
any of them fig
an update for at
contains r data packets
the system goes into
r data packets it
update for at least
data packets it fires
for at least a
at least a second
a repair packet is
every experiment was repeated
repair packet is generated
experiment was repeated ten
packet is generated consisting
was repeated ten times
is generated consisting of
e valuation we observe
generated consisting of the
valuation we observe that
repeated ten times at
we observe that running
consisting of the xor
observe that running multiple
ten times at each
that running multiple front
of the xor and
a form of the
the xor and the
times at each of
xor and the recipe
at each of five
and the recipe list
each of five possible
the recipe list and
of five possible bandwidth
recipe list and is
five possible bandwidth values
which cloud computing makes
list and is scheduled
cloud computing makes easy
form of the oscillating
computing makes easy to
and is scheduled for
of the oscillating state
is scheduled for sending
makes easy to do
the oscillating state we
oscillating state we encountered
state we encountered in
shows the time taken
we encountered in figure
while the repair bin
increases the throughput of
the repair bin is
the throughput of read
repair bin is re
throughput of read operations
the time taken for
time taken for each
taken for each workload
for each workload at
initialized with an empty
each workload at a
with an empty recipe
vn by running a
an empty recipe list
by running a fixed
empty recipe list and
running a fixed number
recipe list and blank
a fixed number of
list and blank xor
fixed number of clients
workload at a bandwidth
the amount of memory
at a bandwidth of
amount of memory in
of memory in use
each repeatedly checking out
memory in use at
repeatedly checking out about
in use at the
use at the sender
at the sender ceases
the sender ceases to
incoming repair packets are
sender ceases to be
repair packets are processed
ceases to be a
packets are processed as
to be a good
are processed as follows
be a good predictor
a good predictor of
good predictor of the
predictor of the amount
of the amount of
if all the data
the amount of memory
all the data packets
amount of memory in
the data packets contained
of memory in use
data packets contained in
memory in use at
packets contained in the
in use at receivers
contained in the repair
shows overall results for
in the repair s
overall results for selected
the repair s recipe
results for selected configurations
repair s recipe list
s recipe list have
violating what turns out
recipe list have been
what turns out to
list have been received
turns out to be
have been received successfully
out to be an
the results in table
to be an implicit
be an implicit requirement
an implicit requirement of
implicit requirement of our
the repair packet is
requirement of our flow
repair packet is discarded
demonstrate the benefit of
the benefit of priorities
benefit of priorities when
of priorities when there
priorities when there is
if the repair s
when there is high
the repair s recipe
there is high contention
repair s recipe list
is high contention between
s recipe list contains
high contention between high
recipe list contains a
list contains a single
contains a single missing
yet propagated through s
a single missing data
single missing data packet
priority rpcs and writes
recovery can occur immediately
overheads in a perturbed
in the latter case
can occur immediately by
in a perturbed system
in both the i
a perturbed system the
perturbed system the reader
the server retries indefinitely
system the reader might
server retries indefinitely until
the reader might wonder
retries indefinitely until the
reader might wonder whether
indefinitely until the file
bound gw and rw
might wonder whether our
gw and rw workloads
until the file is
wonder whether our results
the file is available
whether our results would
our results would be
adding priorities decreases the
results would be different
zookeeper ensures that the
priorities decreases the time
ensures that the latest
would be different if
that the latest revision
decreases the time required
the latest revision number
be different if the
latest revision number is
the time required for
revision number is incremented
different if the system
number is incremented atomically
time required for the
if the system experienced
required for the foreground
the system experienced high
for the foreground workload
system experienced high loss
the foreground workload to
experienced high loss rates
zookeeper maintains a simple
high loss rates or
foreground workload to execute
loss rates or was
maintains a simple filesystem
rates or was otherwise
a simple filesystem like
or was otherwise perturbed
simple filesystem like tree
filesystem like tree of
like tree of nodes
nodes may store a
may store a small
store a small amount
we performed an experiment
a small amount of
performed an experiment in
small amount of data
an experiment in which
amount of data and
experiment in which one
of data and can
in which one of
data and can have
which one of the
and can have children
see elapsed times for
one of the receiver
elapsed times for rw
of the receiver nodes
the receiver nodes experiences
receiver nodes experiences a
nodes experiences a periodic
read with synchronous writes
with synchronous writes in
vn stores the latest
synchronous writes in the
stores the latest revision
writes in the table
the latest revision number
latest revision number in
s the node sleeps
the node sleeps for
this is particularly true
is particularly true in
particularly true in the
true in the rw
in the rw test
where the foreground workload
the foreground workload generates
foreground workload generates heavy
workload generates heavy contention
generates heavy contention by
heavy contention by fetching
contention by fetching a
this simulates the effect
by fetching a large
simulates the effect of
fetching a large volume
the effect of disruptive
a large volume of
large volume of data
supporting multiple named repositories
multiple named repositories in
the greatest benefits are
named repositories in a
greatest benefits are observable
repositories in a single
benefits are observable for
in the loss scenario
are observable for the
in a single zookeeper
observable for the combination
a single zookeeper tree
for the combination of
the combination of asynchronous
combination of asynchronous writes
of asynchronous writes with
asynchronous writes with priorities
before pushing a new
pushing a new revision
s the node drops
the node drops all
node drops all incoming
drops all incoming packets
all incoming packets for
since here the performance
here the performance of
the performance of the
end server must acquire
performance of the background
server must acquire a
of the background workload
must acquire a lock
the background workload can
layer with interleave of
acquire a lock by
background workload can also
a lock by creating
workload can also improve
lock by creating a
can also improve by
by creating a sequence
also improve by not
creating a sequence node
improve by not having
by not having to
not having to wait
having to wait for
to wait for its
wait for its writes
for its writes to
its writes to be
writes to be committed
to be committed at
be committed at the
committed at the server
the loss rate is
loss rate is higher
in the gc and
the gc and rc
gc and rc tests
where there is lighter
there is lighter contention
the impact of priorities
impact of priorities is
of priorities is negligible
to which zookeeper will
which zookeeper will append
zookeeper will append a
because recovery traffic interferes
will append a unique
recovery traffic interferes with
and in some cases
traffic interferes with regular
in some cases results
interferes with regular multicast
some cases results in
cases results in a
monotonically increasing sequence number
results in a slight
in a slight overhead
but this is chiefly
this is chiefly after
is chiefly after adding
end server then lists
chiefly after adding priorities
cpu utilization at the
after adding priorities to
server then lists the
adding priorities to rpcs
utilization at the receivers
then lists the children
at the receivers is
lists the children of
the receivers is in
receivers is in the
it is natural to
is natural to ask
natural to ask when
to ask when they
ask when they are
when they are beneficial
and to what degree
in addition to comparing
addition to comparing mfs
to comparing mfs with
comparing mfs with and
mfs with and without
with and without prioritised
and without prioritised rpcs
range and doesn t
and doesn t grow
if its own lock
doesn t grow with
its own lock node
t grow with system
own lock node has
grow with system size
lock node has the
we also investigate the
node has the lowest
also investigate the performance
has the lowest number
investigate the performance impact
the performance impact of
performance impact of replacing
impact of replacing synchronous
of replacing synchronous rpcs
it may proceed with
replacing synchronous rpcs for
may proceed with the
synchronous rpcs for file
proceed with the commit
rpcs for file updates
for file updates with
file updates with asynchronous
updates with asynchronous writeback
otherwise it watches the
it watches the node
watches the node with
the performance of these
the node with the
performance of these alternatives
node with the next
of these alternatives is
in the sleep scenario
these alternatives is compared
with the next lower
alternatives is compared in
the next lower number
is compared in a
next lower number in
the decrease starts at
compared in a set
decrease starts at about
in a set of
lower number in order
a set of microbenchmarks
number in order to
in order to be
order to be notified
to be notified when
be notified when that
and with workloads gathered
notified when that node
with workloads gathered from
nodes and proceeds steadily
workloads gathered from windows
and proceeds steadily thereafter
gathered from windows nt
when that node and
from windows nt file
that node and its
windows nt file system
node and its associated
it doesn t appear
and its associated lock
doesn t appear to
its associated lock go
t appear to be
associated lock go away
nt file system traces
appear to be correlated
to be correlated to
be correlated to the
correlated to the amount
to the amount of
after comitting the revision
our experimental setup consists
the amount of loss
experimental setup consists of
comitting the revision to
setup consists of two
the revision to s
which oscillates at the
oscillates at the level
at the level of
ghz pentium iii desktop
pentium iii desktop machines
iii desktop machines running
desktop machines running the
machines running the freebsd
combining the xor in
the xor in the
xor in the repair
in the repair with
the repair with the
repair with the other
with the other successfully
the other successfully received
other successfully received data
successfully received data packets
if the repair contains
one of which acts
the repair contains multiple
of which acts as
repair contains multiple missing
which acts as an
contains multiple missing data
acts as an mfs
multiple missing data packets
it releases its lock
as an mfs server
releases its lock by
its lock by deleting
lock by deleting the
by deleting the lock
deleting the lock node
it cannot be used
and the other as
cannot be used immediately
in the controlled loss
the other as an
the controlled loss scenario
other as an mfs
lock nodes are marked
as an mfs client
be used immediately for
nodes are marked with
used immediately for recovery
are marked with zookeeper
throughput remains fairly constant
immediately for recovery it
marked with zookeeper s
for recovery it is
the client machine makes
recovery it is instead
with zookeeper s ephemeral
client machine makes use
zookeeper s ephemeral flag
it is instead stored
s ephemeral flag to
is instead stored in
ephemeral flag to ensure
instead stored in a
flag to ensure that
stored in a table
to ensure that the
in a table that
until it falls sharply
a table that maps
it falls sharply beyond
table that maps missing
ensure that the lock
machine makes use of
that the lock is
that maps missing data
the lock is forcibly
makes use of the
lock is forcibly released
maps missing data packets
is forcibly released if
missing data packets to
forcibly released if the
data packets to repair
released if the front
packets to repair packets
use of the dummynet
of the dummynet trafficshaping
the dummynet trafficshaping module
dummynet trafficshaping module in
whenever a data packet
trafficshaping module in freebsd
a data packet is
module in freebsd to
data packet is subsequently
in freebsd to limit
performance does not appear
freebsd to limit its
does not appear to
to limit its incoming
not appear to be
limit its incoming and
appear to be directly
its incoming and outgoing
to be directly correlated
incoming and outgoing bandwidth
be directly correlated to
packet is subsequently received
directly correlated to the
zookeeper runs as a
is subsequently received or
correlated to the observed
subsequently received or recovered
the experiments we conduct
runs as a replicated
experiments we conduct in
as a replicated service
to the observed packet
we conduct in this
the observed packet loss
conduct in this section
this table is checked
so it remains available
in this section have
it remains available as
this section have a
remains available as long
section have a constant
available as long as
have a constant bandwidth
table is checked to
a constant bandwidth over
throughput is uncorrelated with
is checked to see
constant bandwidth over the
as long as a
bandwidth over the duration
checked to see if
over the duration of
long as a majority
the duration of the
to see if any
duration of the experiment
as a majority of
see if any xors
is uncorrelated with memory
a majority of the
uncorrelated with memory use
majority of the hosts
with memory use both
of the hosts are
but we analyse the
the hosts are up
memory use both on
if any xors now
we analyse the performance
hosts are up and
use both on the
any xors now have
analyse the performance of
are up and reachable
both on the perturbed
xors now have singleton
on the perturbed receiver
the performance of mfs
now have singleton losses
performance of mfs when
a client only speaks
of mfs when the
have singleton losses due
mfs when the bandwidth
singleton losses due to
when the bandwidth varies
losses due to the
the bandwidth varies over
due to the presence
bandwidth varies over the
client only speaks to
varies over the course
to the presence of
over the course of
only speaks to one
the course of an
the presence of the
course of an experiment
speaks to one zookeeper
of an experiment in
to one zookeeper server
an experiment in section
one zookeeper server at
presence of the new
zookeeper server at a
of the new packet
server at a time
the new packet and
new packet and can
packet and can be
and can be used
can be used for
though it may fail
be used for recovering
used for recovering other
for recovering other missing
at scales of up
recovering other missing packets
over to another server
scales of up to
to another server if
another server if necessary
xors received from different
received from different layers
but the server ensures
from different layers interact
the server ensures that
memory usage actually decreases
different layers interact to
server ensures that the
layers interact to recover
microbenchmarks the first set
interact to recover missing
ensures that the relevant
to recover missing data
that the relevant state
the first set of
the relevant state has
first set of experiments
relevant state has been
set of experiments compares
state has been replicated
recover missing data packets
has been replicated before
of experiments compares different
been replicated before responding
a consequence of the
replicated before responding to
experiments compares different mfs
before responding to a
consequence of the cooperative
responding to a client
since an xor received
compares different mfs configurations
of the cooperative caching
different mfs configurations for
an xor received at
mfs configurations for specific
the cooperative caching policy
xor received at a
configurations for specific types
to a client s
for specific types of
a client s request
specific types of contention
received at a higher
cooperative caching policy described
at a higher interleave
caching policy described in
a higher interleave can
policy described in section
higher interleave can recover
four workloads were used
interleave can recover a
in general multiple front
can recover a packet
recover a packet that
a packet that makes
packet that makes an
end servers may be
the shape of the
servers may be run
shape of the performance
executes the grep utility
of the performance curve
the grep utility several
the performance curve does
grep utility several times
that makes an earlier
utility several times on
each on its own
makes an earlier xor
on its own ec
several times on each
an earlier xor at
times on each of
earlier xor at a
xor at a lower
correlate closely with the
at a lower interleave
closely with the number
a lower interleave usable
with the number of
lower interleave usable hence
the system is organized
the number of unacknowledged
system is organized as
number of unacknowledged requests
is organized as in
organized as in figure
though layered interleaving is
layered interleaving is equivalent
interleaving is equivalent to
is equivalent to c
equivalent to c different
unlike the traditional replicated
the files are present
the traditional replicated subversion
files are present in
traditional replicated subversion setups
are present in the
replicated subversion setups that
present in the cache
subversion setups that are
setups that are used
that are used today
we conclude that the
but must be validated
conclude that the drop
must be validated before
instances in terms of
that the drop in
in terms of overhead
no single server acts
be validated before they
single server acts as
terms of overhead and
the drop in performance
validated before they are
drop in performance in
of overhead and design
server acts as a
before they are used
in performance in these
acts as a master
performance in these scenarios
its recovery power is
in these scenarios can
recovery power is much
these scenarios can t
power is much higher
scenarios can t be
is much higher and
can t be explained
much higher and comes
vn all are equivalent
higher and comes close
t be explained by
and comes close to
be explained by correlation
comes close to standard
explained by correlation with
performance of simultaneous checkouts
by correlation with cpu
correlation with cpu activity
mb files in sequence
or loss rates at
loss rates at the
writing the contents of
rates at the receivers
the contents of each
contents of each file
of each file to
optimizations staggered start for
staggered start for rate
but that it does
that it does appear
it does appear correlated
does appear correlated to
appear correlated to slower
limiting in the naive
correlated to slower cleanup
in the naive implementation
to slower cleanup and
the naive implementation of
slower cleanup and the
naive implementation of the
cleanup and the resulting
implementation of the layered
and the resulting memory
of the layered interleaving
the files are not
the layered interleaving algorithm
files are not initially
are not initially present
not initially present in
related overheads at the
initially present in the
overheads at the sender
present in the cache
repair packets are transmitted
packets are transmitted as
are transmitted as soon
transmitted as soon as
the effect is much
as soon as repair
effect is much stronger
soon as repair bins
is much stronger than
as repair bins fill
much stronger than in
repair bins fill and
stronger than in the
performance of simultaneous commits
than in the undisturbed
of simultaneous commits source
in the undisturbed experiments
bins fill and allow
simultaneous commits source code
fill and allow them
commits source code from
and allow them to
source code from an
allow them to be
the number of pending
them to be constructed
code from an ec
number of pending messages
of pending messages starts
pending messages starts at
messages starts at a
mb files from the
starts at a higher
files from the local
at a higher level
from the local file
the local file system
all the repair bins
local file system into
the repair bins in
file system into the
repair bins in a
system into the mfs
bins in a layer
into the mfs file
in a layer fill
the mfs file system
a layer fill in
layer fill in quick
fill in quick succession
and varying the number
varying the number of
the number of servers
number of servers over
of servers over which
servers over which the
over which the load
token roundtrip time increases
which the load was
the load was distributed
the arrival of packets
and if a failure
if a failure occurs
write performance was measured
performance was measured by
was measured by observing
measured by observing the
by observing the latency
observing the latency of
token rounds before repair
the latency of simultaneous
rounds before repair occurs
latency of simultaneous commits
of simultaneous commits from
simultaneous commits from different
commits from different clients
and then another round
then another round before
another round before cleanup
round before cleanup takes
before cleanup takes place
since simultaneous commits to
simultaneous commits to a
commits to a single
to a single repository
a single repository would
single repository would not
repository would not be
would not be a
not be a typical
will successively fill the
be a typical case
successively fill the four
fill the four repair
the four repair bins
four repair bins in
repair bins in layer
this behavior leads to
behavior leads to a
leads to a large
to a large number
a large number of
large number of repair
number of repair packets
of repair packets being
repair packets being generated
vn repositories were used
packets being generated and
these account for the
being generated and sent
account for the rapid
generated and sent within
for the rapid increase
and sent within a
the rapid increase in
sent within a short
all sharing the same
within a short period
rapid increase in acknowledgement
a short period of
sharing the same set
short period of time
increase in acknowledgement latency
the same set of
same set of front
which results in undesirable
results in undesirable overhead
end servers and same
in undesirable overhead and
servers and same set
undesirable overhead and traffic
and same set of
overhead and traffic spikes
same set of three
set of three zookeeper
of three zookeeper servers
as the number of
the number of caching
number of caching replicas
each client checked out
of caching replicas increases
client checked out a
we would like to
checked out a random
would like to rate
out a random repository
a random repository from
random repository from a
repository from a random
from a random front
limit transmissions of repair
transmissions of repair packets
of repair packets to
repair packets to one
packets to one for
to one for every
one for every r
for every r data
and then repeatedly committed
every r data packets
then repeatedly committed small
repeatedly committed small amounts
committed small amounts of
small amounts of data
throughput in the experiments
this problem is fixed
in the experiments with
problem is fixed by
the experiments with a
is fixed by staggering
changes were propgated in
fixed by staggering the
were propgated in the
by staggering the starting
propgated in the background
staggering the starting sizes
in the background to
the starting sizes of
the background to the
starting sizes of the
background to the other
sizes of the bins
experiments with a perturbed
to the other front
with a perturbed node
analogous to the starting
to the starting positions
the starting positions of
starting positions of runners
positions of runners in
of runners in a
runners in a sprint
the very first time
very first time bin
first time bin number
time bin number x
shows that adding front
bin number x in
number x in a
x in a layer
in a layer of
a layer of interleave
layer of interleave i
end servers can indeed
of interleave i fires
servers can indeed alleviate
can indeed alleviate latency
indeed alleviate latency problems
alleviate latency problems caused
latency problems caused by
it does so at
problems caused by high
does so at size
caused by high load
so at size x
average packet loss observed
at size x mod
packet loss observed at
size x mod r
loss observed at the
observed at the perturbed
and that the overhead
at the perturbed node
that the overhead of
the overhead of propagating
overhead of propagating data
of propagating data in
propagating data in the
data in the backgound
in the backgound is
the backgound is not
backgound is not significant
is not significant enough
the first repair bin
not significant enough to
first repair bin in
memory usage at the
repair bin in the
usage at the perturbed
bin in the second
at the perturbed node
in the second layer
significant enough to negatively
the second layer with
enough to negatively affect
second layer with interleave
to negatively affect performance
at unperturbed nodes it
unperturbed nodes it is
nodes it is similar
would fire at size
r elated w orks
elated w orks moving
w orks moving services
the second would fire
orks moving services to
second would fire at
moving services to the
would fire at size
services to the cloud
to the cloud has
the cloud has been
cloud has been published
has been published on
been published on in
although it would be
published on in other
it would be hard
on in other contexts
would be hard to
be hard to precisely
hard to precisely measure
to precisely measure these
precisely measure these delays
measuring alarm delays sheds
alarm delays sheds light
delays sheds light on
sheds light on the
light on the magnitude
on the magnitude of
the magnitude of the
magnitude of the problem
is a backup application
a backup application that
backup application that implements
application that implements a
that implements a custom
recall that our timesharing
implements a custom block
that our timesharing policy
our timesharing policy assigns
timesharing policy assigns quanta
policy assigns quanta to
assigns quanta to different
based file system to
quanta to different types
file system to store
to different types of
system to store multiple
different types of events
to store multiple versions
store multiple versions of
multiple versions of backup
versions of backup data
of backup data on
high volumes of i
backup data on s
such as caused by
as caused by the
the authors make the
caused by the increased
authors make the distinction
by the increased forwarding
make the distinction between
the increased forwarding traffic
the distinction between thin
will cause qsm to
clouds that provide a
cause qsm to use
that provide a low
qsm to use a
to use a larger
use a larger fraction
a larger fraction of
larger fraction of its
level api and thick
fraction of its i
clouds that are designed
o quantum to process
that are designed for
quantum to process i
are designed for a
designed for a specific
for a specific application
thick clouds for a
clouds for a variety
with the consequence that
for a variety of
the consequence that timers
a variety of purposes
consequence that timers will
gc test rw test
that timers will fire
timers will fire late
including backup and source
backup and source code
and source code repository
source code repository hosting
this effect is magnified
effect is magnified each
is magnified each time
magnified each time qsm
each time qsm is
time qsm is preempted
qsm is preempted by
with sourceforge and google
is preempted by other
sourceforge and google code
preempted by other processes
and google code being
by other processes or
google code being examples
other processes or by
code being examples of
processes or by its
being examples of the
or by its own
examples of the latter
by its own garbage
its own garbage collector
the authors of cumulus
authors of cumulus and
such delays are typically
of cumulus and we
delays are typically shorter
cumulus and we show
are typically shorter than
and we show that
typically shorter than the
we show that thin
shorter than the i
cloud solutions can be
solutions can be a
can be a cost
yet longer than the
longer than the alarm
than the alarm quantum
another example of moving
thus causing the alarm
example of moving a
of moving a service
moving a service to
a service to the
service to the cloud
but not the i
to the cloud is
the cloud is metacdn
the maximum alarm firing
maximum alarm firing delays
alarm firing delays taken
firing delays taken from
a content distribution network
delays taken from samples
taken from samples in
the work evaluates the
s intervals are indeed
work evaluates the latency
intervals are indeed much
evaluates the latency of
are indeed much larger
the latency of various
indeed much larger in
latency of various cloud
much larger in the
of various cloud storage
larger in the perturbed
various cloud storage services
in the perturbed experiments
cloud storage services from
storage services from several
services from several locations
from several locations and
both on the sender
several locations and provides
on the sender and
locations and provides an
the sender and on
and provides an abstraction
sender and on the
provides an abstraction to
and on the receiver
an abstraction to integrate
on the receiver side
abstraction to integrate the
to integrate the different
integrate the different offerings
gw test rc test
the different offerings into
different offerings into a
offerings into a single
into a single system
large delays are also
delays are also more
like transactional data store
are also more frequent
transactional data store backed
data store backed by
store backed by s
and faced similar issues
faced similar issues as
similar issues as s
the maximum delay measured
maximum delay measured on
delay measured on receivers
measured on receivers in
on receivers in the
vn due to its
receivers in the perturbed
due to its need
in the perturbed runs
to its need for
the perturbed runs is
its need for high
need for high consistency
elastras assigns update priviledges
assigns update priviledges for
update priviledges for different
priviledges for different areas
for different areas of
different areas of the
areas of the data
of the data store
the data store to
data store to individual
store to individual front
using the lock service
second set of rsized
relative speedup relative speedup
set of rsized xors
speedup relative speedup relative
the lock service to
of rsized xors staggered
lock service to elect
relative speedup relative speedup
service to elect an
rsized xors staggered start
to elect an owner
xors staggered start xors
elect an owner for
an owner for each
owner for each partition
much in the style
in the style described
the style described by
ms in the unperturbed
style described by google
in the unperturbed experiments
described by google s
by google s chubby
the value grows from
uniform priorities async relative
priorities async relative speedup
async relative speedup gc
relative speedup gc test
a lock service based
lock service based on
service based on paxos
defers finegrained locking to
the problem could be
finegrained locking to the
problem could be alleviated
locking to the application
could be alleviated by
to the application in
be alleviated by making
the application in order
alleviated by making our
application in order not
by making our priority
in order not to
making our priority scheduling
order not to burden
our priority scheduling more
not to burden the
priority scheduling more fine
to burden the global
burden the global lock
the global lock service
global lock service with
lock service with high
service with high traffic
vn we opted to
we opted to use
varying priorities for control
opted to use the
priorities for control packets
to use the lock
use the lock service
or by assigning priorities
by assigning priorities to
assigning priorities to feeds
priorities to feeds in
to feeds in the
feeds in the sending
in the sending stack
grained locking instead of
locking instead of just
instead of just leader
of just leader election
since the latter would
the latter would have
latter would have required
would have required duplicating
have required duplicating much
number of messages awaiting
required duplicating much of
of messages awaiting acknowledgement
duplicating much of zookeeper
messages awaiting acknowledgement in
much of zookeeper s
awaiting acknowledgement in experiments
of zookeeper s functionality
acknowledgement in experiments with
zookeeper s functionality to
in experiments with perturbances
s functionality to replicate
functionality to replicate the
to replicate the leader
replicate the leader s
the leader s state
scalability is not an
is not an obstacle
not an obstacle because
an obstacle because there
obstacle because there is
because there is no
there is no need
token roundtrip time and
is no need for
roundtrip time and the
no need for global
time and the time
need for global locking
and the time to
for global locking across
the time to recover
global locking across multiple
time to recover in
locking across multiple repositories
to recover in the
the load can be
load can be partitioned
can be partitioned across
be partitioned across as
partitioned across as many
across as many zookeeper
as many zookeeper instances
many zookeeper instances as
zookeeper instances as necessary
replication is not without
is not without its
not without its dangers
token roundtrip time and
roundtrip time and the
time and the time
and the time to
the time to recover
time to recover in
to recover in the
and it has been
it has been shown
has been shown that
been shown that replicating
it is worth noting
shown that replicating too
is worth noting that
that replicating too eagerly
worth noting that the
replicating too eagerly leads
noting that the doubled
too eagerly leads quickly
that the doubled token
eagerly leads quickly to
the doubled token roundtrip
leads quickly to degraded
doubled token roundtrip time
quickly to degraded performance
as compared to unperturbed
the solution proposed is
compared to unperturbed experiments
solution proposed is to
proposed is to use
is to use master
to use master copy
use master copy replication
can t be accounted
t be accounted for
be accounted for by
accounted for by the
where a transaction does
for by the increase
a transaction does not
by the increase in
transaction does not immediately
the increase in memory
does not immediately update
increase in memory overhead
not immediately update all
in memory overhead or
immediately update all replicas
relative speedup relative speedup
memory overhead or cpu
speedup relative speedup relative
overhead or cpu activity
relative speedup relative speedup
or cpu activity on
cpu activity on the
activity on the receivers
as was the case
was the case in
as the master copy
the case in experiments
case in experiments where
in experiments where we
experiments where we varied
where we varied the
and only the lock
we varied the replication
only the lock service
varied the replication factor
which deals with simple
the problem can be
problem can be traced
can be traced to
be traced to a
traced to a priority
to a priority inversion
bandwidth operations that may
operations that may be
that may be concentrated
because of repeated losses
may be concentrated on
be concentrated on a
concentrated on a small
on a small number
a small number of
the system maintains a
small number of servers
system maintains a high
maintains a high volume
a high volume of
high volume of forwarding
volume of forwarding traffic
must be eagerly replicated
the forwarded messages tend
also relevant is sundr
forwarded messages tend to
messages tend to get
tend to get ahead
to get ahead of
get ahead of the
the secure untrusted data
ahead of the token
secure untrusted data repository
both on the send
on the send path
where in the sinks
we use a simple
use a simple round
this file system allows
robin policy of multiplexing
file system allows clients
policy of multiplexing between
system allows clients to
of multiplexing between data
allows clients to detect
multiplexing between data feeds
clients to detect against
to detect against malicious
detect against malicious or
against malicious or compromised
and on the receive
malicious or compromised storage
on the receive path
or compromised storage servers
compromised storage servers or
storage servers or hosting
servers or hosting platforms
where forwarded packets are
or hosting platforms by
forwarded packets are treated
hosting platforms by providing
packets are treated as
platforms by providing fork
are treated as control
by providing fork consistency
treated as control traffic
and while they re
a property which ensures
while they re prioritized
property which ensures that
they re prioritized over
which ensures that clients
re prioritized over data
ensures that clients can
that clients can detect
clients can detect integrity
can detect integrity failures
they are treated as
detect integrity failures as
are treated as equally
integrity failures as long
treated as equally important
failures as long as
as equally important as
as long as they
equally important as tokens
long as they see
as they see each
they see each other
see each other s
each other s file
they also increase the
other s file modifications
also increase the overall
increase the overall volume
the overall volume of
overall volume of i
similar techniques could be
techniques could be used
o that the nodes
could be used to
that the nodes process
be used to recover
used to recover data
to recover data from
recover data from client
data from client working
from client working copies
client working copies in
tokens are processed with
working copies in the
are processed with higher
copies in the event
processed with higher latency
in the event of
the event of a
event of a catastrophic
of a catastrophic cloud
a catastrophic cloud failure
once code repositories are
code repositories are stored
repositories are stored in
are stored in the
stored in the cloud
one might imagine enabling
might imagine enabling mashups
imagine enabling mashups in
enabling mashups in ways
mashups in ways not
in ways not previously
ways not previously possible
histogram of maximum alarm
of maximum alarm delays
web based code viewers
maximum alarm delays in
and cross reference viewers
cross reference viewers might
reference viewers might be
viewers might be built
might be built by
be built by third
pulling data from the
data from the repositories
histogram of maximum alarm
from the repositories of
of maximum alarm delays
the repositories of several
maximum alarm delays in
repositories of several distinct
of several distinct communities
seeks to enable such
to enable such applications
overheads in a lightly
enable such applications by
such applications by granting
applications by granting direct
by granting direct access
granting direct access of
loaded system so far
direct access of cloud
system so far the
access of cloud storage
so far the evaluation
of cloud storage to
far the evaluation has
cloud storage to third
the evaluation has focused
storage to third parties
evaluation has focused on
has focused on scenarios
focused on scenarios where
on scenarios where the
scenarios where the system
subject to the data
where the system was
to the data owner
the system was heavily
the data owner s
system was heavily loaded
data owner s security
owner s security requirements
with unbounded multicast rates
a question that may
unbounded multicast rates and
question that may naturally
multicast rates and occasional
that may naturally arise
rates and occasional perturbations
may naturally arise is
why not use a
not use a general
performance of prioritised rpc
use a general purpose
of prioritised rpc with
a general purpose file
prioritised rpc with respect
general purpose file system
rpc with respect to
purpose file system interface
with respect to bandwidth
file system interface to
respect to bandwidth variation
system interface to s
we traced degraded performance
traced degraded performance or
degraded performance or scheduling
performance or scheduling delays
each pair of graphs
or scheduling delays to
pair of graphs in
scheduling delays to memory
of graphs in shows
graphs in shows the
in shows the speedup
shows the speedup of
the speedup of one
speedup of one of
of one of three
one of three cache
of three cache manager
but how does the
and store a repository
how does the system
store a repository on
three cache manager configurations
a repository on that
does the system behave
the system behave when
system behave when lightly
behave when lightly loaded
this is indeed possible
relative to the time
is indeed possible to
do similar phenomena occur
indeed possible to do
to the time taken
the time taken by
time taken by uniform
taken by uniform priorities
here we ll see
by uniform priorities with
we ll see that
but would entail pushing
ll see that load
uniform priorities with synchronous
see that load has
would entail pushing temporary
that load has a
priorities with synchronous rpcs
entail pushing temporary files
with synchronous rpcs at
load has a super
pushing temporary files such
temporary files such as
files such as transactions
linear impact on performance
and incurring additional monetary
incurring additional monetary costs
additional monetary costs due
the growth in memory
monetary costs due to
growth in memory consumption
as well as uniform
costs due to the
well as uniform priorities
in memory consumption causes
as uniform priorities and
due to the increased
uniform priorities and synchronous
memory consumption causes slowdowns
priorities and synchronous rpcs
to the increased number
consumption causes slowdowns that
the increased number of
causes slowdowns that amplify
increased number of s
slowdowns that amplify the
that amplify the increased
amplify the increased latencies
the increased latencies associated
increased latencies associated with
latencies associated with the
associated with the growth
with the growth in
there would also likely
the growth in traffic
would also likely be
the graphs also show
also likely be performance
graphs also show curves
likely be performance problems
also show curves for
show curves for differentiated
to show this we
curves for differentiated priorities
show this we designed
for differentiated priorities and
this we designed experiments
differentiated priorities and synchronous
since file append and
priorities and synchronous rpcs
we designed experiments that
file append and rename
designed experiments that vary
append and rename operations
experiments that vary the
and rename operations do
that vary the multicast
rename operations do not
vary the multicast rate
operations do not map
do not map efficiently
not map efficiently to
and differentiated priorities and
map efficiently to s
differentiated priorities and asynchronous
priorities and asynchronous rpcs
showed that the load
that the load on
the load on receivers
load on receivers grows
on receivers grows roughly
receivers grows roughly linearly
the values plotted for
values plotted for bandwidth
plotted for bandwidth of
fs that is aware
as expected given the
that is aware of
expected given the linearly
is aware of subversion
given the linearly increasing
aware of subversion s
the linearly increasing load
of subversion s file
subversion s file naming
s file naming and
negligible loss rates and
file naming and use
loss rates and the
naming and use scenario
rates and the nearly
and use scenario could
and the nearly flat
use scenario could of
the nearly flat curve
scenario could of course
nearly flat curve of
s are the same
flat curve of memory
are the same as
could of course overcome
the same as shown
curve of memory consumption
of course overcome these
same as shown in
as shown in table
course overcome these limitations
overcome these limitations by
these limitations by pushing
limitations by pushing only
by pushing only what
pushing only what is
only what is actually
what is actually required
is actually required into
due to the overhead
actually required into s
to the overhead of
the overhead of priorities
overhead of priorities for
of priorities for small
priorities for small rpcs
for small rpcs mentioned
small rpcs mentioned in
the latter reflecting our
rpcs mentioned in section
latter reflecting our cooperative
reflecting our cooperative caching
but we believe that
our cooperative caching policy
we believe that such
believe that such specialized
that such specialized tools
load on the sender
such specialized tools are
specialized tools are better
tools are better built
are better built on
better built on top
built on top of
on top of a
top of a file
comparing the execution time
of a file system
the execution time of
a file system abstraction
execution time of the
file system abstraction than
time of the foreground
system abstraction than pushed
of the foreground workloads
because the linear growth
the foreground workloads with
the linear growth of
foreground workloads with synchronous
abstraction than pushed underneath
workloads with synchronous writes
linear growth of traffic
than pushed underneath it
update logging and asynchronous
combined with our fixed
logging and asynchronous writeback
with our fixed rate
and asynchronous writeback reveals
our fixed rate of
c onclusion we have
asynchronous writeback reveals that
fixed rate of state
writeback reveals that the
rate of state aggregation
onclusion we have shown
reveals that the latter
we have shown that
that the latter two
have shown that the
the latter two options
shown that the cost
latter two options generally
that the cost of
two options generally perform
the cost of using
options generally perform comparably
increases the amount of
generally perform comparably to
the amount of unacknowledged
perform comparably to or
amount of unacknowledged data
comparably to or better
cost of using a
to or better than
of using a cloud
or better than synchronous
using a cloud computing
better than synchronous writes
a cloud computing storage
cloud computing storage service
computing storage service for
storage service for source
service for source code
logging and asynchronous writeback
for source code repository
and asynchronous writeback greatly
comparison of packet recovery
source code repository hosting
of packet recovery probability
code repository hosting is
asynchronous writeback greatly improve
repository hosting is low
writeback greatly improve the
greatly improve the performance
improve the performance of
the performance of the
performance of the background
of the background workloads
both for individual projects
this triggers higher overheads
for individual projects and
individual projects and moderately
projects and moderately sized
as has been noted
and moderately sized communities
has been noted previously
the time spent in
time spent in the
considering the costs of
spent in the garbage
the costs of a
in the garbage collector
costs of a resilient
the garbage collector grows
of a resilient local
garbage collector grows from
a resilient local storage
resilient local storage system
local storage system of
storage system of scsi
system of scsi disks
of scsi disks and
scsi disks and tape
disks and tape backup
staggered start first i
start first i data
first i data packets
cloud computing is a
i data packets added
computing is a very
data packets added to
is a very attractive
packets added to a
a very attractive solution
added to a layer
very attractive solution for
to a layer with
we focus on mfs
a layer with interleave
attractive solution for this
layer with interleave i
focus on mfs with
solution for this application
on mfs with asynchronous
mfs with asynchronous writeback
with asynchronous writeback in
our implementation of s
asynchronous writeback in the
writeback in the rest
r fire immediately with
in the rest of
fire immediately with just
the rest of this
immediately with just one
rest of this paper
with just one packet
vn brings this concept
combined with a linear
brings this concept a
with a linear growth
this concept a step
just one packet in
of this paper because
a linear growth of
this paper because it
linear growth of cpu
concept a step closer
one packet in them
paper because it provides
growth of cpu usage
because it provides comparable
of cpu usage due
it provides comparable performance
cpu usage due to
for the next i
usage due to the
a step closer to
due to the increasing
provides comparable performance to
to the increasing volume
comparable performance to logged
the increasing volume of
performance to logged updates
increasing volume of traffic
step closer to becoming
the next i data
closer to becoming reality
next i data packets
i data packets added
these overheads cause the
overheads cause the super
allows straightforward modeless adaptation
and provides evidence that
straightforward modeless adaptation to
provides evidence that performance
modeless adaptation to bandwidth
linear growth of cpu
adaptation to bandwidth variation
growth of cpu overhead
r fire immediately with
of cpu overhead shown
evidence that performance will
cpu overhead shown on
fire immediately with two
that performance will be
immediately with two data
overhead shown on figure
performance will be acceptable
with two data packets
will be acceptable for
two data packets in
be acceptable for typical
data packets in them
and is easily extensible
acceptable for typical use
is easily extensible to
for typical use scenarios
easily extensible to more
extensible to more than
and so on until
to more than one
so on until r
more than one level
on until r i
than one level of
until r i data
one level of priority
the increasing number of
r i data packets
increasing number of unacknowledged
i data packets have
number of unacknowledged requests
data packets have been
which is required for
packets have been added
of unacknowledged requests and
is required for our
have been added to
required for our cache
unacknowledged requests and the
been added to the
for our cache consistency
added to the layer
our cache consistency algorithm
to the layer and
requests and the resulting
the layer and all
and the resulting overheads
layer and all bins
the resulting overheads rise
and all bins have
resulting overheads rise sharply
all bins have fired
since reducing available bandwidth
bins have fired exactly
reducing available bandwidth increases
have fired exactly once
overheads rise sharply at
available bandwidth increases the
rise sharply at the
bandwidth increases the contention
technological impact of magnetic
increases the contention between
sharply at the highest
the contention between rpcs
impact of magnetic hard
contention between rpcs of
at the highest rates
between rpcs of different
of magnetic hard disk
rpcs of different types
the highest rates because
all bins fire at
highest rates because of
magnetic hard disk drives
rates because of the
bins fire at size
because of the increasing
fire at size r
of the increasing token
the benefits of rpc
the increasing token roundtrip
benefits of rpc priorities
hard disk drives on
of rpc priorities should
disk drives on storage
rpc priorities should be
drives on storage systems
increasing token roundtrip time
priorities should be more
should be more apparent
now that they have
be more apparent at
that they have been
more apparent at lower
they have been staggered
apparent at lower priorities
the issue here is
have been staggered at
issue here is that
been staggered at the
here is that the
staggered at the start
is that the amount
that the amount of
the amount of i
shows the experiments of
the experiments of table
o to be processed
to be processed increases
r fire for any
fire for any i
for any i data
extended to a wider
any i data packets
to a wider range
much as in some
a wider range of
as in some of
wider range of bandwidth
in some of the
range of bandwidth values
some of the earlier
of the earlier scenarios
the outlined scheme works
outlined scheme works when
scheme works when i
works when i is
in these and later
when i is greater
this delays tokens as
i is greater than
these and later experiments
is greater than or
delays tokens as a
greater than or equal
tokens as a function
than or equal to
as a function of
or equal to r
a function of the
we evaluate mfs performance
function of the growing
evaluate mfs performance with
of the growing volume
mfs performance with bandwidths
the growing volume of
performance with bandwidths from
growing volume of multicast
as is usually the
volume of multicast traffic
is usually the case
we confirm the hypothesis
if i is smaller
confirm the hypothesis by
i is smaller than
the hypothesis by looking
is smaller than r
hypothesis by looking at
by looking at the
looking at the end
the bin with index
bin with index x
with index x fires
index x fires at
s is not low
we would expect latency
is not low in
would expect latency to
not low in the
expect latency to decrease
low in the sense
latency to decrease as
in the sense of
to decrease as the
the sense of prior
decrease as the sending
sense of prior work
as the sending rate
the sending rate increases
sending rate increases because
rate increases because the
increases because the system
it is low enough
because the system operates
is low enough to
the system operates more
the initial firing sizes
system operates more smoothly
low enough to cause
initial firing sizes would
enough to cause significant
firing sizes would be
to cause significant contention
cause significant contention for
avoiding context switching overheads
significant contention for the
context switching overheads and
for the first bin
contention for the workloads
the first bin and
switching overheads and the
for the workloads we
overheads and the extra
the workloads we have
and the extra latencies
workloads we have considered
for the second bin
the extra latencies caused
extra latencies caused by
latencies caused by the
caused by the small
and we believe that
by the small amount
we believe that our
the small amount of
if r and i
small amount of buffering
believe that our results
amount of buffering in
r and i are
of buffering in our
that our results will
and i are not
our results will hold
i are not integral
buffering in our protocol
are not integral multiples
in our protocol stack
not integral multiples of
results will hold if
integral multiples of each
will hold if available
multiples of each other
hold if available bandwidth
if available bandwidth and
with larger packets once
available bandwidth and grep
larger packets once the
bandwidth and grep write
packets once the rate
once the rate exceeds
limiting still works but
still works but is
works but is slightly
but is slightly less
is slightly less effective
slightly less effective due
less effective due to
effective due to rounding
due to rounding errors
delaying xors in the
xors in the straightforward
in the straightforward implementation
afs mfs afs mfs
the latency starts increasing
repair packets are transmitted
mfs afs mfs elapsed
packets are transmitted as
afs mfs elapsed time
are transmitted as soon
latency starts increasing again
transmitted as soon as
as soon as they
soon as they are
as they are generated
due to the longer
to the longer pipeline
the longer pipeline at
longer pipeline at the
this results in the
pipeline at the receive
results in the repair
at the receive side
in the repair packet
the receive side and
the repair packet leaving
receive side and other
repair packet leaving immediately
side and other phenomena
packet leaving immediately after
and other phenomena just
leaving immediately after the
other phenomena just mentioned
immediately after the last
after the last data
the last data packet
last data packet that
data packet that was
this is not the
packet that was added
is not the case
that was added to
not the case for
was added to it
the case for small
case for small packets
which lowers burst tolerance
lowers burst tolerance if
burst tolerance if the
tolerance if the repair
if the repair packet
the repair packet was
repair packet was generated
packet was generated at
was generated at interleave
generated at interleave i
the resulting protocol can
here the load on
resulting protocol can tolerate
the load on the
brewer s conjecture and
load on the system
protocol can tolerate a
s conjecture and the
can tolerate a burst
on the system is
tolerate a burst of
the system is much
conjecture and the feasibility
a burst of i
and the feasibility of
burst of i lost
the feasibility of consistent
of i lost data
system is much smaller
i lost data packets
feasibility of consistent available
lost data packets excluding
of consistent available partition
data packets excluding the
packets excluding the repair
the above observations are
but the burst could
above observations are consistent
the burst could swallow
in in acm sigact
observations are consistent with
in acm sigact news
burst could swallow both
are consistent with the
could swallow both the
consistent with the sharp
swallow both the repair
with the sharp rise
both the repair and
the sharp rise of
the repair and the
sharp rise of the
repair and the last
rise of the average
and the last data
of the average delay
the last data packet
the average delay for
last data packet in
average delay for timer
data packet in it
delay for timer events
packet in it as
in it as they
it as they are
as they are not
they are not separated
are not separated by
not separated by the
separated by the requisite
by the requisite interleave
the solution to this
solution to this is
to this is simple
this is simple delay
as the rate changes
is simple delay sending
the rate changes from
simple delay sending the
delay sending the repair
sending the repair packet
the repair packet generated
repair packet generated by
packet generated by a
generated by a repair
by a repair bin
a repair bin until
repair bin until the
bin until the next
until the next time
the next time a
next time a data
time a data packet
a data packet is
data packet is added
packet is added to
is added to the
added to the now
to the now empty
the now empty bin
which happens i packets
happens i packets later
i packets later and
timer delays at the
packets later and introduces
delays at the receiver
later and introduces the
at the receiver increase
and introduces the required
the receiver increase from
introduces the required interleave
the required interleave between
required interleave between the
interleave between the repair
between the repair packet
the repair packet and
repair packet and the
packet and the last
and the last data
the last data packet
filesystem backup to the
last data packet included
backup to the cloud
data packet included in
packet included in it
and on the sender
notice that although transmitting
that although transmitting the
although transmitting the xor
transmitting the xor immediately
the xor immediately results
xor immediately results in
immediately results in faster
results in faster recovery
comparison of mfs and
of mfs and afs
mfs and afs performance
doing so also reduces
so also reduces the
also reduces the probability
reduces the probability of
mfs with synchronous rpcs
the probability of a
with synchronous rpcs and
probability of a lost
synchronous rpcs and priorities
of a lost packet
rpcs and priorities is
a lost packet being
and priorities is compared
lost packet being recovered
priorities is compared to
is compared to a
compared to a version
to a version of
number of unacknowledged messages
a version of the
of unacknowledged messages and
version of the andrew
unacknowledged messages and average
of the andrew file
messages and average token
off results in a
and average token roundtrip
the andrew file system
average token roundtrip time
results in a minor
token roundtrip time as
in a minor control
roundtrip time as a
a minor control knob
time as a function
minor control knob permitting
speedups for the two
control knob permitting us
as a function of
knob permitting us to
a function of the
permitting us to balance
function of the sending
us to balance speed
of the sending rate
for the two workloads
to balance speed against
the two workloads of
balance speed against burst
two workloads of the
speed against burst tolerance
workloads of the gw
of the gw test
the gw test are
gw test are shown
our default configuration is
default configuration is to
configuration is to transmit
is to transmit the
relative to the performance
to transmit the xor
to the performance of
transmit the xor immediately
the performance of afs
performance of afs at
linearly growing memory use
growing memory use on
memory use on sender
use on sender and
on sender and the
sender and the nearly
and the nearly flat
the nearly flat usage
nearly flat usage on
flat usage on the
usage on the receiver
on the receiver as
the receiver as a
traffic are scaled down
receiver as a function
are scaled down further
as a function of
envelope analysis to start
a function of the
analysis to start with
function of the sending
scaled down further in
of the sending rate
down further in parallel
we note that no
note that no two
the graphs in figure
that no two repair
no two repair packets
two repair packets generated
repair packets generated at
packets generated at different
validate the incorporation of
generated at different interleaves
the incorporation of rpc
at different interleaves i
incorporation of rpc priorities
harnessing storage clouds for
storage clouds for high
clouds for high performance
for high performance content
high performance content delivery
since all the foreground
all the foreground workloads
the foreground workloads improve
receive latency for varying
foreground workloads improve their
latency for varying rate
workloads improve their performance
improve their performance substantially
their performance substantially at
performance substantially at lower
substantially at lower bandwidths
with various message sizes
relative to mfs with
to mfs with no
mfs with no priorities
th international conference on
international conference on service
will have more than
have more than one
more than one data
than one data packet
the decrease in throughput
one data packet in
decrease in throughput for
alarm firing delays on
in throughput for the
data packet in common
firing delays on sender
packet in common as
delays on sender and
in common as long
on sender and receiver
common as long as
sender and receiver as
as long as the
and receiver as a
long as the least
receiver as a function
as the least common
as a function of
the least common multiple
a function of sending
parameter trace mostly writes
function of sending rate
of the interleaves is
the interleaves is greater
interleaves is greater than
is greater than r
greater than r i
pairings of repair bins
of repair bins in
repair bins in two
bins in two different
in two different layers
two different layers with
different layers with interleaves
layers with interleaves i
group memory consumption in
memory consumption in a
consumption in a final
in a final set
a final set of
final set of experiments
we focus on scalability
focus on scalability with
on scalability with the
scalability with the number
with the number of
the number of groups
a single sender multicasts
single sender multicasts to
sender multicasts to a
multicasts to a varying
to a varying number
a varying number of
varying number of groups
number of groups in
a good rule of
of groups in a
good rule of thumb
groups in a roundrobin
rule of thumb is
in a roundrobin fashion
of thumb is to
thumb is to select
is to select interleaves
to select interleaves that
all receivers join all
select interleaves that are
receivers join all groups
interleaves that are relatively
that are relatively prime
are relatively prime to
relatively prime to maximize
prime to maximize their
and since the groups
to maximize their lcm
since the groups are
the groups are perfectly
groups are perfectly overlapped
and also ensure that
also ensure that the
the system contains a
ensure that the larger
system contains a single
that the larger interleave
contains a single region
an elastic transactional data
the larger interleave is
elastic transactional data store
larger interleave is greater
transactional data store in
interleave is greater than
data store in the
is greater than r
store in the cloud
qsm s regional recovery
s regional recovery protocol
regional recovery protocol is
recovery protocol is oblivious
protocol is oblivious to
let us assume that
is oblivious to the
us assume that packets
oblivious to the groups
assume that packets are
that packets are dropped
packets are dropped with
are dropped with uniform
hence the receivers behave
the receivers behave identically
receivers behave identically no
behave identically no matter
identically no matter how
no matter how many
matter how many groups
given a lost data
how many groups we
a lost data packet
many groups we use
what is the probability
on the other hand
is the probability that
the probability that we
probability that we can
that we can recover
we can recover it
the sender maintains a
sender maintains a number
maintains a number of
a number of per
we can recover a
can recover a data
recover a data packet
a data packet if
data packet if at
packet if at least
this affects the sender
if at least one
affects the sender s
at least one of
the sender s memory
least one of the
sender s memory footprint
the chubby lock service
one of the c
chubby lock service for
of the c xors
lock service for loosely
the c xors containing
so changes to throughput
c xors containing it
changes to throughput or
xors containing it is
to throughput or protocol
containing it is received
throughput or protocol behavior
it is received correctly
or protocol behavior must
is received correctly and
protocol behavior must be
received correctly and usable
behavior must be directly
must be directly or
be directly or indirectly
directly or indirectly linked
or indirectly linked to
indirectly linked to memory
linked to memory usage
we do not expect
all the other data
do not expect the
the other data packets
not expect the token
other data packets in
expect the token roundtrip
data packets in it
the token roundtrip time
packets in it have
token roundtrip time or
in it have also
roundtrip time or the
it have also been
time or the amount
have also been received
or the amount of
also been received correctly
th conference on usenix
these traces are representative
the amount of messages
traces are representative periods
amount of messages pending
conference on usenix symposium
of messages pending acknowledgement
are representative periods of
messages pending acknowledgement to
representative periods of mixed
pending acknowledgement to vary
periods of mixed read
acknowledgement to vary with
of mixed read and
to vary with the
mixed read and write
vary with the number
read and write activity
with the number of
on usenix symposium on
the probability of which
usenix symposium on operating
the number of groups
symposium on operating systems
probability of which is
on operating systems design
of which is simply
operating systems design and
the durations are from
systems design and implementation
durations are from the
are from the original
from the original ntfs
the original ntfs traces
note that the total
that the total file
the total file sizes
total file sizes represent
file sizes represent the
sizes represent the amount
represent the amount fetched
groups this is the
the amount fetched by
this is the case
amount fetched by mfs
the probability of a
fetched by mfs during
probability of a received
by mfs during the
of a received xor
mfs during the trace
a received xor being
received xor being unusable
xor being unusable is
being unusable is the
unusable is the complement
where this is exceed
this is exceed by
is exceed by the
exceed by the write
by the write traffic
the additional traffic is
additional traffic is due
traffic is due to
in this range memory
is due to new
this range memory consumption
due to new files
range memory consumption on
to new files being
memory consumption on the
new files being created
consumption on the sender
files being created or
on the sender grows
being created or existing
created or existing ones
or existing ones extended
time spent on rpcs
and so does the
so does the time
does the time spent
the time spent in
time spent in the
the probability x of
spent in the clr
probability x of a
x of a sent
of a sent xor
a sent xor being
sent xor being dropped
xor being dropped or
being dropped or unusable
dropped or unusable is
or unusable is the
unusable is the sum
is the sum of
the sum of the
sum of the probability
of the probability that
the probability that it
probability that it was
that it was dropped
it was dropped and
was dropped and the
dropped and the probability
and the probability that
the probability that it
probability that it was
that it was received
it was received and
was received and unusable
inspection of the managed
of the managed heap
the managed heap in
managed heap in a
heap in a debugger
in a debugger shows
a debugger shows that
debugger shows that the
shows that the growth
that the growth in
the growth in memory
growth in memory used
in memory used is
memory used is caused
used is caused not
is caused not by
caused not by messages
but by the per
group elements of the
elements of the protocol
of the protocol stack
each maintains a queue
small structures for profiling
structures for profiling etc
with thousands of groups
these add up to
add up to tens
up to tens of
to tens of megabytes
we can confirm the
can confirm the theory
confirm the theory by
ntfs workloads in addition
the theory by turning
workloads in addition to
theory by turning on
in addition to measuring
by turning on additional
addition to measuring the
turning on additional tracing
to measuring the performance
on additional tracing in
measuring the performance of
since it is easy
additional tracing in the
it is easy to
tracing in the per
the performance of mfs
is easy to ensure
performance of mfs with
easy to ensure that
of mfs with synthetic
to ensure that no
mfs with synthetic workloads
ensure that no two
that no two xors
no two xors share
two xors share more
this tracing is lightweight
xors share more than
tracing is lightweight and
share more than one
we have also conducted
more than one data
is lightweight and has
than one data packet
have also conducted experiments
lightweight and has little
also conducted experiments with
and has little effect
conducted experiments with traces
has little effect on
experiments with traces gathered
the usability probabilities of
little effect on cpu
usability probabilities of different
effect on cpu consumption
probabilities of different xors
with traces gathered from
of different xors are
traces gathered from the
different xors are independent
gathered from the windows
from the windows nt
but it increases the
the windows nt file
it increases the memory
windows nt file system
increases the memory footprint
the probability of all
the memory footprint by
probability of all the
memory footprint by adding
of all the c
footprint by adding additional
all the c xors
by adding additional data
the c xors being
adding additional data structures
c xors being dropped
additional data structures that
xors being dropped or
data structures that are
being dropped or unusable
structures that are updated
dropped or unusable is
that are updated once
or unusable is xc
are updated once per
updated once per second
which burdens the gc
the probability of correctly
probability of correctly receiving
of correctly receiving at
correctly receiving at least
although mfs is implemented
receiving at least one
mfs is implemented on
at least one usable
is implemented on a
least one usable xor
implemented on a variant
one usable xor is
on a variant of
a variant of unix
and ntfs has a
ntfs has a somewhat
has a somewhat different
a somewhat different interface
somewhat different interface to
different interface to the
interface to the file
the probability of recovering
to the file system
probability of recovering the
of recovering the lost
recovering the lost data
the lost data packet
lost data packet is
the traces were converted
it is worth noting
traces were converted to
is worth noting that
were converted to run
worth noting that the
converted to run on
noting that the memory
to run on top
that the memory usages
run on top of
the memory usages reported
on top of mfs
memory usages reported here
top of mfs with
usages reported here are
of mfs with little
reported here are averages
mfs with little difficulty
the dangers of replication
dangers of replication and
of replication and a
replication and a solution
the original traces recorded
original traces recorded file
traces recorded file accesses
recorded file accesses on
file accesses on a
accesses on a set
on a set of
and the peak values
a set of machines
the peak values are
set of machines in
peak values are typically
of machines in a
machines in a lan
a majority of the
majority of the accesses
of the accesses were
the accesses were local
accesses were local but
were local but some
local but some were
but some were to
some were to remote
were to remote machines
form formula only gives
formula only gives us
only gives us a
gives us a lower
us a lower bound
we extracted subintervals from
acm sigmod international conference
extracted subintervals from the
a lower bound on
subintervals from the traces
lower bound on the
sigmod international conference on
bound on the recovery
from the traces which
on the recovery probability
international conference on management
the traces which featured
conference on management of
the nodes on our
on management of data
traces which featured interesting
nodes on our cluster
which featured interesting file
since the xor usability
on our cluster only
featured interesting file system
our cluster only have
the xor usability formula
interesting file system behaviour
xor usability formula does
file system behaviour and
usability formula does not
system behaviour and processed
formula does not factor
behaviour and processed them
does not factor in
and processed them to
not factor in the
processed them to remove
factor in the probability
them to remove accesses
in the probability of
to remove accesses to
the probability of the
remove accesses to files
probability of the other
accesses to files over
of the other data
the other data packets
other data packets in
data packets in the
packets in the xor
in the xor being
the xor being dropped
xor being dropped and
being dropped and recovered
this preprocessing was necessary
preprocessing was necessary to
was necessary to eliminate
necessary to eliminate the
to eliminate the influence
eliminate the influence of
the influence of extremely
influence of extremely large
we extend the analysis
of extremely large nt
extend the analysis to
extremely large nt system
the analysis to bursty
large nt system files
analysis to bursty losses
if the lost data
the lost data packet
memory footprint is significant
lost data packet was
data packet was part
packet was part of
was part of a
part of a loss
of a loss burst
a loss burst of
loss burst of size
burst of size b
of the file system
the file system traffic
file system traffic in
system traffic in some
repair packets generated at
traffic in some portions
packets generated at interleaves
in some portions of
generated at interleaves less
some portions of the
at interleaves less than
portions of the original
interleaves less than b
of the original traces
less than b are
than b are dropped
the peak footprint approaches
b are dropped or
are dropped or useless
dropped or useless with
given that mfs retrieves
or useless with high
that mfs retrieves and
useless with high probability
mfs retrieves and writes
retrieves and writes back
and writes back whole
writes back whole files
and we can discount
we can discount them
and the system is
including these system files
the system is close
these system files would
system is close to
system files would have
is close to swapping
files would have distorted
of recovering the data
would have distorted the
recovering the data packet
have distorted the experiments
the data packet is
distorted the experiments at
data packet is then
the experiments at low
experiments at low bandwidths
gives statistics for the
statistics for the three
for the three traces
is the number of
the number of xors
number of xors generated
of xors generated at
xors generated at interleaves
a trace in which
generated at interleaves greater
trace in which reads
at interleaves greater than
in which reads predominate
interleaves greater than b
a trace in which
the formulae derived for
trace in which writes
formulae derived for xor
in which writes predominate
derived for xor usability
for xor usability still
groups are enough to
xor usability still hold
are enough to trigger
enough to trigger signs
to trigger signs of
and one containing exceptionally
trigger signs of instability
one containing exceptionally heavy
since packet losses with
containing exceptionally heavy file
packet losses with more
exceptionally heavy file system
losses with more than
token roundtrip times start
with more than b
roundtrip times start to
heavy file system traffic
times start to grow
more than b intervening
than b intervening packets
b intervening packets between
intervening packets between them
thus delaying message cleanup
each trace was run
packets between them have
trace was run over
between them have independent
was run over mfs
them have independent probability
run over mfs with
over mfs with the
mfs with the combinations
with the combinations of
there is only correlation
the combinations of synchronous
is only correlation within
combinations of synchronous and
only correlation within the
of synchronous and asynchronous
correlation within the bursts
and increasing memory overhead
synchronous and asynchronous writes
and asynchronous writes and
asynchronous writes and differentiated
writes and differentiated and
and differentiated and uniform
differentiated and uniform priorities
and uniform priorities in
uniform priorities in previous
how does this compare
priorities in previous experiments
does this compare to
this compare to traditional
and the results are
the results are given
results are given in
are given in figure
although the process is
the process is fairly
process is fairly unpredictable
codes such as reed
we see spikes and
to interpret these graphs
see spikes and anomalies
look for instance at
for instance at the
instance at the heavy
at the heavy load
we can easily recognize
the heavy load bar
can easily recognize a
heavy load bar mostly
easily recognize a super
load bar mostly reads
linear trend starting at
trend starting at around
c repair packets are
repair packets are generated
packets are generated and
are generated and sent
generated and sent for
and sent for every
sent for every r
for every r data
every r data packets
at around this point
and the correct delivery
the correct delivery of
we also start to
correct delivery of any
also start to see
delivery of any r
start to see occasional
of any r of
to see occasional bursts
any r of the
see occasional bursts of
r of the r
occasional bursts of packet
bursts of packet losses
secure untrusted data repository
c packets transmitted is
packets transmitted is sufficient
transmitted is sufficient to
is sufficient to reconstruct
sufficient to reconstruct the
to reconstruct the original
reconstruct the original r
the original r data
often roughly correlated across
original r data packets
roughly correlated across receivers
such events trigger bursty
events trigger bursty recovery
trigger bursty recovery overloads
given a lost data
a lost data packet
th conference on symposium
we can recover it
conference on symposium on
can recover it if
on symposium on opearting
recover it if at
symposium on opearting systems
it if at least
on opearting systems design
if at least r
at least r packets
least r packets are
r packets are received
packets are received correctly
number of messages pending
are received correctly in
of messages pending ack
received correctly in the
messages pending ack and
correctly in the encoding
pending ack and token
in the encoding set
ack and token roundtrip
the encoding set of
and token roundtrip time
encoding set of r
token roundtrip time as
roundtrip time as a
time as a function
as a function of
a function of the
function of the number
of the number of
the number of groups
c data and repair
applications unique files total
data and repair packets
unique files total file
and repair packets that
files total file sizes
repair packets that the
packets that the lost
that the lost packet
the lost packet belongs
lost packet belongs to
memory usage grows with
usage grows with the
the probability of recovering
grows with the number
probability of recovering a
with the number of
of recovering a lost
the number of groups
recovering a lost packet
a lost packet is
lost packet is equivalent
packet is equivalent to
beyond a certain threshold
is equivalent to the
equivalent to the probability
to the probability of
the probability of losing
probability of losing c
the system is increasingly
system is increasingly unstable
grep in the gw
or less packets from
in the gw workload
less packets from the
the gw workload even
packets from the total
gw workload even is
from the total r
workload even is less
even is less than
is less than would
less than would be
than would be expected
would be expected with
be expected with reduced
time spent in the
expected with reduced bandwidth
spent in the clr
in the clr code
since the number of
the number of other
number of other lost
here uniform priorities result
of other lost packets
uniform priorities result in
other lost packets in
priorities result in throughput
lost packets in the
result in throughput linear
packets in the xor
in throughput linear in
in the xor is
throughput linear in the
the xor is a
linear in the bandwidth
xor is a random
throughput decreases with the
is a random variable
decreases with the number
a random variable y
with the number of
random variable y and
while differentiated priorities are
variable y and has
differentiated priorities are less
y and has a
priorities are less sensitive
and has a binomial
the number of groups
has a binomial distribution
a binomial distribution with
binomial distribution with parameters
the rc and gc
rc and gc tests
and gc tests show
gc tests show the
tests show the benefit
show the benefit of
communal data sharing in
the benefit of asynchronous
data sharing in public
benefit of asynchronous writeback
sharing in public clouds
since the updates from
the updates from the
updates from the compile
from the compile workload
the compile workload are
compile workload are committed
workload are committed sooner
are committed sooner to
committed sooner to the
all groups have the
sooner to the server
groups have the same
to the server than
have the same subscribers
the server than with
server than with synchronous
than with synchronous writes
is the summation p
the summation p z
summation p z c
due to the overlap
to the overlap of
the overlap of think
overlap of think time
of think time with
think time with asynchronous
time with asynchronous writes
though uniform priorities provide
the key insight is
uniform priorities provide better
key insight is that
priorities provide better performance
insight is that all
provide better performance for
is that all these
better performance for the
that all these effects
performance for the write
all these effects originate
for the write component
these effects originate at
the write component of
effects originate at the
write component of the
we plot the recovery
component of the rw
originate at the sender
of the rw test
plot the recovery probability
the rw test at
at the sender node
the recovery probability curves
recovery probability curves for
probability curves for layered
curves for layered interleaving
for layered interleaving and
which is more loaded
layered interleaving and reed
is more loaded and
more loaded and less
loaded and less responsive
solomon against uniformly random
against uniformly random loss
uniformly random loss rate
detailed analysis of the
analysis of the captured
of the captured network
the captured network traffic
as is to be
captured network traffic shows
is to be expected
network traffic shows that
traffic shows that the
shows that the multicast
that the multicast stream
since we are prioritising
the multicast stream in
we are prioritising reads
multicast stream in all
stream in all cases
in all cases looks
all cases looks basically
cases looks basically identical
this benefit largely vanishes
benefit largely vanishes at
and hence we cannot
largely vanishes at lower
hence we cannot attribute
vanishes at lower bandwidths
note that the curves
we cannot attribute token
that the curves are
cannot attribute token latency
the curves are very
attribute token latency or
curves are very close
token latency or losses
though we have concentrated
latency or losses to
are very close to
or losses to the
very close to each
losses to the increased
close to each other
to the increased volume
we have concentrated on
the increased volume of
increased volume of traffic
have concentrated on determining
concentrated on determining the
especially in the loss
on determining the benefit
in the loss range
determining the benefit of
the loss range of
throughput spikes or longer
loss range of interest
the benefit of rpc
range of interest between
spikes or longer bursts
benefit of rpc priorities
or longer bursts of
of rpc priorities by
longer bursts of data
rpc priorities by a
priorities by a comparison
by a comparison of
a comparison of different
comparison of different configurations
of different configurations of
different configurations of mfs
configurations of mfs to
of mfs to one
the sender spends more
mfs to one another
sender spends more time
spends more time transmitting
more time transmitting at
time transmitting at lower
transmitting at lower rates
we have also performed
have also performed a
also performed a few
performed a few experiments
but doesn t produce
a few experiments to
doesn t produce any
few experiments to compare
t produce any faster
local recovery for receiver
experiments to compare the
produce any faster data
to compare the performance
recovery for receiver loss
compare the performance of
any faster data bursts
the performance of mfs
for receiver loss in
performance of mfs to
faster data bursts than
of mfs to a
receiver loss in the
mfs to a standard
data bursts than those
loss in the absence
to a standard distributed
bursts than those we
in the absence of
than those we observe
the absence of intelligent
those we observe with
absence of intelligent flow
we observe with smaller
a standard distributed file
observe with smaller numbers
of intelligent flow control
with smaller numbers of
standard distributed file system
smaller numbers of groups
intelligent flow control mechanisms
flow control mechanisms like
control mechanisms like tcp
illustrates the result of
the result of running
result of running the
of running the gw
running the gw test
the gw test over
inexpensive data center end
gw test over mfs
test over mfs and
over mfs and an
mfs and an andrew
and an andrew file
an andrew file system
receiver performance indicators such
hosts can be easily
performance indicators such as
can be easily overwhelmed
indicators such as delays
be easily overwhelmed and
such as delays in
easily overwhelmed and drop
as delays in firing
overwhelmed and drop packets
delays in firing timer
and drop packets during
in firing timer event
drop packets during traffic
firing timer event or
packets during traffic spikes
timer event or cpu
we used the arla
during traffic spikes or
used the arla implementation
traffic spikes or cpu
event or cpu utilization
the arla implementation of
or cpu utilization don
arla implementation of the
cpu utilization don t
implementation of the afs
utilization don t show
intensive maintenance tasks like
don t show any
of the afs cache
t show any noticeable
maintenance tasks like garbage
show any noticeable trend
tasks like garbage collection
the afs cache manager
all roads lead back
level protocols layered over
roads lead back to
protocols layered over udp
lead back to the
layered over udp for
back to the sender
over udp for reliable
udp for reliable multicast
and the openafs server
and the main thing
the main thing going
main thing going on
thing going on in
afs uses a udp
going on in the
on in the sender
in the sender is
the sender is that
based rpc library without
sender is that it
rpc library without priorities
is that it has
or high speed data
that it has a
high speed data transfer
it has a steadily
has a steadily growing
the results largely correspond
a steadily growing memory
results largely correspond to
steadily growing memory footprint
largely correspond to those
correspond to those in
to those in figure
we also looked at
also looked at token
looked at token round
mfs significantly outperforms afs
significantly outperforms afs for
outperforms afs for the
for example would ordinarily
afs for the foreground
example would ordinarily go
for the foreground grep
would ordinarily go back
the foreground grep workload
the distribution of token
ordinarily go back to
distribution of token roundtrip
go back to the
of token roundtrip times
back to the sender
token roundtrip times for
since afs effectively uses
to the sender to
afs effectively uses synchronous
the sender to retrieve
effectively uses synchronous rpcs
sender to retrieve the
uses synchronous rpcs with
to retrieve the lost
synchronous rpcs with uniform
retrieve the lost packet
rpcs with uniform priorities
roundtrip times for different
times for different numbers
for different numbers of
different numbers of groups
even though it was
numbers of groups shows
in the background write
of groups shows an
the background write workload
though it was dropped
groups shows an increase
it was dropped at
shows an increase of
was dropped at the
an increase of the
dropped at the receiver
increase of the token
afs slightly outperforms mfs
of the token roundtrip
at the receiver after
the token roundtrip time
the receiver after covering
receiver after covering the
after covering the entire
but it is both
covering the entire geographical
it is both a
the entire geographical distance
caused almost entirely by
is both a more
both a more mature
a more mature system
the maelstrom proxy acts
maelstrom proxy acts as
proxy acts as a
and more optimised than
acts as a local
more optimised than mfs
as a local packet
optimised than mfs for
a local packet cache
than mfs for this
of the tokens that
the miner s dilemma
the tokens that are
mfs for this sort
tokens that are delayed
for this sort of
that are delayed the
this sort of communication
storing incoming packets for
are delayed the most
miner s dilemma ittay
incoming packets for a
s dilemma ittay eyal
packets for a short
since the results of
for a short period
the results of running
dilemma ittay eyal cornell
a short period of
results of running the
ittay eyal cornell university
of running the other
short period of time
running the other tests
eyal cornell university abstract
the other tests are
period of time and
other tests are similar
cornell university abstract an
of time and providing
university abstract an open
time and providing hooks
abstract an open distributed
and providing hooks that
we omit them for
an open distributed system
which points to disruptive
omit them for brevity
points to disruptive events
open distributed system can
to disruptive events as
providing hooks that allow
distributed system can be
hooks that allow protocols
disruptive events as the
system can be secured
events as the culprit
that allow protocols to
can be secured by
allow protocols to first
be secured by requiring
mostly reads mostly writes
secured by requiring participants
protocols to first query
by requiring participants to
reads mostly writes heavy
requiring participants to present
to first query the
participants to present proof
mostly writes heavy load
to present proof of
first query the cache
writes heavy load store
present proof of work
heavy load store overhead
proof of work and
rather than a uniform
of work and rewarding
query the cache to
than a uniform increase
work and rewarding them
the cache to locate
a uniform increase of
cache to locate missing
uniform increase of the
load store overhead priorities
and rewarding them for
store overhead priorities uniform
rewarding them for participation
to locate missing packets
increase of the token
overhead priorities uniform priorities
of the token processing
locate missing packets before
the token processing overhead
priorities uniform priorities uniform
missing packets before sending
uniform priorities uniform synchronous
packets before sending retransmission
priorities uniform synchronous asynchronous
before sending retransmission requests
uniform synchronous asynchronous time
sending retransmission requests back
synchronous asynchronous time spent
retransmission requests back to
the bitcoin digital currency
requests back to the
asynchronous time spent on
back to the sender
bitcoin digital currency introduced
time spent on rpcs
digital currency introduced this
currency introduced this mechanism
we find that these
find that these tokens
future versions of maelstrom
that these tokens were
versions of maelstrom could
these tokens were most
which is adopted by
tokens were most commonly
is adopted by almost
were most commonly delayed
of maelstrom could potentially
most commonly delayed on
adopted by almost all
commonly delayed on the
maelstrom could potentially use
delayed on the sender
by almost all contemporary
could potentially use knowledge
almost all contemporary digital
potentially use knowledge of
all contemporary digital currencies
use knowledge of protocol
contemporary digital currencies and
knowledge of protocol internals
digital currencies and related
of protocol internals to
currencies and related services
with many thousands of
protocol internals to transparently
many thousands of groups
internals to transparently intervene
a natural process leads
natural process leads participants
the average time to
process leads participants of
average time to travel
leads participants of such
participants of such systems
of such systems to
by intercepting and satisfying
such systems to form
intercepting and satisfying retransmission
systems to form pools
and satisfying retransmission requests
satisfying retransmission requests sent
retransmission requests sent by
requests sent by the
sent by the receiver
where members aggregate their
by the receiver in
members aggregate their power
time to travel by
the receiver in a
aggregate their power and
receiver in a nak
their power and share
to travel by one
power and share the
travel by one hop
and share the rewards
by one hop from
one hop from sender
hop from sender to
from sender to receiver
sender to receiver or
experience with bitcoin shows
to receiver or receiver
or by resending packets
receiver or receiver to
with bitcoin shows that
or receiver to sender
by resending packets when
receiver to sender can
bitcoin shows that the
to sender can grow
resending packets when acknowledgments
sender can grow to
shows that the largest
packets when acknowledgments are
that the largest pools
can grow to nearly
the largest pools are
when acknowledgments are not
largest pools are often
acknowledgments are not observed
pools are often open
are not observed within
not observed within a
observed within a certain
within a certain time
a certain time period
allowing anyone to join
certain time period in
time period in an
period in an ack
it has long been
has long been known
long been known that
been known that a
known that a member
that a member can
a member can sabotage
as compared to an
implementation details we initially
compared to an average
member can sabotage an
details we initially implemented
can sabotage an open
we initially implemented and
sabotage an open pool
initially implemented and evaluated
an open pool by
ms per hop from
implemented and evaluated maelstrom
per hop from receiver
open pool by seemingly
hop from receiver to
and evaluated maelstrom as
from receiver to receiver
pool by seemingly joining
evaluated maelstrom as a
by seemingly joining it
maelstrom as a user
seemingly joining it but
joining it but never
it but never sharing
but never sharing its
never sharing its proofs
sharing its proofs of
its proofs of work
performance turned out to
turned out to be
out to be limited
the pool shares its
to be limited by
pool shares its revenue
be limited by copying
shares its revenue with
limited by copying and
its revenue with the
by copying and context
revenue with the attacker
the overloaded sender occasionally
overloaded sender occasionally releases
sender occasionally releases the
occasionally releases the tokens
releases the tokens with
and so each of
the tokens with a
so each of its
tokens with a delay
each of its participants
and we subsequently reimplemented
of its participants earns
we subsequently reimplemented the
its participants earns less
subsequently reimplemented the system
reimplemented the system as
the system as a
system as a module
as a module that
a module that runs
we define and analyze
module that runs within
define and analyze a
that runs within the
and analyze a game
runs within the linux
analyze a game where
a game where pools
game where pools use
where pools use some
pools use some of
use some of their
some of their participants
of their participants to
their participants to infiltrate
participants to infiltrate other
the value of the
to infiltrate other pools
value of the delay
infiltrate other pools and
of the delay grows
other pools and perform
the delay grows with
pools and perform such
delay grows with the
and perform such an
grows with the number
perform such an attack
with the number of
the number of groups
with any number of
any number of pools
at an encoding rate
an encoding rate of
attacks is not a
is not a nash
our old culprit is
not a nash equilibrium
old culprit is back
we study the special
study the special cases
related costs at the
the special cases where
costs at the sender
special cases where either
the experimental prototype of
cases where either two
experimental prototype of the
where either two pools
prototype of the kernel
either two pools or
of the kernel version
two pools or any
increasing the number of
the kernel version reaches
pools or any number
the number of groups
kernel version reaches output
number of groups slows
or any number of
of groups slows the
version reaches output speeds
groups slows the sender
any number of identical
reaches output speeds close
number of identical pools
output speeds close to
of identical pools play
identical pools play the
and this cascades to
pools play the game
this cascades to create
play the game and
gigabit per second of
the game and the
per second of combined
game and the rest
second of combined data
and the rest of
cascades to create all
the rest of the
of combined data and
rest of the participants
combined data and fec
of the participants are
data and fec traffic
the participants are uninvolved
to create all sorts
create all sorts of
all sorts of downstream
limited only by the
sorts of downstream problems
only by the capacity
in both of these
of downstream problems that
by the capacity of
both of these cases
the capacity of the
downstream problems that can
capacity of the outbound
of these cases there
of the outbound network
problems that can destabilize
the outbound network card
that can destabilize the
these cases there exists
can destabilize the system
destabilize the system as
cases there exists an
the system as a
system as a whole
there exists an equilibrium
exists an equilibrium that
an equilibrium that constitutes
lambda networks are already
equilibrium that constitutes a
networks are already reaching
are already reaching speeds
that constitutes a tragedy
already reaching speeds of
discussion the experiments just
constitutes a tragedy of
the experiments just reported
a tragedy of the
experiments just reported make
tragedy of the commons
just reported make it
of the commons where
reported make it clear
the commons where the
make it clear that
commons where the participating
it clear that the
where the participating pools
clear that the performance
the participating pools attack
participating pools attack one
pools attack one another
attack one another and
limiting factor in the
one another and earn
factor in the qsm
another and earn less
in the qsm system
and earn less than
the qsm system is
earn less than they
qsm system is latency
less than they would
than they would have
they would have if
would have if none
have if none had
and higher speeds are
and that in addition
higher speeds are a
if none had attacked
speeds are a certainty
that in addition to
are a certainty down
in addition to protocol
a certainty down the
addition to protocol factors
certainty down the road
to protocol factors such
protocol factors such as
factors such as the
such as the length
as the length of
the decision whether or
the length of token
decision whether or not
length of token rings
whether or not to
or not to attack
not to attack is
to attack is the
attack is the miner
we envision maelstrom as
is the miner s
envision maelstrom as a
the miner s dilemma
maelstrom as a small
latency is strongly influenced
as a small rack
is strongly influenced by
strongly influenced by the
influenced by the memory
an instance of the
by the memory footprint
instance of the iterative
style cluster of servers
of the iterative prisoner
the memory footprint of
the iterative prisoner s
memory footprint of the
iterative prisoner s dilemma
footprint of the system
each acting as an
acting as an individual
as an individual proxy
the game is played
game is played daily
is played daily by
played daily by the
when we built the
daily by the active
traffic would be distributed
by the active bitcoin
we built the system
the active bitcoin pools
would be distributed over
built the system it
the system it was
be distributed over such
system it was obvious
distributed over such a
it was obvious that
which apparently choose not
was obvious that minimizing
apparently choose not to
over such a rack
choose not to attack
obvious that minimizing latency
such a rack by
that minimizing latency would
minimizing latency would be
a rack by partitioning
latency would be important
rack by partitioning the
if this balance breaks
by partitioning the address
partitioning the address space
this motivated several of
the address space of
motivated several of the
the revenue of open
several of the design
revenue of open pools
of the design decisions
of open pools might
the design decisions discussed
open pools might diminish
design decisions discussed in
address space of the
decisions discussed in section
space of the remote
of the remote data
making them unattractive to
the remote data center
them unattractive to participants
remote data center and
data center and routing
center and routing different
but the repeated linkage
and routing different segments
the repeated linkage of
routing different segments of
repeated linkage of latency
different segments of the
linkage of latency and
segments of the space
of latency and oscillatory
of the space through
latency and oscillatory throughputs
the space through distinct
and oscillatory throughputs to
space through distinct maelstrom
oscillatory throughputs to memory
through distinct maelstrom appliance
throughputs to memory was
distinct maelstrom appliance pairs
to memory was a
memory was a surprise
is a digital currency
we expected a much
a digital currency that
expected a much smaller
digital currency that is
a much smaller impact
currency that is gaining
we plan to experiment
that is gaining acceptance
plan to experiment with
to experiment with such
experiment with such configurations
we can summarize our
can summarize our design
summarize our design insights
our design insights as
design insights as follows
which would also permit
would also permit us
also permit us to
permit us to explore
us to explore fault
minimize the memory footprint
if a maelstrom blade
a maelstrom blade fails
we expected that the
expected that the primary
that the primary cost
the primary cost of
with an estimated market
primary cost of managed
an estimated market capitalization
cost of managed memory
estimated market capitalization of
of managed memory would
market capitalization of over
and to support load
managed memory would be
memory would be associated
would be associated with
be associated with garbage
associated with garbage collection
balancing schemes that might
schemes that might vary
that might vary the
might vary the ip
vary the ip address
the ip address space
ip address space partitioning
all costs associated with
address space partitioning dynamically
costs associated with managed
space partitioning dynamically to
associated with managed memory
partitioning dynamically to spread
with managed memory rise
dynamically to spread the
managed memory rise in
to spread the encoding
memory rise in the
spread the encoding load
rise in the amount
the encoding load over
in the amount of
encoding load over multiple
the amount of allocated
load over multiple machines
amount of allocated memory
at least in the
least in the windows
in the windows clr
we present the implementation
present the implementation and
the implementation and performance
implementation and performance of
and performance of a
performance of a single
bitcoin s security stems
s security stems from
security stems from a
stems from a robust
from a robust incentive
the kernel implementation is
a robust incentive system
kernel implementation is a
implementation is a module
is a module for
a module for linux
whereas traditional multicast systems
participants are required to
traditional multicast systems accept
are required to provide
multicast systems accept messages
required to provide expensive
systems accept messages whenever
to provide expensive proofs
accept messages whenever the
provide expensive proofs of
messages whenever the application
expensive proofs of work
whenever the application layer
the application layer or
application layer or the
layer or the multicast
or the multicast protocols
and they are rewarded
the multicast protocols produce
they are rewarded according
multicast protocols produce it
are rewarded according to
rewarded according to their
according to their efforts
qsm uses an upcall
with hooks into the
this architecture has proved
hooks into the kernel
architecture has proved both
into the kernel packet
has proved both stable
the kernel packet filter
proved both stable and
both stable and scalable
often we can delay
we can delay generating
can delay generating a
delay generating a message
generating a message until
and it is used
a message until the
it is used by
message until the last
is used by most
until the last minute
used by most contemporary
by most contemporary digital
most contemporary digital currencies
contemporary digital currencies and
digital currencies and related
and we can also
currencies and related services
we can also avoid
can also avoid situations
maelstrom proxies work in
also avoid situations in
proxies work in pairs
avoid situations in which
situations in which data
in which data piles
which data piles up
one on each side
data piles up on
on each side of
piles up on behalf
each side of the
up on behalf of
side of the long
on behalf of an
of the long haul
behalf of an aggressive
the long haul link
of an aggressive sender
each proxy acts both
proxy acts both as
acts both as an
both as an ingress
as an ingress and
an ingress and egress
ingress and egress router
and egress router at
egress router at the
limit buffering and caching
router at the same
at the same time
the same time since
same time since they
time since they handle
most existing multicast protocols
since they handle duplex
existing multicast protocols buffer
they handle duplex traffic
multicast protocols buffer data
handle duplex traffic in
protocols buffer data at
duplex traffic in the
buffer data at many
traffic in the following
data at many layers
in the following manner
at many layers and
many layers and cache
layers and cache data
and cache data rather
cache data rather casually
data rather casually for
rather casually for recovery
the egress router captures
casually for recovery purposes
egress router captures ip
router captures ip packets
captures ip packets and
ip packets and creates
packets and creates redundant
and creates redundant fec
this turns out to
creates redundant fec packets
turns out to be
out to be extremely
to be extremely costly
be extremely costly in
the original ip packets
extremely costly in a
original ip packets are
costly in a managed
ip packets are routed
in a managed setting
packets are routed through
a managed setting and
are routed through unaltered
managed setting and must
routed through unaltered as
setting and must be
through unaltered as they
and must be avoided
unaltered as they would
must be avoided whenever
as they would have
be avoided whenever possible
they would have been
would have been originally
the redundant packets are
redundant packets are then
packets are then forwarded
our results apply to
are then forwarded to
results apply to all
then forwarded to the
apply to all such
forwarded to the remote
to all such incentive
to the remote ingress
all such incentive systems
the remote ingress router
cumulative distribution of the
remote ingress router via
distribution of the multicast
ingress router via a
of the multicast rates
router via a udp
the multicast rates for
via a udp channel
but we use bitcoin
we use bitcoin terminology
use bitcoin terminology and
bitcoin terminology and examples
the ingress router captures
terminology and examples since
ingress router captures and
and examples since it
router captures and stores
examples since it serves
captures and stores ip
since it serves as
and stores ip packets
it serves as an
stores ip packets coming
serves as an active
ip packets coming from
as an active and
packets coming from the
an active and archetypal
coming from the direction
active and archetypal example
from the direction of
the direction of the
direction of the egress
of the egress router
token roundtrip times for
bitcoin implements its incentive
implements its incentive systems
upon receipt of a
its incentive systems with
receipt of a redundant
incentive systems with a
of a redundant packet
systems with a data
with a data structure
a data structure called
data structure called the
structure called the blockchain
an ip packet is
ip packet is recovered
packet is recovered if
is recovered if there
recovered if there is
the blockchain is a
if there is an
blockchain is a serialization
there is an opportunity
is a serialization of
is an opportunity to
a serialization of all
an opportunity to do
serialization of all bitcoin
opportunity to do so
of all bitcoin transactions
redundant packets that can
it is a single
packets that can be
is a single global
that can be used
a single global ledger
can be used at
intervals between the subsequent
be used at a
between the subsequent tokens
used at a later
single global ledger maintained
at a later time
global ledger maintained by
a later time are
ledger maintained by an
later time are stored
maintained by an open
by an open distributed
an open distributed system
if the redundant packet
the redundant packet is
since anyone can join
redundant packet is useless
anyone can join the
packet is useless it
can join the open
is useless it is
join the open system
useless it is immediately
the open system and
it is immediately discarded
open system and participate
system and participate in
and participate in maintaining
participate in maintaining the
in maintaining the blockchain
upon recovery the ip
recovery the ip packet
the ip packet is
ip packet is sent
bitcoin uses a proof
packet is sent through
uses a proof of
is sent through a
a proof of work
sent through a raw
proof of work mechanism
through a raw socket
of work mechanism to
a raw socket to
work mechanism to deter
raw socket to its
mechanism to deter attacks
clear messages out of
socket to its intended
messages out of the
to its intended destination
out of the system
of the system quickly
participation requires exerting significant
requires exerting significant compute
exerting significant compute resources
using fec requires that
data paths should have
paths should have rapid
fec requires that each
should have rapid data
have rapid data movement
a participant that proves
requires that each data
rapid data movement as
participant that proves she
that each data packet
data movement as a
that proves she has
movement as a key
each data packet have
as a key goal
proves she has exerted
data packet have a
she has exerted enough
packet have a unique
has exerted enough resources
have a unique identifier
exerted enough resources with
a unique identifier that
enough resources with a
unique identifier that the
resources with a proof
identifier that the receiver
with a proof of
that the receiver can
a proof of work
the receiver can use
proof of work is
receiver can use to
of work is allowed
we ve already mentioned
can use to keep
work is allowed to
ve already mentioned that
use to keep track
already mentioned that data
is allowed to take
mentioned that data paths
to keep track of
that data paths should
allowed to take a
data paths should clear
keep track of received
paths should clear messages
to take a step
should clear messages quickly
track of received data
take a step in
of received data packets
a step in the
received data packets and
step in the protocol
but there are other
data packets and to
there are other important
in the protocol by
are other important forms
packets and to identify
other important forms of
the protocol by generating
important forms of delay
and to identify missing
protocol by generating a
to identify missing data
by generating a block
identify missing data packets
missing data packets in
data packets in a
packets in a repair
in a repair packet
participants are compensated for
most situations in which
are compensated for their
situations in which qsm
compensated for their efforts
in which qsm developed
if we had access
for their efforts with
which qsm developed convoy
their efforts with newly
we had access to
efforts with newly minted
had access to end
with newly minted bitcoins
like behavior or oscillatory
behavior or oscillatory throughput
the process of creating
or oscillatory throughput can
process of creating a
of creating a block
oscillatory throughput can be
creating a block is
we could have added
a block is called
throughput can be traced
block is called mining
could have added a
can be traced to
have added a header
be traced to design
added a header to
traced to design decisions
a header to each
and the participants miners
to design decisions that
header to each packet
design decisions that caused
to each packet with
decisions that caused scheduling
each packet with a
in order to win
packet with a unique
order to win the
with a unique sequence
to win the reward
a unique sequence number
that caused scheduling jitter
caused scheduling jitter or
scheduling jitter or allowed
jitter or allowed some
many miners try to
or allowed some form
miners try to generate
allowed some form of
try to generate blocks
some form of priority
form of priority inversion
of priority inversion to
priority inversion to occur
the system automatically adjusts
system automatically adjusts the
automatically adjusts the difficulty
adjusts the difficulty of
delaying a crucial message
the difficulty of block
a crucial message behind
difficulty of block generation
crucial message behind a
message behind a less
behind a less important
a less important one
such that one block
we intercept traffic transparently
that one block is
intercept traffic transparently and
one block is added
traffic transparently and need
block is added every
transparently and need to
implications included the following
route it without modification
it without modification or
without modification or addition
minutes to the blockchain
this means that each
means that each miner
that each miner seldom
each miner seldom generates
event handlers should be
miner seldom generates a
handlers should be short
seldom generates a block
we identify ip packets
identify ip packets by
ip packets by a
packets by a tuple
although its revenue may
by a tuple consisting
its revenue may be
a tuple consisting of
revenue may be positive
tuple consisting of the
may be positive in
consisting of the source
be positive in expectation
of the source and
we struggled to make
the source and destination
source and destination ip
struggled to make the
and destination ip address
a miner may have
to make the overall
miner may have to
make the overall behavior
may have to wait
the overall behavior of
have to wait for
overall behavior of the
to wait for an
size of the ip
behavior of the system
of the ip header
wait for an extended
the ip header plus
of the system as
ip header plus data
for an extended period
the system as predictable
an extended period to
system as predictable as
extended period to create
as predictable as possible
period to create a
and a checksum over
to create a block
predictable as possible not
create a block and
a checksum over the
as possible not a
checksum over the ip
a block and earn
over the ip data
possible not a trivial
the ip data payload
block and earn the
not a trivial task
and earn the actual
a trivial task in
earn the actual bitcoins
trivial task in configurations
the checksum over the
task in configurations where
checksum over the payload
in configurations where hundreds
over the payload is
configurations where hundreds of
the payload is necessary
where hundreds of processes
payload is necessary since
hundreds of processes might
is necessary since the
of processes might be
miners form mining pools
processes might be multicasting
necessary since the ip
might be multicasting in
since the ip identification
be multicasting in thousands
the ip identification field
multicasting in thousands of
where all members mine
ip identification field is
in thousands of overlapping
identification field is only
thousands of overlapping groups
all members mine concurrently
members mine concurrently and
mine concurrently and they
concurrently and they share
and they share their
by keeping event handlers
they share their revenue
keeping event handlers short
bits long and a
share their revenue whenever
long and a single
event handlers short and
and a single pair
their revenue whenever one
a single pair of
handlers short and predictable
single pair of end
revenue whenever one of
short and predictable and
whenever one of them
and predictable and eliminating
one of them creates
predictable and eliminating the
of them creates a
and eliminating the need
hosts communicating at high
eliminating the need for
them creates a block
communicating at high speeds
the need for locking
at high speeds will
high speeds will use
speeds will use the
pools are typically implemented
we obtained a more
are typically implemented as
will use the same
typically implemented as a
obtained a more predictable
use the same identifier
implemented as a pool
a more predictable system
as a pool manager
the same identifier for
a pool manager and
more predictable system and
same identifier for different
predictable system and were
pool manager and a
system and were able
identifier for different data
and were able to
manager and a cohort
were able to eliminate
and a cohort of
for different data packets
able to eliminate multithreading
different data packets within
a cohort of miners
data packets within a
packets within a fairly
within a fairly short
with the associated context
a fairly short interval
the associated context switching
the pool manager joins
fairly short interval unless
pool manager joins the
associated context switching and
manager joins the bitcoin
short interval unless the
joins the bitcoin system
interval unless the checksum
the bitcoin system as
context switching and locking
bitcoin system as a
unless the checksum is
system as a single
switching and locking overheads
as a single miner
the checksum is added
checksum is added to
is added to differentiate
added to differentiate between
to differentiate between them
instead of generating proof
of generating proof of
generating proof of work
it outsources the work
outsources the work to
the work to the
unique identifiers result in
work to the miners
identifiers result in garbled
result in garbled recovery
in garbled recovery by
here we encounter a
garbled recovery by maelstrom
we encounter a tension
in order to evaluate
encounter a tension between
order to evaluate the
a tension between two
to evaluate the miners
tension between two goals
evaluate the miners efforts
an event which will
event which will be
which will be caught
from a memory footprint
will be caught by
a memory footprint perspective
the pool manager accepts
be caught by higher
pool manager accepts partial
caught by higher level
manager accepts partial proof
by higher level checksums
one might prefer not
accepts partial proof of
might prefer not to
higher level checksums designed
partial proof of work
prefer not to pull
level checksums designed to
proof of work and
not to pull in
checksums designed to deal
to pull in a
of work and estimates
designed to deal with
pull in a message
work and estimates each
in a message until
to deal with tranmission
a message until qsm
and estimates each miner
deal with tranmission errors
message until qsm can
estimates each miner s
until qsm can process
with tranmission errors on
qsm can process it
each miner s power
tranmission errors on commodity
miner s power according
errors on commodity networks
s power according to
on commodity networks and
power according to the
but in a datacenter
according to the rate
in a datacenter or
commodity networks and hence
a datacenter or cluster
to the rate with
networks and hence does
the rate with which
and hence does not
rate with which it
hence does not have
with which it submits
most message loss occurs
which it submits such
message loss occurs in
it submits such partial
loss occurs in the
submits such partial proof
occurs in the operating
such partial proof of
in the operating system
partial proof of work
does not have significant
mostly reads mostly writes
not have significant consequences
reads mostly writes heavy
have significant consequences unless
not on the network
significant consequences unless it
when a miner generates
consequences unless it occurs
a miner generates a
unless it occurs frequently
miner generates a full
mostly writes heavy load
generates a full proof
hence message loss rates
writes heavy load store
message loss rates soar
a full proof of
loss rates soar if
full proof of work
heavy load store overhead
rates soar if we
load store overhead priorities
the kernel version of
store overhead priorities uniform
soar if we leave
overhead priorities uniform priorities
it sends it to
if we leave messages
sends it to the
we leave messages on
kernel version of maelstrom
leave messages on input
it to the pool
version of maelstrom can
messages on input sockets
of maelstrom can generate
on input sockets for
priorities uniform priorities uniform
to the pool manager
uniform priorities uniform synchronous
input sockets for long
priorities uniform synchronous asynchronous
the pool manager which
uniform synchronous asynchronous figure
maelstrom can generate up
pool manager which publishes
can generate up to
manager which publishes this
generate up to a
which publishes this proof
up to a gigabit
publishes this proof of
to a gigabit per
this proof of work
a gigabit per second
proof of work to
gigabit per second of
of work to the
per second of data
work to the bitcoin
second of data and
to the bitcoin system
of data and fec
control the event processing
graphs of ntfs traces
the event processing order
data and fec traffic
the pool manager thus
each trace ran with
pool manager thus receives
trace ran with synchronous
with the input data
ran with synchronous or
manager thus receives the
the input data rate
with synchronous or asynchronous
thus receives the full
synchronous or asynchronous writes
input data rate depending
or asynchronous writes and
data rate depending on
asynchronous writes and uniform
rate depending on the
writes and uniform or
depending on the encoding
receives the full revenue
on the encoding rate
and uniform or differentiated
the full revenue of
uniform or differentiated priorities
full revenue of the
revenue of the block
and the imposition of
of the block and
the imposition of an
the block and distributes
imposition of an internal
block and distributes it
the total height of
and distributes it fairly
we were able to
distributes it fairly according
were able to saturate
it fairly according to
total height of each
fairly according to its
able to saturate the
of an internal event
to saturate the outgoing
an internal event processing
saturate the outgoing card
internal event processing prioritization
height of each bar
according to its members
the outgoing card at
of each bar denotes
small delays add up
each bar denotes the
delays add up in
bar denotes the time
add up in large
outgoing card at rates
to its members power
card at rates as
up in large systems
at rates as high
denotes the time from
rates as high as
the time from the
time from the first
from the first to
many of the pools
the first to last
tight control over event
of the pools are
control over event processing
first to last write
over event processing largely
the pools are open
event processing largely eliminated
pools are open they
processing largely eliminated convoy
are open they allow
largely eliminated convoy effects
and the shaded portion
eliminated convoy effects and
open they allow any
convoy effects and oscillatory
the shaded portion denotes
effects and oscillatory throughput
they allow any miner
and oscillatory throughput problems
allow any miner to
shaded portion denotes the
any miner to join
portion denotes the time
miner to join them
denotes the time from
to join them using
the time from the
join them using a
time from the first
them using a public
from the first to
using a public internet
the first to last
with cpu overload occurring
a public internet interface
cpu overload occurring at
first to last read
act on fresh state
such open pools are
the white portions denote
open pools are susceptible
white portions denote the
pools are susceptible to
portions denote the extra
are susceptible to the
denote the extra time
many inefficiencies can be
susceptible to the classical
the extra time required
to the classical block
extra time required to
the classical block withholding
inefficiencies can be traced
classical block withholding attack
time required to complete
can be traced to
required to complete all
be traced to situations
to complete all writes
where each incoming data
complete all writes after
traced to situations in
all writes after the
each incoming data packet
writes after the last
to situations in which
after the last read
incoming data packet had
situations in which one
data packet had to
the last read has
packet had to be
last read has finished
had to be xored
in which one node
which one node takes
one node takes action
node takes action on
takes action on the
action on the basis
on the basis of
where a miner sends
the basis of stale
for asynchronous writeback with
basis of stale state
a miner sends only
of stale state information
asynchronous writeback with priorities
stale state information from
writeback with priorities in
state information from some
with priorities in the
information from some other
buffering requirements at the
from some other node
requirements at the receive
miner sends only partial
sends only partial proof
only partial proof of
partial proof of work
triggering redundant retransmissions or
proof of work to
redundant retransmissions or other
of work to the
retransmissions or other overheads
work to the pool
to the pool manager
incoming data packets are
the pool manager and
data packets are buffered
pool manager and discards
packets are buffered so
this shows that the
manager and discards full
shows that the total
are buffered so that
that the total duration
and discards full proof
the total duration of
discards full proof of
total duration of the
full proof of work
the pull architecture has
buffered so that they
duration of the trace
so that they can
of the trace with
pull architecture has the
the trace with this
due to the partial
trace with this mfs
to the partial proof
with this mfs configuration
architecture has the secondary
this mfs configuration is
the partial proof of
has the secondary benefit
partial proof of work
that they can be
proof of work it
the secondary benefit of
of work it sends
they can be used
work it sends to
can be used in
it sends to the
secondary benefit of letting
sends to the pool
be used in conjunction
benefit of letting us
used in conjunction with
of letting us delay
in conjunction with xors
letting us delay the
conjunction with xors to
us delay the preparation
the miner is considered
delay the preparation of
with xors to recover
the preparation of status
xors to recover missing
miner is considered a
to recover missing data
preparation of status packets
recover missing data packets
but all the fetch
is considered a regular
all the fetch traffic
of status packets until
the fetch traffic is
considered a regular pool
fetch traffic is completed
status packets until they
traffic is completed within
a regular pool member
packets until they are
regular pool member and
until they are about
pool member and the
they are about to
any received xor that
are about to be
member and the pool
about to be transmitted
received xor that is
and the pool can
xor that is missing
the pool can estimate
that is missing more
pool can estimate its
is missing more than
can estimate its power
missing more than one
more than one data
than one data packet
one data packet is
seconds of the start
data packet is stored
conclusions the premise of
packet is stored temporarily
the premise of our
the attacker shares the
this is a significant
attacker shares the revenue
premise of our work
shares the revenue obtained
is a significant improvement
of our work is
the revenue obtained by
in case all but
revenue obtained by the
our work is that
obtained by the other
case all but one
by the other pool
work is that developers
a significant improvement over
all but one of
significant improvement over the
is that developers of
improvement over the alternative
but one of the
over the alternative configurations
that developers of services
the alternative configurations measured
one of the missing
the other pool members
of the missing packets
developers of services intended
the missing packets are
of services intended to
missing packets are received
but does not contribute
packets are received later
services intended to run
are received later or
intended to run on
received later or recovered
to run on clustered
later or recovered through
it reduces the revenue
or recovered through other
run on clustered platforms
recovered through other xors
reduces the revenue of
on clustered platforms desire
the revenue of the
seconds of the trace
clustered platforms desire the
of the trace are
revenue of the other
the trace are taken
of the other members
trace are taken up
platforms desire the productivity
are taken up by
allowing the recovery of
taken up by asynchronously
desire the productivity and
up by asynchronously writing
but also its own
the recovery of the
the productivity and robustness
recovery of the remaining
by asynchronously writing back
of the remaining missing
asynchronously writing back file
productivity and robustness benefits
writing back file updates
we provide necessary background
the remaining missing packet
provide necessary background on
remaining missing packet from
necessary background on the
and robustness benefits of
background on the bitcoin
missing packet from this
on the bitcoin protocol
packet from this xor
in all cases the
robustness benefits of managed
all cases the traces
benefits of managed environments
cases the traces take
pools and the classical
the traces take significantly
and the classical block
in practice we stored
the classical block withholding
practice we stored data
and need replication tools
we stored data and
need replication tools integrated
traces take significantly longer
replication tools integrated with
stored data and xor
tools integrated with those
data and xor packets
classical block withholding attack
and xor packets in
integrated with those environments
xor packets in double
block withholding attack in
take significantly longer than
withholding attack in section
packets in double buffered
attack in section ii
significantly longer than they
building such tools so
longer than they originally
such tools so posed
than they originally did
in double buffered red
tools so posed challenges
double buffered red black
they originally did in
buffered red black trees
originally did in ntfs
red black trees for
so posed challenges to
and specify our model
posed challenges to us
specify our model in
challenges to us as
our model in section
to us as protocol
model in section iii
us as protocol and
where they were mostly
as protocol and system
they were mostly accessing
protocol and system designers
were mostly accessing the
mostly accessing the local
for a broader view
accessing the local file
a broader view of
the local file system
which were the primary
local file system and
were the primary focus
broader view of the
the primary focus of
file system and therefore
primary focus of our
view of the protocol
system and therefore had
focus of our paper
and therefore had no
of the protocol and
therefore had no bandwidth
the protocol and ecosystem
had no bandwidth constraints
protocol and ecosystem the
a central insight is
and ecosystem the reader
central insight is that
ecosystem the reader may
insight is that high
the reader may refer
the results largely repeat
reader may refer to
entries this occupies around
results largely repeat those
may refer to the
largely repeat those seen
performance protocols running in
repeat those seen in
refer to the survey
protocols running in managed
those seen in the
to the survey by
seen in the microbenchmarks
running in managed settings
the survey by bonneau
in managed settings need
survey by bonneau et
managed settings need to
by bonneau et al
settings need to maintain
to the extent that
need to maintain the
the extent that the
to maintain the smallest
extent that the greatest
maintain the smallest possible
that the greatest performance
the repair bins in
the smallest possible memory
the greatest performance improvements
smallest possible memory footprint
repair bins in the
greatest performance improvements are
bins in the layered
performance improvements are seen
in the layered interleaving
improvements are seen at
the layered interleaving scheme
are seen at low
layered interleaving scheme store
seen at low bandwidth
interleaving scheme store incrementally
at low bandwidth when
scheme store incrementally computed
low bandwidth when there
store incrementally computed xors
bandwidth when there is
incrementally computed xors and
when there is high
computed xors and lists
there is high read
xors and lists of
and lists of data
in this work we
lists of data packet
this work we analyze
of data packet headers
work we analyze block
we analyze block withholding
analyze block withholding attacks
block withholding attacks among
plication of this principle
withholding attacks among pools
such as in the
without the data packet
as in the mostly
the data packet payloads
qsm achieves scalability and
a pool that employs
achieves scalability and stability
pool that employs the
scalability and stability even
resulting in low storage
and stability even at
that employs the pool
stability even at very
in low storage overheads
even at very high
employs the pool block
at very high loads
low storage overheads for
writes trace where there
storage overheads for each
trace where there is
the pool block withholding
overheads for each layer
pool block withholding attack
an unexpected side effect
for each layer that
block withholding attack registers
unexpected side effect of
where there is an
each layer that rise
withholding attack registers with
side effect of building
attack registers with the
layer that rise linearly
registers with the victim
effect of building qsm
with the victim pool
that rise linearly with
the victim pool as
of building qsm in
victim pool as a
rise linearly with the
pool as a regular
building qsm in windows
as a regular miner
qsm in windows was
decrease in the time
in windows was that
in the time spent
windows was that by
the time spent to
was that by integrating
time spent to read
it receives tasks from
spent to read all
that by integrating our
to read all the
receives tasks from the
read all the files
tasks from the victim
by integrating our system
linearly with the value
integrating our system tightly
from the victim pool
our system tightly with
with the value of
the victim pool and
the value of the
system tightly with the
value of the interleave
victim pool and transfers
even at the higher
tightly with the platform
at the higher bandwidth
pool and transfers them
the higher bandwidth of
and transfers them to
transfers them to some
the memory footprint for
them to some of
memory footprint for a
to some of its
footprint for a longrunning
some of its own
we created a new
of its own miners
for a longrunning proxy
created a new kind
a longrunning proxy was
a new kind of
longrunning proxy was around
new kind of live
kind of live distributed
of live distributed objects
we call these infiltrating
call these infiltrating miners
abstract data types that
data types that form
mb in our experiments
types that form groups
there is a decrease
and the mining power
is a decrease of
the mining power spent
mining power spent by
power spent by a
spent by a pool
by a pool the
a pool the infiltration
pool the infiltration rate
and that are updated
other performance enhancing roles
that are updated using
performance enhancing roles maelstrom
are updated using qsm
updated using qsm multicasts
when the attacking pool
enhancing roles maelstrom appliances
the attacking pool s
roles maelstrom appliances can
attacking pool s infiltrating
maelstrom appliances can optionally
the mostlyreads trace is
these look natural to
mostlyreads trace is not
look natural to the
pool s infiltrating miners
appliances can optionally aggregate
s infiltrating miners deliver
natural to the windows
infiltrating miners deliver partial
to the windows user
miners deliver partial proofs
can optionally aggregate small
trace is not much
deliver partial proofs of
is not much affected
partial proofs of work
not much affected by
such an object changes
much affected by changes
optionally aggregate small subkilobyte
affected by changes in
an object changes faster
by changes in the
object changes faster than
changes in the configuration
changes faster than the
aggregate small subkilobyte packets
faster than the average
the attacker transfers them
than the average windows
small subkilobyte packets from
the average windows object
attacker transfers them to
subkilobyte packets from different
transfers them to the
packets from different flows
them to the victim
from different flows into
although there is a
different flows into larger
but the same basic
flows into larger ones
there is a slight
into larger ones for
the same basic mechanisms
larger ones for better
is a slight decrease
ones for better communication
same basic mechanisms can
for better communication efficiency
basic mechanisms can support
better communication efficiency over
mechanisms can support them
communication efficiency over the
a slight decrease in
efficiency over the long
to the victim pool
slight decrease in both
decrease in both read
and the component integration
in both read and
the component integration environment
letting the attacked pool
both read and write
the attacked pool estimate
read and write times
attacked pool estimate their
and write times for
pool estimate their power
write times for prioritised
times for prioritised asynchronous
in split flow control
for prioritised asynchronous writeback
split flow control mode
flow control mode they
control mode they can
when the infiltrating miners
mode they can perform
the infiltrating miners deliver
they can perform send
infiltrating miners deliver a
miners deliver a full
extends seamlessly to encompass
deliver a full proof
seamlessly to encompass them
a full proof of
side buffering of in
full proof of work
although a great deal
a great deal of
flight data for multi
great deal of additional
the attacking pool discards
deal of additional work
attacking pool discards it
of additional work is
additional work is needed
gigabyte flows that exceed
flows that exceed the
that exceed the sending
exceed the sending end
this attack affects the
qsm should eventually enable
attack affects the revenues
should eventually enable casual
load trace performs best
affects the revenues of
host s buffering capacity
trace performs best with
eventually enable casual use
performs best with uniform
the revenues of the
best with uniform asynchronous
enable casual use of
revenues of the pools
casual use of live
of the pools in
with uniform asynchronous writeback
the pools in several
use of live objects
pools in several ways
maelstrom appliances can act
of live objects not
appliances can act as
live objects not just
can act as multicast
we once again attribute
act as multicast forwarding
once again attribute this
as multicast forwarding nodes
again attribute this to
objects not just in
attribute this to inefficiency
not just in datacenters
this to inefficiency in
the victim pool s
to inefficiency in the
appliances send multicast packets
inefficiency in the rpc
send multicast packets to
in the rpc protocol
multicast packets to each
just in datacenters but
victim pool s effective
in datacenters but also
packets to each other
datacenters but also on
to each other across
but also on desktops
each other across the
also on desktops in
other across the long
pool s effective mining
since under extremely heavy
s effective mining rate
on desktops in wan
effective mining rate is
desktops in wan settings
mining rate is unchanged
under extremely heavy load
extremely heavy load and
heavy load and high
and use ip multicast
load and high bandwidth
but its total revenue
opening the door to
its total revenue is
and high bandwidth it
total revenue is divided
the door to a
revenue is divided among
high bandwidth it performs
is divided among more
door to a new
divided among more miners
to a new style
bandwidth it performs better
a new style of
it performs better when
new style of distributed
the attacker s mining
performs better when all
attacker s mining power
style of distributed programming
s mining power is
to spread them within
mining power is reduced
better when all messages
spread them within their
when all messages have
them within their data
all messages have the
within their data centers
messages have the same
the current version of
have the same priority
since some of its
current version of qsm
some of its miners
version of qsm is
of its miners are
of qsm is stable
its miners are used
qsm is stable in
miners are used for
is stable in cluster
are used for block
stable in cluster settings
used for block withholding
in cluster settings and
appliances can take on
a file group is
can take on other
file group is implemented
take on other existing
group is implemented as
on other existing roles
but it earns additional
other existing roles in
is implemented as a
existing roles in the
it earns additional revenue
implemented as a special
roles in the data
as a special type
in the data center
has a growing community
earns additional revenue through
a special type of
additional revenue through its
a growing community of
revenue through its infiltration
special type of file
through its infiltration of
acting as security and
its infiltration of the
type of file within
growing community of users
of file within the
infiltration of the other
as security and vpn
of the other pool
file within the mfs
security and vpn gateways
within the mfs file
and vpn gateways and
looking to the future
vpn gateways and as
the mfs file system
gateways and as conventional
and as conventional performance
as conventional performance enhancing
conventional performance enhancing proxies
we plan to scale
with its own file
plan to scale qsm
its own file identifier
to scale qsm into
the total effective mining
scale qsm into wan
total effective mining power
qsm into wan settings
effective mining power in
mining power in the
but not attached to
power in the system
not attached to any
in the system is
attached to any specific
to support a wider
to any specific directory
the system is reduced
support a wider range
a wider range of
wider range of multicast
range of multicast reliability
the file group a
of multicast reliability properties
file group a file
causing the bitcoin protocol
group a file belongs
the bitcoin protocol to
a file belongs to
bitcoin protocol to reduce
protocol to reduce the
and to introduce a
to reduce the difficulty
to introduce a gossip
introduce a gossip infrastructure
a gossip infrastructure that
gossip infrastructure that would
taking all these factors
is one of its
infrastructure that would support
e valuation we evaluated
one of its attributes
valuation we evaluated maelstrom
that would support configuration
we evaluated maelstrom on
all these factors into
evaluated maelstrom on the
these factors into account
maelstrom on the emulab
would support configuration discovery
on the emulab testbed
the mfs prefetching subsystem
the emulab testbed at
support configuration discovery and
emulab testbed at utah
mfs prefetching subsystem derives
we observe that a
configuration discovery and other
prefetching subsystem derives much
discovery and other self
observe that a pool
subsystem derives much of
that a pool might
derives much of its
a pool might be
much of its effectiveness
pool might be able
of its effectiveness from
might be able to
its effectiveness from being
be able to increase
effectiveness from being combined
able to increase its
from being combined with
to increase its revenue
being combined with prioritised
increase its revenue by
combined with prioritised rpcs
live objects pose a
its revenue by attacking
objects pose a protocol
revenue by attacking other
pose a protocol design
by attacking other pools
a protocol design challenge
for all the experiments
while the prefetching algorithm
the prefetching algorithm in
prefetching algorithm in mfs
they give rise to
each pool therefore makes
give rise to irregular
we used a dumbbell
rise to irregular patterns
pool therefore makes a
to irregular patterns of
used a dumbbell topology
irregular patterns of overlapping
therefore makes a choice
a dumbbell topology of
algorithm in mfs is
makes a choice of
dumbbell topology of two
in mfs is straightforward
topology of two clusters
a choice of whether
of two clusters of
patterns of overlapping multicast
choice of whether to
of overlapping multicast groups
two clusters of nodes
it can still make
clusters of nodes connected
of whether to attack
of nodes connected via
can still make bad
nodes connected via routing
whether to attack each
still make bad decisions
connected via routing nodes
to attack each of
via routing nodes with
oriented state aggregation mechanisms
routing nodes with a
attack each of the
nodes with a high
state aggregation mechanisms will
make bad decisions without
aggregation mechanisms will need
each of the other
bad decisions without a
mechanisms will need to
of the other pools
decisions without a large
will need to be
latency link in between
need to be redesigned
link in between them
the other pools in
without a large overall
other pools in the
pools in the system
a large overall performance
we have an idea
designed to emulate the
large overall performance penalty
to emulate the setup
have an idea for
emulate the setup in
an idea for solving
the setup in figure
idea for solving this
overall performance penalty because
and with what infiltration
performance penalty because the
with what infiltration rate
penalty because the interference
because the interference of
the interference of prefetching
interference of prefetching with
this gives rise to
and ran the proxy
gives rise to the
recovery would be performed
rise to the pool
of prefetching with other
ran the proxy code
prefetching with other file
the proxy code on
with other file system
proxy code on the
other file system activity
code on the routers
file system activity is
would be performed by
system activity is minimised
to the pool game
be performed by selecting
performed by selecting a
by selecting a subset
selecting a subset of
a subset of nodes
we specify this game
subset of nodes that
in the same way
specify this game and
the same way that
this game and provide
same way that some
game and provide initial
of nodes that form
and provide initial analysis
way that some local
provide initial analysis in
nodes that form a
initial analysis in section
that some local file
analysis in section iv
that form a clean
show the performance of
form a clean overlay
some local file systems
a clean overlay structure
the performance of the
local file systems execute
performance of the kernel
file systems execute speculative
of the kernel version
in section v we
the kernel version at
systems execute speculative operations
kernel version at gigabit
section v we analyze
version at gigabit speeds
execute speculative operations to
v we analyze the
rather than just treating
speculative operations to improve
we analyze the scenario
operations to improve performance
than just treating every
the remainder of the
analyze the scenario where
just treating every single
remainder of the graphs
treating every single receiver
the scenario where exactly
every single receiver as
of the graphs show
single receiver as a
scenario where exactly two
receiver as a member
the graphs show the
as a member of
graphs show the performance
a member of a
where exactly two of
member of a recovery
show the performance of
of a recovery region
exactly two of the
the performance of the
two of the pools
performance of the user
of the pools take
mfs makes use of
the pools take part
makes use of the
pools take part in
use of the speculative
take part in the
space version at slower
part in the game
version at slower speeds
in the game and
whether this can really
the game and only
this can really scale
game and only one
can really scale remains
and only one can
of the speculative communication
only one can attack
to emulate the mtu
one can attack the
the speculative communication of
really scale remains to
emulate the mtu difference
scale remains to be
speculative communication of prioritised
remains to be seen
can attack the other
the mtu difference between
communication of prioritised rpcs
mtu difference between the
of prioritised rpcs in
difference between the long
prioritised rpcs in the
rpcs in the hope
in the hope of
the hope of achieving
hope of achieving a
haul link and the
of achieving a benefit
the attacker can always
achieving a benefit through
attacker can always increase
a benefit through prefetching
link and the data
benefit through prefetching files
and the data center
can always increase its
the data center network
always increase its revenue
increase its revenue by
its revenue by attacking
we conclude that in
conclude that in the
that in the general
in the general case
we set an mtu
set an mtu of
mfs prefetching implementation the
with any number of
prefetching implementation the mfs
any number of pools
implementation the mfs cache
the mfs cache manager
mfs cache manager incorporates
cache manager incorporates a
manager incorporates a small
incorporates a small prefetching
a small prefetching module
bytes on the network
which can be optionally
on the network connecting
attacks is not a
the network connecting the
can be optionally enabled
network connecting the end
is not a nash
be optionally enabled at
not a nash equilibrium
optionally enabled at start
hosts to the proxy
to the proxy and
the proxy and an
proxy and an mtu
and an mtu of
section vi deals with
when it is initialised
vi deals with the
deals with the case
with the case of
the case of two
case of two pools
a prefetching thread starts
prefetching thread starts and
thread starts and initiates
where each can attack
starts and initiates prefetch
each can attack the
and initiates prefetch requests
can attack the other
bytes on the long
initiates prefetch requests in
prefetch requests in parallel
requests in parallel with
in parallel with the
haul link between proxies
parallel with the main
with the main activity
the main activity of
analysis becomes more complicated
main activity of the
becomes more complicated in
activity of the cache
the only exception is
of the cache manager
more complicated in two
only exception is figure
complicated in two ways
the core component of
core component of the
component of the cache
of the cache manager
the cache manager alerts
the revenue of each
cache manager alerts the
revenue of each pool
where we maintained equal
of each pool affects
manager alerts the prefetching
we maintained equal mtus
each pool affects the
maintained equal mtus of
design and implementation of
pool affects the revenue
alerts the prefetching module
affects the revenue of
and implementation of a
the revenue of the
the prefetching module every
revenue of the other
implementation of a reliable
of the other through
prefetching module every time
the other through the
of a reliable group
other through the infiltrating
module every time an
through the infiltrating miners
a reliable group communication
every time an application
reliable group communication toolkit
time an application reads
group communication toolkit for
an application reads or
communication toolkit for java
application reads or writes
bytes on both links
we prove that for
reads or writes a
prove that for a
or writes a file
that for a static
for a static choice
a static choice of
static choice of infiltration
by calling the file
choice of infiltration rates
calling the file access
all the experiments are
the file access routine
of infiltration rates the
the experiments are done
infiltration rates the pool
experiments are done with
rates the pool revenues
are done with maelstrom
the pool revenues converge
done with maelstrom using
this routine checks whether
with maelstrom using end
routine checks whether the
checks whether the file
whether the file belongs
the file belongs to
file belongs to a
belongs to a file
to a file group
a file group if
once one pool changes
file group if not
one pool changes its
pool changes its infiltration
changes its infiltration rate
its infiltration rate of
infiltration rate of the
the access is ignored
rate of the other
the latter may prefer
latter may prefer to
may prefer to change
prefetching it is a
prefer to change its
it is a member
to change its infiltration
is a member of
change its infiltration rate
a member of a
its infiltration rate of
member of a file
infiltration rate of the
of a file group
rate of the former
the group is put
therefore the game itself
group is put at
which illustrates the performance
is put at the
the game itself takes
put at the head
illustrates the performance of
at the head of
game itself takes multiple
the head of the
the performance of split
head of the prefetch
itself takes multiple rounds
of the prefetch list
performance of split mode
takes multiple rounds to
of split mode flow
multiple rounds to converge
split mode flow control
the prefetch thread periodically
prefetch thread periodically examines
we show analytically that
thread periodically examines the
design and evaluation of
show analytically that the
and evaluation of a
periodically examines the prefetching
evaluation of a wide
analytically that the game
examines the prefetching is
that the game has
the prefetching is commonly
the game has a
prefetching is commonly used
area event notification service
is commonly used to
game has a single
commonly used to improve
has a single nash
used to improve the
a single nash equilibrium
acm transactions on computer
to improve the performance
transactions on computer systems
improve the performance of
single nash equilibrium and
the performance of lo
nash equilibrium and numerically
show that commodity tcp
equilibrium and numerically study
and numerically study the
numerically study the equilibrium
group at the head
study the equilibrium points
at the head of
ip throughput collapses in
the equilibrium points for
throughput collapses in the
equilibrium points for different
collapses in the presence
points for different pool
in the presence of
for different pool sizes
the head of the
the presence of non
head of the list
for pools smaller than
if the group file
the group file for
group file for the
file for the group
and that maelstrom successfully
for the group is
that maelstrom successfully masks
the group is cal
maelstrom successfully masks loss
group is cal file
successfully masks loss and
is cal file systems
masks loss and prevents
loss and prevents this
and prevents this collapse
prevents this collapse from
this collapse from occurring
as well as distributed
at the equilibrium point
well as distributed file
the equilibrium point both
as distributed file systems
equilibrium point both pools
point both pools earn
both pools earn less
pools earn less than
earn less than they
less than they would
than they would have
they would have in
would have in the
shows the performance of
not in the cache
the performance of the
have in the nonequilibrium
performance of the userspace
in the nonequilibrium no
of the userspace version
the userspace version on
userspace version on a
it retrieves it from
retrieves it from the
it from the server
then it scans the
it scans the in
scans the in a
the in a file
in a file system
since pools can decide
a file system with
pools can decide to
file system with whole
mbps link and figure
can decide to start
decide to start or
to start or stop
start or stop attacking
or stop attacking at
stop attacking at any
attacking at any point
shows the kernel version
a mechanism is required
the kernel version on
kernel version on a
mechanism is required files
this can be modeled
is required files in
can be modeled as
required files in the
be modeled as the
files in the group
modeled as the miner
in the group in
as the miner s
the group in order
the miner s dilemma
the experiment in each
group in order until
experiment in each case
miner s dilemma an
in each case involves
in order until it
each case involves running
s dilemma an instance
case involves running iperf
order until it finds
dilemma an instance of
until it finds the
an instance of the
it finds the first
instance of the iterative
finds the first one
of the iterative prisoner
the first one which
the iterative prisoner s
first one which is
iterative prisoner s dilemma
one which is not
which is not to
is not to determine
not to determine appropriate
to determine appropriate prefetching
attacking is the dominant
determine appropriate prefetching hints
is the dominant strategy
flows from one node
the dominant strategy in
from one node to
dominant strategy in each
one node to another
strategy in each iteration
node to another across
to another across the
earlier work in file
another across the long
work in file in
in file in the
weight process groups in
but if the pools
file in the cache
if the pools can
process groups in the
the pools can agree
groups in the isis
pools can agree not
in the isis system
can agree not to
distance link with and
agree not to attack
link with and without
with and without intermediary
and without intermediary maelstrom
and issues a prefetch
without intermediary maelstrom proxies
both benefit in the
issues a prefetch request
benefit in the long
intermediary maelstrom proxies and
in the long run
a prefetch request or
maelstrom proxies and measuring
prefetch request or system
proxies and measuring obtained
request or system prefetching
and measuring obtained throughput
or system prefetching has
measuring obtained throughput while
system prefetching has used
obtained throughput while varying
prefetching has used clustering
throughput while varying loss
has used clustering to
while varying loss rate
we address in section
used clustering to derive
address in section vii
clustering to derive file
in section vii the
to derive file groups
section vii the case
derive file groups from
left graph on each
file groups from validation
graph on each figure
vii the case where
groups from validation request
the case where the
from validation request for
case where the participants
validation request for it
where the participants are
the participants are an
participants are an arbitrary
are an arbitrary number
an arbitrary number of
arbitrary number of identical
number of identical pools
if all the files
all the files are
the files are valid
files are valid and
there exists a symmetric
are valid and are
exists a symmetric equilibrium
valid and are in
a symmetric equilibrium in
and are in the
the error bars on
are in the cache
symmetric equilibrium in which
in the cache access
error bars on the
the cache access statistics
equilibrium in which each
bars on the graphs
in which each participating
on the graphs to
which each participating pool
the graphs to the
each participating pool attacks
graphs to the left
participating pool attacks each
to the left are
pool attacks each of
the left are standard
attacks each of the
left are standard errors
each of the other
are standard errors of
of the other participating
standard errors of the
the other participating pools
errors of the throughput
of the throughput over
the throughput over ten
throughput over ten runs
as in the minority
in the minority two
predicted future file accesses
future file accesses from
file accesses from cache
the group is moved
constructing reliable distributed communication
ip s cache of
group is moved to
reliable distributed communication systems
s cache of tuning
is moved to the
distributed communication systems with
cache of tuning parameters
here too at equilibrium
of tuning parameters to
too at equilibrium all
tuning parameters to allow
at equilibrium all pools
parameters to allow for
equilibrium all pools earn
moved to the end
all pools earn less
to allow for repeatable
pools earn less than
allow for repeatable results
earn less than with
to the end of
communication systems with corba
the end of the
less than with the
end of the prefetch
than with the no
of the prefetch list
the clients in the
clients in the experiment
ieee communications magazine feature
in the experiment are
communications magazine feature topic
the experiment are running
magazine feature topic issue
experiment are running tcp
feature topic issue on
topic issue on distributed
issue on distributed object
on distributed object computing
ip reno on a
reno on a linux
our results imply that
results imply that block
imply that block withholding
that block withholding by
block withholding by pools
withholding by pools leads
by pools leads to
pools leads to an
or allowed applications to
leads to an unfavorable
allowed applications to specify
to an unfavorable equilibrium
applications to specify prefetch
due to the anonymity
the thread rechecks the
to the anonymity of
thread rechecks the head
the anonymity of miners
rechecks the head of
the head of the
head of the list
of the list ing
the list ing hints
the maelstrom parameters used
list ing hints explicitly
a single pool might
maelstrom parameters used are
single pool might be
parameters used are r
pool might be tempted
might be tempted to
be tempted to attack
leading the other pools
the other pools to
other pools to attack
pools to attack as
to attack as well
the implications might be
implications might be devastating
might be devastating for
be devastating for open
devastating for open pools
if their revenues are
their revenues are reduced
to find the next
find the next file
the next file to
miners will prefer to
next file to prefetch
will prefer to form
prefer to form closed
to form closed pools
form closed pools that
closed pools that cannot
a new group may
pools that cannot be
new group may now
that cannot be attacked
group may now be
cannot be attacked in
may now be at
be attacked in this
now be at the
attacked in this manner
be at the inter
though this may be
file dependencies can also
this may be conceived
dependencies can also be
may be conceived as
can also be used
be conceived as bad
also be used as
conceived as bad news
be used as a
hierarchical clustering of message
as bad news for
clustering of message flows
bad news for public
used as a source
news for public mining
of message flows in
for public mining pools
as a source of
message flows in a
a source of hints
flows in a multicast
in a multicast data
a multicast data dissemination
on the whole it
space version involved running
the whole it may
version involved running a
whole it may be
head of the list
multicast data dissemination system
of the list as
it may be good
the list as a
may be good news
involved running a single
be good news to
list as a result
good news to the
as a result of
news to the bitcoin
a result of further
to the bitcoin system
result of further application
of further application accesses
further application accesses to
application accesses to files
which prefers small pools
second iperf flow from
iperf flow from one
flow from one node
from one node to
we examine the practicality
one node to another
it may be known
examine the practicality of
node to another with
may be known that
the practicality of the
to another with and
be known that a
practicality of the attack
another with and without
known that a certain
of the attack in
that a certain shared
with and without maelstrom
the attack in section
a certain shared library
and without maelstrom running
attack in section viii
certain shared library is
without maelstrom running on
in section viii and
shared library is reprefetch
section viii and discuss
maelstrom running on the
viii and discuss implications
library is reprefetch requests
and discuss implications and
running on the routers
discuss implications and model
is reprefetch requests are
on the routers and
reprefetch requests are similar
implications and model extensions
the routers and measuring
requests are similar to
routers and measuring throughput
and model extensions in
and measuring throughput while
model extensions in section
optimizing buffer management for
extensions in section ix
are similar to regular
measuring throughput while varying
similar to regular fetch
buffer management for reliable
to regular fetch requests
throughput while varying the
regular fetch requests for
management for reliable multicast
while varying the random
fetch requests for files
varying the random loss
the random loss rate
random loss rate on
loss rate on the
proceedings of the international
rate on the link
of the international conference
quired to run a
the international conference on
to run a text
on the link and
our contributions are the
international conference on dependable
run a text editor
conference on dependable systems
contributions are the following
on dependable systems and
the link and the
dependable systems and networks
link and the oneway
and the oneway latency
in this case it
this case it would
case it would be
it would be advantageous
to test the kernel
would be advantageous with
test the kernel version
definition of the pool
the kernel version at
be advantageous with the
kernel version at gigabit
of the pool game
advantageous with the exception
version at gigabit speeds
the pool game where
with the exception that
pool game where pools
game where pools in
the exception that they
where pools in a
pools in a proof
we ran eight parallel
exception that they are
ran eight parallel iperf
that they are issued
eight parallel iperf flows
they are issued at
parallel iperf flows from
ofwork secured system attack
iperf flows from one
are issued at the
flows from one node
secured system attack one
from one node to
issued at the lowest
one node to another
system attack one another
node to another for
at the lowest level
attack one another with
the lowest level of
one another with a
lowest level of prito
another with a pool
level of prito retrieve
with a pool block
of prito retrieve the
a pool block withholding
prito retrieve the shared
pool block withholding attack
retrieve the shared library
the shared library from
shared library from the
library from the server
from the server as
the server as well
server as well as
as well as retriev
the curves obtained from
curves obtained from the
obtained from the two
from the two versions
the two versions are
in the general case
two versions are almost
versions are almost identical
all other rpc traffic
other rpc traffic takes
rpc traffic takes precedence
traffic takes precedence over
takes precedence over a
we present both to
precedence over a prefetch
over a prefetch rpc
present both to show
both to show that
attacks is not an
to show that the
is not an equilibrium
ing the text editor
show that the kernel
the text editor executable
that the kernel version
the kernel version successfully
kernel version successfully scales
version successfully scales up
successfully scales up the
scales up the performance
up the performance of
the performance of the
a group membership service
performance of the userspace
group membership service for
as shown in table
membership service for wans
of the userspace version
with two minority pools
the userspace version to
two minority pools participating
userspace version to hundreds
version to hundreds of
acm transactions on computer
to hundreds of megabits
transactions on computer systems
hundreds of megabits of
of megabits of traffic
the only nash equilibrium
megabits of traffic per
only nash equilibrium is
of traffic per second
nash equilibrium is when
equilibrium is when the
and only one tion
is when the pools
only one tion such
when the pools attack
one tion such as
the pools attack one
tion such as the
pools attack one another
such as the operating
as the operating system
the operating system s
operating system s database
and both earn less
system s database of
both earn less than
s database of installed
earn less than if
database of installed software
less than if none
of installed software prefetch
than if none had
installed software prefetch is
if none had attacked
software prefetch is made
prefetch is made at
is made at a
made at a time
miners therefore face the
therefore face the miner
face the miner s
the miner s dilemma
this is more a
is more a matter
more a matter of
a matter of implementapackages
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
we show how tcp
specified dependency information tion
dependency information tion convenience
repeatedly choosing between attack
information tion convenience than
choosing between attack and
tion convenience than a
between attack and no
convenience than a design
ip performance degrades on
than a design decision
performance degrades on a
other work has shown
work has shown can
has shown can be
shown can be used
ms link as the
link as the loss
as the loss rate
the loss rate is
the benefits initiating multiple
loss rate is increased
with multiple pools of
benefits initiating multiple concurrent
multiple pools of equal
rate is increased from
pools of equal size
initiating multiple concurrent prefetches
of equal size there
equal size there is
multiple concurrent prefetches from
size there is a
there is a symmetric
concurrent prefetches from differany
is a symmetric nash
prefetches from differany of
a symmetric nash equilibrium
from differany of these
differany of these techniques
of these techniques could
these techniques could be
techniques could be used
where all pools earn
could be used to
all pools earn less
be used to derive
pools earn less than
used to derive hints
earn less than if
to derive hints for
less than if none
derive hints for use
than if none had
hints for use ent
if none had attacked
for use ent servers
maelstrom masks loss up
masks loss up to
inefficient equilibria for open
equilibria for open pools
for open pools may
mfs does not currently
open pools may serve
without significant throughput degradation
does not currently make
pools may serve the
not currently make use
may serve the system
currently make use of
serve the system by
make use of timeouts
with the kernel version
use of timeouts by
the system by reducing
of timeouts by the
the kernel version achieving
timeouts by the mfs
system by reducing their
by the mfs prefetching
kernel version achieving two
by reducing their attraction
the mfs prefetching subsystem
version achieving two orders
reducing their attraction and
achieving two orders of
their attraction and pushing
two orders of magnitude
our evaluation uses hand
orders of magnitude higher
attraction and pushing miners
of magnitude higher throughput
and pushing miners towards
magnitude higher throughput that
pushing miners towards smaller
higher throughput that conventional
miners towards smaller closed
throughput that conventional tcp
towards smaller closed pools
as we have noted
we have noted earlier
the classical block withholding
classical block withholding attack
block withholding attack is
withholding attack is old
but it could easily
attack is old as
it could easily to
is old as pools
could easily to exspecified
old as pools themselves
easily to exspecified dependency
to exspecified dependency information
the graphs on the
graphs on the right
on the right side
but its use by
the right side of
its use by pools
right side of figures
which is inaccurate in
use by pools has
is inaccurate in some
by pools has not
inaccurate in some tended
pools has not been
in some tended to
has not been suggested
some tended to abandon
not been suggested until
tended to abandon a
been suggested until recently
to abandon a prefetching
abandon a prefetching attempt
a prefetching attempt that
prefetching attempt that does
attempt that does not
we overview related attacks
that does not complete
overview related attacks and
does not complete cases
related attacks and prior
attacks and prior work
and prior work in
prior work in section
ip throughput declining on
work in section x
rather than reimplementing an
throughput declining on a
than reimplementing an existing
declining on a link
reimplementing an existing hint
on a link of
a link of increasing
and conclude with final
link of increasing length
conclude with final remarks
of increasing length when
generation in a timely
with final remarks in
in a timely manner
increasing length when subjected
final remarks in section
length when subjected to
remarks in section xi
when subjected to uniform
subjected to uniform loss
to uniform loss rates
uniform loss rates of
we focus on the
focus on the performance
on the performance of
p reliminaries b itcoin
the performance of mfs
reliminaries b itcoin and
performance of mfs with
b itcoin and p
of mfs with prefetchthe
itcoin and p ooled
mfs with prefetchthe main
and p ooled m
with prefetchthe main complexity
p ooled m ining
prefetchthe main complexity in
ooled m ining bitcoin
main complexity in implementing
m ining bitcoin is
complexity in implementing the
ining bitcoin is a
in implementing the prefetching
bitcoin is a distributed
implementing the prefetching subing
using a deliberately simple
a deliberately simple hint
deliberately simple hint mechanism
the top line in
simple hint mechanism for
top line in the
hint mechanism for the
line in the graphs
mechanism for the purposes
in the graphs is
for the purposes system
the graphs is the
the purposes system lies
graphs is the performance
purposes system lies in
is the performance of
system lies in handling
the performance of tcp
lies in handling a
in handling a demand
handling a demand fetch
ip without loss and
without loss and provides
a compulsory fetch to
loss and provides an
compulsory fetch to of
and provides an upper
fetch to of evaluation
provides an upper bound
an upper bound for
upper bound for performance
bound for performance on
for performance on the
performance on the link
dependencies between files are
between files are conveyed
files are conveyed using
are conveyed using a
conveyed using a service
using a service a
a service a cache
service a cache miss
space and kernel versions
for a file which
a file which is
maelstrom masks packet loss
file which is already
masks packet loss and
which is already being
packet loss and tracks
is already being prefetched
loss and tracks the
and tracks the lossless
tracks the lossless line
the lossless line closely
lagging only when the
which is a list
only when the link
is a list of
when the link latency
a list of file
the link latency is
list of file identifiers
link latency is low
of file identifiers for
latency is low and
file identifiers for the
is low and tcp
identifiers for the related
for the related files
ip s throughput is
s throughput is very
this conflict arises very
throughput is very high
conflict arises very frequently
particularly when an appliit
clients use the system
when an appliit is
use the system by
an appliit is assumed
the system by issuing
appliit is assumed that
system by issuing transactions
is assumed that after
assumed that after one
that after one file
after one file in
one file in the
file in the group
and the system s
in the group has
the group has been
the system s only
group has been accessed
system s only task
s only task is
only task is to
cation performs a fast
task is to serialize
performs a fast linear
is to serialize transactions
a fast linear scan
to serialize transactions in
fast linear scan of
serialize transactions in a
linear scan of files
transactions in a single
scan of files in
in a single ledger
of files in a
a single ledger and
files in a file
single ledger and reject
in a file group
ledger and reject transactions
and reject transactions that
reject transactions that cannot
transactions that cannot be
that cannot be serialized
an it becomes advantageous
cannot be serialized due
it becomes advantageous to
be serialized due to
becomes advantageous to prefetch
serialized due to conflicts
advantageous to prefetch the
due to conflicts with
to prefetch the remainder
to conflicts with previous
prefetch the remainder of
conflicts with previous transactions
the remainder of the
remainder of the files
of the files in
the files in efficient
files in efficient implementation
bitcoin transactions are protected
in efficient implementation of
transactions are protected with
efficient implementation of prefetching
are protected with cryptographic
implementation of prefetching requires
protected with cryptographic techniques
of prefetching requires that
with cryptographic techniques that
prefetching requires that the
cryptographic techniques that ensure
requires that the demand
techniques that ensure that
that ensure that only
ensure that only the
that only the rightful
only the rightful owner
the rightful owner of
rightful owner of a
owner of a bitcoin
of a bitcoin can
a bitcoin can transfer
bitcoin can transfer it
the transaction ledger is
transaction ledger is stored
ledger is stored by
is stored by a
stored by a network
by a network of
a network of miners
network of miners in
of miners in a
miners in a data
in a data structure
a data structure caller
data structure caller the
structure caller the blockchain
revenue for proof of
for proof of work
proof of work the
of work the blockchain
work the blockchain records
the blockchain records the
blockchain records the transactions
records the transactions in
the transactions in units
transactions in units of
in units of blocks
dubbed the genesis block
is defined as part
defined as part of
as part of the
part of the protocol
ip no loss maelstrom
no loss maelstrom no
loss maelstrom no loss
maelstrom no loss maelstrom
a valid block contains
valid block contains the
block contains the hash
contains the hash of
the hash of the
hash of the previous
of the previous block
the hash of the
hash of the transactions
of the transactions in
the transactions in the
transactions in the current
in the current block
and a bitcoin address
a bitcoin address which
bitcoin address which is
address which is to
which is to be
is to be credited
to be credited with
be credited with a
credited with a reward
with a reward for
a reward for generating
reward for generating the
for generating the block
any miner may add
miner may add a
may add a valid
add a valid block
a valid block to
valid block to the
block to the chain
to the chain by
proving that it has
that it has spent
it has spent a
has spent a certain
spent a certain amount
a certain amount of
certain amount of work
amount of work and
of work and publishing
work and publishing the
and publishing the block
publishing the block with
the block with the
block with the proof
with the proof over
the proof over an
proof over an overlay
over an overlay network
an overlay network to
overlay network to all
network to all other
to all other miners
when a miner creates
a miner creates a
miner creates a block
it is compensated for
is compensated for its
compensated for its efforts
for its efforts with
its efforts with bitcoins
this compensation includes a
compensation includes a per
transaction fee paid by
fee paid by the
paid by the users
by the users whose
the users whose transactions
users whose transactions are
whose transactions are included
and an amount of
an amount of minted
amount of minted bitcoins
of minted bitcoins that
minted bitcoins that are
bitcoins that are thus
that are thus introduced
are thus introduced into
thus introduced into the
introduced into the system
the work which a
work which a miner
which a miner is
a miner is required
miner is required to
is required to do
required to do is
to do is to
do is to repeatedly
is to repeatedly calculate
to repeatedly calculate a
repeatedly calculate a a
calculate a a hash
a a hash function
a hash function specifically
hash function specifically the
function specifically the sha
aware adaptation techniques for
adaptation techniques for mobile
techniques for mobile file
for mobile file systems
mobile file systems benjamin
file systems benjamin atkin
systems benjamin atkin kenneth
benjamin atkin kenneth p
birman nec laboratories america
nec laboratories america cornell
laboratories america cornell university
america cornell university atkin
of a block header
to indicate that he
indicate that he has
that he has performed
he has performed this
has performed this work
edu abstract therefore react
abstract therefore react to
therefore react to bandwidth
react to bandwidth variations
to bandwidth variations in
the miner provides a
bandwidth variations in a
miner provides a probabilistic
variations in a fine
provides a probabilistic proof
a probabilistic proof as
probabilistic proof as follows
the generated block has
generated block has a
block has a nonce
has a nonce field
life file system traffic
file system traffic featuring
system traffic featuring high
which can contain any
traffic featuring high read
can contain any value
write wireless networks present
the miner places different
wireless networks present unusual
miner places different values
networks present unusual challenges
places different values in
present unusual challenges for
different values in this
unusual challenges for mobile
values in this field
challenges for mobile file
in this field and
for mobile file contention
this field and calculates
field and calculates the
and calculates the hash
calculates the hash for
the hash for each
mafs is able to
hash for each value
is able to achieve
able to achieve improvements
to achieve improvements in
achieve improvements in execusystem
improvements in execusystem clients
if the result of
the result of the
result of the hash
of the hash is
the hash is smaller
since they are characterised
hash is smaller than
they are characterised by
is smaller than a
are characterised by unpredictable
smaller than a target
characterised by unpredictable tion
than a target value
by unpredictable tion time
unpredictable tion time of
tion time of up
time of up to
the nonce is considered
nonce is considered a
is considered a solution
and the block is
the block is valid
the number of attempts
number of attempts to
of attempts to find
attempts to find a
to find a single
find a single hash
a single hash is
single hash is therefore
at both low and
hash is therefore random
both low and high
is therefore random with
low and high bandwidths
therefore random with a
random with a geometric
with a geometric distribution
as each attempt is
each attempt is a
attempt is a bernoulli
is a bernoulli trial
a bernoulli trial with
the traditional approach to
bernoulli trial with a
traditional approach to adapting
trial with a success
approach to adapting network
with a success probability
to adapting network communication
a success probability determined
adapting network communication to
success probability determined by
network communication to these
probability determined by the
communication to these conditions
determined by the target
to these conditions is
by the target value
these conditions is to
conditions is to write
is to write back
to write back file
write back file updates
at the existing huge
back file updates asynchronously
the existing huge hashing
file updates asynchronously when
existing huge hashing rates
updates asynchronously when bandwidth
huge hashing rates and
asynchronously when bandwidth is
hashing rates and small
rates and small target
and small target values
the time to find
time to find a
to find a single
find a single hash
a single hash can
single hash can be
this can lead to
hash can be approximated
can lead to underutilisation
can be approximated by
lead to underutilisation of
be approximated by an
to underutilisation of bandwidth
approximated by an exponential
underutilisation of bandwidth and
by an exponential distribution
of bandwidth and inconsistencies
bandwidth and inconsistencies between
and inconsistencies between clients
the average time for
average time for a
we describe a new
time for a miner
describe a new mobile
for a miner to
a new mobile access
a miner to find
new mobile access to
miner to find a
mobile access to shared
to find a solution
access to shared data
find a solution is
to shared data is
a solution is therefore
shared data is complicated
solution is therefore proportional
data is complicated by
is therefore proportional to
is complicated by an
therefore proportional to its
complicated by an unpredictable
proportional to its hashing
by an unpredictable mobile
to its hashing rate
an unpredictable mobile file
its hashing rate or
unpredictable mobile file system
hashing rate or mining
rate or mining power
to maintain a constant
maintain a constant rate
a constant rate of
that supports graceful degradation
constant rate of bitcoin
supports graceful degradation computing
rate of bitcoin generation
graceful degradation computing environment
and as part of
the network or a
as part of its
network or a particular
part of its defense
or a particular destination
of its defense against
a particular destination of
its defense against denial
particular destination of file
defense against denial of
destination of file system
against denial of service
of file system performance
denial of service and
file system performance as
of service and other
system performance as bandwidth
service and other attacks
performance as bandwidth is
as bandwidth is reduced
the system normalizes the
as well as may
system normalizes the rate
well as may be
normalizes the rate of
as may be unavailable
the rate of block
rate of block generation
or the throughput may
the throughput may be
throughput may be substandard
prefetch no prefetch prefetch
no prefetch prefetch no
the protocol deterministically defines
prefetch prefetch no prefetch
as rapid propagation of
protocol deterministically defines the
rapid propagation of essential
deterministically defines the target
propagation of essential file
defines the target value
of essential file updates
the target value for
target value for each
value for each block
for each block according
mafs is able to
each block according to
is able to shown
block according to the
able to shown in
according to the time
to shown in figure
to the time required
the time required to
prefetch no prefetch relative
time required to generate
no prefetch relative speedup
required to generate recent
prefetch relative speedup relative
to generate recent blocks
relative speedup relative speedup
this graph shows results
graph shows results from
shows results from packet
is updated once every
tcp no loss maelstrom
no loss maelstrom no
loss maelstrom no loss
maelstrom no loss maelstrom
improvements in execution time
in execution time for
blocks such that the
execution time for real
such that the average
that the average time
the average time for
average time for each
time for each block
life measurements of available
for each block to
measurements of available bandwidth
each block to be
of available bandwidth between
block to be found
available bandwidth between a
to be found is
bandwidth between a mobile
between a mobile host
a mobile host on
mobile host on a
host on a wireless
on a wireless network
and a wired host
a wired host near
wired host near the
host near the base
note that the exponential
near the base station
that the exponential distribution
the exponential distribution is
exponential distribution is memoryless
prefetch no prefetch relative
file system traces featuring
no prefetch relative speedup
system traces featuring read
prefetch relative speedup relative
if all miners mine
relative speedup relative speedup
all miners mine for
miners mine for block
mine for block number
for block number b
as the mobile host
the mobile host moves
once the block is
the block is found
block is found at
is found at time
found at time t
prefetch no prefetch relative
factors such as the
no prefetch relative speedup
such as the distance
as the distance to
all miners switch to
the distance to the
miners switch to mine
distance to the base
switch to mine for
to the base station
to mine for the
the base station and
mine for the subsequent
base station and local
for the subsequent block
station and local interference
the subsequent block b
and local interference cause
local interference cause the
interference cause the host
cause the host s
the host s network
host s network card
s network card to
prefetch no prefetch relative
network card to switch
no prefetch relative speedup
at t without changing
card to switch to
prefetch relative speedup bad
to switch to higher
t without changing their
relative speedup bad groups
without changing their probability
changing their probability distribution
their probability distribution of
probability distribution of finding
distribution of finding a
of finding a block
finding a block after
a block after t
the probability that a
probability that a miner
such switching causes available
that a miner i
switching causes available bandwidth
a miner i with
causes available bandwidth to
miner i with mining
available bandwidth to oscillate
i with mining power
bandwidth to oscillate distributed
with mining power mi
to oscillate distributed file
mining power mi finds
oscillate distributed file systems
power mi finds the
distributed file systems are
mi finds the next
file systems are a
finds the next block
systems are a common
the next block is
are a common feature
next block is its
a common feature of
block is its ratio
common feature of large
is its ratio out
feature of large com
its ratio out of
ratio out of the
out of the total
of the total mining
the total mining power
total mining power m
mining power m in
power m in the
m in the system
even when the mobile
one way link latency
when the mobile host
the mobile host is
mobile host is stationary
miner miner miner pool
if it is to
it is to enputing
is to enputing environments
miner miner miner pool
since they simplify sharing
they simplify sharing data
simplify sharing data between
sharing data between sure
data between sure that
between sure that clients
sure that clients file
that clients file operations
clients file operations are
file operations are executed
operations are executed in
are executed in a
executed in a timely
in a timely way
and can provide scalable
can provide scalable and
provide scalable and highly
scalable and highly available
and highly available file
highly available file ac
file system must adapt
system must adapt to
must adapt to this
adapt to this variation
way latency throughput as
latency throughput as a
throughput as a function
as a function of
a function of latency
and one miner mines
one miner mines solo
pools datacenters are built
supporting mobile clients requires
datacenters are built around
mobile clients requires coping
are built around the
clients requires coping existing
built around the world
requires coping existing systems
coping existing systems tailored
existing systems tailored to
systems tailored to low
bandwidth clients differenwith the
clients differenwith the atypical
differenwith the atypical patterns
the atypical patterns of
atypical patterns of connectivity
ip to attain very
patterns of connectivity that
to attain very high
of connectivity that characterise
attain very high speeds
connectivity that characterise them
very high speeds on
high speeds on the
speeds on the gigabit
on the gigabit link
mining is only profitable
tiate between types of
is only profitable using
between types of file
only profitable using dedicated
types of file system
we had to set
of file system communication
profitable using dedicated hardware
had to set the
using dedicated hardware in
to set the mtu
dedicated hardware in cutting
set the mtu of
hardware in cutting edge
the mtu of the
in cutting edge mining
so that bandwhile a
cutting edge mining rigs
mtu of the entire
that bandwhile a desktop
of the entire path
bandwhile a desktop client
the entire path to
a desktop client is
entire path to be
desktop client is well
path to be the
otherwise the energy costs
to be the maximum
the energy costs exceed
energy costs exceed the
costs exceed the expected
connected to a file
exceed the expected revenue
to a file server
a file server un
although expected revenue from
width can be devoted
expected revenue from mining
can be devoted to
revenue from mining is
be devoted to important
from mining is proportional
mining is proportional to
is proportional to the
proportional to the power
to the power of
which meant that the
the power of the
meant that the long
power of the mining
of the mining rigs
the mining rigs used
haul link had the
link had the same
had the same mtu
the same mtu as
a single home miner
same mtu as the
single home miner using
mtu as the inter
home miner using a
miner using a small
using a small rig
a small rig is
small rig is unlikely
rig is unlikely to
is unlikely to mine
a mobile client frequently
unlikely to mine a
mobile client frequently lacks
this resulted in the
client frequently lacks the
to mine a block
resulted in the fragmentation
mine a block for
in the fragmentation of
a block for years
the fragmentation of repair
fragmentation of repair packets
of repair packets sent
repair packets sent over
packets sent over udp
sent over udp on
over udp on the
udp on the longhaul
on the longhaul link
the longhaul link into
longhaul link into two
link into two ip
into two ip packet
two ip packet fragments
since the loss of
the loss of a
loss of a single
of a single fragment
a single fragment resulted
miners often organize themselves
single fragment resulted in
often organize themselves into
fragment resulted in the
organize themselves into mining
resulted in the loss
themselves into mining pools
in the loss of
the loss of the
loss of the repair
writes back changes to
back changes to files
changes to files asynbandwidth
we observed a higher
to files asynbandwidth to
observed a higher loss
a pool is a
files asynbandwidth to perform
a higher loss rate
pool is a group
higher loss rate for
asynbandwidth to perform all
loss rate for repairs
is a group of
rate for repairs than
to perform all its
for repairs than for
perform all its file
repairs than for data
a group of miners
than for data packets
all its file operations
group of miners that
its file operations in
of miners that share
file operations in a
miners that share their
operations in a timely
that share their revenues
in a timely fashion
share their revenues when
relative speedup of workloads
their revenues when one
we expect performance to
revenues when one of
expect performance to be
when one of them
performance to be better
one of them successfully
to be better on
of them successfully mines
speedup of workloads with
be better on a
of workloads with prefetching
better on a network
them successfully mines a
on a network where
successfully mines a block
a network where the
network where the mtu
where the mtu of
these graphs show the
the mtu of the
graphs show the speedup
mtu of the long
for each block found
show the speedup gained
the speedup gained by
speedup gained by adding
gained by adding prefetching
haul link is truly
by adding prefetching for
the revenue is distributed
link is truly larger
adding prefetching for a
revenue is distributed among
assigns lower priorities to
is truly larger than
lower priorities to asynmobile
truly larger than the
prefetching for a range
larger than the mtu
is distributed among the
priorities to asynmobile file
distributed among the pool
to asynmobile file systems
among the pool members
than the mtu within
the pool members in
the mtu within each
pool members in proportion
mtu within each cluster
members in proportion to
asynmobile file systems typically
in proportion to their
for a range of
proportion to their mining
file systems typically assume
to their mining power
even with zero loss
a range of bandwidth
systems typically assume that
range of bandwidth values
typically assume that a
assume that a client
that a client is
a client is strongly
relative to the time
to the time taken
ip throughput in figure
the expected revenue of
the time taken with
expected revenue of a
chronous operations at the
revenue of a pool
time taken with a
of a pool member
taken with a bandwidth
operations at the ip
with a bandwidth of
a pool member is
at the ip level
pool member is therefore
the ip level to
member is therefore the
ip level to reduce
is therefore the same
level to reduce interference
therefore the same as
to reduce interference with
the same as its
reduce interference with connected
same as its revenue
interference with connected like
declines with link latency
with connected like a
as its revenue had
connected like a desktop
its revenue had it
s and no prefetching
revenue had it mined
like a desktop host
had it mined solo
this is due to
is due to the
due to the cap
where a test comprises
to the cap on
a test comprises two
the cap on throughput
test comprises two separate
cap on throughput placed
comprises two separate processes
on throughput placed by
connected and should foreground
due to the large
throughput placed by the
to the large power
and should foreground operations
the large power of
only the speedup for
placed by the buffering
the speedup for the
large power of the
speedup for the foreground
power of the pool
by the buffering available
limit its bandwidth consumption
for the foreground process
its bandwidth consumption to
the buffering available at
bandwidth consumption to a
buffering available at the
consumption to a minimum
available at the receiving
it finds blocks at
at the receiving end
the foreground process is
finds blocks at a
foreground process is shown
blocks at a much
at a much higher
a much higher rate
fetch wait for the
wait for the prefetch
for the prefetch to
the preceding experiments were
the prefetch to complete
and so the frequency
preceding experiments were done
so the frequency of
experiments were done with
the frequency of revenue
were done with maelstrom
frequency of revenue collection
done with maelstrom in
or that the prefetch
with maelstrom in endto
that the prefetch be
of revenue collection is
the prefetch be aborted
revenue collection is higher
end flow control mode
issuing a fetch rpc
allowing for a stable
a fetch rpc at
for a stable daily
fetch rpc at the
adaptation by deferred transmission
rpc at the same
a stable daily or
at the same time
stable daily or weekly
where it is oblivious
by deferred transmission of
it is oblivious to
daily or weekly income
is oblivious to tcp
deferred transmission of file
the same time as
transmission of file upwidth
same time as a
of file upwidth lies
time as a prefetch
file upwidth lies between
as a prefetch is
upwidth lies between these
ip and does not
lies between these extremes
and does not split
a prefetch is in
does not split connections
prefetch is in progress
most pools are controlled
is in progress needlessly
pools are controlled by
in progress needlessly wastes
are controlled by a
progress needlessly wastes bandwidth
controlled by a centralized
assuming weak connectivity dates
by a centralized pool
and is consequently sensitive
a centralized pool manager
is consequently sensitive to
weak connectivity dates has
consequently sensitive to the
since it retrieves the
sensitive to the size
it retrieves the same
to the size of
retrieves the same file
connectivity dates has the
the same file from
the size of the
same file from the
dates has the disadvantage
file from the server
miners register with the
size of the receiver
register with the pool
from the server twice
with the pool manager
of the receiver buffer
the pool manager and
has the disadvantage of
pool manager and mine
the disadvantage of increasing
manager and mine on
disadvantage of increasing the
and mine on its
the same could be
of increasing the delay
same could be true
mine on its behalf
could be true if
increasing the delay before
be true if we
the delay before upcan
true if we opt
delay before upcan be
if we opt for
before upcan be too
we opt for aborting
the pool manager generates
opt for aborting prefetches
shows the performance of
pool manager generates tasks
upcan be too conservative
the performance of split
manager generates tasks and
performance of split mode
generates tasks and the
since an aborted prefetch
of split mode flow
an aborted prefetch could
split mode flow control
aborted prefetch could be
since it delays sending
prefetch could be very
tasks and the miners
could be very close
it delays sending updates
be very close to
and the miners search
delays sending updates to
the miners search for
very close to completion
miners search for solutions
sending updates to the
search for solutions based
updates to the dates
for solutions based on
to the dates are
solutions based on these
mfs therefore makes the
the dates are applied
therefore makes the demand
dates are applied at
makes the demand fetch
are applied at the
the demand fetch wait
applied at the file
demand fetch wait for
at the file server
fetch wait for the
based on these tasks
where maelstrom breaks a
on these tasks that
maelstrom breaks a single
these tasks that can
breaks a single tcp
tasks that can serve
wait for the prefetch
and therefore reduces the
that can serve as
therefore reduces the deserver
can serve as proof
reduces the deserver in
ip connection into three
the deserver in order
serve as proof of
deserver in order to
as proof of work
in order to aggregate
but also raises the
order to aggregate modifications
connection into three hops
also raises the priority
raises the priority of
once they find a
the priority of the
they find a solution
priority of the prefetch
gree of consistency between
of the prefetch rpc
of consistency between clients
the prefetch rpc to
consistency between clients cached
prefetch rpc to that
they send it to
between clients cached copies
send it to the
rpc to that of
it to the pool
to that of a
to the pool manager
that of a regular
of a regular fetch
for its own this
a regular fetch operation
its own this paper
own this paper examines
the pool manager behaves
this paper examines the
pool manager behaves as
paper examines the effectiveness
manager behaves as a
examines the effectiveness of
behaves as a single
the effectiveness of mafs
as a single miner
to prevent a priority
a single miner in
prevent a priority inversion
single miner in the
split mode flow control
miner in the bitcoin
mode flow control eliminates
in the bitcoin system
flow control eliminates the
this requires an additional
control eliminates the requirement
requires an additional raise
eliminates the requirement for
the requirement for large
once it obtains a
requirement for large buffers
bandwidth client may decide
priority rpc to the
for large buffers at
client may decide to
it obtains a legitimate
large buffers at the
rpc to the server
buffers at the receiving
obtains a legitimate block
may decide to delay
a legitimate block from
at the receiving end
legitimate block from one
decide to delay sending
block from one of
which results in more
to delay sending a
from one of its
results in more overhead
one of its miners
delay sending a file
in more overhead than
sending a file system
more overhead than the
a file system that
overhead than the case
file system that propagates
than the case where
throughput is essentially insensitive
the case where a
system that propagates file
case where a demand
is essentially insensitive to
where a demand fetch
the block transfers the
a demand fetch occurs
essentially insensitive to one
demand fetch occurs without
block transfers the revenue
fetch occurs without a
that propagates file modifications
transfers the revenue to
occurs without a fetch
the revenue to the
propagates file modifications asynchronously
revenue to the control
file modifications asynchronously file
to the control of
modifications asynchronously file s
with a slight drop
asynchronously file s update
the control of the
file s update to
a slight drop due
s update to the
on the other hand
update to the file
slight drop due to
to the file server
control of the pool
drop due to buffering
of the pool manager
due to buffering overhead
to buffering overhead on
buffering overhead on the
overhead on the maelstrom
but this decision may
on the maelstrom boxes
this decision may also
the pool manager then
decision may also affect
pool manager then distributes
may also affect at
manager then distributes the
also affect at all
then distributes the revenue
affect at all bandwidth
distributes the revenue among
the fetch can frequently
at all bandwidth levels
the revenue among the
fetch can frequently make
revenue among the miners
can frequently make use
among the miners according
compares split mode to
frequently make use of
split mode to end
rather than delaying writes
make use of the
the miners according to
use of the data
miners according to their
of the data already
according to their mining
the data already transferred
mafs other clients that
to their mining power
data already transferred and
other clients that would
already transferred and so
clients that would like
transferred and so still
that would like to
and so still results
would like to read
so still results in
like to read the
the architecture is illustrated
to read the file
still results in a
architecture is illustrated in
results in a faster
is illustrated in figure
in a faster response
a faster response to
faster response to the
response to the application
optimistic concuruses rpc priorities
in order to estimate
concuruses rpc priorities to
order to estimate the
rpc priorities to reduce
to estimate the mining
as we have explained
estimate the mining power
priorities to reduce interference
the mining power of
mining power of a
to reduce interference between
power of a miner
reduce interference between read
the implementation of the
interference between read and
implementation of the prefetching
between read and rency
of the prefetching subsystem
the pool manager sets
the prefetching subsystem is
read and rency control
prefetching subsystem is not
pool manager sets a
subsystem is not sophisticated
and rency control and
manager sets a partial
rency control and reconciliation
sets a partial target
control and reconciliation of
a partial target for
and reconciliation of conflicting
while it will reach
partial target for each
reconciliation of conflicting updates
target for each member
it will reach an
of conflicting updates are
will reach an equilibrium
conflicting updates are typwrite
reach an equilibrium if
updates are typwrite traffic
an equilibrium if the
are typwrite traffic at
equilibrium if the total
typwrite traffic at low
if the total size
traffic at low bandwidth
the total size of
total size of the
size of the file
of the file groups
to ensure that file
the file groups in
ensure that file modifications
file groups in the
that file modifications ically
groups in the prefetch
file modifications ically used
in the prefetch list
modifications ically used to
the prefetch list is
ically used to resolve
prefetch list is less
used to resolve inconsistencies
list is less than
is less than the
than the target of
less than the cache
the target of the
than the cache size
target of the bitcoin
of the bitcoin system
there is no mechanism
each miner is required
is no mechanism to
miner is required to
no mechanism to prevent
is required to send
mechanism to prevent the
required to send the
to prevent the prefetching
to send the pool
prevent the prefetching subsystem
send the pool manager
the prefetching subsystem running
the pool manager blocks
prefetching subsystem running ahead
pool manager blocks that
subsystem running ahead of
manager blocks that are
running ahead of actual
blocks that are correct
ahead of actual file
that are correct according
when bandwidth are rapidly
are correct according to
of actual file accesses
correct according to the
bandwidth are rapidly propagated
according to the partial
actual file accesses and
to the partial target
are rapidly propagated to
file accesses and evicting
rapidly propagated to the
accesses and evicting useful
propagated to the clients
and evicting useful files
to the clients that
evicting useful files from
the clients that need
useful files from the
clients that need them
the partial target is
files from the cache
partial target is chosen
target is chosen to
is chosen to be
chosen to be large
mafs is very low
or evicting files which
evicting files which it
files which it has
such that partial solutions
this can be an
which it has prefetched
that partial solutions arrive
it has prefetched but
can be an acceptable
partial solutions arrive frequently
has prefetched but have
be an acceptable price
prefetched but have not
solutions arrive frequently enough
but have not yet
an acceptable price to
have not yet been
arrive frequently enough for
not yet been referenced
acceptable price to pay
yet been referenced by
frequently enough for the
been referenced by the
price to pay for
referenced by the user
enough for the manager
to pay for the
for the manager to
pay for the abilalso
the manager to accurately
for the abilalso incorporates
manager to accurately estimate
the abilalso incorporates a
techniques for preventing this
abilalso incorporates a new
to accurately estimate the
incorporates a new invalidation
accurately estimate the power
for preventing this behaviour
estimate the power of
preventing this behaviour have
the power of the
this behaviour have been
power of the miner
behaviour have been discussed
based update propagation ity
have been discussed elsewhere
update propagation ity to
propagation ity to continue
ity to continue accessing
to continue accessing a
continue accessing a file
accessing a file server
but if bandwidth is
to reduce management overhead
if bandwidth is less
bandwidth is less scheme
as the value of
the value of bitcoin
unlike previous mobile file
value of bitcoin rose
previous mobile file systems
bitcoin mining has become
in order to characterise
mining has become a
order to characterise the
has become a rapidly
to characterise the effect
become a rapidly advancing
characterise the effect of
a rapidly advancing industry
the effect of adding
effect of adding prefetching
technological advancements lead to
we ran a set
client consistency is achievable
advancements lead to ever
ran a set of
lead to ever more
a set of eight
to ever more efficient
set of eight microbenchmarks
ever more efficient hashing
codaniques that are oblivious
more efficient hashing asics
that are oblivious to
mode buffering flow control
are oblivious to the
buffering flow control against
oblivious to the exact
the experimental setup was
to the exact bandwidth
flow control against one
the exact bandwidth level
experimental setup was the
setup was the same
was the same as
the same as in
same as in the
way link latency left
as in the priority
and can like file
in the priority tests
can like file systems
like file systems therefore
file systems therefore switch
most bar represents maelstrom
systems therefore switch between
bar represents maelstrom in
therefore switch between a
represents maelstrom in end
switch between a low
though this time mfs
this time mfs was
time mfs was configured
mfs was configured to
was configured to run
this is a simplification
configured to run with
is a simplification that
to run with asynchronous
end mode with manually
a simplification that is
mode with manually configured
run with asynchronous writeback
with manually configured large
simplification that is sufficient
manually configured large buffers
writes mode and a
configured large buffers at
mode and a synchronous
that is sufficient for
and rpc with priorities
is sufficient for our
large buffers at end
sufficient for our analysis
and only prefetching was
only prefetching was either
the intricacies of reward
prefetching was either enabled
intricacies of reward systems
was either enabled or
of reward systems are
either enabled or disabled
and the second and
acthe authors were supported
the second and third
reward systems are explained
second and third bar
systems are explained in
and third bar from
the tests were run
third bar from left
tests were run at
bar from left are
were run at a
from left are split
authors were supported in
left are split mode
run at a range
are split mode and
were supported in part
split mode and end
at a range of
supported in part by
a range of bandwidth
in part by darpa
range of bandwidth values
part by darpa under
by darpa under afrl
darpa under afrl grant
under afrl grant radc
as in the previous
afrl grant radc cording
in the previous section
grant radc cording to
radc cording to the
cording to the available
to the available bandwidth
a notable exception is
each microbenchmark consists of
with standard buffers at
notable exception is p
standard buffers at end
microbenchmark consists of one
consists of one or
of one or two
one or two processes
or two processes accessing
in a wireless f
two processes accessing files
split mode performs as
mode performs as well
performs as well with
with some or all
as well with default
some or all of
well with default sized
or all of the
with default sized buffers
all of the files
default sized buffers as
of the files forming
sized buffers as end
the files forming file
files forming file groups
which we discuss in
we discuss in section
discuss in section ix
end mode performs with
write test is the
mode performs with large
test is the same
performs with large end
is the same as
the same as in
forks block propagation in
same as in section
block propagation in the
propagation in the overlay
in the overlay network
the overlay network takes
overlay network takes seconds
and much better than
much better than end
with a file group
therefore it is possible
a file group added
it is possible for
file group added for
is possible for two
group added for the
possible for two distant
added for the read
for two distant miners
for the read data
end mode with default
two distant miners to
mode with default sized
distant miners to generate
with default sized buffers
miners to generate competing
to generate competing blocks
the compile mfs test
compile mfs test has
mfs test has six
test has six file
has six file groups
both of which name
six file groups for
of which name the
file groups for the
which name the same
groups for the main
name the same block
for the main directories
the same block as
the main directories of
same block as their
main directories of the
and by afosr under
block as their predecessor
directories of the system
by afosr under muri
afosr under muri grant
under muri grant f
mb of data in
are rare since the
rare since the average
since the average mining
the average mining interval
average mining interval is
forming a single file
a single file group
mb of small files
and they occur on
they occur on average
occur on average once
on average once every
all the files are
the files are in
files are in a
are in a single
in a single file
a single file group
the system has a
fetch runs as two
system has a mechanism
runs as two process
has a mechanism to
variations in bandwidth can
a mechanism to solve
in bandwidth can occur
mechanism to solve forks
bandwidth can occur without
to solve forks when
can occur without the
solve forks when they
occur without the user
forks when they do
without the user s
when they do occur
the user s with
user s with additional
s with additional support
with additional support from
additional support from microsoft
support from microsoft research
from microsoft research and
causing one of the
microsoft research and from
one of the blocks
research and from the
of the blocks to
and from the intel
the blocks to be
from the intel corporation
blocks to be discarded
which form a file
form a file group
we ignore bifurcations for
the other does the
ignore bifurcations for the
other does the same
bifurcations for the sake
for the sake of
so that changing modes
the sake of simplicity
that changing modes creates
changing modes creates unexpected
but without a file
modes creates unexpected incon
without a file group
since the choice of
the choice of the
choice of the discarded
simultaneous writeback executes in
of the discarded block
writeback executes in the
several clients concurrently modify
executes in the same
the discarded block on
in the same way
clients concurrently modify a
discarded block on bifurcation
concurrently modify a file
block on bifurcation is
on bifurcation is random
but the second process
the second process writes
the final contents depend
second process writes the
final contents depend on
process writes the files
contents depend on the
one may incorporate this
depend on the client
writes the files to
on the client that
may incorporate this event
the client that closed
the files to the
incorporate this event into
files to the server
client that closed it
to the server instead
that closed it last
the server instead of
this event into the
server instead of reading
event into the probability
instead of reading them
into the probability of
the probability of finding
a client can lock
probability of finding a
client can lock a
of finding a block
can lock a file
the remaining tests investigate
lock a file to
remaining tests investigate the
a file to synchronise
tests investigate the overhead
file to synchronise accesses
and consider instead the
investigate the overhead paid
consider instead the probability
the overhead paid for
instead the probability of
overhead paid for weaknesses
the probability of finding
paid for weaknesses in
probability of finding a
for weaknesses in the
of finding a block
weaknesses in the prefetching
finding a block that
in the prefetching algorithm
a block that is
the server grants the
block that is not
server grants the client
that is not discarded
grants the client a
the client a lease
pools often charge a
often charge a small
charge a small percentage
a small percentage of
small percentage of the
percentage of the revenue
of the revenue as
the revenue as fee
that is renewed each
is renewed each time
renewed each time the
each time the client
we discuss in section
time the client communicates
discuss in section ix
the client communicates with
in section ix the
client communicates with the
section ix the implications
communicates with the file
ix the implications of
with the file server
the implications of such
implications of such fees
of such fees to
such fees to our
fees to our analysis
many pools are open
pools are open and
are open and accept
open and accept any
kb files and forming
and accept any interested
files and forming its
accept any interested miner
and forming its own
forming its own file
its own file group
a pool interface is
pool interface is typically
on its first iteration
interface is typically comprised
is typically comprised of
typically comprised of a
comprised of a web
the workload accesses the
of a web interface
workload accesses the first
a web interface for
accesses the first file
web interface for registration
the first file in
interface for registration and
first file in each
for registration and a
file in each directory
registration and a miner
and a miner interface
a miner interface for
miner interface for the
interface for the mining
for the mining software
in order to mine
order to mine for
to mine for a
mine for a pool
to provoke a large
provoke a large amount
a miner registers with
a large amount of
miner registers with the
large amount of useless
registers with the web
amount of useless prefetches
with the web interface
good order and bad
supplies a bitcoin address
order and bad order
a bitcoin address to
and bad order investigate
bitcoin address to receive
bad order investigate the
address to receive its
order investigate the effect
to receive its future
investigate the effect of
receive its future shares
the effect of the
its future shares of
effect of the ordered
future shares of the
of the ordered list
shares of the revenue
the ordered list of
ordered list of files
list of files in
of files in a
files in a file
in a file group
and receives from the
receives from the pool
from the pool credentials
the pool credentials for
pool credentials for mining
then he feeds his
he feeds his credentials
feeds his credentials and
his credentials and the
credentials and the pool
and the pool s
the pool s address
prefetching evaluation having added
pool s address to
evaluation having added prefetching
s address to its
having added prefetching to
address to its mining
added prefetching to mfs
to its mining rig
we evaluated whether such
evaluated whether such a
whether such a straightforward
such a straightforward algorithm
a straightforward algorithm can
the mining rig obtains
straightforward algorithm can have
mining rig obtains its
algorithm can have a
rig obtains its tasks
can have a benefit
obtains its tasks from
have a benefit for
its tasks from the
a benefit for some
tasks from the pool
benefit for some repre
from the pool and
the pool and sends
pool and sends partial
and sends partial and
sends partial and full
partial and full proof
order accesses the files
and full proof of
accesses the files in
full proof of work
the files in the
files in the group
in the group in
the group in the
group in the same
typically with the stratum
in the same order
with the stratum protocol
the same order as
same order as the
order as the list
adaptive remote procedure call
bad order accesses them
remote procedure call figure
order accesses them in
accesses them in reverse
them in reverse order
time series of wireless
series of wireless bandwidth
as it finds blocks
mafs uses adaptive remote
uses adaptive remote procedure
adaptive remote procedure call
the pool manager credits
remote procedure call for
pool manager credits the
procedure call for client
manager credits the miner
credits the miner s
the miner s account
miner s account according
s account according to
account according to its
according to its share
to its share of
its share of the
share of the work
analysis of prefetching the
of prefetching the graphs
prefetching the graphs in
the graphs in figure
and transfers these funds
transfers these funds either
these funds either on
show the results of
funds either on request
the results of the
adaptation based on low
results of the experiments
either on request or
on request or automatically
request or automatically to
or automatically to the
automatically to the aforementioned
where a test such
to the aforementioned bitcoin
a test such as
the aforementioned bitcoin address
test such as simultaneous
such as simultaneous demand
adaptive rpc is based
too big pools despite
rpc is based on
big pools despite their
is based on our
way delivery latency against
based on our earlier
pools despite their important
on our earlier work
delivery latency against loss
our earlier work in
latency against loss rate
earlier work in modes
despite their important role
fetch incorporates more than
their important role of
work in modes can
important role of enabling
in modes can be
role of enabling small
modes can be ill
incorporates more than one
more than one workload
suited to situations where
to situations where bandwidth
only the elapsed time
situations where bandwidth is
the elapsed time for
where bandwidth is not
elapsed time for the
bandwidth is not network
time for the foreground
pools can constitute a
for the foreground workload
can constitute a threat
constitute a threat to
a threat to the
threat to the bitcoin
to the bitcoin system
the one accessing a
the bitcoin system if
one accessing a file
bitcoin system if their
accessing a file group
system if their size
if their size is
their size is too
size is too large
in most of the
if one pool controls
most of the microbenchmarks
one pool controls the
and differs from severely
pool controls the majority
differs from severely constrained
controls the majority of
the majority of mining
majority of mining power
adding prefetching from the
prefetching from the file
but insufficient for a
from the file groups
insufficient for a client
the file groups specified
the system becomes unstable
file groups specified has
for a client to
groups specified has a
a client to ignore
specified has a substantial
client to ignore it
has a substantial improvement
to ignore it a
a substantial improvement on
ignore it a typical
substantial improvement on the
it a typical rpc
improvement on the performance
a typical rpc system
on the performance of
typical rpc system in
the performance of the
rpc system in allowing
performance of the workload
system in allowing applications
in allowing applications to
allowing applications to control
applications to control how
to control how concurrent
varying with how amenable
control how concurrent rpcs
with how amenable it
how concurrent rpcs are
how amenable it is
concurrent rpcs are transmitted
amenable it is to
it is to prefetching
and special handling for
special handling for failwhen
handling for failwhen deciding
for failwhen deciding what
failwhen deciding what to
more surplus bandwidth and
deciding what to send
surplus bandwidth and more
what to send over
bandwidth and more think
to send over the
and more think time
send over the network
more think time result
think time result in
time result in improved
result in improved performance
ures due to insufficient
due to insufficient bandwidth
this naturally means that
naturally means that the
adaptive rpc requests and
means that the greatest
rpc requests and replies
that the greatest improvements
requests and replies can
the greatest improvements from
warns that the system
and replies can contain
that the system is
replies can contain an
greatest improvements from prefetching
can contain an arbitrary
the system is unstable
contain an arbitrary amount
improvements from prefetching are
an arbitrary amount of
system is unstable with
from prefetching are evident
is unstable with even
arbitrary amount of data
unstable with even smaller
prefetching are evident at
with even smaller pools
are evident at higher
evident at higher bandwidths
a sender also attaches
sender also attaches a
also attaches a priority
six out of eight
attaches a priority and
out of eight microbenchmarks
a priority and timeout
of eight microbenchmarks run
priority and timeout to
eight microbenchmarks run at
and timeout to the
microbenchmarks run at least
timeout to the send
to the send operation
in realistic scenarios of
realistic scenarios of the
scenarios of the bitcoin
of the bitcoin system
the bitcoin system no
bitcoin system no pool
system no pool controls
no pool controls a
file system overview rover
pool controls a majority
system overview rover queued
controls a majority of
faster when bandwidth is
a majority of the
overview rover queued rpc
majority of the mining
of the mining power
for one day in
one day in june
an adaptive rpc can
adaptive rpc can be
rpc can be asynchronous
adaptive mobile file system
a single pool called
single pool called ghash
at low bandwidth most
low bandwidth most workloads
is a distributed file
bandwidth most workloads see
a distributed file sys
most workloads see no
workloads see no benefit
so that an application
that an application need
since all the bandwidth
an application need not
all the bandwidth is
application need not block
the bandwidth is dedicated
need not block waiting
bandwidth is dedicated to
not block waiting for
is dedicated to higher
block waiting for the
of the blocks in
waiting for the result
the blocks in the
blocks in the bitcoin
in the bitcoin main
the bitcoin main chain
intem designed to support
designed to support efficient
only two tests perform
to support efficient access
the bitcoin community backlashed
support efficient access to
bitcoin community backlashed at
efficient access to a
two tests perform worse
access to a remote
community backlashed at the
to a remote file
backlashed at the pool
a remote file server
tests perform worse with
remote file server stead
perform worse with prefetching
worse with prefetching than
with prefetching than without
which has done nothing
has done nothing worse
the library makes an
done nothing worse than
library makes an upcall
nothing worse than being
makes an upcall when
worse than being extremely
an upcall when the
than being extremely successful
upcall when the reply
when the reply arrives
write test performs slightly
test performs slightly worse
performs slightly worse due
slightly worse due to
since an application can
worse due to its
an application can perform
due to its already
application can perform multiple
to its already heavy
can perform multiple rpcs
its already heavy network
io reduced its relative
already heavy network contention
perform multiple rpcs concurby
reduced its relative mining
multiple rpcs concurby mobile
its relative mining power
rpcs concurby mobile clients
relative mining power and
concurby mobile clients that
mining power and publicly
the bad groups test
power and publicly committed
mobile clients that must
and publicly committed to
clients that must cope
publicly committed to stay
that must cope with
committed to stay away
must cope with variations
which exploits poor prefetching
cope with variations in
exploits poor prefetching hints
with variations in available
to stay away from
variations in available bandwidth
stay away from the
the mafs design and
mafs design and terminology
performs when prefetching is
design and terminology are
when prefetching is used
and terminology are similar
terminology are similar to
are similar to rently
this effect is due
effect is due to
adaptive rpc schedules their
is due to the
rpc schedules their transmission
due to the useless
to the useless prefetching
block withholding and its
the useless prefetching rpcs
withholding and its detection
useless prefetching rpcs flooding
this corresponds to allocating
and its detection classical
corresponds to allocating bandwidth
prefetching rpcs flooding the
to allocating bandwidth among
its detection classical block
allocating bandwidth among the
rpcs flooding the outgoing
bandwidth among the competing
detection classical block withholding
among the competing rpcs
flooding the outgoing link
the outgoing link and
outgoing link and imposing
link and imposing minor
the andrew file system
and imposing minor delays
imposing minor delays on
minor delays on each
delays on each demand
on each demand fetch
cumulatively these slow down
is an attack performed
these slow down the
an attack performed by
slow down the overall
attack performed by a
down the overall performance
performed by a pool
by a pool member
a pool member against
pool member against the
member against the other
an usual phenomenon is
against the other pool
usual phenomenon is that
the other pool members
phenomenon is that the
is that the bad
that the bad order
the bad order test
bad order test consistently
attaching priorities to rpcs
the attacking miner registers
priorities to rpcs allows
order test consistently outperforms
attacking miner registers with
to rpcs allows applications
test consistently outperforms good
rpcs allows applications to
consistently outperforms good order
allows applications to control
miner registers with the
applications to control this
registers with the pool
to control this scheduling
with the pool and
control this scheduling policy
even though the latter
the pool and apparently
though the latter triggers
the latter triggers prefetches
pool and apparently starts
latter triggers prefetches in
a programmer divides rpcs
triggers prefetches in the
programmer divides rpcs into
prefetches in the correct
divides rpcs into classes
and apparently starts mining
in the correct order
apparently starts mining honestly
starts mining honestly it
mining honestly it regularly
honestly it regularly sends
the explanation is that
it regularly sends the
regularly sends the pool
sends the pool partial
the pool partial proof
pool partial proof of
partial proof of work
file access model based
access model based on
model based on the
the good order test
based on the importance
good order test suffers
on the importance of
order test suffers from
the importance of their
test suffers from the
importance of their results
the attacking miner sends
suffers from the fast
attacking miner sends only
of their results to
miner sends only partial
from the fast linear
sends only partial proof
their results to the
only partial proof of
the fast linear scan
partial proof of work
results to the user
fast linear scan phenomenon
linear scan phenomenon described
scan phenomenon described in
phenomenon described in section
if it finds a
and then mafs clients
it finds a full
then mafs clients use
finds a full solution
mafs clients use whole
a full solution that
full solution that constitutes
solution that constitutes a
that constitutes a full
constitutes a full proof
a full proof of
full proof of work
when a file is
proof of work it
a file is accessed
of work it discards
file is accessed assigns
all prefetches in this
work it discards the
is accessed assigns priorities
it discards the solution
prefetches in this test
accessed assigns priorities to
in this test conflict
assigns priorities to the
this test conflict with
priorities to the classes
test conflict with demand
conflict with demand fetches
reducing the pool s
the pool s total
pool s total revenue
the library schedules rpcs
library schedules rpcs for
schedules rpcs for the
rpcs for the first
for the first time
this attack is illustrated
attack is illustrated in
at the start of
is illustrated in figure
a client fetches the
the start of the
client fetches the entire
start of the bad
fetches the entire file
of the bad order
the entire file from
the bad order test
entire file from the
file from the file
the attacker does not
from the file based
attacker does not change
the file based on
does not change the
the prefetching subsystem is
not change the pool
file based on priorities
change the pool s
prefetching subsystem is able
the pool s effective
based on priorities whenever
pool s effective mining
subsystem is able to
s effective mining power
on priorities whenever there
is able to prefetch
priorities whenever there is
able to prefetch some
whenever there is insufficient
packet delivery latencies throughput
to prefetch some files
there is insufficient bandwidth
prefetch some files accessed
is insufficient bandwidth to
some files accessed at
insufficient bandwidth to server
files accessed at the
bandwidth to server and
accessed at the end
and does not affect
at the end of
to server and caches
the end of the
does not affect directly
end of the test
server and caches it
not affect directly the
affect directly the revenue
directly the revenue of
the revenue of other
revenue of other pools
without conflicting with a
conflicting with a demand
mafs only sends the
with a demand fetch
only sends the server
sends the server the
the server the contents
server the contents transmit
it can therefore achieve
the contents transmit competing
the attacked pool shares
can therefore achieve a
attacked pool shares its
therefore achieve a greater
pool shares its revenue
achieve a greater speedup
shares its revenue with
contents transmit competing rpcs
its revenue with the
transmit competing rpcs without
revenue with the attacker
competing rpcs without a
rpcs without a noticeable
without a noticeable delay
therefore each miner earns
each miner earns less
rpcs of a modified
of a modified file
a modified file when
modified file when it
as the same revenue
file when it is
the same revenue is
when it is closed
same revenue is distributed
it is closed by
revenue is distributed among
is closed by an
is distributed among more
closed by an application
distributed among more miners
this is from higher
recall that the proof
that the proof of
the proof of work
proof of work is
of work is only
priority classes are performed
work is only valid
classes are performed first
is only valid for
only valid for a
mbps flow alongside on
valid for a specific
flow alongside on the
for a specific block
and rpcs of referred
alongside on the same
rpcs of referred to
on the same link
of referred to as
the same link to
referred to as writeback
same link to simulate
as it is the
link to simulate a
it is the nonce
to simulate a real
is the nonce with
the nonce with which
nonce with which the
with which the block
time stream combined with
which the block s
stream combined with other
the block s hash
combined with other inter
block s hash is
directory operations cache equal
s hash is smaller
operations cache equal priority
hash is smaller than
cache equal priority are
is smaller than its
equal priority are performed
smaller than its target
priority are performed in
are performed in parallel
the attacking miner cannot
attacking miner cannot use
this ensures that the
miner cannot use it
ensures that the directory
that the directory contents
the directory contents and
directory contents and apply
contents and apply changes
and apply changes locally
although the term block
the term block withholding
shows the average delivery
as well as mak
the average delivery latency
term block withholding has
average delivery latency of
block withholding has become
withholding has become canonical
application adapts itself to
adapts itself to the
itself to the available
to the available bandwidth
note that the block
the available bandwidth gracefully
level packets in the
that the block is
the block is discarded
block is discarded and
is discarded and never
ing an rpc to
discarded and never introduced
an rpc to apply
and never introduced into
rpc to apply the
never introduced into the
to apply the changes
introduced into the system
apply the changes to
into the system as
the changes to the
the system as the
changes to the server
system as the name
to the server s
as the name block
the server s copy
the name block withholding
as loss rates go
name block withholding implies
loss rates go up
whole since lower bandwidth
since lower bandwidth translates
lower bandwidth translates into
bandwidth translates into longer
translates into longer delays
miners miners miners pool
into longer delays for
longer delays for lowerfile
delays for lowerfile caching
for lowerfile caching is
lowerfile caching is effective
caching is effective if
is effective if a
effective if a client
if a client s
a client s connectivity
client s connectivity is
s connectivity is uncertain
classical block withholding attack
a group of miners
group of miners attack
of miners attack pool
shows the same scenario
rpc timeouts allow the
the same scenario with
with a block withholding
timeouts allow the application
a block withholding attack
same scenario with a
allow the application to
scenario with a constant
the application to prevent
with a constant uniformly
application to prevent since
a constant uniformly random
to prevent since the
denoted by a dashed
constant uniformly random loss
by a dashed red
prevent since the client
a dashed red arrow
uniformly random loss rate
since the client can
random loss rate of
the client can always
client can always use
can always use cached
always use cached copies
use cached copies of
cached copies of files
copies of files instead
of files instead low
this attack reduces the
attack reduces the attacker
reduces the attacker s
the attacker s revenue
priority rpcs being silently
attacker s revenue compared
rpcs being silently starved
s revenue compared to
revenue compared to solo
compared to solo mining
to solo mining or
solo mining or honest
using priorities alof incrementally
mining or honest pool
priorities alof incrementally fetching
or honest pool participation
alof incrementally fetching them
incrementally fetching them from
fetching them from the
maelstrom s delivery latency
them from the server
s delivery latency is
it suffers from the
delivery latency is almost
suffers from the reduced
latency is almost exactly
from the reduced revenue
is almost exactly equal
the reduced revenue like
almost exactly equal to
reduced revenue like the
exactly equal to the
revenue like the other
equal to the one
like the other pool
lows a programmer to
the other pool participants
a programmer to write
programmer to write an
way latency on the
to write an adaptive
latency on the link
write an adaptive application
and its revenue is
an adaptive application without
its revenue is less
adaptive application without ports
revenue is less than
application without ports this
is less than its
without ports this type
less than its share
ports this type of
than its share of
ip takes more than
its share of the
takes more than twice
share of the total
more than twice as
of the total mining
this type of disconnected
than twice as long
type of disconnected operation
twice as long once
the total mining power
as long once one
total mining power in
mining power in the
power in the system
way latencies go past
number of rpcs by
of rpcs by type
this attack can therefore
rpcs by type in
attack can therefore only
by type in bandwidth
can therefore only be
type in bandwidth variability
but not to the
in bandwidth variability test
not to the ex
therefore only be used
only be used for
be used for sabotage
the entries under p
having to take account
entries under p denote
to take account of
at a cost to
under p denote periods
a cost to the
take account of the
cost to the attacker
p denote periods in
account of the actual
denote periods in the
of the actual bandwidth
periods in the test
the actual bandwidth or
actual bandwidth or current
bandwidth or current mix
or current mix tent
current mix tent of
even if a pool
mix tent of automatic
if a pool detects
tent of automatic reconciliation
a pool detects that
of automatic reconciliation of
gives the abbreviations for
automatic reconciliation of update
the abbreviations for rpc
reconciliation of update conflicts
abbreviations for rpc types
pool detects that it
detects that it is
that it is under
it is under a
is under a block
are likely to be
under a block withholding
likely to be beneficial
a block withholding attack
the first would reduce
it might not be
first would reduce the
might not be able
would reduce the aggressiveness
not be able to
reduce the aggressiveness of
be able to detect
the aggressiveness of prefetching
able to detect which
ip one way link
to detect which of
one way link latency
on of rpcs at
detect which of its
of rpcs at runtime
which of its registered
of its registered miners
its registered miners are
registered miners are the
setting a byte threshold
miners are the perpetrators
and avoid having to
avoid having to specify
having to specify thresholds
to specify thresholds at
specify thresholds at the
from a file group
thresholds at the other
a file group if
at the other hand
file group if it
a pool can estimate
group if it appeared
pool can estimate its
if it appeared that
can estimate its expected
it appeared that a
estimate its expected mining
appeared that a process
its expected mining power
level caching reduces the
that a process was
caching reduces the delay
expected mining power and
reduces the delay incurred
a process was not
the delay incurred which
mining power and its
delay incurred which it
process was not using
incurred which it should
power and its actual
which it should switch
was not using the
it should switch communication
and its actual mining
should switch communication modes
not using the files
its actual mining power
using the files prefetched
actual mining power by
the files prefetched based
split with regular buffers
files prefetched based on
mining power by the
prefetched based on its
an rpc whose results
based on its prior
power by the rates
on its prior accesses
rpc whose results are
by the rates of
whose results are urgently
the rates of partial
results are urgently required
rates of partial proofs
are urgently required should
of partial proofs of
this would reduce the
urgently required should be
would reduce the overhead
partial proofs of work
required should be aswhen
proofs of work and
reduce the overhead in
of work and full
should be aswhen an
work and full proofs
end with large buffers
and full proofs of
be aswhen an application
full proofs of work
the overhead in the
aswhen an application opens
overhead in the bad
an application opens a
in the bad groups
application opens a file
the bad groups case
the second would explicitly
supplied by its miners
second would explicitly detect
as has been shown
would explicitly detect a
has been shown in
explicitly detect a fast
been shown in the
detect a fast linear
shown in the low
a fast linear scan
a difference above a
fast linear scan by
difference above a set
and outperforms it with
above a set confidence
linear scan by a
a set confidence interval
scan by a process
outperforms it with regular
set confidence interval indicates
it with regular buffers
confidence interval indicates an
interval indicates an attack
by counting the instances
counting the instances of
the instances of prefetch
instances of prefetch and
to detect whether a
of prefetch and demand
detect whether a single
prefetch and demand fetch
whether a single miner
and demand fetch conflict
a single miner is
demand fetch conflict for
single miner is attacking
fetch conflict for a
miner is attacking it
conflict for a file
for a file group
it is possible to
latency metrics to measure
is possible to use
metrics to measure the
possible to use a
to measure the latency
to use a signed
measure the latency effects
use a signed the
the latency effects of
a signed the highest
latency effects of tcp
signed the highest priority
the pool must use
and then disable prefetching
pool must use a
then disable prefetching from
must use a similar
disable prefetching from the
particularly if the rpc
use a similar technique
prefetching from the group
if the rpc contains
the rpc contains outcontent
comparing the estimated mining
based division of files
the estimated mining power
division of files into
of files into blocks
estimated mining power of
files into blocks as
mbps stream between two
mining power of the
into blocks as the
stream between two nodes
blocks as the basis
power of the attacker
as the basis for
between two nodes over
prefetching and bandwidth variability
two nodes over a
and bandwidth variability so
of the attacker based
bandwidth variability so far
the basis for re
the attacker based on
attacker based on its
based on its partial
on its partial proof
our experimental results have
its partial proof of
experimental results have demonstrated
partial proof of work
results have demonstrated the
proof of work with
have demonstrated the benefits
of work with the
demonstrated the benefits of
work with the fact
the benefits of mfs
with the fact it
benefits of mfs adaptation
the fact it never
of mfs adaptation mechanisms
fact it never supplies
but still important rpcs
it never supplies a
mfs adaptation mechanisms at
never supplies a full
still important rpcs can
supplies a full proof
adaptation mechanisms at various
important rpcs can ducing
a full proof of
rpcs can ducing client
full proof of work
mechanisms at various levels
at various levels of
various levels of bandwidth
levels of bandwidth availability
if the attacker has
the attacker has a
attacker has a small
has a small mining
but not when the
a small mining power
not when the bandwidth
plots delivery latency against
when the bandwidth is
delivery latency against message
the bandwidth is changing
latency against message identifier
bandwidth is changing over
it will send frequent
is changing over the
will send frequent partial
changing over the duration
send frequent partial proofs
over the duration of
frequent partial proofs of
a key point is
partial proofs of work
the duration of the
key point is that
duration of the test
while the lowest levels
point is that we
the lowest levels are
is that we are
but the pool will
lowest levels are useful
that we are plotting
the pool will only
to conclude this section
we are plotting the
levels are useful for
are plotting the delivery
conclude this section we
plotting the delivery latency
are useful for server
this section we will
pool will only expect
the delivery latency of
section we will describe
useful for server traffic
will only expect to
delivery latency of all
we will describe an
latency of all packets
for server traffic does
will describe an example
only expect to see
server traffic does not
expect to see a
describe an example of
to see a full
not just lost ones
an example of mfs
traffic does not eliminate
see a full proof
does not eliminate the
a full proof of
not eliminate the fundamental
example of mfs traffic
eliminate the fundamental problem
full proof of work
the fundamental problem of
of mfs traffic under
fundamental problem of rpcs
proof of work at
problem of rpcs that
the spikes in latency
of rpcs that can
of work at very
rpcs that can be
work at very low
that can be arbitrarily
at very low frequency
can be arbitrarily delayed
spikes in latency are
mfs traffic under the
in latency are triggered
traffic under the execution
latency are triggered by
under the execution of
are triggered by losses
such as speculative activities
the execution of the
as speculative activities like
triggered by losses that
speculative activities like prefetching
it cannot obtain statistically
by losses that lead
execution of the simultaneous
losses that lead to
of the simultaneous writeback
activities like prefetching and
the simultaneous writeback test
like prefetching and transferring
simultaneous writeback test described
prefetching and transferring archival
writeback test described in
and transferring archival data
test described in section
that lead to packets
cannot obtain statistically significant
lead to packets piling
obtain statistically significant results
to packets piling up
statistically significant results that
packets piling up both
significant results that would
if the inicontention for
results that would indicate
piling up both at
that would indicate an
the inicontention for insufficient
would indicate an attack
up both at the
inicontention for insufficient bandwidth
both at the receiver
at the receiver and
the receiver and the
receiver and the sender
an attacker can use
tial assumption regarding the
attacker can use multiple
this test involves two
can use multiple small
test involves two simultaneous
assumption regarding the correct
involves two simultaneous workloads
use multiple small block
regarding the correct priority
multiple small block withholding
the correct priority level
small block withholding miners
correct priority level for
block withholding miners and
priority level for an
ip delays correctly received
level for an rpc
withholding miners and replace
for an rpc proves
miners and replace them
an rpc proves incorrect
delays correctly received packets
and replace them frequently
correctly received packets at
received packets at the
kb to the server
packets at the receiver
a call to the
to the server and
call to the library
the server and the
a small miner is
server and the other
to the library can
and the other reads
at the receiver while
the library can be
the receiver while waiting
library can be made
receiver while waiting for
can be made to
while waiting for missing
be made to assign
waiting for missing packets
made to assign a
a miners whose expected
for missing packets sequenced
kb files from the
miners whose expected full
files from the server
missing packets sequenced earlier
whose expected full proof
packets sequenced earlier by
expected full proof of
sequenced earlier by the
full proof of work
earlier by the sender
proof of work frequency
but is slightly modified
of work frequency is
is slightly modified from
work frequency is yearly
slightly modified from original
modified from original version
it also delays packets
from original version to
also delays packets at
such a miner will
client cache consistency new
original version to use
cache consistency new priority
a miner will see
delays packets at the
version to use a
packets at the sender
to use a longer
miner will see a
when a client fetches
will see a non
a client fetches a
use a longer think
client fetches a file
at the sender when
a longer think time
the sender when it
longer think time of
sender when it cuts
negligible average daily revenue
when it cuts down
the file server grants
it cuts down on
file server grants it
cuts down on the
server grants it permission
down on the sending
grants it permission to
on the sending window
it permission to cache
the sending window size
permission to cache the
sending window size in
to cache the file
window size in response
cache the file for
size in response to
the file for a
in response to the
file for a limited
response to the loss
for a limited period
to the loss events
seconds when accessing each
when accessing each file
and adds it to
adds it to a
it to a list
improving the potential for
the delays caused by
the potential for rpcs
delays caused by these
potential for rpcs to
caused by these two
for rpcs to overlap
by these two mechanisms
these two mechanisms are
two mechanisms are illustrated
mechanisms are illustrated in
are illustrated in figure
implementation of clients that
we enabled asynchronous writeback
of clients that cache
enabled asynchronous writeback and
clients that cache the
asynchronous writeback and ran
that cache the file
writeback and ran the
and ran the test
ran the test with
the test with the
where single packet losses
if the client modifies
single packet losses cause
the client modifies and
test with the synthetic
client modifies and then
packet losses cause spikes
modifies and then closes
with the synthetic bandwidth
and then closes the
losses cause spikes in
then closes the file
if the attacker replaces
the synthetic bandwidth trace
the attacker replaces such
synthetic bandwidth trace shown
attacker replaces such a
bandwidth trace shown in
replaces such a small
trace shown in figure
such a small miner
cause spikes in delivery
a small miner every
it transmits the new
small miner every month
spikes in delivery latency
transmits the new contents
in delivery latency that
the new contents to
delivery latency that last
new contents to the
latency that last for
contents to the server
he will collect about
that last for hundreds
will collect about b
last for hundreds of
for hundreds of packets
which mafs is implemented
mafs is implemented in
at the end of
is implemented in c
the end of each
implemented in c on
which changes the bandwidth
in c on freebsd
changes the bandwidth once
end of each month
the bandwidth once per
the maelstrom configuration used
bandwidth once per second
maelstrom configuration used is
configuration used is r
the client is a
the pool must decide
client is a usermakes
this has three sections
pool must decide within
is a usermakes a
must decide within this
a usermakes a callback
decide within this month
usermakes a callback rpc
within this month whether
a callback rpc to
this month whether the
callback rpc to any
month whether the miner
rpc to any other
whether the miner is
to any other clients
the miner is an
any other clients on
miner is an attacker
other clients on the
a brief period when
clients on the list
brief period when the
period when the bandwidth
when the bandwidth is
and revoke its earnings
the bandwidth is at
a client level process
client level process that
level process that stores
process that stores cached
that stores cached files
or just an unlucky
stores cached files in
just an unlucky honest
cached files in a
an unlucky honest miner
files in a local
in a local filesystem
since an honest miner
the that receives a
an honest miner of
that receives a callback
honest miner of this
a gradual decrease to
receives a callback rpc
miner of this power
a callback rpc discards
of this power is
callback rpc discards its
this power is unlikely
rpc discards its cached
power is unlikely to
discards its cached copy
is unlikely to find
its cached copy of
unlikely to find a
cached copy of the
to find a full
copy of the file
find a full proof
a full proof of
full proof of work
proof of work within
of work within a
work within a month
server also stores its
s over the course
also stores its copies
over the course of
stores its copies of
the course of ten
its copies of files
course of ten seconds
copies of files in
of files in a
files in a local
in a local filesystem
and then the maintenance
then the maintenance of
the maintenance of the
according to the exponential
to the exponential distribution
if an application has
an application has the
application has the file
a pool that rejects
has the file open
pool that rejects miners
the file open when
that rejects miners based
file open when its
rejects miners based on
open when its client
miners based on this
when its client re
based on this criterion
s rate until the
on this criterion would
rate until the end
this criterion would reject
until the end of
criterion would reject the
the end of the
would reject the majority
system operations from applications
end of the test
operations from applications are
reject the majority of
from applications are redirected
the majority of its
applications are redirected to
majority of its honest
are redirected to user
of its honest miners
redirected to user level
to user level ceives
user level ceives the
level ceives the callback
the alternative of rejecting
alternative of rejecting small
the file is discarded
of rejecting small miners
file is discarded once
rejecting small miners in
summary of results the
is discarded once it
small miners in general
discarded once it is
of results the test
once it is closed
miners in general or
results the test was
in general or distributing
the test was executed
general or distributing revenue
test was executed once
when through a kernel
was executed once with
or distributing revenue on
executed once with prefetching
through a kernel module
once with prefetching enabled
a kernel module at
distributing revenue on a
kernel module at the
revenue on a yearly
module at the client
on a yearly basis
a yearly basis contradicts
and despite the simplicity
yearly basis contradicts the
despite the simplicity of
basis contradicts the goal
the simplicity of the
contradicts the goal of
simplicity of the mfs
the goal of pooled
of the mfs prefetching
goal of pooled mining
the mfs prefetching implementation
once with no prefetching
fetch prefetch metadata store
m odel and s
and the rpcs were
prefetch metadata store fetch
odel and s tandard
metadata store fetch file
the rpcs were then
store fetch file attributes
and s tandard o
rpcs were then divided
s tandard o peration
were then divided acwe
tandard o peration we
then divided acwe have
o peration we specify
divided acwe have shown
peration we specify the
acwe have shown that
we specify the basic
have shown that workloads
pull file update fetch
specify the basic model
file update fetch file
shown that workloads which
update fetch file data
the basic model in
that workloads which are
basic model in which
workloads which are amenable
model in which participants
which are amenable to
in which participants operate
are amenable to file
which participants operate in
participants operate in section
operate in section iii
level cording to which
prefetch file data lock
cording to which period
file data lock a
to which period of
data lock a file
which period of the
proceed to describe how
period of the trace
to describe how honest
of the trace they
describe how honest miners
the trace they terminated
how honest miners operate
trace they terminated in
honest miners operate in
miners operate in this
most metadata rpcs store
operate in this environment
metadata rpcs store file
in this environment in
rpcs store file data
for each prefetching can
this environment in sections
each prefetching can achieve
environment in sections iii
prefetching can achieve speedups
can achieve speedups of
unlink file such as
file such as deleting
such as deleting a
as deleting a modified
deleting a modified file
such optimisations can be
optimisations can be effective
and how the classical
can be effective at
how the classical block
be effective at low
the classical block withholding
effective at low bandwidth
classical block withholding attack
block withholding attack is
withholding attack is implemented
attack is implemented with
four quantities are calculated
when there is a
is implemented with our
there is a natural
implemented with our model
is a natural delay
with our model in
our model in section
the time spent queued
model in section iii
time spent queued for
spent queued for as
but at high bandwidth
queued for as much
for as much as
an artificial delay in
artificial delay in writing
delay in writing back
in writing back updates
writing back updates introduces
model the system is
back updates introduces inconsistencies
the system is comprised
updates introduces inconsistencies between
system is comprised of
at bandwidths as low
is comprised of the
bandwidths as low as
introduces inconsistencies between the
comprised of the bitcoin
inconsistencies between the client
of the bitcoin network
between the client and
the bitcoin network and
the client and the
bitcoin network and nodes
client and the file
network and nodes with
and the file server
and nodes with unique
nodes with unique ids
this can be acceptable
can be acceptable at
and progresses in steps
be acceptable at low
acceptable at low bandwidths
prefetching both the rpc
both the rpc request
the rpc request and
rpc request and reply
a node i generates
when the user may
node i generates tasks
the user may table
i generates tasks which
generates tasks which are
and the time taken
tasks which are associated
the time taken for
which are associated with
time taken for each
are associated with its
taken for each to
associated with its id
for each to be
with its id i
each to be carries
priorities for mafs remote
to be carries a
for mafs remote procedure
be carries a small
mafs remote procedure calls
carries a small performance
a node can work
a small performance overhead
node can work on
can work on a
work on a task
be grateful to be
on a task for
grateful to be able
a task for the
even when performed at
task for the duration
to be able to
when performed at received
for the duration of
be able to use
the duration of a
able to use the
duration of a step
to use the file
use the file system
from the first to
the file system at
the first to the
file system at all
first to the last
the result of this
to the last packet
result of this work
of this work is
but should be avoided
this work is a
should be avoided when
work is a set
be avoided when bandwidth
is a set of
avoided when bandwidth is
this ignores the time
when bandwidth is unconstrained
ignores the time the
a set of partial
the time the lowest
set of partial proofs
time the lowest priority
of partial proofs of
partial proofs of work
proofs of work and
of work and a
work and a set
which can reduce its
and a set of
can reduce its effectiveness
a set of full
reduce its effectiveness for
set of full proofs
its effectiveness for fast
of full proofs of
effectiveness for fast lin
full proofs of work
mafs avoids the need
avoids the need for
spent at the server
percentage of packets recovered
at the server servicing
the number of proofs
the server servicing the
the need for modes
server servicing the rpc
number of proofs in
need for modes by
of proofs in each
for modes by using
proofs in each set
modes by using asynchronous
in each set has
by using asynchronous remote
each set has a
using asynchronous remote procedure
set has a poisson
trip time ear scan
asynchronous remote procedure calls
has a poisson distribution
time ear scan workloads
remote procedure calls between
procedure calls between a
calls between a client
between a client and
partial proofs with a
a client and the
proofs with a large
it is possible to
with a large mean
client and the file
a large mean and
is possible to construct
large mean and full
and the file server
mean and full proofs
possible to construct combination
and full proofs with
the file server writeback
full proofs with a
to construct combination of
proofs with a small
file server writeback at
construct combination of file
server writeback at all
combination of file between
writeback at all bandwidth
of file between the
at all bandwidth levels
with a small mean
file between the client
relatively prime interleaves offer
between the client and
prime interleaves offer better
the client and the
interleaves offer better performance
client and the server
and incorporates a new
nodes that work on
incorporates a new upare
that work on tasks
a new upare divided
work on tasks are
new upare divided into
but these quantities are
on tasks are called
these quantities are small
tasks are called a
upare divided into several
are called a miners
quantities are small groups
divided into several types
are small groups and
into several types depending
small groups and a
several types depending on
groups and a workload
types depending on their
miners have identical power
and a workload for
depending on their function
a workload for which
workload for which prefetching
for which prefetching can
and hence identical probabilities
which prefetching can significantly
hence identical probabilities to
prefetching can significantly compared
rpcs date propagation algorithm
can significantly compared to
identical probabilities to generate
significantly compared to the
date propagation algorithm to
compared to the other
probabilities to generate proofs
to the other costs
propagation algorithm to reduce
to generate proofs of
algorithm to reduce the
generate proofs of work
to reduce the possibility
reduce the possibility of
these values are added
the possibility of inconsisto
values are added up
possibility of inconsisto fetch
are added up for
the bitcoin network pays
added up for each
of inconsisto fetch and
up for each degrade
bitcoin network pays for
for each degrade performance
network pays for full
inconsisto fetch and store
pays for full proofs
fetch and store data
for full proofs of
and store data are
full proofs of work
store data are self
of the rpcs within
the rpcs within a
rpcs within a particular
within a particular period
to acquire this payoff
acquire this payoff an
this payoff an entity
and the results are
payoff an entity publishes
the results are shown
an entity publishes a
results are shown within
entity publishes a task
are shown within the
publishes a task task
shown within the constraints
a task task and
within the constraints imposed
task task and its
the constraints imposed by
task and its corresponding
constraints imposed by our
and its corresponding proof
imposed by our file
its corresponding proof of
by our file group
corresponding proof of work
our file group representa
proof of work to
of work to the
work to the network
as new operations are
new operations are added
operations are added to
are added to the
added to the tail
the payoff goes to
to the tail tions
payoff goes to the
the tail tions include
goes to the id
tail tions include fetching
to the id associated
tions include fetching and
the id associated with
include fetching and setting
id associated with task
fetching and setting file
and setting file attributes
the bitcoin protocol normalizes
and directory of the
directory of the log
bitcoin protocol normalizes revenue
protocol normalizes revenue such
normalizes revenue such that
revenue such that the
the client flushes operations
such that the average
client flushes operations serially
that the average total
flushes operations serially from
the average total revenue
operations serially from the
average total revenue distributed
serially from the head
total revenue distributed in
from the head of
revenue distributed in each
the head of operations
distributed in each step
head of operations such
in each step is
of operations such as
each step is a
operations such as creating
step is a constant
such as creating and
is a constant throughout
as creating and unlinking
a constant throughout the
creating and unlinking files
constant throughout the execution
throughout the execution of
the execution of the
execution of the system
control rpcs the log
any node can transact
the main conclusion we
node can transact bitcoins
main conclusion we draw
can transact bitcoins to
conclusion we draw from
transact bitcoins to another
server traffic consists of
we draw from the
bitcoins to another node
traffic consists of a
draw from the test
to another node by
consists of a variety
from the test cases
another node by issuing
of a variety of
node by issuing a
the test cases exhibitthe
by issuing a bitcoin
a variety of foreground
test cases exhibitthe graphs
issuing a bitcoin transaction
variety of foreground include
cases exhibitthe graphs show
of foreground include locking
exhibitthe graphs show how
foreground include locking files
graphs show how priorities
include locking files and
show how priorities affect
locking files and the
nodes that generate tasks
how priorities affect rpcs
that generate tasks but
files and the server
generate tasks but outsource
priorities affect rpcs and
tasks but outsource the
and the server s
but outsource the work
affect rpcs and how
outsource the work are
the server s callback
the work are called
rpcs and how prefetching
work are called pools
server s callback to
and how prefetching a
s callback to invalidate
how prefetching a prefetch
callback to invalidate a
prefetching a prefetch penalty
to invalidate a rpcs
a prefetch penalty is
pools send tasks to
invalidate a rpcs for
send tasks to miners
prefetch penalty is that
tasks to miners over
a rpcs for control
to miners over the
penalty is that the
miners over the network
rpcs for control operations
is that the implementation
for control operations and
that the implementation could
control operations and fetching
the implementation could be
operations and fetching file
implementation could be im
the miners receive the
and fetching file data
miners receive the tasks
ing changes mfs behaviour
and a stream client
a stream client s
stream client s cached
client s cached copy
in all three time
s cached copy of
and send the partial
cached copy of a
all three time periods
copy of a file
send the partial and
the partial and full
partial and full proofs
and full proofs of
full proofs of work
more time proved to
of background rpcs for
proofs of work to
background rpcs for logged
of work to the
rpcs for logged operations
work to the pool
time proved to incorporate
proved to incorporate a
to incorporate a mechanism
incorporate a mechanism to
when bandwidth is high
apart from working on
a mechanism to inhibit
from working on tasks
mechanism to inhibit prefetching
replayed logged operations complete
logged operations complete quickly
the is spent on
with little extra delay
is spent on rpcs
spent on rpcs to
on rpcs to fetch
rpcs to fetch file
when bandwidth is low
to fetch file attributes
fetch file attributes with
file attributes with prefetching
logged operations are de
attributes with prefetching enabled
with prefetching enabled current
and receipt are instantaneous
prefetching enabled current prefetching
enabled current prefetching algorithm
current prefetching algorithm does
communication adaptation layed in
prefetching algorithm does not
adaptation layed in proportion
we assume that the
layed in proportion to
algorithm does not correlate
assume that the number
does not correlate file
in proportion to the
not correlate file accesses
that the number of
correlate file accesses with
proportion to the foreground
file accesses with than
the number of miners
to the foreground rpc
accesses with than without
number of miners is
the foreground rpc traffic
of miners is large
foreground rpc traffic and
miners is large enough
rpc traffic and the
is large enough such
since the time to
traffic and the availto
the time to receive
large enough such that
time to receive a
and the availto reduce
to receive a fetch
enough such that mining
the availto reduce its
such that mining power
availto reduce its network
that mining power can
reduce its network communication
attributes request the processes
its network communication when
request the processes which
mining power can be
the processes which make
network communication when bandwidth
processes which make them
communication when bandwidth is
power can be split
when bandwidth is low
can be split arbitrarily
be split arbitrarily without
split arbitrarily without resolution
but if this were
arbitrarily without resolution constraints
if this were done
two changes or reply
a mobile file system
changes or reply is
mobile file system client
or reply is negligible
denote the number of
file system client can
the number of pools
system client can automatically
number of pools with
client can automatically adapt
of pools with p
the increased time is
can automatically adapt its
increased time is due
automatically adapt its communication
time is due to
adapt its communication strategy
is due to a
its communication strategy to
the total number of
communication strategy to the
due to a greater
strategy to the available
total number of mining
to the available bandwidth
to a greater queue
number of mining power
of mining power in
mining power in the
power in the system
in the system with
the system with m
system with m and
with m and the
rpc times at intermediate
m and the miners
times at intermediate bandwidth
and the miners participating
the miners participating in
miners participating in pool
participating in pool i
rpc priorities cations transfer
priorities cations transfer a
cations transfer a large
transfer a large volume
a large volume of
large volume of data
volume of data that
of data that the
data that the user
that the user is
the user is unlikely
user is unlikely to
is unlikely to require
unlikely to require immediately
we use a quasistatic
use a quasistatic analysis
a quasistatic analysis where
quasistatic analysis where miner
consuming bandwidth that can
analysis where miner participation
bandwidth that can be
where miner participation in
that can be used
miner participation in a
can be used mafs
participation in a pool
be used mafs uses
in a pool does
used mafs uses priorities
a pool does not
mafs uses priorities to
pool does not change
uses priorities to reduce
does not change over
priorities to reduce contention
not change over time
to reduce contention between
reduce contention between foreground
contention between foreground for
between foreground for important
foreground for important tasks
solo mining a solo
mining a solo miner
a solo miner is
solo miner is a
miner is a node
is a node that
a node that generates
consider an application that
node that generates its
an application that activities
that generates its own
application that activities and
generates its own tasks
that activities and deferrable
activities and deferrable background
layered interleaving recovery percentage
and deferrable background activities
interleaving recovery percentage and
recovery percentage and latency
in every step it
percentage and latency c
every step it generates
adaptive rpc fetches images
step it generates a
rpc fetches images from
it generates a task
fetches images from a
images from a file
layered interleaving and bursty
from a file server
interleaving and bursty loss
and bursty loss thus
works on it for
bursty loss thus far
on it for the
loss thus far we
processes each in turn
it for the duration
thus far we have
for the duration of
far we have shown
the duration of the
we have shown how
duration of the step
have shown how maelstrom
of the step and
shown how maelstrom effectively
the step and if
how maelstrom effectively hides
step and if it
maelstrom effectively hides loss
and if it finds
preferentially allocates bandwidth to
effectively hides loss from
allocates bandwidth to foreground
hides loss from tcp
bandwidth to foreground rpcs
if it finds a
it finds a full
finds a full proof
a full proof of
ip for packets dropped
unlike plays the resulting
for packets dropped with
plays the resulting image
packets dropped with uniform
full proof of work
dropped with uniform randomness
and writes it to
writes it to the
it publishes this proof
it to the server
publishes this proof of
this proof of work
proof of work to
we examine the performance
of work to earn
examine the performance of
work to earn the
the performance of the
to earn the payoff
if the user little
performance of the layered
the user little work
of the layered interleaving
the layered interleaving algorithm
showing how different parameterizations
pools a pool is
how different parameterizations handle
a pool is a
different parameterizations handle bursty
pool is a node
parameterizations handle bursty loss
is a node that
handle bursty loss patterns
a node that serves
node that serves as
that serves as a
which assigns a lower
serves as a coordinator
we use a loss
assigns a lower priority
as a coordinator and
use a loss model
a lower priority to
a coordinator and multiple
a loss model where
lower priority to writeback
loss model where packets
priority to writeback in
model where packets are
coordinator and multiple miners
where packets are dropped
to writeback in wants
packets are dropped in
writeback in wants to
are dropped in bursts
in wants to see
dropped in bursts of
wants to see the
in bursts of fixed
to see the processed
bursts of fixed length
see the processed images
and multiple miners can
multiple miners can register
miners can register to
can register to a
allowing us to study
register to a pool
us to study the
to a pool and
to study the impact
a pool and work
study the impact of
pool and work for
the impact of burst
and work for it
impact of burst length
one else wants to
of burst length on
else wants to im
burst length on performance
in every step it
every step it generates
the link has a
step it generates a
link has a one
it generates a task
generates a task for
a task for each
task for each registered
for each registered miner
mafs has a finer
each registered miner and
registered miner and sends
miner and sends it
and sends it over
sends it over the
grained differentiation mediately read
it over the network
percentage of packets recovered
differentiation mediately read them
each miner receives its
writing the output back
miner receives its task
the output back will
receives its task and
output back will interfere
its task and works
back will interfere with
task and works on
will interfere with between
and works on it
interfere with between rpcs
works on it for
on it for the
it for the duration
for the duration of
the duration of the
duration of the step
and uses priorities at
uses priorities at all
priorities at all bandwidths
reed solomon layered interleaving
at the end of
the end of the
end of the step
this alfetching the next
alfetching the next image
u trsu t u
the miner sends the
and slow down the
trsu t u trsu
slow down the application
t u trsu t
miner sends the pool
u trsu t utrsut
sends the pool the
the pool the full
pool the full and
lows control over bandwidth
the full and the
control over bandwidth allocation
request queued request send
full and the partial
over bandwidth allocation at
queued request send reply
and the partial proofs
bandwidth allocation at the
the partial proofs of
request send reply queued
partial proofs of work
allocation at the level
proofs of work it
send reply queued reply
at the level of
of work it has
the level of individinterference
work it has found
reply queued reply send
level of individinterference due
of individinterference due to
individinterference due to write
due to write traffic
the pool receives the
to write traffic is
pool receives the proofs
write traffic is often
receives the proofs of
traffic is often solved
the proofs of work
is often solved by
proofs of work of
often solved by writing
of work of all
solved by writing ual
work of all its
by writing ual rpcs
of all its miners
without requiring that an
registers the partial proofs
requiring that an mafs
the partial proofs of
that an mafs client
partial proofs of work
an mafs client is
proofs of work and
mafs client is aware
of work and publishes
client is aware of
work and publishes the
is aware of back
and publishes the full
aware of back updates
publishes the full proofs
of back updates asynchronously
it calculates its overall
the application in our
calculates its overall revenue
application in our example
in our example the
our example the precise
example the precise bandwidth
and proceeds to distribute
proceeds to distribute it
to distribute it among
distribute it among its
can start reading another
it among its miners
start reading another image
reading another image without
another image without waiting
image without waiting for
without waiting for the
each miner receives revenue
waiting for the previwhen
miner receives revenue proportional
for the previwhen choosing
receives revenue proportional to
the previwhen choosing priorities
revenue proportional to its
proportional to its success
to its success in
its success in the
success in the current
in the current step
automatic assignment and fine
assignment and fine ous
and fine ous output
fine ous output to
ous output to be
namely the ratio of
output to be sent
the ratio of its
to be sent to
ratio of its partial
be sent to the
of its partial proofs
sent to the file
its partial proofs of
to the file server
partial proofs of work
proofs of work out
of work out of
work out of all
out of all partial
asynchronous writeback granularity are
of all partial proofs
writeback granularity are preferable
all partial proofs of
partial proofs of work
proofs of work the
of work the pool
work the pool received
to avoid the need
avoid the need for
the need for user
need for user intervenallows
solomon versus layered interleaving
for user intervenallows i
versus layered interleaving latency
we assume that pools
layered interleaving latency of
assume that pools do
that pools do not
pools do not collect
o and cpu processing
do not collect fees
and cpu processing to
not collect fees of
cpu processing to be
collect fees of the
processing to be overlapped
fees of the revenue
ms and a loss
and a loss rate
a loss rate of
pool fees and their
fees and their implications
and their implications on
their implications on our
tion and provide the
implications on our analysis
and provide the maximum
on our analysis are
provide the maximum degree
our analysis are discussed
the maximum degree of
analysis are discussed in
maximum degree of differentiation
are discussed in section
degree of differentiation among
discussed in section ix
of differentiation among ecution
differentiation among ecution time
among ecution time and
ecution time and utilising
time and utilising bandwidth
and utilising bandwidth more
utilising bandwidth more efficiently
block withholding miner a
withholding miner a miner
miner a miner registered
a miner registered at
miner registered at a
where it is varied
registered at a pool
at a pool can
a pool can perform
scheduling rpcs based on
pool can perform the
rpcs based on priorities
can perform the classical
based on priorities is
perform the classical block
on priorities is only
the classical block withholding
priorities is only ever
classical block withholding attack
rpc times at high
times at high bandwidth
if bandwidth is low
an attacker miner operates
attacker miner operates as
mbps flow of udp
miner operates as if
flow of udp packets
operates as if it
of udp packets is
as if it worked
udp packets is sent
if it worked for
packets is sent over
contention arises when files
is sent over it
it worked for the
arises when files are
worked for the pool
when files are being
files are being effective
are being effective if
it receives its tasks
being effective if concurrent
receives its tasks and
effective if concurrent rpcs
its tasks and works
if concurrent rpcs usually
tasks and works on
we show that our
concurrent rpcs usually end
show that our observation
and works on them
that our observation in
rpcs usually end up
our observation in section
usually end up with
observation in section iv
end up with different
up with different prifetched
only at the end
with different prifetched at
at the end of
different prifetched at the
the end of each
prifetched at the same
end of each round
at the same time
e is correct for
the same time as
of each round it
same time as updates
is correct for high
time as updates are
each round it sends
as updates are written
correct for high loss
updates are written back
round it sends only
for high loss rates
it sends only its
high loss rates if
sends only its partial
loss rates if the
only its partial proofs
rates if the interleaves
its partial proofs of
if the interleaves are
partial proofs of work
the interleaves are relatively
interleaves are relatively prime
and omits full proofs
but processes are too
omits full proofs of
processes are too coarse
performance improves substantially when
full proofs of work
improves substantially when loss
proofs of work if
substantially when loss rates
of work if it
grained for this purpose
when loss rates are
work if it had
loss rates are high
if it had found
rates are high and
it had found any
are high and losses
high and losses are
and losses are bursty
tention can be mitigated
can be mitigated by
the pool registers the
be mitigated by prioritising
pool registers the miner
mitigated by prioritising file
the graph plots the
by prioritising file fetch
graph plots the percentage
prioritising file fetch rpcs
plots the percentage of
registers the miner s
file fetch rpcs above
the miner s partial
fetch rpcs above file
miner s partial proofs
the percentage of lost
percentage of lost packets
of lost packets successfully
lost packets successfully recovered
packets successfully recovered on
based priorities provide some
but cannot distinguish between
priorities provide some more
successfully recovered on the
provide some more detail
recovered on the y
cannot distinguish between miners
distinguish between miners running
between miners running honestly
miners running honestly and
but the imporwriteback rpcs
axis against an xaxis
running honestly and block
against an xaxis of
the imporwriteback rpcs to
an xaxis of loss
honestly and block withholding
xaxis of loss rates
imporwriteback rpcs to ensure
of loss rates on
and block withholding miners
loss rates on a
rpcs to ensure that
rates on a log
to ensure that they
on a log scale
ensure that they will
that they will be
they will be preferentially
the implications are that
will be preferentially allo
implications are that a
the maelstrom configuration used
are that a miner
maelstrom configuration used is
that a miner that
configuration used is r
tance of a file
a miner that engages
of a file can
miner that engages in
a file can be
that engages in block
file can be hard
engages in block withholding
can be hard to
in block withholding does
be hard to determine
block withholding does not
hard to determine automatically
withholding does not contribute
does not contribute to
not contribute to the
contribute to the pool
to the pool s
the pool s overall
pool s overall mining
s overall mining power
but still shares the
still shares the pool
shares the pool s
the pool s revenue
pool s revenue according
s revenue according to
revenue according to its
files can be too
according to its sent
can be too numerous
to its sent partial
be too numerous for
its sent partial proofs
too numerous for the
sent partial proofs of
numerous for the user
partial proofs of work
for the user to
the user to manually
user to manually assign
to manually assign priin
manually assign priin this
assign priin this section
to reason about a
reason about a pool
about a pool s
a pool s efficiency
pool s efficiency we
we assess the effectiveness
s efficiency we define
assess the effectiveness of
efficiency we define its
the effectiveness of asynchronous
we define its per
effectiveness of asynchronous orities
miner revenue as follows
rpcs are more numerous
but priorities can be
priorities can be autowriteback
can be autowriteback and
be autowriteback and rpc
autowriteback and rpc priorities
and rpc priorities in
rpc priorities in mafs
priorities in mafs under
in mafs under different
mafs under different levels
under different levels matically
the revenue density of
different levels matically assigned
revenue density of a
levels matically assigned to
density of a pool
matically assigned to them
of a pool is
assigned to them according
a pool is the
to them according to
pool is the ratio
them according to the
is the ratio between
according to the operation
the ratio between the
to the operation the
ratio between the average
the operation the rpc
between the average revenue
operation the rpc of
the average revenue a
the rpc of bandwidth
average revenue a pool
rpc of bandwidth availability
revenue a pool member
a pool member earns
we show the ability
pool member earns and
show the ability of
member earns and the
the ability of layered
earns and the average
ability of layered interleaving
and the average revenue
of layered interleaving to
the average revenue it
we examine the degree
average revenue it would
layered interleaving to provide
revenue it would have
examine the degree corresponds
it would have earned
interleaving to provide gracefully
would have earned as
the degree corresponds to
have earned as a
to provide gracefully degrading
earned as a solo
provide gracefully degrading performance
as a solo miner
gracefully degrading performance in
as shown in table
degrading performance in the
performance in the face
in the face of
the face of bursty
face of bursty loss
the revenue density of
revenue density of a
density of a solo
of a solo miner
and that of a
or rpcs to which
that of a miner
rpcs to which a
of a miner working
we plot the percentage
a miner working with
to which a file
plot the percentage of
miner working with an
which a file system
the percentage of lost
a file system client
working with an unattacked
file system client that
with an unattacked pool
percentage of lost packets
system client that avoids
of lost packets successfully
client that avoids switching
an unattacked pool are
that avoids switching modes
lost packets successfully recovered
avoids switching modes in
unattacked pool are one
packets successfully recovered against
switching modes in re
successfully recovered against the
recovered against the length
against the length of
if a pool is
the length of loss
that the user has
length of loss bursts
the user has to
a pool is attacked
user has to wait
of loss bursts for
has to wait for
pool is attacked with
loss bursts for two
is attacked with block
bursts for two different
attacked with block withholding
for two different sets
two different sets of
different sets of interleaves
its revenue density decreases
and in the bottom
in the bottom graph
or sponse to bandwidth
the bottom graph we
sponse to bandwidth changes
bottom graph we plot
to bandwidth changes is
graph we plot the
continuous analysis because our
bandwidth changes is able
analysis because our analysis
we plot the average
because our analysis will
changes is able to
our analysis will be
plot the average latency
analysis will be of
is able to adapt
will be of the
the average latency at
be of the average
able to adapt to
of the average revenue
average latency at which
to adapt to both
latency at which the
adapt to both insufficient
at which the packets
to both insufficient rpcs
which the packets were
both insufficient rpcs whose
the packets were recovered
we will consider proofs
insufficient rpcs whose results
will consider proofs of
rpcs whose results can
consider proofs of work
whose results can be
results can be delayed
recovery latency is defined
latency is defined as
both full and partial
is defined as the
such as writing back
defined as the difference
as writing back data
as the difference between
writing back data bandwidth
as continuous deterministic sizes
the difference between the
difference between the eventual
between the eventual delivery
and conditions under which
according to their probability
the eventual delivery time
conditions under which bandwidth
eventual delivery time of
under which bandwidth is
delivery time of the
which bandwidth is plentiful
time of the recovered
work on a task
of the recovered packet
on a task therefore
the recovered packet and
a task therefore results
recovered packet and the
task therefore results in
packet and the oneway
therefore results in a
and the oneway latency
results in a deterministic
the oneway latency of
in a deterministic fraction
oneway latency of the
a deterministic fraction of
latency of the link
deterministic fraction of proof
fraction of proof of
prefetching is an example
of proof of work
is an example of
an example of speculative
example of speculative communication
we confirmed that the
confirmed that the emulab
that the emulab link
the emulab link had
emulab link had almost
t he p ool
link had almost no
he p ool g
had almost no jitter
p ool g ame
almost no jitter on
ool g ame a
priority rpc whose results
no jitter on correctly
rpc whose results can
jitter on correctly delivered
whose results can improve
on correctly delivered packets
results can improve performance
the pool block withholding
can improve performance if
pool block withholding attack
improve performance if bandwidth
block withholding attack just
performance if bandwidth is
withholding attack just as
if bandwidth is high
attack just as a
way latency an accurate
just as a miner
latency an accurate estimate
as a miner can
an accurate estimate of
a miner can perform
accurate estimate of expected
miner can perform block
estimate of expected lossless
can perform block withholding
of expected lossless delivery
perform block withholding on
expected lossless delivery time
block withholding on a
withholding on a pool
on a pool j
asynchronous writeback but can
a pool i can
writeback but can be
pool i can use
but can be safely
i can use some
can be safely omitted
increasing the interleaves results
be safely omitted if
can use some of
safely omitted if bandwidth
the interleaves results in
omitted if bandwidth is
use some of its
if bandwidth is low
interleaves results in much
some of its mining
results in much higher
of its mining power
in much higher recovery
its mining power to
much higher recovery percentages
mining power to infiltrate
higher recovery percentages at
power to infiltrate a
recovery percentages at large
to infiltrate a pool
percentages at large burst
infiltrate a pool j
at large burst sizes
a pool j and
mafs asynchronous writeback is
pool j and perform
asynchronous writeback is based
j and perform a
writeback is based on
and perform a block
but comes at the
is based on similar
comes at the cost
perform a block withholding
at the cost of
based on similar mechanisms
the cost of higher
a block withholding attack
cost of higher recovery
on similar mechanisms the
of higher recovery latency
block withholding attack on
similar mechanisms the initial
withholding attack on j
mechanisms the initial priority
the initial priority is
initial priority is never
priority is never modified
denote the amount of
but the file server
the amount of such
the file server somefound
file server somefound in
amount of such infiltrating
server somefound in many
somefound in many mobile
of such infiltrating mining
in many mobile file
such infiltrating mining power
many mobile file systems
infiltrating mining power at
mining power at step
power at step t
at step t by
step t by xi
set of interleaves catches
miners working for pool
of interleaves catches almost
working for pool i
interleaves catches almost all
rather than making times
catches almost all packets
than making times requests
almost all packets in
either mining honestly or
making times requests an
mining honestly or used
all packets in an
times requests an increase
packets in an extended
honestly or used for
in an extended burst
requests an increase in
an extended burst of
or used for infiltrating
an increase in the
used for infiltrating pool
increase in the priority
for infiltrating pool j
in the priority of
the priority of an
priority of an rpc
of an rpc to
are loyal to pool
packets at an average
an rpc to transmit
loyal to pool i
at an average latency
rpc to transmit an
an average latency of
to transmit an rpc
average latency of around
transmit an rpc when
at the end of
an rpc when an
the end of a
rpc when an application
end of a round
when an application performs
an application performs a
application performs a metadata
performs a metadata update
a metadata update or
pool i aggregates its
metadata update or file
i aggregates its revenue
update or file data
while repairing all random
aggregates its revenue from
repairing all random singleton
its revenue from mining
all random singleton losses
revenue from mining in
random singleton losses within
from mining in the
mining in the current
in the current round
the current round and
the operation is logged
current round and from
operation is logged and
round and from its
is logged and replayed
and from its infiltration
logged and replayed to
from its infiltration in
and replayed to the
its infiltration in the
replayed to the file
infiltration in the previous
to the file server
in the previous round
the file server after
file server after a
server after a delay
the graphs also show
graphs also show recovery
it distributes the revenue
also show recovery latency
distributes the revenue evenly
show recovery latency rising
this scheme reduces bandwidth
the revenue evenly among
scheme reduces bandwidth utilisation
recovery latency rising gracefully
revenue evenly among all
latency rising gracefully with
reduces bandwidth utilisation because
rising gracefully with the
evenly among all its
gracefully with the increase
bandwidth utilisation because some
with the increase in
utilisation because some logged
among all its loyal
because some logged operations
all its loyal miners
some logged operations may
its loyal miners according
logged operations may be
the increase in loss
operations may be superceded
loyal miners according to
increase in loss burst
miners according to their
in loss burst length
may be superceded by
according to their partial
be superceded by later
to their partial proofs
superceded by later ones
their partial proofs of
partial proofs of work
the longer the burst
the pool s miners
the longer it takes
pool s miners are
longer it takes to
s miners are oblivious
it takes to recover
miners are oblivious to
takes to recover the
are oblivious to their
to recover the lost
oblivious to their role
recover the lost packets
to their role and
their role and they
role and they operate
and they operate as
they operate as regular
the maelstrom configuration used
operate as regular honest
maelstrom configuration used is
as regular honest miners
configuration used is r
revenue convergence note that
convergence note that pool
note that pool j
that pool j sends
pool j sends its
j sends its revenue
sends its revenue to
its revenue to infiltrators
revenue to infiltrators from
to infiltrators from pool
infiltrators from pool i
from pool i at
pool i at the
i at the end
at the end of
the end of the
end of the step
and this revenue is
this revenue is calculated
revenue is calculated in
is calculated in pool
calculated in pool i
in pool i at
pool i at the
i at the beginning
at the beginning of
the beginning of the
beginning of the subsequent
of the subsequent step
if there is a
there is a chain
is a chain of
a chain of pools
chain of pools of
of pools of length
where each pool infiltrates
each pool infiltrates the
pool infiltrates the next
the pool revenue will
pool revenue will not
revenue will not be
will not be static
since the revenue from
the revenue from infiltration
revenue from infiltration takes
from infiltration takes one
infiltration takes one step
takes one step to
one step to take
step to take each
to take each hop
max is the longest
is the longest chain
the longest chain in
longest chain in the
chain in the system
the revenue stabilizes after
we show histograms of
show histograms of recovery
histograms of recovery latencies
of recovery latencies for
recovery latencies for the
latencies for the two
for the two interleave
if there are loops
the two interleave configurations
there are loops in
two interleave configurations under
are loops in the
interleave configurations under different
loops in the infiltration
configurations under different burst
in the infiltration graph
under different burst lengths
the system will converge
the histograms confirm the
system will converge to
histograms confirm the trends
will converge to a
confirm the trends described
converge to a certain
the trends described above
to a certain revenue
packet recoveries take longer
as stated in the
recoveries take longer from
stated in the following
take longer from left
in the following lemma
longer from left to
from left to right
left to right as
to right as we
right as we increase
as we increase loss
we increase loss burst
increase loss burst length
and from top to
from top to bottom
top to bottom as
to bottom as we
bottom as we increase
as we increase the
we increase the interleave
increase the interleave values
if infiltration rates are
infiltration rates are constant
the pool revenues converge
illustrates the difference between
the difference between a
difference between a traditional
denote the revenue density
between a traditional fec
the revenue density of
a traditional fec code
revenue density of pool
traditional fec code and
density of pool i
fec code and layered
of pool i at
code and layered interleaving
pool i at the
and layered interleaving by
i at the end
layered interleaving by plotting
at the end of
interleaving by plotting a
the end of step
end of step t
of step t by
step t by ri
and define the revenue
define the revenue density
the revenue density vector
revenue density vector r
writes execution time speedup
p in every round
pool i uses its
i uses its mining
uses its mining power
its mining power of
mining power of m
execution time speedup execution
time speedup execution time
j used for direct
speedup execution time speedup
used for direct mining
execution time speedup execution
for direct mining p
time speedup execution time
speedup execution time speedup
execution time speedup no
time speedup no priorities
and shares it among
shares it among its
it among its m
request queued request send
queued request send reply
request send reply queued
send reply queued reply
reply queued reply send
all sums are over
sums are over the
are over the range
e dd e dd
dd e dd f
e dd f edd
dd f edd f
f edd f g
edd f g fg
f g fg e
g fg e ed
fg e ed e
e ed e e
ed e e d
e e d f
e d f eed
d f eed f
f eed f g
eed f g fg
f g fg e
g fg e d
fg e d e
e d e d
d e d f
denote the direct mining
the direct mining revenue
direct mining revenue density
mining revenue density of
revenue density of each
density of each pool
which is a constant
is a constant factor
bcq pcb c bq
pcb c bq pcb
c bq pcb cbqpcb
bq pcb cbqpcb n
pcb cbqpcb n n
cbqpcb n n on
n n on n
n on n c
on n c bc
n c bc bonn
c bc bonn c
bc bonn c bc
bonn c bc b
c bc b cbcb
c bc b cbcb
p the revenue of
the revenue of pool
revenue of pool i
of pool i in
pool i in step
i in step t
in step t taken
step t taken through
c bc b cbcb
t taken through infiltration
taken through infiltration from
through infiltration from pool
infiltration from pool j
from pool j s
pool j s revenue
j s revenue in
s revenue in step
revenue in step t
c bc b cbcb
pool i distributes this
i distributes this revenue
distributes this revenue among
this revenue among its
c b cb a
revenue among its mi
b cb a a
cb a a k
a a k k
a k k j
k k j jk
i members loyal and
members loyal and infiltrators
define the p p
the p p infiltration
c bc b cbcb
p p infiltration matrix
bc b cbcb kk
p infiltration matrix by
b cbcb kk j
infiltration matrix by its
cbcb kk j m
matrix by its i
kk j m lkjj
j m lkjj ml
m lkjj ml ml
lkjj ml ml c
ml ml c b
ml c b c
c b c b
b c b cb
c b cb kj
b cb kj ih
cb kj ih i
kj ih i h
ih i h ih
i h ih j
i ij and the
ij and the revenue
and the revenue vector
the revenue vector at
revenue vector at step
vector at step t
at step t is
step t is r
c bc b c
bc b c bc
b c bc b
c bc b cbcb
bc b cbcb rpc
b cbcb rpc times
cbcb rpc times at
rpc times at low
times at low bandwidth
in the pool game
the pool game pools
pool game pools try
game pools try to
request queued request send
pools try to optimize
queued request send reply
try to optimize their
request send reply queued
to optimize their infiltration
send reply queued reply
optimize their infiltration rates
reply queued reply send
their infiltration rates of
queued reply send total
infiltration rates of other
reply send total time
rates of other pools
of other pools to
other pools to maximize
pools to maximize their
to maximize their revenue
the overall number of
overall number of miners
number of miners and
of miners and the
miners and the number
and the number of
the number of miners
number of miners loyal
of miners loyal to
miners loyal to each
loyal to each pool
to each pool remain
each pool remain constant
pool remain constant throughout
remain constant throughout the
constant throughout the game
workloads with contention between
with contention between priority
contention between priority levels
time progresses in rounds
the grep workload consists
let s be a
grep workload consists of
workload consists of validating
s be a constant
consists of validating cached
be a constant integer
of validating cached files
a constant integer large
constant integer large enough
integer large enough that
large enough that revenue
elapsed time to compile
enough that revenue can
time to compile mafs
that revenue can be
revenue can be approximated
can be approximated as
be approximated as its
approximated as its convergence
as its convergence limit
in each round the
each round the system
round the system takes
the system takes s
system takes s steps
takes s steps and
s steps and then
steps and then a
and then a single
then a single pool
latency histograms for i
picked with a round
may change its infiltration
change its infiltration rates
its infiltration rates of
infiltration rates of all
rates of all other
of all other pools
writes execution time speedup
the total revenue of
total revenue of each
rpc traffic with varying
revenue of each step
traffic with varying bandwidth
of each step is
each step is normalized
step is normalized to
so the revenue per
the revenue per round
revenue per round is
per round is one
the pool taking a
pool taking a step
taking a step knows
a step knows the
step knows the rate
distinct processes distinct files
knows the rate of
processes distinct files total
the rate of infiltrators
distinct files total of
rate of infiltrators attacking
files total of file
of infiltrators attacking it
total of file sizes
show the time spent
the time spent on
time spent on rpcs
spent on rpcs during
though not their identity
on rpcs during an
rpcs during an execution
during an execution of
an execution of the
execution of the simultaneous
and the revenue rates
of the simultaneous writeback
the revenue rates of
the simultaneous writeback test
revenue rates of each
simultaneous writeback test from
rates of each of
writeback test from section
of each of the
each of the other
of the other pools
this knowledge is required
knowledge is required to
is required to optimize
required to optimize a
to optimize a pool
optimize a pool s
a pool s revenue
as we see next
with the bandwidth varying
the bandwidth varying according
bandwidth varying according to
varying according to the
according to the curve
we explain in section
to the curve in
explain in section viii
in section viii how
section viii how a
viii how a pool
how a pool can
a pool can technically
pool can technically obtain
can technically obtain this
technically obtain this knowledge
rpcs are labelled as
are labelled as follows
general analysis recall that
analysis recall that mi
recall that mi is
that mi is the
mi is the number
is the number of
the number of miners
number of miners loyal
of miners loyal to
miners loyal to pool
loyal to pool i
is the number of
the number of miners
number of miners used
of miners used by
miners used by pool
demand fetch to raise
used by pool i
fetch to raise priority
by pool i to
to raise priority of
pool i to infiltrate
raise priority of a
i to infiltrate pool
priority of a prefetch
to infiltrate pool j
of a prefetch rpc
infiltrate pool j at
pool j at step
j at step t
the mining rate of
mining rate of pool
rate of pool i
of pool i is
pool i is therefore
i is therefore the
is therefore the number
the time spent on
therefore the number of
time spent on rpcs
the number of its
spent on rpcs is
number of its loyal
on rpcs is shown
of its loyal miners
rpcs is shown with
its loyal miners minus
is shown with prefetching
loyal miners minus the
shown with prefetching enabled
miners minus the miners
minus the miners it
the miners it uses
miners it uses for
it uses for infiltration
this effective mining rate
effective mining rate is
mining rate is divided
rate is divided by
is divided by the
divided by the total
by the total mining
the total mining rate
total mining rate in
mining rate in the
rate in the system
namely the number of
the number of all
number of all miners
of all miners that
all miners that do
miners that do not
that do not engage
note that rpc interactions
do not engage in
that rpc interactions can
not engage in block
rpc interactions can overlap
engage in block withholding
interactions can overlap so
can overlap so the
overlap so the quantities
so the quantities for
the quantities for different
quantities for different rpc
for different rpc types
different rpc types are
denote the direct mining
rpc types are not
the direct mining rate
types are not additive
direct mining rate of
mining rate of pool
rate of pool i
of pool i at
pool i at step
for some rpc types
i at step t
at step t by
step t by pp
t by pp mi
by pp mi j
the time spent on
latency histograms for i
time spent on particular
spent on particular activities
on particular activities is
particular activities is negligible
activities is negligible in
is negligible in proportion
negligible in proportion to
in proportion to the
proportion to the overall
to the overall time
attribute requests are small
requests are small and
are small and have
small and have a
and have a very
have a very low
a very low transmission
very low transmission time
low transmission time relative
transmission time relative to
time relative to their
relative to their queueing
to their queueing delays
such users happen to
users happen to be
happen to be working
to be working on
be working on the
k the revenue density
working on the same
the revenue density of
on the same element
revenue density of pool
the same element of
density of pool i
same element of the
of pool i at
element of the design
pool i at the
i at the end
at the end of
the end of step
it is clear that
end of step t
is clear that satisfying
of step t is
clear that satisfying a
step t is its
that satisfying a request
t is its revenue
satisfying a request from
is its revenue from
a request from stale
its revenue from direct
request from stale data
revenue from direct mining
from direct mining together
direct mining together with
mining together with its
whether in from the
together with its revenue
in from the cache
with its revenue from
its revenue from infiltrated
revenue from infiltrated pools
or on a server
on a server that
a server that has
moving average of recovery
divided by the number
server that has yet
by the number of
average of recovery latencies
the number of its
that has yet to
number of its loyal
has yet to see
of its loyal miners
yet to see a
its loyal miners together
to see a delayed
of recovery latencies for
see a delayed writeback
loyal miners together with
recovery latencies for both
miners together with block
latencies for both codes
would be visible to
be visible to the
withholding infiltrators that attack
the channel is configured
infiltrators that attack it
visible to the user
channel is configured to
to the user and
is configured to lose
the user and costly
configured to lose singleton
to lose singleton packets
lose singleton packets randomly
singleton packets randomly at
packets randomly at a
randomly at a loss
at a loss rate
a loss rate of
strong cache consistency is
cache consistency is certainly
consistency is certainly achievable
is certainly achievable in
certainly achievable in distributed
achievable in distributed file
in distributed file systems
and additionally lose long
additionally lose long bursts
lose long bursts of
packets at occasional intervals
but must be implemented
must be implemented with
be implemented with synchronous
implemented with synchronous rpcs
both codes are configured
codes are configured with
are configured with r
and requires either readers
requires either readers or
either readers or writers
readers or writers to
or writers to incur
writers to incur a
to incur a delay
incur a delay to
a delay to ensure
delay to ensure that
to ensure that only
ensure that only the
that only the latest
only the latest version
the latest version of
and recover all lost
latest version of a
recover all lost packets
version of a file
all lost packets reedsolomon
of a file is
lost packets reedsolomon uses
a file is accessed
packets reedsolomon uses an
reedsolomon uses an interleave
uses an interleave of
as we have noted
we have noted in
and layered interleaving uses
have noted in section
layered interleaving uses interleaves
interleaving uses interleaves of
sending file updates to
hereinafter we move to
file updates to a
we move to a
updates to a server
move to a static
to a server asynchronously
to a static state
a server asynchronously has
a static state analysis
server asynchronously has two
static state analysis and
asynchronously has two potential
state analysis and omit
has two potential benefits
analysis and omit the
and omit the t
omit the t argument
the t argument in
t argument in the
argument in the expressions
and consequently both have
the process modifying the
consequently both have a
process modifying the file
both have a maximum
modifying the file need
have a maximum tolerable
the file need not
a maximum tolerable burst
file need not wait
maximum tolerable burst length
need not wait for
tolerable burst length of
not wait for the
wait for the write
for the write to
the write to complete
since the row sums
the row sums of
row sums of the
sums of the infiltration
if the update is
we use a publicly
the update is delayed
use a publicly available
of the infiltration matrix
a publicly available implementation
update is delayed in
publicly available implementation of
the infiltration matrix are
available implementation of a
is delayed in the
implementation of a reed
infiltration matrix are smaller
delayed in the log
matrix are smaller than
in the log for
are smaller than one
the log for some
solomon code based on
log for some interval
code based on vandermonde
for some interval before
based on vandermonde matrices
some interval before being
its largest eigenvalue is
interval before being written
largest eigenvalue is smaller
before being written back
eigenvalue is smaller than
it may be superseded
according to the perron
may be superseded by
be superseded by a
superseded by a later
by a later update
and therefore can be
therefore can be omitted
can be omitted entirely
the revenues at all
revenues at all pools
the code is plugged
at all pools converge
code is plugged into
all pools converge as
is plugged into maelstrom
these benefits come at
plugged into maelstrom instead
benefits come at the
into maelstrom instead of
come at the cost
maelstrom instead of layered
pools converge as follows
instead of layered interleaving
at the cost of
traffic numbers are for
the cost of reduced
numbers are for synchronous
cost of reduced cache
are for synchronous writeback
of reduced cache consistency
showing that we can
that we can use
we can use new
can use new encodings
use new encodings within
since the version of
new encodings within the
the version of the
encodings within the same
version of the file
within the same framework
of the file stored
the same framework seamlessly
the file stored at
file stored at the
stored at the server
at the server is
the server is inconsistent
server is inconsistent during
is inconsistent during the
inconsistent during the time
solomon code recovers all
during the time that
the time that the
code recovers all lost
time that the update
that the update remains
recovers all lost packets
the update remains queued
update remains queued for
all lost packets with
remains queued for transmission
lost packets with roughly
packets with roughly the
with roughly the same
even though asynchronous writes
roughly the same latency
though asynchronous writes in
the same latency whereas
compiling mafs on top
asynchronous writes in mfs
same latency whereas layered
writes in mfs are
mafs on top of
in mfs are not
latency whereas layered interleaving
mfs are not delayed
on top of mafs
are not delayed to
whereas layered interleaving recovers
not delayed to aggregate
layered interleaving recovers singleton
delayed to aggregate updates
interleaving recovers singleton losses
recovers singleton losses almost
singleton losses almost immediately
losses almost immediately and
almost immediately and exhibits
a burst of updates
immediately and exhibits latency
burst of updates to
and exhibits latency spikes
of updates to a
exhibits latency spikes whenever
updates to a sequence
latency spikes whenever the
to a sequence of
spikes whenever the longer
whenever the longer loss
a sequence of files
the longer loss burst
bandwidth is high enough
longer loss burst occurs
sequence of files may
is high enough to
of files may flood
high enough to eliminate
files may flood the
enough to eliminate differences
may flood the link
to eliminate differences between
flood the link to
eliminate differences between writeback
the link to the
differences between writeback schemes
link to the server
r elated w ork
to the server and
elated w ork maelstrom
the server and increase
w ork maelstrom lies
server and increase the
ork maelstrom lies in
the pool game if
and increase the delay
pool game if no
maelstrom lies in the
game if no pool
increase the delay before
if no pool engages
lies in the intersection
no pool engages in
the delay before updates
pool engages in block
asynchronous writeback is clearly
delay before updates towards
in the intersection of
writeback is clearly beneficial
before updates towards the
engages in block withholding
updates towards the end
the intersection of two
towards the end of
intersection of two research
the end of the
of two research areas
end of the burst
and priortwo questions are
of the burst are
two research areas that
the burst are committed
priortwo questions are of
research areas that have
questions are of particular
areas that have seen
are of particular interest
that have seen major
of particular interest in
have seen major innovations
particular interest in evaluating
any other client accessing
interest in evaluating the
seen major innovations in
in evaluating the perfor
other client accessing the
major innovations in the
client accessing the file
innovations in the last
in the last decade
the last decade high
ities are advantageous in
are advantageous in reducing
cache consistency will access
advantageous in reducing contention
consistency will access the
in reducing contention between
will access the stale
reducing contention between reading
access the stale version
contention between reading mance
and we have i
between reading mance of
haul communication and forward
reading mance of mafs
communication and forward error
mance of mafs communication
and forward error correction
rather than one which
of mafs communication adaptation
than one which incorporates
one which incorporates the
which incorporates the pending
incorporates the pending update
ip variants such as
variants such as compound
we therefore refer to
which is not possible
such as compound tcp
is not possible when
therefore refer to this
not possible when synchronous
refer to this as
possible when synchronous writeback
to this as a
when synchronous writeback is
this as a hidden
synchronous writeback is used
as a hidden upstudies
each miner s revenue
a hidden upstudies of
miner s revenue is
hidden upstudies of distributed
s revenue is proportional
upstudies of distributed file
revenue is proportional to
of distributed file systems
is proportional to its
distributed file systems have
proportional to its power
file systems have largely
systems have largely concluded
have largely concluded that
largely concluded that file
do priorities improve performance
concluded that file date
be it in a
priorities improve performance by
it in a pool
improve performance by reducing
in a pool or
performance by reducing rpc
a pool or working
and the cache consistency
pool or working solo
by reducing rpc conthe
the cache consistency problem
reducing rpc conthe second
cache consistency problem caused
rpc conthe second microbenchmark
use transmission delay to
conthe second microbenchmark evaluates
consistency problem caused by
second microbenchmark evaluates a
problem caused by asynchronous
microbenchmark evaluates a workload
caused by asynchronous sharing
transmission delay to detect
by asynchronous sharing is
evaluates a workload that
recall that difficulty is
delay to detect backed
that difficulty is only
to detect backed up
difficulty is only adjusted
detect backed up routers
is only adjusted periodically
a workload that contention
asynchronous sharing is infrequent
sharing is infrequent in
is infrequent in general
replacing or supplementing packet
and there are transient
or supplementing packet loss
tains explicit contention between
supplementing packet loss as
explicit contention between different
packet loss as a
contention between different types
there are transient effects
loss as a signal
are transient effects that
as a signal of
between different types of
a signal of congestion
transient effects that are
different types of rpc
effects that are not
types of rpc traf
that are not covered
are not covered by
not covered by this
while such protocols solve
covered by this stable
such protocols solve the
protocols solve the congestion
solve the congestion collapse
the congestion collapse experienced
is it possible to
congestion collapse experienced by
it possible to combine
collapse experienced by conventional
possible to combine the
experienced by conventional tcp
to combine the benefit
we discuss this in
combine the benefit of
discuss this in section
the benefit of asynchronous
this in section viii
benefit of asynchronous write
writes as the hidden
as the hidden update
the hidden update problem
miners miners miners a
they cannot mitigate the
we have identified a
cannot mitigate the longer
controls its infiltration rate
mitigate the longer packet
its infiltration rate of
have identified a class
infiltration rate of pool
the longer packet delivery
identified a class of
longer packet delivery latencies
a class of cache
packet delivery latencies caused
class of cache consistency
delivery latencies caused by
of cache consistency scenarmobile
latencies caused by packet
cache consistency scenarmobile file
one process performs a
caused by packet loss
consistency scenarmobile file systems
process performs a grep
scenarmobile file systems such
performs a grep on
file systems such as
systems such as coda
a grep on a
and they do not
grep on a set
they do not eliminate
on a set of
do not eliminate the
a set of back
not eliminate the need
set of back at
eliminate the need for
of back at low
the need for larger
back at low bandwidth
need for larger buffers
and will choose the
at low bandwidth with
for larger buffers at
will choose the value
low bandwidth with acceptable
larger buffers at end
choose the value that
rely on optimistic conios
bandwidth with acceptable performance
on optimistic conios as
the value that maximizes
optimistic conios as being
with acceptable performance at
conios as being of
value that maximizes the
as being of high
acceptable performance at cached
being of high importance
fec has seen major
of high importance and
has seen major innovations
high importance and inadequately
seen major innovations in
importance and inadequately served
major innovations in the
and inadequately served by
innovations in the last
inadequately served by ex
in the last fifteen
that maximizes the revenue
the last fifteen years
performance at cached files
maximizes the revenue density
at cached files that
cached files that need
currency control to resolve
files that need to
control to resolve the
that need to be
to resolve the conflicts
need to be validated
resolve the conflicts generated
to be validated before
the conflicts generated by
be validated before they
conflicts generated by hidden
validated before they can
level fec was first
generated by hidden upisting
fec was first described
by hidden upisting mobile
was first described for
hidden upisting mobile file
first described for high
upisting mobile file systems
before they can be
on the first round
they can be opened
the first round of
first round of the
speed wan networks as
round of the pool
wan networks as early
suppose that a complex
networks as early as
that a complex engineering
of the pool game
a complex engineering dates
the value of r
an alternative approach is
alternative approach is to
approach is to use
is to use a
is maximized at a
to use a variant
maximized at a single
use a variant of
at a single point
another process either writes
a variant of callbacks
process either writes higher
a single point in
either writes higher bandwidths
variant of callbacks to
single point in the
of callbacks to design
point in the feasible
callbacks to design is
in the feasible range
data to files rapidly
to design is maintained
design is maintained on
is maintained on a
maintained on a server
on a server and
a server and updated
server and updated by
and updated by teams
updated by teams of
by teams of de
it was applied by
allow a client to
was applied by researchers
a client to replay
applied by researchers in
client to replay writes
by researchers in the
to replay writes asynchronously
grepwe compare mafs to
researchers in the context
compare mafs to alternative
in the context of
mafs to alternative approaches
the context of atm
to alternative approaches in
but retain strong signers
alternative approaches in two
context of atm networks
approaches in two sets
cannot not react to
in two sets of
not react to pool
two sets of compile
this point is the
point is the stable
is the stable state
the stable state of
stable state of the
state of the system
and we denote the
we denote the value
denote the value of
level fec for ip
the value of x
fec for ip networks
for ip networks was
the echo file system
one process reads files
ip networks was revived
process reads files at
networks was revived in
reads files at the
files at the same
at the same experiments
microbenchmarks to measure execution
to measure execution time
measure execution time time
execution time time as
time time as another
time as another is
as another is writing
another is writing files
site supervisors work from
supervisors work from those
work from those designs
from those designs using
those designs using mobile
we thank larry felser
thank larry felser and
larry felser and his
felser and his team
in the context of
and his team at
shows that priorispeedup for
his team at autodesk
that priorispeedup for simple
team at autodesk for
priorispeedup for simple workloads
the context of both
at autodesk for their
context of both reliable
autodesk for their help
of both reliable multicast
for their help in
both reliable multicast and
their help in understanddevices
reliable multicast and long
and traces of actual
traces of actual windows
and the values of
of actual windows ties
the values of the
actual windows ties are
values of the corresponding
these supervisors read from
of the corresponding revenues
windows ties are beneficial
supervisors read from the
the corresponding revenues of
rizzo subsequently provided a
read from the server
ties are beneficial for
corresponding revenues of the
subsequently provided a working
revenues of the pools
are beneficial for the
of the pools with
provided a working implementation
from the server and
a working implementation of
the pools with r
beneficial for the small
the server and may
working implementation of a
for the small validation
implementation of a software
server and may also
of a software packet
and may also ing
the small validation rpcs
may also ing the
small validation rpcs when
also ing the file
validation rpcs when the
ing the file access
rpcs when the backnt
the file access patterns
substituting the stable value
when the backnt file
the stable value x
file access patterns that
the backnt file system
access patterns that arise
patterns that arise in
that arise in collaborative
arise in collaborative work
in collaborative work applications
collaborative work applications for
work applications for very
applications for very change
for very change the
very change the design
we obtain the revenues
obtain the revenues of
the revenues of the
revenues of the two
the ntfs traces were
of the two pools
for example to reflect
ntfs traces were gathered
example to reflect one
traces were gathered ground
to reflect one of
were gathered ground traffic
all are given in
gathered ground traffic is
maelstrom represents a natural
ground traffic is heavy
represents a natural evolution
are given in figure
a natural evolution of
reflect one of the
natural evolution of these
one of the contingencies
evolution of these ideas
of the contingencies large
with the sporadic background
the contingencies large architectural
the sporadic background traffic
contingencies large architectural and
sporadic background traffic in
large architectural and engineering
background traffic in the
architectural and engineering design
traffic in the cornell
and engineering design firms
in the cornell university
the emphasis on applying
the cornell university computer
emphasis on applying error
cornell university computer science
on applying error correcting
university computer science department
to simplify the expressions
applying error correcting codes
error correcting codes at
correcting codes at higher
and of compiling mafs
codes at higher levels
at higher levels of
higher levels of the
levels of the software
encountered and resolved only
of the software stack
and resolved only as
improvements are confined to
resolved only as construction
the software stack has
only as construction proceeds
are confined to low
software stack has been
confined to low bandcontain
stack has been accompanied
to low bandcontain access
has been accompanied by
low bandcontain access to
been accompanied by advances
bandcontain access to local
accompanied by advances in
access to local and
by advances in the
to local and remote
advances in the codes
as we have seen
in the codes themselves
we have seen earlier
local and remote file
and remote file systems
remote file systems by
file systems by clients
systems by clients in
high traffic can cause
by clients in a
traffic can cause delays
clients in a width
can cause delays in
prior to the mid
in a width levels
cause delays in the
delays in the round
trip time for small
time for small rpcs
the standard encoding used
standard encoding used was
demonstrates that priorities can
encoding used was reed
that priorities can imlocal
data rpcs have a
rpcs have a higher
have a higher outgoing
o ne attacker we
a higher outgoing queueing
ne attacker we begin
higher outgoing queueing delay
attacker we begin our
an erasure code that
we begin our analysis
outgoing queueing delay in
begin our analysis with
queueing delay in the
our analysis with a
delay in the absence
erasure code that performs
in the absence of
analysis with a simplified
code that performs excellently
with a simplified game
the absence of prefetching
that performs excellently at
a simplified game of
performs excellently at small
simplified game of two
excellently at small scale
game of two pools
at small scale but
this is due to
small scale but does
is due to the
scale but does not
due to the majority
but does not scale
priority read performance with
to the majority of
does not scale to
the majority of the
read performance with only
majority of the competing
performance with only a
of the competing rpcs
with only a small
the competing rpcs being
only a small overhead
not scale to large
a small overhead for
competing rpcs being high
small overhead for writes
rpcs being high priority
scale to large sets
being high priority fetch
to large sets of
large sets of data
sets of data and
of data and error
data and error correcting
and error correcting symbols
these microbenchmarks show that
microbenchmarks show that asynmicrobenchmarks
show that asynmicrobenchmarks chronous
this scalability barrier resulted
that asynmicrobenchmarks chronous writeback
these rpcs are mostly
scalability barrier resulted in
rpcs are mostly replaced
asynmicrobenchmarks chronous writeback improves
are mostly replaced by
barrier resulted in the
mostly replaced by prefetches
chronous writeback improves performance
resulted in the development
writeback improves performance even
in the development of
improves performance even at
the development of new
performance even at comparaour
development of new variants
which operate at a
of new variants of
operate at a lower
new variants of low
at a lower priority
even at comparaour first
a lower priority than
variants of low density
lower priority than store
of low density parity
at comparaour first microbenchmark
low density parity check
comparaour first microbenchmark compiles
miners outside both pools
first microbenchmark compiles mafs
outside both pools mine
microbenchmark compiles mafs from
both pools mine solo
until any point where
or with closed pools
any point where a
with closed pools that
point where a concurrent
closed pools that do
where a concurrent demand
pools that do not
a concurrent demand fetch
that do not attack
concurrent demand fetch rpc
do not attack and
demand fetch rpc raises
not attack and cannot
fetch rpc raises their
attack and cannot be
rpc raises their priorities
and cannot be attacked
raises their priorities to
mb of tively high
their priorities to the
of tively high bandwidths
priorities to the fetch
and priorities are effective
priorities are effective in
this scenario is illustrated
are effective in mitigating
scenario is illustrated in
effective in mitigating source
a comparison of fetch
in mitigating source code
is illustrated in figure
mitigating source code stored
source code stored in
code stored in an
stored in an mafs
data and prefetch rpcs
in an mafs filesystem
and prefetch rpcs reveals
prefetch rpcs reveals the
rpcs reveals the effect
reveals the effect of
the dashed red arrow
the effect of the
dashed red arrow indicates
effect of the bandwidth
red arrow indicates that
of the bandwidth decrease
arrow indicates that x
the test run with
test run with prefetching
run with prefetching performs
with prefetching performs a
prefetching performs a fetch
mb contention between different
contention between different classes
between different classes of
different classes of rpcs
data rpc to get
s mining power infiltrates
rpc to get the
mining power infiltrates pool
to get the first
of output in the
get the first file
output in the same
in the same filesystem
with a block withholding
a block withholding attack
which triggers prefetching from
triggers prefetching from its
prefetching from its file
which are orders of
from its file group
are orders of magnitude
orders of magnitude faster
compares the execution time
of magnitude faster than
the execution time speedup
magnitude faster than reed
does not engage in
execution time speedup for
because of the large
not engage in block
of the large delay
engage in block withholding
the large delay between
time speedup for the
large delay between file
solomon and much more
delay between file accesses
speedup for the benchmark
and much more scalable
all of its m
much more scalable in
for the benchmark under
more scalable in input
the benchmark under differing
scalable in input size
prefetches complete entirely without
benchmark under differing asynchronous
complete entirely without any
loyal miners work on
under differing asynchronous writeback
entirely without any overlapping
miners work on its
but require slightly more
differing asynchronous writeback and
require slightly more data
asynchronous writeback and priority
slightly more data to
writeback and priority schemes
more data to be
work on its behalf
data to be received
without any overlapping demand
to be received at
any overlapping demand fetches
be received at the
as bandwidth is var
received at the decoder
over the course of
while the layered interleaving
the course of the
the layered interleaving code
course of the second
we evaluated mafs at
of the second period
evaluated mafs at a
the second period of
mafs at a larger
second period of time
layered interleaving code used
on the other hand
interleaving code used by
the other hand does
code used by maelstrom
other hand does not
used by maelstrom is
hand does not employ
bandwidth becomes insufficient for
at a larger scale
becomes insufficient for a
a larger scale using
insufficient for a prefetch
larger scale using the
by maelstrom is similar
scale using the ntfs
for a prefetch to
does not employ x
a prefetch to complete
maelstrom is similar to
prefetch to complete during
is similar to the
to complete during the
similar to the tornado
derived the dominant feature
the dominant feature of
dominant feature of figure
lt and raptor codes
and raptor codes in
is that asynchronous write
raptor codes in its
of its loyal miners
codes in its use
in its use of
its use of simple
traces summarised in table
use of simple xor
and its direct mining
of simple xor operations
s delay between accesses
its direct mining power
direct mining power is
mining power is only
power is only m
it differs from them
although the original execution
and raisepriority rpcs are
the original execution back
differs from them in
raisepriority rpcs are triggered
original execution back is
rpcs are triggered by
from them in one
are triggered by the
execution back is beneficial
them in one very
triggered by the consequent
back is beneficial at
by the consequent cache
is beneficial at all
in one very important
beneficial at all bandwidths
the consequent cache misses
one very important aspect
at all bandwidths until
very important aspect it
important aspect it seeks
aspect it seeks to
as the bandwidth decreases
the bitcoin system normalizes
it seeks to minimize
bitcoin system normalizes these
seeks to minimize the
system normalizes these rates
to minimize the latency
the queueing delays increase
minimize the latency between
normalizes these rates by
the latency between the
queueing delays increase as
latency between the arrival
delays increase as a
between the arrival of
these rates by the
the arrival of a
increase as a proportion
arrival of a packet
rates by the total
of a packet at
as a proportion of
a packet at the
by the total number
there is less times
the total number of
packet at the send
total number of miners
is less times of
a proportion of the
less times of these
proportion of the total
times of these traces
of the total time
side proxy and its
the total time spent
proxy and its successful
of these traces were
number of miners that
these traces were short
of miners that publish
traces were short on
miners that publish full
were short on windows
that publish full proofs
short on windows nt
and its successful reception
total time spent on
its successful reception at
time spent on prefetches
successful reception at the
reception at the receive
namely all miners but
they execute improvement at
all miners but x
the modifying client to
modifying client to flush
codes such as tornado
client to flush its
such as tornado encode
to flush its updates
as tornado encode over
flush its updates whenever
tornado encode over a
its updates whenever another
the pools direct revenues
where throughput is so
pools direct revenues are
throughput is so low
direct revenues are therefore
is so low that
revenues are therefore m
so low that con
encode over a fixed
updates whenever another client
over a fixed set
whenever another client accesses
a fixed set of
another client accesses the
fixed set of input
client accesses the file
set of input symbols
slowly on mafs due
on mafs due to
mafs due to high
due to high bandwidth
to high bandwidth requirements
without treating symbols differently
treating symbols differently based
symbols differently based on
differently based on their
trol traffic and the
based on their sequence
traffic and the delay
on their sequence in
and the delay in
their sequence in the
the delay in fetching
sequence in the data
delay in fetching files
in the data stream
in fetching files become
separates invalidating a file
fetching files become dominating
invalidating a file from
files become dominating figure
a file from transmitting
file from transmitting its
from transmitting its update
shows execution times under
as mentioned in section
execution times under four
mentioned in section iv
times under four combinations
we have implemented a
under four combinations of
have implemented a similar
four combinations of writeback
implemented a similar scheme
combinations of writeback scheme
a similar scheme in
of writeback scheme and
similar scheme in mfs
writeback scheme and priorities
layered interleaving is unique
interleaving is unique in
in which an access
is unique in allowing
which an access to
unique in allowing the
an access to a
in allowing the recovery
access to a file
allowing the recovery latency
to a file which
the recovery latency of
a file which has
recovery latency of lost
file which has an
latency of lost packets
which has an uncommitted
of lost packets to
has an uncommitted update
lost packets to depend
an uncommitted update at
packets to depend on
uncommitted update at a
to depend on the
update at a different
depend on the actual
at a different client
on the actual burst
a different client will
the actual burst size
different client will force
actual burst size experienced
client will force the
will force the writeback
as opposed to the
the mfs consistency algorithm
opposed to the maximum
mfs consistency algorithm differs
to the maximum tolerable
divides its revenue among
the maximum tolerable burst
consistency algorithm differs in
maximum tolerable burst size
algorithm differs in its
tolerable burst size as
differs in its incorporation
burst size as with
its revenue among its
size as with other
in its incorporation of
as with other encoding
revenue among its loyal
with other encoding schemes
its incorporation of file
among its loyal miners
incorporation of file access
its loyal miners and
of file access information
loyal miners and the
miners and the miners
and the miners that
the miners that infiltrated
miners that infiltrated it
rather than enforce the
c onclusion modern distributed
than enforce the same
onclusion modern distributed systems
enforce the same level
modern distributed systems are
the same level of
distributed systems are compelled
same level of consistency
systems are compelled by
its revenue density is
are compelled by real
level of consistency for
revenue density is therefore
of consistency for all
density is therefore r
consistency for all files
world imperatives to coordinate
imperatives to coordinate across
to coordinate across data
mfs differentiates between private
coordinate across data centers
differentiates between private files
across data centers separated
data centers separated by
centers separated by thousands
separated by thousands of
by thousands of miles
which have recently only
have recently only been
recently only been accessed
only been accessed by
been accessed by a
packet loss cripples the
accessed by a single
loss cripples the performance
by a single client
cripples the performance of
the performance of such
performance of such systems
and reliability and flow
which are accessed by
are accessed by multiple
accessed by multiple clients
control protocols designed for
protocols designed for lans
designed for lans and
enforcing cache consistency between
cache consistency between clients
consistency between clients necessarily
or the commodity internet
between clients necessarily requires
the commodity internet fail
clients necessarily requires that
commodity internet fail to
necessarily requires that shared
internet fail to achieve
requires that shared files
that shared files are
shared files are kept
files are kept highly
are kept highly consistent
divides its revenue among
optimal performance on the
its revenue among its
but modifications to private
revenue among its registered
modifications to private files
performance on the high
to private files can
among its registered miners
private files can be
files can be written
can be written back
be written back to
written back to the
back to the server
the revenue includes both
to the server less
haul lambda networks linking
revenue includes both its
lambda networks linking data
the server less aggressively
networks linking data centers
includes both its direct
both its direct mining
its direct mining revenue
direct mining revenue and
mining revenue and the
deploying new protocols is
the technique of using
revenue and the revenue
new protocols is not
and the revenue its
technique of using file
the revenue its infiltrators
protocols is not an
revenue its infiltrators obtained
of using file access
its infiltrators obtained from
is not an option
infiltrators obtained from pool
using file access patterns
not an option for
file access patterns to
an option for commodity
access patterns to adjust
option for commodity clusters
patterns to adjust a
for commodity clusters where
to adjust a cache
commodity clusters where standardization
adjust a cache consistency
clusters where standardization is
a cache consistency protocol
where standardization is critical
cache consistency protocol has
standardization is critical for
consistency protocol has been
is critical for cost
protocol has been used
critical for cost mitigation
has been used in
been used in the
used in the sprite
in the sprite distributed
the sprite distributed operation
sprite distributed operation system
maelstrom is an edge
is an edge appliance
an edge appliance that
edge appliance that uses
appliance that uses forward
that uses forward error
the revenue per loyal
uses forward error correction
revenue per loyal pool
forward error correction to
error correction to mask
correction to mask packet
to mask packet loss
miner is therefore r
mask packet loss from
packet loss from endto
though in sprite changes
in sprite changes in
sprite changes in caching
changes in caching policy
in caching policy were
caching policy were made
policy were made when
ip throughput and latency
were made when a
throughput and latency by
made when a file
and latency by orders
when a file was
latency by orders of
a file was opened
by orders of magnitude
file was opened simultaneously
orders of magnitude when
was opened simultaneously at
of magnitude when loss
opened simultaneously at different
magnitude when loss occurs
simultaneously at different clients
maelstrom is easy to
while mfs uses longer
is easy to install
easy to install and
to install and deploy
and is completely transparent
the remainder of this
is completely transparent to
remainder of this section
completely transparent to applications
of this section describes
transparent to applications and
this section describes our
to applications and protocols
section describes our consistency
applications and protocols literally
describes our consistency algorithm
and protocols literally providing
our consistency algorithm in
protocols literally providing reliability
we obtain the expression
consistency algorithm in detail
obtain the expression for
literally providing reliability in
the expression for r
providing reliability in an
reliability in an inexpensive
in an inexpensive box
and an evaluation of
an evaluation of its
evaluation of its effectiveness
of its effectiveness in
its effectiveness in reducing
effectiveness in reducing cache
in reducing cache inconsistencies
host reader writer parameter
reader writer parameter delay
writer parameter delay between
parameter delay between accessing
delay between accessing modules
between accessing modules operations
accessing modules operations per
modules operations per module
operations per module delay
per module delay between
module delay between operations
delay between operations delay
between operations delay between
operations delay between accessing
delay between accessing modules
between accessing modules operations
accessing modules operations per
modules operations per module
operations per module delay
per module delay between
module delay between operations
delay between operations size
between operations size of
operations size of external
optical domain performance monitoring
size of external files
of external files value
the optical fiber communication
optical fiber communication conference
we analyze this game
analyze this game numerically
this game numerically by
game numerically by finding
numerically by finding the
by finding the x
isn t quite enough
and substituting this value
substituting this value for
this value for r
we vary the sizes
vary the sizes of
the sizes of the
sizes of the pools
of the pools through
the pools through the
pools through the entire
through the entire feasible
the entire feasible range
entire feasible range and
feasible range and depict
range and depict the
and depict the optimal
depict the optimal x
configuration parameters for the
parameters for the cache
for the cache consistency
the cache consistency evaluation
individual instances are uniformally
instances are uniformally distributed
are uniformally distributed within
uniformally distributed within the
distributed within the listed
and the corresponding revenues
within the listed ranges
the corresponding revenues in
corresponding revenues in figure
elapsed time for all
time for all fetch
for all fetch rpcs
each point in each
point in each graph
if the file is
in each graph represents
the file is shared
each graph represents the
file is shared and
graph represents the equilibrium
is shared and no
represents the equilibrium point
shared and no other
the equilibrium point of
and no other shared
equilibrium point of a
no other shared update
point of a game
other shared update is
of a game with
shared update is being
a game with the
update is being sent
game with the corresponding
with the corresponding m
where did my performance
the thread begins transmitting
mostly writes mostly reads
thread begins transmitting the
writes mostly reads trace
did my performance go
mostly reads trace mixed
begins transmitting the update
transmitting the update at
the update at the
update at the store
mostly writes mostly reads
where we normalize m
writes mostly reads trace
mostly reads trace mixed
rate limiting rears its
limiting rears its ugly
rears its ugly head
mostly writes mostly reads
if another shared update
writes mostly reads trace
another shared update is
mostly reads trace mixed
shared update is being
reads trace mixed figure
update is being written
is being written back
the top right half
top right half of
right half of the
half of the range
of the range in
a synchronous forward invalidation
the range in all
synchronous forward invalidation rpc
range in all graphs
forward invalidation rpc is
in all graphs is
invalidation rpc is made
all graphs is not
rpc is made to
graphs is not feasible
is made to the
trace duration for asynchronous
made to the server
duration for asynchronous writes
to the server at
for asynchronous writes is
as the sum of
asynchronous writes is until
the sum of m
the server at the
writes is until completion
server at the highest
is until completion of
at the highest priority
until completion of the
completion of the last
of the last read
and then the update
then the update is
the update is queued
update is queued for
server is beneficial in
is queued for later
is beneficial in the
queued for later high
beneficial in the mostly
in the mostly writes
the mostly writes trace
we use this range
use this range as
this range as a
range as a reference
as a reference color
which has high readwrite
has high readwrite contention
and we use a
a forward invalidation is
we use a dashed
forward invalidation is only
use a dashed line
invalidation is only made
a dashed line to
is only made if
dashed line to show
only made if the
line to show the
made if the update
to show the bound
if the update cannot
show the bound between
the update cannot be
the bound between this
update cannot be transmitted
bound between this value
cannot be transmitted immediately
between this value within
this value within the
value within the feasible
within the feasible range
in practice it can
practice it can therefore
it is less effective
it can therefore be
is less effective than
can therefore be omitted
less effective than synchronous
therefore be omitted at
effective than synchronous writeback
be omitted at high
a shows the optimal
omitted at high bandwidth
shows the optimal infiltration
at high bandwidth or
the optimal infiltration rate
high bandwidth or when
due to increased contention
bandwidth or when traffic
or when traffic is
when traffic is low
in the entire feasible
but this effect is
the entire feasible range
this effect is mitigated
entire feasible range we
effect is mitigated by
feasible range we see
is mitigated by using
range we see that
mitigated by using priorities
we see that pool
sending a forward invalidation
a cross layer study
a forward invalidation rpc
cross layer study of
forward invalidation rpc without
layer study of packet
invalidation rpc without requiring
chooses a strictly positive
rpc without requiring the
a strictly positive value
without requiring the modifying
strictly positive value for
this is clearer in
study of packet loss
is clearer in the
of packet loss in
clearer in the graph
packet loss in all
requiring the modifying process
positive value for x
the modifying process to
in the graph for
modifying process to wait
the graph for time
process to wait introduces
graph for time spent
for time spent on
time spent on fetch
spent on fetch rpcs
at the timescales in
the timescales in the
the consistency maintenance algorithm
timescales in the ntfs
consistency maintenance algorithm a
in the ntfs traces
maintenance algorithm a transient
the revenue of pool
algorithm a transient inconsistency
the improvements are less
improvements are less dramatic
is depicted in figure
when the server receives
are less dramatic than
the server receives a
less dramatic than in
server receives a forward
dramatic than in the
b and in the
receives a forward invalidation
and in the entire
than in the microbenchmarks
a forward invalidation for
in the entire feasible
forward invalidation for a
the entire feasible region
invalidation for a shared
entire feasible region it
for a shared the
but they demonstrate that
feasible region it is
they demonstrate that mafs
region it is strictly
demonstrate that mafs can
it is strictly larger
a shared the mfs
is strictly larger than
that mafs can improve
shared the mfs cache
mafs can improve the
the mfs cache consistency
can improve the performance
mfs cache consistency algorithm
improve the performance of
cache consistency algorithm is
the performance of large
consistency algorithm is intended
algorithm is intended to
which the pool would
is intended to achieve
the pool would have
intended to achieve a
pool would have gotten
to achieve a file
would have gotten without
have gotten without attacking
store rpc begins to
or begins receiving an
rpc begins to arrive
begins receiving an update
receiving an update for
begins to arrive store
an update for a
update for a file
to arrive store rpc
arrive store rpc received
store rpc received dat
rpc received dat ar
it records the idenhigh
received dat ar re
records the idenhigh degree
dat ar re sto
the idenhigh degree of
ar re sto reply
idenhigh degree of consistency
re sto reply ata
sto reply ata e
reply ata e d
subject to the constraints
ata e d stor
to the constraints imposed
e d stor pc
the constraints imposed by
d stor pc time
constraints imposed by tity
stor pc time open
imposed by tity of
pc time open file
by tity of the
time open file for
tity of the writer
open file for writing
file for writing close
for writing close file
c depicts the revenue
depicts the revenue of
marks the file as
the revenue of pool
the file as dirty
file as dirty and
replay log log update
as dirty and issues
log log update store
dirty and issues callbacks
log update store rpc
and issues callbacks to
update store rpc complete
issues callbacks to file
which is strictly smaller
callbacks to file semantics
is strictly smaller than
store rpc complete writeback
to file semantics and
rpc complete writeback window
file semantics and the
complete writeback window analysis
semantics and the desirability
writeback window analysis client
and the desirability of
in the entire range
the desirability of minimising
window analysis client both
desirability of minimising overhead
analysis client both experiments
client both experiments confirm
both experiments confirm the
experiments confirm the benefits
confirm the benefits of
we all the clients
the benefits of asynchronous
all the clients caching
benefits of asynchronous writeback
note that the total
the clients caching it
that the total system
journal of lightwave technology
the total system mining
total system mining power
system mining power is
mining power is reduced
even at bandwidths where
if one of these
power is reduced when
at bandwidths where a
is reduced when pool
one of these clients
bandwidths where a typical
of these clients fetches
where a typical mobile
these clients fetches the
a typical mobile file
chooses to infiltrate pool
clients fetches the file
typical mobile file system
fetches the file have
mobile file system performs
the file have opted
file system performs all
file have opted for
system performs all rpcs
have opted for a
performs all rpcs synchronously
opted for a compromise
for a compromise which
a compromise which results
compromise which results in
the revenue of third
asynchronous writeback avoids the
revenue of third parties
which results in a
writeback avoids the need
results in a small
avoids the need to
in a small overhead
the need to switch
a small overhead before
need to switch operation
miners not in either
to switch operation into
not in either pool
small overhead before the
switch operation into a
overhead before the update
operation into a distinct
before the update has
into a distinct low
the update has been
update has been committed
the server sends highbut
server sends highbut admits
and choosing a bandwidth
sends highbut admits the
choosing a bandwidth threshold
highbut admits the possibility
a bandwidth threshold at
admits the possibility of
bandwidth threshold at which
the possibility of a
threshold at which to
possibility of a transient
at which to switch
of a transient inconsistency
when used by themselves
priority server pull rpcs
server pull rpcs to
pull rpcs to the
priorities do not always
rpcs to the clients
do not always result
to the clients with
not always result in
the clients with outstanding
always result in improved
clients with outstanding upthe
result in improved performance
with outstanding upthe algorithm
outstanding upthe algorithm requires
upthe algorithm requires information
algorithm requires information about
requires information about client
since they are only
information about client accesses
they are only effective
about client accesses in
are only effective if
client accesses in dates
only effective if concurrent
effective if concurrent rpcs
therefore pays for the
if concurrent rpcs have
pays for the increased
concurrent rpcs have different
for the increased revenue
which causes them to
rpcs have different priorities
causes them to raise
the increased revenue of
them to raise the
increased revenue of its
to raise the priority
revenue of its attacker
raise the priority of
of its attacker and
the priority of any
its attacker and everyone
priority of any store
attacker and everyone else
and everyone else in
they reduce uservisible delay
everyone else in the
reduce uservisible delay and
else in the system
data order to divide
uservisible delay and contention
order to divide files
delay and contention that
to divide files according
and contention that is
divide files according their
contention that is introduced
files according their status
that is introduced by
is introduced by asynchronous
introduced by asynchronous writeback
implications to the general
to the general case
either shared or unrpcs
the general case consider
shared or unrpcs to
general case consider the
or unrpcs to expedite
case consider the case
unrpcs to expedite transmission
consider the case of
the case of p
case of p pools
update propagation using asynchronous
propagation using asynchronous writeback
a fetch rpc for
using asynchronous writeback at
fetch rpc for an
asynchronous writeback at all
for any choice of
rpc for an unshared
any choice of the
for an unshared file
the effects of systemic
choice of the pools
effects of systemic packet
of the pools sizes
writeback at all bandwidths
an unshared file shared
at all bandwidths delays
the pools sizes m
of systemic packet loss
all bandwidths delays sending
systemic packet loss on
bandwidths delays sending updates
packet loss on aggregate
delays sending updates to
loss on aggregate tcp
sending updates to the
since the file server
updates to the file
on aggregate tcp flows
the file server always
to the file server
file server always assumes
server always assumes that
always assumes that an
assumes that an unshared
that an unshared which
an unshared which is
we evaluate the effectiveness
unshared which is already
evaluate the effectiveness of
which is already cached
the effectiveness of an
is already cached by
effectiveness of an update
already cached by a
of an update propagation
cached by a different
an update propagation scheme
ieee conference on supercomputing
update propagation scheme to
by a different client
propagation scheme to reduce
at least one pool
a different client always
least one pool will
scheme to reduce this
one pool will choose
to reduce this delay
different client always triggers
pool will choose to
client always triggers a
will choose to perform
always triggers a file
choose to perform block
mafs allows a client
triggers a file has
allows a client to
to perform block withholding
a client to delay
a file has an
client to delay transmitting
file has an uncommitted
to delay transmitting updates
has an uncommitted write
an uncommitted write when
uncommitted write when it
write when it is
when it is accessed
but the file server
it is accessed by
the file server forces
is accessed by an
file server forces file
in a system with
accessed by an addiserver
server forces file updates
by an addiserver pull
a system with p
forces file updates to
system with p pools
file updates to be
updates to be written
to be written back
be written back when
written back when another
since the server has
back when another client
the server has no
when another client must
server has no way
another client must read
has no way of
client must read an
no way of knowing
must read an up
way of knowing if
of knowing if the
knowing if the file
if the file has
the file has tional
file has tional client
is not an equilibrium
date copy of the
copy of the file
incorrect information about the
information about the status
about the status of
the status of a
status of a file
of a file only
a file only outstanding
file only outstanding updates
assume towards negation this
towards negation this is
negation this is not
this is not the
is not the case
affects the efficiency of
timeline of a file
the efficiency of the
of a file update
efficiency of the algorithm
time advances from left
detection of such a
advances from left to
of such a misfinally
from left to right
since updates to shared
client will access stale
updates to shared and
will access stale data
end performance effects of
to shared and unshared
performance effects of parallel
is an equilibrium point
effects of parallel tcp
shared and unshared files
of parallel tcp sockets
due to network latency
parallel tcp sockets on
and unshared files are
tcp sockets on a
unshared files are writclassification
now consider a setting
sockets on a lossy
consider a setting with
files are writclassification results
a setting with only
on a lossy wide
are writclassification results in
setting with only pools
writclassification results in the
the writeback window can
results in the file
writeback window can never
in the file being
window can never be
the file being marked
can never be eliminated
file being marked as
being marked as shared
but adding an additional
ten back to the
adding an additional delay
back to the server
and treat the other
to the server at
treat the other pools
the server at different
an additional delay before
server at different priorities
the other pools as
additional delay before writing
other pools as independent
delay before writing back
pools as independent miners
before writing back the
writing back the update
the original order of
back the update increases
the update increases the
original order of the
update increases the scope
this is the setting
increases the scope for
international parallel and distributed
order of the status
parallel and distributed processing
the scope for inconsistency
of the status of
is the setting analyzed
and distributed processing symposium
the setting analyzed above
the status of files
setting analyzed above and
status of files can
analyzed above and we
of files can be
above and we have
files can be specified
and we have seen
can be specified by
we have seen there
be specified by the
have seen there that
specified by the user
seen there that pool
by the user or
the user or by
user or by applithe
illustrates how this inconsistency
or by applithe sequence
how this inconsistency can
can increase its revenue
this inconsistency can arise
by applithe sequence of
increase its revenue by
applithe sequence of updates
its revenue by performing
sequence of updates is
revenue by performing a
of updates is no
by performing a block
updates is no longer
performing a block withholding
is no longer entirely
a block withholding attack
no longer entirely preserved
block withholding attack on
like file system such
withholding attack on pool
file system such as
system such as mafs
a different type of
different type of inconsistency
or can be inferred
type of inconsistency is
can be inferred by
of inconsistency is introduced
be inferred by the
s infiltration rate by
inconsistency is introduced between
inferred by the file
infiltration rate by x
is introduced between a
by the file server
introduced between a client
the file server according
between a client and
file server according to
a client and the
server according to how
client and the server
according to how it
and the server when
the performance of tcp
the server when a
to how it dates
server when a file
how it dates to
when a file is
it dates to shared
ip for networks with
a file is modified
for networks with high
dates to shared files
networks with high bandwidth
to shared files form
shared files form a
files form a subsequence
form a subsequence of
since the change is
delay products and random
a subsequence of the
products and random loss
the change is hidden
subsequence of the original
change is hidden from
of the original updates
is hidden from the
hidden from the server
from the server until
take this values p
the server until the
this values p m
server until the file
until the file is
acm transactions on networking
the file is closed
for the purposes of
automatic inference should incorpoas
the purposes of this
inference should incorpoas do
purposes of this investigation
should incorpoas do the
of this investigation we
incorpoas do the updates
this investigation we assume
do the updates to
investigation we assume that
the updates to unshared
we assume that the
updates to unshared files
assume that the open
close interval for a
interval for a file
for a file is
implicit dependenrate a heuristic
a file is small
dependenrate a heuristic for
file is small relative
a heuristic for the
is small relative to
heuristic for the sharing
small relative to the
for the sharing status
relative to the network
the sharing status of
to the network latency
sharing status of new
the network latency and
status of new files
network latency and writeback
latency and writeback delay
and a mechacies between
a mechacies between file
mechacies between file updates
the update propagation techniques
between file updates are
update propagation techniques we
file updates are preserved
propagation techniques we describe
techniques we describe can
we describe can be
describe can be applied
can be applied equally
since the combination of
be applied equally well
the combination of nism
applied equally well to
equally well to individual
combination of nism for
well to individual file
to individual file writes
of nism for converting
individual file writes as
file writes as to
nism for converting shared
writes as to writeback
for converting shared files
converting shared files to
shared files to be
files to be unshared
to be unshared if
be unshared if they
unshared if they cease
if they cease to
they cease to forward
cease to forward invalidations
to forward invalidations and
forward invalidations and compulsory
invalidations and compulsory server
and compulsory server pull
compulsory server pull rpcs
server pull rpcs for
pull rpcs for unbe
techniques for update propagation
rpcs for unbe accessed
for update propagation although
for unbe accessed by
update propagation although coda
unbe accessed by more
accessed by more than
by more than a
more than a single
than a single client
like file systems can
file systems can generate
systems can generate inconsistencies
can generate inconsistencies between
generate inconsistencies between clients
the current implemenshared files
current implemenshared files prevents
they were designed to
implemenshared files prevents a
were designed to permit
files prevents a client
designed to permit a
prevents a client from
to permit a client
a client from accessing
permit a client to
client from accessing new
a client to function
from accessing new versions
client to function at
accessing new versions of
to function at low
new versions of files
function at low bandwidth
versions of files tation
of files tation in
files tation in mfs
tation in mfs assumes
in mfs assumes that
rather than for rapid
mfs assumes that every
than for rapid update
assumes that every new
for rapid update propagation
that every new file
every new file is
new file is unshared
since it is impractical
a simple model and
it is impractical to
and monin contravention of
simple model and its
is impractical to lock
model and its empirical
monin contravention of their
and its empirical validation
impractical to lock files
contravention of their update
to lock files if
of their update order
lock files if clients
files if clients are
acm sigcomm computer communication
if clients are permitted
sigcomm computer communication review
clients are permitted to
are permitted to modify
itors client accesses to
permitted to modify the
client accesses to a
to modify the filesystem
accesses to a file
modify the filesystem while
the filesystem while they
to a file according
filesystem while they are
while they are disconnected
a file according to
file according to an
according to an overlapping
to an overlapping series
coda supports stronger consistency
an overlapping series of
supports stronger consistency through
overlapping series of time
stronger consistency through optimistic
series of time periods
consistency through optimistic replication
of time periods to
time periods to ensure
periods to ensure that
to ensure that files
ensure that files which
that files which are
files which are regularly
which are regularly accessed
are regularly accessed remain
regularly accessed remain shared
since the mfs file
the mfs file monitoring
mfs file monitoring component
file monitoring component op
an alternative approach is
alternative approach is to
approach is to allow
is to allow a
to allow a client
allow a client to
a client to use
client to use asynchronous
to use asynchronous writeback
but require that it
require that it alerts
experimental setup erates on
that it alerts the
setup erates on a
it alerts the file
erates on a larger
alerts the file server
on a larger time
the file server when
a larger time scale
file server when a
larger time scale than
server when a file
time scale than the
when a file is
scale than the experiments
a file is modified
than the experiments considered
the experiments considered in
experiments considered in at
considered in at the
by sending an invalidation
in at the start
sending an invalidation rpc
at the start of
the start of this
start of this section
of this section we
this section we identified
this informs the server
section we identified large
informs the server that
the server that the
server that the update
that the update exists
the update exists before
scale collaborative this paper
update exists before the
exists before the new
before the new file
the new file contents
new file contents ar
we omit its details
omit its details for
its details for brevity
engineering design as an
design as an example
as an example of
an example of a
example of a scenario
of a scenario which
a scenario which features
scenario which features when
which features when a
origin of inconsistencies since
features when a process
when a process modifies
of inconsistencies since asynchronous
a process modifies a
inconsistencies since asynchronous writeback
process modifies a file
since asynchronous writeback decouples
congestion control for high
asynchronous writeback decouples modifying
control for high bandwidth
writeback decouples modifying a
an update is scheduled
decouples modifying a file
update is scheduled to
modifying a file from
is scheduled to be
a file from notifying
scheduled to be a
file from notifying the
to be a high
from notifying the server
be a high degree
notifying the server that
a high degree of
the server that a
high degree of read
server that a change
that a change has
a change has occurred
it can generate inconsistencies
can generate inconsistencies between
at present we have
generate inconsistencies between cached
present we have evalappended
inconsistencies between cached copies
we have evalappended to
have evalappended to the
evalappended to the log
and the process continues
illustrates the potential for
the potential for inconsistency
the process continues executing
process continues executing withuated
continues executing withuated the
during the writeback window
executing withuated the mfs
withuated the mfs cache
the mfs cache consistency
mfs cache consistency algorithm
another client accessing a
cache consistency algorithm using
client accessing a cached
consistency algorithm using a
accessing a cached copy
algorithm using a synthetic
using a synthetic out
a synthetic out having
synthetic out having to
or fetching the file
out having to wait
fetching the file from
having to wait for
the file from the
to wait for the
file from the file
wait for the server
from the file server
for the server to
the server to be
server to be contacted
effective erasure codes for
will not read up
erasure codes for reliable
codes for reliable computer
for reliable computer communication
reliable computer communication protocols
though we are hoping
we are hoping to
acm sigcomm computer communication
are hoping to obtain
sigcomm computer communication review
hoping to obtain real
from the server s
to obtain real data
the server s perspective
obtain real data from
real data from such
data from such an
from such an thread
there is no inconsistency
such an thread then
an thread then checks
thread then checks the
then checks the status
checks the status of
since it is unaware
the status of the
it is unaware of
status of the file
is unaware of the
of the file the
unaware of the new
the file the update
of the new update
file the update modifies
if the environment in
the environment in the
environment in the future
from a global perspective
stable state where only
the update is queued
state where only pool
writing client writes a
update is queued for
client writes a closes
is queued for transmission
writes a closes a
queued for transmission at
for transmission at the
transmission at the reg
reading client server fetch
client server fetch a
server fetch a fetch
fetch a fetch reply
flushes update store a
update store a callback
store a callback for
a callback for a
callback for a fetch
for a fetch a
a fetch a open
fetch a open a
writes a closes a
on the feasibility of
the feasibility of software
feasibility of software fec
universita di pisa deit
di pisa deit technical
pisa deit technical report
deit technical report lr
two pools where one
pools where one infiltrates
where one infiltrates the
one infiltrates the other
flushes update open a
optimal infiltration rate x
fetch reply reading client
reply reading client server
reading client server invalidate
client server invalidate a
as a function of
a function of pool
function of pool sizes
writing client pull a
callback for a fetch
the case for packet
and the lines in
case for packet level
for packet level fec
for a fetch a
in fifth international workshop
fifth international workshop on
international workshop on protocols
workshop on protocols for
on protocols for high
show the revenue density
the revenue density of
store a fetch reply
back to the setting
to the setting at
the setting at hand
setting at hand with
at hand with p
hand with p pools
the revenue of pool
is better when x
asynchronous writeback with invalidations
writeback with invalidations figure
a client s update
client s update is
s update is logged
update is logged when
is logged when the
logged when the file
when the file is
the file is closed
while it is in
it is in the
is in the log
other clients see the
clients see the server
see the server s
number of rpcs average
the server s stale
of rpcs average time
server s stale version
lateral error correction for
error correction for time
an invalidation rpc allows
invalidation rpc allows the
rpc allows the server
allows the server to
the server to invalidate
server to invalidate other
to invalidate other clients
invalidate other clients cached
other clients cached copies
a client that modifies
client that modifies a
that modifies a file
modifies a file could
a file could save
hik j ihkj m
file could save bandwidth
fourth usenix symposium on
could save bandwidth by
usenix symposium on networked
j ihkj m l
symposium on networked systems
save bandwidth by not
on networked systems design
bandwidth by not sending
networked systems design and
by not sending it
systems design and implementation
not sending it to
ihkj m l ml
sending it to the
m l ml cb
it to the file
l ml cb c
to the file server
ml cb c b
the file server at
cb c b cbcb
file server at all
can improve its revenue
c b cbcb ed
improve its revenue by
b cbcb ed f
its revenue by attacking
cbcb ed f gf
revenue by attacking pool
ed f gf cb
unless the server pulls
f gf cb c
the server pulls it
gf cb c b
server pulls it to
cb c b yx
pulls it to supply
c b yx cbcb
it to supply it
to supply it to
supply it to another
it to another client
z eded f f
eded f f gfgf
f f gfgf cb
f gfgf cb b
mafs clients push updates
gfgf cb b on
clients push updates to
cb b on yxyx
push updates to the
b on yxyx cbb
updates to the server
attacks is not an
to the server in
is not an equilibrium
the server in the
not an equilibrium point
server in the background
z eded f f
to reduce the delay
reduce the delay incurred
the delay incurred when
delay incurred when fetching
incurred when fetching an
when fetching an invalidated
fetching an invalidated file
case as a test
as a test case
pushing updates can result
we take the pool
updates can result in
take the pool distribution
can result in the
the pool distribution in
result in the server
gfgf c c b
pool distribution in january
c c b on
in the server having
c b on yx
the server having received
b on yx ccb
server having received some
on yx ccb qp
or all of the
all of the update
of the update by
the update by the
update by the time
by the time another
the time another client
time another client accesses
gf cb b c
another client accesses it
cb b c onon
b c onon yxxy
c onon yxxy cbbc
onon yxxy cbbc qpqp
z eded r f
eded r f f
r f f srs
selective invalidation with reader
invalidation with reader pull
with reader pull the
reader pull the effect
pull the effect of
the effect of selective
effect of selective invalidation
of selective invalidation and
selective invalidation and reader
gfgf c b onon
invalidation and reader pull
c b onon yx
and reader pull is
b onon yx cb
reader pull is that
onon yx cb qp
pull is that mafs
is that mafs incorporates
that mafs incorporates sirp
we analyze the cases
analyze the cases where
an integrated experimental environment
the cases where each
integrated experimental environment for
cases where each of
a new algorithm for
where each of the
z ed r f
each of the pools
ed r f r
experimental environment for distributed
new algorithm for maintaining
environment for distributed systems
algorithm for maintaining inter
for distributed systems and
of the pools attacks
distributed systems and networks
the pools attacks all
pools attacks all other
attacks all other open
all other open pools
gf invalidations and server
sirp behaves similarly to
invalidations and server pulls
behaves similarly to synchronous
and server pulls mfs
similarly to synchronous writeback
to synchronous writeback if
all of which behave
synchronous writeback if a
of which behave honestly
writeback if a client
if a client client
a client client consistency
note that attacking all
that attacking all pools
which combines asynchronous writeback
attacking all pools with
combines asynchronous writeback with
all pools with force
asynchronous writeback with concurrently
pools with force proportional
fifth usenix symposium on
diff synchronous average time
with force proportional to
usenix symposium on operating
writeback with concurrently fetches
symposium on operating systems
with concurrently fetches a
on operating systems design
concurrently fetches a file
operating systems design and
force proportional to their
systems design and implementation
proportional to their size
to their size yields
their size yields the
but behaves like asynchronous
size yields the same
behaves like asynchronous writeinvalidations
yields the same results
like asynchronous writeinvalidations and
the same results as
asynchronous writeinvalidations and expedited
same results as attacking
writeinvalidations and expedited transmission
results as attacking a
and expedited transmission of
as attacking a single
expedited transmission of updates
attacking a single pool
transmission of updates for
a single pool of
of updates for files
single pool of their
updates for files back
pool of their aggregate
for files back when
of their aggregate size
files back when there
back when there are
when there are no
there are no concurrent
are no concurrent fetches
plugging in the numbers
in the numbers into
like synchronous that other
the numbers into the
synchronous that other clients
that other clients are
numbers into the analysis
other clients are attempting
clients are attempting to
into the analysis above
are attempting to read
the analysis above shows
analysis above shows that
above shows that a
shows that a larger
that a larger pool
sirp sends an rpc
a larger pool needs
sends an rpc to
larger pool needs to
an rpc to the
pool needs to use
rpc to the server
needs to use a
to the server as
to use a smaller
the server as soon
use a smaller ratio
server as soon as
a smaller ratio of
as soon as an
smaller ratio of its
soon as an application
ratio of its mining
as an application closes
of its mining power
an application closes a
its mining power for
application closes a modified
mining power for infiltration
closes a modified file
power for infiltration and
for infiltration and can
infiltration and can increase
and can increase its
can increase its revenue
but it can defer
increase its revenue density
it can defer transmitting
its revenue density more
can defer transmitting the
revenue density more than
defer transmitting the selective
density more than a
transmitting the selective invalidation
more than a small
physical layer impact upon
than a small pool
layer impact upon packet
impact upon packet errors
using an invalidation rpc
an invalidation rpc to
invalidation rpc to alert
rpc to alert the
to alert the actual
alert the actual contents
the actual contents until
actual contents until they
contents until they are
until they are needed
achieves its optimum attack
its optimum attack rate
optimum attack rate at
file server to the
server to the existence
to the existence of
the existence of a
existence of a new
of a new update
a new update improves
passive and active measurement
new update improves cache
and active measurement workshop
update improves cache consistency
of the pool s
the pool s mining
but consumes additional bandwidth
pool s mining power
if writeback traffic is
increasing its revenue by
writeback traffic is low
its revenue by almost
traffic is low enough
is low enough for
low enough for the
enough for the server
for the server to
the server to start
server to start receiving
to start receiving an
start receiving an update
this amounts to a
amounts to a daily
to a daily revenue
a daily revenue increase
daily revenue increase of
revenue increase of b
experimental evaluation immediately after
evaluation immediately after it
immediately after it receives
after it receives the
it receives the invalidation
the invalidation we conclude
invalidation we conclude this
we conclude this section
conclude this section with
this section with an
section with an experiment
with an experiment that
an experiment that compares
experiment that compares the
that compares the is
compares the is superfluous
usd at the exchange
at the exchange rate
sirp avoids this overhead
the exchange rate on
avoids this overhead by
exchange rate on that
this overhead by performing
rate on that date
overhead by performing selec
this represents a considerable
effectiveness of sirp to
represents a considerable increase
of sirp to three
a considerable increase of
sirp to three alternatives
considerable increase of the
increase of the pools
of the pools net
the pools net revenue
when a client adds
a client adds an
client adds an update
for the smallest pool
adds an update to
an update to the
update to the writeback
to the writeback back
the writeback back transmits
writeback back transmits an
back transmits an update
the attack is much
transmits an update as
attack is much less
an update as soon
is much less profitable
update as soon as
as soon as a
soon as a file
as a file is
a file is closed
to reach the optimum
reach the optimum it
the optimum it needs
optimum it needs almost
it needs almost a
needs almost a third
it only sends an
almost a third of
only sends an invalidation
a third of its
sends an invalidation if
third of its power
an invalidation if the
of its power for
invalidation if the queue
its power for attacking
if the queue is
power for attacking but
the queue is not
for attacking but increases
queue is not empty
attacking but increases its
but increases its revenue
increases its revenue density
its revenue density by
revenue density by merely
chronous writeback puts the
writeback puts the update
puts the update in
the update in a
update in a queue
in a queue and
a queue and transmits
queue and transmits it
and transmits it if
transmits it if the
it if the queue
if the queue is
the queue is empty
the invalidation is piggybacked
invalidation is piggybacked onto
is piggybacked onto the
piggybacked onto the as
onto the as soon
the as soon as
as soon as it
soon as it reaches
as it reaches the
it reaches the front
reaches the front of
the front of the
front of the queue
the university of illinois
we also compare update
university of illinois national
of illinois national center
illinois national center for
national center for supercomputing
center for supercomputing applications
sirp against a policy
against a policy we
a policy we refer
policy we refer to
we refer to as
refer to as sirp
name size discusfish antpool
size discusfish antpool ghash
io btchine btcguild eligius
btchine btcguild eligius others
which only differs from
only differs from sirp
differs from sirp in
from sirp in performing
sirp in performing compulsory
in performing compulsory invalidations
when the server receives
the server receives an
server receives an invalidation
receives an invalidation from
an invalidation from a
invalidation from a date
from a date results
a date results in
date results in an
results in an invalidation
in an invalidation rpc
an invalidation rpc to
invalidation rpc to the
rpc to the server
global crossing current network
crossing current network performance
it makes callbacks to
makes callbacks to all
callbacks to all the
to all the other
all the other clients
the other clients that
other clients that cache
clients that cache the
that cache the are
cache the are of
the are of particular
are of particular interest
of particular interest in
particular interest in this
interest in this comparison
to tell them to
tell them to discard
them to discard their
to discard their copies
if several clients modify
several clients modify are
clients modify are the
modify are the files
are the files readers
the files readers read
how is the performance
is the performance of
the performance of the
performance of the same
of the same file
modifications are serialised in
are serialised in the
serialised in the order
in the order of
the order of their
order of their readers
of their readers and
their readers and writers
readers and writers affected
and writers affected by
writers affected by stronger
qwest ip network statistics
affected by stronger consistency
the client that made
client that made the
that made the update
made the update only
the update only transmits
update only transmits it
only transmits it when
transmits it when it
it when it reaches
when it reaches the
it reaches the head
reaches the head of
the head of the
head of the writeback
of the writeback queue
if another client attempts
another client attempts to
client attempts to fetch
attempts to fetch the
to fetch the file
fetch the file during
the file during the
file during the update
during the update s
the update s experimental
update s experimental setup
s experimental setup writeback
experimental setup writeback window
the server blocks that
server blocks that client
blocks that client until
that client until the
client until the update
until the update has
the update has arrived
the server also makes
server also makes a
also makes a pull
makes a pull rpc
a pull rpc to
pull rpc to the
rpc to the client
to the client that
the client that experiments
client that experiments were
that experiments were conducted
experiments were conducted in
vice president of research
were conducted in a
president of research and
conducted in a network
of research and t
in a network of
a network of five
network of five hosts
one modified the file
instructing it to expedite
it to expedite sending
to expedite sending the
expedite sending the update
one writer client that
writer client that was
client that was responsible
that was responsible for
was responsible for modifying
responsible for modifying when
for modifying when it
modifying when it receives
when it receives the
it receives the pull
receives the pull rpc
the client begins sending
client begins sending back
begins sending back a
sending back a collection
back a collection of
a collection of files
and three reader clients
three reader clients that
reader clients that only
clients that only read
that only read the
only read the the
read the the update
the the update at
the update at the
update at the same
at the same priority
the same priority as
same priority as an
priority as an rpc
as an rpc to
an rpc to fetch
rpc to fetch file
to fetch file data
the bandwidth between the
bandwidth between the writer
between the writer client
the writer client and
writer client and the
client and the server
and the server that
the server that it
server that it will
that it will be
it will be preferentially
will be preferentially allocated
be preferentially allocated bandwidth
if the update was
the update was set
the six largest open
update was set to
six largest open pool
largest open pool sizes
open pool sizes as
pool sizes as of
sizes as of january
acm transactions on networking
and the reader client
their optimal infiltration rates
server was already being
was already being written
already being written back
of each pool as
each pool as a
pool as a fraction
the client increases its
as a fraction of
client increases its priority
a fraction of its
fraction of its size
bandwidth was always set
was always set to
if it attacked all
it attacked all others
attacked all others without
all others without reciprocation
and their revenue density
their revenue density when
revenue density when attacking
so that it can
that it can prevent
it can prevent inconsistencies
can prevent inconsistencies by
prevent inconsistencies by inhibiting
inconsistencies by inhibiting access
by inhibiting access to
t wo p ools
inhibiting access to the
wo p ools we
access to the file
p ools we proceed
to the file by
ools we proceed to
the file by other
we proceed to analyze
file by other clients
proceed to analyze the
to analyze the case
analyze the case where
the case where two
average duration of reader
case where two pools
duration of reader fetch
as shown in figure
where two pools may
two pools may attack
pools may attack each
may attack each other
attack each other and
each other and the
other and the other
and the other miners
the other miners mine
other miners mine solo
again we have pool
invalidations are used in
are used in fluid
used in fluid replication
to allow clients to
allow clients to avoid
clients to avoid sending
to avoid sending data
avoid sending data across
sending data across a
data across a wide
controls its infiltration rate
its infiltration rate x
a method for improving
method for improving tcp
for improving tcp performance
improving tcp performance over
tcp performance over wireless
performance over wireless links
the server only asks
server only asks the
only asks the client
asks the client for
the client for a
client for a file
for a file s
a file s data
file s data if
s data if another
data if another client
if another client requests
another client requests it
also controls its infiltration
controls its infiltration rate
its infiltration rate x
nd ieee wireless communications
ieee wireless communications and
wireless communications and networking
communications and networking conference
s read staleness at
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
the total mining power
total mining power in
mining power in the
power in the system
in the system is
the system is m
system is m x
the direct revenues r
an adaptive forward error
adaptive forward error correction
forward error correction protocol
error correction protocol for
of the pools from
correction protocol for end
the pools from mining
pools from mining are
from mining are their
mining are their effective
are their effective mining
their effective mining rates
end transport of real
th international conference on
international conference on computer
conference on computer communications
on computer communications and
computer communications and networks
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
two attacking pools system
staleness of version retrieved
based loss recovery for
as a function of
loss recovery for reliable
a function of pool
recovery for reliable multicast
function of pool sizes
for reliable multicast transmission
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
cumulative proportion of reads
end performance evaluation of
on onon yxyx p
onon yxyx p p
yxyx p p qpqp
z onon yxyx p
onon yxyx p p
yxyx p p qppq
z on yx p
on yx p qp
z onon yxxy p
onon yxxy p p
yxxy p p qpqp
z on yx p
on yx p qp
th symposium on high
symposium on high performance
staleness of version retrieved
on high performance interconnects
of version retrieved read
version retrieved read staleness
retrieved read staleness at
z time spent on
time spent on invalidations
cumulative proportion of reads
proportion of reads cumulative
of reads cumulative proportion
reads cumulative proportion of
two pools infiltrating each
cumulative proportion of reads
pools infiltrating each other
average store rpc duration
divided by the total
by the total mining
the total mining rate
end forward error correction
international zurich seminar on
zurich seminar on communications
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
staleness of version retrieved
the case for application
the total revenue of
total revenue of each
revenue of each pool
of each pool is
level network striping for
each pool is its
network striping for data
pool is its direct
striping for data intensive
is its direct mining
for data intensive applications
staleness of reader file
data intensive applications using
v v w w
of reader file accesses
its direct mining revenue
intensive applications using high
v w w ut
applications using high speed
w w ut v
using high speed wide
w ut v wv
high speed wide area
cumulative distributions for the
ut v wv ut
speed wide area networks
distributions for the staleness
for the staleness of
and the infiltration revenue
the staleness of all
the infiltration revenue from
staleness of all accesses
infiltration revenue from the
of all accesses to
revenue from the previous
all accesses to files
from the previous round
accesses to files by
to files by the
files by the three
by the three readers
the three readers are
three readers are shown
which is the attacked
is the attacked pool
the attacked pool s
attacked pool s total
higher curves represent less
pool s total revenue
curves represent less staleness
s total revenue multiplied
ieee conference on supercomputing
total revenue multiplied by
revenue multiplied by its
multiplied by its infiltration
by its infiltration rate
total writer execution time
the pool s total
pool s total revenue
s total revenue is
total revenue is divided
revenue is divided among
is divided among its
divided among its loyal
among its loyal miners
its loyal miners and
loyal miners and miners
miners and miners that
and miners that infiltrated
miners that infiltrated it
at stable state this
stable state this is
state this is r
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
tsunami file transfer protocol
graphs for cache consistency
for cache consistency trace
these graphs show various
graphs show various features
show various features of
various features of the
features of the performance
of the performance results
first international workshop on
synchronous writeback asynchronous writeback
international workshop on protocols
writeback asynchronous writeback sirp
workshop on protocols for
async denotes asynchronous invalidations
on protocols for fast
asynchronous writeback sirp c
protocols for fast long
writeback sirp c sirp
and none no invalidations
diff denotes differentiated writeback
denotes differentiated writeback priorities
differentiated writeback priorities for
writeback priorities for shared
priorities for shared and
for shared and unshared
shared and unshared files
and unif denotes uniform
unif denotes uniform priorities
cc is the mfs
is the mfs cache
the mfs cache consistency
mfs cache consistency algorithm
the height of a
height of a bar
of a bar counts
a bar counts the
bar counts the number
counts the number of
the number of invalidations
the white portion counts
white portion counts the
portion counts the number
counts the number of
the number of server
we obtain the following
obtain the following closed
our experimental setup consisting
the following closed expressions
experimental setup consisting of
following closed expressions for
setup consisting of three
closed expressions for each
consisting of three hosts
we express the revenues
predictable high performance bulk
express the revenues as
high performance bulk data
the revenues as functions
performance bulk data transfer
revenues as functions of
as functions of x
and a writer client
the bandwidth from the
bandwidth from the reader
from the reader to
the reader to the
reader to the server
to the server was
the server was fixed
server was fixed at
ieee international conference on
international conference on cluster
conference on cluster computing
and the bandwidth from
the bandwidth from the
bandwidth from the writer
from the writer to
the writer to the
writer to the server
to the server was
the server was varied
server was varied according
was varied according to
varied according to the
according to the experiment
the writer was configured
writer was configured in
was configured in one
configured in one of
in one of seven
one of seven different
of seven different ways
average reader execution time
synchronous or no invalidations
and differentiated or uniform
differentiated or uniform priorities
or uniform priorities for
solomon codes and their
uniform priorities for writing
codes and their applications
priorities for writing back
for writing back shared
writing back shared and
back shared and unshared
shared and unshared files
the mfs concurrency control
mfs concurrency control algorithm
corresponds to asynchronous invalidations
to asynchronous invalidations with
asynchronous invalidations with differentiated
invalidations with differentiated priority
with differentiated priority for
differentiated priority for shared
priority for shared files
both clients access a
clients access a shared
access a shared repository
a shared repository of
shared repository of files
repository of files stored
of files stored on
files stored on the
stored on the file
on the file server
each module has a
module has a descriptor
has a descriptor file
a descriptor file and
descriptor file and a
file and a set
nat and packet mangling
and a set of
and packet mangling for
packet mangling for linux
execution times for concurrent
times for concurrent access
for concurrent access trace
reader execution times are
module descriptor files are
execution times are averages
descriptor files are about
times are averages for
are averages for the
averages for the three
for the three readers
kb in size and
in size and the
higher bandwidth results in
bandwidth results in less
results in less staleness
member files take up
files take up an
since writes can be
take up an average
writes can be sent
up an average of
can be sent to
be sent to the
sent to the file
to the file server
the file server faster
the total size of
total size of all
size of all the
of all the files
all the files in
the files in the
files in the collection
in the collection is
sirp is most effective
is most effective at
most effective at reducing
effective at reducing staleness
though many reads return
the writer workload consists
many reads return out
writer workload consists of
workload consists of the
consists of the writer
of the writer updating
the writer updating modules
multicast routing in datagram
writer updating modules in
routing in datagram internetworks
updating modules in a
in datagram internetworks and
date file contents when
modules in a random
file contents when compared
in a random order
datagram internetworks and extended
contents when compared to
internetworks and extended lans
when compared to the
compared to the optimal
to the optimal version
an update to a
update to a module
acm transactions on computers
to a module consists
transactions on computers systems
a module consists of
module consists of a
consists of a sequence
of a sequence of
a sequence of operations
more sirp reads are
sirp reads are up
of which are reads
which are reads and
compared to synchronous or
to synchronous or asynchronous
synchronous or asynchronous writeback
allowing higher degrees of
higher degrees of staleness
are writes to a
writes to a file
to a file in
a file in the
file in the module
more reads performed with
reads performed with sirp
performed with sirp are
with sirp are within
versions of the optimal
consist of writes to
of writes to unshared
writes to unshared external
each pool controls only
to unshared external files
pool controls only its
with this bandwidth level
controls only its own
only its own infiltration
its own infiltration rate
which are each created
are each created with
synchronous and asynchronous writeback
each created with a
and asynchronous writeback coincide
in each round of
created with a unique
asynchronous writeback coincide in
each round of the
writeback coincide in performance
round of the pool
with a unique name
of the pool game
since they are constrained
there is a pause
they are constrained by
is a pause between
each pool will optimize
a pause between each
pool will optimize its
pause between each operation
will optimize its infiltration
are constrained by the
optimize its infiltration rate
between each operation and
its infiltration rate of
constrained by the bandwidth
infiltration rate of the
each operation and a
rate of the other
by the bandwidth bottleneck
operation and a longer
the bandwidth bottleneck and
and a longer pause
bandwidth bottleneck and send
a longer pause between
bottleneck and send updates
longer pause between updates
and send updates in
pause between updates to
send updates in the
between updates to modules
updates in the same
acts at step t
in the same order
the reader workload is
reader workload is similar
it optimizes its revenue
by suppressing unnecessary invalidations
optimizes its revenue with
its revenue with x
but an access to
an access to a
sirp reduces its bandwidth
access to a module
reduces its bandwidth usage
to a module consists
its bandwidth usage and
a module consists of
bandwidth usage and achieves
module consists of a
usage and achieves a
consists of a series
and achieves a small
of a series of
achieves a small improvement
a series of reads
a small improvement over
small improvement over sirp
and external files are
external files are never
files are never accessed
since devoting less bandwidth
performance enhancing proxies intended
the configuration parameters used
enhancing proxies intended to
devoting less bandwidth to
proxies intended to mitigate
configuration parameters used to
intended to mitigate link
less bandwidth to invalidations
parameters used to generate
bandwidth to invalidations results
used to generate the
to invalidations results in
to generate the reader
invalidations results in data
generate the reader and
results in data reaching
the reader and writer
in data reaching the
reader and writer workload
data reaching the server
and writer workload are
reaching the server faster
writer workload are listed
workload are listed in
are listed in table
asynchronous writeback performs as
writeback performs as well
performs as well as
the writer workload has
as well as sirp
writer workload has a
workload has a nominal
has a nominal duration
a nominal duration of
nominal duration of two
duration of two minutes
synchronous writeback continues to
writeback continues to underperform
while the reader workload
the reader workload is
reader workload is extended
workload is extended to
this is because the
is extended to terminate
is because the progress
extended to terminate at
because the progress of
to terminate at the
the progress of writers
terminate at the same
progress of writers using
at the same time
of writers using asynchronous
the same time as
writers using asynchronous writeback
same time as the
using asynchronous writeback schemes
time as the writer
asynchronous writeback schemes is
as the writer workload
writeback schemes is less
the writer workload actually
schemes is less constrained
writer workload actually finishes
is less constrained by
less constrained by the
constrained by the bandwidth
acts at step t
since low bandwidth could
low bandwidth could extend
and they can overlap
bandwidth could extend its
they can overlap computation
could extend its running
it optimizes its revenue
extend its running time
optimizes its revenue with
its running time beyond
its revenue with x
can overlap computation and
running time beyond two
overlap computation and fetching
time beyond two minutes
computation and fetching file
and fetching file contents
fetching file contents with
file contents with writeback
rather than simply being
than simply being a
simply being a selfinterested
being a selfinterested optimisation
a selfinterested optimisation by
selfinterested optimisation by writers
optimisation by writers to
by writers to improve
writers to improve their
to improve their own
improve their own performance
analysis of the results
of the results figure
asynchronous writeback therefore benefits
shows graphs of some
writeback therefore benefits both
graphs of some selected
therefore benefits both writers
udp bandwidth measurement tool
of some selected results
benefits both writers and
some selected results from
both writers and readers
selected results from the
results from the experiments
the files shared between
files shared between the
shared between the clients
between the clients were
the clients were divided
clients were divided into
while synchronous writes provide
synchronous writes provide strong
writes provide strong concurrency
provide strong concurrency control
they resulted in the
resulted in the lowest
in the lowest rate
the lowest rate of
lowest rate of completed
rate of completed writes
of completed writes in
completed writes in all
file lengths were randomised
writes in all the
in all the tests
with an average length
an average length of
since the writer had
the writer had no
writer had no possibility
had no possibility of
no possibility of over
lapping think time with
think time with asynchronous
time with asynchronous writeback
an equilibrium exists where
to prevent the clients
equilibrium exists where neither
prevent the clients falling
exists where neither pool
the clients falling into
at all bandwidth levels
clients falling into lockstep
all bandwidth levels the
falling into lockstep in
bandwidth levels the mfs
into lockstep in the
lockstep in the course
in the course of
the course of fetching
can improve its revenue
cc algorithm outperformed synchronous
course of fetching and
improve its revenue by
of fetching and writing
its revenue by changing
fetching and writing back
revenue by changing its
and writing back the
algorithm outperformed synchronous writes
writing back the files
by changing its infiltration
outperformed synchronous writes by
changing its infiltration rate
synchronous writes by at
writes by at least
any pair of values
pair of values x
consisting of selecting a
of selecting a random
and was among the
selecting a random file
was among the options
a scalable and tcp
among the options with
a random file set
the options with the
random file set and
options with the highest
file set and performing
with the highest write
friendly congestion control for
the highest write throughput
congestion control for high
set and performing a
and performing a sequence
such that arg maxx
performing a sequence of
a sequence of reads
this is clear from
sequence of reads or
is clear from graph
of reads or writes
reads or writes on
or writes on files
writes on files in
on files in it
the writer performed a
writer performed a file
performed a file set
a file set operation
which shows the average
file set operation of
shows the average time
the average time to
average time to complete
time to complete store
to complete store rpcs
complete store rpcs initiated
store rpcs initiated by
rpcs initiated by the
initiated by the writer
cc outperforms all of
outperforms all of the
all of the alternatives
this is because of
is because of the
because of the reduced
with each access being
of the reduced number
each access being equally
the reduced number of
access being equally likely
reduced number of invalidations
being equally likely to
number of invalidations it
equally likely to open
of invalidations it generates
likely to open a
to open a file
open a file for
a file for reading
file for reading or
for reading or writing
in contrast to most
contrast to most of
readers performed a file
to most of the
performed a file set
most of the other
a file set operation
of the other schemes
file set operation of
it is able to
is able to take
able to take advantage
to take advantage of
take advantage of both
advantage of both differentiated
of both differentiated writeback
pull rpcs to raise
rpcs to raise the
to raise the priority
raise the priority of
the priority of its
priority of its writes
third international workshop on
international workshop on protocols
workshop on protocols for
on protocols for fast
protocols for fast long
file sets were treated
sets were treated as
shows the performance from
were treated as hot
the performance from the
performance from the reader
from the reader s
the reader s perspective
while the writer is
the writer is able
writer is able to
is able to decrease
able to decrease its
to decrease its time
decrease its time spent
its time spent performing
of the file set
time spent performing store
the file set operations
spent performing store rpcs
file set operations were
set operations were directed
operations were directed to
were directed to those
directed to those file
to those file sets
the reader s average
reader s average time
s average time spent
average time spent on
read staleness comparing update
time spent on fetches
staleness comparing update propagation
spent on fetches increases
comparing update propagation schemes
on fetches increases sharply
update propagation schemes requires
fetches increases sharply when
propagation schemes requires a
increases sharply when the
schemes requires a criterion
sharply when the file
requires a criterion for
when the file in
a criterion for measuring
the file in question
criterion for measuring the
file in question must
for measuring the staleness
in question must be
measuring the staleness of
question must be pulled
the staleness of file
must be pulled from
staleness of file reads
be pulled from the
pulled from the writer
we identified updates to
identified updates to files
updates to files by
to files by associating
files by associating a
this cost must be
packet recovery in high
cost must be weighed
by associating a version
must be weighed against
associating a version number
be weighed against the
a version number with
speed networks using coding
weighed against the benefit
version number with each
against the benefit of
number with each file
networks using coding and
the benefit of substantially
using coding and buffer
benefit of substantially increased
coding and buffer management
of substantially increased writer
and incrementing it every
substantially increased writer throughput
incrementing it every time
it every time the
every time the file
time the file was
the file was modified
differentiated writeback succeeds in
writeback succeeds in reducing
succeeds in reducing the
reads were labelled with
in reducing the time
were labelled with the
reducing the time the
labelled with the version
the time the reader
with the version number
time the reader has
the version number of
the reader has to
version number of the
reader has to wait
number of the file
has to wait when
of the file at
to wait when accessing
the file at the
wait when accessing a
file at the time
when accessing a shared
at the time the
accessing a shared file
the time the read
time the read occurred
the staleness of a
staleness of a particular
of a particular read
a particular read was
particular read was determined
read was determined according
was determined according to
the feasible region for
determined according to an
feasible region for the
according to an ideal
region for the pool
show statistics for invalidations
for the pool sizes
to an ideal version
the pool sizes is
statistics for invalidations and
pool sizes is m
an ideal version number
for invalidations and serverpull
ideal version number derived
invalidations and serverpull rpcs
version number derived from
and serverpull rpcs for
number derived from executing
performance evaluation of forward
serverpull rpcs for those
evaluation of forward error
derived from executing the
rpcs for those writer
of forward error correction
for those writer configurations
forward error correction in
from executing the experiment
error correction in atm
those writer configurations which
correction in atm networks
executing the experiment with
writer configurations which make
the experiment with all
configurations which make use
experiment with all participants
which make use of
with all participants running
make use of them
all participants running on
participants running on a
running on a single
on a single host
in a real execution
cc significantly reduces the
significantly reduces the number
reduces the number of
the number of invalidations
the difference between the
number of invalidations it
difference between the version
of invalidations it must
between the version number
invalidations it must transmit
the version number a
it must transmit by
version number a read
must transmit by putting
number a read returns
transmit by putting off
a read returns and
by putting off invalidating
read returns and the
putting off invalidating a
returns and the optimal
the revenue function for
off invalidating a file
and the optimal version
invalidating a file until
revenue function for ri
a file until it
the optimal version number
file until it is
function for ri is
until it is added
optimal version number determines
it is added to
for ri is concave
is added to the
version number determines how
added to the log
ri is concave in
number determines how stale
is concave in xi
determines how stale the
concave in xi for
how stale the read
in xi for all
stale the read is
xi for all feasible
yet the effect of
for all feasible values
the effect of this
all feasible values of
effect of this policy
feasible values of the
of this policy on
values of the variables
this policy on the
policy on the number
on the number of
shows cumulative distributions for
the number of serverpull
cumulative distributions for the
number of serverpull rpcs
distributions for the staleness
of serverpull rpcs is
for the staleness of
serverpull rpcs is minor
the staleness of reads
staleness of reads at
of reads at different
reads at different writer
improved consistency results in
which differs from mfs
consistency results in fewer
results in fewer stale
in fewer stale reads
cc in omitting differentiated
in omitting differentiated writeback
and this is reflected
this is reflected by
is reflected by a
makes more invalidations and
therefore the solutions for
more invalidations and incurs
reflected by a curve
invalidations and incurs more
the solutions for equations
and incurs more server
by a curve that
a curve that is
curve that is higher
that is higher on
is higher on the
higher on the left
on the left side
the left side of
left side of the
because its store rpcs
side of the graph
its store rpcs must
store rpcs must compete
rpcs must compete with
must compete with the
compete with the rpcs
with the rpcs to
are unique and are
consistency maintenance cost the
unique and are either
the rpcs to write
and are either at
rpcs to write back
maintenance cost the overhead
to write back external
are either at the
write back external files
cost the overhead of
either at the borders
the overhead of the
at the borders of
overhead of the update
the borders of the
this increases the commit
borders of the feasible
of the update propagation
increases the commit delay
of the feasible region
the update propagation schemes
the feasible region or
the commit delay for
feasible region or where
update propagation schemes can
region or where ri
commit delay for each
propagation schemes can be
delay for each file
schemes can be compared
for each file and
can be compared by
each file and the
be compared by referring
efficient erasure correcting codes
compared by referring to
file and the likelihood
by referring to the
and the likelihood of
referring to the reader
the likelihood of it
ieee transactions on information
to the reader and
transactions on information theory
likelihood of it being
the reader and writer
of it being accessed
reader and writer execution
it being accessed by
and writer execution times
being accessed by the
from section v we
accessed by the reader
section v we know
by the reader while
v we know that
the reader while it
we know that no
reader while it is
while it is being
it is being written
is being written back
acknowledgements shown in figure
attack is not an
is not an equilibrium
not an equilibrium point
since each pool can
reader execution time is
each pool can increase
these experiments demonstrate that
execution time is the
experiments demonstrate that for
time is the average
pool can increase its
is the average for
demonstrate that for the
the average for all
can increase its revenue
average for all three
that for the trace
for all three readers
increase its revenue by
for the trace we
its revenue by choosing
the trace we have
revenue by choosing a
trace we have examined
by choosing a strictly
choosing a strictly positive
a strictly positive infiltration
strictly positive infiltration rate
the mfs algorithm of
mfs algorithm of asynchronous
the reduced staleness achievable
reduced staleness achievable by
algorithm of asynchronous invalidations
staleness achievable by sirp
of asynchronous invalidations and
achievable by sirp has
by sirp has little
asynchronous invalidations and differentiated
sirp has little or
invalidations and differentiated writeback
has little or no
little or no cost
and differentiated writeback is
or no cost compared
no cost compared to
differentiated writeback is able
cost compared to asynchronous
compared to asynchronous writeback
writeback is able to
to asynchronous writeback with
asynchronous writeback with no
is able to maintain
writeback with no invalidations
able to maintain cache
to maintain cache consistency
maintain cache consistency between
since the writer is
cache consistency between the
the writer is up
writer is up to
consistency between the two
between the two clients
the two clients and
two clients and to
clients and to allow
and to allow the
is not a solution
to allow the writer
not a solution to
allow the writer to
a solution to equations
slower when using sirp
the writer to write
writer to write back
to write back changes
write back changes to
c compared to sirp
back changes to the
changes to the stored
to the stored data
the stored data faster
selective invalidation is clearly
stored data faster than
invalidation is clearly beneficial
data faster than is
faster than is possible
than is possible with
is possible with the
possible with the alternative
with the alternative schemes
nash equilibrium therefore exists
sirp has the highest
equilibrium therefore exists with
has the highest average
therefore exists with x
the highest average execution
highest average execution time
we intend to further
intend to further evaluate
to further evaluate the
further evaluate the perfor
but this is because
this is because it
is because it provides
because it provides the
references mance of the
it provides the best
mance of the algorithm
provides the best consistency
of the algorithm to
the best consistency of
the algorithm to determine
best consistency of all
algorithm to determine its
consistency of all the
to determine its effectiveness
of all the schemes
determine its effectiveness under
rd annual ieee symposium
its effectiveness under other
annual ieee symposium on
effectiveness under other workloads
ieee symposium on foundations
if a reader reads
symposium on foundations of
a reader reads more
on foundations of computer
reader reads more up
foundations of computer science
and with more clients
then it transfers more
it transfers more data
the reader execution time
reader execution time for
execution time for each
time for each case
for each case is
each case is proportional
case is proportional to
is proportional to the
evaluation of an adaptive
proportional to the amount
of an adaptive transport
to the amount of
an adaptive transport protocol
the amount of data
amount of data transferred
of data transferred between
data transferred between the
transferred between the reader
in proceedings of the
between the reader and
the reader and server
though lack of space
lack of space precludes
nd annual joint conference
of space precludes showing
annual joint conference of
space precludes showing this
joint conference of the
precludes showing this in
conference of the ieee
showing this in a
of the ieee computer
this in a graph
ieee transactions on information
the ieee computer and
transactions on information theory
ieee computer and communications
computer and communications societies
we thank robbert van
thank robbert van renesse
emin gu n sirer
rimon barr and stephen
barr and stephen rago
and stephen rago for
stephen rago for comments
rago for comments regarding
for comments regarding this
comments regarding this work
evaluation of an adaptive
of an adaptive transport
an adaptive transport protocol
conclusion the growing use
the growing use of
growing use of mobile
in proceedings of the
use of mobile computers
proceedings of the twenty
of mobile computers and
mobile computers and wireless
computers and wireless networks
and wireless networks has
second annual joint conference
wireless networks has greatly
annual joint conference of
networks has greatly increased
using symbolic computation tools
has greatly increased the
joint conference of the
greatly increased the scope
conference of the ieee
increased the scope for
of the ieee computer
the scope for adapting
the ieee computer and
scope for adapting data
ieee computer and communications
we see that there
computer and communications societies
for adapting data access
see that there is
adapting data access to
that there is a
data access to vary
there is a single
is a single pair
a single pair of
single pair of values
pair of values for
of values for which
values for which equation
holds for any feasible
for any feasible choice
any feasible choice of
feasible choice of m
numerical analysis a numerical
analysis a numerical analysis
a numerical analysis confirms
numerical analysis confirms these
analysis confirms these observations
we simulate the pool
simulate the pool game
the pool game for
pool game for a
game for a range
for a range of
this paper has explored
paper has explored applying
has explored applying and
explored applying and j
a range of pool
range of pool sizes
for each choice of
each choice of pool
measurements of a distributed
choice of pool sizes
of a distributed file
a distributed file the
distributed file the technique
file the technique of
we start the simulation
the technique of modeless
start the simulation when
technique of modeless adaptation
the simulation when both
of modeless adaptation to
simulation when both pools
modeless adaptation to a
when both pools do
adaptation to a distributed
both pools do not
to a distributed file
pools do not infiltrate
a distributed file system
do not infiltrate each
distributed file system system
not infiltrate each other
in proceedings of the
th acm symposium to
acm symposium to improve
symposium to improve its
to improve its performance
the cache manager for
cache manager for our
manager for our mfs
for our mfs on
our mfs on operating
mfs on operating systems
on operating systems principles
the importance of translucence
importance of translucence in
of translucence in mobile
and the revenue densities
translucence in mobile computing
the revenue densities are
in mobile computing systems
revenue densities are r
acm transactions on computer
pacific file system incorporates
file system incorporates features
system incorporates features that
incorporates features that are
features that are not
that are not present
are not present in
not present in existing
present in existing grove
at each round one
each round one pool
round one pool chooses
one pool chooses its
pool chooses its optimal
chooses its optimal infiltration
its optimal infiltration rate
optimal infiltration rate based
infiltration rate based on
rate based on the
based on the pool
on the pool sizes
the pool sizes and
pool sizes and the
sizes and the rate
and the rate with
the rate with which
rate with which it
with which it is
which it is infiltrated
file systems for mobile
systems for mobile hosts
and we calculate the
we calculate the revenue
adaptation to bandwidth variation
calculate the revenue after
to bandwidth variation through
the revenue after convergence
bandwidth variation through the
revenue after convergence with
variation through the use
after convergence with equation
through the use of
the use of prioritised
use of prioritised communication
recall the players in
the players in the
players in the pool
in the pool game
the pool game are
pool game are chosen
game are chosen with
are chosen with the
chosen with the round
with the round robin
the round robin policy
so the pools take
the pools take turns
and we let the
we let the game
let the game run
the game run until
game run until convergence
tolerant mechanism for distributed
mechanism for distributed file
for distributed file cache
o hint genercache consistency
distributed file cache consistency
hint genercache consistency protocol
the results are illustrated
genercache consistency protocol using
results are illustrated in
consistency protocol using file
in proceedings of the
are illustrated in figure
proceedings of the twelth
protocol using file access
of the twelth symposium
using file access information
the twelth symposium on
file access information to
twelth symposium on operating
access information to imation
symposium on operating systems
information to imation through
on operating systems principles
to imation through speculative
each run with some
imation through speculative execution
run with some m
in operating systems prove
operating systems prove performance
values results in a
results in a single
in a single point
a single point in
single point in each
point in each graph
in each graph in
each graph in figure
we depict the infiltration
depict the infiltration rates
the infiltration rates of
infiltration rates of both
rates of both pools
of both pools x
this experiment demonstrates that
experiment demonstrates that sirp
we have evaluated the
demonstrates that sirp is
have evaluated the effect
that sirp is preferable
evaluated the effect of
sirp is preferable to
the effect of these
is preferable to asynchronous
effect of these features
preferable to asynchronous writeback
of these features on
to asynchronous writeback at
these features on performance
asynchronous writeback at low
features on performance at
writeback at low bandwidth
on performance at varying
performance at varying bandwidth
at varying bandwidth levels
varying bandwidth levels and
bandwidth levels and under
and adds little additional
levels and under both
adds little additional overhead
and under both synthetic
b and the pools
under both synthetic and
and the pools revenue
both synthetic and real
the pools revenue densities
pools revenue densities r
the difference between asynchronous
difference between asynchronous schemes
between asynchronous schemes is
asynchronous schemes is minimal
but any scheme improves
any scheme improves over
scheme improves over synchronous
improves over synchronous writeback
for the same reasons
the same reasons that
same reasons that it
reasons that it improves
that it improves performance
for each choice of
each choice of m
asynchronous writeback reduces staleness
and sirp makes it
sirp makes it an
makes it an acceptable
it an acceptable choice
an acceptable choice at
acceptable choice at low
choice at low bandwidth
the values of x
including a workload emulating
a workload emulating collaborative
workload emulating collaborative data
performance measurements access with
measurements access with high
access with high read
are the points in
the points in each
points in each of
in each of the
each of the graphs
and found that while
of the graphs with
found that while the
the graphs with the
that while the of
graphs with the respective
while the of automatic
with the respective coordinates
the of automatic prefetching
in proceedings of the
proceedings of the isca
of the isca interadditional
the isca interadditional costs
j graphs we draw
isca interadditional costs imposed
graphs we draw a
interadditional costs imposed are
we draw a border
costs imposed are mostly
draw a border around
imposed are mostly hidden
a border around the
border around the region
around the region where
the region where there
region where there is
where there is no
they can have benenational
can have benenational conference
have benenational conference on
benenational conference on parallel
attack by i in
conference on parallel and
by i in equilibrium
on parallel and distributed
parallel and distributed computfits
and distributed computfits which
distributed computfits which are
computfits which are very
for the ri graphs
which are very visible
the ri graphs we
ri graphs we draw
graphs we draw a
we draw a line
draw a line around
a line around the
line around the region
scale and performance in
around the region where
and performance in a
the region where the
performance in a distributed
region where the revenue
in a distributed file
modal nature of ing
a distributed file system
nature of ing systems
where the revenue is
the revenue is the
revenue is the same
is the same as
the same as in
acm transactions on computer
same as in the
transactions on computer systems
as in the no
we first observe that
first observe that only
observe that only in
adaptation in mfs allows
that only in extreme
in mfs allows clients
only in extreme cases
mfs allows clients to
in extreme cases a
allows clients to adapt
extreme cases a pool
clients to adapt quickly
cases a pool does
to adapt quickly to
a pool does not
adapt quickly to a
pool does not attack
quickly to a variety
does not attack its
to a variety of
not attack its counterpart
a variety of bandwidth
variety of bandwidth conditions
of bandwidth conditions without
bandwidth conditions without substantial
conditions without substantial changes
without substantial changes in
substantial changes in operation
at equilibrium a pool
equilibrium a pool will
a pool will refrain
pool will refrain from
will refrain from attacking
refrain from attacking only
from attacking only if
attacking only if the
only if the other
if the other pool
the other pool is
other pool is larger
pool is larger than
is larger than about
of the total mining
the total mining power
we observe that a
observe that a pool
that a pool improves
a pool improves its
pool improves its revenue
improves its revenue compared
its revenue compared to
revenue compared to the
compared to the no
our evaluation has included
attacks scenario only when
evaluation has included comparisons
scenario only when it
has included comparisons of
only when it controls
included comparisons of mfs
when it controls a
comparisons of mfs to
it controls a strict
of mfs to cache
controls a strict majority
mfs to cache manm
a strict majority of
strict majority of the
majority of the total
of the total mining
the total mining power
these are the small
are the small triangular
the small triangular regions
small triangular regions in
triangular regions in figures
in the rest of
the rest of the
rest of the space
ager configurations corresponding to
configurations corresponding to prior
the trapezoids in the
corresponding to prior work
trapezoids in the figures
enforcing fairness in a
fairness in a live
the revenue of the
and confirmed scale and
revenue of the pool
confirmed scale and performance
of the pool is
scale and performance in
the pool is inferior
and performance in a
pool is inferior compared
performance in a distributed
is inferior compared to
in a distributed file
inferior compared to the
a distributed file system
compared to the no
streaming system maya haridasana
acm that there are
that there are situations
there are situations in
are situations in which
situations in which mfs
portob and robbert van
in which mfs would
and robbert van renessea
which mfs would outperform
robbert van renessea a
mfs would outperform afs
van renessea a dept
the prisoner s dilemma
prisoner s dilemma in
s dilemma in a
dilemma in a healthy
in a healthy bitcoin
transactions on computer systems
a healthy bitcoin environment
where neither pool controls
neither pool controls a
pool controls a strict
new york b institute
controls a strict majority
york b institute of
a strict majority of
b institute of informatics
strict majority of the
majority of the mining
of the mining power
federal university of rio
university of rio grande
of rio grande do
both pools will earn
rio grande do sul
pools will earn less
grande do sul porto
will earn less at
do sul porto alegre
earn less at equilibrium
less at equilibrium than
mobile computing with the
at equilibrium than if
computing with the rover
equilibrium than if both
with the rover toolkit
than if both pools
if both pools ran
both pools ran without
pools ran without attacking
ieee transactions on computers
we can analyze in
can analyze in this
analyze in this case
in this case a
this case a game
case a game where
a game where each
game where each pool
where each pool chooses
each pool chooses either
pool chooses either to
chooses either to attack
either to attack and
to attack and optimize
attack and optimize its
and optimize its revenue
or to refrain from
to refrain from attacking
coda and little work
without loss of generality
edu abstract we describe
these earlier systems were
abstract we describe a
earlier systems were designed
we describe a practical
as we have seen
describe a practical auditing
we have seen in
systems were designed for
have seen in section
a practical auditing approach
seen in section v
were designed for a
practical auditing approach designed
designed for a mobile
auditing approach designed to
for a mobile environment
approach designed to encourage
a mobile environment which
designed to encourage fairness
mobile environment which is
to encourage fairness in
environment which is substantially
encourage fairness in peer
which is substantially different
can increase its revenue
increase its revenue above
auditing is employed to
is employed to ensure
employed to ensure that
to ensure that correct
ensure that correct nodes
that correct nodes are
does attack but pool
correct nodes are able
nodes are able to
are able to receive
able to receive streams
partially connected operafrom that
to receive streams even
connected operafrom that available
receive streams even in
operafrom that available today
streams even in the
we denote the revenue
even in the presence
denote the revenue of
in the presence of
the revenue of pool
the presence of nodes
presence of nodes that
of nodes that do
nodes that do not
that do not upload
mfs is able to
do not upload enough
is able to provide
not upload enough data
able to provide tion
the exact value of
exact value of r
depends on the values
on the values of
and scales well when
the values of m
scales well when compared
well when compared to
when compared to previous
compared to previous solutions
to previous solutions that
previous solutions that rely
solutions that rely on
that rely on tit
but it is always
it is always smaller
is always smaller than
always smaller than one
and performance in a
tat style of data
performance in a wide
style of data exchange
as we have seen
we have seen above
auditing involves two roles
in proceedings of the
proceedings of the first
does choose to attack
of the first usenix
the first usenix conference
first usenix conference on
untrusted local auditors run
usenix conference on file
local auditors run on
conference on file and
auditors run on all
on file and storage
run on all nodes
file and storage technologies
on all nodes in
but does not surpass
all nodes in the
does not surpass one
nodes in the system
the game is summarized
game is summarized in
and are responsible for
is summarized in figure
are responsible for collecting
responsible for collecting and
for collecting and maintaining
collecting and maintaining accountable
and maintaining accountable information
maintaining accountable information regarding
improved performance in periods
accountable information regarding data
performance in periods of
information regarding data sent
in periods of high
regarding data sent and
periods of high network
data sent and received
of high network contention
this is the classical
high network contention by
sent and received by
is the classical prisoner
and received by each
the classical prisoner s
received by each node
classical prisoner s dilemma
attack is the dominant
is the dominant strategy
this paper has described
paper has described mafs
one or more trusted
or more trusted global
more trusted global auditors
a new file system
trusted global auditors periodically
chooses to attack or
new file system for
to attack or not
global auditors periodically sample
file system for mobile
auditors periodically sample the
system for mobile clients
periodically sample the state
for mobile clients that
sample the state of
the revenue of pool
the state of participating
mobile clients that is
state of participating nodes
clients that is tailored
that is tailored for
is tailored for wireless
is larger when attacking
tailored for wireless networks
larger when attacking than
estimate whether the streaming
for wireless networks by
whether the streaming quality
when attacking than when
the streaming quality is
attacking than when refraining
streaming quality is satisfactory
wireless networks by incorporating
than when refraining from
networks by incorporating automatic
when refraining from attack
by incorporating automatic adaptation
incorporating automatic adaptation to
and decide whether any
automatic adaptation to the
decide whether any actions
adaptation to the available
whether any actions are
mofavouring cache validation and
to the available bandwidth
and the same for
any actions are required
cache validation and rpcs
the same for pool
validation and rpcs to
and rpcs to retrieve
mafs differs from previous
rpcs to retrieve files
we demonstrate through simulation
to retrieve files over
differs from previous designs
demonstrate through simulation that
retrieve files over other
from previous designs in
files over other bile
through simulation that our
over other bile computing
at equilibrium of this
other bile computing with
equilibrium of this attack
bile computing with the
simulation that our approach
computing with the rover
previous designs in making
with the rover toolkit
designs in making use
that our approach can
in making use of
our approach can successfully
making use of asynchronous
approach can successfully detect
use of asynchronous writeback
ieee transactypes of traffic
of asynchronous writeback at
can successfully detect and
asynchronous writeback at all
successfully detect and react
when both pools attack
detect and react to
writeback at all bandwidth
and react to the
at all bandwidth levels
we have not compared
react to the presence
have not compared mfs
the revenue of each
to the presence of
not compared mfs with
the presence of opportunistic
compared mfs with lbfs
presence of opportunistic nodes
mfs with lbfs since
revenue of each pool
with lbfs since tions
of opportunistic nodes in
lbfs since tions on
of each pool is
since tions on computers
opportunistic nodes in streaming
each pool is smaller
nodes in streaming sessions
pool is smaller than
rather than switching from
is smaller than its
than switching from synchronous
special issue on mobile
smaller than its revenue
issue on mobile computing
switching from synchronous to
than its revenue if
from synchronous to asynchronous
its revenue if neither
synchronous to asynchronous writeback
revenue if neither pool
to asynchronous writeback when
if neither pool attacked
their approaches are orthogonal
it incurs low network
asynchronous writeback when bandwidth
incurs low network and
writeback when bandwidth is
low network and computational
when bandwidth is insufficient
network and computational overheads
the game is not
rpc priorities and a
which remain fixed as
game is not played
remain fixed as the
is not played once
fixed as the system
priorities and a new
as the system scales
and a new update
a new update propagation
new update propagation algorithm
reduce a client s
a client s contention
introduction video and audio
client s contention for
video and audio streaming
where each pool can
s contention for wireless
and audio streaming account
contention for wireless bandwidth
each pool can change
audio streaming account for
pool can change its
streaming account for a
can change its strategy
account for a large
and permit a degree
change its strategy between
permit a degree of
for a large percentage
a degree of consistency
a large percentage of
its strategy between attack
large percentage of content
degree of consistency that
percentage of content accessed
strategy between attack and
of content accessed over
between attack and no
content accessed over the
of consistency that is
accessed over the web
consistency that is equivalent
that is equivalent to
is equivalent to instantaneous
equivalent to instantaneous propagation
to instantaneous propagation of
one popular style of
instantaneous propagation of updates
popular style of streaming
the pools can agree
style of streaming on
of streaming on the
streaming on the web
on the web is
the web is on
experiments demonstrate that these
web is on demand
demonstrate that these techniques
that these techniques allow
to refrain from attacking
these techniques allow mafs
in which users access
techniques allow mafs to
which users access pre
allow mafs to achieve
mafs to achieve performance
and in each round
to achieve performance that
in each round xxx
stored content at will
each round xxx xxx
achieve performance that is
round xxx xxx pool
performance that is at
that is at least
is at least equal
at least equal to
another style requires streams
not present in the
no attack xxx pool
present in the earlier
style requires streams to
in the earlier systems
requires streams to be
the earlier systems we
streams to be generated
earlier systems we have
to be generated and
systems we have compared
and in most cases
we have compared against
be generated and disseminated
in most cases superior
generated and disseminated in
most cases superior to
and disseminated in real
cases superior to that
we anticipate that implementing
superior to that achievable
anticipate that implementing lbfs
to that achievable by
that implementing lbfs file
that achievable by conventional
implementing lbfs file chunks
achievable by conventional file
lbfs file chunks in
by conventional file system
file chunks in mfs
conventional file system designs
chunks in mfs would
this may be the
file system designs that
may be the case
system designs that switch
be the case with
designs that switch between
the case with important
that switch between lowand
case with important social
switch between lowand high
bandwidth modes according to
modes according to thresholds
mafs is therefore able
an important property of
is therefore able to
important property of live
therefore able to make
able to make efficient
to make efficient use
make efficient use of
streaming is that data
efficient use of the
is that data is
use of the network
that data is not
of the network and
data is not available
the network and provide
is not available in
network and provide predictable
not available in advance
and provide predictable file
provide predictable file system
predictable file system semantics
being generated just before
generated just before transmission
just before transmission at
regardless of the available
before transmission at the
of the available bandwidth
transmission at the sender
further improve performance its
improve performance its performance
interested users ideally want
users ideally want to
ideally want to receive
and performance in a
want to receive the
performance in a wide
to receive the stream
receive the stream without
the stream without much
stream without much delay
without much delay from
much delay from its
delay from its original
from its original transmission
in proceedin future work
we plan to investigate
plan to investigate the
to investigate the performance
investigate the performance of
automated hoarding for mobile
the performance of ings
streaming systems now allow
hoarding for mobile computers
performance of ings of
systems now allow large
of ings of the
now allow large numbers
ings of the first
allow large numbers of
of the first usenix
in proceedings of the
large numbers of interested
proceedings of the sixteenth
the first usenix conference
of the sixteenth acm
numbers of interested users
the sixteenth acm symposium
of interested users to
first usenix conference on
interested users to receive
sixteenth acm symposium on
users to receive streamed
usenix conference on file
to receive streamed data
acm symposium on operating
receive streamed data in
conference on file and
streamed data in near
symposium on operating systems
data in near real
on file and storage
in near real time
on operating systems principles
file and storage modeless
and storage modeless adaptation
storage modeless adaptation and
modeless adaptation and mfs
without requiring extensive amounts
adaptation and mfs in
requiring extensive amounts of
and mfs in wide
extensive amounts of resources
area and more web
these systems are based
systems are based on
are based on the
based on the peer
where nodes interested in
nodes interested in receiving
interested in receiving data
in receiving data also
receiving data also help
data also help disseminate
also help disseminate it
help disseminate it to
disseminate it to each
it to each other
prisoner s dilemma for
alleviating the bottleneck at
s dilemma for two
as well as further
dilemma for two pools
the bottleneck at the
well as further evaluating
bottleneck at the source
as further evaluating the
further evaluating the performance
evaluating the performance of
the revenue density of
the performance of the
revenue density of each
initial protocols were based
performance of the mfs
protocols were based on
of the mfs cache
were based on building
the mfs cache consistency
based on building a
mfs cache consistency algorithm
on building a tree
density of each pool
of each pool is
each pool is determined
pool is determined by
we also intend to
is determined by the
also intend to use
based overlay of nodes
determined by the decision
overlay of nodes through
by the decision of
of nodes through which
the decision of both
nodes through which data
decision of both pools
through which data would
of both pools whether
which data would be
both pools whether to
data would be pushed
pools whether to attack
whether to attack or
to attack or not
the dominant strategy of
dominant strategy of each
strategy of each player
of each player is
each player is to
player is to attack
exploiting weak connectivity for
weak connectivity for mobile
such as chainsaw and
connectivity for mobile file
as chainsaw and coolstreaming
however the payoff of
for mobile file access
the payoff of both
payoff of both would
disconnected operamfs to further
of both would be
have shown that the
both would be larger
in proceedings of the
shown that the use
proceedings of the fifteenth
that the use of
of the fifteenth acm
the use of a
the fifteenth acm symposium
use of a mesh
operamfs to further examine
of a mesh of
fifteenth acm symposium on
a mesh of connected
acm symposium on operating
mesh of connected nodes
symposium on operating systems
of connected nodes and
on operating systems principles
connected nodes and a
to further examine the
would be larger if
further examine the benefits
be larger if they
nodes and a pull
larger if they both
examine the benefits achievable
if they both refrain
the benefits achievable from
they both refrain from
benefits achievable from the
both refrain from attacking
achievable from the autotion
based data dissemination approach
from the autotion in
data dissemination approach can
the autotion in the
dissemination approach can provide
autotion in the coda
a pool can detect
in the coda file
approach can provide similar
pool can detect whether
the coda file system
can provide similar results
can detect whether it
provide similar results with
detect whether it is
similar results with better
whether it is being
results with better resilience
it is being attacked
acm transactions on commatic
is being attacked and
with better resilience to
being attacked and deduce
better resilience to failures
transactions on commatic generation
resilience to failures and
attacked and deduce that
to failures and churn
on commatic generation of
and deduce that the
commatic generation of caching
deduce that the other
generation of caching policies
that the other pool
of caching policies for
the other pool is
caching policies for files
nodes joining and leaving
other pool is violating
joining and leaving the
pool is violating the
and leaving the system
is violating the agreement
cooperation where neither pool
where neither pool attacks
neither pool attacks is
pool attacks is a
attacks is a possible
is a possible stable
a possible stable state
nodes notify each other
notify each other of
each other of receipt
other of receipt of
of receipt of data
receipt of data packets
and request packets from
request packets from their
packets from their neighbors
from their neighbors based
their neighbors based on
neighbors based on the
based on the received
on the received notifications
practical systems based on
systems based on pull
despite the fact that
based streaming now exist
the fact that the
streaming now exist in
fact that the single
now exist in china
that the single nash
the single nash equilibrium
single nash equilibrium in
nash equilibrium in every
equilibrium in every round
where they are used
in every round is
they are used to
every round is to
are used to disseminate
round is to attack
used to disseminate television
to disseminate television channels
disseminate television channels to
television channels to thousands
channels to thousands of
to thousands of users
case as an example
as an example we
even though the p
an example we take
bandwidth network file system
example we take again
we take again the
take again the pool
again the pool sizes
p paradigm allows systems
the pool sizes shown
paradigm allows systems to
in proceedings of the
allows systems to scale
pool sizes shown in
systems to scale with
sizes shown in figure
proceedings of the eighteenth
to scale with the
of the eighteenth acm
scale with the number
automated hoarding for mobile
with the number of
the eighteenth acm symposium
the number of users
hoarding for mobile computers
eighteenth acm symposium on
acm symposium on operating
symposium on operating systems
and study the case
on operating systems principles
it also leaves them
in proceedings of the
study the case where
proceedings of the sixteenth
the case where the
also leaves them vulnerable
case where the two
of the sixteenth acm
where the two largest
leaves them vulnerable to
the two largest pools
the sixteenth acm symposium
them vulnerable to opportunistic
sixteenth acm symposium on
vulnerable to opportunistic behavior
acm symposium on operating
symposium on operating systems
on operating systems principles
opportunistic nodes attempt to
nodes attempt to receive
attempt to receive a
to receive a stream
the optimal infiltration rates
receive a stream without
a stream without uploading
stream without uploading their
without uploading their fair
uploading their fair share
out of the total
their fair share of
of the total system
fair share of data
the total system mining
total system mining power
reducing the overall upload
the overall upload capacity
overall upload capacity of
upload capacity of the
capacity of the system
despite the damage that
the damage that they
damage that they may
that they may cause
not much work has
much work has been
work has been done
has been done in
been done in studying
done in studying mechanisms
in studying mechanisms to
studying mechanisms to avoid
mechanisms to avoid their
to avoid their presence
and the pools would
avoid their presence in
the pools would lose
their presence in live
the goal of this
goal of this the
acknowledgements we would like
of this the authors
we would like to
this the authors were
would like to thank
the authors were supported
like to thank robbert
authors were supported by
to thank robbert van
were supported by afrl
thank robbert van renesse
supported by afrl award
by afrl award fa
emin gu n sirer
compared to the no
gu n sirer and
n sirer and paul
sirer and paul francis
and paul francis for
paul francis for comments
francis for comments and
for comments and suggestions
comments and suggestions regarding
and suggestions regarding mfs
q i dentical p
we also thank rimon
i dentical p ools
also thank rimon barr
dentical p ools let
p ools let there
ools let there be
let there be q
there be q pools
be q pools of
q pools of identical
and kevin walsh for
pools of identical size
kevin walsh for helpful
of identical size that
walsh for helpful discussions
identical size that engage
for helpful discussions and
size that engage in
helpful discussions and corrections
that engage in block
discussions and corrections to
engage in block withholding
and corrections to this
in block withholding against
corrections to this paper
block withholding against one
withholding against one another
other miners neither attack
miners neither attack nor
neither attack nor are
attack nor are being
nor are being attacked
managing update conflicts in
update conflicts in bayou
in this case there
this case there exists
case there exists a
there exists a symmetric
a weakly connected replicated
exists a symmetric equilibrium
weakly connected replicated storage
connected replicated storage system
in proceedings of the
proceedings of the fifteenth
without loss of generality
of the fifteenth acm
the fifteenth acm symposium
fifteenth acm symposium on
acm symposium on operating
symposium on operating systems
a step of pool
on operating systems principles
it controls its attack
controls its attack rates
its attack rates each
attack rates each of
rates each of the
each of the other
of the other pools
and due to symmetry
due to symmetry they
a coherent distributed file
to symmetry they are
coherent distributed file cache
symmetry they are all
distributed file cache with
they are all the
file cache with directory
are all the same
cache with directory write
acm transactions on computer
transactions on computer systems
the attack rate of
attack rate of pool
against any other pool
each of the other
of the other pools
the other pools can
other pools can attack
pools can attack its
can attack its peers
attack its peers as
its peers as well
all attack rates by
attack rates by all
rates by all attackers
by all attackers are
all attackers are identical
file system usage in
system usage in windows
usage in windows nt
the attack rate of
attack rate of any
rate of any pool
of any pool other
any pool other than
against any other pool
in proceedings of the
proceedings of the seventeenth
of the seventeenth acm
the seventeenth acm symposium
seventeenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
the direct revenue of
direct revenue of each
revenue of each of
of each of the
each of the other
of the other pools
similarly denote by r
the revenue densities of
revenue densities of pool
a lowbandwidth network file
lowbandwidth network file system
in proceedings of the
proceedings of the seventeenth
of the seventeenth acm
the seventeenth acm symposium
seventeenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
are instantiated to mi
the views and conclusions
views and conclusions herein
and conclusions herein are
conclusions herein are those
herein are those of
are those of the
those of the authors
caching in the sprite
in the sprite network
the sprite network file
sprite network file system
acm transactions on computer
transactions on computer systems
minimum and average download
and average download rates
average download rates across
download rates across all
rates across all nodes
across all nodes when
all nodes when using
nodes when using the
when using the bar
using the bar gossip
the bar gossip and
bar gossip and chainsaw
gossip and chainsaw protocols
paper is to propose
is to propose and
to propose and evaluate
propose and evaluate a
and evaluate a mechanism
evaluate a mechanism that
a mechanism that can
mechanism that can defend
that can defend against
symmetric case we have
can defend against this
case we have r
defend against this problem
whithout incurring large overheads
the approach that most
approach that most closely
that most closely relates
most closely relates to
closely relates to our
the expression is shown
relates to our work
expression is shown in
to our work is
is shown in equation
our work is the
work is the bar
is the bar gossip
the bar gossip protocol
which employs a tit
tat approach for encouraging
approach for encouraging nodes
for encouraging nodes to
encouraging nodes to contribute
given any value of
any value of q
a node only sends
value of q and
node only sends as
of q and mi
only sends as much
sends as much data
as much data to
much data to another
data to another node
to another node as
another node as it
node as it receives
as it receives back
it provides an elegant
provides an elegant solution
an elegant solution shown
elegant solution shown to
solution shown to tolerate
shown to tolerate both
the feasible range of
perspectives on optimistically replicated
feasible range of the
to tolerate both opportunistic
range of the infiltration
on optimistically replicated peer
of the infiltration rates
tolerate both opportunistic behavior
the infiltration rates is
both opportunistic behavior and
opportunistic behavior and other
behavior and other malicious
and other malicious attacks
software practice and experience
within this range ri
this range ri is
range ri is continuous
tat does present a
does present a few
present a few undesirable
a few undesirable requirements
and concave in x
the data source should
data source should ensure
source should ensure that
should ensure that packets
ensure that packets are
that packets are evenly
packets are evenly spread
are evenly spread across
evenly spread across the
spread across the system
across the system by
the system by sending
the optimal point for
system by sending data
optimal point for pool
by sending data to
sending data to a
data to a fixed
to a fixed proportion
a fixed proportion of
fixed proportion of nodes
and by sending different
by sending different packets
sending different packets to
different packets to different
packets to different nodes
it requires the source
requires the source and
the source and all
source and all nodes
and all nodes to
all nodes to have
nodes to have full
to have full membership
have full membership knowledge
since the function is
the function is concave
these restrictions affect scalability
function is concave the
restrictions affect scalability when
is concave the equation
affect scalability when the
concave the equation yields
scalability when the data
the equation yields a
when the data source
equation yields a single
the data source has
yields a single feasible
data source has bounded
a single feasible solution
source has bounded upload
software defined networks and
has bounded upload bandwidth
defined networks and gossip
which is a function
networks and gossip protocols
is a function of
to illustrate this problem
and gossip protocols robert
a function of the
gossip protocols robert soule
function of the attack
protocols robert soule ken
of the attack rates
we fixed the upload
robert soule ken birman
fixed the upload capacity
the attack rates of
soule ken birman nate
the upload capacity of
attack rates of the
upload capacity of a
ken birman nate foster
capacity of a data
rates of the other
birman nate foster university
of the other pools
of a data source
nate foster university of
a data source at
foster university of lugano
university of lugano cornell
of lugano cornell university
lugano cornell university cornell
mbps and simulated bar
cornell university cornell university
and simulated bar gossip
university cornell university the
simulated bar gossip when
cornell university the performance
bar gossip when streaming
university the performance of
the performance of data
center applications are critically
applications are critically dependent
are critically dependent on
critically dependent on the
dependent on the underlying
on the underlying network
informed prefetching and caching
kbps with increasing numbers
with increasing numbers of
increasing numbers of receivers
to find a symmetric
find a symmetric equilibrium
in proceedings of the
proceedings of the fifteenth
of the fifteenth acm
given the complexities associated
varied between one and
the complexities associated with
between one and thirty
complexities associated with management
one and thirty thousand
the fifteenth acm symposium
and thirty thousand nodes
fifteenth acm symposium on
acm symposium on operating
symposium on operating systems
networks today typically provide
on operating systems principles
today typically provide little
we compare its scalability
typically provide little more
compare its scalability against
provide little more than
its scalability against the
little more than best
scalability against the chainsaw
against the chainsaw protocol
effort packet delivery between
packet delivery between hosts
for which we fixed
the emergence of software
which we fixed the
we fixed the source
fixed the source s
the source s upload
source s upload bandwidth
s upload bandwidth to
has created an opportunity
and obtain a single
created an opportunity to
obtain a single feasible
a single feasible solution
an opportunity to build
opportunity to build more
to build more dynamic
build more dynamic networks
the equilibrium infiltration rate
more dynamic networks that
we present the average
dynamic networks that can
present the average and
equilibrium infiltration rate and
networks that can be
infiltration rate and the
that can be tailored
rate and the matching
can be tailored precisely
the average and minimum
be tailored precisely to
and the matching revenues
tailored precisely to the
average and minimum download
precisely to the needs
the matching revenues are
to the needs of
and minimum download rates
the needs of applications
matching revenues are shown
revenues are shown in
are shown in equation
as ratios of the
ratios of the stream
of the stream rate
existing solutions for monitoring
solutions for monitoring within
of both protocols when
for monitoring within sdns
both protocols when the
monitoring within sdns suffer
protocols when the number
within sdns suffer from
when the number of
sdns suffer from several
the number of nodes
suffer from several short
number of nodes is
of nodes is increased
either they are inaccurate
bar gossip is not
as in the two
gossip is not able
due to eventual consistency
is not able to
to eventual consistency of
not able to sustain
eventual consistency of architecture
able to sustain its
to sustain its performance
sustain its performance without
the revenue at the
its performance without scaling
revenue at the symmetric
performance without scaling the
at the symmetric equilibrium
without scaling the upload
the symmetric equilibrium is
scaling the upload capacity
symmetric equilibrium is inferior
the upload capacity of
equilibrium is inferior to
upload capacity of the
is inferior to the
capacity of the source
inferior to the no
of the source proportionally
the source proportionally with
source proportionally with the
proportionally with the size
with the size of
the size of the
size of the system
due to limitations of
design and implementation of
to limitations of current
and implementation of the
limitations of current hardware
implementation of the sun
of the sun network
the sun network file
sun network file system
chainsaw is able to
is able to scale
in proceedings of usenix
able to scale well
proceedings of usenix summer
to scale well even
of usenix summer conference
scale well even with
well even with a
even with a fixed
with a fixed lower
a fixed lower upload
fixed lower upload bandwidth
up our analysis addresses
lower upload bandwidth at
our analysis addresses the
upload bandwidth at the
or too costly to
bandwidth at the source
too costly to be
analysis addresses the eventual
costly to be practical
addresses the eventual revenue
to be practical at
the eventual revenue of
but cannot handle the
eventual revenue of the
be practical at scale
revenue of the pools
cannot handle the presence
handle the presence of
the presence of opportunistic
presence of opportunistic nodes
due to reliance on
assuming the mining difficulty
to reliance on switch
the mining difficulty is
reliance on switch forwarding
mining difficulty is set
on switch forwarding rules
we propose to use
switch forwarding rules and
propose to use auditing
forwarding rules and centralization
difficulty is set based
to use auditing to
is set based on
use auditing to encourage
set based on the
auditing to encourage data
based on the effective
on the effective mining
the effective mining power
not including mining power
including mining power used
streaming systems like chainsaw
mining power used for
power used for withholding
the evolution of coda
our auditing approach establishes
auditing approach establishes a
acm transactions on computer
we argue that gossip
transactions on computer systems
approach establishes a minimum
difficulty is updated only
argue that gossip protocols
is updated only periodically
establishes a minimum threshold
updated only periodically every
that gossip protocols offer
a minimum threshold for
gossip protocols offer an
minimum threshold for the
protocols offer an ideal
threshold for the amount
offer an ideal alternative
for the amount of
an ideal alternative for
the amount of data
ideal alternative for sdn
amount of data sent
alternative for sdn monitoring
of data sent by
data sent by any
sent by any node
by any node in
any node in the
node in the system
due to their scalability
to their scalability and
their scalability and resiliency
when mining power in
mining power in the
ignored the crucial monitoring
and removes nodes that
power in the system
removes nodes that upload
in the system is
the crucial monitoring component
the system is regularly
nodes that upload less
system is regularly increasing
crucial monitoring component that
that upload less data
monitoring component that aggregates
upload less data than
component that aggregates network
less data than the
that aggregates network and
which has been true
aggregates network and application
data than the threshold
network and application state
has been true for
been true for the
true for the majority
for the majority of
instead of relying on
the majority of bitcoin
of relying on a
and sends the events
relying on a tit
majority of bitcoin s
sends the events to
of bitcoin s history
the events to the
events to the controller
a complete system would
complete system would have
system would have a
would have a closed
have a closed loop
we focus on encouraging
focus on encouraging nodes
on encouraging nodes to
encouraging nodes to respect
nodes to respect the
continuously monitoring applications and
to respect the established
monitoring applications and the
respect the established protocol
applications and the network
no adjustment may be
adjustment may be necessary
nodes are forced to
are forced to provide
forced to provide accountable
to provide accountable information
then adjusting sdn policies
provide accountable information regarding
adjusting sdn policies to
if an attacker purchases
sdn policies to optimize
an attacker purchases new
accountable information regarding packets
policies to optimize the
attacker purchases new mining
to optimize the use
information regarding packets sent
optimize the use of
purchases new mining hardware
the use of resources
regarding packets sent to
new mining hardware and
packets sent to and
mining hardware and employs
sent to and received
hardware and employs it
to and received from
and employs it directly
and received from neighbors
employs it directly for
it directly for block
directly for block withholding
gossip protocols are an
determinism and asynchrony of
protocols are an ideal
and the auditing system
are an ideal choice
and asynchrony of set
an ideal choice for
asynchrony of set iterators
ideal choice for implementing
of set iterators to
this mining power is
set iterators to reduce
choice for implementing a
iterators to reduce aggregrate
for implementing a wide
to reduce aggregrate file
implementing a wide range
the auditing system is
a wide range monitoring
mining power is never
wide range monitoring tasks
auditing system is responsible
reduce aggregrate file i
system is responsible for
power is never included
is responsible for detecting
is never included in
with a gossip protocol
responsible for detecting and
never included in the
for detecting and removing
included in the difficulty
detecting and removing misbehaving
in the difficulty calculation
each node exchanges information
and removing misbehaving nodes
node exchanges information with
the difficulty calculation the
exchanges information with a
in proceedings of the
information with a randomly
difficulty calculation the system
with a randomly selected
notice that identifying the
a randomly selected peer
that identifying the misbehaving
randomly selected peer at
identifying the misbehaving nodes
selected peer at periodic
calculation the system is
peer at periodic intervals
proceedings of the sixteenth
the system is never
the misbehaving nodes is
system is never aware
misbehaving nodes is not
is never aware of
of the sixteenth acm
never aware of it
because it is based
the sixteenth acm symposium
nodes is not a
sixteenth acm symposium on
is not a trivial
acm symposium on operating
it is based on
symposium on operating system
the difficulty is therefore
on operating system principles
is based on periodic
not a trivial task
based on periodic peer
difficulty is therefore already
is therefore already correctly
therefore already correctly calculated
already correctly calculated and
since there is no
correctly calculated and the
there is no fixed
calculated and the attack
is no fixed minimum
and the attack is
no fixed minimum amount
the attack is profitable
fixed minimum amount of
gossip s network load
minimum amount of data
s network load tends
amount of data that
network load tends to
of data that nodes
load tends to be
data that nodes should
tends to be well
attack is profitable immediately
that nodes should contribute
nodes should contribute to
should contribute to the
contribute to the system
scaling linearly with system
if we assume a
linearly with system size
if the mining power
with system size and
we assume a model
the mining power is
assume a model where
system size and not
a model where misbehaving
size and not prone
mining power is static
model where misbehaving nodes
and not prone to
where misbehaving nodes simply
not prone to reactive
misbehaving nodes simply did
prone to reactive feedback
nodes simply did not
simply did not upload
did not upload any
the attack becomes profitable
not upload any data
attack becomes profitable only
becomes profitable only after
profitable only after the
only after the bitcoin
because peers are selected
detecting them would be
peers are selected randomly
after the bitcoin system
them would be an
the bitcoin system has
would be an easier
be an easier task
bitcoin system has normalized
no single node is
single node is indispensable
system has normalized the
has normalized the revenues
normalized the revenues by
the revenues by adjusting
so tools built on
revenues by adjusting difficulty
tools built on gossip
once we assume that
built on gossip are
we assume that misbehaving
on gossip are extremely
assume that misbehaving nodes
gossip are extremely tolerant
that misbehaving nodes may
are extremely tolerant to
misbehaving nodes may adjust
extremely tolerant to disruptions
nodes may adjust their
tolerant to disruptions and
the revenue of an
to disruptions and able
may adjust their contribution
revenue of an attacking
disruptions and able to
adjust their contribution level
and able to rapidly
of an attacking pool
able to rapidly recover
their contribution level based
an attacking pool is
to rapidly recover from
contribution level based on
rapidly recover from failures
attacking pool is reduced
level based on the
file system usage in
based on the policy
system usage in windows
on the policy used
usage in windows nt
the policy used by
pool is reduced due
policy used by an
although individual gossip protocols
used by an auditing
is reduced due to
by an auditing system
individual gossip protocols are
reduced due to the
gossip protocols are typically
due to the reduction
protocols are typically very
to the reduction in
are typically very simple
the reduction in block
a more elaborate approach
reduction in block generation
more elaborate approach is
in block generation of
elaborate approach is required
block generation of both
composing multiple protocols can
generation of both the
multiple protocols can lead
of both the attacking
protocols can lead to
in proceedings of the
this paper presents and
can lead to complex
both the attacking and
lead to complex interactions
paper presents and evaluates
to complex interactions with
the attacking and attacked
presents and evaluates an
complex interactions with unpredictable
proceedings of the seventeenth
and evaluates an auditing
attacking and attacked pools
of the seventeenth acm
interactions with unpredictable behavior
the seventeenth acm symposium
evaluates an auditing model
seventeenth acm symposium on
acm symposium on operating
an auditing model based
symposium on operating systems
on operating systems principles
we designed the mica
auditing model based on
model based on sampling
pool knowledge and r
based on sampling the
on sampling the system
sampling the system and
the system and using
system and using the
and using the sampled
using the sampled information
framework to address this
the sampled information to
to address this problem
sampled information to build
information to build a
to build a global
build a global view
a global view of
mica allows programmers to
global view of how
allows programmers to describe
view of how the
programmers to describe gossip
of how the system
to describe gossip protocols
how the system is
describe gossip protocols with
the system is currently
gossip protocols with a
system is currently behaving
protocols with a small
auditors employ strategies to
and compose the protocols
employ strategies to identify
compose the protocols with
strategies to identify the
the protocols with a
to identify the misbehaving
protocols with a rich
identify the misbehaving nodes
with a rich collection
the misbehaving nodes that
a rich collection of
misbehaving nodes that should
rich collection of operators
nodes that should be
collection of operators to
that should be punished
of operators to create
operators to create sophisticated
to create sophisticated protocols
create sophisticated protocols in
sophisticated protocols in a
the paper is organized
protocols in a modular
paper is organized as
in a modular style
is organized as follows
mica ensures that the
ensures that the composed
that the composed protocols
the composed protocols maintain
composed protocols maintain strong
we state the exact
state the exact problem
the exact problem that
exact problem that we
robustness and convergence guarantees
problem that we aim
that we aim to
we aim to solve
aim to solve and
in our evaluation of
to solve and the
arla a free afs
solve and the assumptions
a free afs client
and the assumptions considered
our evaluation of mica
the assumptions considered in
assumptions considered in this
considered in this work
in proceedings of the
we have built monitoring
have built monitoring tasks
built monitoring tasks that
monitoring tasks that maintain
tasks that maintain a
that maintain a predictable
maintain a predictable performance
we review the pull
even when hundreds of
when hundreds of separate
hundreds of separate instances
of separate instances are
based streaming protocol employed
separate instances are deployed
streaming protocol employed in
instances are deployed on
protocol employed in our
are deployed on the
employed in our system
deployed on the same
on the same machines
followed by a description
by a description of
a description of our
description of our novel
of our novel auditing
our novel auditing approach
novel auditing approach in
auditing approach in section
a control program reacts
control program reacts to
program reacts to network
reacts to network events
and updates forwarding rules
updates forwarding rules on
forwarding rules on switches
we evaluate the proposed
rules on switches to
evaluate the proposed approach
on switches to manage
switches to manage packets
we then discuss the
then discuss the costs
building on this interface
discuss the costs of
the costs of auditing
our work on merlin
and briefly describe how
briefly describe how to
describe how to extend
how to extend our
to extend our model
extend our model for
our model for heterogeneous
model for heterogeneous systems
is novel among network
novel among network programming
among network programming languages
network programming languages in
programming languages in that
languages in that it
in that it determines
that it determines allocations
it determines allocations of
determines allocations of limited
allocations of limited network
we present related work
present related work in
related work in section
volume leases for consistency
wide resources such as
leases for consistency in
resources such as bandwidth
for consistency in large
such as bandwidth and
as bandwidth and paths
and conclude in section
we have used merlin
have used merlin to
ieee transactions on knowledge
used merlin to improve
transactions on knowledge and
merlin to improve the
on knowledge and data
and solving we obtain
to improve the latency
solving we obtain a
knowledge and data engineering
we obtain a single
improve the latency of
obtain a single expression
the latency of hadoop
a single expression for
latency of hadoop jobs
single expression for any
of hadoop jobs running
problem statement our approach
hadoop jobs running in
expression for any ri
jobs running in the
statement our approach focuses
running in the presence
our approach focuses on
in the presence of
approach focuses on a
the presence of udp
focuses on a target
since in the in
presence of udp background
in the in order
on a target streaming
the in order to
of udp background traffic
in order to choose
a target streaming system
order to choose its
target streaming system consisting
to choose its optimal
streaming system consisting of
choose its optimal infiltration
system consisting of one
or prioritize classes of
consisting of one data
prioritize classes of traffic
of one data source
its optimal infiltration rate
classes of traffic used
of traffic used for
traffic used for state
a pool has to
pool has to know
machine replication in fault
has to know the
to know the rate
know the rate at
the rate at which
rate at which it
at which it is
which it is attacked
which disseminates data at
disseminates data at a
data at a fixed
and the revenue density
at a fixed rate
the revenue density of
a fixed rate to
revenue density of potential
fixed rate to a
density of potential victim
rate to a dynamic
of potential victim pools
to a dynamic set
a dynamic set of
dynamic set of receivers
these experiments demonstrate that
experiments demonstrate that an
demonstrate that an sdn
a pool can estimate
that an sdn framework
the source has limited
pool can estimate the
source has limited upload
has limited upload bandwidth
can estimate the rate
with the correct information
estimate the rate with
the correct information as
the rate with which
correct information as input
and hence can only
hence can only send
rate with which it
can only send data
only send data directly
with which it is
send data directly to
which it is attacked
can provide automated network
data directly to a
it is attacked by
directly to a small
provide automated network management
is attacked by comparing
to a small subset
attacked by comparing the
a small subset of
automated network management customized
small subset of interested
by comparing the rates
network management customized to
subset of interested receivers
management customized to the
comparing the rates of
customized to the needs
the rates of partial
to the needs of
rates of partial and
the needs of resident
of partial and full
needs of resident distributed
participating nodes are consequently
partial and full proofs
of resident distributed applications
and full proofs of
nodes are consequently required
full proofs of work
are consequently required to
proofs of work it
consequently required to forward
of work it receives
required to forward packets
work it receives from
while the merlin compiler
it receives from its
to forward packets to
receives from its miners
the merlin compiler generates
forward packets to their
merlin compiler generates static
packets to their neighbors
compiler generates static network
generates static network configurations
as explained in section
explained in section ii
helping disseminate all packets
disseminate all packets across
merlin uses a small
all packets across the
packets across the system
runtime component to allow
component to allow for
to allow for dynamic
the streamed data should
allow for dynamic adaptation
in order to estimate
streamed data should be
order to estimate the
data should be received
to estimate the revenue
should be received by
estimate the revenue densities
be received by all
the revenue densities of
received by all nodes
revenue densities of the
by all nodes within
based approach allows this
all nodes within a
approach allows this adaptation
densities of the other
allows this adaptation to
of the other pools
this adaptation to happen
nodes within a fixed
adaptation to happen safely
within a fixed latency
a fixed latency from
fixed latency from the
a pool can use
latency from the source
pool can use one
by providing policy language
can use one of
from the source s
use one of two
providing policy language constructs
one of two methods
the source s original
policy language constructs that
source s original transmission
language constructs that can
constructs that can be
that can be automatically
can be automatically verified
even in the presence
implicit in the design
in the presence of
in the design of
the presence of opportunistic
the design of this
presence of opportunistic nodes
design of this runtime
of this runtime component
and sdn networks in
sdn networks in general
we first assume a
first assume a system
assume a system in
a system in which
system in which all
is the notion that
in which all nodes
the notion that network
notion that network events
that network events are
network events are generated
events are generated in
are generated in response
generated in response to
have similar upload and
in response to the
similar upload and download
response to the situational
upload and download bandwidths
to the situational status
the situational status culled
situational status culled from
status culled from a
culled from a wide
from a wide range
a wide range of
wide range of sources
we briefly discuss how
briefly discuss how to
discuss how to extend
how to extend our
to extend our model
extend our model to
our model to work
model to work in
to work in heterogeneous
work in heterogeneous scenarios
we assume that malicious
assume that malicious nodes
that malicious nodes exhibit
packet and drop rates
malicious nodes exhibit byzantine
nodes exhibit byzantine behavior
while correct nodes follow
correct nodes follow the
nodes follow the protocol
follow the protocol as
the protocol as defined
requesting data as needed
data as needed and
as needed and sending
needed and sending data
and sending data as
sending data as requested
data as requested from
as requested from them
altrustic nodes are a
nodes are a subgroup
are a subgroup of
a subgroup of correct
subgroup of correct nodes
of correct nodes that
correct nodes that are
nodes that are willing
that are willing to
are willing to upload
willing to upload more
to upload more data
upload more data than
more data than required
data than required from
than required from them
we employ the term
employ the term opportunistic
the term opportunistic to
term opportunistic to refer
opportunistic to refer to
to refer to a
refer to a subgroup
to a subgroup of
a subgroup of byzantine
user preferences for a
subgroup of byzantine nodes
preferences for a particular
for a particular network
of byzantine nodes that
byzantine nodes that attempt
nodes that attempt to
that attempt to give
attempt to give less
to give less data
give less data than
less data than they
data than they would
than they would if
they would if they
would if they behaved
if they behaved as
they behaved as correct
behaved as correct nodes
with the intention of
the intention of obtaining
intention of obtaining as
of obtaining as much
obtaining as much data
as much data as
much data as possible
data as possible at
as possible at least
possible at least feasible
at least feasible cost
these may employ a
may employ a simple
employ a simple strategy
such as refuse to
as refuse to contribute
refuse to contribute any
to contribute any upload
much of this information
contribute any upload resources
of this information must
this information must be
information must be created
must be created and
be created and updated
or a more elaborate
created and updated dynamically
a more elaborate strategy
more elaborate strategy that
elaborate strategy that allows
strategy that allows them
that allows them to
allows them to cheat
them to cheat without
to cheat without being
existing sdn frameworks have
cheat without being easily
sdn frameworks have largely
without being easily detected
frameworks have largely closing
have largely closing the
largely closing the loop
notice that our model
that our model diverges
to accommodate the ever
our model diverges from
model diverges from the
diverges from the one
from the one used
the one used in
growing demands of cloud
one used in bar
demands of cloud and
used in bar gossip
of cloud and data
cloud and data center
and data center application
networks will need to
will need to become
in which nodes are
need to become more
which nodes are classified
to become more flexible
nodes are classified as
become more flexible and
are classified as byzantine
more flexible and dynamic
as networks continue to
networks continue to grow
continue to grow in
to grow in complexity
it will become increasingly
will become increasingly difficult
expression for ri in
rational nodes attempt to
become increasingly difficult for
for ri in a
nodes attempt to maximize
ri in a system
increasingly difficult for network
in a system with
attempt to maximize their
a system with pools
difficult for network operators
system with pools of
to maximize their utility
for network operators to
with pools of equal
maximize their utility while
pools of equal size
network operators to provide
their utility while still
operators to provide this
utility while still following
to provide this flexibility
while still following the
provide this flexibility without
still following the defined
this flexibility without the
following the defined protocol
flexibility without the support
without the support of
the support of proper
support of proper tools
of proper tools and
our model is actually
proper tools and infrastructure
model is actually less
is actually less lenient
nodes employing strategies to
employing strategies to maximize
strategies to maximize their
to maximize their utility
maximize their utility are
their utility are classified
utility are classified as
provide both the control
are classified as byzantine
both the control and
the control and monitoring
control and monitoring components
so that we can
and monitoring components necessary
that we can build
monitoring components necessary to
we can build a
components necessary to automatically
can build a practical
necessary to automatically adapt
build a practical punishment
to automatically adapt the
automatically adapt the network
adapt the network to
the network to the
network to the needs
based system in which
to the needs of
system in which any
the needs of the
in which any node
needs of the applications
which any node not
any node not contributing
node not contributing its
not contributing its fair
because both systems use
contributing its fair share
both systems use a
its fair share of
systems use a language
fair share of data
share of data may
of data may be
data may be expelled
may be expelled from
be expelled from the
expelled from the system
they have rigorous semantics
have rigorous semantics that
rigorous semantics that can
semantics that can be
that can be formally
throughout the paper we
can be formally defined
the paper we use
paper we use the
we use the terms
use the terms upload
the terms upload factor
terms upload factor and
they provide predictable operational
upload factor and download
provide predictable operational behavior
factor and download factor
and download factor to
download factor to refer
factor to refer to
to refer to the
refer to the ratio
q mi q mi
to the ratio between
they allow for the
the ratio between an
allow for the rigorous
ratio between an upload
for the rigorous expression
between an upload or
the rigorous expression of
an upload or download
rigorous expression of algorithms
upload or download rate
expression of algorithms for
or download rate and
of algorithms for monitoring
download rate and the
algorithms for monitoring or
rate and the original
for monitoring or managing
and the original stream
monitoring or managing sdn
the original stream rate
or managing sdn networks
given a stream rate
a stream rate of
a download rate of
kbps corresponds to a
corresponds to a download
to a download factor
a download factor of
this work was supported
by a grant from
a grant from the
grant from the darpa
from the darpa mrc
the darpa mrc program
streaming system model our
system model our auditing
model our auditing approach
our auditing approach is
auditing approach is used
approach is used over
is used over the
used over the chainsaw
over the chainsaw protocol
all nodes participating in
nodes participating in the
participating in the system
in the system are
the system are organized
system are organized into
are organized into a
organized into a fully
into a fully connected
a fully connected mesh
fully connected mesh overlay
online measurement of large
measurement of large traffic
of large traffic aggregates
large traffic aggregates on
where each node has
traffic aggregates on commodity
each node has the
aggregates on commodity switches
node has the same
has the same number
the same number of
same number of neighbors
the source is randomly
source is randomly connected
is randomly connected to
randomly connected to a
connected to a small
to a small subset
a small subset of
small subset of the
subset of the nodes
q symmetric equilibrium values
symmetric equilibrium values for
the streaming process starts
equilibrium values for a
streaming process starts at
values for a system
process starts at the
for a system of
starts at the source
a system of q
system of q pools
of q pools of
q pools of equal
pools of equal sizes
which breaks the data
breaks the data stream
the data stream into
often publish this data
data stream into packets
publish this data to
stream into packets and
this data to demonstrate
into packets and sends
data to demonstrate their
packets and sends notifications
to demonstrate their honesty
and sends notifications to
demonstrate their honesty to
sends notifications to its
their honesty to their
notifications to its neighbors
honesty to their miners
to its neighbors as
its neighbors as soon
neighbors as soon as
as soon as it
soon as it has
as it has packets
it has packets to
has packets to disseminate
these notifications are small
notifications are small messages
are small messages used
small messages used only
messages used only to
used only to inform
only to inform neighbors
to inform neighbors of
inform neighbors of the
neighbors of the availability
of the availability of
the availability of new
availability of new packets
based on the received
on the received notifications
each node requests missing
node requests missing packets
a compositional architecture for
compositional architecture for gossip
architecture for gossip protocols
and the source satisfies
the source satisfies as
source satisfies as many
satisfies as many requests
as many requests as
many requests as allowed
requests as allowed by
as allowed by its
allowed by its upload
by its upload capacity
a pool can infiltrate
with chainsaw the upload
pool can infiltrate each
chainsaw the upload capacity
can infiltrate each of
the upload capacity of
infiltrate each of the
upload capacity of the
each of the other
capacity of the source
of the other pools
of the source does
like it or not
the source does not
the other pools with
source does not need
other pools with some
does not need to
pools with some nominal
not need to increase
web services are distributed
with some nominal probing
need to increase with
services are distributed objects
to increase with the
some nominal probing mining
increase with the size
with the size of
nominal probing mining power
the size of the
size of the system
probing mining power and
mining power and measure
power and measure the
and measure the revenue
measure the revenue density
even an upload capacity
the revenue density directly
an upload capacity of
cornell university within the
revenue density directly by
upload capacity of twice
university within the community
density directly by monitoring
capacity of twice the
directly by monitoring the
within the community developing
by monitoring the probe
of twice the stream
monitoring the probe s
the community developing the
the probe s rewards
twice the stream rate
probe s rewards from
community developing the web
s rewards from the
the stream rate is
rewards from the pool
developing the web services
stream rate is sufficient
the web services architecture
rate is sufficient to
web services architecture and
is sufficient to ensure
services architecture and products
sufficient to ensure that
to ensure that the
ensure that the system
that the system performs
the system performs and
block withholding recycling we
system performs and scales
an increasingly schizophrenic message
performs and scales well
withholding recycling we assume
increasingly schizophrenic message is
recycling we assume that
schizophrenic message is emerging
we assume that the
assume that the infiltrating
as nodes receive packets
that the infiltrating miners
the infiltrating miners are
infiltrating miners are loyal
marketing materials assure us
miners are loyal to
materials assure us that
they mimic the role
are loyal to the
mimic the role of
loyal to the attacker
the role of the
assure us that web
role of the source
us that web services
that web services are
web services are a
services are a breakthrough
sending notifications to their
notifications to their own
to their own neighbors
some of the pool
their own neighbors in
of the pool s
managing the network with
own neighbors in the
the network with merlin
the pool s members
offering unparalleled interoperability and
pool s members may
unparalleled interoperability and comprehensive
s members may be
neighbors in the mesh
members may be disloyal
interoperability and comprehensive standards
may be disloyal infiltrators
and comprehensive standards for
comprehensive standards for associated
standards for associated technologies
allowing packets to be
packets to be propagated
when sending disloyal miners
to be propagated through
sending disloyal miners to
be propagated through the
disloyal miners to perform
propagated through the system
miners to perform block
to perform block withholding
they portray web services
perform block withholding at
portray web services as
block withholding at other
web services as a
withholding at other pools
services as a seamless
as a seamless interconnection
based approach to acquisition
a seamless interconnection layer
approach to acquisition of
seamless interconnection layer that
to acquisition of packets
interconnection layer that will
an attacker takes a
layer that will propel
attacker takes a significant
that will propel computer
takes a significant risk
computer commerce to a
commerce to a previously
to a previously inaccessible
a previously inaccessible level
can use a loyal
provides some resilience to
use a loyal miner
some resilience to failure
a loyal miner w
resilience to failure or
loyal miner w to
to failure or malicious
miner w to infiltrate
and they use language
w to infiltrate pool
failure or malicious behavior
they use language evocative
use language evocative of
language evocative of marketing
evocative of marketing for
of marketing for distributed
since a participant will
marketing for distributed object
a participant will have
for distributed object middleware
participant will have multiple
will have multiple possible
have multiple possible sources
multiple possible sources for
possible sources for each
technologists are sending a
sources for each packet
are sending a somewhat
sending a somewhat different
thinking the miner is
a somewhat different message
the miner is loyal
miner is loyal to
is loyal to it
the mesh overlay defines
mesh overlay defines a
overlay defines a predetermined
defines a predetermined set
a predetermined set of
might use it to
predetermined set of neighbors
use it to attack
set of neighbors for
it to attack pool
in an essay entitled
of neighbors for each
an essay entitled web
neighbors for each peer
essay entitled web services
entitled web services are
web services are not
services are not distributed
are not distributed objects
the miner m can
which also makes it
miner m can perform
m can perform honest
also makes it hard
can perform honest mining
werner vogels argues that
perform honest mining for
makes it hard for
honest mining for pool
vogels argues that web
it hard for malicious
argues that web services
hard for malicious peers
that web services will
for malicious peers to
web services will work
malicious peers to round
services will work well
peers to round up
rather than withhold its
will work well for
than withhold its blocks
to round up on
a language for provisioning
work well for important
language for provisioning network
round up on individual
for provisioning network resources
well for important classes
and not return any
up on individual peers
not return any revenue
for important classes of
on individual peers since
return any revenue to
individual peers since attackers
important classes of applications
peers since attackers lack
any revenue to pool
since attackers lack a
attackers lack a deterministic
lack a deterministic means
but he also cites
a deterministic means of
he also cites significant
deterministic means of acquiring
also cites significant limits
means of acquiring control
of acquiring control of
acquiring control of all
control of all of
of all of its
as vogels sees it
it will take its
all of its neighbors
will take its share
take its share of
its share of pool
the architecture is so
architecture is so centered
is so centered on
all nodes with exception
so centered on document
nodes with exception of
centered on document exchange
with exception of the
exception of the source
which thinks the miner
of the source have
thinks the miner is
the source have a
the miner is loyal
and at its core
miner is loyal to
source have a fixed
is loyal to it
at its core is
have a fixed upper
its core is so
a fixed upper limit
core is so simple
fixed upper limit on
upper limit on their
and deliver it back
limit on their upload
deliver it back to
on their upload contribution
that many features taken
it back to pool
many features taken for
features taken for granted
taken for granted in
for granted in object
oriented systems are fundamentally
to avoid such a
systems are fundamentally lacking
avoid such a risk
examples include dynamic object
a pool needs a
include dynamic object creation
pool needs a sufficient
dynamic object creation and
needs a sufficient number
object creation and garbage
software defined traffic measurement
creation and garbage collection
defined traffic measurement with
a sufficient number of
traffic measurement with opensketch
sufficient number of verified
times the stream rate
number of verified miners
of verified miners miners
verified miners miners that
miners miners that it
miners that it knows
dynamically created object references
that it knows to
it knows to be
knows to be loyal
defined by the protocol
and a variety of
a variety of reliability
variety of reliability and
of reliability and transactional
reliability and transactional mechanisms
the optimal infiltration rate
this upper limit is
optimal infiltration rate may
upper limit is not
infiltration rate may be
limit is not respected
rate may be as
is not respected by
may be as high
not respected by opportunistic
be as high as
respected by opportunistic nodes
who attempt to reduce
attempt to reduce it
to reduce it with
reduce it with the
it with the goal
both perspectives can t
with the goal of
perspectives can t be
of the pool size
can t be correct
the goal of uploading
goal of uploading less
of uploading less data
but this is only
it s easy to
this is only in
s easy to see
is only in extreme
easy to see how
on the course of
to see how this
only in extreme cases
see how this situation
the course of a
how this situation arose
in extreme cases when
course of a streaming
extreme cases when pools
of a streaming session
cases when pools are
when pools are large
web services are the
services are the most
each node stores packets
are the most recent
for practical pool sizes
the most recent in
node stores packets and
most recent in a
stores packets and forwards
recent in a long
packets and forwards them
in a long series
and forwards them to
a long series of
forwards them to other
long series of object
them to other peers
a pool may need
series of object oriented
pool may need up
to other peers only
may need up to
of object oriented interoperability
other peers only while
object oriented interoperability platforms
peers only while the
only while the packet
while the packet is
the packet is within
packet is within its
and mixes ideas from
is within its availability
mixes ideas from corba
within its availability window
of its mining power
its mining power for
usually spanning a few
mining power for infiltration
spanning a few seconds
each node also maintains
node also maintains an
also maintains an interest
maintains an interest window
while exploiting xml and
pools typically have loyal
exploiting xml and other
xml and other web
typically have loyal mining
have loyal mining power
which represents the set
loyal mining power either
represents the set of
mining power either run
the set of packets
power either run directly
set of packets in
either run directly by
of packets in which
developers using popular middleware
packets in which the
run directly by the
using popular middleware platforms
in which the peer
directly by the pool
which the peer is
popular middleware platforms can
the peer is currently
by the pool owners
peer is currently interested
middleware platforms can transform
the pool owners or
platforms can transform a
pool owners or sold
can transform a program
owners or sold as
transform a program object
or sold as a
nodes choose packets to
a program object into
sold as a service
choose packets to request
program object into a
as a service but
object into a web
packets to request from
into a web services
a service but run
a web services object
service but run on
to request from each
but run on the
request from each of
run on the pool
from each of its
on the pool owners
each of its neighbors
the pool owners hardware
or access a remote
access a remote ws
a remote ws object
respecting a maximum limit
a maximum limit l
at the touch of
maximum limit l on
the touch of a
limit l on the
touch of a button
l on the number
on the number of
the number of outstanding
number of outstanding requests
of outstanding requests to
performance leaves something to
outstanding requests to each
leaves something to be
something to be desired
but computers and networks
computers and networks have
and networks have become
networks have become astonishingly
have become astonishingly fast
major application providers are
application providers are planning
providers are planning to
are planning to offer
planning to offer ws
to offer ws interfaces
offer ws interfaces to
ws interfaces to their
interfaces to their products
however the size of
the size of this
size of this mining
of this mining power
so it makes perfect
this mining power is
it makes perfect sense
mining power is considered
makes perfect sense that
power is considered a
perfect sense that the
is considered a trade
sense that the marketing
considered a trade secret
that the marketing community
a trade secret and
the marketing community would
trade secret and is
marketing community would feel
secret and is not
community would feel that
and is not published
would feel that finally
they ve reached the
ve reached the promised
reached the promised land
countermeasures as in the
as in the case
in the case of
the case of classical
case of classical block
of classical block withholding
classical block withholding explained
block withholding explained in
withholding explained in section
explained in section ii
has an understandable emphasis
an understandable emphasis on
understandable emphasis on facts
emphasis on facts on
a pool might detect
on facts on the
pool might detect that
facts on the ground
might detect that it
detect that it is
on the ground and
that it is being
it is being attacked
the ground and the
ground and the vogels
and the vogels essay
the one issue that
the vogels essay reflects
but cannot detect which
one issue that unites
cannot detect which of
vogels essay reflects the
detect which of its
issue that unites almost
which of its miners
essay reflects the realities
of its miners is
that unites almost all
its miners is the
reflects the realities of
miners is the attacker
unites almost all approaches
the realities of an
almost all approaches to
realities of an architecture
all approaches to distributed
of an architecture focused
therefore a pool cannot
approaches to distributed computing
a pool cannot block
an architecture focused at
to distributed computing is
pool cannot block or
architecture focused at its
cannot block or punish
distributed computing is the
block or punish withholding
focused at its core
computing is the need
or punish withholding miners
at its core on
is the need to
its core on using
the need to know
core on using document
need to know whether
on using document exchange
to know whether certain
using document exchange to
know whether certain components
document exchange to access
whether certain components in
various techniques can be
exchange to access backend
techniques can be used
certain components in the
can be used to
to access backend servers
be used to encourage
components in the system
used to encourage miners
in the system have
to encourage miners to
the system have failed
encourage miners to submit
system have failed or
miners to submit full
have failed or are
this core has been
failed or are otherwise
to submit full blocks
or are otherwise unavailable
core has been extended
has been extended with
been extended with such
extended with such mechanisms
a pool can pay
with such mechanisms as
pool can pay a
when designing and building
can pay a bonus
such mechanisms as rpc
pay a bonus for
mechanisms as rpc and
a bonus for submitting
as rpc and asynchronous
designing and building systems
bonus for submitting a
rpc and asynchronous messaging
for submitting a full
and building systems that
submitting a full proof
building systems that need
a full proof of
systems that need to
full proof of work
that need to function
need to function at
to function at a
function at a global
at a global scale
this would increase the
would increase the revenue
increase the revenue of
failure management needs to
the revenue of the
management needs to be
revenue of the miner
needs to be considered
of the miner that
to be considered a
a variety of roll
be considered a fundamental
upload factor download factor
considered a fundamental building
the miner that found
a fundamental building block
miner that found a
forward and rendezvous options
that found a block
found a block while
a block while reducing
this paper describes the
block while reducing the
paper describes the development
while reducing the revenue
describes the development of
reducing the revenue of
the development of a
the revenue of the
development of a system
revenue of the other
but the primary usage
of the other miners
the primary usage case
the other miners from
primary usage case remains
independent failure management service
other miners from this
usage case remains that
miners from this block
case remains that of
remains that of a
that of a client
which allows systems and
of a client sending
allows systems and applications
a client sending documents
while the average revenue
client sending documents to
the average revenue of
sending documents to a
systems and applications to
documents to a back
average revenue of each
and applications to incorporate
revenue of each miner
applications to incorporate accurate
of each miner would
to incorporate accurate detection
each miner would stay
incorporate accurate detection of
miner would stay the
end service in a
would stay the same
accurate detection of failed
service in a client
detection of failed processes
small miners will suffer
miners will suffer from
will suffer from higher
suffer from higher variance
from higher variance in
higher variance in revenue
without the need for
the need for making
need for making compromises
the assumption is that
for making compromises in
assumption is that the
another approach is to
making compromises in their
is that the application
compromises in their particular
approach is to introduce
in their particular design
that the application can
is to introduce a
the application can tolerate
to introduce a joining
application can tolerate substantial
introduce a joining fee
can tolerate substantial delay
a joining fee by
tolerate substantial delay before
joining fee by paying
substantial delay before a
with the advent of
delay before a response
the advent of ubiquitous
before a response arrives
fee by paying new
by paying new miners
paying new miners less
new miners less for
and mechanisms capable of
miners less for their
mechanisms capable of introducing
less for their work
capable of introducing delays
for their work until
of introducing delays are
their work until they
introducing delays are scattered
work until they have
delays are scattered throughout
it is becoming clear
are scattered throughout the
until they have established
scattered throughout the architecture
is becoming clear that
they have established a
becoming clear that the
have established a reputation
clear that the systems
established a reputation with
that the systems that
a reputation with the
the systems that are
reputation with the pool
systems that are used
the more basic assumption
that are used today
are used today in
more basic assumption is
used today in local
basic assumption is that
miners that seek flexibility
assumption is that it
that seek flexibility may
is that it all
seek flexibility may not
that it all boils
flexibility may not accept
can not simply be
may not accept this
it all boils down
not accept this policy
not simply be employed
accept this policy and
all boils down to
this policy and choose
simply be employed in
policy and choose another
boils down to moving
be employed in their
and choose another pool
down to moving documents
employed in their existing
to moving documents around
in their existing form
moving documents around whereas
their existing form or
documents around whereas the
existing form or trivially
around whereas the most
form or trivially converted
whereas the most basic
or trivially converted for
the pool can use
trivially converted for wide
the most basic assumption
pool can use a
most basic assumption of
can use a honeypot
basic assumption of a
use a honeypot trap
assumption of a distributed
a honeypot trap by
of a distributed object
honeypot trap by sending
a distributed object system
trap by sending the
distributed object system is
by sending the miners
object system is that
sending the miners tasks
system is that the
the miners tasks which
is that the world
miners tasks which it
that the world consists
tasks which it knows
the world consists of
whatever form such systems
which it knows will
form such systems may
world consists of programs
such systems may take
it knows will result
consists of programs and
knows will result in
of programs and data
systems may take in
will result in a
may take in the
result in a full
take in the future
in a full proof
a full proof of
active and passive objects
full proof of work
whether they are replicated
they are replicated databases
are replicated databases of
the gist of vogel
replicated databases of hyper
gist of vogel s
of vogel s essay
vogel s essay is
s essay is that
essay is that even
is that even with
that even with all
even with all the
with all the contemplated
all the contemplated extensions
view or virtual synchronous
or virtual synchronous groups
if a miner fails
virtual synchronous groups or
web services are deeply
synchronous groups or agents
a miner fails to
groups or agents employing
services are deeply mismatched
or agents employing lazy
miner fails to submit
agents employing lazy consistency
are deeply mismatched with
employing lazy consistency schemes
fails to submit the
maximum upload factor figure
deeply mismatched with distributed
to submit the full
mismatched with distributed object
submit the full proof
one of the key
the full proof of
with distributed object computing
full proof of work
of the key problems
proof of work it
the key problems that
of work it is
download and upload factors
work it is tagged
key problems that needs
and upload factors of
problems that needs to
it is tagged as
that needs to be
is tagged as an
needs to be addressed
tagged as an attacker
the dilemma underlying the
upload factors of nodes
dilemma underlying the debate
factors of nodes in
underlying the debate is
of nodes in an
is that of the
nodes in an ideal
that of the detection
in an ideal system
of the detection and
an ideal system where
the detection and handling
ideal system where all
detection and handling of
system where all nodes
and handling of faulty
where all nodes behave
handling of faulty components
all nodes behave correctly
the debate is that
to prevent the attacker
debate is that the
prevent the attacker from
is that the platforms
the attacker from learning
that the platforms one
attacker from learning them
the platforms one uses
platforms one uses to
one uses to create
building distributed systems and
uses to create wscompatible
this limit not only
distributed systems and applications
to create wscompatible objects
the honeypot tasks have
create wscompatible objects impose
systems and applications today
wscompatible objects impose no
honeypot tasks have to
objects impose no such
and applications today is
impose no such restrictions
tasks have to be
applications today is done
have to be regularly
limit not only improves
to be regularly refreshed
today is done using
not only improves the
there is nothing in
only improves the general
is nothing in j
improves the general flow
is done using a
the general flow of
done using a variety
general flow of packets
using a variety of
a variety of systems
pools can also incorporate
variety of systems ranging
can also incorporate out
of systems ranging from
also incorporate out of
net that warns a
incorporate out of band
that warns a user
out of band mechanisms
systems ranging from the
of band mechanisms to
warns a user that
band mechanisms to deter
a user that an
mechanisms to deter attacks
user that an intended
but also makes it
that an intended use
ranging from the bare
an intended use of
from the bare bone
intended use of the
such as verifying the
the bare bone protocols
as verifying the identity
use of the architecture
verifying the identity of
of the architecture may
the identity of miners
the architecture may be
also makes it harder
bare bone protocols interfaces
makes it harder for
architecture may be inappropriate
it harder for malicious
bone protocols interfaces like
harder for malicious peers
protocols interfaces like bsd
for malicious peers to
interfaces like bsd sockets
identity of miners or
like bsd sockets and
malicious peers to overrequest
of miners or using
peers to overrequest packets
miners or using trusted
bsd sockets and the
much of the excitement
sockets and the tdi
to overrequest packets from
or using trusted computing
overrequest packets from their
using trusted computing technologies
packets from their neighbors
of the excitement reflects
the excitement reflects the
to rpc based systems
excitement reflects the realization
rpc based systems such
reflects the realization that
peers maintain a queue
based systems such as
maintain a queue of
the realization that with
a queue of non
systems such as dce
realization that with web
such as dce and
that with web services
as dce and to
dce and to more
satisfied requests from its
and to more advanced
requests from its neighbors
to more advanced distributed
that assure no block
more advanced distributed support
interoperability really is easier
advanced distributed support systems
assure no block withholding
distributed support systems such
no block withholding is
support systems such as
block withholding is taking
systems such as isis
withholding is taking place
keeping only the l
developers have long struggled
only the l most
have long struggled with
the l most recent
long struggled with program
l most recent ones
this would require miners
would require miners to
require miners to use
miners to use specialized
to use specialized hardware
use specialized hardware and
specialized hardware and software
program interconnection and integration
an overhead miners may
overhead miners may not
and it is natural
miners may not accept
it is natural to
is natural to applaud
natural to applaud a
expected behavior our first
to applaud a widely
behavior our first goal
applaud a widely adopted
our first goal is
a widely adopted advance
first goal is to
goal is to explore
there is no known
is to explore the
is no known silver
to explore the typical
no known silver bullet
like it or not
explore the typical signature
the typical signature of
typical signature of the
signature of the system
all these techniques reduce
web services are becoming
these techniques reduce the
services are becoming a
techniques reduce the pool
are becoming a de
reduce the pool s
since an understanding of
the pool s attractiveness
pool s attractiveness and
an understanding of the
s attractiveness and deter
facto standard for everything
attractiveness and deter miners
understanding of the behavior
of the behavior of
the behavior of pullbased
that s not all
behavior of pullbased dissemination
of pullbased dissemination in
pullbased dissemination in the
block withholding in practice
dissemination in the absence
withholding in practice long
in the absence of
in practice long term
the absence of opportunistic
based direct sales systems
practice long term block
absence of opportunistic nodes
long term block withholding
direct sales systems are
term block withholding attacks
of opportunistic nodes will
block withholding attacks are
sales systems are turning
withholding attacks are difficult
opportunistic nodes will turn
systems are turning to
nodes will turn out
after years of experience
will turn out to
years of experience with
turn out to be
of experience with building
out to be important
experience with building these
attacks are difficult to
with building these systems
to be important when
building these systems and
are difficult to hide
these systems and applications
be important when we
are turning to the
important when we set
turning to the ws
when we set out
to the ws architecture
we set out to
the ws architecture as
set out to introduce
it is clear that
out to introduce auditing
ws architecture as a
since miners using an
architecture as a means
is clear that failure
as a means of
miners using an attacked
a means of enlarging
clear that failure management
we conducted experiments using
means of enlarging their
conducted experiments using an
that failure management is
experiments using an event
of enlarging their markets
failure management is not
using an attacked pool
management is not just
an attacked pool would
is not just a
attacked pool would notice
not just a essential
pool would notice the
just a essential tool
would notice the reduced
a essential tool for
notice the reduced revenue
which is described in
the reduced revenue density
essential tool for group
is described in more
tool for group oriented
described in more detail
for group oriented systems
com has developed a
in more detail in
has developed a web
more detail in section
all which have built
such attacks are rarely
attacks are rarely reported
access library whereby third
and we can therefore
party application developers can
we can therefore conclude
application developers can access
but that it is
can therefore conclude that
that it is a
therefore conclude that they
developers can access their
conclude that they are
it is a fundamental
can access their datacenters
that they are indeed
access their datacenters from
is a fundamental service
their datacenters from a
they are indeed rare
we evaluate the performance
a fundamental service that
evaluate the performance of
datacenters from a diversity
fundamental service that should
from a diversity of
service that should be
a diversity of end
that should be placed
a recent exception is
should be placed among
recent exception is an
be placed among such
exception is an attack
placed among such established
is an attack on
among such established basic
an attack on the
such established basic services
attack on the eligius
established basic services as
on the eligius pool
an application could order
the eligius pool performed
application could order thus
eligius pool performed in
could order thus supplies
pool performed in may
order thus supplies directly
performed in may and
thus supplies directly from
in may and june
nodes during an ideal
basic services as naming
during an ideal execution
supplies directly from amazon
an ideal execution of
ideal execution of chainsaw
where all the nodes
all the nodes behave
the nodes behave correctly
query the fulfillment system
the fulfillment system to
fulfillment system to track
service brokerage and ipc
system to track order
we fixed the upload
to track order status
fixed the upload factor
track order status or
the upload factor of
order status or billing
upload factor of the
status or billing data
factor of the source
this paper reports on
of the source at
paper reports on an
reports on an ongoing
on an ongoing research
both the vendor and
the vendor and the
an ongoing research effort
vendor and the application
and the application developer
ongoing research effort to
the application developer benefit
research effort to abstract
effort to abstract the
to abstract the failure
abstract the failure handling
com enlarges its client
enlarges its client base
the failure handling strategies
bitcoin before detecting the
before detecting the attack
failure handling strategies from
while the developer avoids
handling strategies from a
the developer avoids duplicating
and the stream rate
developer avoids duplicating an
at which point payouts
avoids duplicating an enormous
which point payouts to
duplicating an enormous technology
point payouts to the
an enormous technology investment
payouts to the attackers
strategies from a variety
to the attackers were
the stream rate to
the attackers were blocked
from a variety of
a variety of popular
variety of popular distributed
the attackers continued the
web service components will
attackers continued the attack
of popular distributed systems
service components will play
components will play a
popular distributed systems and
will play a critical
play a critical role
distributed systems and to
a critical role in
systems and to develop
critical role in tremendous
role in tremendous numbers
and to develop a
in tremendous numbers of
we varied the maximum
to develop a basic
tremendous numbers of end
varied the maximum upload
develop a basic failure
the maximum upload factor
a basic failure management
maximum upload factor of
more bitcoin before realizing
upload factor of nodes
basic failure management service
bitcoin before realizing they
factor of nodes to
before realizing they were
failure management service that
of nodes to see
realizing they were not
the challenge is to
they were not receiving
nodes to see how
were not receiving their
challenge is to make
management service that can
is to make such
not receiving their payout
service that can be
to see how it
that can be used
see how it affected
to make such systems
how it affected both
make such systems work
can be used by
such systems work reliably
it affected both the
the reasons the attack
affected both the download
be used by any
both the download and
reasons the attack was
the download and upload
used by any distributed
the attack was so
download and upload factors
attack was so easily
and upload factors of
outages that plague human
upload factors of nodes
was so easily subverted
by any distributed system
so easily subverted is
factors of nodes across
easily subverted is the
of nodes across the
that plague human users
nodes across the system
subverted is the limited
any distributed system regardless
is the limited efforts
plague human users of
the limited efforts of
distributed system regardless of
limited efforts of the
human users of web
efforts of the attackers
users of web browsers
of the attackers to
the maximum upload factor
the attackers to hide
of web browsers don
attackers to hide themselves
maximum upload factor is
system regardless of the
web browsers don t
regardless of the purpose
browsers don t cause
upload factor is a
don t cause much
of the purpose of
t cause much harm
factor is a fixed
they have only used
the purpose of that
have only used two
is a fixed parameter
only used two payout
purpose of that system
used two payout addresses
a fixed parameter which
two payout addresses to
of that system or
payout addresses to collect
fixed parameter which defines
that system or the
outages could disrupt a
system or the techniques
could disrupt a computer
or the techniques used
parameter which defines the
addresses to collect their
which defines the maximum
to collect their payouts
defines the maximum rate
the maximum rate at
maximum rate at which
the strategies employed by
rate at which a
computer pathway buried deep
at which a node
and so it was
which a node will
pathway buried deep within
so it was possible
a node will upload
strategies employed by this
node will upload data
it was possible for
will upload data to
employed by this basic
upload data to all
was possible for the
data to all its
by this basic service
possible for the alert
to all its neighbors
buried deep within an
this basic service are
deep within an application
for the alert pool
within an application on
basic service are specifically
an application on which
for fairness in nodes
service are specifically targeted
application on which an
the alert pool manager
on which an enterprise
are specifically targeted towards
which an enterprise has
alert pool manager to
an enterprise has become
specifically targeted towards applications
enterprise has become dependent
pool manager to cluster
fairness in nodes bandwidth
manager to cluster the
in nodes bandwidth consumption
targeted towards applications that
to cluster the attacking
towards applications that need
cluster the attacking miners
applications that need to
it is too easy
that need to operate
is too easy to
need to operate on
the attacking miners and
to operate on a
too easy to dismiss
operate on a global
attacking miners and obtain
we would like all
easy to dismiss these
would like all nodes
miners and obtain a
like all nodes to
to dismiss these concerns
all nodes to upload
and obtain a statistically
nodes to upload data
dismiss these concerns by
to upload data at
these concerns by arguing
upload data at a
concerns by arguing that
data at a factor
obtain a statistically significant
at a factor as
by arguing that the
a factor as close
a statistically significant proof
factor as close as
arguing that the web
as close as possible
statistically significant proof of
on a global scale
significant proof of their
close as possible to
that the web is
proof of their wrongdoing
the web is extremely
web is extremely scalable
is extremely scalable and
extremely scalable and robust
it is unknown whether
to build a successful
is unknown whether this
build a successful service
but this ignores the
a successful service the
this ignores the way
successful service the following
ignores the way we
unknown whether this was
the way we use
service the following goals
whether this was a
the following goals were
this was a classical
following goals were set
was a classical block
we varied the maximum
a classical block withholding
way we use the
classical block withholding attack
we use the web
varied the maximum upload
design a failure management
the maximum upload factor
a failure management system
with the goal of
maximum upload factor of
the goal of sabotage
a human can deal
failure management system that
human can deal with
upload factor of nodes
can deal with the
factor of nodes from
deal with the many
or a more elaborate
management system that is
a more elaborate scheme
with the many error
system that is independent
the many error conditions
that is independent of
many error conditions the
is independent of the
to verify the effectiveness
error conditions the web
verify the effectiveness of
conditions the web exposes
independent of the distributed
the effectiveness of block
of the distributed systems
effectiveness of block withholding
the distributed systems packages
of block withholding for
handling those conditions in
block withholding for profit
distributed systems packages in
those conditions in a
systems packages in use
conditions in a seamless
packages in use and
in use and provide
use and provide failure
and provide failure detection
provide failure detection of
automated manner is an
failure detection of processes
manner is an entirely
is an entirely different
an entirely different challenge
the left graph shows
left graph shows the
graph shows the minimum
improve the accuracy of
average and maximum download
the accuracy of detection
when we take what
and maximum download factors
accuracy of detection of
we take what was
maximum download factors across
take what was once
implemented an experimental bitcoin
what was once a
an experimental bitcoin test
was once a batch
experimental bitcoin test network
once a batch service
bitcoin test network and
a batch service or
test network and demonstrated
batch service or a
network and demonstrated the
service or a web
and demonstrated the practicality
or a web site
download factors across the
a web site and
demonstrated the practicality of
web site and transform
the practicality of the
site and transform it
practicality of the attack
of detection of process
factors across the nodes
detection of process and
and transform it into
of process and node
transform it into a
process and node failure
across the nodes when
and node failure through
it into a web
node failure through systems
into a web service
failure through systems support
the nodes when the
nodes when the maximum
when the maximum upload
the maximum upload factor
maximum upload factor of
bitcoin s health large
upload factor of nodes
design support for failure
factor of nodes is
s health large pools
of nodes is increased
support for failure detectors
health large pools hinder
there is no way
for failure detectors to
large pools hinder bitcoin
failure detectors to work
is no way to
detectors to work in
pools hinder bitcoin s
to work in large
no way to enforce
work in large scale
hinder bitcoin s distributed
way to enforce appropriate
by increasing the maximum
to enforce appropriate patterns
increasing the maximum upload
enforce appropriate patterns of
the maximum upload factor
appropriate patterns of use
maximum upload factor of
in large scale systems
bitcoin s distributed nature
upload factor of nodes
s distributed nature as
what s to stop
distributed nature as they
s to stop a
while maintaining a high
to stop a web
we increase the global
stop a web client
increase the global upload
a web client from
the global upload capacity
web client from trying
global upload capacity of
client from trying to
upload capacity of the
from trying to download
maintaining a high level
trying to download amazon
nature as they put
a high level of
capacity of the system
as they put a
high level of accuracy
they put a lot
com s entire catalog
put a lot of
a lot of mining
leading to a better
lot of mining power
to a better flow
of mining power in
a better flow of
mining power in the
better flow of packets
provide support for the
power in the hands
support for the detection
in the hands of
for the detection of
the hands of a
the only answer is
hands of a few
the detection of partitions
of a few pool
detection of partitions in
a few pool managers
of partitions in networks
the discrepancy among the
discrepancy among the upload
among the upload factors
the upload factors of
upload factors of individual
build a comprehensive software
this has been mostly
factors of individual nodes
a comprehensive software package
has been mostly addressed
of individual nodes also
been mostly addressed by
individual nodes also increases
comprehensive software package that
mostly addressed by community
one might argue that
software package that can
might argue that none
package that can be
argue that none of
as seen in the
addressed by community pressure
that can be easily
that none of these
seen in the graph
none of these uses
in the graph to
by community pressure on
can be easily integrated
community pressure on miners
the graph to the
pressure on miners to
graph to the right
on miners to avoid
be easily integrated into
miners to avoid forming
of these uses are
to avoid forming large
easily integrated into various
avoid forming large pools
these uses are what
when the maximum upload
uses are what the
the maximum upload factor
are what the architecture
maximum upload factor is
integrated into various distributed
upload factor is increased
what the architecture is
into various distributed systems
the architecture is intended
various distributed systems packages
architecture is intended to
distributed systems packages and
is intended to support
systems packages and applications
some nodes participate more
nodes participate more actively
participate more actively in
more actively in dissemination
not so many years
actively in dissemination while
the resulting system is
in dissemination while others
so many years ago
dissemination while others end
resulting system is implemented
while others end up
however such recommendations had
system is implemented and
such recommendations had only
is implemented and is
recommendations had only had
implemented and is under
had only had limited
and is under test
only had limited success
is under test in
others end up contributing
under test in a
server architectures faltered over
test in a wide
end up contributing less
architectures faltered over precisely
and mining is still
faltered over precisely this
mining is still dominated
over precisely this type
is still dominated by
precisely this type of
even though all of
still dominated by a
though all of them
this type of situation
all of them are
in a local setting
of them are behaving
dominated by a small
them are behaving correctly
a local setting of
by a small number
local setting of a
a small number of
setting of a mix
small number of large
of a mix of
number of large pools
a mix of high
server technologies of the
this is an important
is an important consideration
as a characteristic example
speed and traditional networks
and traditional networks and
when we introduce auditing
traditional networks and in
networks and in the
in the period of
and in the internet
the period of november
we do not want
do not want to
a first software release
first software release is
s were widely seen
not want to punish
were widely seen as
software release is planned
want to punish nodes
release is planned for
widely seen as a
is planned for the
to punish nodes that
planned for the autumn
seen as a kind
for the autumn of
as a kind of
punish nodes that are
a kind of panacea
nodes that are willing
that are willing to
are willing to contribute
a silver bullet that
willing to contribute but
silver bullet that would
to contribute but cannot
bullet that would slay
contribute but cannot do
that would slay evil
but cannot do so
would slay evil mainframe
cannot do so because
slay evil mainframe architectures
do so because of
three pools generated over
so because of factors
because of factors such
of factors such as
enterprises fell over themselves
factors such as their
fell over themselves in
such as their physical
over themselves in a
as their physical positioning
themselves in a kind
external failure detector modules
in a kind of
their physical positioning in
a kind of technology
failure detector modules originate
kind of technology gold
physical positioning in the
of the proofs of
positioning in the system
the proofs of work
of technology gold rush
detector modules originate in
modules originate in asynchronous
originate in asynchronous distributed
in asynchronous distributed systems
only to discover that
in all our future
to discover that the
all our future experiments
discover that the technology
where they were introduced
that the technology had
our future experiments we
the technology had been
they were introduced to
technology had been oversold
future experiments we set
were introduced to de
experiments we set the
we set the maximum
set the maximum upload
the maximum upload factor
maximum upload factor to
couple the mechanism by
the fact that block
the mechanism by which
fact that block withholding
mechanism by which failures
the total cost of
that block withholding attacks
total cost of ownership
by which failures are
block withholding attacks are
cost of ownership for
which failures are detected
withholding attacks are rarely
of ownership for clientserver
failures are detected from
ownership for clientserver systems
attacks are rarely observed
for clientserver systems remains
are detected from the
clientserver systems remains excessively
are rarely observed may
systems remains excessively high
detected from the protocols
rarely observed may indicate
from the protocols used
observed may indicate that
the protocols used to
may indicate that the
protocols used to tolerate
the number of system
used to tolerate those
indicate that the active
number of system administrators
to tolerate those failures
that the active pools
of system administrators remains
the active pools have
system administrators remains roughly
active pools have reached
administrators remains roughly proportional
pools have reached an
remains roughly proportional to
effect of opportunistic behavior
roughly proportional to the
have reached an implicit
proportional to the size
of opportunistic behavior our
to the size of
reached an implicit or
the size of the
opportunistic behavior our next
size of the deployment
an implicit or explicit
behavior our next goal
implicit or explicit agreement
our next goal was
or explicit agreement not
next goal was to
chandra and toueg successfully
explicit agreement not to
goal was to understand
agreement not to attack
and toueg successfully show
was to understand the
not to attack one
toueg successfully show that
to attack one another
to understand the expected
a list like these
successfully show that it
understand the expected behavior
show that it is
the expected behavior of
that it is possible
list like these comments
expected behavior of correct
it is possible to
like these comments might
an attacked pool cannot
is possible to develop
attacked pool cannot detect
these comments might have
pool cannot detect which
possible to develop consensus
cannot detect which of
comments might have seemed
detect which of its
to develop consensus algorithms
which of its miners
might have seemed like
of its miners are
behavior of correct nodes
have seemed like an
its miners are attacking
of correct nodes under
miners are attacking it
develop consensus algorithms using
seemed like an indictment
consensus algorithms using failure
correct nodes under different
algorithms using failure detectors
like an indictment of
nodes under different scenarios
let alone which pool
an indictment of the
alone which pool controls
indictment of the technology
which pool controls the
under different scenarios where
pool controls the miners
different scenarios where opportunistic
even if these failure
scenarios where opportunistic nodes
if these failure detectors
because we lacked solutions
where opportunistic nodes compromise
these failure detectors make
at some point a
opportunistic nodes compromise the
some point a pool
nodes compromise the system
failure detectors make frequent
point a pool might
detectors make frequent mistakes
a pool might miscalculate
make frequent mistakes in
pool might miscalculate and
frequent mistakes in their
might miscalculate and decide
we therefore studied how
mistakes in their observations
miscalculate and decide to
therefore studied how the
and decide to try
we know how to
decide to try and
know how to implement
studied how the download
how to implement management
to try and increase
to implement management tools
try and increase its
implement management tools and
and increase its revenue
how the download and
management tools and fault
the download and contribution
download and contribution rates
and contribution rates of
one pool might be
contribution rates of correct
pool might be enough
rates of correct nodes
might be enough to
of correct nodes are
be enough to break
correct nodes are affected
enough to break the
how to replicate data
to break the agreement
nodes are affected under
to replicate data and
are affected under these
replicate data and functionality
affected under these conditions
possibly leading to a
leading to a constant
and how to achieve
to a constant rate
how to achieve high
a constant rate of
to achieve high ava
the failure detector work
achieve high ava ilability
constant rate of attacks
opportunistic nodes may contribute
rate of attacks among
failure detector work is
of attacks among pools
nodes may contribute with
attacks among pools and
we ve had decades
may contribute with some
ve had decades of
contribute with some data
had decades of experience
with some data in
decades of experience with
among pools and a
of experience with large
pools and a reduced
detector work is extended
some data in an
work is extended to
data in an attempt
and a reduced revenue
is extended to systems
scale system monitoring and
extended to systems that
system monitoring and control
to systems that also
in an attempt to
systems that also take
if open pools reach
that also take network
an attempt to disguise
also take network failure
open pools reach a
take network failure into
and are beginning to
network failure into account
pools reach a state
attempt to disguise their
reach a state where
to disguise their opportunistic
a state where their
disguise their opportunistic behavior
are beginning to understand
state where their revenue
beginning to understand how
where their revenue density
to understand how to
their revenue density is
understand how to build
revenue density is reduced
how to build solutions
density is reduced due
to build solutions on
is reduced due to
build solutions on an
reduced due to attacks
solutions on an internet
we considered different rates
on an internet scale
off in designing practical
considered different rates of
in designing practical distributed
different rates of contribution
miners will leave them
rates of contribution for
designing practical distributed systems
of contribution for opportunistic
will leave them in
practical distributed systems based
leave them in favor
contribution for opportunistic nodes
them in favor of
distributed systems based on
in favor of other
systems based on the
favor of other available
peer file sharing turns
based on the theory
file sharing turns out
of other available options
sharing turns out to
on the theory developed
turns out to be
the theory developed for
out to be illegal
theory developed for asynchronous
miners of sufficient size
developed for asynchronous systems
of sufficient size can
for asynchronous systems is
sufficient size can mine
and it doesn t
size can mine solo
asynchronous systems is where
it doesn t work
systems is where and
doesn t work all
is where and how
t work all that
where and how to
work all that well
and how to introduce
smaller miners can form
how to introduce the
miners can form private
to introduce the notion
can form private pools
introduce the notion of
form private pools with
the notion of time
private pools with closed
pools with closed access
traditionally failure detectors have
limited to trusted participants
failure detectors have been
but spawned a new
detectors have been implemented
spawned a new generation
have been implemented using
a new generation of
such a change may
been implemented using time
a change may be
new generation of technologies
change may be in
generation of technologies based
may be in favor
of technologies based on
be in favor of
technologies based on distributed
in favor of bitcoin
out mechanisms in the
favor of bitcoin as
based on distributed hash
of bitcoin as a
mechanisms in the transport
bitcoin as a whole
on distributed hash tables
in the transport layer
distributed hash tables and
the transport layer that
hash tables and epidemic
transport layer that implements
tables and epidemic communication
since they require such
layer that implements inter
and epidemic communication protocols
they require such intimate
require such intimate trust
these offer remarkably stable
private pools are likely
pools are likely to
are likely to be
likely to be smaller
scalable tools for dealing
tools for dealing with
outs remain an important
for dealing with enormous
remain an important tool
dealing with enormous numbers
an important tool in
and form a fine
with enormous numbers of
important tool in the
enormous numbers of components
tool in the failure
numbers of components scattered
in the failure manager
of components scattered over
the failure manager described
components scattered over a
form a fine grained
scattered over a network
presents the average and
a fine grained distribution
failure manager described in
the average and minimum
fine grained distribution of
average and minimum download
manager described in this
grained distribution of mining
described in this paper
and minimum download factors
not all the stories
minimum download factors among
all the stories are
distribution of mining power
the stories are positive
download factors among all
of mining power with
the mechanism is integrated
factors among all correct
mining power with many
among all correct nodes
power with many small
all correct nodes under
with many small pools
correct nodes under different
many small pools and
mechanism is integrated into
small pools and solo
the web services community
pools and solo miners
is integrated into a
nodes under different configurations
web services community decided
integrated into a more
services community decided not
into a more comprehensive
community decided not to
decided not to adapt
a more comprehensive approach
the stream rate was
not to adapt the
stream rate was fixed
more comprehensive approach that
rate was fixed at
to adapt the corba
comprehensive approach that treats
adapt the corba fault
approach that treats failure
that treats failure detection
treats failure detection using
failure detection using methods
tolerance standard for their
detection using methods based
standard for their setting
using methods based on
methods based on an
a pool may engage
based on an analogy
pool may engage in
on an analogy with
this is a specification
an analogy with fault
may engage in an
is a specification i
and all correct nodes
a specification i know
engage in an attack
specification i know well
all correct nodes had
in an attack against
correct nodes had a
detection techniques used in
nodes had a maximum
an attack against another
had a maximum upload
techniques used in daily
a maximum upload factor
used in daily life
maximum upload factor of
it was based on
attack against another pool
was based on the
against another pool not
based on the virtual
another pool not to
on the virtual synchrony
when trying to contact
pool not to increase
the virtual synchrony model
not to increase its
virtual synchrony model colleagues
to increase its absolute
trying to contact a
increase its absolute revenue
synchrony model colleagues of
to contact a person
model colleagues of mine
colleagues of mine and
contact a person who
of mine and i
but rather to attract
mine and i developed
a person who has
and i developed in
rather to attract miners
person who has allegedly
i developed in work
to attract miners by
developed in work on
attract miners by temporarily
in work on the
who has allegedly disappeared
work on the isis
miners by temporarily increasing
on the isis toolkit
by temporarily increasing its
has allegedly disappeared one
temporarily increasing its revenue
allegedly disappeared one would
increasing its revenue relative
disappeared one would never
the standard hasn t
its revenue relative to
standard hasn t been
revenue relative to a
hasn t been a
relative to a competing
t been a commercial
to a competing pool
been a commercial success
one would never be
we ran experiments with
would never be satisfied
never be satisfied with
but the corba standard
be satisfied with making
recent work has investigated
the corba standard limits
satisfied with making repeated
corba standard limits itself
work has investigated the
standard limits itself to
with making repeated phone
limits itself to lock
has investigated the motivation
making repeated phone calls
investigated the motivation of
repeated phone calls to
the motivation of pools
phone calls to the
motivation of pools to
calls to the same
state replication of a
to the same location
of pools to utilize
the same location for
replication of a deterministic
same location for half
of a deterministic server
nodes and increasing percentages
pools to utilize part
and increasing percentages of
location for half an
increasing percentages of opportunistic
for half an hour
perhaps the issue is
half an hour and
the issue is the
an hour and then
issue is the way
hour and then declaring
is the way the
percentages of opportunistic nodes
the way the technology
to utilize part of
of opportunistic nodes in
way the technology was
opportunistic nodes in the
the technology was used
nodes in the system
utilize part of their
and then declaring the
part of their resources
then declaring the disappearance
of their resources towards
declaring the disappearance a
not the technology itself
their resources towards sabotage
the disappearance a fact
resources towards sabotage attacks
towards sabotage attacks against
sabotage attacks against each
attacks against each other
no matter whether the
used in other ways
matter whether the phone
whether the phone was
the phone was not
phone was not picked
was not picked up
has been quite successful
a busy tone was
busy tone was heard
tone was heard or
was heard or the
heard or the phone
isis runs the new
or the phone was
runs the new york
the phone was disconnected
the new york stock
new york stock exchange
york stock exchange quote
stock exchange quote and
exchange quote and trade
in practice one would
we vary the percentage
practice one would work
quote and trade reporting
one would work to
and trade reporting system
vary the percentage of
would work to gain
the percentage of opportunistic
work to gain more
percentage of opportunistic nodes
to gain more confidence
a role it has
gain more confidence in
role it has played
more confidence in such
it has played since
confidence in such a
the model of those
in such a decision
such a decision by
model of those works
a decision by talking
we can observe that
decision by talking to
of those works is
by talking to the
can observe that the
talking to the landlord
those works is different
observe that the download
works is different from
that the download factors
is different from the
the download factors of
the neighbors or others
download factors of correct
different from the pool
neighbors or others that
factors of correct nodes
from the pool game
of correct nodes decreases
or others that may
the pool game model
correct nodes decreases since
others that may have
pool game model in
nodes decreases since the
that may have a
game model in two
may have a more
decreases since the aggregated
model in two major
have a more informed
and the french air
a more informed idea
the french air traffic
more informed idea about
french air traffic control
since the aggregated upload
in two major ways
the aggregated upload capacity
air traffic control system
aggregated upload capacity in
two major ways a
upload capacity in the
informed idea about the
capacity in the system
major ways a sabotage
idea about the situation
in the system becomes
about the situation of
and the us naval
the situation of the
ways a sabotage attack
situation of the person
the us naval aegis
of the person in
a sabotage attack does
the person in question
us naval aegis warship
sabotage attack does not
naval aegis warship communication
attack does not transfer
aegis warship communication system
does not transfer revenue
not transfer revenue from
the failure management described
transfer revenue from victim
failure management described in
revenue from victim to
to name just a
from victim to attacker
name just a few
management described in this
described in this paper
in this paper is
this paper is capable
paper is capable of
leslie lamport s paxos
and migrating miners switch
lamport s paxos protocol
migrating miners switch to
is capable of following
miners switch to less
capable of following a
switch to less attacked
s paxos protocol has
to less attacked pools
of following a similar
avg download factor min
paxos protocol has been
download factor min download
following a similar strategy
factor min download factor
protocol has been used
changing pool sizes and
has been used to
pool sizes and hence
been used to build
sizes and hence revenues
used to build file
and hence revenues until
if a process under
to build file systems
hence revenues until convergence
a process under investigation
build file systems and
process under investigation is
file systems and scalable
under investigation is not
systems and scalable clusters
investigation is not responding
the model is parametrized
is not responding it
model is parametrized by
not responding it will
is parametrized by the
responding it will contact
none of these examples
it will contact the
of these examples uses
parametrized by the cost
these examples uses lock
will contact the operating
by the cost of
contact the operating system
the cost of the
the operating system under
cost of the attack
operating system under which
of the attack and
system under which the
the attack and by
under which the process
attack and by the
which the process is
and by the mobility
the process is running
by the mobility of
step replication of the
the mobility of the
replication of the type
mobility of the miners
of the type mandated
the type mandated by
or other nodes on
type mandated by corba
other nodes on the
nodes on the same
on the same sub
and the analysis demonstrates
the analysis demonstrates that
every technology has its
analysis demonstrates that when
technology has its successes
demonstrates that when considering
net to help reach
has its successes and
to help reach a
its successes and failures
that when considering only
help reach a decision
when considering only sabotage
reach a decision in
considering only sabotage attacks
a decision in which
only sabotage attacks there
decision in which one
sabotage attacks there are
in which one can
attacks there are regions
which one can have
there are regions where
one can have greater
are regions where no
can have greater confidence
attack is the best
is the best strategy
these technologies could take
technologies could take the
could take the web
take the web services
most distributed systems in
the web services architecture
distributed systems in use
the miner s dilemma
systems in use today
web services architecture to
in use today deal
services architecture to a
miner s dilemma is
architecture to a new
use today deal with
to a new level
s dilemma is therefore
today deal with failure
dilemma is therefore not
deal with failure of
is therefore not manifested
with failure of nodes
therefore not manifested in
failure of nodes or
not manifested in that
of nodes or networks
manifested in that model
nodes or networks in
or networks in some
doing so could greatly
networks in some way
so could greatly enlarge
could greatly enlarge the
greatly enlarge the web
pool competition for miners
enlarge the web services
competition for miners is
the web services market
for miners is an
in general the problem
miners is an incentive
general the problem is
is an incentive in
an incentive in and
the problem is detected
incentive in and of
so what s the
in and of its
what s the bottom
and of its own
s the bottom line
problem is detected in
of its own for
its own for mutual
is detected in the
own for mutual attacks
detected in the communication
are web services distributed
in the communication subsystem
web services distributed objects
the communication subsystem where
and a pool may
communication subsystem where session
a pool may therefore
subsystem where session or
pool may therefore choose
of course they are
where session or transport
may therefore choose to
session or transport protocols
therefore choose to perform
or transport protocols are
choose to perform block
transport protocols are unable
the marketing people are
to perform block withholding
marketing people are listening
protocols are unable to
people are listening to
perform block withholding even
are listening to customers
are unable to make
block withholding even if
unable to make progress
withholding even if its
to make progress because
even if its revenue
make progress because of
if its revenue would
and they want distributed
its revenue would increase
they want distributed objects
progress because of the
revenue would increase only
because of the lack
would increase only after
of the lack of
increase only after the
the lack of response
only after the next
lack of response from
but vogels is right
of response from remote
after the next difficult
response from remote nodes
the next difficult adjustment
traditionally packets are being
the two models are
packets are being retransmitted
two models are therefore
are being retransmitted after
models are therefore complimentary
being retransmitted after a
retransmitted after a time
the analysis of their
analysis of their combination
out period and after
of their combination is
period and after a
their combination is left
it s time for
combination is left for
and after a retry
is left for future
s time for the
left for future work
after a retry threshold
time for the web
a retry threshold is
for the web services
retry threshold is reached
the web services community
threshold is reached the
web services community to
is reached the remote
services community to come
reached the remote destination
community to come to
the remote destination is
to come to grips
remote destination is marked
come to grips with
destination is marked as
to grips with the
is marked as unreachable
grips with the needs
with the needs of
the needs of their
needs of their customer
we assumed in our
of their customer base
assumed in our analysis
some systems inject additional
in our analysis that
systems inject additional packets
our analysis that pools
inject additional packets into
one can justify solutions
analysis that pools do
can justify solutions that
additional packets into the
justify solutions that make
that pools do not
packets into the data
pools do not charge
into the data stream
do not charge fees
the data stream to
not charge fees from
data stream to ensure
charge fees from their
stream to ensure timely
fees from their members
to ensure timely detection
from their members since
ensure timely detection of
their members since such
timely detection of failures
of the customers happy
detection of failures at
the customers happy but
members since such fees
of failures at moments
customers happy but leave
failures at moments when
since such fees are
at moments when the
such fees are typically
moments when the traffic
fees are typically nominal
when the traffic is
the traffic is low
traffic is low or
is low or unidirectional
a solution that tries
of a pool s
solution that tries to
a pool s revenue
that tries to do
tries to do better
to do better will
do better will probably
better will probably overreach
but you can t
you can t get
can t get there
t get there if
get there if you
there if you close
if you close your
you close your eyes
expect the application to
close your eyes to
the application to handle
your eyes to the
application to handle the
eyes to the way
the model can be
to handle the failure
model can be extended
to the way the
handle the failure management
the way the customers
can be extended to
the failure management as
be extended to include
way the customers are
extended to include pools
failure management as the
to include pools fees
the customers are likely
management as the support
customers are likely to
as the support system
are likely to use
the support system does
likely to use the
support system does not
fees would add a
to use the technology
system does not contain
would add a friction
does not contain any
add a friction element
not contain any fault
a friction element to
contain any fault management
friction element to the
will the web services
element to the flow
the web services community
to the flow of
web services community have
the flow of revenue
often these systems cannot
flow of revenue among
services community have the
of revenue among infiltrated
these systems cannot distinguish
revenue among infiltrated and
systems cannot distinguish between
among infiltrated and infiltrating
cannot distinguish between process
infiltrated and infiltrating pools
community have the wisdom
have the wisdom to
the wisdom to tackle
wisdom to tackle the
node or network failure
to tackle the tough
tackle the tough issues
the tough issues before
tough issues before circumstances
issues before circumstances force
before circumstances force it
the mechanisms used to
circumstances force it upon
mechanisms used to detect
would change to take
force it upon them
change to take into
used to detect failure
to take into account
to detect failure do
take into account a
detect failure do not
into account a pool
failure do not adapt
account a pool fee
do not adapt to
a pool fee of
not adapt to changing
pool fee of f
adapt to changing network
fee of f pp
to changing network conditions
of f pp ri
a fellow of the
fellow of the acm
making it almost impossible
it almost impossible to
almost impossible to use
impossible to use these
to use these systems
use these systems unmodified
these systems unmodified in
systems unmodified in wide
of opportunistic nodes figure
unmodified in wide area
in wide area systems
wide area systems without
area systems without resorting
systems without resorting to
without resorting to heavy
minimum and average download
resorting to heavy weight
and average download factors
to heavy weight solutions
average download factors across
heavy weight solutions like
download factors across all
weight solutions like using
factors across all correct
solutions like using a
across all correct nodes
like using a tcp
all correct nodes when
using a tcp connection
correct nodes when opportunistic
a tcp connection as
nodes when opportunistic nodes
tcp connection as the
when opportunistic nodes are
connection as the preferred
opportunistic nodes are present
as the preferred transport
and has worked on
the preferred transport method
has worked on reliability
preferred transport method for
worked on reliability and
each curve corresponds to
on reliability and scalability
transport method for each
curve corresponds to a
method for each rpc
reliability and scalability issues
for each rpc call
corresponds to a different
and scalability issues in
to a different contribution
scalability issues in distributed
a different contribution rate
issues in distributed systems
different contribution rate used
in distributed systems since
contribution rate used by
distributed systems since starting
rate used by opportunistic
systems since starting his
used by opportunistic nodes
since starting his research
starting his research career
especially those designed to
those designed to support
designed to support high
he is the author
is the author of
the author of many
author of many articles
of many articles on
many articles on the
articles on the subject
management in a more
in a more integrated
a more integrated way
many of these systems
of these systems are
these systems are structured
systems are structured as
are structured as groups
structured as groups of
as groups of cooperating
groups of cooperating processes
and applications will be
of cooperating processes using
applications will be published
cooperating processes using some
will be published by
processes using some form
be published by springer
using some form of
published by springer verlag
some form of group
by springer verlag in
form of group membership
springer verlag in fall
a pool with a
pool with a fee
with a fee of
a fee of f
fee of f is
of f is a
f is a less
is a less attractive
detection to be able
a less attractive target
to be able to
less attractive target for
be able to reach
attractive target for block
able to reach consensus
target for block withholding
various methods are used
since the attacker s
the attacker s revenue
attacker s revenue is
s revenue is reduced
revenue is reduced by
of which fault monitors
is reduced by f
however it is also
it is also less
is also less attractive
also less attractive for
less attractive for miners
attractive for miners in
for miners in general
web services are not
services are not distributed
trading off the two
are not distributed objects
off the two for
the two for best
two for best protection
for best protection is
best protection is left
protection is left for
is left for future
left for future work
avg upload factor min
as part of the
upload factor min upload
part of the treatment
factor min upload factor
of the treatment of
the treatment of the
treatment of the miner
r elated w ork
elated w ork a
are the most popular
the block withholding attack
block withholding attack the
however in each of
withholding attack the danger
in each of these
attack the danger of
each of these systems
the danger of a
of these systems the
danger of a block
these systems the failure
of a block withholding
systems the failure management
a block withholding attack
the failure management is
block withholding attack is
failure management is an
withholding attack is as
management is an integral
attack is as old
is an integral part
is as old as
an integral part of
as old as bitcoin
integral part of the
old as bitcoin pools
part of the particular
of the particular membership
the particular membership or
particular membership or transport
the attack was described
membership or transport system
attack was described by
or transport system and
was described by rosenfeld
transport system and not
system and not available
and not available for
not available for general
available for general use
although some research groups
as pools were becoming
pools were becoming a
were becoming a dominant
becoming a dominant player
a dominant player in
dominant player in the
player in the bitcoin
are focusing on wide
in the bitcoin world
focusing on wide area
on wide area systems
the paper described the
paper described the standard
the majority of the
described the standard attack
majority of the existing
of the existing failure
the existing failure detectors
existing failure detectors are
used by a miner
failure detectors are not
by a miner to
detectors are not suitable
a miner to sabotage
are not suitable for
miner to sabotage a
not suitable for use
to sabotage a pool
suitable for use in
sabotage a pool at
for use in large
a pool at the
use in large scale
pool at the cost
in large scale systems
at the cost of
the cost of reducing
cost of reducing its
of reducing its own
reducing its own revenue
because of their inflexibility
of their inflexibility or
their inflexibility or the
inflexibility or the simplicity
or the simplicity of
a more general view
the simplicity of their
more general view of
simplicity of their assumptions
general view of fairness
view of fairness in
of fairness in proof
fairness in proof of
in proof of work
proof of work schemes
of work schemes was
work schemes was discussed
schemes was discussed in
building a failure detector
a failure detector that
failure detector that is
detector that is not
that is not an
is not an integral
not an integral part
an integral part of
integral part of the
part of the communication
of the communication architecture
the communication architecture permits
communication architecture permits the
architecture permits the implementation
in the context of
permits the implementation of
the context of the
context of the hashcash
the implementation of a
of the hashcash system
implementation of a collection
of a collection of
a collection of failure
collection of failure detection
of failure detection techniques
failure detection techniques and
detection techniques and support
techniques and support for
and support for failure
support for failure detection
for failure detection methods
failure detection methods of
early work did not
detection methods of varying
work did not address
methods of varying levels
did not address the
of varying levels of
not address the possibility
varying levels of complexity
address the possibility of
levels of complexity from
the possibility of pools
of complexity from which
possibility of pools infiltrating
complexity from which the
of pools infiltrating other
pools infiltrating other pools
from which the system
infiltrating other pools for
which the system designer
other pools for block
the system designer can
pools for block withholding
system designer can choose
designer can choose to
can choose to match
choose to match the
to match the system
match the system requirements
the failure management service
failure management service consists
management service consists of
service consists of three
consists of three functional
of three functional modules
optimizing power consumption in
power consumption in large
experimentally demonstrate that block
consumption in large scale
demonstrate that block withholding
in large scale storage
that block withholding can
large scale storage systems
block withholding can increase
scale storage systems lakshmi
withholding can increase the
storage systems lakshmi ganesh
can increase the attacker
increase the attacker s
the attacker s revenue
they do not address
do not address the
not address the question
address the question of
a library that implements
the question of mutual
library that implements simple
question of mutual attacks
ken birman computer science
that implements simple failure
birman computer science department
implements simple failure management
simple failure management functionality
failure management functionality and
management functionality and provide
functionality and provide the
and provide the api
provide the api to
the api to the
api to the complete
to the complete service
a service implementing per
service implementing per node
implementing per node failure
have recently noted that
per node failure management
recently noted that a
noted that a pool
that a pool can
a pool can increase
of opportunistic nodes figure
combining fault management with
pool can increase its
fault management with other
can increase its overall
management with other local
increase its overall revenue
with other local nodes
its overall revenue with
other local nodes to
overall revenue with block
local nodes to exploit
revenue with block withholding
minimum and average upload
with block withholding if
and average upload factors
block withholding if all
average upload factors across
withholding if all other
upload factors across all
if all other mining
edu abstract data centers
all other mining is
factors across all correct
abstract data centers are
other mining is performed
nodes to exploit locality
mining is performed by
data centers are the
is performed by honest
to exploit locality of
performed by honest pools
centers are the backend
across all correct nodes
are the backend for
all correct nodes when
exploit locality of communication
correct nodes when opportunistic
the backend for a
nodes when opportunistic nodes
locality of communication and
when opportunistic nodes are
we consider the general
opportunistic nodes are present
of communication and failure
backend for a large
communication and failure patterns
consider the general case
for a large number
the general case where
a large number of
general case where not
large number of services
each curve corresponds to
number of services that
an inquiry service closely
of services that we
curve corresponds to a
services that we take
corresponds to a different
that we take for
to a different contribution
we take for granted
a different contribution rate
take for granted today
inquiry service closely coupled
case where not all
service closely coupled with
different contribution rate used
closely coupled with the
contribution rate used by
coupled with the operating
rate used by opportunistic
a significant fraction of
with the operating system
significant fraction of the
the operating system which
fraction of the total
used by opportunistic nodes
where not all mining
of the total cost
not all mining is
the total cost of
all mining is performed
total cost of ownership
mining is performed through
cost of ownership of
is performed through public
of ownership of these
performed through public pools
ownership of these large
insufficient to provide all
provides information about the
to provide all nodes
information about the state
provide all nodes with
about the state of
all nodes with all
the state of local
nodes with all data
scale storage systems is
and analyze situations where
storage systems is the
state of local participating
systems is the cost
of local participating processes
analyze situations where pools
is the cost of
situations where pools can
the cost of keeping
where pools can attack
cost of keeping hundreds
pools can attack one
of keeping hundreds of
can attack one another
the extent of the
keeping hundreds of thousands
extent of the impact
hundreds of thousands of
of the impact may
of thousands of disks
the impact may be
the most fundamental operation
impact may be surprising
the discrepancy between the
most fundamental operation offered
discrepancy between the calculations
thousands of disks spinning
between the calculations of
fundamental operation offered by
operation offered by a
offered by a failure
by a failure detection
we present a simple
a failure detection service
present a simple idea
failure detection service is
a simple idea that
detection service is that
simple idea that allows
service is that of
idea that allows the
is that of the
that allows the storage
that of the investigation
allows the storage system
of the investigation of
the storage system to
and our results for
storage system to turn
performance drops by as
system to turn off
drops by as much
the investigation of a
by as much as
our results for the
investigation of a suspected
to turn off a
of a suspected process
results for the special
turn off a large
for the special case
off a large fraction
the special case analyzed
a large fraction of
special case analyzed there
large fraction of its
to make use of
fraction of its disks
case analyzed there can
make use of this
analyzed there can be
use of this operation
there can be explained
of this operation it
without incurring unacceptable performance
can be explained by
incurring unacceptable performance penalties
this operation it is
be explained by the
operation it is not
explained by the strong
presents the average and
by the strong approximations
of particular appeal is
it is not necessary
particular appeal is the
the strong approximations in
appeal is the fact
strong approximations in that
is the fact that
approximations in that work
the fact that our
is not necessary for
fact that our solution
the average and minimum
that our solution is
not necessary for either
our solution is not
average and minimum upload
solution is not application
necessary for either the
and minimum upload factors
for either the local
minimum upload factors among
either the local or
upload factors among all
we calculate exactly how
factors among all correct
the local or remote
among all correct nodes
calculate exactly how infiltrating
local or remote process
exactly how infiltrating miners
or remote process to
how infiltrating miners reduce
remote process to run
infiltrating miners reduce the
process to run any
miners reduce the revenue
savings for a very
reduce the revenue density
for a very generic
to run any of
a very generic data
the revenue density of
very generic data center
run any of the
generic data center model
axis we vary the
revenue density of the
we vary the percentage
density of the infiltrated
vary the percentage of
of the infiltrated pool
the percentage of opportunistic
any of the heartbeat
percentage of opportunistic nodes
of the heartbeat or
the heartbeat or polling
heartbeat or polling patterns
we describe our solution
and on the y
the reasons that the
identify the parameters that
temporary block withholding in
the parameters that determine
axis we present the
reasons that the local
we present the upload
block withholding in the
present the upload factors
that the local process
the upload factors of
withholding in the block
the local process began
upload factors of nodes
local process began to
in the block withholding
process began to suspect
parameters that determine its
began to suspect the
that determine its cost
which can vary up
to suspect the remote
the block withholding attack
can vary up to
suspect the remote process
block withholding attack discussed
the remote process are
withholding attack discussed in
remote process are not
attack discussed in this
process are not of
discussed in this work
and present a simulator
in this work the
are not of any
this work the withheld
present a simulator that
work the withheld blocks
not of any importance
the withheld blocks are
a simulator that allows
withheld blocks are never
of any importance to
blocks are never published
simulator that allows us
any importance to the
that allows us to
importance to the failure
allows us to explore
to the failure management
it is interesting to
us to explore this
is interesting to note
to explore this parameter
interesting to note that
explore this parameter space
to note that the
blocks can be withheld
note that the average
can be withheld temporarily
that the average upload
the average upload factor
average upload factor among
we also present some
upload factor among correct
also present some initial
not following the bitcoin
factor among correct nodes
following the bitcoin protocol
present some initial simulation
among correct nodes initially
some initial simulation results
correct nodes initially increases
initial simulation results that
to improve an attacker
simulation results that add
improve an attacker s
results that add weight
an attacker s revenue
that add weight to
and then starts falling
add weight to our
then starts falling when
weight to our claim
starts falling when the
to our claim that
falling when the percentage
a miner or a
when the percentage of
our claim that our
miner or a pool
the percentage of opportunistic
or a pool can
claim that our solution
a pool can perform
that our solution represents
percentage of opportunistic nodes
our solution represents a
pool can perform a
solution represents a new
can perform a selfish
represents a new powersaving
perform a selfish mining
a new powersaving opportunity
a selfish mining attack
of opportunistic nodes increases
the process at address
new powersaving opportunity for
opportunistic nodes increases significantly
powersaving opportunity for large
process at address is
at address is investigated
address is investigated and
is investigated and a
investigated and a report
this behavior can be
and a report is
behavior can be explained
a report is returned
can be explained by
report is returned within
be explained by the
is returned within the
explained by the fact
returned within the deadline
by the fact that
within the deadline set
introduction the declining costs
the deadline set by
the declining costs of
deadline set by the
with selfish mining the
set by the local
declining costs of commodity
by the local process
selfish mining the attacker
costs of commodity disk
mining the attacker increases
of commodity disk drives
correct nodes start contributing
the attacker increases its
commodity disk drives has
nodes start contributing more
the local process does
disk drives has made
start contributing more to
drives has made online
local process does not
has made online data
contributing more to compensate
process does not have
made online data storage
more to compensate for
does not have to
online data storage a
attacker increases its revenue
to compensate for the
not have to wait
compensate for the lack
increases its revenue by
data storage a way
have to wait for
for the lack of
its revenue by temporarily
the lack of data
to wait for the
lack of data provided
revenue by temporarily withholding
wait for the investigation
of data provided by
by temporarily withholding its
storage a way of
for the investigation to
a way of life
temporarily withholding its blocks
the investigation to finish
data provided by a
withholding its blocks and
provided by a small
investigation to finish but
by a small percentage
its blocks and publishing
a small percentage of
to finish but can
small percentage of opportunistic
blocks and publishing them
percentage of opportunistic nodes
finish but can make
so much so that
but can make use
and publishing them in
can make use of
much so that companies
make use of the
publishing them in response
use of the asynch
them in response to
of the asynch interface
in response to block
once the effect of
response to block publication
the effect of opportunistic
to block publication by
effect of opportunistic nodes
block publication by other
of opportunistic nodes becomes
publication by other pools
opportunistic nodes becomes significant
by other pools and
the asynch interface to
other pools and miners
so that companies like
asynch interface to collect
that companies like google
interface to collect the
companies like google and
the system collapses and
like google and yahoo
to collect the result
google and yahoo host
this attack is independent
and yahoo host hundreds
system collapses and correct
yahoo host hundreds of
attack is independent of
collect the result at
collapses and correct nodes
the result at a
is independent of the
result at a later
and correct nodes are
host hundreds of thousands
correct nodes are not
hundreds of thousands of
nodes are not able
of thousands of servers
are not able to
independent of the block
not able to keep
thousands of servers for
able to keep contributing
of the block withholding
at a later moment
of servers for storage
the block withholding attack
block withholding attack we
another important point to
withholding attack we discuss
important point to note
attack we discuss here
point to note is
the report contains information
we discuss here and
to note is that
there is a catch
note is that the
report contains information on
is that the minimum
discuss here and the
contains information on whether
here and the two
that the minimum upload
and the two can
a hundred thousand servers
the two can be
the minimum upload factor
two can be performed
hundred thousand servers consume
can be performed in
minimum upload factor does
be performed in concert
thousand servers consume a
information on whether the
servers consume a lot
upload factor does not
on whether the remote
consume a lot of
factor does not follow
a lot of power
an attacker can also
does not follow a
whether the remote node
not follow a clearly
attacker can also perform
the remote node was
follow a clearly defined
not only does this
a clearly defined pattern
remote node was reachable
can also perform a
only does this translate
also perform a double
node was reachable within
perform a double spending
does this translate to
was reachable within the
making it hard to
this translate to many
reachable within the deadline
it hard to estimate
translate to many millions
within the deadline and
a double spending attack
the deadline and whether
double spending attack as
hard to estimate the
spending attack as follows
deadline and whether the
to many millions of
and whether the process
many millions of dollars
whether the process under
millions of dollars annually
the process under investigation
of dollars annually on
to estimate the minimum
dollars annually on electricity
process under investigation was
annually on electricity bills
estimate the minimum contribution
under investigation was still
the minimum contribution of
investigation was still present
minimum contribution of correct
was still present at
contribution of correct nodes
still present at the
of correct nodes under
present at the host
the heat produced by
correct nodes under compromised
heat produced by so
nodes under compromised scenarios
produced by so much
by so much computing
he intentionally generates two
if the mode parameter
intentionally generates two conflicting
so much computing power
generates two conflicting transactions
the mode parameter was
much computing power can
mode parameter was used
computing power can be
parameter was used to
power can be searing
was used to request
places one in a
by applying thresholds to
one in a block
used to request a
in a block it
applying thresholds to punish
a block it withholds
to request a more
an article in the
request a more detailed
thresholds to punish opportunistic
a more detailed remote
article in the new
more detailed remote reporting
and publishes the other
to punish opportunistic nodes
publishes the other transaction
in the new york
the new york times
new york times describes
process checkpoint information is
york times describes one
after the recipient sees
times describes one of
the recipient sees the
describes one of google
recipient sees the published
one of google s
sees the published transaction
of google s data
checkpoint information is returned
google s data centers
correct nodes may also
information is returned or
nodes may also be
is returned or the
may also be unfairly
returned or the remote
also be unfairly penalized
the attacker publishes the
or the remote process
attacker publishes the withheld
the remote process is
publishes the withheld block
remote process is interrupted
the withheld block to
process is interrupted to
withheld block to revoke
is interrupted to provide
block to revoke the
interrupted to provide status
a computing center as
to provide status information
computing center as big
to revoke the former
center as big as
revoke the former transaction
as big as two
big as two football
auditing protocol our idea
as two football fields
protocol our idea for
see the section on
our idea for auditing
the section on os
idea for auditing the
section on os integration
for auditing the described
this attack is performed
auditing the described live
with twin cooling plants
attack is performed by
twin cooling plants protruding
is performed by miners
cooling plants protruding four
performed by miners or
plants protruding four stories
streaming system against opportunistic
if the node was
system against opportunistic behavior
by miners or pools
against opportunistic behavior is
miners or pools against
protruding four stories into
or pools against service
four stories into the
pools against service providers
stories into the sky
the node was not
opportunistic behavior is motivated
node was not reachable
behavior is motivated by
was not reachable and
is motivated by the
against service providers that
motivated by the graphs
not reachable and the
by the graphs presented
service providers that accept
the graphs presented in
providers that accept bitcoin
graphs presented in the
reachable and the local
presented in the previous
and the local process
in the previous section
the local process has
local process has requested
and it not directly
process has requested extensive
it not directly related
has requested extensive investigation
not directly related to
directly related to this
we propose to employ
related to this work
propose to employ auditing
power conservation is an
the failure investigator will
conservation is an important
to employ auditing to
is an important concern
failure investigator will try
employ auditing to ensure
investigator will try to
an important concern for
will try to contact
auditing to ensure that
try to contact a
important concern for big
to contact a failure
concern for big server
contact a failure manager
for big server clusters
block withholding defense most
to ensure that all
withholding defense most crypto
a failure manager at
ensure that all nodes
failure manager at the
that all nodes in
since disks account for
manager at the node
disks account for a
all nodes in the
account for a significant
currencies use a proof
for a significant fraction
nodes in the system
a significant fraction of
in the system contribute
significant fraction of the
the system contribute more
fraction of the energy
system contribute more than
of the energy consumed
net or within its
contribute more than a
or within its administrative
work architecture similar to
more than a particular
within its administrative domain
than a particular specified
architecture similar to bitcoin
a particular specified threshold
its administrative domain which
administrative domain which should
domain which should be
which should be able
where finding proof of
should be able to
finding proof of work
be able to give
proof of work is
able to give a
of work is the
to give a more
several approaches for disk
give a more conclusive
approaches for disk power
a more conclusive answer
for disk power management
more conclusive answer about
we illustrate the potential
conclusive answer about the
disk power management have
answer about the node
work is the result
power management have been
illustrate the potential benefit
management have been proposed
is the result of
have been proposed and
the potential benefit from
been proposed and studied
the result of solution
s failure to respond
potential benefit from using
result of solution guessing
benefit from using auditing
of solution guessing and
we will examine some
solution guessing and checking
from using auditing in
if network failure is
using auditing in a
network failure is the
auditing in a system
will examine some of
in a system where
failure is the cause
examine some of these
is the cause of
some of these here
the cause of the
all of the algorithms
cause of the loss
of the algorithms we
of the loss of
the algorithms we are
the loss of connectivity
but first let us
algorithms we are aware
first let us lay
we are aware of
let us lay out
are aware of are
us lay out some
aware of are susceptible
the report will indicate
of are susceptible to
of the nodes are
are susceptible to the
the nodes are correct
susceptible to the block
nodes are correct and
to the block withholding
report will indicate which
the block withholding attack
lay out some of
will indicate which part
out some of the
indicate which part of
some of the groundwork
which part of the
part of the path
as in all of
of the path is
in all of them
the path is reachable
any disk power management
all of them the
disk power management scheme
path is reachable and
power management scheme essentially
is reachable and where
of them the miner
reachable and where the
the latter do not
them the miner can
management scheme essentially attempts
and where the suspected
scheme essentially attempts to
the miner can check
essentially attempts to exploit
latter do not upload
attempts to exploit one
miner can check whether
to exploit one fact
do not upload any
can check whether she
not upload any data
check whether she found
whether she found a
disks can be run
she found a full
can be run in
found a full or
be run in highpower
a full or a
run in highpower mode
full or a partial
if the failure investigator
or a partial proof
the failure investigator is
a partial proof of
failure investigator is configured
partial proof of work
investigator is configured with
is configured with alternative
configured with alternative outgoing
with alternative outgoing paths
prominent examples are litecoin
with a corresponding performance
no punishment was applied
a corresponding performance tradeoff
punishment was applied in
these paths are probed
was applied in an
paths are probed to
applied in an attempt
are probed to see
in an attempt to
probed to see if
an attempt to simulate
to see if it
attempt to simulate a
a disk can be
to simulate a system
see if it is
simulate a system with
disk can be shut
if it is possible
a system with no
can be shut off
system with no auditing
it is possible to
be shut off so
is possible to circumvent
shut off so that
possible to circumvent the
off so that it
to circumvent the network
so that it consumes
circumvent the network failure
that it consumes no
the network failure and
it consumes no power
network failure and in
failure and in such
and in such a
in such a way
given a large cluster
such a way collect
a large cluster of
a way collect information
large cluster of disks
way collect information about
collect information about the
information about the remote
about the remote process
it is possible to
only a fraction of
auditing is enabled and
is possible to use
a fraction of them
is enabled and opportunistic
the report contains information
possible to use an
enabled and opportunistic nodes
fraction of them is
to use an alternative
and opportunistic nodes start
report contains information about
use an alternative proof
of them is accessed
opportunistic nodes start to
them is accessed at
an alternative proof of
contains information about the
nodes start to be
information about the results
alternative proof of work
about the results of
start to be expelled
proof of work mechanism
the results of these
is accessed at any
results of these probes
of work mechanism in
to be expelled from
accessed at any time
be expelled from the
work mechanism in which
expelled from the system
mechanism in which miners
from the system for
early triggers many systems
in which miners would
the system for low
so that the rest
system for low contribution
which miners would not
triggers many systems find
miners would not be
that the rest could
many systems find it
the rest could potentially
would not be able
rest could potentially be
systems find it desirable
could potentially be switched
not be able to
potentially be switched to
find it desirable to
be switched to a
the minimum upload factor
it desirable to detect
switched to a low
desirable to detect failure
minimum upload factor for
to detect failure of
upload factor for nodes
be able to distinguish
factor for nodes to
detect failure of remote
for nodes to stay
able to distinguish partial
nodes to stay in
failure of remote processes
to stay in the
of remote processes even
stay in the system
to distinguish partial from
in the system was
remote processes even if
the system was set
since mode transitions consume
processes even if there
system was set to
even if there is
mode transitions consume time
if there is no
distinguish partial from full
there is no data
partial from full proofs
is no data exchange
from full proofs of
no data exchange actually
full proofs of work
data exchange actually under
exchange actually under way
systems are free to
are free to implement
free to implement whatever
to implement whatever scheme
implement whatever scheme they
whatever scheme they find
transitions consume time and
scheme they find appropriate
consume time and power
they find appropriate and
find appropriate and use
appropriate and use the
and use the failure
use the failure investigator
disk management schemes have
the failure investigator from
management schemes have to
failure investigator from the
schemes have to walk
investigator from the previous
have to walk the
from the previous section
to walk the tightrope
the previous section to
walk the tightrope of
previous section to handle
the tightrope of finding
section to handle the
tightrope of finding the
to handle the suspicions
of finding the right
finding the right balance
the right balance between
right balance between power
balance between power consumption
between power consumption and
or they can make
power consumption and performance
they can make use
can make use of
make use of two
use of two standardized
of two standardized schemes
the solution space explored
two standardized schemes implemented
solution space explored thus
standardized schemes implemented by
space explored thus far
schemes implemented by the
explored thus far in
implemented by the failure
thus far in the
such a solution could
far in the literature
by the failure manager
without auditing with auditing
in the literature can
a solution could reduce
the literature can be
the failure manager library
literature can be divided
solution could reduce or
can be divided as
could reduce or remove
be divided as follows
reduce or remove the
the first scheme uses
or remove the danger
first scheme uses a
remove the danger of
scheme uses a heartbeat
the danger of block
uses a heartbeat mechanism
danger of block withholding
which sends out i
making such a change
such a change may
a change may not
change may not be
alive messages to a
may not be in
messages to a group
not be in the
to a group of
be in the interest
a group of processes
in the interest of
group of processes using
the interest of the
of processes using multiple
interest of the community
processes using multiple point
or even its potential
point messages or a
messages or a single
or a single ip
could lead to a
lead to a reduction
to a reduction of
a reduction of pool
reduction of pool sizes
each process keeps track
as explained in section
process keeps track of
explained in section ix
keeps track of the
track of the reception
of the reception times
each of these solutions
the reception times of
of these solutions proposes
reception times of messages
download factor of correct
these solutions proposes a
factor of correct nodes
solutions proposes a new
of correct nodes during
proposes a new system
correct nodes during a
a new system of
decentralized pools although most
new system of some
times of messages and
system of some kind
pools although most pools
of messages and if
although most pools use
messages and if a
most pools use a
and if a number
pools use a centralized
if a number of
use a centralized manager
a number of consecutive
number of consecutive heartbeats
second streaming session with
based solutions propose novel
of consecutive heartbeats from
a prominent exception is
consecutive heartbeats from a
prominent exception is p
solutions propose novel storage
heartbeats from a destination
propose novel storage hierarchies
from a destination is
novel storage hierarchies to
a destination is missed
pool a distributed pool
destination is missed a
storage hierarchies to strike
is missed a suspicion
a distributed pool architecture
missed a suspicion is
hierarchies to strike the
a suspicion is raised
distributed pool architecture with
to strike the right
pool architecture with no
strike the right balance
architecture with no central
the right balance between
with no central manager
auditing is enabled in
right balance between performance
is enabled in the
balance between performance and
enabled in the last
between performance and power
performance and power consumption
fixed period or an
period or an exponential
disk management solutions interject
or an exponential back
management solutions interject a
solutions interject a new
interject a new disk
a new disk management
new disk management layer
disk management layer on
management layer on top
we present the minimum
but the question of
layer on top of
on top of the
the question of whether
top of the file
of the file system
question of whether a
average and maximum download
of whether a pool
and maximum download factors
fixed or estimated by
maximum download factors across
or estimated by the
which controls disk configuration
estimated by the system
download factors across correct
whether a pool is
factors across correct nodes
controls disk configuration and
across correct nodes varying
a pool is run
correct nodes varying along
disk configuration and data
pool is run by
configuration and data layout
is run by a
and data layout to
run by a centralized
data layout to achieve
and multiple suspicion levels
by a centralized manager
multiple suspicion levels are
layout to achieve power
a centralized manager or
suspicion levels are configurable
centralized manager or with
levels are configurable by
manager or with a
optimal disk access patterns
are configurable by the
or with a decentralized
configurable by the application
as observed in this
with a decentralized architecture
observed in this particular
caching solutions devise new
a decentralized architecture is
solutions devise new power
in this particular example
decentralized architecture is almost
the application can provide
architecture is almost immaterial
application can provide application
is almost immaterial for
can provide application specific
almost immaterial for the
auditing has the potential
immaterial for the attack
provide application specific data
for the attack we
has the potential to
the attack we describe
application specific data to
aware caching algorithms that
specific data to be
the potential to improve
caching algorithms that allow
data to be piggybacked
potential to improve the
to be piggybacked on
algorithms that allow large
be piggybacked on the
to improve the quality
piggybacked on the heartbeats
that allow large fractions
improve the quality of
allow large fractions of
the quality of streamed
pool group can be
large fractions of the
group can be infiltrated
the second scheme uses
can be infiltrated and
fractions of the storage
be infiltrated and attacked
second scheme uses a
quality of streamed sessions
scheme uses a polling
of the storage system
uses a polling method
of streamed sessions significantly
a polling method to
the storage system to
polling method to collect
storage system to remain
method to collect acknowledgments
system to remain idle
pool code can be
to remain idle for
and at low cost
remain idle for longer
code can be changed
idle for longer periods
to collect acknowledgments from
for longer periods of
can be changed to
longer periods of time
collect acknowledgments from the
one important concern is
acknowledgments from the peer
be changed to support
from the peer processes
important concern is that
changed to support attacks
concern is that if
to support attacks against
allowing them to be
support attacks against other
is that if the
attacks against other pools
if no acknowledgments are
them to be switched
that if the specified
to be switched to
no acknowledgments are received
be switched to lower
if the specified threshold
switched to lower power
on the other hand
to lower power modes
the specified threshold is
acknowledgments are received after
specified threshold is too
are received after a
threshold is too high
received after a number
after a number of
the principal contribution of
a number of retries
principal contribution of this
number of retries a
pool can be used
of retries a suspicion
contribution of this paper
retries a suspicion is
can be used by
a suspicion is raised
of this paper is
be used by groups
more opportunistic nodes may
used by groups of
this paper is to
by groups of miners
paper is to argue
groups of miners to
opportunistic nodes may be
of miners to easily
nodes may be caught
miners to easily form
is to argue that
to easily form closed
to argue that there
easily form closed pools
argue that there is
that there is a
but correct nodes may
there is a fourth
correct nodes may also
is a fourth niche
nodes may also be
a fourth niche as
may also be unfairly
these do not accept
and retransmission limits are
also be unfairly punished
retransmission limits are configurable
do not accept untrusted
limits are configurable by
fourth niche as yet
are configurable by the
niche as yet unexplored
not accept untrusted miners
configurable by the application
by the application or
no correct nodes were
the application or can
correct nodes were mistakenly
application or can be
and are therefore protected
or can be adapted
are therefore protected against
can be adapted by
therefore protected against block
be adapted by the
protected against block withholding
adapted by the failure
nodes were mistakenly expelled
by the failure manager
were mistakenly expelled from
the failure manager to
mistakenly expelled from the
failure manager to the
expelled from the system
manager to the network
c onclusion we explored
we do not present
instrumenting the operating system
do not present a
onclusion we explored a
not present a new
present a new system
we explored a block
to achieve greater failure
explored a block withholding
achieve greater failure detection
a block withholding attack
greater failure detection accuracy
block withholding attack among
auditing components we now
withholding attack among bitcoin
components we now give
we take an idea
attack among bitcoin mining
take an idea that
it is necessary to
an idea that has
among bitcoin mining pools
idea that has been
is necessary to instrument
that has been around
bitcoin mining pools an
has been around for
necessary to instrument the
been around for well
mining pools an attack
around for well over
to instrument the operating
we now give some
instrument the operating environment
now give some additional
the operating environment with
give some additional details
operating environment with support
some additional details of
pools an attack that
additional details of the
an attack that is
details of the auditing
environment with support for
of the auditing architecture
attack that is possible
for well over a
that is possible in
well over a decade
with support for process
over a decade now
is possible in any
focusing upon two aspects
support for process investigation
possible in any similar
in any similar system
any similar system that
similar system that rewards
system that rewards for
that rewards for proof
it has always been
rewards for proof of
has always been argued
for proof of work
always been argued that
been argued that in
argued that in a
that in a distributed
such systems are gaining
in a distributed system
systems are gaining popularity
collecting accountable information about
a distributed system it
accountable information about the
distributed system it is
information about the download
system it is impossible
about the download and
it is impossible to
running most digital currencies
the download and upload
is impossible to distinguish
most digital currencies and
impossible to distinguish a
digital currencies and related
to distinguish a crashed
currencies and related services
download and upload factors
distinguish a crashed process
and upload factors of
a crashed process from
upload factors of individual
crashed process from one
factors of individual nodes
process from one that
we observe that no
from one that is
of individual nodes in
one that is slow
individual nodes in the
and argue that technological
nodes in the system
argue that technological evolution
that technological evolution has
technological evolution has given
evolution has given it
attacks is not a
has given it a
is not a nash
given it a new
not a nash equilibrium
it a new relevance
a new relevance today
new relevance today as
relevance today as a
today as a natural
if none of the
as a natural power
none of the other
but with the proper
of the other pools
with the proper system
the other pools attack
the proper system support
establishing and applying the
proper system support this
saving opportunity for large
system support this is
and applying the best
support this is no
applying the best threshold
a pool can increase
this is no longer
pool can increase its
is no longer true
the best threshold at
can increase its revenue
best threshold at any
increase its revenue by
threshold at any given
its revenue by attacking
the key insight is
revenue by attacking the
if the node is
at any given time
the node is reachable
any given time during
key insight is that
given time during execution
node is reachable and
by attacking the others
is reachable and operating
reachable and operating correctly
where other solutions attempt
we employ two types
when two pools can
employ two types of
two pools can attack
two types of components
pools can attack each
other solutions attempt to
can attack each other
the operating system can
solutions attempt to predict
types of components to
attempt to predict disk
of components to perform
to predict disk access
components to perform these
they face a version
operating system can determine
face a version of
to perform these two
a version of the
system can determine whether
version of the prisoner
perform these two roles
predict disk access to
can determine whether or
disk access to determine
determine whether or not
access to determine which
whether or not the
to determine which disks
or not the process
determine which disks to
not the process has
which disks to power
the process has crashed
disks to power down
of the prisoner s
local and global auditors
the prisoner s dilemma
the lfs automatically provides
the failure management integrated
lfs automatically provides a
local auditors are executed
automatically provides a perfect
auditors are executed on
if one pool chooses
failure management integrated into
provides a perfect prediction
management integrated into the
a perfect prediction mechanism
are executed on the
one pool chooses to
executed on the nodes
pool chooses to attack
on the nodes participating
integrated into the os
the nodes participating in
simply by virtue of
nodes participating in the
into the os offers
participating in the system
by virtue of the
the victim s revenue
virtue of the fact
the os offers processes
of the fact that
victim s revenue is
the fact that all
os offers processes a
fact that all write
s revenue is reduced
and therefore cannot be
offers processes a mechanism
therefore cannot be trusted
processes a mechanism to
a mechanism to register
accesses go to the
mechanism to register and
and it can retaliate
to register and request
if a node is
it can retaliate by
go to the log
a node is malicious
can retaliate by attacking
to the log head
register and request a
retaliate by attacking and
and request a certain
by attacking and increase
request a certain level
attacking and increase its
a certain level of
and increase its revenue
certain level of service
it might report false
might report false data
explains and expands on
and expands on this
expands on this idea
global auditors are trusted
auditors are trusted components
are trusted components that
trusted components that run
components that run on
that run on dedicated
at nash equilibrium both
run on dedicated external
is a simple binary
on dedicated external nodes
nash equilibrium both earn
a simple binary test
equilibrium both earn less
simple binary test performed
both earn less than
binary test performed by
earn less than they
there can be just
less than they would
test performed by the
than they would have
can be just one
they would have if
performed by the os
would have if neither
be just one or
have if neither attacked
by the os upon
idea overview to see
the os upon receipt
just one or a
os upon receipt of
one or a few
upon receipt of an
or a few global
with multiple pools of
receipt of an inquiry
overview to see why
a few global auditors
to see why lfs
multiple pools of equal
see why lfs is
pools of equal size
why lfs is a
of equal size a
indicating whether the process
lfs is a natural
we describe their roles
whether the process is
is a natural solution
describe their roles and
the process is still
equal size a similar
a natural solution to
size a similar situation
natural solution to the
a similar situation arises
process is still present
similar situation arises with
solution to the problem
situation arises with a
is still present in
their roles and interactions
still present in the
roles and interactions in
to the problem of
arises with a symmetric
the problem of disk
present in the process
problem of disk power
with a symmetric equilibrium
and interactions in detail
in the process table
interactions in detail below
of disk power management
the process table and
process table and thus
table and thus not
the fact that block
and thus not has
fact that block withholding
consider some of the
thus not has crashed
that block withholding is
some of the challenges
block withholding is not
of the challenges involved
not has crashed or
withholding is not common
has crashed or voluntary
is not common may
crashed or voluntary exited
not common may be
common may be explained
may be explained by
be explained by modeling
server systems typically are
explained by modeling the
systems typically are not
local auditors each node
the two other levels
auditors each node n
typically are not idle
each node n runs
two other levels that
node n runs a
are not idle long
n runs a local
other levels that are
runs a local auditor
by modeling the attack
not idle long enough
modeling the attack decisions
levels that are currently
the attack decisions as
that are currently implemented
attack decisions as an
which interacts with other
decisions as an iterative
idle long enough to
as an iterative prisoner
interacts with other local
an iterative prisoner s
long enough to make
iterative prisoner s dilemma
provide a remote process
with other local auditors
enough to make it
other local auditors and
a remote process with
local auditors and has
to make it worthwhile
auditors and has two
make it worthwhile to
and has two main
remote process with information
has two main roles
it worthwhile to incur
process with information about
worthwhile to incur the
we argue that the
with information about the
to incur the time
argue that the situation
information about the progress
that the situation is
publish n s data
the situation is unstable
n s data exchange
about the progress the
power expense of switching
s data exchange history
expense of switching the
the progress the local
of switching the disk
situation is unstable since
switching the disk to
progress the local process
the disk to a
is unstable since the
disk to a lowpower
the local process is
to a lowpower mode
unstable since the attack
n s local auditor
since the attack can
local process is making
the attack can be
s local auditor periodically
attack can be done
and switching it back
local auditor periodically compiles
switching it back when
process is making which
it back when it
auditor periodically compiles and
back when it is
periodically compiles and distributes
is making which is
when it is accessed
making which is useful
compiles and distributes the
which is useful in
can be done anonymously
is useful in the
and distributes the history
useful in the investigation
this is a notable
distributes the history of
is a notable point
the history of packets
in the investigation of
history of packets exchanged
a notable point of
of packets exchanged by
the investigation of processes
notable point of difference
investigation of processes that
one pool may decide
of processes that are
point of difference between
pool may decide to
processes that are alive
may decide to increase
of difference between server
decide to increase its
difference between server systems
to increase its revenue
packets exchanged by n
between server systems and
increase its revenue and
server systems and typical
but that appear slow
systems and typical mobile
that appear slow or
and typical mobile device
appear slow or unresponsive
typical mobile device scenarios
its revenue and drag
revenue and drag the
and drag the others
drag the others to
the others to attack
others to attack as
to attack as well
it queries the local
at certain intervals the
queries the local streaming
certain intervals the process
ending with a reduced
the local streaming application
with a reduced revenue
intervals the process logs
a reduced revenue for
local streaming application running
reduced revenue for all
the process logs checkpoint
streaming application running on
which makes it hard
application running on n
process logs checkpoint timestamps
makes it hard to
the inferior revenue would
logs checkpoint timestamps with
inferior revenue would push
checkpoint timestamps with the
revenue would push miners
timestamps with the failure
would push miners to
with the failure service
push miners to join
it hard to translate
miners to join private
running on n for
to join private pools
hard to translate the
on n for the
which simultaneously logs the
to translate the solutions
simultaneously logs the process
n for the set
translate the solutions devised
which can verify that
the solutions devised for
for the set of
solutions devised for mobile
can verify that their
devised for mobile devices
the set of packets
for mobile devices to
verify that their registered
set of packets it
mobile devices to server
that their registered miners
devices to server systems
of packets it sent
the response to an
packets it sent and
their registered miners do
it sent and received
registered miners do not
response to an inquiry
miners do not withhold
sent and received using
do not withhold blocks
to an inquiry request
as we shall see
an inquiry request holds
and received using the
inquiry request holds the
received using the streaming
request holds the last
this would lead to
holds the last checkpoint
would lead to smaller
the last checkpoint timestamp
lead to smaller pools
using the streaming protocol
the streaming protocol in
access to a small
streaming protocol in the
to a small subset
protocol in the most
a small subset of
and so ultimately to
small subset of disks
in the most recent
the current local time
the most recent time
so ultimately to a
most recent time interval
ultimately to a better
to a better environment
a better environment for
whether the process has
better environment for bitcoin
the process has been
environment for bitcoin as
process has been allocated
for bitcoin as a
when combined with a
bitcoin as a whole
has been allocated cpu
combined with a cache
been allocated cpu time
with a cache that
allocated cpu time since
a cache that absorbs
cpu time since the
cache that absorbs read
time since the last
since the last checkpoint
for their valuable advice
the local auditor signs
and whether the process
local auditor signs and
whether the process has
auditor signs and publishes
the process has consumed
results in long disk
process has consumed any
in long disk idle
has consumed any messages
long disk idle periods
signs and publishes the
consumed any messages since
the author is grateful
and publishes the collected
any messages since the
author is grateful to
messages since the last
is grateful to ken
since the last checkpoint
grateful to ken birman
low predictability of idle
publishes the collected history
predictability of idle periods
the collected history to
collected history to an
history to an assigned
to an assigned subset
an assigned subset of
upon receipt of an
assigned subset of its
receipt of an inquiry
subset of its neighboring
of an inquiry the
of its neighboring nodes
emin gu n sirer
an inquiry the operating
inquiry the operating system
the operating system uses
operating system uses an
system uses an upcall
from whom other auditors
whom other auditors may
have shown that there
other auditors may obtain
shown that there exists
auditors may obtain it
and the paper shepherd
that there exists low
the paper shepherd joseph
there exists low correlation
paper shepherd joseph bonneau
to interrupt the process
exists low correlation between
interrupt the process and
this level of indirection
the process and requests
low correlation between a
level of indirection is
process and requests that
correlation between a given
and requests that the
of indirection is used
requests that the process
between a given idle
indirection is used to
that the process prepares
a given idle period
the process prepares a
is used to prevent
process prepares a special
given idle period s
prepares a special response
used to prevent nodes
idle period s duration
to prevent nodes from
period s duration and
prevent nodes from masking
s duration and the
this response is returned
nodes from masking their
response is returned to
duration and the duration
is returned to the
from masking their real
and the duration of
returned to the caller
the duration of previous
masking their real upload
duration of previous idle
their real upload and
of previous idle periods
real upload and download
upload and download factors
and download factors by
download factors by presenting
factors by presenting different
this variability makes it
by presenting different information
the previous sections all
presenting different information to
variability makes it difficult
different information to different
previous sections all deal
information to different auditors
sections all deal with
peer electronic cash system
all deal with provisions
makes it difficult to
deal with provisions targeted
it difficult to devise
audit n s neighbors
with provisions targeted towards
n s neighbors histories
difficult to devise effective
provisions targeted towards the
to devise effective predictive
targeted towards the failure
devise effective predictive mechanisms
towards the failure management
effective predictive mechanisms for
the failure management of
predictive mechanisms for disk
n s local auditor
failure management of processes
s local auditor periodically
mechanisms for disk idle
local auditor periodically audits
for disk idle times
auditor periodically audits the
periodically audits the published
exploiting the close coupled
audits the published histories
the close coupled nature
the published histories of
close coupled nature of
published histories of the
the lfs neatly circumvents
histories of the nodes
coupled nature of a
lfs neatly circumvents this
of the nodes with
nature of a process
the nodes with whom
neatly circumvents this problem
nodes with whom n
of a process and
circumvents this problem by
with whom n exchanges
a process and the
whom n exchanges packets
this problem by predetermining
process and the operating
problem by predetermining which
and the operating system
by predetermining which disk
the operating system it
predetermining which disk is
operating system it runs
which disk is written
system it runs under
disk is written to
is written to at
written to at all
if node n exchanges
to at all times
node n exchanges packets
n exchanges packets with
to aid accurate detection
exchanges packets with nodes
packets with nodes p
aid accurate detection in
ebay s paypal unit
accurate detection in the
s paypal unit to
detection in the case
paypal unit to start
q and r in
unit to start accepting
and r in the
server systems are often
r in the livestreaming
to start accepting bitcoin
in the livestreaming protocol
systems are often constrained
in the case of
are often constrained by
start accepting bitcoin payments
the case of node
often constrained by service
case of node failure
constrained by service level
n s local auditor
by service level agreements
s local auditor compares
of node failure the
local auditor compares these
service level agreements to
auditor compares these three
node failure the fault
compares these three nodes
level agreements to guarantee
these three nodes histories
failure the fault management
three nodes histories with
the fault management system
agreements to guarantee a
fault management system implements
to guarantee a certain
nodes histories with n
guarantee a certain level
histories with n s
a certain level of
with n s own
certain level of performance
n s own history
management system implements a
system implements a node
implements a node management
a node management service
this involves ensuring that
so that finding a
that finding a solution
finding a solution that
which is based on
a solution that provides
is based on the
solution that provides acceptable
based on the experience
that provides acceptable performance
on the experience that
provides acceptable performance to
the experience that local
acceptable performance to only
experience that local failure
performance to only a
that local failure investigation
to only a fraction
local failure investigation on
only a fraction of
the amount of data
a fraction of the
failure investigation on a
fraction of the incoming
google adds bitcoin currency
of the incoming requests
investigation on a subnet
amount of data sent
on a subnet is
adds bitcoin currency conversion
a subnet is more
of data sent by
subnet is more accurate
bitcoin currency conversion to
data sent by these
is more accurate than
sent by these nodes
currency conversion to search
by these nodes satisfies
more accurate than investigation
these nodes satisfies the
accurate than investigation over
albeit a large fraction
nodes satisfies the defined
than investigation over the
satisfies the defined minimum
investigation over the internet
the defined minimum threshold
may often not be
defined minimum threshold for
often not be sufficient
minimum threshold for the
threshold for the system
on a participating subnet
a participating subnet one
as we shall show
participating subnet one or
subnet one or more
one or more node
or more node failure
more node failure monitors
the lfs provides an
lfs provides an applicationindependent
provides an applicationindependent solution
an applicationindependent solution that
applicationindependent solution that allows
solution that allows the
that allows the system
the set of packets
allows the system to
the system to perform
set of packets they
these are simple services
system to perform consistently
of packets they claim
are simple services capable
to perform consistently across
packets they claim to
perform consistently across a
simple services capable of
they claim to have
consistently across a wide
services capable of performing
across a wide range
capable of performing local
a wide range of
of performing local failure
wide range of datasets
claim to have sent
performing local failure investigations
to have sent to
local failure investigations upon
have sent to and
failure investigations upon requests
the law of large
sent to and received
law of large numbers
investigations upon requests from
to and received from
upon requests from remote
and received from node
requests from remote nodes
received from node n
large scale server systems
from node n corresponds
scale server systems process
node n corresponds to
server systems process incredibly
n corresponds to the
systems process incredibly large
corresponds to the set
process incredibly large request
to the set of
incredibly large request loads
the set of packets
set of packets n
of packets n claims
multicast to announce their
packets n claims to
directing these to a
to announce their availability
these to a small
n claims to have
to a small fraction
announce their availability within
a small fraction of
claims to have respectively
small fraction of the
their availability within the
fraction of the total
to have respectively received
of the total number
availability within the organization
the total number of
have respectively received from
total number of disks
within the organization where
respectively received from and
the organization where their
received from and sent
organization where their presence
from and sent to
where their presence is
the fraction that is
their presence is being
fraction that is in
presence is being tracked
that is in high
and sent to them
is being tracked by
being tracked by the
tracked by the other
by the other nfm
if the first check
the first check comparison
first check comparison fails
can significantly raise the
significantly raise the probability
raise the probability of
the probability of error
the local auditor issues
probability of error and
an nfm accepts queries
of error and failure
local auditor issues an
nfm accepts queries from
auditor issues an accusation
accepts queries from remote
issues an accusation against
queries from remote nodes
an accusation against the
from remote nodes about
accusation against the node
the fact that the
against the node to
remote nodes about the
the node to a
fact that the disks
node to a global
nodes about the availability
to a global auditor
that the disks used
about the availability of
the disks used in
the availability of a
disks used in these
availability of a node
used in these contexts
of a node within
in the second case
a node within its
in these contexts are
node within its organization
these contexts are typically
contexts are typically low
the local auditor is
local auditor is not
auditor is not able
it will forward this
is not able to
end with relatively weak
not able to prove
with relatively weak reliability
able to prove the
relatively weak reliability guarantees
to prove the neighbor
will forward this request
prove the neighbor s
the neighbor s misbehavior
forward this request to
this request to an
request to an nfm
to an nfm on
as we shall see
an nfm on the
nfm on the particular
on the particular subnet
it instructs its local
the particular subnet which
instructs its local streaming
our solution alleviates this
particular subnet which will
its local streaming application
solution alleviates this problem
subnet which will investigate
local streaming application to
alleviates this problem by
which will investigate the
streaming application to not
this problem by making
application to not further
will investigate the availability
to not further exchange
problem by making sure
not further exchange packets
investigate the availability of
further exchange packets with
by making sure that
exchange packets with the
the availability of the
packets with the misbehaving
making sure that the
with the misbehaving neighbor
availability of the node
sure that the live
of the node by
that the live subset
the node by launching
the live subset of
node by launching a
live subset of disks
by launching a number
more complex types of
launching a number of
subset of disks is
a number of fault
of disks is not
number of fault test
disks is not constant
complex types of checks
of fault test requests
types of checks may
of checks may also
checks may also be
the rest of this
may also be performed
rest of this paper
also be performed to
if this is support
be performed to address
of this paper is
performed to address other
this paper is organized
to address other types
this is support by
address other types of
paper is organized as
other types of byzantine
is organized as follows
types of byzantine behavior
is support by the
support by the host
by the host under
the host under investigation
host under investigation or
under investigation or by
investigation or by icmp
describes some of the
or by icmp echo
some of the solutions
by icmp echo requests
of the solutions explored
icmp echo requests if
the solutions explored in
echo requests if not
solutions explored in the
explored in the first
in the first three
the first three quadrants
first three quadrants mentioned
the result of the
three quadrants mentioned above
result of the query
of the query is
the query is then
query is then returned
is then returned to
then returned to the
returned to the requesting
to the requesting node
presents and analyzes our
and analyzes our solution
the nfm also functions
nfm also functions as
also functions as proxy
functions as proxy for
discusses our evaluation methodology
as proxy for process
our evaluation methodology and
proxy for process availability
evaluation methodology and results
for process availability queries
process availability queries in
availability queries in the
we conclude in section
queries in the case
in the case where
the case where a
case where a firewall
where a firewall obstructs
a firewall obstructs the
firewall obstructs the free
obstructs the free querying
the free querying of
free querying of the
querying of the nodes
of the nodes by
the nodes by their
nodes by their peers
based solutions the concept
solutions the concept of
the concept of a
concept of a memory
of a memory hierarchy
a memory hierarchy arose
s are configured with
memory hierarchy arose as
are configured with domain
hierarchy arose as a
configured with domain and
arose as a result
with domain and acl
as a result of
domain and acl mechanisms
a result of the
and acl mechanisms to
result of the natural
acl mechanisms to control
of the natural tradeoff
mechanisms to control access
the natural tradeoff between
to control access to
natural tradeoff between memory
repurposing bitcoin work for
control access to the
bitcoin work for data
tradeoff between memory speed
work for data preservation
between memory speed and
access to the information
memory speed and memory
speed and memory cost
in proceedings of the
proceedings of the ieee
an extension which is
of the ieee symposium
extension which is under
the ieee symposium on
which is under investigation
ieee symposium on security
is under investigation is
symposium on security and
under investigation is to
on security and privacy
investigation is to have
is to have nodes
to have nodes multicast
have nodes multicast heartbeats
nodes multicast heartbeats with
multicast heartbeats with local
heartbeats with local node
with local node information
local node information periodically
that there exists a
there exists a similar
exists a similar tradeoff
this information can be
a similar tradeoff between
information can be collected
similar tradeoff between performance
can be collected by
tradeoff between performance and
be collected by the
between performance and power
collected by the local
by the local nfm
s and shared in
and shared in compressed
shared in compressed form
performance disks and low
in compressed form among
compressed form among the
form among the other
among the other nfm
performance disks such as
disks such as laptop
such as laptop disks
s in the organization
namecoin dns dotbit project
they explore the possibility
local system management tools
explore the possibility of
system management tools can
the possibility of setting
management tools can connect
possibility of setting up
tools can connect to
of setting up a
can connect to an
setting up a disk
connect to an nfm
up a disk hierarchy
to an nfm to
a disk hierarchy by
an nfm to retrieve
disk hierarchy by using
nfm to retrieve the
hierarchy by using high
to retrieve the information
retrieve the information and
the information and set
information and set trap
and set trap conditions
performance disks in conjunction
disks in conjunction with
in conjunction with each
conjunction with each other
in distributed systems build
distributed systems build on
systems build on top
in a related vein
build on top of
on top of a
top of a web
of a web of
a web of interconnected
web of interconnected networks
we have to take
have to take network
to take network failure
take network failure into
network failure into account
failures at network level
propose dynamic rotations per
at network level are
dynamic rotations per minute
network level are in
level are in general
are in general related
in general related to
general related to crash
related to crash failures
to crash failures of
crash failures of routers
failures of routers and
of routers and gateways
a next generation smart
next generation smart contract
whereby disks can be
disks can be run
or to severe degradation
can be run at
to severe degradation of
be run at multiple
severe degradation of the
run at multiple speeds
degradation of the service
at multiple speeds depending
of the service level
multiple speeds depending on
the service level due
speeds depending on whether
service level due to
depending on whether power
level due to network
on whether power or
due to network congestion
whether power or performance
power or performance takes
or performance takes precedence
causing minimum performance requirements
minimum performance requirements to
performance requirements to be
requirements to be violated
global auditing there are
auditing there are two
there are two ways
the failure investigator will
are two ways in
poses a significant engineering
two ways in which
a significant engineering challenge
ways in which a
significant engineering challenge whose
when not able to
in which a node
not able to reach
engineering challenge whose feasibility
able to reach the
which a node could
to reach the node
challenge whose feasibility is
reach the node under
whose feasibility is far
the node under investigation
feasibility is far from
a node could pretend
node under investigation or
is far from obvious
under investigation or a
node could pretend to
investigation or a relevant
could pretend to be
or a relevant nfm
pretend to be sending
another approach is proposed
to be sending more
approach is proposed by
be sending more or
is proposed by colarelli
sending more or receiving
proposed by colarelli et
more or receiving less
perform a path search
or receiving less data
a path search to
receiving less data than
path search to find
less data than it
search to find the
data than it actually
to find the trouble
than it actually does
find the trouble spot
the trouble spot in
trouble spot in the
spot in the network
it could send different
could send different histories
send different histories to
different histories to each
it uses the traceroute
histories to each neighbor
uses the traceroute technique
the traceroute technique of
traceroute technique of emitting
technique of emitting small
always lying about its
of emitting small messages
lying about its interactions
emitting small messages with
about its interactions with
small messages with limited
using massive arrays of
messages with limited ttl
its interactions with other
massive arrays of inexpensive
interactions with other neighbors
arrays of inexpensive disks
triggering icmp responses from
icmp responses from routers
n could send a
responses from routers among
could send a history
from routers among the
send a history to
they propose the use
routers among the path
a history to p
propose the use of
history to p pretending
the use of a
to p pretending to
use of a small
p pretending to send
of a small number
pretending to send more
if an obstruction is
to send more data
a small number of
send more data to
an obstruction is found
more data to q
small number of cache
data to q than
obstruction is found it
to q than it
number of cache disks
q than it actually
is found it is
than it actually did
of cache disks in
found it is reported
cache disks in addition
it is reported to
disks in addition to
is reported to the
in addition to the
reported to the caller
while it sends a
addition to the maid
analysis of bitcoin pooled
it sends a different
of bitcoin pooled mining
to the maid disks
bitcoin pooled mining reward
sends a different history
pooled mining reward systems
the failure management library
a different history to
failure management library offers
different history to q
management library offers functionality
the data in these
history to q where
library offers functionality to
to q where it
data in these cache
q where it pretends
offers functionality to keep
where it pretends to
in these cache disks
it pretends to send
functionality to keep the
pretends to send more
these cache disks is
to send more data
to keep the obstruction
send more data to
cache disks is updated
keep the obstruction under
more data to p
disks is updated to
data to p than
the obstruction under investigation
to p than it
is updated to reflect
p than it actually
obstruction under investigation and
than it actually did
updated to reflect the
under investigation and to
to reflect the workload
investigation and to notify
reflect the workload that
and to notify the
the workload that is
to notify the application
workload that is currently
n s goal would
notify the application once
that is currently being
s goal would be
the application once the
is currently being accessed
application once the obstruction
goal would be to
once the obstruction seems
would be to send
the obstruction seems to
be to send less
obstruction seems to be
to send less data
seems to be removed
send less data while
the maid disks can
less data while not
maid disks can then
data while not being
disks can then be
while not being caught
can then be powered
not being caught by
then be powered down
being caught by any
this way the process
caught by any of
way the process does
by any of its
and need only be
any of its neighbors
need only be spun
the process does not
only be spun up
be spun up when
process does not need
spun up when a
up when a cache
does not need to
when a cache miss
the process of publishing
not need to keep
a cache miss occurs
process of publishing a
need to keep the
of publishing a node
to keep the partitioned
publishing a node s
keep the partitioned processes
upon which their contents
the partitioned processes under
which their contents are
a node s history
their contents are copied
partitioned processes under investigation
node s history to
contents are copied onto
processes under investigation but
are copied onto the
s history to a
under investigation but can
copied onto the cache
history to a predefined
onto the cache disks
investigation but can wait
to a predefined set
but can wait until
a predefined set of
can wait until the
predefined set of neighbors
wait until the connectivity
this approach has several
until the connectivity is
set of neighbors ensures
approach has several of
the connectivity is restored
has several of the
of neighbors ensures that
several of the weaknesses
connectivity is restored by
of the weaknesses that
neighbors ensures that the
the weaknesses that memory
is restored by simply
weaknesses that memory caches
ensures that the node
that memory caches suffer
restored by simply monitoring
that the node cannot
by simply monitoring the
the node cannot send
simply monitoring the trouble
node cannot send conflicting
monitoring the trouble spot
cannot send conflicting histories
only on a larger
send conflicting histories to
on a larger scale
conflicting histories to different
histories to different neighbors
to different neighbors undetected
in case the network
case the network topology
the network topology permits
if the cache disks
network topology permits it
the cache disks are
cache disks are insufficient
disks are insufficient to
therefore avoiding this problem
are insufficient to store
the investigator can be
insufficient to store the
investigator can be configured
to store the entire
can be configured to
store the entire working
be configured to use
the entire working set
configured to use alternate
a node could also
to use alternate paths
entire working set of
node could also lie
working set of the
could also lie about
set of the current
also lie about the
of the current workload
lie about the set
about the set of
the set of packets
set of packets sent
of packets sent to
packets sent to or
sent to or received
research perspectives on bitcoin
to or received from
to reach one of
or received from a
reach one of the
received from a particular
one of the destination
from a particular neighbor
of the destination nfm
a particular neighbor p
with considerable latency penalties
perspectives on bitcoin and
on bitcoin and secondgeneration
bitcoin and secondgeneration cryptocurrencies
from cornell for example
cornell for example it
p will be able
in ieee symposium on
for example it is
ieee symposium on security
example it is possible
symposium on security and
it is possible to
on security and privacy
is possible to construct
the cache disks represent
will be able to
cache disks represent a
be able to identify
disks represent a significant
able to identify that
represent a significant added
alternative routes to anywhere
a significant added cost
routes to anywhere in
significant added cost in
to anywhere in california
added cost in themselves
to identify that the
identify that the node
that the node has
the node has lied
node has lied and
disk management solutions pinheiro
has lied and will
management solutions pinheiro and
lied and will therefore
solutions pinheiro and bianchini
the request contains sufficient
and will therefore stop
request contains sufficient information
will therefore stop exchanging
contains sufficient information for
therefore stop exchanging packets
sufficient information for the
stop exchanging packets with
information for the nfm
exchanging packets with n
for the nfm to
the nfm to construct
nfm to construct a
to construct a symmetric
construct a symmetric return
given that an opportunistic
a symmetric return path
that an opportunistic node
an opportunistic node s
suggest that if data
opportunistic node s goal
that if data is
node s goal is
protocols that can exploit
if data is laid
that can exploit this
s goal is to
can exploit this type
goal is to maximize
exploit this type of
is to maximize its
data is laid out
to maximize its utility
this type of information
is laid out on
type of information are
laid out on disks
of information are under
out on disks according
information are under development
on disks according to
it should have no
disks according to frequency
should have no interest
according to frequency of
have no interest in
to frequency of access
no interest in losing
interest in losing data
in losing data exchange
losing data exchange partners
with the most popular
the most popular files
most popular files being
popular files being located
files being located in
being located in one
located in one set
in one set of
opportunistic nodes have no
one set of disks
nodes have no incentive
have no incentive to
no incentive to publish
incentive to publish incorrect
to publish incorrect histories
and the least popular
the least popular ones
least popular ones in
popular ones in another
then the latter set
local auditing ensures that
the latter set of
auditing ensures that correct
latter set of disks
failure investigation of a
set of disks could
investigation of a process
ensures that correct information
of a process at
of disks could be
that correct information is
a process at the
disks could be powered
process at the same
correct information is available
at the same sub
could be powered down
information is available regarding
be powered down to
is available regarding the
powered down to conserve
available regarding the set
down to conserve energy
regarding the set of
net has always been
the set of data
has always been viewed
set of data sent
always been viewed as
of data sent and
been viewed as a
data sent and received
their scheme is called
sent and received by
viewed as a reasonably
and received by any
scheme is called popular
received by any node
as a reasonably accurate
is called popular data
called popular data concentration
and allows nodes to
reasons for false suspicions
allows nodes to monitor
for false suspicions were
nodes to monitor each
false suspicions were overload
to monitor each other
suspicions were overload in
monitor each other s
were overload in the
each other s contribution
overload in the receiver
and they implement and
other s contribution rates
they implement and evaluate
in the receiver os
implement and evaluate a
and evaluate a prototype
evaluate a prototype file
a prototype file server
prototype file server called
file server called nomad
server called nomad fs
which runs on top
runs on top of
on top of the
top of the file
of the file system
the file system and
file system and monitors
system and monitors data
which could cause high
and monitors data layout
could cause high message
monitors data layout on
cause high message loss
global auditors global auditors
data layout on disks
auditors global auditors are
global auditors are trusted
auditors are trusted components
or unresponsiveness due to
are trusted components with
unresponsiveness due to application
trusted components with global
due to application overload
components with global membership
their findings are that
with global membership knowledge
findings are that if
are that if the
that if the low
although that could be
that could be seen
could be seen as
who interact with one
be seen as a
access disks are powered
seen as a design
disks are powered down
as a design error
interact with one another
with one another and
one another and with
another and with the
and with the local
this results in a
with the local auditors
results in a considerable
in a considerable performance
a considerable performance hit
although confident about the
confident about the result
as shown in figure
they suggest instead that
suggest instead that they
one was never guaranteed
instead that they be
was never guaranteed that
that they be run
never guaranteed that the
they be run at
guaranteed that the process
be run at low
that the process had
run at low speed
global auditors execute on
the process had truly
auditors execute on nodes
process had truly crashed
execute on nodes external
on nodes external to
while their idea is
nodes external to the
their idea is sound
external to the system
using the os failure
the os failure management
os failure management extensions
it is not clear
their main roles are
is not clear whether
not clear whether this
clear whether this scheme
this assurance is now
whether this scheme would
assurance is now available
this scheme would adapt
define the minimum upload
scheme would adapt to
the minimum upload threshold
would adapt to different
adapt to different workloads
the time needed by
time needed by the
global auditors periodically sample
needed by the failure
auditors periodically sample the
by the failure detector
periodically sample the state
the failure detector to
sample the state of
failure detector to come
the state of the
detector to come to
state of the system
to come to a
of the system by
come to a result
propose another data layout
the system by querying
another data layout management
system by querying local
to a result has
data layout management scheme
a result has been
by querying local auditors
result has been greatly
layout management scheme to
has been greatly reduced
management scheme to optimize
been greatly reduced in
scheme to optimize disk
greatly reduced in the
to optimize disk access
reduced in the optimistic
optimize disk access patterns
they then cooperate to
then cooperate to analyze
cooperate to analyze the
to analyze the collected
analyze the collected samples
common case that the
case that the node
that the node on
the node on which
node on which the
and on this basis
on which the process
on this basis compute
which the process was
this basis compute the
the process was running
basis compute the minimum
process was running is
compute the minimum upload
was running is reachable
the minimum upload contribution
minimum upload contribution threshold
their approach uses finer
regardless if the process
if the process has
different strategies may be
the process has failed
strategies may be employed
grained control over data
process has failed or
control over data layout
has failed or not
over data layout on
may be employed for
data layout on disk
be employed for choosing
employed for choosing the
for choosing the best
the node is able
choosing the best possible
node is able to
tuning it on a
the best possible threshold
is able to indicate
it on a per
information propagation in the
able to indicate whether
propagation in the bitcoin
to indicate whether or
in the bitcoin network
indicate whether or not
whether or not the
or not the process
not the process has
once thresholds are varied
the process has crashed
applications are instrumented and
are instrumented and then
instrumented and then profiled
and then profiled to
they are gossiped to
then profiled to obtain
are gossiped to all
profiled to obtain array
gossiped to all local
th ieee international conference
to all local auditors
in general a single
to obtain array access
general a single round
ieee international conference on
obtain array access sequences
international conference on peer
who then enforce the
then enforce the determined
enforce the determined threshold
trip time is sufficient
time is sufficient at
which their system then
is sufficient at the
their system then uses
sufficient at the local
system then uses to
expurge nodes from the
then uses to determine
nodes from the system
at the local network
uses to determine optimal
the local network to
to determine optimal disk
local network to get
determine optimal disk layouts
network to get a
optimal disk layouts by
to get a result
global auditors are also
disk layouts by computing
auditors are also responsible
layouts by computing optimal
are also responsible for
by computing optimal stripe
also responsible for verifying
computing optimal stripe factor
responsible for verifying accusations
for verifying accusations issued
verifying accusations issued by
area case this time
accusations issued by local
case this time is
issued by local auditors
this time is a
by local auditors against
time is a function
local auditors against particular
is a function of
auditors against particular nodes
a function of the
function of the level
of the level of
the level of congestion
level of congestion in
and after validating the
of congestion in the
after validating the accusation
congestion in the network
the wisdom of marrying
in the network path
wisdom of marrying the
of marrying the disk
marrying the disk layout
expurging misbehaving nodes from
the disk layout to
misbehaving nodes from the
disk layout to the
the os extensions also
layout to the application
nodes from the system
to the application seems
os extensions also improve
the application seems questionable
extensions also improve the
also improve the confidence
improve the confidence in
the confidence in the
validation involves verifying that
confidence in the failure
involves verifying that the
in the failure investigation
verifying that the accused
the failure investigation process
bitcoin and the age
that the accused node
and the age of
failure investigation process in
the age of bespoke
the accused node s
age of bespoke silicon
investigation process in the
accused node s history
process in the wide
proposed by zhu et
node s history indeed
s history indeed indicates
in proceedings of the
history indeed indicates that
indeed indicates that the
indicates that the node
that the node is
using the old strategy
the node is sending
the old strategy of
node is sending less
is sending less data
old strategy of simply
sending less data than
strategy of simply polling
less data than the
of simply polling a
data than the current
simply polling a process
than the current threshold
polling a process until
a process until a
international conference on compilers
combines a number of
process until a time
a number of ideas
expurging a node involves
architectures and synthesis for
a node involves informing
and synthesis for embedded
it assumes multispeed disks
synthesis for embedded systems
out occurs gives much
node involves informing the
occurs gives much less
involves informing the nodes
gives much less confidence
informing the nodes immediate
much less confidence in
and computes online the
less confidence in the
the nodes immediate neighbors
confidence in the result
computes online the optimal
nodes immediate neighbors of
in the result of
online the optimal speed
the result of the
immediate neighbors of its
result of the failure
the optimal speed that
of the failure investigation
neighbors of its status
optimal speed that each
of its status and
speed that each disk
its status and forcing
that each disk should
status and forcing the
if no response was
each disk should run
and forcing the removal
disk should run at
no response was received
forcing the removal of
response was received after
the removal of the
was received after the
removal of the node
received after the maximum
of the node from
after the maximum number
to minimize speed transition
the maximum number of
minimize speed transition overheads
maximum number of retransmission
the node from the
number of retransmission is
node from the overlay
of retransmission is reached
from the overlay mesh
disks maintain their speeds
maintain their speeds for
their speeds for a
speeds for a fixed
it was not certain
the number of global
was not certain whether
number of global auditors
not certain whether this
of global auditors may
certain whether this was
global auditors may vary
whether this was because
auditors may vary according
this was because of
may vary according to
was because of network
vary according to different
because of network failure
according to different parameters
into the bitcoin mines
they call this the
call this the coarse
host failure or process
such as the size
failure or process failure
as the size of
the size of the
size of the system
with the new scheme
the new scheme it
new scheme it is
the use of more
scheme it is possible
use of more global
hibernator includes a file
it is possible to
of more global auditors
is possible to distinguish
includes a file server
more global auditors distributes
possible to distinguish among
a file server that
to distinguish among these
global auditors distributes the
distinguish among these different
file server that sits
among these different failures
auditors distributes the load
server that sits on
distributes the load of
that sits on top
the load of sampling
sits on top of
load of sampling and
on top of the
of sampling and improves
additional information the full
sampling and improves efficiency
top of the file
information the full report
and improves efficiency in
of the file system
improves efficiency in reacting
the full report contains
efficiency in reacting to
the file system and
full report contains the
in reacting to accusations
file system and manipulates
reacting to accusations against
report contains the detailed
to accusations against nodes
system and manipulates data
contains the detailed results
and manipulates data layout
the detailed results of
manipulates data layout to
detailed results of the
data layout to put
results of the trace
layout to put the
global auditors are also
of the trace study
to put the most
auditors are also perfect
the trace study on
are also perfect candidates
trace study on the
also perfect candidates to
study on the accuracy
perfect candidates to perform
on the accuracy and
accessed data on the
the accuracy and performance
data on the highest
candidates to perform membership
accuracy and performance of
on the highest speed
to perform membership tasks
the highest speed disks
and performance of the
perform membership tasks such
performance of the failure
membership tasks such as
of the failure detector
tasks such as acting
the failure detector in
such as acting as
the authors address the
failure detector in the
as acting as entry
detector in the internet
authors address the issue
acting as entry points
address the issue of
as entry points to
the issue of performance
entry points to the
issue of performance guarantees
points to the p
the effectiveness of its
of performance guarantees by
effectiveness of its partition
performance guarantees by stipulating
of its partition detection
guarantees by stipulating that
its partition detection mechanism
by stipulating that if
stipulating that if performance
that if performance drops
if performance drops below
performance drops below some
since they are required
drops below some threshold
they are required to
host failure measurements and
failure measurements and measurements
then all disks are
measurements and measurements of
all disks are spun
and measurements of failure
disks are spun up
measurements of failure detection
are spun up to
of failure detection for
spun up to their
failure detection for server
up to their highest
detection for server fail
to their highest speed
caching solutions zhu et
are required to have
required to have full
it will be available
to have full membership
will be available later
have full membership knowledge
be available later this
full membership knowledge of
available later this year
membership knowledge of the
later this year through
knowledge of the system
this year through the
of the system for
year through the cornell
observe that the storage
the system for performing
through the cornell university
system for performing their
that the storage cache
for performing their auditing
the cornell university technical
performing their auditing roles
the storage cache management
cornell university technical report
storage cache management policy
university technical report server
cache management policy is
management policy is pivotal
policy is pivotal in
is pivotal in determining
pivotal in determining the
in determining the sequence
global auditing monitors the
determining the sequence of
auditing monitors the global
the sequence of requests
monitors the global health
sequence of requests that
of requests that access
the global health of
requests that access disks
global health of the
health of the system
of the system to
the system to identify
system to identify the
to identify the best
identify the best value
cache management policies could
the best value for
management policies could be
best value for the
policies could be tailored
value for the minimum
could be tailored to
for the minimum upload
be tailored to change
the minimum upload threshold
tailored to change the
minimum upload threshold at
to change the average
upload threshold at any
change the average idle
threshold at any time
the average idle time
relevant url s the
average idle time between
at any time during
url s the horus
any time during a
idle time between disk
s the horus project
time between disk requests
time during a streaming
the horus project the
during a streaming session
horus project the cornell
project the cornell cluster
thus providing more opportunities
the cornell cluster computing
providing more opportunities for
and makes final decisions
more opportunities for reducing
cornell cluster computing project
opportunities for reducing disk
makes final decisions regarding
for reducing disk energy
cluster computing project werner
reducing disk energy consumption
final decisions regarding punishment
computing project werner vogels
decisions regarding punishment of
project werner vogels personal
regarding punishment of nodes
werner vogels personal home
vogels personal home page
personal home page papers
home page papers on
page papers on failure
cache policies that are
papers on failure detection
policies that are aware
on failure detection http
that are aware of
are aware of the
aware of the underlying
of the underlying disk
the underlying disk management
underlying disk management schemes
adaptive threshold strategies choosing
threshold strategies choosing an
strategies choosing an upload
choosing an upload threshold
an upload threshold requires
upload threshold requires care
which disks are running
disks are running at
are running at which
running at which speeds
a low threshold may
low threshold may not
threshold may not be
may not be sufficient
not be sufficient to
be sufficient to identify
sufficient to identify opportunistic
can make more intelligent
to identify opportunistic nodes
make more intelligent replacement
more intelligent replacement decisions
while high thresholds may
high thresholds may incorrectly
the authors present both
thresholds may incorrectly punish
authors present both offline
may incorrectly punish correct
present both offline and
incorrectly punish correct nodes
both offline and online
offline and online power
we considered different strategies
aware cache replacement algorithms
considered different strategies for
cache replacement algorithms to
different strategies for the
replacement algorithms to optimize
strategies for the choice
algorithms to optimize read
for the choice of
to optimize read accesses
the choice of the
choice of the minimum
of the minimum contribution
the minimum contribution t
minimum contribution t hreshold
they also show through
contribution t hreshold used
also show through experiments
t hreshold used for
show through experiments the
hreshold used for identifying
through experiments the somewhat
used for identifying misbehaving
experiments the somewhat obvious
for identifying misbehaving nodes
the somewhat obvious fact
somewhat obvious fact that
obvious fact that for
fact that for write
that for write accesses
the simplest strategy sets
simplest strategy sets a
strategy sets a fixed
sets a fixed threshold
back policies offer more
policies offer more opportunities
offer more opportunities to
more opportunities to save
opportunities to save power
to save power than
save power than write
in the context of
the context of write
a very natural candidate
very natural candidate is
natural candidate is the
candidate is the log
independent of the current
of the current state
the current state of
current state of the
state of the system
any node contributing at
node contributing at a
contributing at a rate
at a rate of
a rate of less
rate of less than
we now give a
now give a brief
give a brief overview
a brief overview of
brief overview of the
overview of the log
of the stream rate
the stream rate would
structured file system before
stream rate would be
file system before describing
rate would be removed
system before describing the
before describing the power
one downside of using
saving opportunity it represents
downside of using a
of using a fixed
using a fixed threshold
a fixed threshold is
fixed threshold is that
threshold is that opportunistic
is that opportunistic nodes
that opportunistic nodes that
opportunistic nodes that learn
nodes that learn the
that learn the threshold
learn the threshold can
the threshold can simply
threshold can simply contribute
can simply contribute at
structured file system the
simply contribute at the
file system the log
contribute at the lowest
at the lowest possible
the lowest possible upload
lowest possible upload factor
was motivated by a
from the graphs in
motivated by a need
the graphs in section
by a need to
transis a communication subsystem
a need to optimize
a communication subsystem for
need to optimize the
communication subsystem for high
to optimize the latency
subsystem for high availability
optimize the latency of
the latency of write
it is clear that
is clear that such
idigest of papers of
clear that such a
that such a stretagy
such a stretagy may
a stretagy may disrupt
stretagy may disrupt the
may disrupt the streaming
writing a block of
disrupt the streaming session
a block of data
block of data to
of data to a
data to a seagate
to a seagate barracuda
a seagate barracuda disk
seagate barracuda disk costs
barracuda disk costs about
choosing a high threshold
a high threshold is
high threshold is not
threshold is not a
is not a practical
not a practical option
since correct nodes would
correct nodes would get
nodes would get unfairly
would get unfairly punished
ms in seek time
in seek time and
to avoid this problem
we have explored adaptive
have explored adaptive strategies
one simple strategy starts
simple strategy starts with
strategy starts with a
starts with a minimum
with a minimum threshold
fast message ordering and
message ordering and membership
kb in transmission time
ordering and membership using
and membership using a
membership using a logical
using a logical token
the key observation here
key observation here is
observation here is that
here is that seek
is that seek time
that seek time is
seek time is a
time is a large
is a large and
a large and constant
large and constant term
and constant term in
constant term in latency
term in latency computation
to eliminate this term
the lfs replaces write
lfs replaces write operations
replaces write operations by
write operations by append
increasing it only if
operations by append operations
it only if the
only if the system
if the system is
the system is compromised
secondary storage is treated
storage is treated as
is treated as a
treated as a large
as a large append
global auditors sample the
auditors sample the system
sample the system to
the system to identify
system to identify the
only log and writes
to identify the average
log and writes always
identify the average download
and writes always go
the average download factor
writes always go to
always go to the
go to the log
to the log head
and if this factor
if this factor is
this factor is lower
factor is lower than
seek time is thus
time is thus eliminated
how a mining monopoly
and write latency becomes
a mining monopoly can
write latency becomes purely
mining monopoly can attack
latency becomes purely a
monopoly can attack bitcoin
becomes purely a function
purely a function of
a function of the
function of the disk
of the disk bandwidth
reliable communication in the
communication in the presence
in the presence of
the presence of failure
how do reads in
do reads in the
reads in the lfs
in the lfs work
acm transaction on computer
once the download factor
transaction on computer systems
the download factor reaches
in the same way
download factor reaches a
the same way as
factor reaches a satisfactory
same way as in
reaches a satisfactory level
way as in conventional
a satisfactory level again
as in conventional file
in conventional file systems
the threshold may be
threshold may be reduced
may be reduced back
be reduced back to
reduced back to its
back to its initial
to its initial value
and hence do not
hence do not avoid
do not avoid seek
this stepwise approach allows
stepwise approach allows the
approach allows the system
allows the system to
the system to catch
system to catch opportunistic
to catch opportunistic nodes
catch opportunistic nodes in
opportunistic nodes in case
the assumption is that
nodes in case their
assumption is that with
in case their presence
is that with good
case their presence starts
that with good caching
their presence starts affecting
with good caching mechanisms
presence starts affecting the
starts affecting the performance
affecting the performance of
the performance of the
performance of the system
reads will be a
will be a small
be a small fraction
a small fraction of
small fraction of disk
while avoiding incorrect accusations
fraction of disk accesses
avoiding incorrect accusations of
incorrect accusations of correct
accusations of correct nodes
as can be imagined
we also considered a
also considered a second
considered a second adaptive
space reclamation is a
a second adaptive strategy
reclamation is a tricky
is a tricky problem
group membership and viewsynchronous
a tricky problem in
membership and viewsynchronous communication
tricky problem in log
and viewsynchronous communication in
problem in log structured
viewsynchronous communication in partitionable
in log structured file
communication in partitionable asynchronous
log structured file systems
in partitionable asynchronous systems
for computing the threshold
computing the threshold based
the threshold based on
threshold based on periodically
based on periodically sampled
excellent solutions have been
on periodically sampled download
solutions have been proposed
periodically sampled download and
have been proposed to
sampled download and upload
been proposed to solve
download and upload factors
proposed to solve it
and one such is
the average download factors
one such is of
average download factors once
such is of interest
download factors once again
is of interest to
factors once again are
of interest to us
once again are used
again are used for
are used for detecting
used for detecting whether
the disk is divided
for detecting whether the
disk is divided into
detecting whether the threshold
is divided into large
whether the threshold should
divided into large log
the threshold should be
into large log segments
threshold should be varied
should be varied or
be varied or not
once a log segment
a log segment gets
log segment gets filled
our initial threshold is
initial threshold is set
a new log segment
threshold is set to
majority is not enough
new log segment is
is set to null
log segment is allocated
segment is allocated and
is allocated and the
bitcoin mining is vulnerable
allocated and the log
and the threshold is
and the log head
the threshold is chosen
the log head moves
threshold is chosen from
log head moves to
is chosen from sampled
head moves to the
in financial cryptography and
moves to the new
chosen from sampled upload
to the new segment
financial cryptography and data
from sampled upload factors
cryptography and data security
when some threshold of
some threshold of a
threshold of a segment
of a segment gets
a segment gets invalidated
if the system seems
the system seems to
system seems to be
seems to be in
its valid data is
unreliable failure detectors for
valid data is moved
to be in a
data is moved to
be in a compromised
is moved to another
in a compromised state
moved to another segment
failure detectors for reliable
detectors for reliable distributed
for reliable distributed systems
the collected upload factors
replacing that segment s
collected upload factors are
that segment s invalid
to appear in journal
segment s invalid data
upload factors are ordered
appear in journal of
factors are ordered and
in journal of the
are ordered and the
journal of the acm
ordered and the value
and the value dividing
the value dividing the
value dividing the lowest
and it is then
it is then added
is then added to
then added to the
added to the pool
to the pool of
the pool of free
pool of free log
percent is used as
of free log segments
is used as the
used as the new
as the new threshold
this approach relies on
approach relies on efficiently
this process results in
relies on efficiently sampling
process results in a
on efficiently sampling the
results in a natural
efficiently sampling the system
in a natural division
a natural division of
natural division of allocated
division of allocated segments
of allocated segments into
and on fact that
allocated segments into stable
on fact that if
fact that if the
that if the system
if the system s
the system s performance
system s performance is
s performance is not
performance is not satisfactory
consisting almost entirely of
impossibility of distributed consensus
almost entirely of data
of distributed consensus with
entirely of data that
distributed consensus with one
of data that is
consensus with one faulty
data that is rarely
with one faulty process
that is rarely invalidated
percent of the nodes
of the nodes are
the nodes are opportunistic
journal of the acm
evaluation in this section
which need to be
need to be constantly
to be constantly cleaned
we evaluate the performance
evaluate the performance of
the performance of our
performance of our proposed
of our proposed auditing
our proposed auditing strategy
proposed auditing strategy over
we will see how
auditing strategy over the
will see how this
strategy over the original
see how this feature
over the original streaming
how this feature can
the original streaming protocol
this feature can be
feature can be used
can be used to
be used to save
used to save power
we built an event
cooperative equilibrium for supergames
driven simulator and used
simulator and used it
the review of economic
and used it to
review of economic studies
used it to simulate
it to simulate streaming
to simulate streaming sessions
simulate streaming sessions on
streaming sessions on networks
sessions on networks with
r van and vogels
saving opportunity we shall
opportunity we shall now
we shall now argue
shall now argue that
nodes and an average
support for highly reliable
and an average of
now argue that there
argue that there remains
that there remains an
there remains an unexplored
remains an unexplored quadrant
an unexplored quadrant in
unexplored quadrant in this
quadrant in this solution
in this solution space
caches are used to
are used to minimize
used to minimize accesses
the target streaming rate
to minimize accesses to
target streaming rate in
minimize accesses to disk
streaming rate in the
rate in the experiments
in the experiments was
the experiments was fixed
acm sigops european workshop
experiments was fixed to
good caching algorithms practically
caching algorithms practically eliminate
algorithms practically eliminate read
practically eliminate read accesses
eliminate read accesses to
read accesses to disk
whether synchronous or not
and all our experiments
all our experiments were
our experiments were repeated
must still eventually access
still eventually access the
eventually access the disk
term competition a game
confidence intervals were small
disk access will be
access will be write
and for simplicity are
for simplicity are omitted
simplicity are omitted from
are omitted from the
omitted from the graphs
putting a disk management
a disk management layer
disk management layer on
management layer on top
layer on top of
on top of the
the source of the
top of the file
source of the stream
of the stream has
the stream has an
stream has an upload
has an upload capacity
system to optimize data
an upload capacity of
to optimize data layout
upload capacity of four
optimize data layout for
capacity of four times
data layout for writes
of four times the
layout for writes is
four times the stream
for writes is only
times the stream rate
writes is only halfway
reliable multicast for distributed
is only halfway to
multicast for distributed interactive
only halfway to the
for distributed interactive simulation
halfway to the solution
proceedings of acm sigcomm
to take this idea
take this idea to
this idea to its
and is connected to
idea to its logical
to its logical conclusion
it is necessary to
is necessary to rethink
necessary to rethink the
to rethink the file
rethink the file the
the file the disk
other nodes have enough
nodes have enough download
have enough download capacity
enough download capacity to
download capacity to receive
management policies described in
capacity to receive the
to receive the stream
policies described in the
described in the related
in the related works
the related works section
and upload factor of
related works section essentially
works section essentially attack
section essentially attack the
essentially attack the problem
attack the problem by
the problem by trying
problem by trying to
by trying to predict
trying to predict in
to predict in advance
predict in advance which
in advance which disk
advance which disk any
we defined an availability
which disk any given
defined an availability window
disk any given access
an availability window of
any given access will
given access will go
access will go to
seconds and an interest
they optimize the data
and an interest window
optimize the data layout
an interest window of
the data layout on
data layout on disks
layout on disks to
view synchronous communication in
on disks to ensure
synchronous communication in large
disks to ensure that
communication in large scale
to ensure that accesses
ensure that accesses are
to evaluate the quality
that accesses are localized
evaluate the quality of
accesses are localized to
the quality of each
are localized to some
quality of each auditing
localized to some fraction
of each auditing strategy
to some fraction of
nd open broadcast workshop
some fraction of the
fraction of the disks
we evaluate the average
evaluate the average download
the average download factors
so that only these
average download factors of
that only these need
download factors of correct
only these need be
factors of correct nodes
these need be powered
of correct nodes during
need be powered up
correct nodes during a
these are all probabilistic
are all probabilistic models
second time interval after
time interval after auditing
a new access has
interval after auditing is
new access has some
after auditing is first
access has some probability
auditing is first applied
has some probability of
is first applied to
some probability of not
first applied to the
probability of not fitting
applied to the system
of not fitting this
not fitting this model
fitting this model and
this model and needing
model and needing to
and needing to access
needing to access a
to access a powered
increasing reliability of communication
reliability of communication in
of communication in large
communication in large scale
we considered that global
in large scale distributed
considered that global auditors
that global auditors collected
global auditors collected information
auditors collected information from
disk layout becomes tied
layout becomes tied to
becomes tied to particular
tied to particular applications
nodes between each interval
between each interval of
two applications that have
applications that have completely
that have completely different
have completely different access
completely different access patterns
different access patterns might
access patterns might require
patterns might require completely
might require completely different
notice that the sample
require completely different data
that the sample size
completely different data layouts
the sample size does
different data layouts on
sample size does not
io bitcoin mining pool
size does not increase
data layouts on disk
does not increase with
layouts on disk leading
not increase with the
on disk leading to
increase with the size
disk leading to conflicts
with the size of
leading to conflicts that
the size of the
to conflicts that reduce
size of the system
conflicts that reduce possible
that reduce possible powersavings
which is a positive
is a positive aspect
since all writes in
a positive aspect of
all writes in an
positive aspect of the
writes in an lfs
aspect of the auditing
in an lfs are
of the auditing approach
an lfs are to
lfs are to the
are to the log
to the log head
we know in advance
know in advance which
in advance which disk
advance which disk they
which disk they will
disk they will access
a generic architecture for
generic architecture for dependable
we discuss the costs
architecture for dependable distributed
this gives us the
for dependable distributed computing
gives us the perfect
discuss the costs involved
us the perfect prediction
the costs involved in
the perfect prediction mechanism
costs involved in collecting
involved in collecting these
in collecting these samples
at least for writeaccesses
this prediction mechanism is
prediction mechanism is also
mechanism is also entirely
is also entirely application
if most accesses to
most accesses to disks
accesses to disks were
to disks were writes
we could power down
could power down every
power down every disk
down every disk but
every disk but the
disk but the one
but the one that
the one that the
one that the log
that the log head
the log head resides
log head resides on
is an ideal case
an ideal case scenario
a flexible group communications
flexible group communications system
our view is that
cornell university technical report
with a good caching
a good caching algorithm
number of false positives
of false positives download
false positives download factor
aware caching algorithms described
caching algorithms described in
algorithms described in the
described in the related
in the related works
the related works section
related works section are
works section are good
section are good candidates
reads to disk can
to disk can be
disk can be minimized
and only a small
only a small fraction
a small fraction of
small fraction of the
fraction of the disks
of the disks need
the disks need be
disks need be powered
need be powered on
be powered on in
powered on in order
on in order to
in order to serve
order to serve all
to serve all writes
serve all writes as
all writes as well
writes as well as
as well as reads
what about the performance
about the performance and
the performance and power
performance and power costs
and power costs of
power costs of log
costs of log cleaning
al present some optimizations
present some optimizations in
to hide the performance
hide the performance penalty
the performance penalty of
performance penalty of log
penalty of log cleaning
of log cleaning even
log cleaning even when
cleaning even when the
even when the workload
when the workload allows
the workload allows little
workload allows little idle
allows little idle time
the power costs of
power costs of log
costs of log cleaning
of log cleaning are
log cleaning are a
cleaning are a little
are a little more
a little more tricky
little more tricky to
more tricky to justify
this is where the
is where the natural
where the natural division
the natural division of
natural division of segments
division of segments into
of segments into stable
segments into stable and
into stable and volatile
stable and volatile ones
and volatile ones that
volatile ones that the
ones that the log
that the log cleaning
the log cleaning process
log cleaning process results
cleaning process results in
after a significant fraction
a significant fraction of
significant fraction of segments
fraction of segments on
of segments on a
segments on a disk
on a disk have
a disk have been
disk have been classified
have been classified as
kncminer bitcoin mining cloud
been classified as stable
bitcoin mining cloud mining
we power the disk
power the disk on
the disk on and
disk on and copy
on and copy the
and copy the stable
copy the stable segments
the stable segments to
stable segments to a
segments to a stable
to a stable disk
volatile segments to a
segments to a volatile
to a volatile disk
disk is kept on
and the entire disk
the entire disk is
entire disk is freed
disk is freed for
is freed for reuse
this is similar to
is similar to the
similar to the log
to the log cleaning
the log cleaning scheme
log cleaning scheme described
cleaning scheme described in
a private framework for
private framework for distributed
framework for distributed computation
for distributed computation edward
which uses a hidden
distributed computation edward tremel
uses a hidden structure
a hidden structure embedded
hidden structure embedded in
structure embedded in the
embedded in the log
in the log to
the log to track
log to track segment
to track segment utilization
cleaning an entire disk
and ma rk jelasity
an entire disk amortizes
ma rk jelasity there
entire disk amortizes the
disk amortizes the cost
rk jelasity there is
amortizes the cost of
the cost of powering
jelasity there is a
cost of powering the
of powering the disk
there is a growing
powering the disk on
is a growing class
a growing class of
growing class of distributed
number of accesses number
class of distributed systems
of accesses number of
of distributed systems applications
accesses number of files
distributed systems applications in
number of files touched
systems applications in which
of files touched number
applications in which data
files touched number of
in which data stored
touched number of bytes
which data stored on
number of bytes touched
data stored on client
of bytes touched average
stored on client platforms
bytes touched average number
on client platforms must
touched average number of
client platforms must be
average number of bytes
platforms must be aggregated
must be aggregated or
be aggregated or analyzed
aggregated or analyzed without
or analyzed without revealing
analyzed without revealing private
without revealing private information
an authorization architecture for
revealing private information to
authorization architecture for trustworthy
private information to the
architecture for trustworthy computing
information to the operator
in proceedings of the
proceedings of the twenty
systems such as the
such as the smart
as the smart power
the smart power grid
third acm symposium on
quality of streaming when
acm symposium on operating
of streaming when applying
symposium on operating systems
control systems for energy
streaming when applying the
on operating systems principles
when applying the fixed
applying the fixed threshold
the fixed threshold strategy
threshold is varied from
and traffic analysis in
traffic analysis in large
analysis in large cities
in large cities all
large cities all depend
cities all depend on
all depend on the
depend on the analysis
on the analysis of
the analysis of data
analysis of data supplied
of data supplied by
data supplied by measurement
supplied by measurement devices
yet the clients being
the clients being tracked
clients being tracked are
being tracked are unwilling
tracked are unwilling to
are unwilling to reveal
unwilling to reveal such
to reveal such measurement
reveal such measurement data
such measurement data directly
and the contribution rate
measurement data directly to
the contribution rate of
data directly to the
contribution rate of opportunistic
directly to the system
rate of opportunistic nodes
to the system owner
of opportunistic nodes is
opportunistic nodes is varied
nodes is varied from
who might be curious
might be curious about
be curious about private
curious about private client
about private client information
these systems thus may
based simulator of a
systems thus may elicit
simulator of a log
thus may elicit public
may elicit public opposition
elicit public opposition despite
public opposition despite their
opposition despite their useful
despite their useful features
their useful features because
given a trace of
useful features because of
a trace of read
features because of a
trace of read and
because of a perceived
of read and write
presents the average download
read and write requests
of a perceived privacy
the average download factors
a perceived privacy risk
average download factors across
download factors across all
factors across all correct
logsim returns the observed
across all correct nodes
returns the observed access
there are ways to
the observed access latencies
are ways to upload
ways to upload sensitive
to upload sensitive data
upload sensitive data to
sensitive data to an
data to an aggregator
to an aggregator without
an aggregator without compromising
presents the number of
aggregator without compromising privacy
the number of correct
number of correct nodes
of correct nodes incorrectly
correct nodes incorrectly punished
but existing options have
existing options have limitations
one possibility is to
for the chosen set
possibility is to keep
the chosen set of
is to keep the
chosen set of configuration
to keep the data
set of configuration parameters
keep the data encrypted
the data encrypted with
data encrypted with keys
encrypted with keys known
with keys known only
keys known only to
known only to the
we consider the use
only to the clients
consider the use of
world traces for our
the use of fixed
traces for our simulations
use of fixed thresholds
for our simulations from
our simulations from a
but this requires expensive
simulations from a web
this requires expensive homomorphic
requires expensive homomorphic encryption
we studied the effects
expensive homomorphic encryption if
studied the effects of
homomorphic encryption if the
the effects of using
server that serves images
effects of using different
that serves images from
of using different values
serves images from a
using different values for
images from a database
encryption if the aggregator
different values for t
if the aggregator is
the aggregator is to
aggregator is to compute
is to compute directly
to compute directly on
compute directly on it
another is to employ
is to employ a
to employ a mechanism
employ a mechanism to
a mechanism to de
and increasing it until
correlate client identifiers from
client identifiers from their
identifiers from their data
describes the characteristics of
as chen et al
the characteristics of a
characteristics of a sample
of a sample trace
while a true evaluation
a true evaluation of
true evaluation of the
evaluation of the feasibility
of the feasibility and
the feasibility and efficacy
feasibility and efficacy of
of the stream rate
and efficacy of our
efficacy of our solution
but this imposes restrictions
of our solution can
this imposes restrictions on
our solution can only
imposes restrictions on the
solution can only be
restrictions on the kind
can only be achieved
on the kind of
and present a detailed
the kind of aggregation
only be achieved through
kind of aggregation that
present a detailed set
of aggregation that can
be achieved through an
aggregation that can be
a detailed set of
that can be done
achieved through an actual
detailed set of results
through an actual implementation
set of results on
of results on applying
results on applying different
on applying different thresholds
applying different thresholds to
simulation provides an elegant
different thresholds to different
it would be beneficial
thresholds to different scenarios
provides an elegant way
would be beneficial to
an elegant way to
be beneficial to execute
elegant way to identify
beneficial to execute needed
way to identify and
to execute needed computation
to identify and explore
execute needed computation directly
identify and explore some
needed computation directly on
and explore some of
computation directly on the
explore some of the
directly on the client
some of the cost
on the client platforms
the ratio of opportunistic
ratio of opportunistic nodes
of opportunistic nodes is
opportunistic nodes is fixed
nodes is fixed to
benefit tradeoffs in a
so that the system
tradeoffs in a scaled
that the system operator
the system operator or
system operator or analyst
operator or analyst only
down version of our
or analyst only sees
version of our system
analyst only sees aggregate
only sees aggregate results
the mechanism we simulate
mechanism we simulate is
we simulate is as
this approach would provide
simulate is as follows
but their contribution factor
approach would provide a
would provide a better
provide a better alternative
a better alternative to
on power splitting games
better alternative to central
power splitting games in
alternative to central aggregation
splitting games in distributed
to central aggregation provided
games in distributed computation
central aggregation provided it
aggregation provided it is
provided it is privacy
disks are assumed to
are assumed to begin
the case of bitcoin
assumed to begin in
case of bitcoin pooled
to begin in the
of bitcoin pooled mining
begin in the on
in the on state
and an access count
a data aggregation system
data aggregation system based
aggregation system based on
is maintained for each
system based on client
maintained for each disk
side computation suggests a
the user specifies the
computation suggests a purely
user specifies the maximum
suggests a purely peer
specifies the maximum percentage
of disks that are
disks that are kept
that are kept powered
are kept powered on
which many systems have
many systems have used
systems have used to
have used to avoid
used to avoid centralized
nodes follow the protocol
to avoid centralized control
with a maximum contribution
a maximum contribution rate
maximum contribution rate set
contribution rate set to
a disk check process
disk check process scans
check process scans the
process scans the access
scans the access count
the access count for
access count for each
count for each disk
for each disk and
each disk and powers
disk and powers down
and powers down all
powers down all but
down all but the
all but the most
as well as any
well as any disk
as any disk which
any disk which does
disk which does not
which does not have
we present the average
peer systems have problems
present the average download
does not have at
the average download rates
systems have problems of
not have at least
have problems of their
have at least t
problems of their own
at least t access
least t access count
even if we set
if we set privacy
and the number of
we set privacy concerns
the number of correct
set privacy concerns aside
number of correct nodes
of correct nodes mistakenly
correct nodes mistakenly removed
nodes mistakenly removed from
mistakenly removed from the
by eschewing centralization entirely
removed from the system
weekly bitcoin network statistics
miss results in an
results in an access
they can no longer
in an access to
can no longer take
an access to a
no longer take advantage
access to a powered
longer take advantage of
take advantage of the
advantage of the powerful
of the powerful management
the powerful management tools
powerful management tools developed
for each of these
management tools developed for
then this disk is
tools developed for today
this disk is spun
developed for today s
disk is spun up
each of these configurations
for today s cloud
today s cloud computing
s cloud computing model
to remain powered on
the threshold applied is
remain powered on until
threshold applied is presented
powered on until the
applied is presented on
on until the next
is presented on the
until the next disk
presented on the x
the next disk check
in the left graph
and there is a
clients are isolated network
there is a corresponding
are isolated network hosts
is a corresponding latency
isolated network hosts rather
a corresponding latency penalty
as the threshold increases
network hosts rather than
hosts rather than devices
rather than devices within
than devices within a
judicious choice of the
higher download averages are
devices within a single
download averages are observed
choice of the parameters
within a single administrative
of the parameters m
a single administrative domain
the parameters m and
parameters m and t
since more opportunistic nodes
m and t minimizes
more opportunistic nodes are
and t minimizes the
opportunistic nodes are detected
t minimizes the probability
nodes are detected and
minimizes the probability of
are detected and punished
and often have difficulty
the probability of this
often have difficulty maintaining
probability of this occurrence
have difficulty maintaining connections
difficulty maintaining connections to
maintaining connections to each
connections to each other
the number of nodes
to each other through
number of nodes incorrectly
each other through firewalls
of nodes incorrectly accused
other through firewalls and
nodes incorrectly accused also
through firewalls and address
incorrectly accused also increases
firewalls and address translation
accused also increases with
and address translation barriers
also increases with higher
increases with higher thresholds
determining the membership of
as observed in the
the membership of a
observed in the right
membership of a peer
in the right graph
scenarios where opportunistic nodes
where opportunistic nodes contribute
opportunistic nodes contribute at
methodology we have proposed
nodes contribute at higher
peer network is a
contribute at higher rates
we have proposed the
network is a surprisingly
have proposed the use
is a surprisingly difficult
proposed the use of
a surprisingly difficult problem
the use of lfs
use of lfs in
of lfs in lieu
lfs in lieu of
in lieu of ffs
since there is no
there is no one
is no one entity
no one entity that
or other conventional file
one entity that knows
other conventional file systems
entity that knows the
that knows the identities
knows the identities of
the identities of all
identities of all the
of all the clients
are less disruptive to
less disruptive to the
disruptive to the system
center scenarios to achieve
scenarios to achieve power
to achieve power conservation
and changes in membership
changes in membership may
but they also require
in membership may not
they also require higher
membership may not be
also require higher thresholds
may not be detected
for this idea to
not be detected and
this idea to be
require higher thresholds to
idea to be accepted
be detected and propagated
higher thresholds to be
detected and propagated in
thresholds to be applied
and propagated in a
propagated in a timely
in a timely fashion
two questions need to
questions need to be
need to be answered
different thresholds yield best
to be answered in
thresholds yield best results
be answered in the
yield best results under
answered in the affirmative
best results under different
results under different scenarios
without a centralized service
from the results presented
a centralized service to
the results presented in
centralized service to assign
results presented in figure
service to assign and
to assign and manage
does this new scheme
assign and manage node
this new scheme result
and manage node identities
new scheme result in
scheme result in significant
result in significant power
we concluded that the
theoretic analysis of ddos
concluded that the best
in significant power savings
that the best fixed
analysis of ddos attacks
the best fixed threshold
of ddos attacks against
best fixed threshold is
ddos attacks against bitcoin
fixed threshold is t
attacks against bitcoin mining
against bitcoin mining pools
in workshop on bitcoin
workshop on bitcoin research
does this new scheme
this new scheme provide
new scheme provide comparable
peer system is extremely
scheme provide comparable performance
system is extremely vulnerable
providing the best compromise
provide comparable performance to
is extremely vulnerable to
comparable performance to existing
the best compromise in
performance to existing schemes
extremely vulnerable to a
best compromise in terms
vulnerable to a few
compromise in terms of
to a few malicious
in terms of performance
a few malicious peers
terms of performance and
few malicious peers becoming
of performance and false
malicious peers becoming a
performance and false positives
the answers to these
and false positives across
peers becoming a majority
false positives across all
answers to these questions
positives across all scenarios
becoming a majority of
to these questions must
a majority of the
these questions must be
majority of the apparent
questions must be largely
of the apparent nodes
must be largely applicationindependent
the apparent nodes in
apparent nodes in the
nodes in the system
and must apply to
must apply to a
apply to a generic
to a generic data
we compare all three
a generic data center
even choosing peers fairly
generic data center model
compare all three strategies
choosing peers fairly becomes
all three strategies proposed
peers fairly becomes difficult
three strategies proposed in
strategies proposed in subsection
to address these questions
because peers usually do
peers usually do not
we present a simulator
usually do not store
do not store the
not store the entire
store the entire membership
when bitcoin mining pools
the entire membership list
bitcoin mining pools run
entire membership list locally
mining pools run dry
against each other and
each other and against
logsim consists of less
other and against a
consists of less than
and against a configuration
of less than a
against a configuration with
in workshop on bitcoin
less than a thousand
workshop on bitcoin research
a configuration with no
and it is fairly
configuration with no auditing
than a thousand lines
it is fairly easy
a thousand lines of
is fairly easy for
thousand lines of java
fairly easy for malicious
lines of java code
easy for malicious peers
of java code and
for malicious peers to
java code and is
malicious peers to poison
code and is a
and is a single
peers to poison local
to poison local mem
poison local mem cornell
local mem cornell bership
mem cornell bership views
cornell bership views so
bership views so that
views so that they
so that they will
that they will be
for the fixed threshold
they will be preferred
the fixed threshold strategy
will be preferred as
fixed threshold strategy and
be preferred as neighbors
threshold strategy and as
we must turn off
strategy and as the
preferred as neighbors by
and as the initial
must turn off some
as the initial threshold
turn off some percentage
as neighbors by honest
off some percentage of
the initial threshold in
neighbors by honest nodes
initial threshold in the
some percentage of disks
threshold in the stepwise
percentage of disks in
comparison of mining pools
of disks in the
in the stepwise adaptive
disks in the storage
the stepwise adaptive strategy
in the storage system
we summarize the three
summarize the three strategies
the three strategies in
three strategies in table
there are two opposing
are two opposing forces
two opposing forces at
opposing forces at play
forces at play here
we simulated sessions where
a large number of
large number of powered
on disks results in
disks results in good
results in good performance
since neither completely centralized
neither completely centralized aggregation
comparison of mining pools
completely centralized aggregation nor
of the nodes were
centralized aggregation nor a
the nodes were opportunistic
aggregation nor a completely
nodes were opportunistic and
nor a completely peer
were opportunistic and with
opportunistic and with varying
and with varying ratios
with varying ratios of
but also low power
varying ratios of contribution
also low power savings
peer system is adequate
system is adequate for
on the other hand
is adequate for our
adequate for our purposes
decreasing the number of
the number of powered
we explore a new
the contribution rate of
explore a new approach
contribution rate of opportunistic
a new approach that
rate of opportunistic nodes
new approach that combines
of opportunistic nodes is
approach that combines the
opportunistic nodes is varied
on disks incurs two
that combines the features
disks incurs two possible
combines the features of
incurs two possible penalties
the features of these
nodes is varied from
features of these two
of these two extremes
although the idea of
the idea of a
idea of a communication
of a communication system
a communication system that
communication system that combines
hashcash amortizable publicly auditable
system that combines some
amortizable publicly auditable cost
that combines some centralized
combines some centralized control
some centralized control with
centralized control with a
transitions consume power and
control with a peer
consume power and thus
all other nodes are
power and thus counter
other nodes are correct
and thus counter the
thus counter the potential
counter the potential savings
the potential savings achieved
potential savings achieved by
contributing at a maximum
peer overlay is not
at a maximum rate
savings achieved by powered
a maximum rate of
overlay is not new
we are the first
are the first to
the first to use
to find the optimal
first to use such
find the optimal percentage
to use such a
the optimal percentage of
use such a system
optimal percentage of disks
such a system to
percentage of disks to
a system to preserve
of disks to be
system to preserve privacy
disks to be powered
to preserve privacy while
we present both the
preserve privacy while computing
to be powered down
privacy while computing on
present both the average
while computing on sensitive
both the average and
computing on sensitive data
the average and the
average and the minimum
we ran a set
and the minimum download
ran a set of
the minimum download factors
a set of simulations
this combination is a
minimum download factors across
combination is a sensible
download factors across all
is a sensible tradeoff
factors across all correct
set of simulations on
across all correct nodes
a sensible tradeoff for
of simulations on logsim
all correct nodes in
sensible tradeoff for the
correct nodes in the
simulations on logsim and
nodes in the system
tradeoff for the kinds
on logsim and varied
for the kinds of
logsim and varied the
the kinds of systems
and varied the number
kinds of systems we
varied the number of
as the contribution rate
of systems we target
the contribution rate of
the number of disks
contribution rate of opportunistic
number of disks that
rate of opportunistic nodes
of disks that we
of opportunistic nodes increases
disks that we kept
that we kept powered
in which there is
we kept powered up
kept powered up from
which there is an
powered up from none
the download factors are
there is an owner
download factors are expected
factors are expected to
is an owner or
are expected to increase
an owner or operator
owner or operator who
or operator who can
which is clear from
operator who can be
is clear from the
who can be trusted
clear from the curves
can be trusted to
from the curves presented
be trusted to provide
trusted to provide basic
to provide basic services
provide basic services such
strategy no auditing fixed
basic services such as
no auditing fixed threshold
services such as node
auditing fixed threshold stepwise
such as node identification
fixed threshold stepwise adaptive
as node identification and
threshold stepwise adaptive percentile
node identification and membership
identification and membership tracking
and membership tracking but
membership tracking but not
hashcash a denial of
tracking but not to
a denial of service
but not to see
based adaptive description fixed
not to see non
denial of service counter
adaptive description fixed t
aggregated raw client data
out of a total
of a total of
we treat the system
treat the system operator
the system operator as
system operator as an
operator as an honest
who will keep the
will keep the system
keep the system running
the system running correctly
system running correctly but
running correctly but cannot
correctly but cannot be
but cannot be allowed
cannot be allowed to
be allowed to see
allowed to see more
to see more information
see more information than
more information than he
information than he or
than he or she
he or she needs
if avg sampled download
or she needs to
avg sampled download factor
she needs to know
we introduce a method
disks were kept powered
were kept powered up
introduce a method for
a method for constructing
method for constructing a
for constructing a communication
constructing a communication overlay
a communication overlay among
communication overlay among the
overlay among the client
decrease t back to
among the client nodes
the client nodes that
client nodes that can
nodes that can safely
that can safely be
can safely be used
safely be used to
be used to perform
used to perform aggregation
to perform aggregation and
perform aggregation and computation
when avg download is
aggregation and computation on
avg download is satisfactory
and computation on private
download is satisfactory again
computation on private data
on subversive miner strategies
although this overlay is
subversive miner strategies and
this overlay is set
miner strategies and block
overlay is set up
strategies and block withholding
is set up and
and block withholding attack
set up and operated
block withholding attack in
up and operated by
withholding attack in bitcoin
and operated by the
attack in bitcoin digital
operated by the system
in bitcoin digital currency
by the system owner
if avg sampled download
avg sampled download factor
it provides minimal opportunity
provides minimal opportunity for
minimal opportunity for the
opportunity for the owner
for the owner to
the owner to learn
owner to learn any
to learn any information
learn any information about
any information about the
information about the data
about the data being
the data being aggregated
data being aggregated other
being aggregated other than
aggregated other than the
other than the final
than the final result
the final result of
t is chosen based
final result of the
is chosen based on
result of the computation
chosen based on sampled
based on sampled upload
on sampled upload factors
when combined with differential
combined with differential privacy
with differential privacy techniques
to protect the aggregation
protect the aggregation results
the aggregation results themselves
it can be used
can be used to
be used to ensure
used to ensure that
to ensure that no
ensure that no query
that no query made
no query made to
query made to the
made to the system
to the system reveals
the system reveals the
system reveals the contribution
reveals the contribution of
the contribution of any
contribution of any particular
strategies used for defining
of any particular node
used for defining the
for defining the minimum
defining the minimum upload
the minimum upload threshold
minimum upload threshold t
our overlay network looks
upload threshold t figure
overlay network looks a
network looks a bit
looks a bit like
a bit like a
bit like a gossip
like a gossip infrastructure
shows that all strategies
that all strategies yield
all strategies yield significantly
strategies yield significantly better
yield significantly better results
significantly better results compared
better results compared to
results compared to an
compared to an approach
to an approach with
an approach with no
approach with no auditing
how incentivize large bitcoin
incentivize large bitcoin mining
and can be used
large bitcoin mining http
can be used to
while both adaptive strategies
be used to run
both adaptive strategies yield
used to run gossip
adaptive strategies yield excellent
strategies yield excellent download
yield excellent download rates
excellent download rates to
download rates to correct
rates to correct nodes
with the key difference
the key difference that
the fixed threshold strategy
key difference that the
fixed threshold strategy s
difference that the random
threshold strategy s performance
that the random peer
strategy s performance is
the random peer selection
s performance is not
random peer selection of
performance is not as
peer selection of gossip
is not as good
selection of gossip is
not as good when
of gossip is replaced
as good when opportunistic
gossip is replaced with
good when opportunistic nodes
is replaced with a
when opportunistic nodes are
replaced with a completely
opportunistic nodes are contributing
with a completely deterministic
nodes are contributing with
a completely deterministic function
cdf number of accesses
nodes are assigned virtual
are assigned virtual ids
assigned virtual ids that
virtual ids that are
ids that are either
that are either integers
or slightly more kbps
are either integers or
either integers or finite
integers or finite field
or finite field elements
and each node uses
each node uses a
node uses a function
uses a function based
a function based on
function based on either
based on either modular
on either modular arithmetic
either modular arithmetic or
modular arithmetic or finite
arithmetic or finite fields
at those rates opportunistic
or finite fields to
those rates opportunistic nodes
finite fields to compute
rates opportunistic nodes are
fields to compute the
opportunistic nodes are harmful
to compute the order
nodes are harmful to
compute the order in
are harmful to the
the order in which
harmful to the system
order in which it
in which it should
which it should communicate
it should communicate with
should communicate with the
yet the fixed threshold
communicate with the other
the fixed threshold of
with the other nodes
we construct this function
construct this function to
this function to ensure
function to ensure that
to ensure that the
ensure that the network
is not able to
that the network is
not able to detect
the network is optimally
able to detect them
network is optimally robust
is optimally robust and
optimally robust and efficient
converging in logarithmic time
in logarithmic time and
logarithmic time and tolerating
time and tolerating message
and tolerating message failures
tolerating message failures with
message failures with minimal
failures with minimal delay
we consider a scenario
consider a scenario where
a scenario where opportunistic
scenario where opportunistic nodes
key cryptography to encrypt
where opportunistic nodes contribute
cryptography to encrypt messages
opportunistic nodes contribute with
nodes contribute with different
contribute with different rates
ensuring that the the
that the the system
we varied the percentage
the the system operator
varied the percentage of
the system operator cannot
the percentage of opportunistic
system operator cannot infer
percentage of opportunistic nodes
operator cannot infer anything
of opportunistic nodes in
cannot infer anything about
opportunistic nodes in the
infer anything about the
nodes in the system
anything about the data
in the system from
about the data being
the data being aggregated
data being aggregated by
being aggregated by observing
aggregated by observing network
by observing network traffic
even the communication pattern
the communication pattern is
communication pattern is completely
pattern is completely predictable
is completely predictable and
completely predictable and hence
predictable and hence reveals
and hence reveals nothing
and evenly assigned them
evenly assigned them different
assigned them different contribution
them different contribution rates
malicious nodes cannot significantly
the graphs present the
nodes cannot significantly deviate
graphs present the average
cannot significantly deviate from
present the average and
significantly deviate from correct
the average and minimum
deviate from correct behavior
average and minimum download
from correct behavior without
and minimum download rates
correct behavior without being
minimum download rates for
behavior without being detected
download rates for these
rates for these scenarios
so the network encourages
the network encourages the
network encourages the operator
encourages the operator to
the operator to behave
operator to behave correctly
no auditing performs significantly
auditing performs significantly worse
performs significantly worse than
significantly worse than any
worse than any of
and it even tolerates
than any of the
it even tolerates byzantine
any of the proposed
even tolerates byzantine failure
of the proposed strategies
tolerates byzantine failure by
byzantine failure by a
failure by a small
by a small minority
a small minority of
small minority of clients
the stepwise adaptive approach
this ensures that important
stepwise adaptive approach yields
ensures that important queries
adaptive approach yields the
that important queries will
approach yields the best
important queries will not
yields the best results
queries will not be
the best results when
will not be corrupted
best results when large
not be corrupted or
results when large percentages
be corrupted or blocked
when large percentages of
corrupted or blocked by
large percentages of opportunistic
or blocked by compromised
percentages of opportunistic nodes
blocked by compromised devices
of opportunistic nodes are
opportunistic nodes are present
nodes are present in
are present in the
present in the system
and that an adversary
that an adversary cannot
an adversary cannot compromise
it is also simpler
adversary cannot compromise the
is also simpler than
cannot compromise the privacy
also simpler than the
compromise the privacy of
simpler than the percentile
the privacy of client
privacy of client data
of client data by
client data by gaining
data by gaining control
by gaining control of
gaining control of a
control of a few
since it is based
of a few devices
it is based only
a few devices in
is based only on
few devices in the
based only on samples
devices in the system
only on samples of
on samples of the
samples of the download
of the download rates
the download rates of
download rates of nodes
in both sets of
both sets of experiments
the number of false
number of false positives
of false positives was
false positives was practically
positives was practically null
was practically null under
practically null under all
null under all three
under all three strategies
all three strategies considered
effect of increasing percentage
ro bert orma ndi
of increasing percentage of
increasing percentage of powered
at most one in
most one in some
istva n hegedu s
one in some cases
up disks on performance
and ma rk jelasity
gossip learning with linear
learning with linear models
with linear models on
linear models on fully
effect of increasing percentage
models on fully distributed
of increasing percentage of
on fully distributed this
increasing percentage of powered
fully distributed this work
distributed this work was
this work was supported
up disks on power
disks on power consumption
on power consumption both
power consumption both its
consumption both its performance
by a grant from
auditing costs the overheads
a grant from the
costs the overheads imposed
grant from the nsf
as well as its
the overheads imposed by
from the nsf data
well as its power
overheads imposed by auditing
imposed by auditing are
by auditing are an
auditing are an important
are an important consideration
practice and exsmart grids
the former is measured
and exsmart grids program
former is measured using
which we address in
is measured using the
we address in this
measured using the observed
address in this subsection
using the observed access
the observed access latencies
most of the work
of the work of
while the latter is
the work of auditing
the latter is measured
work of auditing is
latter is measured by
of auditing is performed
is measured by comparing
auditing is performed by
measured by comparing the
is performed by local
by comparing the cumulative
performed by local auditors
comparing the cumulative percentage
the cumulative percentage of
cumulative percentage of time
percentage of time the
which are executed on
of time the disks
are executed on the
time the disks are
executed on the user
the disks are kept
on the user nodes
disks are kept powered
are kept powered on
the overhead is constant
as well as the
well as the number
as the number of
the number of mode
independent of the size
of the size of
the size of the
size of the system
and is not significant
since nodes only exchange
nodes only exchange a
only exchange a small
exchange a small amount
a small amount of
small amount of accounting
amount of accounting data
of accounting data at
accounting data at pre
defined intervals of time
show the results of
the results of these
results of these simulations
of the disks powered
the disks powered on
if we consider a
antony rowstron and peter
we consider a packet
rowstron and peter druschel
consider a packet rate
a packet rate of
of the disks can
and routing for large
the disks can be
disks can be spun
can be spun down
be spun down while
spun down while still
down while still maintaining
while still maintaining performance
seconds the maximum number
still maintaining performance comparable
the maximum number of
maintaining performance comparable to
maximum number of packets
performance comparable to that
number of packets received
comparable to that of
of packets received and
to that of a
packets received and sent
that of a conventional
received and sent by
of a conventional file
and sent by each
a conventional file system
sent by each node
by each node is
the performance of our
performance of our system
of our system depends
our system depends very
system depends very heavily
depends very heavily on
very heavily on its
heavily on its cache
on its cache configuration
since cache optimization is
cache optimization is an
for each packet sent
optimization is an orthogonal
each packet sent or
is an orthogonal issue
packet sent or received
an orthogonal issue that
orthogonal issue that comprises
issue that comprises an
that comprises an entire
comprises an entire field
the history needs to
an entire field of
history needs to indicate
entire field of research
needs to indicate which
field of research in
to indicate which neighbor
of research in itself
indicate which neighbor sent
which neighbor sent or
neighbor sent or received
sent or received the
or received the packet
it is important to
is important to isolate
important to isolate its
to isolate its effect
isolate its effect on
its effect on performance
bits to identify each
to identify each neighbor
we implemented an ideal
the history s size
implemented an ideal cache
history s size adds
an ideal cache algorithm
s size adds up
size adds up to
which we term the
we term the oracle
this data point represents
data point represents the
point represents the best
represents the best performance
the best performance we
best performance we could
performance we could achieve
we could achieve since
could achieve since an
achieve since an oracle
since an oracle has
an oracle has future
oracle has future knowledge
has future knowledge and
correctness of a gossip
future knowledge and is
of a gossip based
knowledge and is able
a gossip based membership
and is able to
gossip based membership protocol
is able to replace
this is not significant
able to replace items
is not significant compared
to replace items accessed
not significant compared to
in proceedings of the
significant compared to the
proceedings of the twenty
replace items accessed furthest
compared to the amount
items accessed furthest in
to the amount of
accessed furthest in the
the amount of regular
furthest in the future
amount of regular data
fourth annual acm sympo
of regular data exchanged
regular data exchanged in
data exchanged in a
exchanged in a streaming
in a streaming session
we also analyzed the
also analyzed the costs
analyzed the costs of
the costs of the
costs of the global
of the global auditors
since they are dedicated
we also wish to
they are dedicated and
also wish to provide
are dedicated and external
wish to provide a
dedicated and external to
to provide a performance
and external to the
provide a performance comparison
external to the system
a performance comparison of
performance comparison of our
comparison of our system
and ma rk jelasity
of our system against
the overhead imposed by
our system against conventional
overhead imposed by them
imposed by them is
a private framework for
by them is of
private framework for distributed
them is of higher
framework for distributed comsium
is of higher concern
for distributed comsium on
distributed comsium on principles
comsium on principles of
on principles of distributed
principles of distributed computing
global auditors main tasks
as an approximation of
auditors main tasks consist
an approximation of such
main tasks consist of
approximation of such a
tasks consist of sampling
of such a system
consist of sampling the
of sampling the system
sampling the system to
the system to collect
system to collect download
we implemented a random
to collect download and
implemented a random placement
collect download and upload
a random placement algorithm
download and upload rates
and upload rates of
upload rates of nodes
which maps each block
maps each block to
each block to a
block to a random
and of occasionally disseminating
to a random disk
of occasionally disseminating updates
occasionally disseminating updates to
disseminating updates to the
updates to the threshold
all disks are kept
to the threshold value
disks are kept powered
are kept powered up
the sample size remains
sample size remains fixed
size remains fixed independent
remains fixed independent of
fixed independent of the
independent of the size
of the size of
the size of the
size of the population
having set the context
we ran simulations to
let us examine fig
ran simulations to estimate
simulations to estimate the
to estimate the worst
case standard deviation of
standard deviation of the
deviation of the download
of the download rates
the download rates across
download rates across all
rates across all nodes
we estimate that a
estimate that a sample
the additional two data
that a sample size
a sample size of
points described above are
described above are represented
above are represented in
are represented in fig
nodes is sufficient to
is sufficient to provide
independent of the population
of the population size
such as the ones
as the ones simulated
the ones simulated in
ones simulated in this
simulated in this work
even a smaller number
uniform node sampling service
a smaller number of
node sampling service robust
smaller number of samples
sampling service robust against
number of samples was
service robust against collusions
of samples was found
robust against collusions of
samples was found to
against collusions of malicious
was found to be
collusions of malicious nodes
found to be sufficient
to be sufficient to
be sufficient to yield
sufficient to yield satisfactory
to yield satisfactory results
centralized costs are fixed
if we imagine a
and provide a clear
we imagine a line
provide a clear advantage
imagine a line at
a clear advantage for
a line at y
clear advantage for using
advantage for using auditing
for using auditing against
using auditing against tit
ifip international conference on
international conference on dependable
conference on dependable systems
managed transactional consistency for
tat approaches in large
on dependable systems and
transactional consistency for web
dependable systems and networks
consistency for web caching
for web caching ittay
web caching ittay eyal
caching ittay eyal ken
ittay eyal ken birman
eyal ken birman robbert
ken birman robbert van
birman robbert van renesse
robbert van renesse cornell
van renesse cornell university
renesse cornell university abstract
cornell university abstract in
heterogenous systems so far
systems so far we
so far we considered
far we considered the
we considered the use
considered the use of
the use of auditing
only caches are widely
use of auditing to
caches are widely used
of auditing to enforce
are widely used in
auditing to enforce node
widely used in cloud
of the accesses live
to enforce node contribution
the accesses live above
used in cloud infrastructure
enforce node contribution in
accesses live above this
in cloud infrastructure to
live above this line
node contribution in systems
cloud infrastructure to reduce
contribution in systems where
infrastructure to reduce access
in systems where all
to reduce access latency
systems where all nodes
reduce access latency and
where all nodes are
access latency and to
all nodes are assumed
latency and to reduce
nodes are assumed to
and to reduce load
are assumed to have
to reduce load on
assumed to have homogeneous
reduce load on backend
to have homogeneous bandwidth
load on backend databases
have homogeneous bandwidth resources
disks on is the
on is the third
is the third best
the third best configuration
operators view coherent caches
enough to upload and
view coherent caches as
to upload and download
next only to the
upload and download at
only to the oracle
and download at a
to the oracle and
coherent caches as impractical
download at a rate
caches as impractical at
at a rate close
as impractical at genuinely
a rate close to
impractical at genuinely large
rate close to the
at genuinely large scale
close to the stream
genuinely large scale and
to the stream rate
large scale and many
scale and many client
byzantine resilient random membership
resilient random membership sampling
pullbased streaming may be
streaming may be extended
facing caches are updated
may be extended to
in proceedings of the
caches are updated in
proceedings of the twenty
be extended to heterogenous
are updated in an
extended to heterogenous systems
updated in an asynchronous
to heterogenous systems by
in an asynchronous manner
the performance degradation in
seventh acm symposium on
an asynchronous manner with
acm symposium on principles
asynchronous manner with best
heterogenous systems by organizing
performance degradation in going
symposium on principles of
systems by organizing nodes
degradation in going from
on principles of distributed
by organizing nodes into
principles of distributed computing
organizing nodes into multiple
existing solutions that support
nodes into multiple groups
solutions that support cache
that support cache consistency
support cache consistency are
cache consistency are inapplicable
consistency are inapplicable to
are inapplicable to this
inapplicable to this scenario
to this scenario since
this scenario since they
scenario since they require
since they require a
they require a round
require a round trip
a round trip to
round trip to the
trip to the database
to the database on
disks on is negligibly
the database on every
on is negligibly small
database on every cache
on every cache transaction
existing incoherent cache technologies
incoherent cache technologies are
cache technologies are oblivious
technologies are oblivious to
are oblivious to transactional
for the system under
oblivious to transactional data
the system under test
to transactional data access
no auditing fixed threshold
auditing fixed threshold stepwise
the optimal configuration is
fixed threshold stepwise percentile
optimal configuration is to
even if the backend
configuration is to fig
if the backend database
the backend database supports
backend database supports transactions
shows an estimate of
an estimate of the
estimate of the actual
of the actual power
the actual power savings
actual power savings achieved
power savings achieved by
savings achieved by our
achieved by our solution
avg download factor min
download factor min download
aware cache for read
factor min download factor
we assume the following
assume the following disk
the following disk specifications
cache improves cache consistency
improves cache consistency despite
cache consistency despite asynchronous
consistency despite asynchronous and
despite asynchronous and unreliable
asynchronous and unreliable communication
and unreliable communication between
unreliable communication between the
communication between the cache
between the cache and
the cache and the
cache and the database
in proceedings of the
no auditing fixed threshold
proceedings of the acm
auditing fixed threshold stepwise
a variant of serializability
fixed threshold stepwise percentile
of the acm sigcomm
variant of serializability that
of serializability that is
serializability that is suitable
that is suitable for
is suitable for incoherent
suitable for incoherent caches
and prove that with
prove that with unbounded
that with unbounded resources
with unbounded resources t
cache allows the system
allows the system manager
the system manager to
system manager to choose
manager to choose a
to choose a trade
avg time for transition
off between performance and
between performance and consistency
our evaluation shows that
evaluation shows that t
we see that turning
see that turning off
cache detects many inconsistencies
detects many inconsistencies with
many inconsistencies with only
inconsistencies with only nominal
with only nominal overhead
we use synthetic workloads
use synthetic workloads to
of the disks results
synthetic workloads to demonstrate
the disks results in
workloads to demonstrate the
to demonstrate the efficacy
demonstrate the efficacy of
the efficacy of t
cache when data accesses
when data accesses are
data accesses are clustered
accesses are clustered and
are clustered and its
clustered and its adaptive
and its adaptive reaction
its adaptive reaction to
adaptive reaction to workload
reaction to workload changes
with workloads based on
workloads based on the
with all the disks
based on the real
all the disks off
while maintaining acceptable performance
upload rate of opportunistic
rate of opportunistic nodes
shows some of the
some of the tradeoffs
of the tradeoffs involved
note that the y
of the inconsistencies and
the inconsistencies and increases
inconsistencies and increases the
axis represents three different
and increases the rate
represents three different quantities
increases the rate of
the rate of consistent
epidemic algorithms for replicated
rate of consistent transactions
algorithms for replicated database
of consistent transactions by
the cumulative percentage of
for replicated database maintenance
cumulative percentage of time
percentage of time the
of time the disks
time the disks are
the disks are powered
disks are powered on
in proceedings of the
proceedings of the sixth
of the sixth annual
the sixth annual acm
the total duration of
sixth annual acm symposium
total duration of the
annual acm symposium on
duration of the simulation
acm symposium on principles
symposium on principles of
on principles of distributed
principles of distributed computing
and the cumulative number
the cumulative number of
cumulative number of mode
i ntroduction internet services
ntroduction internet services like
transitions that the disks
internet services like online
that the disks undergo
services like online retailers
like online retailers and
online retailers and social
retailers and social networks
and social networks store
social networks store important
networks store important data
store important data sets
important data sets in
data sets in large
sets in large distributed
both the total duration
in large distributed databases
the total duration of
total duration of the
duration of the experiment
as well as the
well as the number
as the number of
technical challenges have forced
the number of mode
challenges have forced such
have forced such large
system operators to forgo
operators to forgo transactional
to forgo transactional consistency
increase as the percentage
as the percentage of
the percentage of disks
percentage of disks that
of disks that is
providing perobject consistency instead
disks that is powered
that is powered on
is powered on is
powered on is decreased
often with some form
with some form of
some form of eventual
form of eventual consistency
upload rate of opportunistic
rate of opportunistic nodes
we see that keeping
minimum and average download
and average download factors
average download factors across
download factors across all
disks on strikes an
factors across all correct
on strikes an acceptable
across all correct nodes
strikes an acceptable balance
all correct nodes when
correct nodes when using
nodes when using different
when using different strategies
using different strategies for
different strategies for choosing
strategies for choosing the
conclusion in this paper
for choosing the threshold
we point out a
the upload contribution rate
point out a new
upload contribution rate of
out a new opportunity
contribution rate of opportunistic
a new opportunity for
rate of opportunistic nodes
new opportunity for saving
of opportunistic nodes is
opportunity for saving power
opportunistic nodes is varied
for saving power in
nodes is varied in
saving power in large
is varied in the
varied in the x
in lecture notes in
lecture notes in computer
notes in computer science
the idea is elegant
idea is elegant in
and the number of
is elegant in its
the number of opportunistic
elegant in its simplicity
number of opportunistic nodes
support transactions with guarantees
of opportunistic nodes is
transactions with guarantees such
opportunistic nodes is fixed
with guarantees such as
nodes is fixed at
log structured file systems
guarantees such as snapshot
structured file systems write
such as snapshot isolation
file systems write only
as snapshot isolation and
systems write only to
snapshot isolation and even
write only to the
isolation and even full
only to the log
and even full transactional
to the log head
even full transactional atomicity
our work begins with
work begins with the
begins with the observation
if read accesses are
with the observation that
read accesses are served
accesses are served by
avg download factor min
are served by the
download factor min download
served by the cache
factor min download factor
it can be difficult
then write accesses touch
can be difficult for
write accesses touch only
be difficult for client
accesses touch only the
touch only the log
only the log head
the log head disk
tier applications to leverage
applications to leverage the
to leverage the transactions
leverage the transactions that
potentially allowing us to
the transactions that the
allowing us to power
transactions that the databases
us to power down
that the databases provide
to power down all
power down all the
down all the other
all the other disks
their reads are satisfied
reads are satisfied primarily
are satisfied primarily from
existing solutions like disk
satisfied primarily from incoherent
solutions like disk management
primarily from incoherent cache
like disk management solutions
the benefits of caching
benefits of caching are
of caching are twofold
no auditing fixed threshold
auditing fixed threshold stepwise
fixed threshold stepwise percentile
it reduces database load
thereby enabling higher throughput
the caches are typically
caches are typically placed
are typically placed close
typically placed close to
the working set model
placed close to the
working set model for
close to the clients
set model for program
model for program behavior
the problem centers on
problem centers on the
centers on the asynchronous
on the asynchronous style
the asynchronous style of
asynchronous style of communication
style of communication used
of communication used between
communication used between the
used between the database
between the database and
the database and the
database and the geo
no auditing fixed threshold
auditing fixed threshold stepwise
fixed threshold stepwise percentile
a cache should not
cache should not access
should not access the
not access the database
access the database on
the database on every
database on every transaction
any approach requiring a
approach requiring a high
requiring a high rate
a high rate of
high rate of round
trips to an authoritative
to an authoritative backend
an authoritative backend database
authoritative backend database would
backend database would cause
database would cause unacceptable
would cause unacceptable latency
a cache must respond
cache must respond instantly
and asynchronous updates rule
asynchronous updates rule out
updates rule out cache
rule out cache coherency
out cache coherency schemes
cache coherency schemes that
coherency schemes that would
schemes that would require
that would require the
time disks on num
would require the backend
require the backend database
the backend database to
backend database to promptly
transitions total time of
database to promptly invalidate
total time of run
to promptly invalidate or
promptly invalidate or update
invalidate or update cached
or update cached this
update cached this work
cached this work is
this work is supported
by a grant from
a grant from the
grant from the darpa
from the darpa mrc
the darpa mrc program
or even to track
based fast overlay topology
even to track the
fast overlay topology construction
to track the locations
track the locations at
the locations at which
locations at which cached
at which cached objects
which cached objects reside
we define a variant
define a variant of
a variant of serializability
variant of serializability called
of serializability called cacheserializability
serializability called cacheserializability that
called cacheserializability that is
cacheserializability that is suitable
that is suitable for
improving the performance of
is suitable for incoherent
the performance of log
suitable for incoherent caches
structured file systems with
a wide range of
file systems with adaptive
wide range of web
systems with adaptive methods
range of web applications
from social networks to
social networks to online
networks to online retailers
settle for caches that
for caches that are
caches that are oblivious
that are oblivious to
are oblivious to transactions
despite the fact that
the fact that an
fact that an inconsistent
that an inconsistent read
an inconsistent read access
inconsistent read access can
read access can deter
access can deter a
can deter a client
deter a client and
a client and reduce
client and reduce their
and reduce their income
they cannot afford consistent
cannot afford consistent cache
afford consistent cache techniques
consistent cache techniques that
cache techniques that require
techniques that require backend
that require backend accesses
require backend accesses on
backend accesses on every
accesses on every transaction
a novel caching scheme
novel caching scheme that
caching scheme that improves
scheme that improves consistency
that improves consistency at
improves consistency at the
consistency at the cache
and maarten van steen
at the cache level
the cache level with
cache level with a
level with a nominal
with a nominal storage
a nominal storage and
nominal storage and communication
storage and communication tradeoff
cache significantly improves consistency
significantly improves consistency for
improves consistency for workloads
consistency for workloads where
for workloads where data
workloads where data accesses
where data accesses are
data accesses are clustered
reducing energy consumption of
ratio of freeloaders figure
energy consumption of disk
which is common in
consumption of disk storage
is common in today
of disk storage using
common in today s
disk storage using power
in today s large
minimum and average download
and average download factors
this is achieved while
average download factors across
is achieved while retaining
download factors across all
achieved while retaining the
factors across all correct
while retaining the global
across all correct nodes
retaining the global scalability
all correct nodes when
the global scalability afforded
correct nodes when using
global scalability afforded by
nodes when using different
scalability afforded by executing
when using different strategies
afforded by executing read
using different strategies for
different strategies for choosing
strategies for choosing the
for choosing the threshold
only transactions on the
transactions on the edge
each session has mixed
session has mixed set
has mixed set of
directly from the cache
mixed set of opportunistic
set of opportunistic nodes
we do this by
do this by storing
contributing at different rates
this by storing dependency
by storing dependency information
storing dependency information with
dependency information with the
information with the cached
and percentage of opportunistic
with the cached objects
percentage of opportunistic nodes
of opportunistic nodes is
opportunistic nodes is varied
nodes is varied on
is varied on the
varied on the x
to identify possible inconsistencies
to their upload bandwidths
identify possible inconsistencies without
possible inconsistencies without contacting
inconsistencies without contacting the
without contacting the database
nodes able to upload
able to upload at
to upload at a
upload at a rate
the user can improve
at a rate higher
user can improve the
a rate higher than
can improve the level
rate higher than the
improve the level of
higher than the stream
the level of consistency
than the stream rate
level of consistency by
the stream rate are
of consistency by adjusting
stream rate are placed
consistency by adjusting the
rate are placed in
are placed in higher
by adjusting the size
adjusting the size of
the size of this
size of this dependency
of this dependency data
which are closer to
more dependency data leads
are closer to the
dependency data leads to
closer to the source
data leads to increased
leads to increased consistency
the source sends data
source sends data to
to demonstrate the efficacy
sends data to the
demonstrate the efficacy of
data to the highest
the efficacy of the
to the highest level
efficacy of the proposed
the highest level group
of the proposed scheme
highest level group only
we created a prototype
who uses the basic
created a prototype implementation
uses the basic protocol
a prototype implementation and
the basic protocol to
prototype implementation and exposed
basic protocol to disseminate
implementation and exposed it
protocol to disseminate data
and exposed it to
to disseminate data among
exposed it to workloads
disseminate data among each
it to workloads based
data among each other
to workloads based on
effect of increasing percentage
workloads based on graphically
of increasing percentage of
increasing percentage of powered
nodes in lower levels
in lower levels may
lower levels may receive
up disks on power
levels may receive data
disks on power and
may receive data at
on power and time
receive data at smaller
data at smaller rates
such as those seen
as those seen in
and caching solutions are
those seen in social
caching solutions are typically
after some filtering is
solutions are typically application
some filtering is applied
level nodes may be
nodes may be used
may be used to
on the other hand
be used to act
used to act as
to act as sources
act as sources to
as sources to the
is applicable to any
sources to the lower
applicable to any cacheable
to any cacheable dataset
since existing solutions are
existing solutions are typically
of the inconsistencies and
solutions are typically layered
alleviating the burden at
are typically layered on
the inconsistencies and can
the burden at the
typically layered on top
inconsistencies and can increase
burden at the source
and can increase the
layered on top of
can increase the ratio
on top of the
increase the ratio of
top of the file
the ratio of consistent
ratio of consistent transactions
auditing can be used
of consistent transactions by
can be used to
be used to avoid
used to avoid the
to avoid the presence
avoid the presence of
they could be used
the presence of opportunistic
could be used in
presence of opportunistic and
be used in conjunction
of opportunistic and lower
used in conjunction with
opportunistic and lower bandwidth
in conjunction with our
and lower bandwidth nodes
conjunction with our solution
lower bandwidth nodes in
with our solution to
bandwidth nodes in the
our solution to take
nodes in the higher
solution to take advantage
to take advantage of
take advantage of application
it can ensure that
can ensure that the
ensure that the hierarchy
we also provide some
that the hierarchy of
both with low overhead
the hierarchy of nodes
also provide some initial
hierarchy of nodes is
provide some initial simulation
of nodes is obeyed
some initial simulation results
nodes is obeyed by
initial simulation results that
we construct synthetic workloads
simulation results that validate
construct synthetic workloads and
results that validate our
is obeyed by all
that validate our claim
obeyed by all nodes
validate our claim that
synthetic workloads and observe
our claim that power
workloads and observe how
and observe how t
while allowing the system
savings are possible using
allowing the system to
are possible using a
cache reacts to different
the system to leverage
possible using a log
reacts to different clustering
system to leverage additional
to different clustering levels
to leverage additional resources
different clustering levels and
leverage additional resources from
clustering levels and how
additional resources from privileged
levels and how it
resources from privileged altruistic
and how it adapts
from privileged altruistic nodes
how it adapts as
privileged altruistic nodes to
it adapts as clusters
while simulations can never
adapts as clusters change
altruistic nodes to forward
simulations can never provide
nodes to forward data
can never provide conclusive
to forward data to
never provide conclusive evidence
forward data to lower
provide conclusive evidence for
with perfectly clustered workloads
conclusive evidence for the
data to lower level
evidence for the feasibility
to lower level groups
for the feasibility of
the feasibility of a
feasibility of a system
we intend to explore
cache implements full cache
intend to explore this
they are an effective
to explore this further
are an effective means
explore this further in
an effective means to
this further in future
effective means to identify
further in future work
means to identify promising
to identify promising solutions
to explain this perfect
explain this perfect behavior
this perfect behavior we
our principal contribution in
perfect behavior we prove
principal contribution in this
behavior we prove a
contribution in this paper
we prove a related
in this paper is
prove a related claim
this paper is in
related work several p
paper is in having
a related claim we
is in having shown
related claim we show
in having shown a
claim we show that
having shown a new
we show that with
shown a new fit
show that with unbounded
a new fit for
that with unbounded resources
new fit for an
with unbounded resources t
streaming protocols have been
fit for an old
protocols have been previously
for an old idea
have been previously proposed
we believe that the
the first generation of
believe that the log
first generation of systems
structured file system shows
file system shows promise
system shows promise as
shows promise as a
the contributions of this
promise as a powersaving
contributions of this work
as a powersaving opportunity
of this work are
a powersaving opportunity for
powersaving opportunity for large
relied on approaches based
on approaches based on
acknowledgments this work was
approaches based on pushing
this work was partially
based on pushing data
work was partially funded
on pushing data through
was partially funded by
pushing data through a
partially funded by intel
data through a single
funded by intel corporation
through a single dissemination
by intel corporation and
a single dissemination tree
a variant of serializability
intel corporation and the
variant of serializability suitable
corporation and the national
of serializability suitable for
and the national science
serializability suitable for incoherent
the national science foundation
suitable for incoherent caches
later approaches focused on
approaches focused on improving
focused on improving fairness
special thanks to saikat
on improving fairness among
thanks to saikat guha
improving fairness among peers
to saikat guha for
fairness among peers and
saikat guha for his
among peers and resilience
guha for his input
peers and resilience to
for his input in
and resilience to churn
his input in the
resilience to churn by
input in the simulator
to churn by breaking
in the simulator design
churn by breaking data
by breaking data into
which allows trading off
breaking data into multiple
allows trading off efficiency
data into multiple substreams
trading off efficiency and
into multiple substreams and
off efficiency and transaction
we also wish to
multiple substreams and sending
also wish to thank
substreams and sending them
wish to thank our
and sending them along
to thank our anonymous
sending them along disjoing
thank our anonymous reviewers
them along disjoing paths
consistency in large scale
our anonymous reviewers for
in large scale cache
anonymous reviewers for their
large scale cache deployments
reviewers for their valuable
for their valuable feedback
cache with synthetic workloads
demonstrating its adaptivity and
its adaptivity and sensitivity
adaptivity and sensitivity to
more recent systems like
and sensitivity to clustering
recent systems like coolstreaming
based style of data
style of data dissemination
conserving disk energy in
disk energy in network
energy in network servers
cache with workloads based
with workloads based on
coolstreaming breaks the data
workloads based on graphically
breaks the data into
the data into packets
and peers organized into
peers organized into a
organized into a mesh
world data demonstrating detection
into a mesh request
data demonstrating detection rates
a mesh request packets
demonstrating detection rates of
mesh request packets from
request packets from their
packets from their neighbors
from their neighbors using
their neighbors using a
neighbors using a scheduling
using a scheduling algorithm
th international conference on
international conference on supercomputing
as we saw earlier
chainsaw uses a simpler
uses a simpler policy
a simpler policy for
simpler policy for requesting
and consistency improvements of
policy for requesting packets
randomly fetching them while
fetching them while respecting
them while respecting a
while respecting a maximum
respecting a maximum limit
a maximum limit on
maximum limit on the
limit on the number
on the number of
the number of outstanding
number of outstanding requests
of outstanding requests to
outstanding requests to each
requests to each neighbor
chainsaw presents smaller delays
presents smaller delays for
smaller delays for the
delays for the receipt
for the receipt of
the receipt of packets
receipt of packets compared
of packets compared to
packets compared to the
compared to the coolstreaming
cache with unbounded resources
to the coolstreaming protocol
with unbounded resources implements
unbounded resources implements cache
in a more recent
a more recent work
the case for massive
case for massive arrays
for massive arrays of
massive arrays of idle
arrays of idle disks
the complexity of implementing
complexity of implementing geo
based approaches are shown
approaches are shown to
are shown to present
scale databases with strong
shown to present better
databases with strong guarantees
to present better performance
with strong guarantees initially
present better performance over
strong guarantees initially led
better performance over tree
guarantees initially led companies
initially led companies to
led companies to abandon
companies to abandon cross
conference on file and
object consistency altogether and
previous papers have considered
on file and storage
consistency altogether and make
papers have considered a
altogether and make do
file and storage technologies
and make do with
have considered a variety
make do with weak
considered a variety of
do with weak guarantees
a variety of possible
with weak guarantees such
variety of possible mechanisms
weak guarantees such as
of possible mechanisms to
guarantees such as per
possible mechanisms to encourage
mechanisms to encourage node
to encourage node contribution
object atomicity or eventual
atomicity or eventual consistency
such systems do repair
is a framework proposed
systems do repair any
a framework proposed to
do repair any problems
framework proposed to enforce
repair any problems that
proposed to enforce download
any problems that arise
to enforce download rate
enforce download rate limitations
download rate limitations on
rate limitations on p
p media streaming systems
user is sometimes exposed
the protocol relies on
is sometimes exposed to
protocol relies on a
sometimes exposed to inconsistency
relies on a set
on a set of
a set of trusted
helping disk arrays sleep
set of trusted nodes
disk arrays sleep through
for some applications this
arrays sleep through the
of trusted nodes that
sleep through the winter
some applications this is
trusted nodes that store
applications this is acceptable
nodes that store information
that store information on
store information on the
information on the data
and the approach has
on the data downloaded
the approach has been
the data downloaded by
approach has been surprisingly
data downloaded by each
has been surprisingly successful
downloaded by each node
by each node receiving
each node receiving data
in today s cloud
proceedings of the twentieth
of the twentieth acm
the twentieth acm symposium
nodes only send an
twentieth acm symposium on
only send an object
relaxed consistency is something
acm symposium on operating
send an object after
symposium on operating systems
consistency is something of
an object after consulting
is something of a
on operating systems principles
object after consulting the
something of a credo
after consulting the trusted
consulting the trusted nodes
the trusted nodes to
trusted nodes to verify
nodes to verify if
to verify if the
verify if the nodes
if the nodes requesting
the nodes requesting the
nodes requesting the stream
requesting the stream are
the stream are not
stream are not overrequesting
are not overrequesting data
it is targeted to
is targeted to systems
targeted to systems where
to systems where nodes
systems where nodes upload
where nodes upload full
nodes upload full media
upload full media objects
only transactions by accessing
full media objects from
transactions by accessing caches
media objects from each
objects from each other
which receive their values
and not for live
receive their values by
their values by reading
values by reading from
by reading from the
reading from the database
streaming systems where all
systems where all nodes
interplay of energy and
where all nodes are
of energy and performance
all nodes are interested
energy and performance for
nodes are interested in
and performance for disk
are interested in receiving
performance for disk arrays
interested in receiving the
for disk arrays running
in receiving the exact
disk arrays running transaction
receiving the exact same
arrays running transaction processing
the exact same data
update transactions go directly
running transaction processing workloads
transactions go directly to
exact same data in
go directly to the
same data in close
directly to the database
data in close to
in close to real
close to real time
in ieee international symposium
ieee international symposium on
international symposium on performance
symposium on performance analysis
on performance analysis of
performance analysis of systems
analysis of systems and
of systems and software
subsequent cache invalidations can
cache invalidations can be
invalidations can be delayed
can be delayed or
be delayed or even
delayed or even lost
consider fairness issues in
or even lost due
fairness issues in the
even lost due to
issues in the context
lost due to race
in the context of
due to race conditions
the context of tree
leading to a potentially
to a potentially inconsistent
a potentially inconsistent view
potentially inconsistent view by
inconsistent view by the
view by the cache
by the cache clients
the authors present mechanisms
authors present mechanisms that
present mechanisms that rank
mechanisms that rank peers
that rank peers according
rank peers according to
peers according to their
according to their level
to their level of
their level of cooperation
level of cooperation with
of cooperation with the
cooperation with the system
large internet services store
one of their techniques
internet services store vast
of their techniques involves
services store vast amounts
their techniques involves the
store vast amounts of
techniques involves the reconstruction
vast amounts of data
involves the reconstruction of
the reconstruction of trees
reconstruction of trees as
of trees as a
trees as a way
online retailers such as
as a way of
retailers such as amazon
a way of punishing
such as amazon and
reducing disk power consumption
way of punishing opportunistic
disk power consumption in
as amazon and ebay
power consumption in servers
of punishing opportunistic nodes
consumption in servers with
amazon and ebay maintain
in servers with drpm
and ebay maintain product
ebay maintain product stocks
maintain product stocks and
product stocks and information
most of their mechanisms
of their mechanisms require
their mechanisms require peers
mechanisms require peers to
require peers to keep
and social networking sites
peers to keep track
social networking sites such
to keep track of
networking sites such as
keep track of their
sites such as facebook
track of their parents
such as facebook and
of their parents and
as facebook and twitter
their parents and children
facebook and twitter maintain
parents and children s
and twitter maintain graphical
and children s behavior
twitter maintain graphical databases
maintain graphical databases representing
graphical databases representing user
databases representing user relations
representing user relations and
user relations and group
relations and group structures
studied the effect of
the effect of different
effect of different types
of different types of
different types of incentives
types of incentives on
of incentives on the
incentives on the chainsaw
on the chainsaw protocol
such databases are sharded
databases are sharded and
hiding in plain sight
are sharded and replicated
google seeks more power
the vast majority of
vast majority of accesses
majority of accesses are
of accesses are read
in the new york
the new york times
tat and some variations
the authors propose an
authors propose an algorithm
propose an algorithm that
an algorithm that sets
algorithm that sets up
that sets up local
sets up local markets
up local markets at
local markets at every
markets at every node
where neighbors compete for
neighbors compete for the
compete for the node
for the node s
the node s upload
node s upload capacity
nodes favor neighbors who
favor neighbors who contribute
neighbors who contribute more
with nodes classified as
nodes classified as fast
classified as fast or
as fast or slow
fast or slow nodes
the results indicate that
results indicate that the
indicate that the proposed
that the proposed algorithm
the proposed algorithm improves
to reduce database load
proposed algorithm improves the
reduce database load and
algorithm improves the performance
berkeley db java edition
database load and to
improves the performance of
load and to reduce
db java edition architecture
and to reduce access
the performance of the
to reduce access latency
performance of the system
of the system when
an oracle white paper
the system when the
these companies employ a
system when the total
companies employ a twotier
when the total upload
employ a twotier structure
the total upload capacity
total upload capacity is
upload capacity is not
capacity is not enough
is not enough to
placing layers of cache
not enough to supply
layers of cache servers
enough to supply all
of cache servers in
to supply all the
cache servers in front
supply all the nodes
servers in front of
in front of the
front of the database
streaming system where nodes
system where nodes choose
where nodes choose their
nodes choose their neighbors
choose their neighbors based
their neighbors based on
neighbors based on their
the caches of primary
based on their history
caches of primary interest
on their history of
of primary interest to
their history of interaction
primary interest to us
interest to us are
to us are typically
us are typically situated
nodes are placed in
are typically situated far
are placed in the
placed in the system
typically situated far from
in the system according
situated far from the
the system according to
far from the backend
system according to their
from the backend database
according to their current
the backend database systems
to their current trading
backend database systems to
their current trading performances
database systems to reduce
systems to reduce latency
encouraging nodes to contribute
nodes to contribute more
companies place caches close
to contribute more and
place caches close to
contribute more and therefore
caches close to clients
more and therefore be
and therefore be closer
therefore be closer to
be closer to the
closer to the source
timeouts are used to
eduardo pinheiro and ricardo
are used to ensure
pinheiro and ricardo bianchini
used to ensure that
to ensure that stale
ensure that stale cached
that stale cached objects
is a more recent
energy conservation techniques for
a more recent live
stale cached objects will
conservation techniques for disk
cached objects will eventually
techniques for disk array
objects will eventually be
will eventually be flushed
streaming approach that tolerates
approach that tolerates the
that tolerates the existence
tolerates the existence of
but to achieve a
the existence of opportunistic
to achieve a high
existence of opportunistic and
achieve a high cache
of opportunistic and malicious
a high cache hit
opportunistic and malicious nodes
high cache hit ratio
time is divided into
timeout values are generally
is divided into rounds
values are generally large
in which each peer
to obtain reasonable consistency
which each peer communicates
each peer communicates with
th annual international conference
peer communicates with another
annual international conference on
communicates with another peer
the database sends an
with another peer selected
international conference on supercomputing
another peer selected using
database sends an asynchronous
peer selected using a
sends an asynchronous stream
selected using a pseudo
an asynchronous stream of
asynchronous stream of invalidation
stream of invalidation records
of invalidation records or
invalidation records or cache
records or cache updates
often using protocols optimized
using protocols optimized for
peers exchange their current
protocols optimized for throughput
exchange their current history
optimized for throughput and
their current history containing
for throughput and freshness
current history containing the
throughput and freshness and
history containing the identifiers
and freshness and lacking
containing the identifiers of
freshness and lacking absolute
the identifiers of all
and lacking absolute guarantees
identifiers of all the
lacking absolute guarantees of
of all the current
absolute guarantees of order
all the current data
guarantees of order or
the current data they
of order or reliability
current data they hold
as basis for the
basis for the next
for the next exchanges
it is difficult to
is difficult to make
nodes also perform a
difficult to make this
also perform a phase
to make this invalidation
perform a phase of
make this invalidation mechanism
characteristics of file system
this invalidation mechanism reliable
of file system workloads
a phase of optimistic
invalidation mechanism reliable without
phase of optimistic push
mechanism reliable without hampering
reliable without hampering database
without hampering database efficiency
forwarding useful updates to
useful updates to pseudo
the issues are many
randomly picked peers with
picked peers with no
peers with no guarantee
with no guarantee of
no guarantee of useful
guarantee of useful return
the databases are large
residing on many servers
conclusion we propose and
we propose and evaluate
propose and evaluate a
and evaluate a scalable
evaluate a scalable auditing
databases use locks prudently
use locks prudently in
based technique for enforcing
locks prudently in order
technique for enforcing fairness
prudently in order to
for enforcing fairness in
in order to maximize
enforcing fairness in a
order to maximize concurrency
mendel rosenblum and john
fairness in a live
rosenblum and john k
to the extent that
the extent that the
extent that the database
that the database keeps
the design and implementation
our approach employs local
design and implementation of
approach employs local auditors
and implementation of a
the database keeps track
implementation of a log
employs local auditors that
database keeps track of
local auditors that execute
keeps track of the
auditors that execute on
track of the caches
that execute on all
of the caches that
execute on all nodes
the caches that hold
on all nodes in
caches that hold a
all nodes in a
acm transactions on computer
nodes in a streaming
transactions on computer systems
in a streaming session
that hold a copy
hold a copy of
a copy of each
copy of each object
they are responsible for
are responsible for collecting
responsible for collecting auditable
it may be possible
for collecting auditable information
may be possible to
collecting auditable information about
be possible to send
auditable information about other
possible to send an
information about other neighbors
to send an invalidation
about other neighbors data
other neighbors data exchanges
but tracking the state
tracking the state of
and for verifying that
the state of caches
for verifying that neighbors
state of caches is
verifying that neighbors upload
of caches is complicated
that neighbors upload more
caches is complicated and
neighbors upload more data
is complicated and hence
upload more data than
complicated and hence if
more data than a
and hence if they
data than a specified
hence if they are
than a specified threshold
if they are used
they are used at
are used at all
this threshold is defined
threshold is defined by
is defined by dedicated
such systems view invalidations
defined by dedicated global
systems view invalidations as
by dedicated global auditors
view invalidations as a
invalidations as a kind
as a kind of
a kind of hint
which periodically sample the
periodically sample the state
they could be delayed
sample the state of
the state of the
state of the system
of the system to
the system to determine
system to determine if
to determine if the
determine if the overall
if the overall download
the overall download rate
overall download rate is
download rate is compromised
rate is compromised by
is compromised by the
due to buffering or
compromised by the presence
to buffering or retransmissions
by the presence of
buffering or retransmissions after
the presence of opportunistic
or retransmissions after message
presence of opportunistic nodes
retransmissions after message loss
global auditing determines the
auditing determines the minimum
determines the minimum threshold
the minimum threshold for
minimum threshold for uploads
and works with local
works with local auditing
with local auditing to
local auditing to punish
auditing to punish nodes
to punish nodes that
punish nodes that do
nodes that do not
that do not upload
do not upload enough
not upload enough data
due to an inaccurate
to an inaccurate list
disk layout optimization for
an inaccurate list of
layout optimization for reducing
we study the efficiency
optimization for reducing energy
inaccurate list of locations
for reducing energy consumption
study the efficiency of
the efficiency of our
efficiency of our auditing
of our auditing approach
our auditing approach through
auditing approach through simulation
and show that it
show that it is
that it is able
it is able to
is able to maintain
able to maintain the
to maintain the throughput
maintain the throughput of
the throughput of the
th annual international conference
throughput of the streaming
annual international conference on
of the streaming system
international conference on supercomputing
due to a system
the streaming system even
to a system configuration
streaming system even in
a system configuration change
system even in the
even in the presence
in the presence of
the presence of a
presence of a large
of a large number
a large number of
large number of opportunistic
number of opportunistic nodes
or because of races
because of races between
of races between reads
a missing invalidation obviously
missing invalidation obviously leaves
invalidation obviously leaves the
obviously leaves the corresponding
leaves the corresponding cache
the corresponding cache entry
corresponding cache entry stale
pitfalls of such invalidation
of such invalidation schemes
such invalidation schemes are
invalidation schemes are described
schemes are described in
are described in detail
described in detail by
in detail by nishita
detail by nishita et
by nishita et al
a case for end
case for end system
for end system multicast
and by bronson et
by bronson et al
but forgoing transactional consistency
forgoing transactional consistency can
transactional consistency can result
consistency can result in
can result in undesired
result in undesired behavior
in undesired behavior of
undesired behavior of a
behavior of a service
consider a buyer at
a buyer at an
buyer at an online
at an online site
an online site who
online site who looks
site who looks for
who looks for a
looks for a toy
for a toy train
a toy train with
toy train with its
train with its matching
with its matching tracks
its matching tracks just
matching tracks just as
tracks just as the
just as the vendor
as the vendor is
the vendor is adding
vendor is adding them
is adding them to
adding them to the
them to the database
the client may see
client may see only
may see only the
see only the train
only the train in
the train in stock
train in stock but
in stock but not
stock but not the
but not the tracks
not the tracks because
the tracks because the
tracks because the product
because the product insertion
the product insertion transaction
product insertion transaction would
insertion transaction would often
transaction would often be
would often be broken
often be broken into
be broken into two
broken into two or
reliable multicasting with an
into two or more
multicasting with an overlay
two or more atomic
with an overlay network
or more atomic but
more atomic but independent
atomic but independent subtransactions
in a social network
th symposium on operating
symposium on operating systems
an inconsistency with unexpected
on operating systems design
inconsistency with unexpected results
operating systems design and
with unexpected results can
systems design and implementation
unexpected results can occur
results can occur if
can occur if a
occur if a user
if a user x
a user x s
user x s record
x s record says
s record says it
record says it belongs
says it belongs to
it belongs to a
belongs to a certain
to a certain group
but that group s
that group s record
group s record does
s record does not
record does not include
does not include x
web albums maintain picture
albums maintain picture data
maintain picture data and
picture data and access
data and access control
and access control lists
and it is important
it is important that
is important that acl
important that acl and
that acl and album
acl and album updates
and album updates are
album updates are consistent
the classical example involves
classical example involves removing
example involves removing one
involves removing one s
removing one s boss
one s boss from
s boss from the
boss from the album
from the album acl
the album acl and
album acl and then
acl and then adding
and then adding unflattering
then adding unflattering pictures
while many of these
many of these systems
of these systems make
these systems make do
systems make do with
make do with weak
do with weak consistency
their utility is reduced
utility is reduced when
is reduced when their
reduced when their clients
when their clients observe
their clients observe inconsistencies
there has been a
has been a wave
been a wave of
highbandwidth content distribution in
a wave of recent
content distribution in cooperative
distribution in cooperative environments
wave of recent innovations
of recent innovations within
recent innovations within the
innovations within the backend
a scalable services architecture
offering scalable object stores
scalable services architecture tudor
scalable object stores that
services architecture tudor marian
object stores that can
architecture tudor marian ken
stores that can efficiently
th acm symposium on
that can efficiently support
acm symposium on operating
tudor marian ken birman
symposium on operating systems
can efficiently support transactions
on operating systems principles
marian ken birman department
efficiently support transactions through
ken birman department of
support transactions through snapshot
birman department of computer
transactions through snapshot isolation
department of computer science
through snapshot isolation and
of computer science cornell
snapshot isolation and even
computer science cornell university
isolation and even full
and even full atomicity
edu abstract data centers
abstract data centers constructed
data centers constructed as
centers constructed as clusters
our challenge is to
constructed as clusters of
challenge is to improve
as clusters of inexpensive
is to improve transaction
clusters of inexpensive machines
to improve transaction consistency
of inexpensive machines have
improve transaction consistency at
inexpensive machines have compelling
transaction consistency at the
machines have compelling cost
consistency at the cache
at the cache layer
even when the cache
when the cache cannot
the cache cannot access
but developing services to
cache cannot access the
developing services to run
cannot access the backend
services to run on
access the backend on
to run on them
the backend on each
run on them can
backend on each read
on them can be
eliminating trees from overlay
them can be challenging
trees from overlay multicast
this paper reports on
paper reports on a
reports on a new
on a new framework
th international workshop on
international workshop on peer
the scalable services architecture
today s consistency solutions
s consistency solutions are
consistency solutions are limited
solutions are limited to
are limited to the
limited to the database
to the database backend
even when the database
which helps developers develop
when the database itself
helps developers develop scalable
the database itself is
developers develop scalable clustered
database itself is consistent
develop scalable clustered applications
the vast majority of
the work is focused
vast majority of operations
work is focused on
majority of operations are
is focused on nontransactional
of operations are read
focused on nontransactional high
only transactions issued by
transactions issued by edge
issued by edge clients
by edge clients and
these are poorly supported
edge clients and are
are poorly supported in
clients and are at
poorly supported in existing
and are at high
supported in existing platforms
are at high risk
at high risk of
high risk of observing
risk of observing inconsistent
of observing inconsistent state
a primary goal was
observing inconsistent state in
primary goal was to
inconsistent state in the
goal was to keep
state in the cache
was to keep the
to keep the ssa
keep the ssa as
the ssa as small
ssa as small and
as small and simple
the outright loss of
small and simple as
outright loss of cache
and simple as possible
loss of cache invalidations
of cache invalidations emerges
cache invalidations emerges as
key elements include a
invalidations emerges as an
elements include a tcp
emerges as an especially
as an especially significant
an especially significant problem
especially significant problem if
significant problem if transactional
based chain replication mechanism
problem if transactional consistency
chain replication mechanism and
if transactional consistency is
replication mechanism and a
transactional consistency is required
mechanism and a gossip
based subsystem for managing
an acceptable solution for
subsystem for managing configuration
acceptable solution for a
for managing configuration data
solution for a consistent
managing configuration data and
for a consistent cache
configuration data and repairing
a consistent cache must
data and repairing inconsistencies
consistent cache must maintain
and repairing inconsistencies after
cache must maintain the
repairing inconsistencies after faults
must maintain the performance
maintain the performance properties
the performance properties of
performance properties of the
properties of the existing
our experimental results confirm
of the existing caching
experimental results confirm the
the existing caching tier
results confirm the effectiveness
confirm the effectiveness of
the effectiveness of the
effectiveness of the approach
we need to maintain
driven overlay network for
need to maintain the
overlay network for efficient
to maintain the shielding
network for efficient live
introduction large computing systems
maintain the shielding role
for efficient live media
the shielding role of
efficient live media streaming
shielding role of the
large computing systems are
role of the cache
computing systems are often
systems are often structured
are often structured as
often structured as service
structured as service oriented
the cache hit ratio
as service oriented architectures
cache hit ratio should
hit ratio should be
ratio should be high
th conference on computer
conference on computer communications
on computer communications and
computer communications and networking
for example using web
example using web services
using web services platforms
only cache access should
cache access should complete
access should complete with
should complete with a
complete with a single
with a single client
clients access services in
access services in a
services in a request
trip on cache hits
each service is self
this prohibits coherent cache
prohibits coherent cache solutions
coherent cache solutions such
cache solutions such as
offers its own api
and handles its own
handles its own quality
its own quality of
own quality of service
quality of service or
of service or availability
service or availability guarantees
for example by arranging
example by arranging to
a rchitecture since the
by arranging to be
rchitecture since the cache
arranging to be restarted
since the cache is
to be restarted after
the cache is required
be restarted after a
cache is required to
restarted after a failure
is required to respond
required to respond immediately
to respond immediately to
respond immediately to the
immediately to the client
defense against intrusion in
while many services need
against intrusion in a
to the client on
intrusion in a live
the client on hits
in a live streaming
many services need to
a live streaming multicast
services need to maintain
live streaming multicast system
need to maintain availability
to maintain availability in
maintain availability in the
availability in the face
in the face of
the face of challenging
face of challenging operating
of challenging operating conditions
cache channel is asynchronous
th ieee international conference
ieee international conference on
international conference on peer
we decided to employ
decided to employ a
to employ a transactional
employ a transactional consistency
a transactional consistency that
transactional consistency that is
consistency that is weaker
that is weaker than
is weaker than the
weaker than the full
than the full acid
the full acid model
building services with these
services with these properties
with these properties is
these properties is difficult
existing web services platforms
web services platforms offer
services platforms offer load
only transactions and update
transactions and update transactions
and update transactions that
update transactions that access
balancing and restart mechanisms
transactions that access the
and restart mechanisms for
that access the same
restart mechanisms for transactional
access the same cache
mechanisms for transactional services
the same cache are
for transactional services implemented
same cache are guaranteed
transactional services implemented using
cache are guaranteed an
services implemented using a
are guaranteed an atomic
implemented using a three
guaranteed an atomic execution
but not for services
not for services implemented
only transactions that access
for services implemented using
transactions that access different
services implemented using other
that access different caches
implemented using other technologies
access different caches may
different caches may observe
caches may observe different
may observe different orderings
observe different orderings for
developers of nontransactional web
different orderings for independent
of nontransactional web services
orderings for independent update
nontransactional web services must
for independent update transactions
web services must implement
services must implement their
must implement their own
implement their own mechanisms
their own mechanisms for
own mechanisms for replicating
mechanisms for replicating data
tracking membership and live
membership and live this
and live this work
live this work was
this work was supported
work was supported by
was supported by darpa
ipto under the srs
under the srs program
every partial execution that
the srs program and
partial execution that includes
srs program and by
execution that includes all
program and by the
that includes all update
and by the rome
includes all update transactions
by the rome air
all update transactions in
the rome air force
update transactions in and
rome air force research
transactions in and all
air force research laboratory
in and all read
only transactions that go
transactions that go through
th conference on computer
that go through a
conference on computer communications
go through a single
through a single cache
a single cache server
under the prometheus program
additional support was provided
support was provided by
was provided by the
provided by the nsf
our solution seeks to
solution seeks to approximate
seeks to approximate cache
to approximate cache serializability
approximate cache serializability with
cache serializability with bounded
serializability with bounded caches
robbert van renesse ness
with bounded caches and
bounded caches and asynchronous
caches and asynchronous communication
and asynchronous communication with
asynchronous communication with the
redirecting requests during failures
communication with the db
requests during failures to
during failures to minimize
failures to minimize client
to minimize client disruption
our idea starts with
idea starts with an
starts with an observation
and detecting and repairing
detecting and repairing inconsistencies
our premise in this
premise in this paper
objects form clusters with
in this paper is
form clusters with strong
this paper is that
clusters with strong locality
paper is that for
with strong locality properties
is that for many
that for many services
transactions are likely to
are likely to access
the transactional model is
likely to access objects
transactional model is a
to access objects that
model is a poor
access objects that are
is a poor fit
a poor fit and
poor fit and hence
fit and hence that
and hence that tools
hence that tools aimed
that tools aimed at
tools aimed at non
close to each other
transactional web services systems
web services systems will
for retailers this might
services systems will be
retailers this might involve
systems will be needed
this might involve related
might involve related products
we recognize that this
recognize that this is
for social networks the
that this is debatable
social networks the set
networks the set of
the set of friends
vendors have generally argued
have generally argued that
for geographical services physical
generally argued that only
geographical services physical proximity
argued that only transactional
that only transactional systems
only transactional systems offer
transactional systems offer the
and for web albums
systems offer the hooks
for web albums the
offer the hooks needed
web albums the acl
the hooks needed to
albums the acl objects
hooks needed to support
the acl objects and
needed to support automated
acl objects and the
to support automated scalability
objects and the pictures
and the pictures assigned
the pictures assigned to
pictures assigned to them
repair and restart mechanisms
key to this argument
to this argument is
in some cases applications
this argument is the
some cases applications explicitly
argument is the ease
cases applications explicitly cluster
is the ease with
applications explicitly cluster their
the ease with which
explicitly cluster their data
ease with which interrupted
cluster their data accesses
with which interrupted transactions
their data accesses to
which interrupted transactions can
data accesses to benefit
interrupted transactions can be
accesses to benefit from
transactions can be rolled
to benefit from improved
can be rolled back
benefit from improved parallelism
th symposium on operating
symposium on operating systems
and the relative simplicity
on operating systems design
the relative simplicity of
operating systems design and
relative simplicity of cleaning
systems design and implementation
the resulting transactions access
simplicity of cleaning up
resulting transactions access objects
of cleaning up a
transactions access objects from
cleaning up a database
access objects from a
up a database after
objects from a single
a database after a
from a single cluster
database after a crash
although there will also
yet the transactional programming
there will also be
the transactional programming model
will also be some
transactional programming model also
also be some frequency
programming model also brings
be some frequency of
model also brings constraints
some frequency of transactions
also brings constraints and
frequency of transactions that
brings constraints and overheads
of transactions that access
transactions that access unrelated
that access unrelated objects
access unrelated objects in
unrelated objects in different
were this not the
objects in different clusters
this not the case
our solution requires minor
the transactional model would
solution requires minor changes
transactional model would long
requires minor changes to
model would long ago
minor changes to the
would long ago have
changes to the database
long ago have become
to the database object
ago have become universal
the database object representation
database object representation format
some of these constraints
imposing a small and
of these constraints relate
a small and constant
these constraints relate to
small and constant memory
constraints relate to the
and constant memory overhead
relate to the challenges
to the challenges of
the challenges of maintaining
challenges of maintaining a
of maintaining a clean
maintaining a clean separation
a clean separation of
clean separation of code
separation of code and
independent of the database
of code and data
of the database size
the database size and
database size and the
size and the transaction
and the transaction rate
not all applications can
all applications can be
applications can be structured
can be structured in
be structured in this
structured in this manner
this overhead involves tracking
overhead involves tracking and
transactional rollback and restart
involves tracking and caching
rollback and restart can
tracking and caching what
and restart can be
and caching what we
restart can be costly
caching what we refer
what we refer to
high bandwidth data dissemination
we refer to as
bandwidth data dissemination using
refer to as dependency
data dissemination using an
to as dependency lists
dissemination using an overlay
and restarting a database
using an overlay mesh
restarting a database after
a database after a
database after a crash
after a crash incurs
a crash incurs delays
crash incurs delays while
incurs delays while cleanup
length lists of object
delays while cleanup code
lists of object identifiers
while cleanup code runs
of object identifiers and
object identifiers and the
identifiers and the associated
and the associated version
the associated version numbers
th acm symposium on
high availability is difficult
acm symposium on operating
availability is difficult to
symposium on operating systems
is difficult to acheive
on operating systems principles
difficult to acheive in
each representing some recently
to acheive in the
representing some recently updated
acheive in the transactional
some recently updated objects
in the transactional model
recently updated objects upon
updated objects upon which
objects upon which the
upon which the cached
which the cached object
the fastest database replication
the cached object depends
fastest database replication schemes
sized list can omit
suffer from failure scenarios
list can omit dependency
from failure scenarios that
can omit dependency information
failure scenarios that can
omit dependency information required
scenarios that can require
dependency information required to
that can require intervention
information required to detect
can require intervention by
required to detect inconsistencies
require intervention by a
intervention by a human
by a human operator
hence it is important
it is important to
yet the higher fidelity
is important to use
the higher fidelity schemes
important to use a
higher fidelity schemes require
to use a bound
fidelity schemes require expensive
use a bound large
schemes require expensive multi
a bound large enough
bound large enough to
large enough to capture
enough to capture most
to capture most of
phase commit protocols and
capture most of the
commit protocols and hence
most of the relevant
protocols and hence may
of the relevant dependencies
and hence may not
hence may not give
may not give adequate
not give adequate performance
at present we lack
present we lack an
we lack an automated
lack an automated way
an automated way to
automated way to do
way to do this
clustered threetier database products
threetier database products are
database products are powerful
products are powerful solutions
we require the developer
require the developer to
the developer to tune
developer to tune the
but they negotiate these
to tune the length
they negotiate these potential
tune the length so
negotiate these potential pitfalls
the length so that
these potential pitfalls in
length so that the
potential pitfalls in ways
so that the frequency
pitfalls in ways that
that the frequency of
in ways that preclude
the frequency of errors
ways that preclude important
frequency of errors is
that preclude important classes
of errors is reduced
preclude important classes of
a comparative study of
important classes of applications
comparative study of live
errors is reduced to
study of live p
is reduced to an
reduced to an acceptable
to an acceptable level
our motivation is to
motivation is to show
is to show that
reasoning about the trade
to show that a
show that a simple
that a simple and
a simple and remarkably
simple and remarkably inexpensive
and remarkably inexpensive infrastructure
remarkably inexpensive infrastructure can
inexpensive infrastructure can support
infrastructure can support clustered
th conference on computer
in a manner we
can support clustered execution
conference on computer communications
a manner we discuss
support clustered execution of
manner we discuss further
clustered execution of a
we discuss further below
execution of a significant
of a significant class
a significant class of
significant class of non
dependency lists should be
lists should be roughly
should be roughly the
be roughly the same
the work reported here
roughly the same size
work reported here focuses
the same size as
reported here focuses on
same size as the
here focuses on services
size as the size
focuses on services that
as the size of
on services that don
the size of the
services that don t
size of the workload
that don t fit
of the workload s
don t fit the
the workload s clusters
t fit the transactional
fit the transactional paradigm
our extensions offer a
typically for reasons of
extensions offer a transactional
for reasons of performance
offer a transactional interface
a transactional interface to
transactional interface to the
interface to the cache
ones that operate directly
to the cache in
that operate directly on
the cache in addition
operate directly on in
cache in addition to
in addition to the
addition to the standard
to the standard read
memory data structures or
data structures or simple
structures or simple non
to simplify our task
our algorithm detects and
algorithm detects and fixes
detects and fixes inconsistent
and fixes inconsistent read
we assume that these
assume that these services
that these services are
these services are capable
only transactions at the
services are capable of
transactions at the cache
are capable of handling
at the cache with
capable of handling outof
the cache with constant
cache with constant complexity
preventing dos attacks in
it does so by
dos attacks in peer
does so by either
so by either aborting
and that processes implementing
by either aborting the
that processes implementing them
either aborting the transaction
processes implementing them experience
implementing them experience only
them experience only crash
experience only crash failures
peer media streaming systems
which can then be
can then be retried
as will be shown
will be shown below
our assumptions hold for
assumptions hold for a
or invalidating a cached
hold for a very
invalidating a cached object
for a very large
a cached object which
a very large group
cached object which can
th annual multimedia computing
object which can then
very large group of
which can then force
large group of applications
annual multimedia computing and
can then force a
multimedia computing and networking
then force a read
computing and networking conference
force a read from
a read from the
the ssa was built
read from the database
ssa was built using
was built using epidemic
similar to handling cache
to handling cache misses
communication protocols in conjunction
protocols in conjunction with
in conjunction with a
when the dependency lists
conjunction with a novel
the dependency lists fail
with a novel variant
dependency lists fail to
a novel variant of
lists fail to document
novel variant of the
fail to document a
variant of the chain
to document a necessary
of the chain replication
document a necessary dependency
the chain replication scheme
chain replication scheme which
replication scheme which has
scheme which has evolved
which has evolved from
an application might be
has evolved from the
application might be exposed
evolved from the mechanism
might be exposed to
from the mechanism first
be exposed to stale
the mechanism first proposed
exposed to stale values
mechanism first proposed in
because we have in
we have in mind
have in mind client
side applications that are
applications that are unlikely
that are unlikely to
are unlikely to validate
unlikely to validate against
to validate against the
validate against the back
gossip based infrastructures are
based infrastructures are beneficial
infrastructures are beneficial because
are beneficial because they
beneficial because they are
for many of our
simple to implement rapidly
many of our intended
to implement rapidly self
of our intended uses
our intended uses some
intended uses some level
uses some level of
stabilizing after disruptions analytically
some level of undetected
after disruptions analytically appealing
level of undetected inconsistency
disruptions analytically appealing this
of undetected inconsistency can
analytically appealing this paper
undetected inconsistency can slip
appealing this paper reports
inconsistency can slip past
this paper reports on
paper reports on the
reports on the architecture
on the architecture and
the architecture and performance
architecture and performance of
and performance of the
performance of the platform
because the developer would
the developer would often
developer would often be
would often be able
and explores the limitations
often be able to
explores the limitations of
be able to tune
the limitations of its
able to tune the
limitations of its underlying
to tune the mechanism
of its underlying techniques
nd workshop on the
workshop on the economics
on the economics of
the economics of peer
state operation of large
operation of large applications
the experiments are designed
experiments are designed to
are designed to help
the rate of unnoticed
designed to help us
rate of unnoticed inconsistencies
to help us fully
of unnoticed inconsistencies could
help us fully understand
unnoticed inconsistencies could be
inconsistencies could be extremely
us fully understand the
could be extremely low
fully understand the fundamental
understand the fundamental properties
the fundamental properties of
fundamental properties of a
properties of a single
of a single partitioned
with clustered workloads we
a single partitioned replicated
clustered workloads we will
single partitioned replicated service
workloads we will demonstrate
partitioned replicated service and
we will demonstrate that
replicated service and thus
will demonstrate that it
service and thus gain
demonstrate that it is
and thus gain a
that it is sufficient
thus gain a firm
it is sufficient to
gain a firm grasp
is sufficient to store
a firm grasp on
sufficient to store a
firm grasp on the
to store a small
grasp on the behavior
store a small set
on the behavior of
a small set of
the behavior of the
small set of dependencies
behavior of the ssa
set of dependencies to
of the ssa s
of dependencies to detect
the ssa s building
dependencies to detect most
ssa s building blocks
to detect most inconsistencies
we also investigate workloads
also investigate workloads where
we defer for future
investigate workloads where the
defer for future work
workloads where the clustered
for future work the
where the clustered access
future work the full
the clustered access pattern
work the full scale
clustered access pattern is
the full scale evaluation
improving robustness of peer
access pattern is less
full scale evaluation of
pattern is less strongly
scale evaluation of multiple
is less strongly evident
evaluation of multiple services
of multiple services deployed
multiple services deployed and
services deployed and running
peer streaming with incentives
deployed and running at
and running at the
running at the same
at the same time
our approach is less
approach is less effective
is less effective even
less effective even with
effective even with longer
the ssa currently runs
even with longer dependency
ssa currently runs on
with longer dependency list
currently runs on a
longer dependency list lengths
runs on a tightly
st workshop on the
on a tightly coupled
workshop on the economics
a tightly coupled cluster
on the economics of
tightly coupled cluster of
the economics of networked
coupled cluster of blade
economics of networked systems
cluster of blade servers
thus our solution is
our solution is not
solution is not a
is not a panacea
we show that developers
show that developers can
that developers can tune
developers can tune parameters
can tune parameters to
for applications matched to
tune parameters to trade
applications matched to our
parameters to trade overhead
matched to our assumptions
to trade overhead for
trade overhead for speed
overhead for speed of
for speed of repair
can be highly effective
speed of repair and
of repair and we
repair and we believe
and we believe that
we believe that our
believe that our results
that our results validate
our results validate the
results validate the approach
database we assume that
we assume that the
assume that the database
that the database tags
the database tags each
database tags each object
tags each object with
application model our work
each object with a
model our work focuses
object with a version
our work focuses on
with a version number
work focuses on datacenters
a version number specific
focuses on datacenters supporting
version number specific to
on datacenters supporting one
number specific to the
datacenters supporting one or
specific to the transaction
supporting one or more
to the transaction that
one or more services
the transaction that most
or more services deployed
transaction that most recently
more services deployed within
that most recently updated
services deployed within a
most recently updated it
deployed within a cluster
within a cluster of
a cluster of compute
cluster of compute nodes
and that there is
that there is a
there is a total
is a total ordering
a total ordering on
total ordering on version
ordering on version numbers
tailer might implement a
might implement a front
the version of a
version of a transaction
end service that builds
of a transaction is
service that builds web
that builds web pages
a transaction is chosen
transaction is chosen to
is chosen to be
p live streaming system
chosen to be larger
parallelizing the task by
to be larger than
the task by dispatching
be larger than the
task by dispatching sub
larger than the versions
than the versions of
the versions of all
versions of all objects
of the ninth ieee
tasks to services to
of all objects accessed
to services to rank
the ninth ieee global
services to rank product
all objects accessed by
to rank product popularity
ninth ieee global internet
objects accessed by the
ieee global internet workshop
accessed by the transaction
the database stores for
database stores for each
stores for each object
for each object o
each object o a
object o a list
o a list of
a list of k
list of k dependencies
end service would probably
service would probably just
would probably just be
probably just be cloned
with identical replicas that
identical replicas that build
replicas that build pages
end services might be
services might be partitioned
might be partitioned into
be partitioned into subservices
partitioned into subservices for
into subservices for scalability
subservices for scalability using
for scalability using some
scalability using some key
and subservices cloned for
subservices cloned for faulttolerance
cloned for faulttolerance and
for faulttolerance and load
this is a common
is a common model
this is a list
jim gray and others
is a list of
gray and others have
a list of identifiers
and others have suggested
list of identifiers and
others have suggested that
of identifiers and versions
have suggested that such
identifiers and versions of
suggested that such a
and versions of other
that such a system
versions of other objects
such a system be
of other objects that
a system be termed
other objects that the
system be termed a
objects that the current
be termed a farm
that the current version
termed a farm consisting
the current version of
a farm consisting of
current version of o
farm consisting of raps
version of o depends
of o depends on
reliable array of partitioned
array of partitioned services
only transaction that sees
transaction that sees the
that sees the current
sees the current version
reliable array of cloned
the current version of
array of cloned server
current version of o
of cloned server processes
version of o must
of o must not
o must not see
must not see object
not see object di
see object di with
object di with version
di with version smaller
with version smaller than
version smaller than vi
when a transaction t
a transaction t with
transaction t with version
t with version vt
with version vt touches
version vt touches objects
vt touches objects o
up to the present
this structure has arisen
it updates both their
structure has arisen mostly
updates both their versions
has arisen mostly in
both their versions and
arisen mostly in very
their versions and their
mostly in very large
versions and their dependency
in very large datacenters
and their dependency lists
very large datacenters and
large datacenters and is
datacenters and is supported
and is supported primarily
subsequent accesses to object
is supported primarily in
accesses to object o
supported primarily in the
primarily in the context
in the context of
the context of three
must see object o
with a version not
a version not smaller
version not smaller than
not smaller than vt
we believe that similar
believe that similar architectures
that similar architectures will
similar architectures will be
architectures will be needed
it inherits all of
will be needed more
inherits all of the
be needed more widely
all of the l
of the l dependencies
the l dependencies of
l dependencies of o
because the need to
the need to tolerate
need to tolerate heavy
to tolerate heavy loads
tolerate heavy loads is
heavy loads is increasingly
loads is increasingly ubiquitous
where l is the
l is the length
is the length of
the length of o
and economic considerations favor
economic considerations favor clustered
considerations favor clustered solutions
so the dependency list
game servers require scalability
the dependency list of
servers require scalability for
dependency list of o
require scalability for situations
scalability for situations in
for situations in which
situations in which there
in which there are
which there are many
there are many users
military systems require scalability
systems require scalability to
require scalability to support
scalability to support new
to support new generations
support new generations of
new generations of integrated
generations of integrated applications
hospital automation is putting
automation is putting new
is putting new demands
putting new demands on
new demands on medical
demands on medical information
on medical information subsystems
in a wide range
a wide range of
wide range of everyday
range of everyday settings
the rollout of soas
rollout of soas and
of soas and the
soas and the ease
and the ease of
the ease of application
ease of application integration
of application integration they
application integration they support
integration they support will
they support will place
support will place services
will place services under
place services under growing
services under growing load
our goal is to
goal is to make
is to make it
to make it easy
make it easy to
it easy to build
easy to build raps
to build raps and
build raps and racs
raps and racs from
and racs from traditional
web service applications designed
service applications designed for
applications designed for quick
designed for quick responsiveness
we also want to
also want to build
want to build the
to build the simplest
build the simplest platform
the simplest platform capable
simplest platform capable of
platform capable of accomplishing
capable of accomplishing this
of accomplishing this task
a set of racs
gossip traffic chain figure
elements of the model
when a transaction is
of the model a
a transaction is committed
the model a service
model a service is
a service is simply
service is simply an
this update is done
is simply an application
update is done for
simply an application that
is done for all
an application that provides
done for all objects
application that provides interfaces
for all objects in
that provides interfaces that
all objects in the
provides interfaces that manipulate
objects in the transaction
interfaces that manipulate objects
in the transaction at
that manipulate objects of
the transaction at once
manipulate objects of unspecified
building collaboration applications that
objects of unspecified nature
collaboration applications that mix
applications that mix web
given a read set
that mix web services
a read set readset
mix web services hosted
web services hosted content
a query operation reads
services hosted content with
query operation reads some
hosted content with p
operation reads some object
and a write set
reads some object and
a write set writeset
some object and returns
object and returns a
and returns a computed
returns a computed value
containing tuples comprised of
tuples comprised of the
comprised of the keys
of the keys accessed
an update operation modifies
update operation modifies one
operation modifies one or
modifies one or more
one or more objects
their versions and their
versions and their dependency
and their dependency lists
one unusual assumption made
unusual assumption made in
assumption made in our
the database aggregates them
made in our work
database aggregates them to
in our work is
aggregates them to a
our work is that
them to a single
work is that many
to a single full
is that many services
a single full dependency
that many services can
single full dependency list
many services can process
krzysztof ostrowski cornell university
services can process updates
full dependency list as
can process updates out
dependency list as follows
process updates out of
updates out of order
dept of computer science
we focus on services
focus on services that
on services that can
services that can respond
that can respond correctly
can respond correctly to
respond correctly to queries
correctly to queries even
to queries even if
queries even if some
even if some updates
if some updates are
some updates are temporarily
updates are temporarily missing
converge into a state
into a state determined
a state determined entirely
state determined entirely by
determined entirely by the
entirely by the set
by the set of
the set of updates
so that if two
that if two members
if two members of
two members of some
members of some subservice
of some subservice receive
some subservice receive the
readset writeset this list
subservice receive the same
writeset this list is
receive the same updates
this list is pruned
the same updates they
list is pruned to
same updates they will
is pruned to match
updates they will be
pruned to match the
they will be in
to match the target
will be in equivalent
match the target size
be in equivalent states
the target size using
target size using lru
even if those updates
and stored with each
if those updates were
stored with each write
those updates were delivered
updates were delivered in
were delivered in different
delivered in different orders
a list entry can
list entry can be
entry can be discarded
a reissued query or
can be discarded if
reissued query or update
be discarded if the
query or update returns
discarded if the same
or update returns an
if the same entry
update returns an equivalent
edu abstract the most
returns an equivalent result
the same entry s
abstract the most commonly
same entry s object
the most commonly deployed
entry s object appears
most commonly deployed web
what this amounts to
commonly deployed web service
s object appears in
this amounts to is
object appears in another
deployed web service applications
amounts to is that
web service applications employ
appears in another entry
service applications employ client
to is that the
in another entry with
is that the ssa
another entry with a
that the ssa should
entry with a larger
the ssa should deliver
with a larger version
ssa should deliver updates
should deliver updates as
deliver updates as soon
with clients running remotely
updates as soon as
clients running remotely and
as soon as it
running remotely and services
soon as it can
remotely and services hosted
as it can even
and services hosted in
it can even if
services hosted in data
were their lengths not
hosted in data centers
can even if they
their lengths not bounded
even if they are
if they are not
they are not in
are not in order
dependency lists could quickly
lists could quickly grow
could quickly grow to
we make the case
quickly grow to include
make the case for
grow to include all
the case for service
to include all objects
include all objects in
one way that an
all objects in the
objects in the database
way that an application
that an application might
an application might process
application might process out
might process out of
process out of order
out of order updates
applications that combine service
cache in our scheme
of order updates is
order updates is simply
updates is simply to
is simply to delay
hosted data with collaboration
simply to delay processing
data with collaboration features
the cache interacts with
with collaboration features implemented
to delay processing them
collaboration features implemented using
cache interacts with the
features implemented using peerto
delay processing them until
interacts with the database
processing them until it
with the database in
them until it can
the database in essentially
until it can sort
database in essentially the
it can sort them
in essentially the same
can sort them into
essentially the same manner
sort them into order
the same manner as
collaboration features are awkward
same manner as for
features are awkward to
manner as for a
are awkward to support
as for a consistency
awkward to support solely
but we believe that
to support solely based
we believe that for
support solely based on
believe that for many
solely based on the
that for many uses
based on the existing
on the existing web
the existing web services
existing web services technologies
it will be possible
will be possible to
be possible to act
indirection through the data
possible to act on
through the data center
to act on an
the data center introduces
act on an update
data center introduces high
on an update or
center introduces high latencies
an update or query
introduces high latencies and
update or query immediately
high latencies and limits
or query immediately upon
latencies and limits scalability
query immediately upon receiving
and receiving invalidations as
immediately upon receiving it
receiving invalidations as the
invalidations as the database
as the database updates
the database updates objects
and precludes collaboration between
the ssa can support
precludes collaboration between clients
ssa can support raps
collaboration between clients connected
between clients connected to
clients connected to one
another but lacking connectivity
but lacking connectivity to
a raps of racs
lacking connectivity to the
the caches read from
connectivity to the data
caches read from the
to the data center
read from the database
from the database not
a service that can
the database not only
database not only the
service that can be
cornell s live distributed
not only the object
that can be structured
only the object s
s live distributed objects
can be structured as
the object s value
live distributed objects platform
be structured as a
distributed objects platform combines
structured as a raps
objects platform combines web
as a raps must
but also its version
platform combines web services
a raps must have
combines web services with
also its version and
web services with direct
raps must have a
services with direct peerto
its version and the
must have a partitioning
version and the dependency
have a partitioning function
and the dependency list
a partitioning function that
peer communication to eliminate
partitioning function that can
communication to eliminate these
function that can be
to eliminate these issues
that can be used
can be used to
be used to map
used to map each
the extended cache exports
to map each operation
extended cache exports a
map each operation to
cache exports a transactional
each operation to the
exports a transactional read
operation to the subservice
to the subservice that
the subservice that should
subservice that should execute
that should execute it
introduction there is a
there is a growing
is a growing opportunity
a growing opportunity to
growing opportunity to use
client read requests are
opportunity to use service
existing systems typically implement
read requests are extended
systems typically implement partitioning
requests are extended with
typically implement partitioning functions
are extended with a
implement partitioning functions in
extended with a transaction
partitioning functions in one
with a transaction identifier
functions in one of
a transaction identifier and
in one of two
transaction identifier and a
one of two ways
identifier and a last
applications in ways that
in ways that can
ways that can slash
that can slash health
the service exports its
service exports its partitioning
exports its partitioning function
so that clients are
that clients are able
clients are able to
permit more effective search
are able to locally
more effective search and
able to locally implement
effective search and rescue
to locally implement the
search and rescue after
locally implement the logic
and rescue after a
implement the logic mapping
rescue after a disaster
the transaction identifier txnid
the logic mapping requests
transaction identifier txnid allows
logic mapping requests to
identifier txnid allows the
mapping requests to subservices
enable a more nimble
txnid allows the cache
a more nimble information
allows the cache to
the cache to recognize
cache to recognize reads
to recognize reads belonging
recognize reads belonging to
reads belonging to the
belonging to the same
the cluster might control
to the same transaction
cluster might control the
or make possible a
might control the dns
make possible a world
possible a world of
a world of professional
the cache responds with
world of professional dialog
or could influence the
cache responds with either
could influence the creation
responds with either the
influence the creation of
with either the value
of professional dialog and
either the value of
the creation of web
the value of the
creation of web pages
value of the requested
of web pages by
of the requested object
web pages by modifying
professional dialog and collaboration
pages by modifying urls
dialog and collaboration without
and collaboration without travel
or with an abort
so that clients will
with an abort if
that clients will be
soc applications will need
clients will be directed
an abort if it
will be directed to
applications will need to
abort if it detects
be directed to an
will need to combine
directed to an appropriate
if it detects an
to an appropriate subservice
need to combine two
it detects an inconsistency
to combine two types
detects an inconsistency between
combine two types of
an inconsistency between this
two types of content
inconsistency between this read
between this read and
this read and any
the servers might export
read and any of
servers might export actual
traditional web service hosted
might export actual code
web service hosted content
export actual code that
and any of the
actual code that the
any of the previous
code that the client
of the previous reads
that the client runs
the previous reads with
such as data from
previous reads with the
as data from databases
reads with the same
with the same transaction
the same transaction id
the partitioning logic is
we do not guarantee
partitioning logic is situated
do not guarantee that
logic is situated on
not guarantee that inconsistencies
is situated on a
guarantee that inconsistencies will
situated on a load
and weather prediction systems
on a load balancing
that inconsistencies will be
a load balancing component
inconsistencies will be detected
load balancing component resident
balancing component resident in
with a variety of
component resident in the
a variety of collaboration
resident in the server
variety of collaboration features
in the server cluster
the lastop allows the
lastop allows the cache
allows the cache to
the cache to garbage
such as chat windows
the load balancer sprays
load balancer sprays requests
balancer sprays requests over
collect its transaction record
sprays requests over the
its transaction record after
requests over the subservices
transaction record after responding
over the subservices in
record after responding to
the subservices in accordance
after responding to the
subservices in accordance with
responding to the last
in accordance with server
to the last read
accordance with server logic
peer video and other
the last read operation
video and other media
last read operation of
and other media streams
read operation of the
operation of the transaction
the ssa supports the
ssa supports the latter
the cache will treat
supports the latter approach
cache will treat subsequent
will treat subsequent accesses
treat subsequent accesses with
subsequent accesses with the
offering a mechanism that
existing web service technologies
accesses with the same
a mechanism that assists
with the same transaction
mechanism that assists the
the same transaction id
that assists the load
web service technologies make
same transaction id as
service technologies make it
transaction id as new
technologies make it easy
id as new transactions
balancing component in tracking
make it easy to
component in tracking membership
it easy to build
in tracking membership so
easy to build applications
tracking membership so that
to build applications in
to implement this interface
build applications in which
membership so that it
applications in which all
so that it can
in which all data
that it can appropriately
which all data travels
it can appropriately route
all data travels through
the cache maintains a
data travels through a
can appropriately route queries
travels through a data
cache maintains a record
through a data center
appropriately route queries and
maintains a record of
route queries and updates
a record of each
record of each transaction
of each transaction with
each transaction with its
implementing collaboration features using
transaction with its read
collaboration features using these
with its read values
features using these technologies
using these technologies is
we assume that processes
these technologies is problematic
assume that processes are
technologies is problematic because
that processes are fail
is problematic because collaborative
problematic because collaborative applications
because collaborative applications can
and their dependency lists
collaborative applications can generate
applications can generate high
should a failure occur
on a read of
a read of keycurr
bursty update rates and
update rates and yet
rates and yet often
and yet often require
the cache first obtains
yet often require low
cache first obtains the
and will eventually be
first obtains the requested
often require low latencies
obtains the requested entry
will eventually be detected
the requested entry from
eventually be detected as
requested entry from memory
be detected as faulty
require low latencies and
low latencies and tight
latencies and tight synchronization
and tight synchronization between
tight synchronization between collaborating
synchronization between collaborating users
a failure may be
failure may be transient
one can often achieve
can often achieve better
often achieve better performance
a process can become
achieve better performance using
process can become temporarily
better performance using direct
can become temporarily unavailable
performance using direct client
but then restart and
then restart and recover
restart and recover any
and recover any missing
recover any missing updates
the entry includes the
entry includes the value
version vercurr and dependency
vercurr and dependency list
and dependency list deplistcurr
the cache checks the
discussion our model is
cache checks the currently
our model is not
model is not completely
checks the currently read
is not completely general
the currently read object
currently read object against
but in today s
read object against each
in today s soa
object against each of
and for this reason
against each of the
for this reason some
each of the previously
this reason some discussion
of the previously read
reason some discussion is
the previously read objects
today s soa plat
some discussion is needed
if a previously read
consider the following example
a previously read version
previously read version v
read version v is
version v is older
we wish to support
v is older than
wish to support a
is older than expected
band communication is hard
older than expected by
communication is hard to
to support a scalable
is hard to integrate
than expected by the
hard to integrate with
support a scalable inventory
to integrate with hosted
expected by the current
integrate with hosted content
a scalable inventory service
by the current read
scalable inventory service that
the current read s
inventory service that receives
current read s dependencies
service that receives updates
read s dependencies v
this problem is reflected
s dependencies v k
that receives updates corresponding
problem is reflected by
receives updates corresponding to
is reflected by a
updates corresponding to inventory
reflected by a growing
corresponding to inventory consumption
by a growing number
to inventory consumption and
a growing number of
inventory consumption and re
growing number of publications
number of publications on
of publications on the
publications on the integration
on the integration of
the integration of web
integration of web services
of web services with
web services with peer
queries against such a
against such a service
such a service would
a service would compute
service would compute and
would compute and return
compute and return an
and return an inventory
return an inventory count
an inventory count as
inventory count as of
count as of the
as of the time
of the time the
the time the query
time the query was
the query was processed
but inventory can change
inventory can change in
can change in real
reissued a moment later
might yield a different
yield a different result
a different result and
different result and yet
result and yet both
and yet both would
yet both would be
both would be correct
or the current read
the current read vcurr
current read vcurr is
read vcurr is older
vcurr is older than
is older than expected
older than expected by
than expected by the
responses reflecting a reasonably
expected by the dependencies
reflecting a reasonably current
by the dependencies of
a reasonably current server
the dependencies of a
reasonably current server state
dependencies of a previous
current server state are
server state are acceptable
of a previous read
a previous read v
previous read v v
on the other hand
a response reflecting a
response reflecting a very
reflecting a very stale
a very stale state
very stale state would
stale state would be
state would be incorrect
a client should not
client should not be
should not be offered
not be offered a
be offered a promotional
offered a promotional price
a promotional price on
promotional price on a
price on a plasma
on a plasma tv
a plasma tv if
plasma tv if the
tv if the last
if the last unit
the last unit was
last unit was actually
unit was actually sold
was actually sold hours
actually sold hours ago
an inconsistency is detected
the inventory service should
otherwise the cache returns
inventory service should reflect
the cache returns the
service should reflect as
cache returns the read
should reflect as many
returns the read value
reflect as many updates
the read value to
as many updates as
read value to the
many updates as possible
value to the client
updates as possible in
as possible in the
possible in the replies
in the replies it
the replies it gives
upon detecting an inconsistency
replies it gives to
it gives to requests
the cache can take
but any reply is
cache can take one
any reply is correct
can take one of
reply is correct provided
take one of three
is correct provided that
one of three paths
correct provided that it
provided that it was
that it was based
it was based on
was based on a
based on a recent
on a recent state
we shall see that
shall see that the
see that the ssa
that the ssa allows
abort the current transaction
the ssa allows brief
ssa allows brief inconsistencies
allows brief inconsistencies but
brief inconsistencies but that
inconsistencies but that they
compared to the other
but that they can
to the other approaches
that they can be
they can be limited
can be limited to
be limited to a
limited to a few
to a few seconds
this has the benefit
has the benefit of
the benefit of affecting
benefit of affecting only
of affecting only the
operations against the inventory
affecting only the running
against the inventory service
only the running transaction
the inventory service happen
the running transaction and
inventory service happen to
running transaction and limiting
service happen to be
transaction and limiting collateral
happen to be commutative
and limiting collateral damage
yet the issue remains
the issue remains unresolved
hence the service can
the service can process
service can process updates
can process updates out
process updates out of
updates out of order
but many kinds of
many kinds of services
kinds of services can
abort the current transaction
of services can handle
the current transaction and
services can handle out
cornell s live distributed
can handle out of
current transaction and evict
handle out of order
s live distributed objects
out of order updates
transaction and evict the
live distributed objects platform
and evict the violating
if for no other
for no other reason
no other reason than
other reason than that
reason than that in
than that in many
that in many settings
object from the cache
each update is uniquely
update is uniquely sequenced
is uniquely sequenced by
uniquely sequenced by its
sequenced by its source
this approach guesses that
approach guesses that future
live objects for short
guesses that future transactions
that future transactions are
permitting the service to
future transactions are likely
the service to sort
allow even a non
service to sort updates
transactions are likely to
to sort updates and
are likely to abort
sort updates and to
likely to abort because
programmer to construct content
to abort because of
updates and to process
abort because of this
and to process queries
because of this object
to process queries against
process queries against the
rich solutions that blend
queries against the sorted
solutions that blend traditional
against the sorted database
that blend traditional web
blend traditional web services
traditional web services and
web services and peer
our group has held
group has held discussions
has held discussions with
held discussions with operators
discussions with operators of
with operators of several
operators of several large
check which is the
of several large datacenters
which is the violating
is the violating object
and to share them
to share them with
share them with others
and concluded that many
if it is the
concluded that many services
it is the currently
that many services have
is the currently accessed
many services have the
the currently accessed object
this is like creating
services have the kinds
is like creating a
have the kinds of
like creating a slide
the kinds of properties
creating a slide show
kinds of properties just
of properties just cited
ability to respond based
to respond based on
respond based on a
based on a reasonable
on a reasonable current
a reasonable current state
treat this access as
after which the solution
this access as a
which the solution can
access as a miss
the solution can be
as a miss and
and to handle out
solution can be shared
a miss and respond
can be shared in
miss and respond to
be shared in a
and respond to it
shared in a file
respond to it with
in a file or
to it with a
a file or via
it with a value
file or via email
the ssa is a
or via email and
with a value read
via email and opened
ssa is a good
email and opened on
a value read from
and opened on other
value read from the
opened on other machines
read from the database
is a good match
a good match for
good match for personalization
match for personalization services
the users are immersed
if the violating object
users are immersed in
the violating object was
are immersed in the
violating object was returned
immersed in the resulting
object was returned to
in the resulting collaborative
was returned to the
the resulting collaborative application
returned to the user
to the user as
the user as the
user as the result
as the result of
they can interact with
the result of a
can interact with the
result of a read
interact with the application
of a read earlier
with the application and
a read earlier in
the application and peers
read earlier in the
application and peers see
earlier in the transaction
and peers see the
peers see the results
see the results instantly
updates are applied to
are applied to all
applied to all replicas
to all replicas in
all replicas in a
replicas in a consistent
in a consistent manner
evict the stale object
the stale object and
stale object and abort
object and abort the
and abort the transaction
in contrast to today
contrast to today s
to today s web
today s web service
s web service platforms
consistency with unbounded resources
p communication can coexist
communication can coexist with
can coexist with more
cache detects all inconsistencies
coexist with more standard
with more standard solutions
more standard solutions that
as stated in the
standard solutions that reach
stated in the following
these deal primarily with
in the following theorem
solutions that reach back
deal primarily with weakly
that reach back to
primarily with weakly consistent
reach back to the
with weakly consistent data
back to the hosted
to the hosted content
the hosted content and
hosted content and trigger
content and trigger updates
and trigger updates at
trigger updates at the
updates at the associated
at the associated data
the associated data centers
and all sorts of
all sorts of services
sorts of services in
of services in which
services in which replies
cache with unbounded cache
in which replies are
when an application needs
with unbounded cache size
an application needs high
which replies are intrinsically
application needs high data
unbounded cache size and
needs high data rates
replies are intrinsically noisy
cache size and unbounded
size and unbounded dependency
and unbounded dependency lists
unbounded dependency lists implements
dependency lists implements cache
such as services that
as services that report
services that report data
that report data gathered
report data gathered from
data gathered from remote
gathered from remote sensors
it can use protocols
can use protocols that
use protocols that bypass
protocols that bypass the
that bypass the data
bypass the data center
the data center to
a datacenter would also
deferred to appendix a
datacenter would also host
data center to achieve
would also host some
center to achieve the
also host some kinds
to achieve the full
host some kinds of
achieve the full performance
some kinds of services
is by constructing a
the full performance of
kinds of services ill
full performance of the
by constructing a serialization
performance of the network
constructing a serialization of
a serialization of the
serialization of the transactions
matched to our model
of the transactions in
this paper makes the
the transactions in the
paper makes the following
transactions in the database
makes the following contributions
in the database and
but because we are
the database and in
because we are working
database and in one
we are working with
and in one cache
are working with web
we describe a new
working with web services
describe a new class
a new class of
new class of service
based on the fact
on the fact that
services running on the
the fact that the
running on the ssa
fact that the transactions
on the ssa can
that the transactions in
the ssa can easily
the transactions in the
ssa can easily interact
transactions in the database
can easily interact with
in the database are
easily interact with services
the database are serializable
applications that integrate service
interact with services that
database are serializable by
with services that employ
that integrate service hosted
services that employ other
integrate service hosted content
that employ other solutions
are serializable by definition
service hosted content with
hosted content with peer
the implications of theorem
will be seen in
be seen in section
seen in section v
we analyze two important
analyze two important examples
consistency semantics the ssa
two important examples of
semantics the ssa implements
important examples of soc
the ssa implements stochastic
examples of soc applications
ssa implements stochastic consistency
implements stochastic consistency semantics
search and rescue mission
and rescue mission and
rescue mission and virtual
an application will only
mission and virtual worlds
application will only observe
will only observe an
only observe an inconsistency
observe an inconsistency if
cache converges to perfect
an inconsistency if a
inconsistency if a fault
converges to perfect detection
if a fault occurs
to perfect detection when
perfect detection when stable
we list the key
and even then only
list the key challenges
even then only for
the key challenges that
then only for a
key challenges that soc
only for a period
challenges that soc applications
for a period of
that soc applications place
a period of time
soc applications place on
period of time associated
applications place on their
of time associated with
place on their runtime
detection when stable clusters
on their runtime environments
time associated with our
when stable clusters are
associated with our repair
stable clusters are as
with our repair protocol
clusters are as large
we describe a new
describe a new class
are as large as
a new class of
and only if it
new class of multi
only if it has
as large as its
if it has the
large as its dependency
it has the bad
as its dependency lists
has the bad luck
layered mashups and contrast
the bad luck to
mashups and contrast them
bad luck to query
and contrast them with
luck to query a
contrast them with more
to query a node
in such a scenario
query a node impacted
them with more traditional
a node impacted by
node impacted by the
impacted by the failure
the dependency lists are
dependency lists are large
this window can be
based approach to building
window can be made
lists are large enough
can be made small
approach to building mashups
are large enough to
large enough to describe
enough to describe all
so that applications are
characteristic of today s
to describe all relevant
of today s web
that applications are unlikely
today s web development
describe all relevant dependencies
applications are unlikely to
are unlikely to observe
unlikely to observe a
to observe a problem
we discuss the relative
discuss the relative advantages
the relative advantages of
relative advantages of these
or permitted to grow
e xperimental s etup
permitted to grow somewhat
advantages of these two
to grow somewhat larger
xperimental s etup to
of these two approaches
s etup to evaluate
these two approaches for
etup to evaluate the
two approaches for building
to evaluate the effectiveness
approaches for building soc
depending upon the cost
evaluate the effectiveness of
upon the cost of
for building soc applications
the cost of inconsistency
the effectiveness of our
cost of inconsistency and
effectiveness of our scheme
of inconsistency and the
inconsistency and the relative
we discuss the advantages
and the relative value
discuss the advantages of
we implemented a prototype
the advantages of decoupling
advantages of decoupling transport
of decoupling transport and
decoupling transport and information
to study the properties
transport and information layers
study the properties of
and information layers as
the properties of the
information layers as a
of faster response time
layers as a means
properties of the cache
as a means of
faster response time versus
a means of achieving
response time versus lower
means of achieving reusability
time versus lower risk
versus lower risk of
lower risk of an
risk of an observed
of an observed fault
we only need a
only need a single
need a single column
in the experimental work
ability to rapidly deploy
the experimental work that
to rapidly deploy soc
experimental work that follows
rapidly deploy soc applications
deploy soc applications in
soc applications in new
applications in new environments
we measure these windows
in new environments and
measure these windows for
new environments and adapt
these windows for scenarios
environments and adapt them
windows for scenarios representative
and adapt them dynamically
for scenarios representative of
adapt them dynamically this
namely a single cache
scenarios representative of conditions
them dynamically this work
a single cache backed
dynamically this work was
representative of conditions that
this work was supported
single cache backed by
of conditions that arise
conditions that arise in
cache backed by a
that arise in realistic
arise in realistic settings
backed by a single
by a single database
a single database server
the ssa framework the
ssa framework the basic
framework the basic operation
the basic operation of
basic operation of the
operation of the ssa
illustrates the structure of
qi huang is a
the structure of our
of the ssa is
structure of our experimental
huang is a visiting
of our experimental setup
the ssa is as
is a visiting scientist
ssa is as follows
a visiting scientist from
visiting scientist from the
scientist from the school
a single database implements
from the school of
single database implements a
as queries or updates
database implements a transactional
queries or updates are
implements a transactional key
or updates are received
the school of computer
updates are received in
school of computer sci
are received in the
received in the cluster
they are passed through
are passed through a
passed through a partition
huazhong university of sci
through a partition mapping
a partition mapping component
which directs the request
update clients access database
directs the request to
supported by the chinese
the request to an
by the chinese nsfc
request to an appropriate
to an appropriate racs
which sends invalidations to
sends invalidations to the
invalidations to the cache
we will use the
will use the term
use the term subservice
the term subservice rather
term subservice rather than
subservice rather than racs
only clients access cache
rather than racs in
than racs in the
racs in the remainder
in the remainder of
the remainder of the
remainder of the paper
to create a subservice
create a subservice the
a subservice the developer
subservice the developer must
the developer must first
developer must first implement
must first implement a
receives all transactions and
first implement a non
all transactions and rigorously
transactions and rigorously detects
and rigorously detects inconsistencies
rigorously detects inconsistencies for
detects inconsistencies for statistics
this is then cloned
is then cloned using
then cloned using the
cloned using the ssa
using the ssa platform
each replica is placed
a set of cache
replica is placed on
set of cache clients
is placed on a
of cache clients perform
placed on a separate
cache clients perform readonly
on a separate node
clients perform readonly transactions
perform readonly transactions through
readonly transactions through a
transactions through a single
through a single cache
and the replicas are
a single cache server
the replicas are then
replicas are then linked
are then linked using
then linked using tcp
linked using tcp to
using tcp to create
tcp to create a
layered mashup to the
to create a chain
mashup to the changing
to the changing needs
the cache serves the
cache serves the requests
serves the requests from
we discuss the resulting
the requests from its
discuss the resulting objectoriented
requests from its local
the resulting objectoriented perspective
from its local storage
its local storage if
local storage if possible
in which instances of
we therefore have a
which instances of distributed
or reads from the
instances of distributed communication
reads from the database
of distributed communication protocols
from the database otherwise
distributed communication protocols are
communication protocols are modeled
protocols are modeled uniformly
are modeled uniformly as
modeled uniformly as objects
uniformly as objects similar
as objects similar to
objects similar to those
mapping between a subservice
similar to those in
between a subservice and
to those in java
a subservice and a
the cache registers an
subservice and a chain
cache registers an upcall
registers an upcall that
an upcall that can
upcall that can be
that can be used
can be used by
be used by the
used by the database
by the database to
the database to report
database to report invalidations
the embedded script is
embedded script is often
after each update transaction
gossip based chain replication
script is often tightly
each update transaction the
based chain replication the
is often tightly integrated
update transaction the database
often tightly integrated with
chain replication the replication
tightly integrated with backend
transaction the database asynchronously
integrated with backend services
the database asynchronously sends
with backend services in
replication the replication scheme
backend services in the
database asynchronously sends invalidations
the replication scheme has
services in the data
asynchronously sends invalidations to
in the data center
replication scheme has evolved
sends invalidations to the
scheme has evolved out
invalidations to the cache
has evolved out of
to the cache for
evolved out of the
the cache for all
making it awkward to
cache for all objects
out of the chain
for all objects that
it awkward to access
all objects that were
of the chain replication
objects that were modified
the chain replication mechanism
awkward to access the
chain replication mechanism first
to access the underlying
replication mechanism first introduced
access the underlying services
mechanism first introduced in
the underlying services directly
underlying services directly from
services directly from a
directly from a different
from a different script
a different script or
different script or a
script or a standalone
or a standalone client
chosen uniformly at random
are dropped by the
the only way such
the original scheme was
only way such services
dropped by the experiment
original scheme was developed
way such services can
scheme was developed as
such services can be
was developed as a
services can be mashed
developed as a means
can be mashed up
as a means of
be mashed up with
a means of obtaining
mashed up with other
means of obtaining high
up with other web
this is extreme and
with other web content
of obtaining high throughput
is extreme and would
other web content is
obtaining high throughput and
web content is by
extreme and would only
content is by either
high throughput and availability
is by either having
throughput and availability for
by either having the
and would only be
either having the data
and availability for query
having the data center
availability for query and
would only be seen
for query and update
the data center compute
query and update requests
data center compute the
only be seen in
center compute the mashup
and update requests without
be seen in the
update requests without sacrificing
seen in the real
requests without sacrificing strong
in the real world
without sacrificing strong consistency
the real world under
so that it can
sacrificing strong consistency guarantees
that it can be
real world under conditions
it can be accessed
can be accessed via
world under conditions of
be accessed via the
accessed via the minibrowser
under conditions of overload
conditions of overload or
of overload or when
overload or when the
the gossip based chain
or when the system
gossip based chain replication
when the system configuration
based chain replication behaves
or by embedding the
the system configuration is
chain replication behaves in
system configuration is changed
by embedding the entire
replication behaves in the
embedding the entire minibrowser
behaves in the following
the entire minibrowser window
in the following manner
entire minibrowser window in
the following manner during
minibrowser window in a
following manner during normal
window in a web
manner during normal operation
both the database and
during normal operation when
in a web page
the database and the
normal operation when nodes
database and the cache
operation when nodes aren
and the cache report
when nodes aren t
the cache report all
nodes aren t failing
but an embedded minibrowser
aren t failing or
cache report all completed
t failing or restarting
an embedded minibrowser can
report all completed transactions
embedded minibrowser can t
all completed transactions to
minibrowser can t seamlessly
completed transactions to a
can t seamlessly blend
transactions to a consistency
t seamlessly blend with
to a consistency monitor
update operations are forwarded
seamlessly blend with the
operations are forwarded to
blend with the surrounding
are forwarded to the
with the surrounding content
forwarded to the head
to the head of
created in order to
the head of the
in order to gather
head of the chain
order to gather statistics
it is like a
to gather statistics for
is like a standalone
gather statistics for our
like a standalone browser
statistics for our evaluation
a standalone browser within
where the request is
standalone browser within its
the request is processed
browser within its own
request is processed using
within its own frame
is processed using the
this server collects both
processed using the local
server collects both committed
using the local replica
collects both committed and
and runs independent of
both committed and aborted
runs independent of the
committed and aborted transactions
independent of the rest
and aborted transactions and
the state changes are
aborted transactions and it
of the rest of
transactions and it maintains
the rest of the
and it maintains the
rest of the page
state changes are passed
it maintains the full
changes are passed along
maintains the full dependency
are passed along down
the full dependency graph
passed along down the
to illustrate this point
along down the chain
down the chain to
the chain to the
chain to the next
to the next element
it performs full serialization
performs full serialization graph
full serialization graph testing
which in turn updates
in turn updates it
turn updates it s
updates it s state
it s state and
s state and performs
the figures are screenshots
state and performs the
figures are screenshots of
and performs the same
are screenshots of web
performs the same operation
screenshots of web applications
the same operation until
same operation until the
operation until the tail
until the tail is
the tail is reached
with content from multiple
and calculates the rate
content from multiple sources
calculates the rate of
from multiple sources mashed
the rate of inconsistent
queries can either be
rate of inconsistent transactions
can either be directed
of inconsistent transactions that
either be directed towards
inconsistent transactions that committed
be directed towards a
transactions that committed and
directed towards a randomly
that committed and the
towards a randomly selected
committed and the rate
a randomly selected process
and the rate of
randomly selected process in
the rate of consistent
was constructed using a
rate of consistent transactions
constructed using a standard
selected process in the
using a standard web
process in the group
a standard web services
in the group or
standard web services approach
the group or to
of consistent transactions that
group or to a
consistent transactions that were
or to a specific
transactions that were unnecessarily
to a specific one
that were unnecessarily aborted
pulling content from the
content from the yahoo
the strongest consistency guarantee
maps and weather web
strongest consistency guarantee is
and weather web services
consistency guarantee is acheived
weather web services and
our prototype does not
web services and assembling
guarantee is acheived if
services and assembling it
prototype does not address
and assembling it into
is acheived if all
assembling it into a
acheived if all query
it into a web
if all query operations
into a web page
does not address the
a web page as
all query operations are
not address the issue
web page as a
query operations are targeted
page as a set
address the issue of
as a set of
operations are targeted at
a set of tiled
the issue of cache
are targeted at the
set of tiled frames
targeted at the tail
issue of cache eviction
at the tail of
of cache eviction when
the tail of the
cache eviction when running
tail of the chain
eviction when running out
each frame is a
when running out of
of the chain node
running out of memory
frame is a minibrowser
is a minibrowser with
a minibrowser with its
minibrowser with its own
with its own interactive
which is the case
its own interactive controls
is the case for
the case for the
case for the vanilla
all objects in the
for the vanilla chain
objects in the workload
the vanilla chain replication
and comes from a
vanilla chain replication scheme
comes from a single
in the workload fit
from a single content
the workload fit in
a single content source
workload fit in the
fit in the cache
however this eliminates the
this eliminates the opportunity
eliminates the opportunity to
to illustrate one of
the opportunity to load
illustrate one of the
one of the many
of the many restrictions
and eviction is only
eviction is only done
is only done if
only done if there
if the user pans
done if there is
the user pans or
if there is a
faults and node restarts
there is a direct
and node restarts can
is a direct reason
user pans or zooms
node restarts can disrupt
pans or zooms in
restarts can disrupt the
or zooms in the
can disrupt the primary
zooms in the map
disrupt the primary communication
in the map frame
the primary communication pattern
primary communication pattern of
communication pattern of the
pattern of the ssa
the associated map will
had we modeled them
associated map will shift
map will shift or
if the head of
will shift or zoom
the head of a
head of a chain
evictions would reduce the
of a chain fails
would reduce the cache
reduce the cache hit
the cache hit rate
but the other frames
the other frames remain
update sources will need
other frames remain as
sources will need to
frames remain as they
will need to discover
but could not cause
remain as they were
need to discover a
could not cause new
as they were the
not cause new inconsistencies
to discover a new
they were the frames
discover a new head
were the frames are
the frames are not
frames are not synchronized
we evaluate the effectiveness
if an inner node
an inner node crashes
inner node crashes the
evaluate the effectiveness of
node crashes the chain
crashes the chain may
the effectiveness of our
the chain may break
effectiveness of our transactional
of our transactional cache
here we see a
our transactional cache using
we see a similar
and if the tail
transactional cache using various
if the tail crashes
see a similar application
cache using various workloads
a similar application constructed
using various workloads and
similar application constructed using
various workloads and varying
application constructed using live
acks might not be
workloads and varying the
might not be sent
constructed using live objects
not be sent back
and varying the size
varying the size of
the size of the
size of the dependency
of the dependency lists
the dependency lists maintained
dependency lists maintained by
lists maintained by the
content from different sources
maintained by the cache
from different sources is
by the cache and
different sources is overlaid
or some of its
sources is overlaid in
some of its members
is overlaid in the
the cache and the
overlaid in the same
cache and the database
in the same window
the same window and
same window and synchronized
for the cases considered
processes will miss updates
will miss updates and
we used white backgrounds
miss updates and hence
used white backgrounds to
updates and hence queries
white backgrounds to highlight
and hence queries will
backgrounds to highlight the
hence queries will return
to highlight the contributions
queries will return outdated
short dependency lists suffice
will return outdated results
highlight the contributions of
the contributions of different
contributions of different sources
to repair these inconsistencies
but there are no
there are no frame
are no frame boundaries
the ssa implements a
ssa implements a secondary
implements a secondary update
a secondary update propagation
elements of this mashup
secondary update propagation mechanism
which can include map
it uses gossip protocols
can include map layers
uses gossip protocols to
an open question for
gossip protocols to rapidly
open question for further
protocols to rapidly detect
question for further study
tables showing buildings or
to rapidly detect and
showing buildings or points
for further study is
rapidly detect and repair
buildings or points of
further study is whether
detect and repair inconsistencies
study is whether there
or points of interest
is whether there are
whether there are workloads
there are workloads that
while simultaneously orchestrating repair
are workloads that might
simultaneously orchestrating repair of
workloads that might require
orchestrating repair of the
that might require limited
repair of the chain
icons representing severe weather
might require limited but
representing severe weather reports
require limited but larger
limited but larger values
the gossip rate can
gossip rate can be
rate can be tuned
note that dependencies arise
with a higher rate
that dependencies arise from
a higher rate overheads
dependencies arise from the
higher rate overheads rise
arise from the topology
rate overheads rise but
from the topology of
overheads rise but repair
the topology of the
rise but repair occurs
topology of the object
but repair occurs more
of the object graph
repair occurs more rapidly
exist layers within which
layers within which the
within which the end
which the end user
the end user can
and not from the
end user can easily
not from the size
user can easily navigate
from the size of
the size of the
repair is slower but
size of the transactions
is slower but overheads
of the transactions read
slower but overheads drop
the transactions read and
data can come from
transactions read and write
read and write sets
can come from many
come from many kinds
the subsections that follow
from many kinds of
subsections that follow discuss
as a baseline for
that follow discuss the
many kinds of we
follow discuss the two
a baseline for comparison
kinds of we discuss
discuss the two core
of we discuss our
the two core mechanisms
we discuss our live
two core mechanisms in
we also implemented a
core mechanisms in greater
discuss our live distributed
mechanisms in greater detail
also implemented a timeout
our live distributed objects
live distributed objects platform
distributed objects platform as
objects platform as an
a second class of
platform as an example
second class of faults
as an example of
class of faults are
an example of a
it reduces the probability
example of a technology
of faults are transient
of a technology that
reduces the probability of
a technology that fits
faults are transient and
technology that fits well
the probability of inconsistency
that fits well with
are transient and relate
fits well with the
probability of inconsistency by
well with the layered
transient and relate to
of inconsistency by limiting
and relate to the
inconsistency by limiting the
relate to the behavior
by limiting the life
componentized model we derived
limiting the life span
to the behavior of
the life span of
model we derived through
life span of cache
the behavior of tcp
span of cache entries
we derived through our
behavior of tcp when
derived through our analysis
of tcp when a
tcp when a node
when a node is
a node is subjected
we compare this method
node is subjected to
we compare performance of
compare this method against
compare performance of hosted
is subjected to stress
performance of hosted enterprise
this method against our
of hosted enterprise service
hosted enterprise service bus
method against our transactional
such as a burst
against our transactional cache
as a burst of
our transactional cache by
a burst of traffic
transactional cache by measuring
cache by measuring its
by measuring its effectiveness
measuring its effectiveness with
its effectiveness with a
effectiveness with a varying
with a varying time
the os tends to
os tends to lose
peer communication protocols as
tends to lose packets
communication protocols as an
to lose packets and
protocols as an underlying
lose packets and the
as an underlying communication
packets and the effect
an underlying communication substrate
and the effect is
underlying communication substrate for
the effect is that
communication substrate for soc
effect is that tcp
substrate for soc applications
is that tcp will
that tcp will impose
tcp will impose congestion
will impose congestion control
impose congestion control mechanisms
the relative strengths of
congestion control mechanisms and
control mechanisms and choke
relative strengths of each
mechanisms and choke back
strengths of each of
of each of the
both read and update
each of the solutions
read and update transactions
and update transactions access
of the solutions tested
updates will cease to
will cease to propagate
the solutions tested and
cease to propagate down
to propagate down the
solutions tested and the
propagate down the chain
tested and the lack
and the lack of
the lack of a
our experiment satisfies all
lack of a clear
experiment satisfies all read
even though most of
of a clear winner
though most of the
a clear winner serve
most of the nodes
clear winner serve as
of the nodes involved
only transactions from the
the nodes involved could
transactions from the cache
winner serve as a
nodes involved could still
serve as a further
involved could still have
as a further justification
could still have ample
a further justification for
while passing all update
still have ample capacity
passing all update transactions
further justification for the
all update transactions directly
justification for the decoupling
update transactions directly to
for the decoupling of
transactions directly to the
the decoupling of information
directly to the backend
decoupling of information and
to the backend database
of information and transport
we will show that
information and transport layers
will show that when
and transport layers advocated
show that when such
transport layers advocated above
that when such a
each cache server is
when such a problem
cache server is unaware
such a problem arises
server is unaware of
is unaware of the
unaware of the other
of the other servers
gossip will route data
the other servers it
will route data around
other servers it has
route data around the
servers it has its
data around the congested
it has its own
around the congested nodes
limitations of the existing
has its own clients
of the existing model
its own clients and
the existing model there
own clients and communicates
existing model there are
clients and communicates directly
model there are two
and communicates directly with
there are two important
and will also deliver
communicates directly with the
are two important reasons
directly with the backend
will also deliver missed
with the backend database
two important reasons why
also deliver missed updates
important reasons why integrating
deliver missed updates to
reasons why integrating peerto
missed updates to the
updates to the overloaded
the percentage of read
to the overloaded nodes
the overloaded nodes when
overloaded nodes when the
peer collaboration with server
nodes when the problem
when the problem ends
only transactions can be
transactions can be arbitrarily
can be arbitrarily high
hosted content is difficult
be arbitrarily high or
arbitrarily high or low
in the original chain
high or low in
the original chain replication
or low in this
the first is not
original chain replication scheme
first is not strictly
low in this situation
is not strictly limited
chain replication scheme the
not strictly limited to
replication scheme the queries
strictly limited to collaboration
scheme the queries are
limited to collaboration and
the queries are directed
to collaboration and peer
queries are directed to
are directed to the
directed to the tail
we can push the
to the tail of
can push the percentage
the tail of the
push the percentage up
tail of the chain
our simulation focuses on
since there is no
there is no additional
simulation focuses on just
is no additional epidemic
no additional epidemic communication
focuses on just a
it is a general
on just a single
is a general weakness
just a single cache
a general weakness of
any update known to
general weakness of the
update known to the
weakness of the current
known to the tail
a single cache it
to the tail is
of the current web
the tail is stable
the current web mashup
single cache it would
current web mashup technologies
tail is stable because
cache it would behave
is stable because it
web mashup technologies that
it would behave the
mashup technologies that makes
stable because it must
technologies that makes it
because it must first
would behave the same
that makes it hard
it must first have
makes it hard to
behave the same had
it hard to seamlessly
must first have been
the same had there
first have been seen
hard to seamlessly integrate
have been seen by
same had there been
been seen by all
to seamlessly integrate data
seen by all the
had there been many
by all the members
seamlessly integrate data from
all the members of
integrate data from several
the members of the
data from several different
members of the chain
from several different sources
there been many cache
been many cache servers
to maintain such an
maintain such an invariant
the web developers community
web developers community has
developers community has slowly
community has slowly converged
the original paper includes
has slowly converged towards
original paper includes mechanisms
slowly converged towards service
paper includes mechanisms to
converged towards service platforms
includes mechanisms to ensure
towards service platforms that
mechanisms to ensure that
service platforms that export
to ensure that a
platforms that export autonomous
ensure that a request
that export autonomous interactive
that a request really
export autonomous interactive components
a request really reaches
autonomous interactive components to
request really reaches the
interactive components to their
really reaches the head
components to their clients
reaches the head of
cache can be used
the head of the
head of the chain
can be used with
be used with any
in the form of
used with any transactional
the form of what
with any transactional backend
form of what we
any transactional backend and
of what we ll
transactional backend and any
what we ll call
that updates are passed
we ll call minibrowser
backend and any transactional
updates are passed down
and any transactional workload
ll call minibrowser interfaces
are passed down the
passed down the chain
down the chain and
the chain and applied
a minibrowser is an
chain and applied in
minibrowser is an interactive
and applied in a
is an interactive web
applied in a strictly
an interactive web page
in a strictly fifo
interactive web page with
a strictly fifo manner
web page with embedded
strictly fifo manner even
only transactions will be
fifo manner even when
page with embedded script
transactions will be similar
manner even when nodes
will be similar to
even when nodes fail
be similar to non
when nodes fail and
nodes fail and the
fail and the chain
and the chain is
the chain is restructured
and that queries are
that queries are sent
queries are sent to
the underlying database is
are sent to the
underlying database is only
sent to the tail
database is only accessed
to the tail of
is only accessed on
the tail of the
only accessed on cache
tail of the chain
optimized for displaying a
accessed on cache misses
for displaying a single
displaying a single type
a single type of
single type of content
strong consistency follows easily
consistency follows easily because
follows easily because query
easily because query requests
for example interactive maps
because query requests and
inconsistencies may be observed
example interactive maps from
query requests and update
interactive maps from google
requests and update requests
maps from google earth
and update requests are
from google earth or
update requests are processed
google earth or virtual
requests are processed serially
earth or virtual earth
are processed serially at
processed serially at the
we will use synthetic
serially at the tail
at the tail element
will use synthetic workloads
use synthetic workloads so
synthetic workloads so we
workloads so we can
the gossip based chain
our example actually overlays
gossip based chain replication
so we can evaluate
example actually overlays weather
based chain replication weakens
we can evaluate how
chain replication weakens the
actually overlays weather from
replication weakens the model
can evaluate how much
overlays weather from google
weakens the model in
weather from google on
evaluate how much inconsistency
the model in two
from google on terrain
model in two key
how much inconsistency can
in two key respects
google on terrain maps
much inconsistency can be
on terrain maps from
inconsistency can be observed
terrain maps from microsoft
can be observed as
maps from microsoft s
be observed as a
from microsoft s virtual
observed as a function
microsoft s virtual earth
as a function of
our solution might sometimes
a function of the
s virtual earth platform
function of the amount
solution might sometimes use
of the amount of
virtual earth platform and
the amount of clustering
might sometimes use the
amount of clustering in
earth platform and extracts
of clustering in the
sometimes use the wrong
clustering in the workload
platform and extracts census
use the wrong head
and extracts census data
the wrong head of
extracts census data from
wrong head of the
census data from the
head of the chain
data from the us
from the us census
this also allows us
the us census bureau
also allows us to
for example if an
allows us to look
example if an update
the lion coexists with
if an update source
lion coexists with the
us to look at
coexists with the lamb
an update source is
to look at the
update source is operating
look at the dynamic
source is operating with
at the dynamic behavior
is operating with inaccurate
the dynamic behavior of
operating with inaccurate membership
dynamic behavior of the
with inaccurate membership information
behavior of the system
the second problem is
second problem is that
problem is that with
is that with the
that with the traditional
when the amount of
with the traditional style
the amount of clustering
the traditional style of
amount of clustering and
updates might sometimes arrive
traditional style of web
might sometimes arrive out
style of web development
sometimes arrive out of
of clustering and the
arrive out of order
clustering and the clustering
and the clustering formation
the clustering formation change
content is assumed to
clustering formation change over
is assumed to be
formation change over time
assumed to be fetched
for example if the
to be fetched from
example if the chain
be fetched from a
if the chain is
fetched from a server
the chain is disrupted
chain is disrupted by
is disrupted by a
disrupted by a failure
we will look at
either directly over http
will look at workloads
by a failure and
look at workloads based
a failure and some
at workloads based on
failure and some updates
workloads based on amazon
and some updates arrive
or by interacting with
based on amazon s
some updates arrive via
on amazon s product
by interacting with a
amazon s product co
updates arrive via the
interacting with a web
arrive via the gossip
with a web service
via the gossip protocol
purchasing and orkut s
and orkut s social
orkut s social network
web pages downloaded by
s social network to
these changes substantially simplify
social network to see
pages downloaded by clients
network to see how
changes substantially simplify the
to see how much
downloaded by clients browsers
see how much inconsistency
substantially simplify the algorithm
how much inconsistency t
by clients browsers contain
simplify the algorithm but
clients browsers contain embedded
the algorithm but they
browsers contain embedded addresses
algorithm but they also
contain embedded addresses of
but they also weaken
embedded addresses of specific
cache can detect as
addresses of specific servers
they also weaken the
can detect as a
also weaken the properties
detect as a function
weaken the properties of
as a function of
the properties of the
a function of dependency
properties of the solution
technologies such as ajax
function of dependency list
such as ajax allow
of dependency list length
as ajax allow for
ajax allow for asynchronous
a less significant change
less significant change is
and compare this with
significant change is that
compare this with a
change is that we
this with a ttl
is that we load
balance queries over the
queries over the members
over the members of
the members of the
we are also interested
but traffic is still
are also interested in
members of the chain
also interested in overhead
traffic is still always
is still always routed
still always routed through
always routed through a
routed through a data
through a data center
particularly the additional load
the additional load on
additional load on the
but in ways that
load on the backend
in ways that seem
the clients don t
ways that seem to
clients don t talk
that seem to match
don t talk to
on the backend database
t talk to one
seem to match the
talk to one another
the backend database that
to match the class
backend database that could
match the class of
the class of applications
database that could form
class of applications of
of applications of interest
that could form if
could form if the
live objects allow visual
form if the the
objects allow visual content
if the the rate
and has the potential
allow visual content and
has the potential to
the the rate of
the potential to greatly
the rate of cache
potential to greatly improve
rate of cache misses
to greatly improve query
of cache misses increases
greatly improve query performance
visual content and update
content and update events
and update events to
update events to be
events to be communicated
to be communicated using
be communicated using any
communicated using any sort
b presented three strategies
using any sort of
presented three strategies for
any sort of protocol
three strategies for responding
strategies for responding to
for responding to inconsistency
responding to inconsistency detection
epidemic dissemination as noted
dissemination as noted earlier
ssa uses gossip to
for both the synthetic
uses gossip to detect
both the synthetic and
but also overlay multicast
the synthetic and realistic
gossip to detect and
synthetic and realistic workloads
to detect and repair
detect and repair the
and repair the inconsistencies
repair the inconsistencies that
we compare the efficacy
the inconsistencies that can
compare the efficacy of
inconsistencies that can arise
the efficacy of the
that can arise after
efficacy of the three
can arise after a
of the three strategies
arise after a failure
after a failure or
a failure or when
failure or when a
even a custom protocol
or when a node
a custom protocol designed
when a node joins
custom protocol designed by
protocol designed by the
designed by the content
synthetic workloads synthetic workloads
by the content provider
the basic idea is
workloads synthetic workloads allow
basic idea is simple
synthetic workloads allow us
workloads allow us to
allow us to understand
us to understand the
to understand the efficacy
each process in the
understand the efficacy of
process in the system
the efficacy of t
this makes it possible
in the system runs
makes it possible to
the system runs a
it possible to achieve
system runs a periodic
possible to achieve extremely
runs a periodic local
to achieve extremely high
cache as a function
achieve extremely high levels
as a function of
a periodic local timer
a function of clustering
extremely high levels of
high levels of throughput
levels of throughput and
of throughput and latency
without synchronization across processes
for the experiments described
the experiments described here
it also enhances security
when a timer expires
the data center server
a process computes a
data center server can
process computes a summary
center server can t
server can t see
cache with a maximum
can t see data
with a maximum of
t see data exchanged
also called a digest
see data exchanged directly
data exchanged directly between
exchanged directly between peers
elements per dependency list
the above discussion motivates
above discussion motivates our
discussion motivates our problem
motivates our problem statement
a list of things
list of things that
of things that it
things that it knows
describes synthetic workload generation
allow web applications to
web applications to overlay
applications to overlay content
to overlay content from
this summary is sent
overlay content from multiple
summary is sent to
content from multiple sources
is sent to a
from multiple sources in
sent to a randomly
multiple sources in a
to a randomly selected
sources in a layered
a randomly selected peer
in a layered fashion
measures how many inconsistencies
how many inconsistencies we
or subset of peers
many inconsistencies we can
such that the distinct
inconsistencies we can detect
that the distinct content
we can detect as
the distinct content layers
can detect as a
distinct content layers share
detect as a function
content layers share a
as a function of
layers share a single
a function of clustering
quick delivery is more
function of clustering and
share a single view
of clustering and section
a single view and
clustering and section v
single view and remain
delivery is more important
view and remain well
is more important than
and remain well synchronized
more important than reliability
important than reliability for
than reliability for gossip
reliability for gossip messages
considers clustering changes over
hence we favor udp
clustering changes over time
we favor udp datagrams
favor udp datagrams over
udp datagrams over tcp
or panning should cause
datagrams over tcp for
panning should cause all
over tcp for this
should cause all layers
tcp for this kind
cause all layers to
for this kind of
all layers to respond
this kind of communication
layers to respond simultaneously
the recipient compares the
and an update in
recipient compares the gossiped
an update in any
compares the efficacy of
update in any of
compares the gossiped information
the efficacy of various
in any of the
efficacy of various approaches
the gossiped information with
any of the layers
gossiped information with its
of various approaches to
information with its own
of the layers should
with its own state
various approaches to dealing
the layers should be
approaches to dealing with
layers should be reflected
to dealing with detected
should be reflected in
dealing with detected inconsistencies
be reflected in all
identifying information known to
reflected in all other
information known to the
in all other layers
known to the sender
to the sender but
the sender but unknown
sender but unknown to
but unknown to itself
allow updates to be
updates to be carried
to be carried by
or known to it
be carried by the
known to it but
carried by the protocol
to it but apparently
by the protocol best
it but apparently unknown
the protocol best matched
but apparently unknown to
protocol best matched to
apparently unknown to the
our basic synthetic workload
unknown to the sender
best matched to the
basic synthetic workload is
matched to the setting
synthetic workload is constructed
to the setting in
workload is constructed as
the setting in which
is constructed as follows
it then sends back
setting in which the
then sends back a
in which the application
sends back a gossip
which the application is
back a gossip reply
the application is used
using an unreliable datagram
the solutions discussed here
an unreliable datagram protocol
solutions discussed here are
discussed here are based
here are based on
are based on live
based on live objects
containing information the sender
information the sender might
the sender might find
sender might find useful
might find useful and
find useful and requesting
useful and requesting information
and requesting information it
requesting information it lacks
the originator of the
new types of components
originator of the exchange
types of components must
of the exchange will
of components must be
the exchange will send
the objects are divided
components must be created
objects are divided into
must be created for
are divided into clusters
be created for each
divided into clusters of
created for each type
into clusters of size
for each type of
exchange will send a
each type of content
will send a final
send a final message
a final message containing
final message containing any
message containing any data
but the existing collection
containing any data that
the existing collection of
any data that was
existing collection of components
data that was solicited
collection of components provides
that was solicited by
of components provides access
was solicited by the
components provides access to
solicited by the receiver
provides access to several
access to several different
to several different types
several different types of
different types of web
gossip messages are bounded
types of web services
messages are bounded in
of web services hosted
are bounded in size
web services hosted content
thus during a round
including all the examples
during a round each
all the examples given
a round each process
the examples given above
round each process will
each process will send
process will send a
will send a message
perhaps eliciting a reply
the resulting live application
and perhaps will respond
resulting live application is
perhaps will respond to
live application is stored
will respond to that
application is stored as
respond to that reply
is stored as an
stored as an xml
as an xml file
in the worst case
the file can be
file can be moved
can be moved about
a round results in
be moved about and
moved about and even
and there are two
about and even embedded
there are two types
and even embedded in
are two types of
even embedded in email
two types of workloads
the load imposed on
load imposed on the
imposed on the network
users that open it
on the network will
that open it find
the network will thus
open it find themselves
network will thus be
it find themselves immersed
will thus be linear
clustering is perfect and
thus be linear in
find themselves immersed into
be linear in the
themselves immersed into the
linear in the number
immersed into the application
in the number of
is perfect and each
the number of processes
perfect and each transaction
and each transaction chooses
each transaction chooses a
several transport protocols optimized
transaction chooses a single
but any individual process
chooses a single cluster
transport protocols optimized for
a single cluster and
any individual process will
single cluster and chooses
individual process will see
protocols optimized for various
process will see a
optimized for various settings
will see a constant
for various settings are
see a constant load
various settings are or
times with repetitions within
settings are or will
with repetitions within this
are or will be
repetitions within this cluster
or will be available
within this cluster to
independent of system size
this cluster to establish
will be available in
cluster to establish its
be available in a
to establish its access
available in a near
establish its access set
in a near future
the ssa gossips about
in the second type
ssa gossips about membership
the second type of
including support for wan
second type of workloads
support for wan networks
type of workloads access
for wan networks with
of workloads access is
wan networks with nats
workloads access is not
networks with nats and
access is not fully
with nats and firewalls
is not fully contained
recoveries and application state
not fully contained within
fully contained within each
contained within each cluster
using this information to
this information to initiate
information to initiate repairs
when a transaction starts
one form of repair
it chooses a cluster
form of repair involves
chooses a cluster uniformly
of repair involves disruption
a cluster uniformly at
repair involves disruption to
cluster uniformly at random
involves disruption to a
disruption to a chain
if a fault breaks
a fault breaks a
fault breaks a chain
breaks a chain or
a chain or disables
chain or disables the
or disables the head
each object is chosen
disables the head of
object is chosen using
the head of a
is chosen using a
head of a chain
chosen using a bounded
using a bounded pareto
a bounded pareto distribution
bounded pareto distribution starting
pareto distribution starting at
distribution starting at detected
starting at detected inconsistencies
gossip is used to
high throughput and very
is used to detect
throughput and very large
and very large numbers
used to detect the
very large numbers of
large numbers of nodes
to detect the problem
detect the problem and
the problem and repair
problem and repair involves
and repair involves designating
repair involves designating a
involves designating a new
update clients access the
designating a new head
clients access the database
a new head for
access the database at
new head for the
the database at a
head for the chain
database at a rate
for the chain or
at a rate of
the chain or establishing
chain or establishing a
or establishing a new
establishing a new tcp
a new tcp connection
new tcp connection bridging
tcp connection bridging the
connection bridging the gap
large numbers of irregularly
numbers of irregularly overlapping
a second form of
of irregularly overlapping multicast
second form of repair
irregularly overlapping multicast groups
form of repair involves
of repair involves lost
repair involves lost updates
only clients access the
clients access the cache
if subservice a has
access the cache at
subservice a has a
the cache at a
a has a member
cache at a rate
has a member m
at a rate of
a member m that
member m that knows
we assume that all
assume that all forms
that all forms of
all forms of information
forms of information are
and strong reliability properties
of information are uniquely
information are uniquely named
are uniquely named and
uniquely named and that
named and that updates
and that updates are
that updates are ordered
updates are ordered separately
are ordered separately by
ordered separately by each
separately by each update
by each update source
of update x and
update x and a
x and a member
and a member m
a member m that
member m that lacks
m that lacks x
gossip can be used
can be used to
be used to detect
used to detect this
to detect this and
detect this and m
this and m can
and m can then
m can then send
can then send x
then send x to
send x to m
x to m directly
before saying more about
saying more about our
more about our approach
without waiting for the
waiting for the chain
for the chain to
the chain to be
chain to be repaired
we analyze a concrete
analyze a concrete example
a concrete example of
concrete example of a
example of a soc
of a soc application
a soc application more
gossip is not a
soc application more carefully
is not a particularly
application more carefully to
not a particularly fast
more carefully to expose
a particularly fast protocol
carefully to expose the
to expose the full
expose the full range
the full range of
full range of needs
range of needs and
of needs and issues
needs and issues that
and issues that arise
consider a rescue mission
a rescue mission coordinator
rounds of the protocol
of the protocol to
the protocol to reach
protocol to reach n
a police or fire
to reach n processes
police or fire chief
or fire chief coordinating
fire chief coordinating teams
on the other hand
chief coordinating teams who
coordinating teams who will
teams who will enter
who will enter a
if rounds occur frequently
will enter a disaster
enter a disaster zone
a disaster zone in
disaster zone in the
zone in the wake
the delay before information
in the wake of
delay before information spreads
the wake of a
before information spreads to
wake of a catastrophe
information spreads to all
of a catastrophe to
spreads to all members
a catastrophe to help
to all members of
catastrophe to help survivors
all members of a
members of a system
of a system may
a system may still
system may still be
may still be small
even in a large
in a large system
gossip is astonishingly robust
there are exponentially many
are exponentially many paths
exponentially many paths by
many paths by which
paths by which information
by which information can
which information can pass
and move supplies as
information can pass from
move supplies as needed
can pass from point
pass from point a
from point a to
point a to point
a to point b
ratio of inconsistencies as
of inconsistencies as a
hence almost any imaginable
inconsistencies as a function
almost any imaginable disruption
as a function of
any imaginable disruption short
imaginable disruption short of
disruption short of a
short of a lasting
would arrive on the
the head of its
arrive on the scene
of a lasting partitioning
head of its cluster
a lasting partitioning failure
of its cluster i
lasting partitioning failure can
partitioning failure can be
build a new collaboration
failure can be overcome
a new collaboration tool
and distribute it to
the gossip protocols implemented
distribute it to his
gossip protocols implemented in
protocols implemented in the
implemented in the ssa
in the ssa have
the ssa have been
ssa have been designed
if the pareto variable
have been designed specifically
the pareto variable plus
each team member would
been designed specifically for
team member would carry
pareto variable plus the
member would carry a
designed specifically for use
would carry a tablet
variable plus the offset
specifically for use in
plus the offset results
for use in our
the offset results in
use in our modified
offset results in a
style device with wireless
results in a number
in our modified version
in a number outside
device with wireless communication
a number outside the
our modified version of
number outside the range
with wireless communication capabilities
modified version of chain
version of chain replication
the application built by
and with the goal
application built by the
with the goal of
built by the coordinator
the goal of running
by the coordinator would
goal of running in
the coordinator would be
of running in large
coordinator would be installed
running in large clusters
would be installed on
in large clusters or
be installed on each
large clusters or datacenters
installed on each team
on each team member
each team member s
team member s mobile
member s mobile device
let be a group
be a group of
a group of processes
and in the offices
in the offices in
the offices in mission
and let p be
offices in mission headquarters
let p be a
p be a process
be a process in
a process in that
process in that group
in that group p
the coordinator would then
coordinator would then deploy
would then deploy teams
then deploy teams in
the count wraps back
deploy teams in the
count wraps back to
teams in the field
each process has its
process has its own
has its own view
our rescue workers now
its own view of
rescue workers now use
own view of the
workers now use the
view of the group
now use the solution
use the solution to
the solution to coordinate
solution to coordinate and
to coordinate and prioritize
coordinate and prioritize actions
inform each other of
inconsistency detection as a
each other of the
detection as a function
other of the evolving
as a function of
of the evolving situation
steer clear of hazards
we start by exploring
these views can lag
start by exploring the
views can lag reality
by exploring the importance
exploring the importance of
the importance of the
importance of the cluster
for example if a
as new events occur
example if a process
if a process joins
of the cluster structure
a process joins or
the cluster structure by
process joins or leaves
cluster structure by varying
the situational status would
structure by varying the
situational status would evolve
by varying the parameter
varying the parameter of
the parameter of the
parameter of the pareto
of the pareto distribution
and the team member
and different members might
the team member who
different members might not
team member who causes
members might not have
we vary the pareto
might not have consistent
member who causes or
not have consistent views
vary the pareto parameter
who causes or observes
the pareto parameter from
causes or observes these
or observes these status
our work assumes that
observes these status changes
work assumes that the
these status changes would
assumes that the network
status changes would need
that the network within
changes would need to
the network within a
would need to report
network within a cluster
need to report them
within a cluster does
to report them to
a cluster does not
report them to the
cluster does not partition
them to the others
although there are low
removing debris blocking access
probability failure patterns that
in this experiment we
debris blocking access to
failure patterns that could
this experiment we are
blocking access to a
experiment we are only
patterns that could temporarily
we are only interested
access to a building
are only interested in
that could temporarily partition
only interested in detection
to a building may
could temporarily partition some
a building may enable
temporarily partition some subservice
building may enable the
partition some subservice in
may enable the team
some subservice in a
so we choose the
subservice in a logical
we choose the abort
in a logical sense
choose the abort strategy
enable the team to
the team to check
team to check it
to check it for
check it for victims
shows the ratio of
and fire that breaks
the ratio of inconsistencies
fire that breaks out
ratio of inconsistencies detected
that breaks out in
of inconsistencies detected by
breaks out in a
inconsistencies detected by t
out in a chemical
in a chemical storage
process p chooses a
a chemical storage warehouse
p chooses a random
chemical storage warehouse may
chooses a random subset
storage warehouse may force
a random subset of
warehouse may force diversion
cache compared to the
may force diversion of
random subset of a
force diversion of resources
subset of a particular
compared to the total
of a particular size
to the total number
a particular size view
the total number of
total number of potential
as rescue workers capture
number of potential inconsistencies
rescue workers capture information
their mobile devices send
mobile devices send updates
devices send updates that
send updates that must
updates that must be
and commences a dialog
that must be propagated
commences a dialog with
must be propagated in
a dialog with each
be propagated in real
dialog with each process
with each process in
each process in the
process in the set
the initial message is
having defined the scenario
initial message is a
message is a compact
is a compact state
a compact state digest
the distribution is almost
compact state digest summarizing
distribution is almost uniform
now let s analyze
is almost uniform across
state digest summarizing the
almost uniform across the
let s analyze in
uniform across the object
digest summarizing the state
across the object set
s analyze in more
summarizing the state of
analyze in more detail
the state of the
in more detail the
state of the sender
more detail the requirements
and the inconsistency detection
detail the requirements it
the inconsistency detection ratio
the requirements it places
inconsistency detection ratio is
requirements it places on
the follow up dialog
it places on our
detection ratio is low
places on our collaboration
follow up dialog consists
on our collaboration tool
ratio is low the
up dialog consists of
is low the dependency
dialog consists of an
consists of an explicit
low the dependency lists
of an explicit request
an explicit request of
the dependency lists are
explicit request of missing
dependency lists are too
request of missing update
lists are too small
of missing update operations
are too small to
too small to hold
small to hold all
the collaboration tool pulls
to hold all relevant
collaboration tool pulls data
hold all relevant information
tool pulls data from
several details of the
pulls data from many
details of the epidemic
data from many kinds
of the epidemic protocols
at the other extreme
from many kinds of
the epidemic protocols employed
many kinds of sources
epidemic protocols employed in
protocols employed in the
employed in the framework
in the framework turned
it makes far more
the framework turned out
makes far more sense
framework turned out to
far more sense to
turned out to be
more sense to imagine
out to be important
sense to imagine that
to be important determinants
to imagine that weather
be important determinants of
imagine that weather information
important determinants of system
determinants of system performance
the distribution is so
of system performance and
distribution is so spiked
system performance and behavior
is so spiked that
so spiked that almost
spiked that almost all
that almost all accesses
almost all accesses of
suppose that a process
all accesses of a
that a process disseminates
accesses of a transaction
a process disseminates information
of a transaction are
process disseminates information via
a transaction are within
disseminates information via epidemics
transaction are within a
information via epidemics about
are within a cluster
via epidemics about a
epidemics about a subject
about a subject s
allowing for perfect inconsistency
for perfect inconsistency detection
messages and alerts come
process p gossips about
and alerts come from
p gossips about subject
alerts come from a
gossips about subject s
we note that the
about subject s a
come from a dozen
note that the rate
subject s a finite
from a dozen providers
s a finite number
that the rate of
a dozen providers than
a finite number of
the rate of detected
finite number of times
dozen providers than to
rate of detected inconsistencies
providers than to assume
of detected inconsistencies is
than to assume that
detected inconsistencies is so
to assume that one
as long as subject
inconsistencies is so high
assume that one organization
long as subject s
is so high at
as subject s is
that one organization would
subject s is hot
so high at this
one organization would be
high at this point
organization would be hosting
at this point that
would be hosting services
this point that much
after which subject s
be hosting services with
which subject s is
point that much of
subject s is no
hosting services with everything
s is no longer
that much of the
is no longer gossiped
services with everything we
no longer gossiped about
much of the load
with everything we need
of the load goes
everything we need in
the load goes to
we need in one
load goes to the
explicit requests for copies
goes to the backend
need in one place
to the backend database
requests for copies of
the backend database and
for copies of missed
backend database and saturates
copies of missed messages
database and saturates it
of missed messages are
missed messages are limited
data from distinct sources
messages are limited in
from distinct sources could
are limited in size
distinct sources could have
sources could have different
could have different format
reducing the overall throughput
have different format and
to prevent a process
different format and one
prevent a process that
format and one will
a process that lagged
and one will often
process that lagged behind
one will often need
that lagged behind or
will often need to
lagged behind or just
often need to interface
behind or just joined
need to interface to
or just joined from
to interface to each
just joined from trying
interface to each using
joined from trying to
to each using its
from trying to catch
each using its own
trying to catch up
using its own protocols
to catch up all
its own protocols and
catch up all at
own protocols and interfaces
up all at once
so far we have
far we have considered
we have considered behavior
have considered behavior with
considered behavior with static
which would result in
behavior with static clusters
would result in enormous
result in enormous messages
in enormous messages and
enormous messages and serious
as conditions evolve the
messages and serious fluctuations
conditions evolve the team
and serious fluctuations in
evolve the team might
serious fluctuations in system
the team might need
fluctuations in system load
team might need to
might need to be
need to be modify
to be modify the
over the entire run
be modify the application
the entire run of
entire run of each
run of each experiment
of each experiment accesses
each experiment accesses are
for example adding new
experiment accesses are confined
example adding new types
accesses are confined to
such a process may
are confined to the
adding new types of
confined to the same
a process may need
new types of information
process may need to
may need to catch
need to catch up
to catch up over
catch up over many
changing the way it
up over many seconds
the way it is
way it is represented
explicit message requests are
or even modifying the
message requests are honored
even modifying the way
requests are honored if
modifying the way team
in a real system
the way team members
are honored if the
way team members communicate
honored if the requested
if the requested messages
the requested messages are
requested messages are still
messages are still in
are still in the
still in the bounded
and so if t
in the bounded buffers
cache converges to maintain
back network links fail
once a message has
converges to maintain the
a message has been
to maintain the correct
message has been delivered
maintain the correct dependency
has been delivered to
the correct dependency lists
been delivered to the
correct dependency lists as
delivered to the upper
dependency lists as clusters
to the upper levels
lists as clusters change
whereas a minibrowser would
a minibrowser would typically
minibrowser would typically be
would typically be prebuilt
and it has been
typically be prebuilt with
it has been expunged
be prebuilt with all
our setup serves as
prebuilt with all the
setup serves as a
with all the available
serves as a valid
has been expunged from
as a valid quasi
all the available features
been expunged from the
the available features in
expunged from the buffers
available features in place
from the buffers located
the buffers located at
buffers located at the
located at the gossiper
at the gossiper level
our scenario demands a
scenario demands a much
demands a much more
a much more flexible
requests are simply ignored
much more flexible kind
more flexible kind of
flexible kind of tool
we investigate the convergence
kind of tool that
investigate the convergence of
of tool that can
the convergence of t
the requesting process would
tool that can be
requesting process would have
that can be redesigned
process would have to
can be redesigned while
cache when clusters change
would have to try
be redesigned while in
when clusters change over
have to try to
clusters change over time
redesigned while in use
to try to find
try to find the
to find the missing
find the missing data
the missing data elsewhere
since the dependency lists
the dependency lists of
dependency lists of the
lists of the objects
of the objects are
depending on the location
the objects are updated
on the location and
objects are updated using
the location and other
are updated using lru
location and other factors
if data cannot be
data cannot be recovered
the dependency list of
the best networking protocols
we signal this to
best networking protocols and
dependency list of an
networking protocols and connectivity
signal this to the
protocols and connectivity options
list of an object
and connectivity options may
this to the application
connectivity options may vary
of an object o
to the application by
an object o tends
the application by delivering
application by delivering an
object o tends to
by delivering an exception
o tends to include
delivering an exception upcall
in our rescue scenario
tends to include those
to include those objects
include those objects that
those objects that are
objects that are frequently
the workers may have
that are frequently accessed
workers may have to
are frequently accessed together
and leave it to
may have to use
leave it to the
have to use wireless
frequently accessed together with
to use wireless p
it to the application
accessed together with o
to the application to
the application to decide
application to decide how
to decide how to
p protocols much of
decide how to handle
protocols much of the
dependencies in a new
much of the time
how to handle the
in a new cluster
to handle the problem
a new cluster automatically
new cluster automatically push
cluster automatically push out
reaching back to hosted
automatically push out dependencies
back to hosted services
push out dependencies that
the size of the
out dependencies that are
size of the buffers
to hosted services only
of the buffers is
dependencies that are now
the buffers is configurable
hosted services only intermittently
that are now outside
services only intermittently when
are now outside the
only intermittently when a
now outside the cluster
intermittently when a drone
but this rule implies
when a drone aircraft
this rule implies that
a drone aircraft passes
rule implies that certain
drone aircraft passes within
implies that certain kinds
aircraft passes within radio
that certain kinds of
passes within radio range
certain kinds of failures
kinds of failures may
of failures may be
failures may be unrecoverable
may be unrecoverable within
be unrecoverable within the
we perform an experiment
unrecoverable within the ssa
perform an experiment where
an experiment where accesses
the right choice of
experiment where accesses suddenly
right choice of protocol
where accesses suddenly become
choice of protocol should
accesses suddenly become clustered
digests are bounded in
of protocol should reflect
are bounded in the
protocol should reflect the
bounded in the number
should reflect the operating
in the number of
reflect the operating conditions
initially accesses are uniformly
the number of messages
accesses are uniformly at
number of messages they
are uniformly at random
of messages they advertise
uniformly at random from
messages they advertise about
and if these change
they advertise about in
at random from the
advertise about in one
random from the entire
about in one single
from the entire set
in one single datagram
one single datagram packet
the platform should be
platform should be capable
should be capable of
be capable of swapping
capable of swapping in
and each round only
of swapping in a
each round only a
swapping in a different
round only a single
in a different protocol
only a single digest
a different protocol without
a single digest is
different protocol without disrupting
single digest is disseminated
protocol without disrupting the
without disrupting the end
disrupting the end user
even if the subset
if the subset view
the subset view selected
this argues for a
argues for a decoupling
for a decoupling of
then at a single
a decoupling of functionality
at a single moment
a single moment they
single moment they become
moment they become perfectly
has cardinality greater than
whereas a minibrowser packages
cardinality greater than one
they become perfectly clustered
a minibrowser packages it
become perfectly clustered into
minibrowser packages it all
perfectly clustered into clusters
packages it all into
clustered into clusters of
it all into one
into clusters of size
all into one object
messages that are potentially
that are potentially in
are potentially in transit
potentially in transit are
in transit are not
better is a design
transit are not retransmitted
are not retransmitted to
is a design in
not retransmitted to requesting
transactions are aborted on
retransmitted to requesting processes
a design in which
are aborted on detecting
design in which the
aborted on detecting an
in which the presentation
on detecting an inconsistency
which the presentation object
for example if a
the presentation object is
example if a process
presentation object is distinct
we use a transaction
object is distinct from
if a process p
use a transaction rate
is distinct from objects
a process p makes
a transaction rate of
distinct from objects representing
transaction rate of approximately
process p makes an
from objects representing information
p makes an explicit
objects representing information sources
representing information sources and
makes an explicit request
information sources and objects
sources and objects representing
an explicit request for
and objects representing transport
explicit request for a
objects representing transport protocols
request for a message
for a message m
a message m and
decoupling makes it possible
message m and the
makes it possible to
m and the request
it possible to dynamically
and the request lands
possible to dynamically modify
the request lands at
to dynamically modify or
request lands at process
dynamically modify or even
lands at process q
modify or even replace
at process q that
or even replace a
process q that has
even replace a component
q that has already
replace a component with
that has already sent
a component with some
has already sent p
component with some other
already sent p a
sent p a copy
p a copy of
a copy of m
shows the percentage of
copy of m in
the percentage of transactions
of m in the
percentage of transactions that
m in the recent
of transactions that commit
in the recent past
option when changing conditions
the recent past then
transactions that commit and
recent past then m
that commit and are
past then m will
commit and are consistent
then m will not
when changing conditions require
m will not be
changing conditions require it
will not be retransmitted
we have posed what
have posed what may
a process creates a
posed what may sound
process creates a digest
what may sound like
creates a digest based
may sound like a
the percentage of transactions
sound like a very
a digest based upon
like a very specialized
percentage of transactions that
a very specialized problem
digest based upon all
of transactions that commit
based upon all the
transactions that commit but
upon all the messages
that commit but are
all the messages received
commit but are inconsistent
but in fact we
the messages received by
in fact we see
messages received by means
fact we see this
received by means of
we see this as
by means of any
see this as a
means of any communication
this as a good
of any communication channels
as a good example
a good example of
good example of a
and the percentage of
example of a more
the percentage of transactions
not just the epidemics
percentage of transactions that
of a more general
of transactions that abort
a more general kind
more general kind of
general kind of need
kind of need that
of need that could
need that could arise
that could arise in
could arise in many
arise in many kinds
in many kinds of
many kinds of settings
the messages received by
messages received by fifo
received by fifo chained
by fifo chained channels
consider a physician treating
a physician treating a
physician treating a patient
treating a patient with
a patient with a
patient with a complex
the message buffers are
with a complex condition
message buffers are bounded
who needs collaboration help
and once a message
needs collaboration help from
once a message has
collaboration help from specialists
a message has been
message has been delivered
has been delivered by
been delivered by means
and who might even
delivered by means of
who might even be
by means of an
might even be working
means of an upcall
even be working in
of an upcall it
be working in a
an upcall it is
working in a remote
upcall it is prone
in a remote location
it is prone to
a remote location under
is prone to be
remote location under conditions
prone to be replaced
location under conditions demanding
to be replaced by
under conditions demanding urgent
be replaced by the
conditions demanding urgent action
replaced by the replacement
by the replacement policy
the mixture of patient
mixture of patient data
the ssa implements several
ssa implements several replacement
implements several replacement policies
most advertised message in
advertised message in digests
may be just as
be just as rich
just as rich and
as rich and dynamic
rich and dynamic as
and dynamic as in
although the ssa should
dynamic as in our
the ssa should work
as in our search
ssa should work well
in our search and
should work well on
our search and rescue
work well on clusters
search and rescue scenario
well on clusters with
on clusters with as
clusters with as many
with as many as
as many as thousands
many as thousands of
and the underlying communication
as thousands of nodes
the underlying communication options
underlying communication options equally
communication options equally heterogeneous
options equally heterogeneous and
equally heterogeneous and unpredictable
companies like google and
abort evict retry behavior
like google and amazon
evict retry behavior on
google and amazon reportedly
retry behavior on inconsistency
and amazon reportedly operate
behavior on inconsistency detection
amazon reportedly operate centers
reportedly operate centers with
operate centers with tens
designed for a wired
centers with tens of
for a wired environment
with tens of thousands
a wired environment might
tens of thousands of
wired environment might perform
of thousands of machines
environment might perform poorly
thousands of machines in
might perform poorly or
of machines in them
perform poorly or fail
poorly or fail under
or fail under such
fail under such conditions
and are said to
are said to deploy
said to deploy some
to deploy some popular
deploy some popular services
some popular services on
popular services on huge
if there is a
services on huge numbers
there is a way
on huge numbers of
is a way to
huge numbers of nodes
a way to solve
way to solve the
to solve the problem
were we to use
we to use the
to use the ssa
there is a way
use the ssa in
is a way to
the ssa in such
a way to build
ssa in such settings
way to build the
to build the desired
build the desired mashup
our gossip protocol might
gossip protocol might need
throughout the above we
protocol might need to
the above we noted
might need to be
above we noted requirements
need to be revisited
to be revisited to
be revisited to ensure
revisited to ensure that
to ensure that messages
ensure that messages do
that messages do not
messages do not become
we now summarize them
do not become excessively
now summarize them below
not become excessively large
one way to accomplish
way to accomplish this
these needs are seen
to accomplish this might
needs are seen in
accomplish this might be
are seen in many
this might be to
seen in many settings
might be to modify
be to modify the
to modify the epidemic
modify the epidemic protocol
the epidemic protocol using
epidemic protocol using spatial
protocol using spatial distributions
using spatial distributions to
we believe them to
spatial distributions to improve
believe them to be
distributions to improve the
them to be typical
to improve the performance
to be typical of
be typical of most
typical of most soc
of most soc applications
we would like to
would like to enable
like to enable a
to enable a non
programmer to rapidly develop
such an approach would
to rapidly develop a
an approach would let
rapidly develop a new
approach would let us
develop a new collaborative
would let us restrict
a new collaborative application
let us restrict information
new collaborative application by
us restrict information to
collaborative application by composing
restrict information to the
application by composing together
information to the vicinity
by composing together and
to the vicinity of
composing together and customizing
the vicinity of the
together and customizing preexisting
vicinity of the nodes
and customizing preexisting components
s accesses are uniformly
of the nodes where
accesses are uniformly at
the nodes where it
are uniformly at random
nodes where it might
where it might be
it might be needed
we would like to
would like to be
like to be able
to be able to
in effect adding an
be able to overlay
effect adding an additional
able to overlay data
adding an additional layer
to overlay data from
an additional layer of
overlay data from multiple
additional layer of hierarchy
data from multiple sources
layer of hierarchy to
of hierarchy to the
hierarchy to the architecture
potentially in different formats
we believe the required
believe the required changes
the efficacy of t
the required changes would
obtained using different protocols
required changes would be
using different protocols and
changes would be relatively
different protocols and inconsistent
protocols and inconsistent interfaces
cache as a function
would be relatively minor
as a function of
a function of the
function of the strategy
of the strategy taken
we would like to
the strategy taken for
would like to be
strategy taken for handling
like to be able
taken for handling detected
to be able to
for handling detected inconsistencies
be able to dynamically
able to dynamically customize
to dynamically customize the
dynamically customize the application
customize the application at
the application at runtime
epidemic analytical model one
of the uncommitable tranasctions
analytical model one benefit
model one benefit of
one benefit of using
benefit of using gossip
and evict and retry
by incorporating new data
evict and retry reduce
incorporating new data sources
and retry reduce the
new data sources or
of using gossip in
retry reduce the rate
using gossip in the
data sources or changing
reduce the rate of
sources or changing the
gossip in the ssa
or changing the way
the rate of uncommitable
changing the way data
in the ssa is
the way data is
rate of uncommitable transactions
way data is presented
the ssa is that
of uncommitable transactions to
ssa is that we
uncommitable transactions to about
is that we can
that we can use
we can use analytical
can use analytical methods
use analytical methods to
analytical methods to predict
and without disrupting system
methods to predict the
without disrupting system operation
to predict the behavior
predict the behavior of
the behavior of a
behavior of a cluster
we would like to
would like to be
like to be able
to be able to
complementing our experimental work
be able to accommodate
able to accommodate new
to accommodate new types
accommodate new types of
the middle portion is
new types of data
middle portion is committed
a basic result of
portion is committed transactions
types of data sources
is committed transactions that
basic result of epidemic
committed transactions that are
result of epidemic theory
transactions that are inconsistent
of epidemic theory states
epidemic theory states that
new formats or protocols
theory states that simple
formats or protocols that
states that simple epidemics
and the top portion
that simple epidemics eventually
or protocols that we
the top portion is
simple epidemics eventually infect
top portion is aborted
protocols that we may
portion is aborted transactions
epidemics eventually infect the
that we may not
eventually infect the entire
we may not have
infect the entire population
may not have anticipated
the entire population with
not have anticipated at
entire population with probability
have anticipated at the
anticipated at the time
at the time the
the time the system
time the system was
the system was released
moreover starting with a
data might be published
starting with a single
might be published by
with a single infected
be published by the
a single infected site
published by the individual
single infected site this
by the individual users
infected site this is
site this is achieved
this is achieved in
is achieved in expected
and it might be
achieved in expected time
it might be necessary
in expected time proportional
might be necessary for
expected time proportional to
be necessary for the
time proportional to the
necessary for the users
proportional to the log
for the users to
to the log of
the users to exchange
the log of the
users to exchange their
log of the population
to exchange their data
of the population size
exchange their data without
their data without access
data without access to
without access to a
access to a centralized
to a centralized repository
data may be obtained
may be obtained using
be obtained using different
obtained using different types
the protocol roughly falls
using different types of
protocol roughly falls under
different types of network
roughly falls under the
types of network protocols
falls under the category
under the category of
the category of a
category of a push
and the type of
the type of the
type of the physical
of the physical network
the physical network or
physical network or protocols
network or protocols may
and the exact formula
or protocols may not
the exact formula for
protocols may not be
exact formula for it
may not be known
formula for it can
not be known in
for it can be
be known in advance
it can be expressed
can be expressed as
be expressed as log
it should be possible
should be possible to
be possible to rapidly
possible to rapidly compose
to rapidly compose the
rapidly compose the application
compose the application using
the application using whatever
application using whatever communication
using whatever communication infrastructure
whatever communication infrastructure is
communication infrastructure is currently
infrastructure is currently available
users may be mobile
may be mobile or
be mobile or temporarily
mobile or temporarily disconnected
and the topology of
the topology of the
topology of the network
of the network and
for large values of
the network and its
large values of n
network and its characteristics
and its characteristics might
its characteristics might change
characteristics might change over
might change over time
where n the number
n the number of
the number of sites
number of sites participating
of sites participating in
the system should be
sites participating in the
system should be easily
participating in the epidemic
should be easily reconfigurable
in the epidemic spread
the requirements outlined above
let pi be the
requirements outlined above might
pi be the probability
outlined above might seem
be the probability that
above might seem hard
the probability that a
might seem hard to
probability that a site
seem hard to satisfy
that a site remains
a site remains susceptible
not touched by the
touched by the epidemic
the solution is surprisingly
solution is surprisingly simple
after the ith round
the ith round of
ith round of the
our analysis motivates a
round of the protocol
analysis motivates a component
a site remains susceptible
site remains susceptible after
remains susceptible after the
susceptible after the i
in which the web
which the web services
the web services and
web services and hosted
services and hosted content
and hosted content are
th round if it
hosted content are modeled
round if it was
content are modeled as
if it was susceptible
are modeled as reusable
it was susceptible after
modeled as reusable overlayed
was susceptible after the
as reusable overlayed information
susceptible after the ith
reusable overlayed information layers
after the ith cycle
overlayed information layers backed
the ith cycle and
information layers backed by
ith cycle and it
layers backed by customizable
cycle and it is
backed by customizable transport
and it is not
by customizable transport layers
it is not contacted
is not contacted by
not contacted by any
contacted by any infectious
by any infectious site
a graph of components
any infectious site in
infectious site in the
site in the i
a collaborative application is
collaborative application is a
application is a forest
a set of such
set of such graphs
our vision demands a
vision demands a new
demands a new kind
a new kind of
new kind of soc
kind of soc standard
relation that we obtain
in order to facilitate
that we obtain is
order to facilitate the
perfectly clustered synthetic workload
to facilitate the side
clustered synthetic workload where
synthetic workload where the
workload where the clusters
where the clusters shift
the clusters shift by
side coexistence of components
coexistence of components that
of components that might
components that might today
that might today be
might today be implemented
marked by vertical lines
today be implemented as
be implemented as proprietary
implemented as proprietary minibrowsers
if we enable components
since infection starts with
we enable components to
infection starts with one
enable components to talk
starts with one site
components to talk to
to talk to oneanother
for any randomly chosen
s access is unclustered
any randomly chosen site
we need to agree
randomly chosen site p
need to agree on
to agree on the
agree on the events
and as a result
on the events and
as a result the
the events and representation
a result the dependency
events and representation that
result the dependency lists
and representation that the
the dependency lists are
representation that the dialog
dependency lists are useless
that the dialog will
the dialog will employ
only few inconsistencies are
few inconsistencies are detected
the decoupling of functionality
decoupling of functionality into
of functionality into layers
functionality into layers also
into layers also suggests
layers also suggests a
also suggests a need
as a function of
suggests a need for
a function of the
a need for a
function of the rate
need for a standardized
of the rate of
for a standardized layering
the rate of gossip
in the examples above
we can predict the
of the transactions that
can predict the delay
the transactions that commit
one can identify at
predict the delay before
can identify at least
transactions that commit have
the delay before a
that commit have witnessed
identify at least four
delay before a typical
commit have witnessed inconsistent
before a typical process
have witnessed inconsistent data
a typical process that
typical process that has
process that has been
that has been disrupted
the linkage layer that
has been disrupted by
linkage layer that talks
been disrupted by a
layer that talks to
disrupted by a failure
that talks to the
by a failure will
talks to the underlying
a failure will learn
to the underlying data
failure will learn about
the underlying data source
will learn about inconsistency
learn about inconsistency introduced
about inconsistency introduced by
inconsistency introduced by the
the update generating and
accesses become perfectly clustered
update generating and interpreting
introduced by the failure
generating and interpreting layer
by the failure and
the failure and can
failure and can initiate
and can initiate repair
and the transport protocol
we see fast improvement
see fast improvement of
fast improvement of inconsistency
improvement of inconsistency detection
if the model predicts
we propose that this
the model predicts that
propose that this decoupling
model predicts that for
that this decoupling be
predicts that for a
the inconsistency rate drops
that for a given
this decoupling be done
for a given gossip
inconsistency rate drops as
decoupling be done using
a given gossip rate
rate drops as the
be done using event
drops as the abort
as the abort rate
a broken chain should
the abort rate rises
broken chain should be
abort rate rises this
chain should be repaired
rate rises this is
should be repaired within
rises this is desired
a natural way of
this is desired as
natural way of thinking
is desired as well
way of thinking about
of thinking about components
thinking about components that
about components that dates
components that dates back
that dates back to
the overall rate of
dates back to smalltalk
overall rate of consistent
rate of consistent committed
of consistent committed transactions
consistent committed transactions drops
committed transactions drops because
one can anticipate that
transactions drops because the
rather than having the
can anticipate that the
than having the data
drops because the probability
anticipate that the disruption
having the data center
because the probability of
that the disruption associated
the data center developer
the probability of conflicts
the disruption associated with
data center developer offer
probability of conflicts in
disruption associated with a
center developer offer content
of conflicts in the
associated with a failure
conflicts in the clustered
developer offer content through
with a failure should
in the clustered scenario
offer content through proprietary
the clustered scenario is
a failure should be
clustered scenario is higher
content through proprietary minibrowser
failure should be limited
through proprietary minibrowser interface
should be limited to
be limited to the
limited to the maximum
to the maximum number
the maximum number of
maximum number of updates
to illustrate more realistic
number of updates that
she would define an
illustrate more realistic behavior
would define an event
of updates that would
updates that would be
that would be sent
would be sent to
we use clustered accesses
based interface between transport
be sent to a
interface between transport and
sent to a given
between transport and information
to a given subservice
transport and information layers
a given subservice during
use clustered accesses that
given subservice during a
clustered accesses that slowly
accesses that slowly drift
the visual events delivered
visual events delivered by
transactions are perfectly clustered
events delivered by the
delivered by the transport
by the transport could
the transport could then
as in the previous
transport could then be
in the previous experiment
could then be delivered
then be delivered to
be delivered to an
delivered to an information
to an information layer
an information layer responsible
information layer responsible for
layer responsible for visualizing
minutes the cluster structure
if we know how
the cluster structure shifts
we know how large
cluster structure shifts by
know how large the
responsible for visualizing them
how large the typical
large the typical update
the typical update is
and we know the
we know the size
know the size limit
the size limit on
size limit on data
limit on data sent
user mouse and keyboard
on data sent in
mouse and keyboard events
data sent in response
and keyboard events and
sent in response to
keyboard events and pass
in response to explicit
events and pass them
response to explicit requests
and pass them down
we can predict the
can predict the amount
predict the amount of
the amount of time
with this type of
amount of time that
this type of event
of time that will
time that will be
that will be needed
will be needed to
be needed to repair
needed to repair the
to repair the resulting
repair the resulting data
the resulting data inconsistency
either layer could easily
layer could easily be
could easily be replaced
easily be replaced with
be replaced with a
replaced with a different
these capabilities should help
with a different one
capabilities should help the
should help the developer
help the developer parameterize
the developer parameterize the
developer parameterize the cluster
parameterize the cluster to
the cluster to balance
cluster to balance overhead
to balance overhead for
balance overhead for gossip
overhead for gossip against
for gossip against repair
gossip against repair times
peer protocols would also
against repair times desired
protocols would also be
repair times desired by
would also be encapsulated
times desired by the
also be encapsulated within
desired by the application
be encapsulated within their
encapsulated within their respective
within their respective transport
their respective transport layers
membership some readers may
some readers may be
readers may be curious
may be curious about
be curious about what
curious about what will
about what will seem
what will seem to
one version of a
will seem to be
version of a transport
seem to be a
and wrapping back to
of a transport layer
wrapping back to zero
to be a chicken
a transport layer could
back to zero after
transport layer could fetch
layer could fetch data
could fetch data directly
fetch data directly from
data directly from a
directly from a server
from a server in
a server in a
server in a data
in a data center
on the one hand
we use gossip epidemics
whereas a different version
use gossip epidemics to
a different version might
gossip epidemics to propagate
different version might use
epidemics to propagate information
version might use a
to propagate information about
might use a peer
propagate information about membership
information about membership changes
yet the gossip protocol
the gossip protocol uses
gossip protocol uses membership
protocol uses membership information
uses membership information to
membership information to select
a reliable multicast protocol
information to select gossip
the objects dependency lists
to select gossip peers
objects dependency lists are
dependency lists are outdated
it could leverage different
could leverage different type
leverage different type of
this leads to a
different type of hardware
leads to a sudden
type of hardware or
to a sudden increased
of hardware or be
our solution starts with
hardware or be optimized
a sudden increased inconsistency
or be optimized for
solution starts with approximate
be optimized for different
starts with approximate membership
optimized for different types
sudden increased inconsistency rate
with approximate membership information
increased inconsistency rate that
for different types of
inconsistency rate that converges
different types of workloads
rate that converges back
that converges back to
converges back to zero
extracted from a group
from a group management
provided that the different
a group management service
that the different versions
until this convergence is
the different versions of
group management service component
this convergence is interrupted
different versions of the
management service component that
versions of the transport
convergence is interrupted by
service component that list
is interrupted by the
of the transport layer
interrupted by the next
component that list the
the transport layer conform
by the next shift
transport layer conform to
that list the nodes
layer conform to the
list the nodes in
conform to the same
the nodes in the
to the same standardized
nodes in the cluster
the same standardized event
in the cluster and
the cluster and the
cluster and the rough
and the rough mapping
the rough mapping of
rough mapping of services
mapping of services to
of services to those
services to those nodes
the application could then
application could then switch
could then switch between
then switch between them
switch between them as
and then refines this
between them as conditions
then refines this with
them as conditions demand
refines this with incremental
this with incremental updates
b presented three possible
presented three possible strategies
three possible strategies for
possible strategies for the
strategies for the cache
a different concern relates
for the cache to
different concern relates to
the cache to deal
concern relates to behavior
cache to deal with
relates to behavior when
to deal with inconsistency
to behavior when membership
deal with inconsistency detection
behavior when membership information
when membership information is
membership information is perceived
users interact through live
information is perceived differently
interact through live objects
is perceived differently at
through live objects that
perceived differently at different
differently at different nodes
live objects that transform
objects that transform actions
that transform actions into
transform actions into updates
although such a condition
actions into updates that
such a condition may
into updates that are
a condition may arise
updates that are communicated
condition may arise during
that are communicated in
may arise during transitional
are communicated in the
arise during transitional periods
communicated in the form
in the form of
the form of events
form of events that
of events that are
these quickly resolve as
events that are shared
quickly resolve as additional
that are shared via
resolve as additional rounds
are shared via the
as additional rounds of
shared via the transport
additional rounds of gossip
via the transport layer
rounds of gossip replace
of gossip replace stale
gossip replace stale data
replace stale data with
aborting and evicting value
the protocol implemented by
stale data with more
protocol implemented by the
data with more accurate
implemented by the transport
by the transport layer
the transport layer might
transport layer might replicate
layer might replicate the
might replicate the event
deliver it to the
it to the tablets
to the tablets of
we have never observed
the tablets of our
have never observed a
tablets of our rescue
never observed a membership
of our rescue workers
observed a membership inconsistency
a membership inconsistency that
membership inconsistency that persisted
inconsistency that persisted for
and report it through
that persisted for longer
report it through the
persisted for longer than
it through the event
for longer than a
through when possible as
longer than a few
when possible as in
than a few hundred
possible as in cache
a few hundred milliseconds
as in cache miss
based interface back to
interface back to the
back to the information
to the information layer
the ssa is quite
the information layer at
ssa is quite tolerant
information layer at which
is quite tolerant of
layer at which the
quite tolerant of short
at which the event
which the event has
the event has originated
we will now compare
will now compare their
customuserserviceapp heartbeatmonitor gossiper subserviceprocess
now compare their efficacies
heartbeatmonitor gossiper subserviceprocess chainlink
the transport layer with
gossiper subserviceprocess chainlink subservicecontrol
transport layer with the
subserviceprocess chainlink subservicecontrol nonblockingtransport
layer with the embedded
we use the approximate
with the embedded distributed
use the approximate clusters
the embedded distributed protocol
the approximate clusters workload
embedded distributed protocol would
approximate clusters workload with
distributed protocol would behave
protocol would behave very
would behave very much
behave very much like
very much like an
much like an object
like an object in
an object in smalltalk
it would consume events
would consume events and
consume events and respond
the component stack of
events and respond with
component stack of one
and respond with events
stack of one subservice
of one subservice process
a window size of
this motivates thinking about
motivates thinking about communication
thinking about communication protocols
about communication protocols as
communication protocols as objects
a pareto parameter of
failure and recovery process
and indeed in treating
and recovery process failure
indeed in treating them
recovery process failure detection
in treating them as
process failure detection is
treating them as objects
failure detection is accomplished
them as objects much
detection is accomplished by
as objects much as
is accomplished by means
objects much as we
accomplished by means of
and the maximum dependency
by means of two
much as we treat
the maximum dependency list
means of two mechanisms
maximum dependency list size
as we treat any
dependency list size is
we treat any other
list size is set
treat any other kind
size is set to
detecting fifo channels that
any other kind of
fifo channels that break
other kind of object
kind of object in
of object in a
object in a language
in our case they
in a language like
our case they are
a language like java
case they are tcp
language like java or
they are tcp channels
like java or in
are tcp channels with
java or in a
tcp channels with low
or in a runtime
channels with low value
in a runtime environment
with low value for
a runtime environment like
low value for the
runtime environment like jini
value for the so
environment like jini or
for the so timeout
the so timeout property
the lower portion of
lower portion of the
portion of the graph
doing so unifies apparently
of the graph is
so unifies apparently distinct
the graph is the
unifies apparently distinct approaches
based heartbeat detection mechanism
graph is the ratio
is the ratio of
the ratio of committed
ratio of committed transactions
once a process is
just as a remotely
a process is deceased
of committed transactions that
as a remotely hosted
committed transactions that the
a remotely hosted form
transactions that the abort
remotely hosted form of
that the abort strategy
the information is propagated
hosted form of content
information is propagated within
the abort strategy provides
is propagated within the
form of content such
propagated within the group
abort strategy provides a
within the group in
of content such as
the group in two
strategy provides a significant
group in two ways
content such as a
provides a significant improvement
such as a map
a significant improvement over
as a map or
significant improvement over a
a map or an
improvement over a normal
map or an image
or an image of
an image of a
the process that has
image of a raincloud
process that has detected
of a raincloud can
that has detected the
a raincloud can be
has detected the membership
raincloud can be modeled
detected the membership change
can be modeled as
the membership change feeds
be modeled as an
membership change feeds the
as the strategy detects
change feeds the event
modeled as an object
feeds the event description
the strategy detects and
the event description into
strategy detects and aborts
event description into the
detects and aborts over
description into the chain
into the chain itself
so can network protocols
can network protocols be
network protocols be treated
protocols be treated as
be treated as objects
this is delivered in
is delivered in chain
delivered in chain order
in chain order to
chain order to every
order to every non
of all inconsistent transactions
all inconsistent transactions that
p systems try to
inconsistent transactions that would
systems try to make
transactions that would have
try to make everything
that would have been
to make everything a
would have been committed
make everything a p
faulty process and where
process and where necessary
but the other strategies
the other strategies make
chain repair procedure is
other strategies make further
repair procedure is undertaken
strategies make further improvements
but in the examples
in the examples we
the examples we ve
examples we ve seen
evict reduces uncommittable transactions
reduces uncommittable transactions to
the same detector process
several kinds of content
same detector process starts
kinds of content would
detector process starts up
of content would more
process starts up a
content would more naturally
starts up a backup
would more naturally be
up a backup gossip
more naturally be hosted
a backup gossip notification
backup gossip notification stream
of its value with
its value with abort
this is a fast
is a fast dying
a fast dying epidemic
this indicates that violating
d images of terrain
images of terrain and
it spreads rapidly but
of terrain and buildings
spreads rapidly but also
rapidly but also dies
but also dies out
also dies out rapidly
cache entries are likely
entries are likely to
are likely to be
the fifo channels are
likely to be repeat
to be repeat offenders
fifo channels are rebuilt
channels are rebuilt appropriately
are rebuilt appropriately by
rebuilt appropriately by the
on the other hand
appropriately by the processes
they are too old
by the processes that
are too old for
the processes that identify
too old for objects
processes that identify themselves
old for objects that
that identify themselves to
for objects that are
identify themselves to be
soc applications are likely
themselves to be affected
objects that are likely
to be affected by
applications are likely to
be affected by the
that are likely to
affected by the membership
are likely to embody
by the membership change
are likely to be
likely to embody quite
likely to be accessed
to embody quite a
to be accessed together
embody quite a range
be accessed together with
quite a range of
accessed together with them
a range of p
and the group converges
together with them in
the group converges to
with them in future
group converges to a
them in future transactions
converges to a stable
to a stable configuration
and so it is
each separate video object
so it is better
it is better to
is better to evict
better to evict them
update sources can use
sources can use this
can use this update
retry reduces uncommittable transactions
use this update to
reduces uncommittable transactions further
this update to reconnect
uncommittable transactions further to
update to reconnect to
transactions further to about
to reconnect to a
may have its own
reconnect to a new
have its own associated
to a new head
its own associated update
a new head of
own associated update stream
new head of any
head of any chain
of any chain that
any chain that may
if one thinks of
chain that may have
of its value with
that may have lost
its value with abort
one thinks of these
may have lost its
thinks of these as
have lost its previous
of these as topics
lost its previous head
these as topics in
its previous head as
as topics in publish
previous head as a
head as a consequence
as a consequence of
realistic workloads we now
a consequence of the
workloads we now evaluate
consequence of the crash
we now evaluate the
now evaluate the efficacy
evaluate the efficacy of
the efficacy of t
an application could have
application could have many
could have many such
have many such topics
cache with workloads based
with workloads based on
if a process wants
workloads based on two
a process wants to
and the application instance
process wants to join
based on two sampled
the application instance running
on two sampled topologies
application instance running on
two sampled topologies from
instance running on a
sampled topologies from the
it starts by sending
topologies from the online
starts by sending a
from the online retailer
running on a given
the online retailer amazon
by sending a request
online retailer amazon and
on a given user
retailer amazon and the
sending a request to
amazon and the social
a request to a
and the social network
request to a random
a given user s
the social network orkut
to a random member
given user s machine
a random member of
user s machine could
random member of the
s machine could simultaneously
member of the group
machine could simultaneously display
could simultaneously display data
simultaneously display data from
display data from several
data from several topics
describes how we generated
the group member will
we have previously said
how we generated these
group member will commence
we generated these workloads
have previously said that
member will commence a
previously said that we
will commence a membership
said that we d
commence a membership change
that we d like
a membership change protocol
we d like to
membership change protocol as
d like to think
change protocol as described
like to think of
protocol as described above
to think of protocols
think of protocols as
of protocols as objects
measures the efficacy of
again once all the
the efficacy of t
once all the nodes
it now becomes clear
all the nodes receive
now becomes clear that
the nodes receive the
becomes clear that further
nodes receive the membership
clear that further precision
receive the membership event
that further precision is
the membership event and
further precision is needed
membership event and update
cache on these workloads
event and update their
on these workloads as
and update their view
these workloads as a
workloads as a function
the objects aren t
as a function of
objects aren t merely
a function of maximum
aren t merely protocols
function of maximum dependency
of maximum dependency list
maximum dependency list size
but in fact are
in fact are individual
fact are individual protocol
and compares this to
implementation details the framework
are individual protocol instances
details the framework was
compares this to a
the framework was implemented
this to a strategy
framework was implemented using
to a strategy based
was implemented using the
a strategy based on
implemented using the java
our system will need
using the java language
strategy based on ttls
system will need to
the java language and
will need to simultaneously
java language and its
need to simultaneously support
language and its non
to simultaneously support potentially
simultaneously support potentially large
support potentially large numbers
potentially large numbers of
large numbers of transport
numbers of transport objects
of transport objects running
compares the efficacy of
transport objects running concurrently
the efficacy of the
objects running concurrently in
efficacy of the three
running concurrently in the
of the three strategies
concurrently in the end
the system design was
the three strategies of
system design was strongly
three strategies of dealing
design was strongly influenced
strategies of dealing with
was strongly influenced by
of dealing with detected
strongly influenced by prior
dealing with detected inconsistencies
influenced by prior work
by prior work on
prior work on highperformance
in support of a
work on highperformance services
support of a variety
on highperformance services platforms
of a variety of
a variety of applications
variety of applications and
of applications and uses
notably welsh s seda
welsh s seda architecture
all of this leads
of this leads to
this leads to new
leads to new challenges
we generated two workloads
generated two workloads based
two workloads based on
the obvious one was
workloads based on real
obvious one was mentioned
based on real data
one was mentioned earlier
today s web services
s web services don
web services don t
components are highly autonomous
services don t support
don t support p
we started from a
started from a snapshot
from a snapshot of
contemporary web services solutions
a snapshot of amazon
web services solutions presume
snapshot of amazon s
services solutions presume a
of amazon s product
solutions presume a client
amazon s product co
there are only four
are only four distinct
only four distinct control
four distinct control threads
server style of interaction
purchasing graph taken early
distinct control threads in
control threads in the
threads in the component
in the component stack
with data relayed through
the component stack of
data relayed through a
component stack of a
relayed through a message
stack of a process
even if clients are
if clients are connected
clients are connected to
are connected to one
namely one for the
one for the non
for the non blocking
the non blocking transport
if they lose connectivity
they lose connectivity to
lose connectivity to the
connectivity to the broker
the tcp chain and
they can t collaborate
tcp chain and for
each product sold by
chain and for the
and for the heartbeat
product sold by the
for the heartbeat component
sold by the online
another serious issue arises
by the online retailer
serious issue arises if
the online retailer is
issue arises if the
online retailer is a
arises if the clients
retailer is a node
if the clients don
the ssa is roughly
the clients don t
is a node and
clients don t trust
a node and each
don t trust the
node and each pair
t trust the data
and each pair of
trust the data center
each pair of products
pair of products purchased
of products purchased in
products purchased in a
purchased in a single
sensitive data will need
in a single user
data will need to
a single user session
will need to be
single user session is
need to be encrypted
user session is an
session is an edge
the problem here is
the original graph contains
problem here is that
original graph contains more
here is that web
graph contains more than
is that web services
that web services security
web services security standards
services security standards tend
security standards tend to
standards tend to trust
tend to trust the
to trust the web
trust the web services
the web services platform
web services platform itself
the standards offer no
standards offer no help
offer no help at
no help at all
help at all if
at all if we
all if we need
if we need to
we need to provide
need to provide end
end encryption mechanisms while
encryption mechanisms while also
mechanisms while also preventing
while also preventing the
also preventing the hosted
preventing the hosted services
the hosted services from
hosted services from seeing
services from seeing the
from seeing the keys
we used a snapshot
used a snapshot of
a snapshot of the
snapshot of the friendship
of the friendship relations
we encounter debilitating latency
the friendship relations graph
encounter debilitating latency and
friendship relations graph in
debilitating latency and throughput
relations graph in the
latency and throughput issues
graph in the orkut
in the orkut social
the orkut social network
hosted services will be
services will be performance
limiting bottlenecks when used
bottlenecks when used in
when used in settings
used in settings with
in settings with large
settings with large numbers
with large numbers of
large numbers of clients
as we will see
we will see in
will see in our
see in our experimental
in our experimental section
we are left with
are left with a
left with a mixture
with a mixture of
a mixture of good
mixture of good and
of good and bad
good and bad news
web services standardize client
services standardize client access
standardize client access to
each user is a
client access to hosted
user is a node
access to hosted services
is a node and
to hosted services and
a node and each
hosted services and data
node and each pair
and each pair of
each pair of users
pair of users with
of users with a
we can easily build
users with a friend
can easily build some
with a friend relationship
easily build some form
a friend relationship is
build some form of
friend relationship is an
some form of multiframed
relationship is an edge
form of multiframed web
of multiframed web page
multiframed web page that
web page that could
the original graph contains
page that could host
original graph contains more
that could host each
graph contains more than
could host each kind
host each kind of
each kind of information
kind of information in
of information in its
information in its own
in its own minibrowser
when connectivity is adequate
relaying data via a
data via a hosted
via a hosted service
a hosted service has
hosted service has many
service has many of
has many of the
many of the benefits
of the benefits of
the benefits of a
benefits of a publishsubscribe
of a publishsubscribe architecture
such as robustness as
as robustness as the
robustness as the set
as the set of
the set of clients
set of clients changes
because the sampled topologies
the sampled topologies are
sampled topologies are large
the natural way to
topologies are large and
natural way to think
are large and we
way to think of
to think of our
large and we only
think of our application
of our application is
and we only need
our application is as
application is as an
we only need to
is as an object
only need to simulate
need to simulate a
to simulate a single
simulate a single column
a single column of
single column of the
but web services provide
column of the system
web services provide no
of the system for
services provide no support
the system for our
provide no support for
system for our purposes
no support for this
for our purposes one
support for this kind
our purposes one database
for this kind of
purposes one database server
this kind of client
one database server and
kind of client application
database server and one
of client application development
server and one cache
and one cache server
one cache server we
cache server we down
our solution may perform
solution may perform very
may perform very poorly
sample both graphs to
or fail if the
fail if the hosted
if the hosted services
the hosted services are
hosted services are inaccessible
all data will probably
data will probably be
will probably be visible
probably be visible to
be visible to the
visible to the hosted
to the hosted services
we use a technique
the hosted services unless
use a technique based
hosted services unless the
a technique based on
services unless the developer
technique based on random
unless the developer uses
based on random walks
the developer uses some
on random walks that
developer uses some sort
random walks that maintains
uses some sort of
walks that maintains important
some sort of non
that maintains important properties
maintains important properties of
important properties of the
properties of the original
of the original graph
specifically clustering which is
using live objects for
clustering which is central
live objects for soc
which is central to
objects for soc applications
is central to our
for soc applications cornell
central to our experiment
soc applications cornell s
applications cornell s live
cornell s live objects
s live objects platform
live objects platform supports
we start by choosing
objects platform supports componentized
start by choosing a
by choosing a node
choosing a node uniformly
a node uniformly and
layered mashup creation and
node uniformly and random
mashup creation and sharing
uniformly and random and
and random and start
random and start a
and start a random
start a random walk
and overcomes limitations of
a random walk from
overcomes limitations of existing
random walk from that
limitations of existing web
walk from that location
of existing web technologies
the major design aspects
major design aspects are
design aspects are as
aspects are as follows
the developer starts by
developer starts by creating
or gaining access to
a collection of components
the walk reverts back
walk reverts back to
reverts back to the
back to the first
to the first node
each component is an
the first node and
component is an object
first node and start
is an object that
node and start again
an object that supports
object that supports live
that supports live functionality
this is repeated until
is repeated until the
repeated until the target
and exposes eventbased interfaces
until the target number
exposes eventbased interfaces by
the target number of
eventbased interfaces by which
target number of nodes
interfaces by which it
number of nodes have
by which it interacts
of nodes have been
which it interacts with
nodes have been visited
it interacts with other
interacts with other components
components representing hosted content
representing hosted content sensors
hosted content sensors and
content sensors and actuators
sensors and actuators renderers
and actuators renderers that
actuators renderers that graphically
show a further down
renderers that graphically depict
that graphically depict events
graphically depict events replication
depict events replication protocols
events replication protocols synchronization
replication protocols synchronization protocols
protocols synchronization protocols folders
synchronization protocols folders containing
protocols folders containing sets
folders containing sets of
containing sets of objects
sets of objects display
nodes to provide some
of objects display interfaces
to provide some perception
objects display interfaces that
provide some perception of
display interfaces that visualize
some perception of the
interfaces that visualize folders
perception of the topologies
the graphs are visibly
mashups of components are
graphs are visibly clustered
of components are represented
components are represented as
are represented as a
represented as a kind
as a kind of
the amazon topology more
a kind of xml
amazon topology more so
kind of xml web
topology more so than
of xml web pages
more so than the
so than the orkut
than the orkut one
each describing a recipe
describing a recipe for
a recipe for obtaining
recipe for obtaining and
for obtaining and parameterizing
obtaining and parameterizing components
and parameterizing components that
parameterizing components that will
components that will serve
that will serve as
its topology has a
will serve as layers
topology has a more
serve as layers of
has a more clustered
as layers of the
a more clustered structure
layers of the composed
of the composed mashup
and so the dependency
so the dependency lists
we call such an
the dependency lists hold
call such an xml
dependency lists hold more
such an xml page
lists hold more relevant
an xml page a
hold more relevant information
xml page a live
page a live object
a live object reference
treating nodes of the
nodes of the graphs
of the graphs as
references can be distributed
the graphs as database
can be distributed as
graphs as database objects
be distributed as files
transactions are likely to
are likely to access
likely to access objects
to access objects that
http or other means
access objects that are
objects that are topologically
that are topologically close
are topologically close to
topologically close to one
an soc application is
close to one another
soc application is created
application is created by
is created by building
created by building a
for the online retailer
by building a forest
building a forest consisting
a forest consisting of
forest consisting of graphs
consisting of graphs of
it is likely that
of graphs of references
is likely that objects
graphs of references that
likely that objects bought
of references that are
that objects bought together
references that are mashed
objects bought together are
that are mashed together
bought together are also
together are also viewed
are also viewed and
also viewed and updated
viewed and updated together
an automated tool lets
automated tool lets the
tool lets the developer
lets the developer drag
the developer drag and
developer drag and drop
drag and drop to
and drop to combine
viewing and buying a
drop to combine references
and buying a toy
to combine references for
buying a toy train
combine references for individual
a toy train and
references for individual objects
toy train and matching
for individual objects into
train and matching rails
individual objects into an
objects into an xml
into an xml mashup
an xml mashup of
xml mashup of references
mashup of references describing
of references describing a
references describing a graph
for the social network
describing a graph of
a graph of objects
it is likely that
is likely that data
likely that data of
that data of befriended
data of befriended users
of befriended users are
befriended users are viewed
checks mashups to verify
users are viewed and
mashups to verify that
are viewed and updated
to verify that they
viewed and updated together
verify that they compose
that they compose correctly
tagging a person in
a person in a
d visualization of an
person in a picture
visualization of an airplane
of an airplane may
an airplane may need
airplane may need to
commenting on a post
may need to be
on a post by
need to be connected
a post by a
to be connected to
post by a friend
be connected to a
by a friend s
connected to a source
a friend s friend
to a source of
a source of gps
source of gps and
of gps and other
gps and other orientation
or viewing one s
and other orientation data
viewing one s neighborhood
which in turn needs
in turn needs to
turn needs to run
needs to run over
we run a set
to run over a
run a set of
run over a data
a set of experiments
over a data replication
set of experiments similar
a data replication protocol
of experiments similar to
data replication protocol with
experiments similar to the
replication protocol with specific
similar to the t
protocol with specific reliability
ordering or security properties
varying cache entry ttl
when activated on a
cache entry ttl to
activated on a user
entry ttl to evaluate
on a user s
ttl to evaluate the
a user s machine
to evaluate the efficacy
evaluate the efficacy of
the efficacy of this
efficacy of this method
an xml mashup yields
of this method in
xml mashup yields a
this method in reducing
mashup yields a graph
as seen by the
method in reducing inconsistencies
seen by the entire
yields a graph of
by the entire chain
in reducing inconsistencies and
a graph of interconnected
reducing inconsistencies and the
graph of interconnected proxies
inconsistencies and the corresponding
and the corresponding overhead
a proxy is a
proxy is a piece
is a piece of
a piece of running
piece of running code
of running code that
running code that may
code that may render
limiting ttl has detrimental
ttl has detrimental effects
has detrimental effects on
detrimental effects on cache
effects on cache hit
on cache hit ratio
or transform visual content
quickly increasing the database
encapsulate a protocol stack
increasing the database workload
by increasing database access
increasing database access rate
database access rate to
access rate to more
component in the xml
in the xml mashup
rate to more than
the xml mashup produces
xml mashup produces an
to more than twice
mashup produces an associated
more than twice its
produces an associated proxy
than twice its original
twice its original load
its original load we
original load we only
load we only observe
the hierarchy of proxies
we only observe a
hierarchy of proxies reflects
only observe a reduction
of proxies reflects the
observe a reduction of
proxies reflects the hierarchical
a reduction of inconsistencies
reflects the hierarchical structure
reduction of inconsistencies of
the hierarchical structure of
of inconsistencies of about
hierarchical structure of the
structure of the xml
of the xml mashup
an object proxy can
object proxy can initialize
proxy can initialize itself
can initialize itself by
initialize itself by copying
itself by copying the
by copying the state
this is more than
experimental results and validation
is more than twice
copying the state from
more than twice the
the state from some
than twice the rate
state from some active
twice the rate of
from some active proxy
the rate of inconsistencies
rate of inconsistencies achieved
of inconsistencies achieved by
inconsistencies achieved by t
our platform assists with
platform assists with this
assists with this sort
with this sort of
this sort of state
cache for the retailer
sort of state transfer
for the retailer workload
the retailer workload and
retailer workload and only
workload and only slightly
and only slightly better
only slightly better than
slightly better than the
the object proxies then
better than the rate
object proxies then become
than the rate of
proxies then become active
the rate of inconsistencies
rate of inconsistencies achieved
of inconsistencies achieved by
inconsistencies achieved by t
cache for the social
for the social network
the social network workload
the tests reported here
for example by relaying
tests reported here employ
example by relaying events
reported here employ a
by relaying events from
and with twice the
relaying events from sensors
here employ a hard
events from sensors into
with twice the additional
from sensors into a
twice the additional load
sensors into a replica
the additional load on
additional load on the
load on the database
or by receiving events
the ssa is a
by receiving events and
ssa is a work
we generate a transactional
is a work in
receiving events and reacting
generate a transactional workload
events and reacting to
a work in progress
and reacting to them
a transactional workload that
transactional workload that accesses
workload that accesses products
that accesses products that
accesses products that are
products that are topologically
that are topologically close
fledged system will use
system will use a
will use a software
by redisplaying an aircraft
use a software partitioning
a software partitioning mechanism
we use random walks
software partitioning mechanism based
partitioning mechanism based on
mechanism based on the
based on the web
on the web services
each transaction starts by
the web services request
our approach shares certain
web services request invocation
transaction starts by picking
approach shares certain similarities
starts by picking a
services request invocation model
by picking a node
shares certain similarities with
picking a node uniformly
certain similarities with the
a node uniformly at
similarities with the existing
node uniformly at random
with the existing web
although extracting the partitioning
uniformly at random and
extracting the partitioning key
at random and takes
the existing web development
the partitioning key from
existing web development model
partitioning key from incoming
key from incoming requests
from incoming requests will
steps of a random
incoming requests will impose
of a random walk
requests will impose some
in the sense that
will impose some overhead
the sense that it
sense that it uses
that it uses hierarchical
the nodes visited by
it uses hierarchical xml
we do not expect
uses hierarchical xml documents
nodes visited by the
hierarchical xml documents to
do not expect performance
xml documents to define
visited by the random
not expect performance of
by the random walk
expect performance of the
the random walk are
performance of the full
documents to define the
random walk are the
to define the content
walk are the objects
are the objects the
the objects the transaction
fledged system to deviate
objects the transaction accesses
system to deviate significantly
on the other hand
to deviate significantly from
deviate significantly from what
significantly from what is
from what is reported
update transactions first read
we depart from some
what is reported below
depart from some of
transactions first read all
from some of the
first read all objects
some of the de
read all objects from
all objects from the
objects from the database
facto stylistic standards that
stylistic standards that have
standards that have emerged
and then update all
then update all objects
update all objects at
all objects at the
objects at the database
for example if one
example if one pulls
if one pulls a
one pulls a minibrowser
pulls a minibrowser from
read transactions read the
a minibrowser from google
transactions read the objects
minibrowser from google earth
read the objects directly
the objects directly from
objects directly from the
directly from the cache
it expects to interact
expects to interact directly
to interact directly with
interact directly with the
directly with the end
with the end user
and includes embedded javascript
includes embedded javascript that
embedded javascript that handles
javascript that handles such
that handles such interactions
in this section we
this section we evaluate
section we evaluate t
the same functionality would
cache using the workloads
same functionality would be
using the workloads described
the workloads described above
functionality would be represented
would be represented as
be represented as a
represented as a mashup
we found that the
as a mashup of
found that the abort
a mashup of a
that the abort rate
mashup of a component
the abort rate is
of a component that
abort rate is negligible
a component that fetches
rate is negligible in
component that fetches maps
is negligible in all
that fetches maps and
negligible in all runs
fetches maps and similar
maps and similar content
and similar content with
similar content with a
content with a second
efficacy is therefore defined
with a second component
is therefore defined to
a second component that
therefore defined to be
second component that provides
defined to be the
component that provides the
to be the ratio
that provides the visualization
be the ratio of
provides the visualization interface
the ratio of inconsistent
ratio of inconsistent transactions
of inconsistent transactions out
inconsistent transactions out of
transactions out of all
although the term mashup
out of all commits
the term mashup may
term mashup may sound
mashup may sound static
update injection time against
the overhead of the
injection time against delivery
overhead of the system
in the sense of
of the system is
time against delivery time
the system is twofold
the sense of having
against delivery time at
sense of having its
delivery time at node
of having its components
having its components predetermined
this is not necessarily
dependency list maintenance implies
is not necessarily the
list maintenance implies storage
not necessarily the case
maintenance implies storage and
implies storage and bandwidth
storage and bandwidth overhead
and bandwidth overhead at
one kind of live
bandwidth overhead at both
kind of live object
overhead at both the
of live object could
at both the database
live object could be
both the database and
object could be a
the database and the
could be a folder
database and the cache
be a folder including
a folder including a
folder including a set
including a set of
a set of objects
as well as compute
well as compute overhead
as compute overhead for
compute overhead for dependency
for example extracted from
overhead for dependency list
example extracted from a
for dependency list merging
extracted from a directory
dependency list merging at
from a directory in
list merging at the
a directory in a
merging at the server
directory in a file
at the server and
in a file system
the server and consistency
a file system or
server and consistency checks
file system or pulled
and consistency checks at
system or pulled from
consistency checks at the
or pulled from a
checks at the cache
pulled from a database
from a database in
a database in response
database in response to
in response to a
response to a query
the storage required is
when the folder contents
storage required is only
the folder contents change
required is only for
is only for object
only for object ids
for object ids and
object ids and versions
the mashup is dynamically
mashup is dynamically updated
as might occur when
might occur when a
and both updates and
occur when a rescue
both updates and checks
when a rescue worker
updates and checks are
a rescue worker enters
and checks are o
rescue worker enters a
worker enters a building
enters a building or
a building or turns
building or turns a
or turns a corner
in the number of
the number of objects
live objects can easily
number of objects in
objects can easily support
of objects in the
can easily support applications
objects in the system
easily support applications that
in the system and
support applications that dynamically
the system and o
applications that dynamically recompute
that dynamically recompute the
dynamically recompute the set
recompute the set of
the set of visible
set of visible objects
as a function of
in the size of
a function of location
the size of the
function of location and
size of the dependency
of location and orientation
of the dependency lists
and dynamically add or
which is limited to
dynamically add or remove
add or remove them
or remove them from
remove them from the
them from the mashup
the second and potentially
a rescuer would automatically
second and potentially more
rescuer would automatically and
and potentially more significant
would automatically and instantly
potentially more significant overhead
automatically and instantly be
more significant overhead is
and instantly be shown
significant overhead is the
instantly be shown the
overhead is the effect
be shown the avatars
is the effect on
shown the avatars of
the effect on cache
the avatars of others
effect on cache hit
avatars of others who
on cache hit ratio
of others who are
cache hit ratio due
others who are already
hit ratio due to
who are already working
ratio due to evictions
are already working at
due to evictions and
already working at that
to evictions and hence
working at that site
evictions and hence the
and hence the database
hence the database load
and be able to
be able to participate
able to participate in
update delay as seen
to participate in conference
delay as seen by
since cache load is
as seen by individual
cache load is significantly
seen by individual processes
load is significantly larger
is significantly larger than
significantly larger than database
larger than database load
point dialog with them
orders of magnitude for
of magnitude for facebook
through chat objects that
chat objects that run
objects that run over
that run over multicast
run over multicast protocol
over multicast protocol objects
this model can support
model can support a
can support a wide
support a wide variety
a wide variety of
wide variety of collaboration
variety of collaboration and
of collaboration and coordination
collaboration and coordination paradigms
even a minor deterioration
a minor deterioration in
minor deterioration in hit
deterioration in hit ratio
the live objects platform
in hit ratio can
live objects platform makes
hit ratio can yield
objects platform makes it
ratio can yield a
platform makes it easy
can yield a prohibitive
makes it easy for
yield a prohibitive load
it easy for a
a prohibitive load on
easy for a non
prohibitive load on the
load on the backend
on the backend database
programmer to create the
to create the needed
create the needed soc
the needed soc application
c shows the experiment
shows the experiment results
the rescue coordinator pulls
rescue coordinator pulls prebuilt
coordinator pulls prebuilt object
pulls prebuilt object references
each data point is
prebuilt object references from
data point is the
object references from a
point is the result
references from a folder
is the result of
the result of a
result of a single
of a single run
each corresponding to a
corresponding to a desired
to a desired kind
a desired kind of
desired kind of information
we vary the dependency
our experiments were conducted
vary the dependency list
experiments were conducted using
the dependency list size
were conducted using the
dependency list size and
conducted using the ssa
list size and for
using the ssa framework
size and for each
the ssa framework deployed
and for each value
ssa framework deployed on
for each value run
framework deployed on a
each value run the
deployed on a tightly
value run the experiment
on a tightly coupled
run the experiment for
a tightly coupled homogeneous
the experiment for the
tightly coupled homogeneous cluster
would correspond to objects
experiment for the two
correspond to objects that
coupled homogeneous cluster of
to objects that point
for the two workloads
objects that point to
the two workloads and
that point to a
two workloads and measure
point to a web
workloads and measure the
to a web service
and measure the average
a web service over
measure the average values
web service over the
the average values of
service over the network
average values of these
values of these metrics
the nodes are connected
nodes are connected by
are connected by two
connected by two separate
by two separate high
two separate high speed
separate high speed ethernet
cache is able to
high speed ethernet backbone
is able to reduce
peer objects would implement
able to reduce inconsistencies
speed ethernet backbone planes
to reduce inconsistencies significantly
objects would implement chat
would implement chat windows
we experimented with several
for the retailer workload
experimented with several configurations
a single dependency reduces
single dependency reduces inconsistencies
some placed the control
dependency reduces inconsistencies to
placed the control traffic
event interfaces allow such
the control traffic on
interfaces allow such objects
control traffic on a
allow such objects to
traffic on a different
such objects to coexist
on a different switched
objects to coexist in
a different switched ethernet
to coexist in a
different switched ethernet segment
of their original value
coexist in a shared
switched ethernet segment while
in a shared display
ethernet segment while others
a shared display window
segment while others aggregated
shared display window that
while others aggregated both
two dependencies reduce inconsistencies
others aggregated both the
dependencies reduce inconsistencies to
display window that can
aggregated both the control
window that can pan
both the control traffic
the control traffic and
control traffic and the
traffic and the data
and the data traffic
the data traffic on
data traffic on the
traffic on the same
jump to new locations
on the same segment
of their original value
no significant differences were
and three to less
significant differences were observed
three to less than
the relative advantages and
relative advantages and disadvantages
advantages and disadvantages of
and disadvantages of our
but this may be
disadvantages of our model
this may be because
of our model can
may be because our
our model can be
be because our control
model can be summarized
because our control traffic
can be summarized as
our control traffic consisted
be summarized as follows
for the social network
control traffic consisted mainly
the social network workload
traffic consisted mainly of
consisted mainly of fast
like other modern web
other modern web development
modern web development tools
our platform supports drag
which put little stress
put little stress on
little stress on the
stress on the communication
on the communication channels
of the inconsistencies remain
drop style of development
in the future we
the future we hope
in both workloads there
future we hope to
both workloads there is
we hope to explore
workloads there is no
hope to explore scenarios
there is no visible
to explore scenarios that
easy creation of content
explore scenarios that generate
is no visible effect
scenarios that generate exceptionally
no visible effect on
that generate exceptionally heavy
visible effect on cache
generate exceptionally heavy control
effect on cache hit
exceptionally heavy control traffic
on cache hit ratio
the resulting solutions are
resulting solutions are easy
solutions are easy to
which would allow us
are easy to share
and hence no increased
would allow us to
hence no increased access
allow us to explore
no increased access rate
us to explore the
increased access rate at
by selecting appropriate transport
access rate at the
to explore the benefits
rate at the database
selecting appropriate transport layers
explore the benefits of
the benefits of isolation
benefits of isolation of
of isolation of that
isolation of that traffic
the reduction in inconsistency
functionality such as coordination
of that traffic with
reduction in inconsistency ratio
such as coordination between
that traffic with respect
in inconsistency ratio is
as coordination between searchers
traffic with respect to
coordination between searchers can
inconsistency ratio is significantly
between searchers can remain
ratio is significantly better
searchers can remain active
with respect to data
can remain active even
respect to data traffic
is significantly better for
remain active even if
significantly better for the
active even if connectivity
better for the next
even if connectivity to
for the next we
in the interest of
if connectivity to the
the next we compared
the interest of brevity
connectivity to the data
next we compared our
to the data center
interest of brevity we
we compared our technique
the data center is
compared our technique with
data center is disrupted
of brevity we did
our technique with a
brevity we did not
technique with a simple
we did not perform
with a simple approach
did not perform any
streams of video or
a simple approach in
not perform any experiments
simple approach in which
of video or sensor
approach in which we
perform any experiments to
video or sensor data
in which we limited
any experiments to evaluate
which we limited the
or sensor data can
we limited the life
experiments to evaluate the
limited the life span
sensor data can travel
to evaluate the load
data can travel directly
evaluate the load balancing
can travel directly and
the load balancing component
travel directly and won
load balancing component but
directly and won t
balancing component but we
and won t be
component but we plan
won t be delayed
but we plan to
we plan to do
t be delayed by
plan to do so
to do so in
be delayed by the
do so in the
so in the future
delayed by the need
here inconsistencies are not
by the need to
inconsistencies are not detected
the need to ricochet
need to ricochet off
to ricochet off a
ricochet off a remote
all the experiments involved
off a remote and
but their probability of
a remote and potentially
the experiments involved a
their probability of being
remote and potentially inaccessible
experiments involved a single
probability of being witnessed
and potentially inaccessible server
involved a single partitioned
of being witnessed is
a single partitioned and
being witnessed is reduced
single partitioned and replicated
witnessed is reduced by
partitioned and replicated service
is reduced by having
reduced by having the
by having the cache
for ease of exposition
based interoperability standards are
having the cache evict
interoperability standards are needed
the cache evict entries
cache evict entries after
this service implements a
evict entries after a
service implements a simple
entries after a certain
implements a simple wall
after a certain period
a certain period even
we could lose access
certain period even if
could lose access to
period even if the
lose access to some
even if the database
access to some of
if the database did
the service itself maintains
the database did not
to some of the
database did not indicate
service itself maintains the
did not indicate they
some of the sophisticated
not indicate they are
itself maintains the time
indicate they are invalid
of the sophisticated proprietary
the sophisticated proprietary interactive
sophisticated proprietary interactive functionality
proprietary interactive functionality optimized
with updates coming from
interactive functionality optimized for
updates coming from client
functionality optimized for proprietary
coming from client applications
optimized for proprietary minibrowser
from client applications that
client applications that read
applications that read a
that read a high
based solutions with an
solutions with an embedded
with an embedded javascript
quality clock and send
clock and send the
and send the current
send the current value
as processes forward updates
processes forward updates along
compares the efficacy of
forward updates along the
the efficacy of the
updates along the chain
efficacy of the abort
peer communication can be
communication can be much
can be much harder
they will track the
be much harder to
will track the clock
evict and retry policies
track the clock themselves
much harder to use
and retry policies with
harder to use than
retry policies with the
to use than relaying
policies with the amazon
all of our partitioning
with the amazon and
use than relaying data
the amazon and orkut
of our partitioning scenarios
amazon and orkut workloads
than relaying data through
our partitioning scenarios included
relaying data through a
partitioning scenarios included at
data through a hosted
scenarios included at least
through a hosted service
included at least four
in these experiments we
at least four subservices
a hosted service that
these experiments we use
hosted service that uses
experiments we use dependency
service that uses an
we use dependency lists
that uses an enterprise
use dependency lists of
and each subservice included
dependency lists of length
uses an enterprise service
each subservice included between
an enterprise service bus
just as with the
as with the synthetic
with the synthetic workload
evicting conflicting transactions is
we expect these to
conflicting transactions is an
expect these to be
the lack of a
these to be typical
lack of a one
transactions is an effective
of a one size
to be typical cases
a one size fits
is an effective way
one size fits all
be typical cases for
size fits all publish
an effective way of
typical cases for real
effective way of invalidating
cases for real deployments
way of invalidating stale
for real deployments of
of invalidating stale objects
subscribe substrate forces the
real deployments of the
invalidating stale objects that
deployments of the ssa
substrate forces the developers
stale objects that might
forces the developers to
objects that might cause
the developers to become
it should be noted
that might cause problems
developers to become familiar
should be noted that
might cause problems for
be noted that small
cause problems for future
noted that small subservice
to become familiar with
that small subservice sizes
problems for future transactions
become familiar with and
familiar with and choose
with and choose between
and choose between a
choose between a range
the effects are more
between a range of
effects are more pronounced
a range of different
are more pronounced for
range of different and
more pronounced for the
of different and incompatible
pronounced for the well
different and incompatible options
can result in degenerate
result in degenerate behavior
in degenerate behavior and
degenerate behavior and are
an wrong choice of
behavior and are not
wrong choice of transport
and are not appropriate
choice of transport could
are not appropriate configurations
with the amazon workload
not appropriate configurations for
of transport could result
appropriate configurations for the
transport could result in
configurations for the ssa
could result in degraded
for the ssa architecture
result in degraded qos
abort is able to
is able to detect
or even data loss
of the inconsistent transactions
mapping between service processes
between service processes and
service processes and physical
processes and physical nodes
whereas with the less
second life as a
life as a soc
as a soc application
in order to avoid
clustered orkut workload it
order to avoid os
orkut workload it only
to avoid os resource
workload it only detects
avoid os resource contention
a soc application up
soc application up to
application up to now
we experimented with groups
experimented with groups of
we have focused on
have focused on a
focused on a small
in both cases evict
both cases evict reduces
but our longer term
cases evict reduces uncommittable
our longer term goal
evict reduces uncommittable transactions
longer term goal is
reduces uncommittable transactions considerably
term goal is to
goal is to support
is to support a
to support a large
relative to their value
to their value with
their value with abort
scale nextgeneration collaboration system
nextgeneration collaboration system similar
collaboration system similar to
system similar to second
similar to second life
a virtual reality immersion
virtual reality immersion system
with the amazon workload
reality immersion system created
the amazon workload and
immersion system created by
system created by linden
created by linden labs
by convention the head
convention the head of
the head of the
head of the chain
of the chain for
the chain for each
second life is implemented
chain for each group
life is implemented with
for each group was
is implemented with a
each group was called
in the amazon workload
group was called node
implemented with a data
with a data center
a data center including
data center including a
retry further reduces this
center including a large
further reduces this value
including a large number
reduces this value to
a large number of
and all update requests
large number of servers
all update requests for
number of servers storing
update requests for a
of servers storing the
requests for a partition
servers storing the state
for a partition were
storing the state of
a partition were routed
the state of the
partition were routed towards
state of the virtual
were routed towards this
of the virtual world
routed towards this node
of its value with
its value with abort
the locations of all
since delivery delays in
locations of all users
delivery delays in the
delays in the chain
in the chain were
the chain were measured
r elated w ork
chain were measured relative
elated w ork a
were measured relative to
measured relative to node
recent years have seen
all the statistics pertaining
years have seen a
the statistics pertaining to
have seen a surge
statistics pertaining to the
then move about and
seen a surge of
pertaining to the group
move about and interact
to the group disregarded
a surge of progress
the group disregarded node
about and interact with
surge of progress in
and interact with others
of progress in the
progress in the development
in the development of
the development of scalable
development of scalable object
of scalable object stores
we simulated two classes
scalable object stores that
simulated two classes of
one can create a
object stores that support
can create a cybercaf
stores that support transactions
two classes of failures
some systems such as
at some time t
some time t one
time t one process
as other second life
other second life users
second life users enter
life users enter the
users enter the room
the system must detect
they can interact with
system must detect the
can interact with the
must detect the failure
interact with the environment
with the environment and
the environment and one
repair the broken fifo
the broken fifo channel
in the second life
the second life architecture
whenever an avatar moves
an avatar moves or
avatar moves or performs
moves or performs some
or performs some action
performs some action in
the failed process recovers
some action in the
failed process recovers and
action in the virtual
process recovers and rejoins
in the virtual world
recovers and rejoins the
and rejoins the chain
a request describing this
the join protocol would
request describing this event
join protocol would run
describing this event is
this event is passed
event is passed to
is passed to the
and the previously failed
passed to the hosting
the previously failed node
to the hosting data
previously failed node would
the hosting data center
failed node would become
hosting data center and
node would become the
export novel consistency definitions
data center and processed
novel consistency definitions that
center and processed by
would become the new
and processed by servers
become the new tail
processed by servers running
consistency definitions that allow
by servers running there
the new tail of
definitions that allow for
new tail of the
that allow for effective
tail of the chain
allow for effective optimizations
clients do perform a
do perform a variety
perform a variety of
a variety of decoding
the scenario is intended
several recent systems implement
variety of decoding and
scenario is intended to
of decoding and rendering
recent systems implement full
decoding and rendering functions
is intended to model
systems implement full fledged
and rendering functions locally
intended to model a
implement full fledged atomicity
to model a common
full fledged atomicity while
model a common case
fledged atomicity while preserving
a common case in
atomicity while preserving the
common case in which
but the data center
case in which the
while preserving the system
in which the failure
the data center must
preserving the system s
which the failure detection
the system s scalability
data center must be
system s scalability with
the failure detection mechanism
s scalability with a
center must be in
scalability with a wide
failure detection mechanism senses
with a wide variety
must be in the
a wide variety of
detection mechanism senses a
wide variety of workloads
be in the loop
mechanism senses a transient
in the loop to
senses a transient problem
the loop to ensure
loop to ensure that
to ensure that all
google s spanner utilizes
ensure that all users
s spanner utilizes accurate
that all users observe
spanner utilizes accurate clock
all users observe consistent
utilizes accurate clock synchronization
users observe consistent state
a node that has
node that has become
that has become overloaded
when the number of
has become overloaded or
the number of users
become overloaded or is
number of users in
overloaded or is unresponsive
of users in a
or is unresponsive for
users in a scenario
is unresponsive for some
in a scenario isn
unresponsive for some other
a scenario isn t
for some other reason
scenario isn t huge
by balakrishnan et al
such as garbage collection
second life can easily
is constructed on top
life can easily keep
constructed on top of
can easily keep up
on top of the
easily keep up using
top of the scalable
keep up using a
and does not respond
of the scalable corfu
does not respond to
up using a standard
not respond to the
using a standard workload
respond to the heartbeat
a standard workload partitioning
to the heartbeat within
standard workload partitioning scheme
the heartbeat within the
workload partitioning scheme in
heartbeat within the accepted
partitioning scheme in which
within the accepted window
scheme in which different
in which different servers
which different servers handle
different servers handle different
servers handle different portions
handle different portions of
different portions of the
portions of the virtual
of the virtual world
by reconfiguring the chain
the load on node
load on node drops
and the problem will
the problem will eventually
problem will eventually resolve
for example because large
example because large numbers
utilize a large set
because large numbers of
a large set of
large numbers of users
it then requests a
numbers of users want
then requests a rejoin
of users want to
large set of independent
users want to enter
set of independent logs
want to enter the
to enter the same
enter the same virtual
a node crash that
the same virtual discotheque
node crash that results
crash that results in
that results in a
results in a reboot
in a reboot would
the servers can become
a reboot would result
servers can become overwhelmed
reboot would result in
can become overwhelmed and
would result in similar
become overwhelmed and are
result in similar behavior
overwhelmed and are forced
and are forced to
are forced to reject
forced to reject some
to reject some of
reject some of the
some of the users
of the users or
the users or reduce
users or reduce their
or reduce their frame
all the nodes in
the nodes in the
nodes in the subservice
rendering rates and resolution
in the subservice remain
the subservice remain operational
but one of them
one of them becomes
of them becomes overloaded
second life might seem
life might seem jumpy
might seem jumpy and
seem jumpy and unrealistic
causing the tcp link
the tcp link to
use lock chains and
tcp link to the
lock chains and assume
second life as a
chains and assume transactions
link to the upstream
and assume transactions are
life as a live
assume transactions are known
to the upstream node
transactions are known in
as a live objects
are known in advance
the upstream node to
a live objects application
upstream node to become
live objects application poses
node to become congested
objects application poses some
to become congested and
application poses some new
become congested and starving
these methods all scale
poses some new challenges
methods all scale well
congested and starving downstream
all scale well and
and starving downstream nodes
scale well and in
on the one hand
well and in many
and in many cases
in many cases allow
which begin to miss
many cases allow databases
begin to miss updates
cases allow databases to
many aspects of the
allow databases to accept
aspects of the application
databases to accept loads
of the application can
to accept loads similar
this scenario models a
accept loads similar to
the application can be
loads similar to those
scenario models a behavior
similar to those handled
models a behavior common
to those handled by
a behavior common in
those handled by non
application can be addressed
behavior common in experiments
can be addressed in
common in experiments on
be addressed in the
in experiments on our
addressed in the same
experiments on our cluster
in the same manner
the same manner we
same manner we ve
manner we ve outlined
we ve outlined for
when a node becomes
ve outlined for the
they are not expected
outlined for the search
a node becomes very
for the search and
are not expected to
the search and rescue
node becomes very busy
search and rescue application
not expected to disrupt
becomes very busy or
expected to disrupt the
very busy or the
to disrupt the prevailing
busy or the communication
disrupt the prevailing two
or the communication subsystem
one could use microsoft
the communication subsystem becomes
could use microsoft virtual
communication subsystem becomes heavily
use microsoft virtual earth
subsystem becomes heavily loaded
tcp at the node
at the node upstream
the node upstream from
note that we are
as a source of
that we are addressing
node upstream from it
we are addressing the
upstream from it will
are addressing the problem
from it will sense
addressing the problem of
it will sense congestion
d textures representing landscapes
the problem of read
will sense congestion and
sense congestion and reduce
congestion and reduce its
and reduce its window
reduce its window size
only incoherent caches that
incoherent caches that respond
caches that respond to
that respond to queries
if the impacted node
respond to queries without
the impacted node is
to queries without access
impacted node is in
queries without access to
node is in the
without access to the
is in the middle
access to the backend
in standards for creating
to the backend database
in the middle of
standards for creating mashups
the middle of the
for creating mashups could
middle of the chain
creating mashups could be
previous work on coherent
mashups could be used
work on coherent caches
could be used to
be used to identify
it ceases to relay
used to identify sensors
ceases to relay updates
to identify sensors and
identify sensors and other
sensors and other data
and other data sources
or does so after
does so after long
so after long delays
which could then be
could then be wrapped
then be wrapped as
be wrapped as live
wrapped as live objects
as live objects and
live objects and incorporated
hence downstream nodes fall
objects and incorporated into
downstream nodes fall behind
and incorporated into live
incorporated into live scenes
on top of this
the chain replication scheme
chain replication scheme slows
replication scheme slows to
scheme slows to a
slows to a crawl
streaming media sources such
media sources such as
sources such as video
such as video cameras
as video cameras mounted
video cameras mounted at
the ssa benefits from
cameras mounted at street
ssa benefits from its
mounted at street level
benefits from its gossip
at street level in
from its gossip repair
street level in places
its gossip repair mechanisms
level in places such
in places such as
places such as tokyo
such as tokyo s
which route missing updates
as tokyo s ginza
route missing updates around
tokyo s ginza can
missing updates around the
s ginza can be
updates around the slow
ginza can be added
around the slow node
can be added to
be added to create
added to create realistic
to create realistic experience
supports transactions using locks
route them to that
the more complex issue
them to that node
transactions using locks or
more complex issue is
using locks or communication
complex issue is that
locks or communication with
issue is that a
or communication with the
when it recovers and
communication with the database
it recovers and needs
with the database on
recovers and needs to
the database on each
and needs to repair
database on each transaction
needs to repair its
is that a search
to repair its state
that a search and
a search and rescue
these techniques are not
search and rescue application
techniques are not applicable
and rescue application can
are not applicable in
rescue application can be
not applicable in our
application can be imagined
applicable in our scenario
can be imagined as
be imagined as a
knowing that gossip will
imagined as a situational
that gossip will kick
as a situational state
gossip will kick in
a situational state fully
situational state fully replicated
state fully replicated across
fully replicated across all
an upstream node can
replicated across all of
upstream node can deliberately
across all of its
node can deliberately drop
all of its users
can deliberately drop updates
deliberately drop updates on
drop updates on congested
updates on congested tcp
on congested tcp connections
all machines would see
we used our wall
machines would see all
would see all the
see all the state
all the state updates
clock service to evaluate
service to evaluate the
to evaluate the behavior
even if the user
evaluate the behavior of
if the user is
the behavior of the
the user is zoomed
behavior of the overall
user is zoomed into
of the overall system
is zoomed into some
the overall system in
zoomed into some particular
overall system in various
into some particular spot
system in various scenarios
some particular spot within
in various scenarios and
particular spot within the
various scenarios and with
spot within the overall
scenarios and with different
within the overall scene
and with different parameters
a stream of updates
stream of updates of
of updates of various
one can contemplate such
updates of various rates
can contemplate such an
of various rates is
contemplate such an approach
various rates is injected
such an approach because
rates is injected into
an approach because the
is injected into the
approach because the aggregate
injected into the head
because the aggregate amount
into the head of
the aggregate amount of
the head of the
aggregate amount of information
head of the chain
amount of information might
of information might not
information might not be
might not be that
not be that large
for groups of nodes
second life conceptually is
life conceptually is a
conceptually is a whole
is a whole universe
established point in time
unbounded in size and
in size and hence
size and hence with
and hence with different
hence with different users
a victim node receives
with different users in
victim node receives a
different users in very
node receives a command
users in very distinct
receives a command that
in very distinct parts
a command that forces
very distinct parts of
command that forces it
distinct parts of the
that forces it to
parts of the space
forces it to halt
it would make no
the node continues to
would make no sense
node continues to listen
make no sense for
continues to listen for
no sense for every
to listen for commands
sense for every user
listen for commands that
for every user to
for commands that would
every user to see
commands that would restart
user to see every
that would restart it
to see every event
this is accomplished by
is accomplished by having
we would solve this
accomplished by having node
would solve this problem
solve this problem using
this problem using the
problem using the dynamic
using the dynamic database
send a crash command
the dynamic database querying
a crash command to
dynamic database querying approach
crash command to the
database querying approach outlined
command to the victim
querying approach outlined in
to the victim node
approach outlined in section
the victim node once
victim node once a
node once a certain
once a certain number
a certain number of
certain number of updates
number of updates were
of updates were injected
each user would see
updates were injected into
user would see only
were injected into the
would see only the
injected into the chain
see only the objects
only the objects within
the objects within some
objects within some range
or within line of
within line of sight
as a user moves
the victim node will
a user moves about
victim node will stop
node will stop participating
will stop participating in
stop participating in the
the platform would recompute
participating in the normal
platform would recompute the
in the normal protocol
would recompute the query
the normal protocol and
recompute the query result
normal protocol and will
protocol and will handle
and will handle only
will handle only wakeup
and then update the
handle only wakeup commands
then update the display
only wakeup commands from
update the display accordingly
wakeup commands from this
commands from this moment
from this moment onwards
the chain detects the
chain detects the failure
that since some live
since some live objects
repairs and announces the
some live objects uses
and announces the membership
live objects uses p
announces the membership change
p protocols that might
after a number of
protocols that might organize
a number of updates
that might organize user
number of updates have
might organize user s
of updates have been
organize user s machines
updates have been injected
user s machines into
have been injected since
s machines into groups
been injected since the
machines into groups forwarding
injected since the crash
into groups forwarding streams
since the crash command
groups forwarding streams of
the crash command was
forwarding streams of data
crash command was issued
streams of data to
of data to one
data to one another
we end up in
sends a wakeup command
end up in a
a wakeup command to
up in a situation
wakeup command to the
in a situation where
command to the victim
a situation where each
to the victim node
situation where each user
where each user belongs
each user belongs to
user belongs to a
belongs to a potentially
to a potentially large
a potentially large number
potentially large number of
large number of such
number of such groups
the victim node rejoins
and the groups that
victim node rejoins the
node rejoins the group
the groups that one
groups that one user
that one user is
one user is a
it has to catch
user is a part
has to catch up
is a part of
to catch up by
a part of might
catch up by obtaining
part of might be
up by obtaining copies
of might be very
by obtaining copies of
might be very different
obtaining copies of updates
be very different from
copies of updates that
very different from the
of updates that it
different from the groups
updates that it has
from the groups that
that it has missed
the groups that other
groups that other users
that other users belong
other users belong to
we experimentally determined that
to support such a
support such a model
repetitions of each experiment
of each experiment were
each experiment were enough
experiment were enough to
we need to be
were enough to yield
need to be able
enough to yield accurate
to be able to
to yield accurate measurements
be able to support
yield accurate measurements with
able to support very
accurate measurements with low
to support very large
measurements with low variance
support very large numbers
very large numbers of
large numbers of publish
shows the update delivery
the update delivery delay
and with different users
update delivery delay for
with different users subscribed
delivery delay for a
different users subscribed to
delay for a set
users subscribed to very
for a set of
subscribed to very different
a set of four
to very different sets
set of four consecutive
very different sets of
of four consecutive nodes
different sets of topics
four consecutive nodes in
consecutive nodes in a
nodes in a chain
up to now we
starting with the victim
db access rate normed
with the victim node
to now we have
now we have been
we have been fairly
have been fairly negative
been fairly negative about
fairly negative about the
negative about the trend
the chain length is
about the trend to
the trend to standardize
db access rate normed
trend to standardize client
to standardize client access
standardize client access to
client access to hosted
and we report on
access to hosted content
we report on a
report on a gossip
to hosted content through
on a gossip rate
a gossip rate of
hosted content through web
content through web minibrowsers
through web minibrowsers that
web minibrowsers that make
minibrowsers that make the
that make the javascript
make the javascript running
the javascript running on
javascript running on a
running on a user
on a user s
a user s machine
milliseconds at a steady
user s machine virtually
at a steady update
s machine virtually inseparable
a steady update injection
machine virtually inseparable from
steady update injection rate
virtually inseparable from the
update injection rate of
inseparable from the data
from the data center
our core criticism was
core criticism was that
criticism was that for
was that for most
that for most soc
for most soc applications
there are three anomalies
a minibrowser approach would
are three anomalies that
minibrowser approach would lack
three anomalies that can
approach would lack the
anomalies that can be
would lack the flexibility
that can be seen
lack the flexibility to
can be seen on
the flexibility to seamlessly
be seen on the
flexibility to seamlessly combine
seen on the graphs
to seamlessly combine content
seamlessly combine content from
combine content from different
content from different sources
the first one is
first one is experienced
one is experienced by
and to customize the
is experienced by the
to customize the underlying
experienced by the victim
customize the underlying communication
by the victim node
the underlying communication substrate
the victim node for
hit ratio hit ratio
victim node for updates
node for updates injected
for updates injected between
our earlier concerns carry
earlier concerns carry over
concerns carry over to
carry over to the
over to the second
to the second life
the second life scenario
seconds after the start
after the start of
the start of the
start of the experiment
d texture representing terrain
the second is experienced
texture representing terrain in
second is experienced by
representing terrain in some
is experienced by all
terrain in some region
experienced by all the
by all the other
all the other nodes
the other nodes for
other nodes for update
nodes for update messages
for update messages injected
update messages injected at
messages injected at around
in a minibrowser approach
seconds after the start
the minibrowser generates the
after the start of
minibrowser generates the texture
the start of the
generates the texture from
start of the experiment
the texture from hosted
product a nity social
texture from hosted data
a nity social network
while the third one
the third one is
third one is a
one is a smaller
is a smaller mixed
a smaller mixed burst
smaller mixed burst for
mixed burst for updates
burst for updates injected
for updates injected at
this model makes it
model makes it difficult
seconds into the experiment
note that the y
to superimpose other content
superimpose other content over
other content over the
content over the texture
axes have different scales
have different scales to
different scales to observe
scales to observe how
to observe how the
observe how the system
how the system handles
we would need to
the system handles the
would need to rely
system handles the transient
need to rely on
handles the transient failure
to rely on a
the transient failure better
rely on a hosting
on a hosting system
a hosting system s
hosting system s mashup
system s mashup technology
therefore the third anomaly
s mashup technology to
the third anomaly appears
mashup technology to do
third anomaly appears to
technology to do this
anomaly appears to grow
appears to grow with
to grow with the
grow with the chain
with the chain distance
the chain distance from
chain distance from the
distance from the victim
from the victim node
if we wanted to
we wanted to blend
wanted to blend weather
to blend weather information
the growth is not
blend weather information from
growth is not significant
weather information from the
information from the national
from the national hurricane
the national hurricane center
national hurricane center with
since the cause of
hurricane center with a
the cause of this
center with a google
cause of this anomaly
with a google map
of this anomaly is
this anomaly is an
anomaly is an artifact
is an artifact of
the google map service
an artifact of java
google map service would
artifact of java s
map service would need
of java s garbage
service would need to
java s garbage collection
would need to explicitly
s garbage collection mechanism
need to explicitly support
garbage collection mechanism kicking
to explicitly support this
collection mechanism kicking in
explicitly support this sort
support this sort of
this sort of embedding
as can be noted
performed recovery for the
in our second life
recovery for the updates
our second life scenario
for the updates it
the updates it has
updates it has missed
it has missed during
has missed during the
missed during the period
the visible portion of
during the period it
the period it was
visible portion of the
period it was down
portion of the scene
of the scene the
the scene the part
because the chain delivers
scene the part of
the chain delivers new
the part of the
chain delivers new updates
part of the texture
delivers new updates at
of the texture being
new updates at the
updates at the moment
the texture being displayed
at the moment of
the moment of rejoin
texture being displayed will
being displayed will often
displayed will often be
will often be controlled
all past updates were
often be controlled by
past updates were solely
be controlled by events
updates were solely recovered
controlled by events generated
were solely recovered by
by events generated by
solely recovered by means
events generated by other
recovered by means of
generated by other live
by means of epidemics
by other live objects
other live objects that
live objects that share
objects that share the
that share the display
share the display window
the second anomaly that
second anomaly that shows
anomaly that shows up
that shows up in
shows up in the
perhaps under control of
up in the update
under control of users
in the update delivery
control of users running
the update delivery delay
of users running on
update delivery delay for
users running on machines
delivery delay for the
running on machines elsewhere
delay for the nodes
on machines elsewhere in
for the nodes downstream
machines elsewhere in the
the nodes downstream from
elsewhere in the network
nodes downstream from the
downstream from the victim
from the victim node
the victim node reflects
victim node reflects the
these remote sources won
node reflects the period
remote sources won t
reflects the period when
sources won t fit
the period when the
won t fit into
period when the chain
t fit into the
when the chain is
fit into the interaction
the chain is broken
product a nity social
into the interaction model
a nity social network
the interaction model expected
interaction model expected by
model expected by the
expected by the minibrowser
during the time it
the time it took
time it took for
it took for the
took for the failure
for the failure detection
the failure detection mechanism
failure detection mechanism to
detection mechanism to declare
mechanism to declare the
to declare the node
declare the node deceased
the size and shape
size and shape of
and shape of the
to start up the
shape of the display
start up the membership
up the membership change
of the display window
the membership change protocol
the display window and
display window and other
window and other elements
and for the membership
and other elements of
for the membership information
other elements of the
the membership information to
membership information to propagate
elements of the runtime
of the runtime environment
the runtime environment should
runtime environment should be
the chain is interrupted
environment should be inherited
chain is interrupted between
should be inherited from
is interrupted between node
be inherited from the
inherited from the hierarchy
from the hierarchy structure
the hierarchy structure of
hierarchy structure of the
structure of the object
of the object mashup
the object mashup used
object mashup used to
mashup used to create
used to create the
to create the application
and hence the updates
hence the updates circumvent
the updates circumvent the
updates circumvent the gap
circumvent the gap by
the gap by means
gap by means of
thus our texture should
by means of gossip
our texture should learn
texture should learn its
should learn its size
learn its size and
updates can bypass nodes
its size and orientation
can bypass nodes in
size and orientation and
bypass nodes in the
and orientation and even
nodes in the chain
orientation and even the
in the chain using
and even the gps
the chain using the
even the gps coordinates
chain using the gossip
the gps coordinates on
using the gossip as
gps coordinates on which
the gossip as it
coordinates on which to
gossip as it can
on which to center
as it can be
which to center from
it can be seen
to center from the
can be seen in
center from the parent
be seen in the
from the parent object
seen in the figure
the parent object that
parent object that hosts
object that hosts it
but this phenomenon is
this phenomenon is less
and similarly until we
phenomenon is less likely
similarly until we reach
is less likely as
until we reach the
less likely as the
we reach the root
likely as the node
reach the root object
as the node receiving
the root object hosting
the node receiving the
root object hosting the
node receiving the update
object hosting the display
receiving the update is
hosting the display window
the update is farther
update is farther away
is farther away downstream
farther away downstream from
away downstream from the
a minibrowser isn t
downstream from the victim
minibrowser isn t a
from the victim node
isn t a component
it runs the show
contains an aggregated view
despite all of the
an aggregated view of
all of the above
aggregated view of the
of the above criticism
view of the data
of the data in
the data in figure
minibrowsers retain one potential
retain one potential advantage
for the entire chain
one potential advantage over
potential advantage over the
advantage over the layered
over the layered architecture
at gossip rates of
the layered architecture we
layered architecture we proposed
architecture we proposed earlier
since all aspects of
all aspects of the
aspects of the view
of the view are
the view are optimized
view are optimized to
are optimized to run
optimized to run together
the interaction controls might
interaction controls might be
controls might be far
milliseconds showing that the
might be far more
showing that the behavior
limited cache entry ttl
be far more sophisticated
cache entry ttl fig
that the behavior of
far more sophisticated and
the behavior of the
more sophisticated and perform
behavior of the scheme
sophisticated and perform potentially
of the scheme is
and perform potentially much
the scheme is not
perform potentially much better
scheme is not a
potentially much better than
is not a fluke
much better than a
experiments with workloads based
better than a solution
with workloads based on
than a solution resulting
workloads based on a
a solution resulting from
note that the delay
based on a web
solution resulting from mashing
that the delay of
on a web retailer
resulting from mashing up
the delay of the
from mashing up together
a web retailer product
mashing up together multiple
delay of the updates
up together multiple layers
web retailer product affinity
together multiple layers developed
of the updates delivered
multiple layers developed independently
retailer product affinity topology
the updates delivered at
product affinity topology and
updates delivered at the
affinity topology and a
delivered at the victim
topology and a social
at the victim node
and a social network
the victim node is
a social network topology
victim node is significantly
social network topology illustrated
in many realistic examples
network topology illustrated in
many realistic examples event
node is significantly larger
is significantly larger than
significantly larger than that
larger than that of
based interfaces could get
than that of the
interfaces could get fairly
that of the nodes
could get fairly complex
of the nodes downstream
the nodes downstream of
nodes downstream of it
downstream of it in
of it in the
and difficult for most
it in the chain
difficult for most developers
for most developers to
most developers to work
developers to work with
we observed that even
observed that even with
that even with sufficiently
even with sufficiently high
this observation highlights the
with sufficiently high gossip
sufficiently high gossip rate
observation highlights the importance
highlights the importance of
the importance of developing
compared against the alternative
importance of developing component
the only node to
against the alternative of
of developing component interface
the alternative of reducing
only node to experience
alternative of reducing cache
developing component interface and
of reducing cache entry
node to experience any
reducing cache entry time
component interface and event
to experience any significant
interface and event standards
experience any significant inconsistency
and event standards for
any significant inconsistency window
event standards for the
significant inconsistency window is
standards for the layered
inconsistency window is the
for the layered architecture
window is the node
the layered architecture we
is the node that
layered architecture we ve
the node that failed
architecture we ve outlined
note that when the
the task isn t
that when the failed
task isn t really
when the failed node
isn t really all
data points are medians
t really all that
points are medians and
really all that daunting
are medians and error
the failed node rejoins
medians and error bars
and error bars bound
error bars bound the
the designers of microsoft
queries are performed against
designers of microsoft s
are performed against its
of microsoft s object
performed against its data
microsoft s object linking
against its data before
s object linking and
its data before it
object linking and embedding
data before it has
before it has time
it has time to
has time to fully
time to fully recover
standard faced similar challenges
once the chain is
the chain is restored
all new updates are
new updates are received
their ole interfaces are
ole interfaces are pervasively
interfaces are pervasively used
there were rare cases
this could work well
are pervasively used to
could work well if
were rare cases when
work well if a
pervasively used to support
well if a system
rare cases when gossip
if a system has
used to support thousands
a system has multiple
cases when gossip circumvented
system has multiple classes
to support thousands of
has multiple classes of
when gossip circumvented the
multiple classes of objects
support thousands of plugins
gossip circumvented the chain
thousands of plugins that
circumvented the chain replication
of plugins that implement
the chain replication even
plugins that implement context
all clustered but with
that implement context menus
chain replication even though
clustered but with different
replication even though the
but with different associated
even though the chain
with different associated clustering
though the chain was
different associated clustering properties
the chain was not
virtual folders and various
chain was not broken
folders and various namespace
and various namespace extensions
but this happened only
and drag and drop
this happened only for
drag and drop technologies
happened only for gossip
only for gossip rates
for gossip rates close
gossip rates close to
lacking the needed standards
rates close to the
close to the update
to the update injection
the update injection rate
later in this section
the live objects platform
in this section we
live objects platform supports
this section we will
objects platform supports both
section we will show
platform supports both options
we will show that
supports both options today
will show that even
show that even with
that even with these
even with these rapid
with these rapid repairs
in addition to allowing
addition to allowing hosted
to allowing hosted content
allowing hosted content to
the gossip overhead is
hosted content to be
gossip overhead is actually
content to be pulled
overhead is actually low
to be pulled in
be pulled in and
pulled in and exposed
in and exposed via
and exposed via event
exposed via event interfaces
consistent inconsistent aborted ab
inconsistent aborted ab ev
aborted ab ev re
components developed by some
ab ev re ab
developed by some of
ev re ab ev
by some of our
re ab ev re
some of our users
ab ev re i
of our users also
ev re i i
our users also use
re i i tr
users also use embedded
i i tr tr
also use embedded minibrowsers
i tr tr o
use embedded minibrowsers to
of the messages were
tr tr o o
embedded minibrowsers to gain
tr o o rt
the messages were delivered
o o rt ct
minibrowsers to gain access
o rt ct rt
messages were delivered by
to gain access to
rt ct rt ct
gain access to a
ct rt ct y
access to a wide
rt ct y y
to a wide range
ct y y amazon
were delivered by gossip
y y amazon orkut
a wide range of
delivered by gossip ahead
wide range of platforms
y amazon orkut fig
by gossip ahead of
gossip ahead of the
ahead of the chain
of the chain for
the chain for gossip
chain for gossip rate
for gossip rate identical
gossip rate identical to
rate identical to the
identical to the update
to the update injection
the update injection rate
the efficacy of t
cache as a function
as a function of
a function of the
function of the inconsistency
of the inconsistency handling
the inconsistency handling strategy
inconsistency handling strategy for
handling strategy for realistic
contains a plot of
strategy for realistic workloads
a plot of update
plot of update injection
of update injection time
update injection time against
injection time against update
time against update delivery
against update delivery time
update delivery time for
performance evaluation central to
delivery time for the
evaluation central to our
time for the victim
for the victim node
much work has been
central to our argument
work has been done
to our argument is
has been done on
our argument is the
been done on creating
ideally this is a
done on creating consistent
this is a straight
argument is the assertion
is a straight line
on creating consistent caches
is the assertion that
a straight line because
creating consistent caches for
straight line because of
consistent caches for web
the assertion that hosted
caches for web servers
line because of chain
assertion that hosted event
because of chain replication
that hosted event notification
hosted event notification solutions
event notification solutions scale
notification solutions scale poorly
note that once the
solutions scale poorly and
that once the victim
scale poorly and stand
once the victim node
poorly and stand as
the victim node recovers
and stand as a
stand as a barrier
as a barrier to
a barrier to collaboration
barrier to collaboration applications
it gracefully catches up
gracefully catches up and
catches up and does
up and does so
and that developers will
and does so quickly
that developers will want
does so quickly for
developers will want to
so quickly for both
will want to combine
quickly for both gossip
want to combine hosted
for both gossip rates
to combine hosted content
both gossip rates identical
combine hosted content with
gossip rates identical and
hosted content with p
rates identical and half
identical and half the
and half the update
half the update injection
the update injection rate
p protocols to overcome
protocols to overcome these
to overcome these problems
now consider the link
consider the link congestion
the link congestion case
in this section we
this section we present
section we present data
we present data to
present data to support
data to support our
to support our claims
some of the results
are drawn from a
drawn from a widely
from a widely cited
a widely cited industry
widely cited industry whitepaper
and were obtained using
were obtained using a
obtained using a testing
using a testing methodology
a testing methodology and
testing methodology and setup
methodology and setup developed
and setup developed and
setup developed and published
developed and published by
and published by sonic
published by sonic software
the remainder was produced
remainder was produced in
was produced in our
produced in our own
in our own experiments
from the industry white
the industry white paper
analyzes the performance of
the performance of several
performance of several commercial
of several commercial enterprise
several commercial enterprise service
commercial enterprise service bus
and higher level objects
shown is the maximum
is the maximum throughput
the experiment varies the
experiment varies the number
such systems consider only
varies the number of
systems consider only one
the number of subscribers
consider only one object
number of subscribers while
only one object at
of subscribers while using
one object at a
object at a time
subscribers while using a
while using a single
using a single publisher
a single publisher that
and only individual read
single publisher that communicates
only individual read and
publisher that communicates through
individual read and write
that communicates through a
read and write operations
communicates through a single
through a single hosted
a single hosted message
single hosted message broker
hosted message broker on
as they do not
message broker on a
they do not support
broker on a single
do not support a
on a single topic
not support a transactional
support a transactional interface
there are few if
are few if any
few if any multi
figured for message durability
even if a subscriber
if a subscriber experiences
a subscriber experiences a
subscriber experiences a transient
experiences a transient loss
a transient loss of
these systems generally try
transient loss of connectivity
systems generally try to
generally try to avoid
try to avoid staleness
to avoid staleness through
avoid staleness through techniques
the publisher retains and
staleness through techniques such
publisher retains and hence
through techniques such as
retains and hence can
techniques such as time
and hence can replay
hence can replay all
can replay all messages
as the number of
the number of subscribers
number of subscribers increases
latency will also soars
will also soars because
also soars because the
soars because the amount
our work considers multi
because the amount of
the amount of time
amount of time the
object transactional consistency of
of time the broker
transactional consistency of cache
time the broker needs
consistency of cache access
the broker needs to
broker needs to spend
needs to spend sending
to spend sending a
spend sending a single
sending a single message
a single message increases
single message increases linearly
message increases linearly with
increases linearly with the
linearly with the number
with the number of
early work on scalable
the number of subscribers
work on scalable database
on scalable database caching
scalable database caching mostly
database caching mostly ignored
caching mostly ignored transactional
mostly ignored transactional consistency
durability is often not
is often not required
shows throughput in an
throughput in an experiment
in an experiment in
work has been done
an experiment in which
has been done on
experiment in which the
been done on creating
in which the publisher
done on creating consistent
which the publisher does
on creating consistent caches
the publisher does not
creating consistent caches for
publisher does not log
consistent caches for databases
does not log data
a disconnected subscriber would
disconnected subscriber would experience
subscriber would experience a
would experience a loss
extends a centralized database
we find that while
a centralized database with
find that while the
centralized database with support
that while the maximum
database with support for
while the maximum throughput
with support for caches
the maximum throughput is
support for caches that
maximum throughput is much
for caches that provide
throughput is much higher
caches that provide snapshot
that provide snapshot isolation
provide snapshot isolation semantics
the degradation of performance
degradation of performance is
of performance is even
albeit the snapshots seen
performance is even more
the snapshots seen may
is even more dramatic
snapshots seen may be
seen may be stale
to improve the commit
improve the commit rate
the commit rate for
commit rate for read
developers of collaboration applications
of collaboration applications that
collaboration applications that need
applications that need good
that need good scalability
need good scalability might
good scalability might discover
scalability might discover that
might discover that hosted
discover that hosted esb
that hosted esb options
where the cache holds
hosted esb options won
the cache holds several
esb options won t
cache holds several versions
options won t achieve
holds several versions of
won t achieve this
several versions of an
t achieve this goal
versions of an object
of an object and
an object and enables
object and enables the
and enables the cache
enables the cache to
the cache to choose
cache to choose a
we report on some
to choose a version
report on some experiments
choose a version that
on some experiments we
a version that allows
some experiments we conducted
version that allows a
experiments we conducted on
that allows a transaction
we conducted on our
allows a transaction to
conducted on our own
a transaction to commit
on our own at
our own at cornell
this technique could also
technique could also be
focusing on scalability of
could also be used
on scalability of event
also be used with
scalability of event notification
be used with our
of event notification platforms
used with our solution
event notification platforms that
notification platforms that leverage
platforms that leverage peer
peer techniques for dissemination
techniques for dissemination and
for dissemination and recovery
on the first graph
we compare the maximum
compare the maximum throughput
the maximum throughput of
maximum throughput of two
throughput of two decentralized
of two decentralized reliable
two decentralized reliable multicast
decentralized reliable multicast protocols
also support snapshot isolation
but can be used
can be used with
be used with any
used with any backend
with any backend database
including ones that are
ones that are sharded
that are sharded and
a single topic and
single topic and a
topic and a single
and a single publisher
unlike in the previous
in the previous tests
provides a transactionally consistent
a transactionally consistent cache
transactionally consistent cache for
consistent cache for the
cache for the jboss
for the jboss middleware
these experiments used a
support transactions on cached
transactions on cached enterprise
on cached enterprise javabeans
this limits the peak
limits the peak performance
the peak performance to
allows update transactions to
update transactions to read
transactions to read stale
to read stale data
read stale data out
stale data out of
data out of caches
out of caches and
of caches and provide
caches and provide bounds
and provide bounds on
provide bounds on how
bounds on how much
on how much staleness
how much staleness is
much staleness is allowed
these techniques require fast
techniques require fast communication
require fast communication between
fast communication between the
achieves stable high throughput
communication between the cache
between the cache and
the cache and the
cache and the database
and the database for
the database for good
database for good performance
in our work caches
our work caches are
work caches are asynchronously
caches are asynchronously updated
runs at about a
at about a fifth
about a fifth that
a fifth that speed
collapsing as the number
as the number of
the number of subscribers
number of subscribers increases
which is how caches
is how caches currently
how caches currently work
caches currently work in
currently work in large
work in large multi
at small loss rates
latency in qsm is
in qsm is at
qsm is at the
is at the level
at the level of
f uture d irections
uture d irections the
d irections the dependency
irections the dependency list
the dependency list sizes
dependency list sizes for
list sizes for all
sizes for all objects
for all objects in
all objects in t
cache are currently all
are currently all of
currently all of the
ms irrespectively of the
all of the same
irrespectively of the number
of the same maximum
of the number of
the same maximum length
the number of subscribers
this may not be
when the number of
may not be optimal
the number of topics
number of topics is
of topics is varied
update delay as seen
qsm maintains its high
delay as seen by
maintains its high performance
as seen by individual
if the workload accesses
seen by individual processes
the workload accesses objects
by individual processes during
workload accesses objects in
individual processes during persistent
accesses objects in clusters
processes during persistent link
objects in clusters of
on the second graph
in clusters of different
during persistent link congestion
clusters of different sizes
persistent link congestion node
objects of larger clusters
of larger clusters call
larger clusters call for
clusters call for longer
call for longer dependency
for longer dependency lists
we report performance for
once appropriate real workloads
appropriate real workloads are
updates on upstream and
real workloads are available
on upstream and downstream
upstream and downstream fifo
and downstream fifo channels
it may be possible
may be possible to
be possible to improve
possible to improve performance
to improve performance by
improve performance by dynamically
but performance for other
performance by dynamically changing
performance for other group
by dynamically changing per
for other group sizes
other group sizes is
group sizes is similar
object dependency list sizes
jgroups performance was higher
performance was higher with
was higher with smaller
higher with smaller group
balancing between objects to
with smaller group sizes
between objects to maintain
objects to maintain the
to maintain the same
maintain the same overall
the same overall space
same overall space overhead
but erodes as the
erodes as the number
as the number of
the number of topics
number of topics increases
another option is to
option is to explore
is to explore an
jgroups failed when we
to explore an approach
failed when we attempted
explore an approach in
when we attempted to
an approach in which
we attempted to configure
approach in which each
attempted to configure it
in which each type
to configure it with
which each type of
configure it with more
each type of object
it with more than
type of object would
of object would have
object would have its
would have its own
have its own dependency
its own dependency list
own dependency list bound
we look at two
look at two scalable
at two scalable protocols
agnostic and treats all
two scalable protocols under
and treats all objects
scalable protocols under conditions
treats all objects and
protocols under conditions of
all objects and object
under conditions of stress
objects and object relations
and object relations as
object relations as equal
with a focus on
a focus on delivery
focus on delivery latency
using an lru policy
an lru policy to
lru policy to trim
policy to trim the
to trim the list
trim the list of
the list of dependencies
as a fixed message
a fixed message rate
fixed message rate is
message rate is spread
rate is spread over
is spread over varying
spread over varying numbers
over varying numbers of
there may be cases
varying numbers of topics
may be cases in
be cases in which
cases in which the
in which the application
which the application could
the application could explicitly
application could explicitly inform
could explicitly inform the
explicitly inform the cache
inform the cache of
the cache of relevant
subscribers each join some
cache of relevant object
each join some number
of relevant object dependencies
join some number of
some number of topics
and those could then
a publisher sends data
those could then be
publisher sends data at
could then be treated
sends data at a
then be treated as
data at a rate
be treated as more
at a rate of
treated as more important
as more important and
more important and retained
while other less important
other less important ones
less important ones are
important ones are managed
ones are managed by
are managed by some
managed by some other
by some other policy
some other policy such
other policy such as
policy such as lru
selecting the topic in
the topic in which
topic in which to
in which to send
which to send at
in a web album
to send at random
a web album the
web album the set
album the set of
the set of pictures
set of pictures and
of pictures and their
inconsistency window against gossip
pictures and their acl
window against gossip rate
against gossip rate at
and their acl is
gossip rate at the
their acl is an
rate at the failed
acl is an important
at the failed node
is an important dependency
an important dependency whereas
important dependency whereas occasional
dependency whereas occasional tagging
whereas occasional tagging operations
occasional tagging operations that
tagging operations that relate
operations that relate pictures
that relate pictures to
we see that ricochet
relate pictures to users
pictures to users may
to users may be
users may be less
may be less important
it may be straightforward
may be straightforward to
be straightforward to extend
straightforward to extend the
a cornelldeveloped protocol for
to extend the cache
cornelldeveloped protocol for low
extend the cache api
the cache api to
cache api to allow
api to allow the
to allow the application
allow the application to
the application to specify
application to specify such
to specify such dependencies
specify such dependencies and
such dependencies and to
dependencies and to modify
and to modify t
time between node failure
between node failure and
cache to respect them
node failure and rejoin
failure and rejoin as
and rejoin as number
rejoin as number of
as number of consecutive
number of consecutive updates
of consecutive updates missed
consecutive updates missed by
updates missed by the
missed by the victim
c onclusion existing large
by the victim node
as the number of
the number of topics
number of topics increases
of topics increases to
scale computing frameworks make
computing frameworks make heavy
frameworks make heavy use
make heavy use of
heavy use of edge
use of edge caches
of edge caches to
edge caches to reduce
caches to reduce client
to reduce client latency
but this form of
this form of caching
form of caching has
of caching has not
caching has not been
has not been available
not been available for
been available for transactional
available for transactional applications
we believe this is
believe this is one
this is one reason
latency soars when we
is one reason that
soars when we repeat
one reason that transactions
when we repeat this
reason that transactions are
we repeat this with
that transactions are generally
repeat this with the
transactions are generally not
this with the industrystandard
are generally not considered
with the industrystandard scalable
generally not considered to
the industrystandard scalable reliable
not considered to be
industrystandard scalable reliable multicast
considered to be a
to be a viable
be a viable option
a viable option in
viable option in extremely
option in extremely large
in extremely large systems
widely used for event
used for event notification
for event notification in
event notification in their
notification in their datacenters
a variant of serializability
variant of serializability that
of serializability that is
as can be seen
serializability that is suitable
can be seen in
that is suitable for
be seen in the
is suitable for incoherent
seen in the graph
suitable for incoherent caches
srm s recovery latency
which cannot communicate with
s recovery latency rises
cannot communicate with the
recovery latency rises linearly
communicate with the backend
latency rises linearly in
with the backend database
rises linearly in the
the backend database on
linearly in the figure
backend database on every
database on every read
on every read access
scalability of commercial esbs
of commercial esbs figure
we then presented t
scalability of commercial esbs
of commercial esbs number
commercial esbs number of
esbs number of topics
an architecture for controlling
architecture for controlling transaction
for controlling transaction consistency
controlling transaction consistency with
transaction consistency with caches
the system extends the
system extends the edge
extends the edge cache
the edge cache by
edge cache by allowing
cache by allowing it
by allowing it to
allowing it to offer
it to offer a
to offer a transactional
offer a transactional interface
we believe that t
our experiments confirm that
cache is the first
is the first transaction
hosted enterprise service bus
enterprise service bus architectures
service bus architectures can
bus architectures can achieve
aware caching architecture in
architectures can achieve high
caching architecture in which
can achieve high levels
architecture in which caches
achieve high levels of
in which caches are
high levels of publish
which caches are updated
caches are updated asynchronously
subscribe performance for small
performance for small numbers
for small numbers of
small numbers of subscribers
a lookup request only
lookup request only requires
request only requires a
but performance degrades very
only requires a round
performance degrades very sharply
degrades very sharply as
very sharply as the
sharply as the number
as the number of
trip to the database
the number of subscribers
to the database in
number of subscribers or
the database in case
of subscribers or topics
database in case there
subscribers or topics grows
in case there is
case there is a
there is a cache
is a cache miss
the jgroups and srm
a cache miss there
jgroups and srm platforms
cache miss there is
miss there is no
there is no additional
is no additional traffic
which don t leverage
no additional traffic and
don t leverage peer
additional traffic and delays
traffic and delays to
and delays to ensure
delays to ensure cache
to ensure cache coherence
scale poorly in the
poorly in the number
cache associates dependency information
in the number of
associates dependency information with
the number of subscribers
dependency information with cached
number of subscribers or
information with cached database
of subscribers or topics
with cached database objects
while leaving the interaction
leaving the interaction between
the interaction between the
interaction between the backend
between the backend systems
the backend systems and
scale well in these
backend systems and the
well in these dimensions
systems and the cache
and the cache otherwise
the cache otherwise unchanged
ricochet achieved the best
achieved the best recovery
the best recovery latency
this information includes version
best recovery latency when
information includes version identifiers
recovery latency when message
includes version identifiers and
latency when message loss
version identifiers and bounded
when message loss is
message loss is an
loss is an issue
but at relatively high
at relatively high overhead
with this modest amount
this modest amount of
modest amount of additional
amount of additional information
not shown on these
shown on these graphs
we show that inconsistency
show that inconsistency can
that inconsistency can be
inconsistency can be greatly
can be greatly reduced
qsm at small loss
be greatly reduced or
at small loss rates
greatly reduced or even
small loss rates achieves
reduced or even completely
loss rates achieves similar
or even completely eliminated
rates achieves similar average
even completely eliminated in
achieves similar average latency
completely eliminated in some
similar average latency with
eliminated in some cases
average latency with considerably
latency with considerably lower
with considerably lower network
considerably lower network overheads
but if a packet
cache is intended for
if a packet is
is intended for clustered
a packet is lost
intended for clustered workloads
gossip chain inconsistency window
it may take several
and those arise naturally
may take several seconds
those arise naturally in
take several seconds to
arise naturally in social
several seconds to recover
naturally in social networks
seconds to recover it
making it less appropriate
it less appropriate for
less appropriate for time
mobile applications with spatial
applications with spatial locality
we don t see
don t see any
t see any single
see any single winner
our experiments demonstrate t
any single winner here
cache to be effective
each of the solutions
to be effective in
of the solutions tested
be effective in realistic
the solutions tested has
effective in realistic workloads
solutions tested has some
in realistic workloads based
tested has some advantages
realistic workloads based on
has some advantages that
workloads based on datasets
some advantages that its
based on datasets from
advantages that its competitors
on datasets from amazon
that its competitors lack
datasets from amazon and
from amazon and orkut
using dependency lists of
dependency lists of size
we re currently developing
re currently developing new
currently developing new p
it builds an overlay
builds an overlay multicast
an overlay multicast tree
overlay multicast tree within
multicast tree within which
tree within which events
within which events travel
and was also able
was also able to
also able to increase
and is capable of
able to increase consistent
is capable of selforganizing
to increase consistent transaction
capable of selforganizing in
increase consistent transaction rate
of selforganizing in the
consistent transaction rate by
selforganizing in the presence
in the presence of
the presence of firewalls
a separate project is
with only nominal overhead
separate project is creating
only nominal overhead on
project is creating a
nominal overhead on the
is creating a protocol
overhead on the database
creating a protocol suite
a protocol suite that
protocol suite that we
suite that we call
that we call the
our experiments with synthetic
we call the properties
experiments with synthetic workloads
call the properties framework
with synthetic workloads showed
synthetic workloads showed that
workloads showed that t
cache s efficacy depends
s efficacy depends on
efficacy depends on the
inconsistency window against gossip
depends on the clustering
window against gossip rate
on the clustering level
against gossip rate for
the clustering level of
gossip rate for the
clustering level of the
rate for the whole
level of the workload
for the whole chain
the goal is to
goal is to offer
is to offer strong
to offer strong forms
offer strong forms of
strong forms of reliability
cache adapts to dynamically
forms of reliability that
adapts to dynamically changing
of reliability that can
to dynamically changing workloads
reliability that can be
dynamically changing workloads where
that can be customized
changing workloads where clusters
can be customized for
workloads where clusters change
be customized for special
where clusters change over
customized for special needs
clusters change over time
due to resource limitations
to resource limitations t
speed and scalability are
and scalability are only
scalability are only elements
cache maintains only a
are only elements of
maintains only a short
only elements of a
only a short dependency
elements of a broader
a short dependency list
of a broader story
which is naturally imperfect
developers will need different
is naturally imperfect and
will need different solutions
naturally imperfect and does
need different solutions for
imperfect and does not
different solutions for different
and does not include
solutions for different purposes
does not include all
not include all dependencies
by offering a flexible
offering a flexible yet
time between node failure
a flexible yet structured
we proved that when
flexible yet structured component
proved that when resources
yet structured component mashup
that when resources are
structured component mashup environment
when resources are unbounded
between node failure and
node failure and rejoin
failure and rejoin as
and rejoin as number
live objects makes it
rejoin as number of
objects makes it possible
as number of consecutive
makes it possible to
number of consecutive updates
it possible to create
of consecutive updates missed
cache s algorithm implements
consecutive updates missed by
possible to create applications
updates missed by the
s algorithm implements cache
missed by the victim
to create applications that
by the victim node
create applications that mix
applications that mix hosted
that mix hosted with
mix hosted with p
and that can adapt
that can adapt their
can adapt their behavior
to achieve desired properties
achieve desired properties in
desired properties in a
properties in a way
in a way matched
a way matched to
way matched to the
matched to the environment
scalability of qsm and
of qsm and jgroups
throughput for various group
for various group sizes
prior work the idea
work the idea of
the idea of integrating
idea of integrating web
inconsistency window against the
of integrating web services
window against the ratio
integrating web services with
against the ratio between
web services with peer
the ratio between injection
ratio between injection rate
between injection rate and
injection rate and gossip
rate and gossip rate
peer platforms is certainly
platforms is certainly not
is certainly not new
different update injection delay
s overload by dropping
overload by dropping updates
by dropping updates on
dropping updates on its
updates on its inbound
on its inbound and
its inbound and outbound
inbound and outbound fifo
and outbound fifo channels
outbound fifo channels according
fifo channels according to
channels according to a
according to a random
to a random distribution
a random distribution throughout
random distribution throughout the
distribution throughout the first
throughout the first three
the first three quarters
first three quarters of
three quarters of the
quarters of the experiment
and we report on
updates that were initially
that were initially dropped
were initially dropped and
initially dropped and eventually
dropped and eventually made
and eventually made their
eventually made their way
made their way through
their way through gossip
way through gossip could
through gossip could later
gossip could later be
could later be sent
later be sent via
be sent via fifo
sent via fifo channels
via fifo channels as
the existing work falls
fifo channels as shown
existing work falls roughly
channels as shown by
work falls roughly into
as shown by the
falls roughly into two
shown by the increasingly
roughly into two categories
by the increasingly large
the increasingly large density
increasingly large density of
large density of dark
the first line of
first line of research
line of research is
of research is focused
research is focused on
is focused on the
focused on the use
on the use of
the use of peer
plots closer to the
closer to the tail
to the tail of
the tail of the
tail of the chain
as before note that
before note that the
note that the yaxes
that the yaxes have
the yaxes have different
yaxes have different scales
as a basis for
have different scales to
a basis for scalable
different scales to observe
basis for scalable web
scales to observe the
for scalable web service
to observe the delays
scalable web service discovery
observe the delays better
the second line of
the figures show that
second line of research
figures show that even
line of research concentrates
show that even for
of research concentrates on
that even for a
research concentrates on the
even for a gossip
concentrates on the use
for a gossip rate
on the use of
a gossip rate half
the use of replication
gossip rate half the
use of replication protocols
rate half the injection
of replication protocols at
half the injection rate
replication protocols at the
protocols at the web
at the web service
the web service backend
web service backend to
recall that this is
service backend to achieve
that this is the
backend to achieve fault
this is the rate
is the rate at
the rate at which
rate at which digests
are exchanged between two
exchanged between two or
between two or more
two or more processes
p platforms such as
platforms such as jxta
the epidemics could deliver
such as jxta are
epidemics could deliver messages
as jxta are treated
could deliver messages with
jxta are treated not
deliver messages with a
are treated not as
messages with a delay
treated not as means
with a delay of
not as means of
a delay of about
as means of collaboration
means of collaboration or
of collaboration or media
collaboration or media carrying
or media carrying live
media carrying live content
but rather as a
rather as a supporting
as a supporting infrastructure
a supporting infrastructure at
supporting infrastructure at the
infrastructure at the data
at the data center
the data center backend
our work is focused
work is focused on
is focused on blending
focused on blending the
s for the rest
on blending the content
for the rest of
blending the content available
the rest of the
the content available through
rest of the chain
content available through p
of the chain during
the chain during a
chain during a congestion
during a congestion that
a congestion that took
p and web service
and web service protocols
neither technology is subordinate
technology is subordinate with
is subordinate with respect
subordinate with respect to
with respect to the
respect to the other
the plot also shows
plot also shows that
also shows that delays
shows that delays increased
technologies that use peer
that delays increased with
delays increased with time
therefore if congestion may
if congestion may span
congestion may span large
peer protocols to support
may span large periods
protocols to support live
span large periods of
to support live and
large periods of time
support live and interactive
live and interactive content
and interactive content have
google s globally distributed
interactive content have existed
s globally distributed database
the gossip rate must
content have existed earlier
gossip rate must be
rate must be carefully
acm transactions on computer
must be carefully tuned
transactions on computer systems
be carefully tuned to
an excellent example of
carefully tuned to compensate
excellent example of such
tuned to compensate for
example of such technology
to compensate for the
of such technology is
compensate for the losses
such technology is the
for the losses induced
technology is the croquet
the losses induced by
losses induced by the
induced by the congested
by the congested tcp
the congested tcp channels
the second round of
second round of experiments
round of experiments quantified
of experiments quantified the
experiments quantified the average
quantified the average and
the average and maximum
average and maximum inconsistency
in which the entire
and maximum inconsistency window
which the entire state
maximum inconsistency window for
the entire state of
inconsistency window for a
entire state of a
window for a service
state of a virtual
d world is stored
world is stored in
is stored in a
stored in a peer
under various update injection
peer fashion and updated
various update injection rates
fashion and updated using
update injection rates and
and updated using a
injection rates and gossip
updated using a two
rates and gossip rates
and gossip rates respectively
we define the inconsistency
define the inconsistency window
other work in this
work in this direction
the inconsistency window as
in this direction includes
inconsistency window as the
window as the time
as the time interval
the time interval during
time interval during which
interval during which queries
during which queries against
which queries against the
queries against the service
against the service return
the service return a
service return a stale
return a stale value
shows that the inconsistency
none of these systems
that the inconsistency window
of these systems supports
the inconsistency window grows
these systems supports the
inconsistency window grows slowly
systems supports the sorts
window grows slowly as
supports the sorts of
grows slowly as the
the sorts of componentized
slowly as the gap
as the gap between
the gap between the
gap between the update
layered architectures that we
between the update injection
architectures that we have
the update injection rate
that we have advocated
update injection rate and
we have advocated here
injection rate and the
rate and the gossip
and the gossip rate
the gossip rate widens
the types of peer
the graph s x
graph s x axis
s x axis represents
x axis represents the
peer protocols these systems
axis represents the ratio
protocols these systems can
represents the ratio between
these systems can leverage
the ratio between the
ratio between the update
between the update injection
the update injection rate
update injection rate and
and the types of
injection rate and gossip
the types of a
rate and gossip rate
types of a traditional
of a traditional hosted
a traditional hosted content
traditional hosted content they
hosted content they can
content they can blend
they can blend with
can blend with their
this confirms that epidemics
blend with their p
confirms that epidemics are
that epidemics are a
epidemics are a robust
are a robust tunable
a robust tunable mechanism
robust tunable mechanism providing
distributed data structures over
tunable mechanism providing graceful
data structures over a
mechanism providing graceful degradation
structures over a shared
over a shared log
in proceedings of the
our platform is designed
platform is designed from
the inconsistency window shifts
is designed from ground
inconsistency window shifts in
designed from ground up
window shifts in accordance
from ground up with
shifts in accordance with
ground up with extensibility
in accordance with the
th acm symposium on
up with extensibility in
acm symposium on operating
accordance with the update
symposium on operating systems
with extensibility in mind
on operating systems principles
with the update injection
the update injection rate
every part of it
part of it can
of it can be
it can be replaced
can be replaced and
be replaced and customized
notice that the difference
that the difference between
the difference between the
and different components within
difference between the maximum
different components within a
between the maximum inconsistency
components within a single
the maximum inconsistency window
within a single mashup
maximum inconsistency window and
a single mashup application
inconsistency window and the
single mashup application can
window and the average
mashup application can leverage
and the average inconsistency
application can leverage different
the average inconsistency window
can leverage different transport
average inconsistency window is
leverage different transport protocols
inconsistency window is two
window is two orders
is two orders of
two orders of magnitude
prior work on typed
work on typed component
on typed component architectures
typed component architectures includes
this reflects the degree
component architectures includes a
reflects the degree to
architectures includes a tremendous
the degree to which
includes a tremendous variety
degree to which the
a tremendous variety of
to which the victim
tremendous variety of programming
which the victim node
variety of programming languages
the victim node lags
of programming languages and
victim node lags the
programming languages and platforms
node lags the other
lags the other nodes
the other nodes during
other nodes during the
nodes during the period
including early languages such
during the period before
early languages such as
the period before it
languages such as smalltalk
period before it has
such as smalltalk alongside
before it has fully
as smalltalk alongside modern
it has fully caught
smalltalk alongside modern component
has fully caught up
based environments such as
environments such as java
next we evaluated the
we evaluated the inconsistency
evaluated the inconsistency window
the inconsistency window of
inconsistency window of a
window of a service
of a service running
a service running at
service running at a
running at a particular
at a particular update
a particular update rate
specialized component architectures such
component architectures such figure
and for three different
ordering transactions with prediction
for three different intervals
transactions with prediction in
three different intervals in
with prediction in distributed
different intervals in which
prediction in distributed object
scalability qsm and jgroups
in distributed object stores
intervals in which the
in which the victim
which the victim node
the victim node is
victim node is halted
throughput for various numbers
for various numbers of
various numbers of topics
th workshop on large
show average and maximum
scale distributed systems and
average and maximum inconsistency
distributed systems and middleware
and maximum inconsistency windows
maximum inconsistency windows for
inconsistency windows for both
windows for both the
for both the victim
both the victim and
the victim and for
victim and for the
and for the other
for srm and ricochet
for the other processes
srm and ricochet with
the other processes of
and ricochet with varying
other processes of one
ricochet with varying numbers
processes of one subservice
with varying numbers of
varying numbers of topics
as mit s argus
mit s argus system
the more messages the
more messages the victim
messages the victim node
flexible protocol composition stacks
the victim node needs
protocol composition stacks such
victim node needs to
composition stacks such as
node needs to recover
stacks such as bast
the larger the inconsistency
larger the inconsistency window
again the difference between
the difference between the
difference between the average
between the average and
the average and maximum
average and maximum in
oriented architectures such as
architectures such as juni
has been used in
been used in the
used in the context
in the context of
key transactions for key
the context of integrating
context of integrating service
discussion of component integration
of component integration systems
component integration systems and
integration systems and their
systems and their relation
and their relation to
their relation to live
relation to live objects
is beyond the scope
beyond the scope of
the scope of this
scope of this paper
more details can be
details can be found
can be found in
much relevant prior work
relevant prior work consists
prior work consists of
work consists of the
consists of the scripting
of the scripting languages
the scripting languages mentioned
scripting languages mentioned in
languages mentioned in the
mentioned in the discussion
in the discussion above
our belief is that
belief is that even
is that even though
that even though these
even though these languages
though these languages are
these languages are intended
languages are intended for
are intended for fairly
intended for fairly general
for fairly general use
they have evolved to
have evolved to focus
evolved to focus on
to focus on minibrowser
focus on minibrowser situations
on minibrowser situations in
minibrowser situations in which
situations in which the
in which the application
which the application lives
the application lives within
application lives within a
lives within a dedicated
within a dedicated browser
a dedicated browser frame
interacts directly with the
directly with the user
and cannot be mixed
cannot be mixed with
be mixed with content
mixed with content from
with content from other
content from other sources
from other sources in
other sources in a
sources in a layered
in a layered fashion
live objects can support
objects can support minibrowsers
can support minibrowsers as
support minibrowsers as objects
but we ve argued
we ve argued that
ve argued that by
argued that by modeling
that by modeling hosted
by modeling hosted content
facebook s distributed data
modeling hosted content at
s distributed data store
hosted content at a
distributed data store for
content at a lower
data store for the
at a lower level
store for the social
a lower level as
for the social graph
lower level as components
level as components that
as components that interact
components that interact via
in usenix annual technical
that interact via events
usenix annual technical conference
interact via events and
via events and focusing
events and focusing on
and focusing on the
focusing on the multi
layered style of mashups
style of mashups as
of mashups as opposed
mashups as opposed to
as opposed to the
opposed to the standard
to the standard tiled
the standard tiled model
conclusions to build ambitious
to build ambitious collaboration
build ambitious collaboration application
the web services community
web services community will
services community will need
community will need ways
will need ways to
need ways to combine
content from multiple sources
these include hosted sources
include hosted sources that
hosted sources that run
sources that run in
that run in data
run in data centers
in data centers and
data centers and support
centers and support web
and support web services
support web services interfaces
but also direct peer
peer protocols capable of
protocols capable of transporting
capable of transporting audio
whiteboard data and other
data and other content
and other content at
other content at high
content at high data
at high data rates
delivery distribution for a
distribution for a chain
a further need is
further need is to
need is to allow
is to allow disconnected
to allow disconnected collaboration
gossip rate left figure
back to data centers
our review of the
review of the performance
of the performance of
the performance of enterprise
performance of enterprise service
of enterprise service bus
enterprise service bus eventing
service bus eventing solutions
bus eventing solutions in
eventing solutions in the
scaling memcache at facebook
solutions in the standard
in the standard hosted
the standard hosted web
standard hosted web services
hosted web services model
web services model made
services model made it
model made it clear
th usenix symposium on
made it clear that
usenix symposium on networked
it clear that hosted
symposium on networked systems
on networked systems design
clear that hosted event
networked systems design and
that hosted event channels
systems design and implementation
hosted event channels won
event channels won t
channels won t have
won t have the
t have the scalability
have the scalability and
the scalability and latency
scalability and latency properties
and latency properties needed
latency properties needed by
properties needed by many
needed by many applications
on each graph left
each graph left bars
graph left bars denote
left bars denote transient
bars denote transient failure
p alternatives often achieve
alternatives often achieve far
often achieve far better
achieve far better scalability
right bars denote a
bars denote a transient
denote a transient failure
a transient failure corroborated
transient failure corroborated with
failure corroborated with a
they also have security
corroborated with a link
also have security advantages
with a link congestion
a link congestion phenomenon
link congestion phenomenon modeled
congestion phenomenon modeled by
the data center doesn
data center doesn t
center doesn t get
doesn t get a
t get a chance
get a chance to
a chance to see
message drop on the
drop on the adjacent
on the adjacent fifo
the adjacent fifo channels
adjacent fifo channels of
fifo channels of node
the live objects platform
live objects platform can
objects platform can seamlessly
platform can seamlessly support
can seamlessly support applications
seamlessly support applications that
support applications that require
applications that require a
that require a mixture
require a mixture of
a mixture of data
mixture of data sources
including both hosted and
both hosted and direct
hosted and direct p
further benefits include an
benefits include an easy
include an easy to
an easy to use
easy to use drag
drop programming style that
programming style that yields
style that yields applications
that yields applications represented
yields applications represented as
applications represented as xml
represented as xml files
which can be shared
can be shared as
be shared as files
shared as files or
as files or even
files or even via
or even via email
users that open such
that open such files
open such files find
such files find themselves
files find themselves immersed
find themselves immersed in
themselves immersed in a
immersed in a mediarich
in a mediarich collaborative
a mediarich collaborative environment
mediarich collaborative environment that
collaborative environment that also
environment that also offers
that also offers strong
also offers strong reliability
in the near future
most important of all
live objects are real
the platform is available
platform is available for
transactional consistency and automatic
is available for free
consistency and automatic management
available for free download
and automatic management in
for free download from
automatic management in an
free download from cornell
management in an application
in an application data
an application data cache
th usenix symposium on
usenix symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
lateral error correction for
error correction for time
fast iterative graph computation
iterative graph computation with
graph computation with block
computation with block updates
of the vldb endowment
we found that less
found that less than
of the messages were
the messages were delivered
messages were delivered by
were delivered by gossip
delivered by gossip for
exploiting gossip for self
by gossip for the
gossip for the nodes
for the nodes to
the nodes to the
nodes to the left
management in scalable event
to the left of
in scalable event notification
the left of the
scalable event notification systems
left of the victim
this confirms that gossip
confirms that gossip rarely
that gossip rarely is
gossip rarely is used
rarely is used to
is used to circumvent
used to circumvent chain
to circumvent chain replication
circumvent chain replication in
chain replication in the
replication in the normal
in the normal case
a peculiar effect is
peculiar effect is noticeable
effect is noticeable in
is noticeable in figure
semantic integration of web
in that more messages
integration of web services
that more messages are
of web services and
more messages are delivered
web services and peer
messages are delivered via
are delivered via gossip
concurrency control and recovery
even in the prefix
control and recovery in
in the prefix part
and recovery in database
the prefix part of
recovery in database systems
prefix part of the
peer networks to achieve
part of the chain
networks to achieve fault
although the effect is
the effect is also
effect is also evident
is also evident in
also evident in the
evident in the suffix
it is more significant
is more significant on
more significant on the
significant on the left
on the left hand
the left hand side
left hand side figure
where the gossip rate
the gossip rate is
gossip rate is higher
because we observed this
we observed this phenomenon
observed this phenomenon only
this phenomenon only with
phenomenon only with update
only with update rates
with update rates of
flexible protocol composition in
protocol composition in bast
we suspect that the
suspect that the network
that the network stack
the network stack is
network stack is more
stack is more efficient
is more efficient in
more efficient in dealing
efficient in dealing with
in dealing with udp
dealing with udp packets
with udp packets then
udp packets then with
packets then with tcp
then with tcp ones
with tcp ones under
tcp ones under heavy
ones under heavy load
the dynamics of viral
dynamics of viral marketing
acm transactions on the
transactions on the web
self organizing live objects
delivery distribution for a
distribution for a chain
jms performance comparison for
performance comparison for publish
comparison for publish subscribe
for publish subscribe messaging
fiorano software technologies pvt
measurement and analysis of
and analysis of online
analysis of online social
of online social networks
in proceedings of the
th acm sigcomm conference
acm sigcomm conference on
sigcomm conference on internet
conference on internet measurement
consistency windows is slightly
leveraging collaboration of peer
windows is slightly more
is slightly more than
slightly more than an
more than an order
than an order of
an order of magnitude
peer and web services
and this is attributable
this is attributable to
is attributable to the
attributable to the victim
to the victim node
the victim node observe
victim node observe that
node observe that the
observe that the two
that the two graphs
the two graphs denoting
two graphs denoting the
graphs denoting the maximum
denoting the maximum inconsistency
the maximum inconsistency windows
maximum inconsistency windows for
inconsistency windows for the
windows for the victim
for the victim node
the victim node and
victim node and for
node and for the
and for the entire
for the entire chain
the entire chain are
entire chain are identical
which means that clients
means that clients perceiving
that clients perceiving significant
clients perceiving significant inconsistency
perceiving significant inconsistency are
significant inconsistency are the
inconsistency are the ones
based web service composition
are the ones that
web service composition with
the ones that are
service composition with jade
ones that are querying
composition with jade and
that are querying the
with jade and jxta
sampling from large graphs
are querying the victim
querying the victim node
the victim node while
victim node while it
node while it is
in proceedings of the
while it is still
it is still recovering
is still recovering state
finally we performed a
th acm sigkdd international
we performed a set
acm sigkdd international conference
performed a set of
sigkdd international conference on
a set of experiments
international conference on knowledge
set of experiments to
conference on knowledge discovery
of experiments to determine
on knowledge discovery and
experiments to determine the
knowledge discovery and data
to determine the distribution
discovery and data mining
determine the distribution of
the distribution of messages
distribution of messages delivered
of messages delivered by
messages delivered by the
delivered by the chain
by the chain vs
the chain vs delivered
chain vs delivered by
vs delivered by gossip
one transient failure affects
transient failure affects the
failure affects the wall
based architecture for semanticweb
the runs are eight
architecture for semanticweb service
runs are eight times
for semanticweb service automatic
are eight times longer
semanticweb service automatic composition
eight times longer than
times longer than the
longer than the runs
than the runs before
both in total experiment
in total experiment time
total experiment time and
experiment time and time
time and time the
and time the victim
time the victim node
the victim node is
victim node is halted
show the number of
the number of messages
number of messages delivered
of messages delivered by
messages delivered by the
delivered by the chain
by the chain replication
the chain replication mechanism
chain replication mechanism and
replication mechanism and the
mechanism and the ones
and the ones delivered
the ones delivered by
ones delivered by the
delivered by the epidemics
don t settle for
t settle for eventual
for each of the
each of the nodes
of the nodes in
the nodes in a
nodes in a chain
scalable causal consistency for
causal consistency for wide
again we omitted the
area storage with cops
we omitted the head
omitted the head of
the head of the
head of the chain
of the chain node
the chain node because
chain node because its
node because its behavior
because its behavior is
its behavior is not
behavior is not representative
and in this experiment
rd acm symposium on
in this experiment we
acm symposium on operating
this experiment we have
symposium on operating systems
experiment we have chains
on operating systems principles
we have chains of
have chains of length
and jong hoon ahnn
programming with live distributed
with live distributed objects
delivered updates by means
updates by means of
by means of the
means of the gossip
of the gossip repair
the gossip repair mechanism
as the nodes get
the nodes get further
nodes get further away
get further away from
further away from the
away from the victim
from the victim node
more of the messages
of the messages were
the messages were delivered
messages were delivered by
were delivered by means
delivered by means of
by means of the
means of the chain
because the repair mechanism
the repair mechanism relinked
repair mechanism relinked the
mechanism relinked the chain
relinked the chain and
the chain and chain
chain and chain replication
and chain replication began
chain replication began to
achieving reliability through distributed
replication began to function
reliability through distributed data
began to function normally
through distributed data flows
distributed data flows and
data flows and recursive
flows and recursive delegation
transactional storage for geo
the speed with which
speed with which the
with which the chain
which the chain is
the chain is restored
chain is restored depends
is restored depends on
restored depends on the
depends on the rate
on the rate of
the rate of the
rate of the fast
rd acm symposium on
and on the responsiveness
acm symposium on operating
on the responsiveness of
symposium on operating systems
the responsiveness of the
on operating systems principles
responsiveness of the failure
of the failure detection
the failure detection mechanism
future development the current
development the current ssa
the current ssa implementation
current ssa implementation uses
ssa implementation uses gossip
implementation uses gossip in
uses gossip in situations
gossip in situations where
in situations where faster
situations where faster notifications
where faster notifications might
faster notifications might be
notifications might be helpful
we believe that when
believe that when a
that when a node
when a node fails
a node fails or
node fails or joins
it would be useful
would be useful to
be useful to spread
useful to spread the
to spread the news
spread the news as
the news as quickly
news as quickly as
as quickly as possible
we realize that for
realize that for some
that for some particular
for some particular tasks
some particular tasks gossip
particular tasks gossip could
tasks gossip could be
gossip could be done
could be done more
be done more efficiently
we are therefore exploring
are therefore exploring the
therefore exploring the use
exploring the use of
the use of ip
use of ip multicast
of ip multicast for
ip multicast for dissemination
multicast for dissemination of
for dissemination of urgent
dissemination of urgent information
of urgent information as
urgent information as long
information as long as
changtao qu and wolfgang
as long as the
qu and wolfgang nejdl
long as the physical
replicated systems fast as
as the physical nodes
systems fast as possible
the physical nodes are
physical nodes are not
nodes are not on
are not on a
not on a public
on a public network
a public network segment
peer network with web
network with web services
we plan to include
th usenix symposium on
plan to include support
usenix symposium on operating
to include support for
symposium on operating systems
include support for the
on operating systems design
support for the partitioning
operating systems design and
for the partitioning of
systems design and implementation
the partitioning of the
partitioning of the services
of the services by
the services by means
services by means of
by means of registering
means of registering partition
of registering partition function
registering partition function handlers
partition function handlers with
function handlers with a
handlers with a global
with a global data
we have implemented only
have implemented only the
implemented only the server
only the server side
the server side load
server side load balancing
side load balancing scheme
a scalable and ontology
we are considering ways
are considering ways to
considering ways to extend
ways to extend our
to extend our approach
extend our approach for
p infrastructure for semantic
our approach for use
infrastructure for semantic web
approach for use in
for semantic web services
for use in settings
use in settings where
in settings where partitioning
settings where partitioning is
where partitioning is done
partitioning is done on
is done on the
done on the client
on the client side
side access to subservice
access to subservice membership
to subservice membership information
subservice membership information is
membership information is needed
we are also developing
are also developing a
also developing a gui
developing a gui assisted
a gui assisted automated
gui assisted automated web
assisted automated web service
automated web service deployment
web service deployment tool
combining acid and base
acid and base in
focused on web service
and base in a
on web service applications
base in a distributed
in a distributed database
developers could simply drop
could simply drop a
simply drop a wsdl
drop a wsdl service
a wsdl service description
th usenix symposium on
usenix symposium on operating
symposium on operating systems
on operating systems design
a collaboration system architecture
operating systems design and
systems design and implementation
and the system will
the system will generate
system will generate a
will generate a xml
generate a xml description
a xml description that
xml description that can
description that can be
that can be used
can be used later
be used later on
used later on to
later on to actually
on to actually deploy
to actually deploy the
actually deploy the service
deploy the service automatically
the service will be
service will be partitioned
sonic performance test suite
and deployed on the
deployed on the fly
on the fly on
the fly on top
fly on top of
on top of the
top of the processing
of the processing nodes
scaling up to turn
up to turn the
to turn the ssa
turn the ssa into
the ssa into a
ssa into a full
into a full scale
a full scale platform
one of the immediate
of the immediate future
the immediate future challenges
immediate future challenges is
future challenges is the
challenges is the necessity
is the necessity of
the necessity of evaluating
necessity of evaluating a
of evaluating a full
evaluating a full raps
a full raps of
full raps of racs
raps of racs deployment
a shared log design
shared log design for
multiple partitioned and cloned
log design for flash
design for flash clusters
partitioned and cloned services
and cloned services running
cloned services running on
services running on our
running on our tightly
on our tightly coupled
th usenix symposium on
our tightly coupled cluster
usenix symposium on networked
tightly coupled cluster would
symposium on networked systems
coupled cluster would lead
on networked systems design
cluster would lead to
networked systems design and
would lead to a
systems design and implementation
lead to a series
to a series of
a series of other
series of other issues
of other issues that
other issues that should
issues that should be
that should be investigated
placement given a set
given a set of
a set of services
how to place the
to place the clones
place the clones on
the clones on physical
clones on physical nodes
on physical nodes in
physical nodes in order
nodes in order to
in order to satisfy
order to satisfy certain
to satisfy certain constraints
caching placement deciding if
a demonstration of collaborative
placement deciding if some
demonstration of collaborative web
deciding if some services
of collaborative web services
if some services would
collaborative web services and
some services would benefit
web services and peer
services would benefit if
would benefit if they
benefit if they are
if they are fitted
they are fitted with
are fitted with response
fitted with response caches
and ultimately placing the
ultimately placing the cache
placing the cache components
the cache components in
cache components in a
components in a smart
in a smart way
location placing multiple service
placing multiple service clones
multiple service clones on
service clones on the
clones on the same
on the same physical
the same physical node
same physical node to
physical node to exploit
node to exploit fast
to exploit fast ipc
exploit fast ipc communication
fast ipc communication as
ipc communication as opposed
communication as opposed to
as opposed to network
opposed to network messages
to network messages if
network messages if the
p network based architecture
messages if the benefits
network based architecture for
if the benefits overweigh
based architecture for web
the benefits overweigh the
architecture for web service
benefits overweigh the cost
overweigh the cost incurred
the cost incurred by
cost incurred by resource
incurred by resource contention
by resource contention on
resource contention on the
contention on the shared
on the shared host
management tools developing tools
tools developing tools that
developing tools that monitor
tools that monitor service
that monitor service properties
monitor service properties such
service properties such as
properties such as response
such as response time
by restarting new clones
using vmm tricks virtual
vmm tricks virtual machines
tricks virtual machines can
virtual machines can be
machines can be used
can be used to
be used to migrate
used to migrate transparently
to migrate transparently a
migrate transparently a collection
transparently a collection of
a collection of services
collection of services on
of services on a
services on a different
on a different physical
a different physical processor
or provide isolation guarantees
provide isolation guarantees between
isolation guarantees between co
the ssa can be
ssa can be seen
can be seen as
be seen as a
seen as a platform
as a platform that
a platform that leverages
platform that leverages tradeoffs
that leverages tradeoffs between
leverages tradeoffs between weaker
tradeoffs between weaker consistency
with a compensating gossip
a compensating gossip repair
compensating gossip repair mechanism
for higher availability and
higher availability and simplicity
this is an old
is an old idea
an old idea first
old idea first explored
idea first explored in
first explored in the
explored in the grapevine
and later in systems
later in systems like
in systems like bayou
which offer a broad
offer a broad operational
a broad operational spectrum
broad operational spectrum between
operational spectrum between strong
acid in the distributed
in the distributed database
the distributed database cases
several database and distributed
database and distributed systems
and distributed systems take
distributed systems take advantage
systems take advantage of
take advantage of the
advantage of the same
of the same tradeoff
for example allowing multiple
example allowing multiple updates
allowing multiple updates to
multiple updates to occur
updates to occur simultaneously
to occur simultaneously at
occur simultaneously at distinct
simultaneously at distinct replicas
at distinct replicas by
distinct replicas by specifying
replicas by specifying a
by specifying a maximum
specifying a maximum accepted
a maximum accepted deviation
maximum accepted deviation from
accepted deviation from strong
deviation from strong consistency
tolerating a bounded number
a bounded number of
bounded number of consistency
number of consistency violations
of consistency violations to
consistency violations to increase
violations to increase concurrency
to increase concurrency of
increase concurrency of transactions
achieving serializability with low
or replication according to
serializability with low latency
replication according to the
with low latency in
according to the need
low latency in geodistributed
latency in geodistributed storage
in geodistributed storage systems
in proceedings of the
th acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
our work on the
work on the ssa
on the ssa is
the ssa is the
ssa is the first
is the first to
the first to apply
first to apply such
to apply such thinking
apply such thinking to
such thinking to a
thinking to a cluster
to a cluster computing
a cluster computing environment
platform was designed to
was designed to provide
designed to provide a
to provide a cluster
provide a cluster based
a cluster based environment
cluster based environment for
based environment for scalable
environment for scalable internet
for scalable internet services
scalable internet services of
internet services of the
services of the sort
of the sort used
the sort used in
sort used in web
used in web servers
caching proxies and transformation
proxies and transformation proxies
service components are controlled
components are controlled by
are controlled by a
controlled by a front
by a front end
a front end machine
front end machine that
end machine that acts
machine that acts as
that acts as a
acts as a request
as a request dispatcher
a request dispatcher and
request dispatcher and incorporates
dispatcher and incorporates the
and incorporates the load
incorporates the load balancing
the load balancing and
load balancing and restart
balancing and restart logics
end processes are detected
acm transactions on database
processes are detected to
transactions on database systems
are detected to have
detected to have failed
new processes are forked
processes are forked to
are forked to take
forked to take over
to take over the
take over the load
tacc workers can be
workers can be composed
can be composed to
be composed to address
composed to address more
to address more complex
address more complex tasks
tacc stands for transformation
ssa can be seen
can be seen as
be seen as revisiting
seen as revisiting these
as revisiting these architectural
revisiting these architectural ideas
these architectural ideas in
architectural ideas in conjunction
ideas in conjunction with
in conjunction with chain
conjunction with chain replication
have long supported clustered
long supported clustered architectures
and were the first
were the first systems
the first systems to
first systems to exploit
systems to exploit the
to exploit the style
exploit the style of
the style of partitioning
style of partitioning that
of partitioning that leads
partitioning that leads to
that leads to a
leads to a raps
to a raps of
a raps of racs
raps of racs solution
research edition where the
edition where the academic
where the academic knights
most database systems adhere
the academic knights meet
database systems adhere closely
academic knights meet the
systems adhere closely to
knights meet the evil
adhere closely to the
closely to the acid
meet the evil empire
to the acid model
the evil empire werner
evil empire werner vogels
empire werner vogels the
at potentially high cost
werner vogels the rivalry
potentially high cost in
vogels the rivalry in
high cost in terms
the rivalry in the
cost in terms of
rivalry in the operating
in terms of reduced
in the operating system
terms of reduced availability
the operating system market
of reduced availability during
operating system market place
reduced availability during faults
system market place has
market place has a
place has a severe
has a severe impact
a severe impact on
severe impact on the
impact on the academic
on the academic world
discuss this problem in
where in the old
in the old days
the old days intellection
old days intellection quality
days intellection quality and
intellection quality and careful
quality and careful deliberation
and careful deliberation would
careful deliberation would prevail
nowadays discussions about operating
ultimately arguing for precisely
discussions about operating systems
arguing for precisely the
about operating systems research
for precisely the weak
operating systems research appear
precisely the weak update
systems research appear to
the weak update model
research appear to be
weak update model that
appear to be more
update model that we
to be more like
model that we adopted
be more like the
that we adopted here
more like the battlefield
like the battlefield of
the battlefield of a
battlefield of a holy
of a holy war
application servers like the
servers like the j
with objectivity as its
objectivity as its main
as its main victim
we have tried to
have tried to side
tried to side step
to side step the
side step the emotional
step the emotional current
offer persistent state support
and select an operating
persistent state support by
select an operating system
state support by wrapping
an operating system that
support by wrapping soft
operating system that could
by wrapping soft state
system that could bring
wrapping soft state business
that could bring our
soft state business logic
could bring our research
state business logic components
bring our research into
business logic components on
our research into the
logic components on top
research into the next
components on top of
into the next century
on top of a
top of a relational
of a relational or
a relational or object
based on objective technical
on objective technical and
objective technical and organizational
shoring up persistent applications
technical and organizational criteria
they also target large
in proceedings of the
this paper describes how
paper describes how this
scale highly available services
describes how this evaluation
how this evaluation lead
this evaluation lead to
evaluation lead to the
and hence we believe
lead to the insight
hence we believe they
to the insight that
we believe they could
the insight that microsoft
believe they could benefit
insight that microsoft s
acm sigmod international conference
that microsoft s windows
they could benefit from
sigmod international conference on
could benefit from ssa
microsoft s windows nt
international conference on management
s windows nt is
conference on management of
windows nt is the
on management of data
nt is the operating
is the operating system
the operating system that
operating system that is
in a similar vein
system that is best
that is best prepared
is best prepared for
best prepared for the
prepared for the future
introduction until recently there
until recently there was
recently there was no
there was no doubt
was no doubt in
framework makes it easy
no doubt in academia
makes it easy to
doubt in academia which
it easy to create
in academia which operating
easy to create robust
academia which operating system
to create robust scalable
which operating system to
create robust scalable services
operating system to use
system to use for
to use for systems
use for systems research
ninja is arguably more
is arguably more flexible
arguably more flexible than
more flexible than application
flexible than application servers
whether it was a
than application servers in
it was a bsd
application servers in that
was a bsd or
servers in that it
a bsd or system
in that it performs
bsd or system v
that it performs connection
or system v derivative
it performs connection management
performs connection management and
connection management and automatically
management and automatically partitions
was the predominant choice
and automatically partitions and
automatically partitions and replicates
partitions and replicates persistent
and replicates persistent state
which had its roots
but the framework takes
had its roots in
the framework takes a
its roots in research
framework takes a different
takes a different tiered
a different tiered approach
different tiered approach to
tiered approach to services
was used since its
approach to services based
used since its inception
to services based on
since its inception to
services based on bases
its inception to investigate
inception to investigate fundamental
to investigate fundamental system
investigate fundamental system research
active proxies and units
and the accumulated knowledge
and represents shared state
the accumulated knowledge in
represents shared state by
accumulated knowledge in academia
shared state by means
knowledge in academia about
state by means of
in academia about its
by means of distributed
academia about its internals
means of distributed data
about its internals and
of distributed data structures
its internals and operations
internals and operations was
and operations was significant
other available operating systems
available operating systems such
conclusion our paper presents
operating systems such as
our paper presents the
systems such as vms
paper presents the scalable
such as vms and
presents the scalable services
as vms and mvs
the scalable services architecture
a new platform for
had their roots in
new platform for porting
platform for porting a
their roots in the
for porting a large
porting a large class
roots in the commercial
a large class of
large class of service
in the commercial world
the commercial world and
commercial world and knowledge
oriented applications onto clusters
world and knowledge about
and knowledge about these
knowledge about these systems
the ssa was designed
about these systems never
ssa was designed to
these systems never accumulated
was designed to be
systems never accumulated to
designed to be as
never accumulated to the
to be as simple
accumulated to the critical
be as simple as
to the critical mass
as simple as possible
the critical mass were
critical mass were these
mass were these systems
were these systems could
and at the core
these systems could be
at the core uses
systems could be considered
the core uses just
could be considered for
core uses just two
be considered for widespread
uses just two primitive
considered for widespread research
just two primitive mechanisms
for widespread research tasks
tcp chains that support
chains that support a
that support a variant
although new research operating
support a variant of
new research operating systems
a variant of chain
research operating systems have
variant of chain replication
operating systems have been
systems have been developed
and gossip epidemics which
none have found the
gossip epidemics which are
have found the following
epidemics which are used
found the following that
which are used to
the following that the
are used to manage
following that the established
used to manage configuration
that the established unix
to manage configuration data
the established unix s
manage configuration data and
established unix s received
configuration data and initiate
data and initiate repair
and initiate repair after
initiate repair after failures
with appropriate parameter settings
freebsd and others continue
and others continue to
others continue to dominate
continue to dominate the
to dominate the academic
given a gossip rate
dominate the academic landscape
a gossip rate that
gossip rate that is
rate that is sufficiently
that is sufficiently fast
but slowly but surely
is sufficiently fast relative
slowly but surely windows
sufficiently fast relative to
but surely windows nt
fast relative to the
surely windows nt is
relative to the update
windows nt is now
to the update rates
nt is now entering
the update rates seen
is now entering the
update rates seen in
now entering the academic
rates seen in the
entering the academic world
seen in the cluster
the academic world as
academic world as a
world as a viable
alternative platform for research
efficient optimistic concurrency control
optimistic concurrency control using
concurrency control using loosely
we find that the
control using loosely synchronized
using loosely synchronized clocks
find that the ssa
although academia looked with
that the ssa can
academia looked with fascination
the ssa can rapidly
looked with fascination at
ssa can rapidly and
with fascination at dave
can rapidly and automatically
fascination at dave cutler
rapidly and automatically reconfigure
at dave cutler s
dave cutler s attempt
and automatically reconfigure itself
cutler s attempt to
automatically reconfigure itself after
s attempt to build
reconfigure itself after a
attempt to build a
itself after a failure
to build a new
after a failure and
build a new operating
a failure and can
a new operating system
failure and can rapidly
new operating system from
and can rapidly repair
operating system from the
can rapidly repair data
system from the ground
rapidly repair data inconsistencies
from the ground up
repair data inconsistencies that
data inconsistencies that arise
inconsistencies that arise during
that arise during the
arise during the period
during the period when
the period when the
period when the cluster
when the cluster configuration
the cluster configuration was
cluster configuration was still
configuration was still disrupted
our goal is to
goal is to make
all expected that windows
is to make the
to make the software
expected that windows nt
make the software available
that windows nt would
the software available to
windows nt would go
software available to a
available to a general
nt would go the
to a general user
would go the same
a general user community
general user community in
go the same way
the same way as
same way as the
way as the other
as the other commercially
the other commercially designed
other commercially designed operating
commercially designed operating systems
designed operating systems before
operating systems before it
systems before it and
before it and remain
it and remain in
and remain in the
remain in the dark
in the dark corner
the dark corner from
dark corner from a
corner from a research
from a research use
a research use point
research use point of
use point of view
acknowledgments the authors are
the authors are grateful
authors are grateful to
are grateful to the
grateful to the research
about four years ago
to the research team
a scalable system for
the research team at
scalable system for consistently
research team at afrl
system for consistently caching
team at afrl in
for consistently caching dynamic
not long after the
at afrl in rome
long after the final
consistently caching dynamic web
after the final major
caching dynamic web data
the final major release
final major release of
major release of academic
release of academic version
of academic version of
for their help in
academic version of the
their help in understanding
version of the unix
help in understanding the
of the unix operating
in understanding the challenges
the unix operating system
understanding the challenges of
the challenges of using
challenges of using service
of using service oriented
using service oriented architectures
service oriented architectures in
oriented architectures in large
architectures in large scale
in large scale settings
and to the researchers
to the researchers at
the researchers at amazon
for helping us understand
helping us understand the
us understand the architectures
understand the architectures employed
the architectures employed in
architectures employed in very
employed in very large
in very large data
very large data centers
the farewell of the
farewell of the berkeley
of the berkeley systems
the berkeley systems werner
berkeley systems werner vogels
systems werner vogels is
werner vogels is a
a scalable web cache
vogels is a research
scalable web cache consistency
is a research scientist
web cache consistency architecture
a research scientist at
research scientist at the
scientist at the department
at the department of
sigcomm computer communications review
the department of computer
department of computer science
of computer science of
computer science of cornell
science of cornell university
his research targets high
availability in distributed systems
with a particular focus
a particular focus on
particular focus on enterprise
focus on enterprise cluster
on enterprise cluster systems
an exercise in distributed
president of reliable network
exercise in distributed computing
of reliable network solutions
communications of the acm
which specializes in building
specializes in building solutions
in building solutions for
building solutions for very
solutions for very large
scale reliable distributed systems
usenix windows nt symposium
his personal homepage is
personal homepage is at
homepage is at http
based cache management for
cache management for dynamic
management for dynamic web
for dynamic web content
alternative architectures and protocols
architectures and protocols for
and protocols for providing
protocols for providing strong
group and the early
for providing strong consistency
and the early demise
providing strong consistency in
the early demise of
strong consistency in dynamic
early demise of mach
consistency in dynamic web
demise of mach as
in dynamic web applications
of mach as the
mach as the last
as the last of
the last of the
last of the research
world wide web journal
of the research operating
the research operating systems
an architecture to support
architecture to support scalable
to support scalable online
the operating system research
support scalable online personalization
operating system research world
scalable online personalization in
system research world was
online personalization in the
research world was at
personalization in the web
world was at a
was at a crossroads
the international journal on
international journal on very
intel based personal computers
journal on very large
based personal computers were
on very large data
personal computers were becoming
very large data bases
computers were becoming ubiquitous
and a myriad of
a myriad of unix
myriad of unix operating
of unix operating systems
unix operating systems was
operating systems was available
systems was available for
was available for this
available for this platform
eventually many moved to
many moved to use
moved to use linux
a popular architectural clone
popular architectural clone of
architectural clone of the
clone of the traditional
of the traditional unix
at the computer science
the computer science department
computer science department at
science department at cornell
department at cornell university
at cornell university we
cornell university we made
university we made the
we made the decision
made the decision to
the decision to conduct
decision to conduct our
to conduct our research
conduct our research on
our research on windows
research on windows nt
by that time we
that time we had
time we had learned
we had learned enough
had learned enough from
learned enough from the
enough from the early
from the early design
the early design of
early design of windows
design of windows nt
of windows nt to
windows nt to realize
nt to realize that
to realize that it
realize that it was
that it was a
it was a major
was a major step
a major step forward
major step forward in
step forward in operating
forward in operating system
in operating system design
it would provide us
would provide us with
provide us with a
us with a platform
with a platform on
a platform on which
platform on which we
cache coherence in distributed
on which we could
coherence in distributed systems
which we could perform
we could perform research
could perform research more
perform research more effectively
research more effectively and
more effectively and it
effectively and it would
and it would allows
it would allows us
would allows us to
allows us to focus
us to focus on
to focus on the
focus on the future
on the future directions
the future directions without
future directions without having
directions without having to
without having to worry
having to worry whether
to worry whether the
worry whether the operating
whether the operating system
the operating system was
operating system was capable
epidemic algorithms for replicated
system was capable of
algorithms for replicated database
was capable of supporting
for replicated database maintenance
capable of supporting innovation
in proceedings of the
proceedings of the sixth
by now our complete
of the sixth annual
now our complete educational
the sixth annual acm
our complete educational operation
sixth annual acm symposium
complete educational operation and
annual acm symposium on
educational operation and the
acm symposium on principles
operation and the majority
symposium on principles of
and the majority of
on principles of distributed
the majority of our
principles of distributed computing
majority of our research
of our research projects
our research projects have
research projects have switched
projects have switched to
have switched to using
switched to using windows
to using windows nt
a global cache coherent
global cache coherent file
cache coherent file system
as it now officially
it now officially has
now officially has been
officially has been christened
the ride has been
ride has been rocky
has been rocky and
been rocky and fascinating
in this article i
this article i want
article i want to
i want to share
a distributed memory object
want to share some
distributed memory object caching
to share some of
memory object caching system
share some of the
some of the reasoning
of the reasoning behind
the reasoning behind our
reasoning behind our choice
behind our choice for
our choice for windows
choice for windows nt
for windows nt and
windows nt and to
nt and to share
and to share some
to share some our
share some our experiences
some our experiences with
our experiences with windows
experiences with windows nt
with windows nt as
windows nt as a
nt as a research
as a research platform
os research as religion
research as religion the
as religion the biggest
religion the biggest hurdle
support for data sharing
the biggest hurdle in
for data sharing among
biggest hurdle in starting
data sharing among mobile
hurdle in starting research
sharing among mobile users
in starting research on
starting research on windows
research on windows nt
on windows nt was
windows nt was not
in ieee workshop on
nt was not technical
ieee workshop on mobile
workshop on mobile computing
on mobile computing systems
it was to overcome
was to overcome the
to overcome the skepticism
overcome the skepticism of
the skepticism of our
skepticism of our colleagues
of our colleagues who
our colleagues who were
colleagues who were convinced
who were convinced that
were convinced that it
convinced that it would
distributed data structures for
that it would not
data structures for internet
it would not be
structures for internet service
would not be possible
for internet service construction
not be possible to
be possible to use
possible to use windows
to use windows nt
in proceedings of the
use windows nt as
windows nt as a
nt as a good
as a good platform
a good platform for
th conference on symposium
good platform for research
conference on symposium on
on symposium on operating
symposium on operating system
on operating system design
the predictions were fascinating
we would turn into
would turn into a
turn into a bug
microsoft would sue the
would sue the department
sue the department for
the department for every
department for every technical
for every technical publication
microsoft would hide the
would hide the pieces
hide the pieces of
the pieces of buggy
pieces of buggy code
of buggy code from
buggy code from us
code from us or
from us or bill
us or bill gates
or bill gates would
bill gates would personally
gates would personally tell
would personally tell us
personally tell us where
tell us where and
us where and how
where and how we
and how we should
how we should do
we should do our
should do our research
the operating systems research
operating systems research community
systems research community has
research community has not
community has not remained
has not remained untouched
not remained untouched by
remained untouched by the
untouched by the market
by the market place
the market place rivalry
market place rivalry between
place rivalry between microsoft
rivalry between microsoft and
between microsoft and the
microsoft and the group
and the group lead
the group lead by
group lead by sun
lead by sun microsystems
it is even more
is even more unfortunate
even more unfortunate that
more unfortunate that the
unfortunate that the positions
that the positions taken
the positions taken are
positions taken are not
taken are not based
are not based on
not based on intellectual
based on intellectual deliberation
on intellectual deliberation but
intellectual deliberation but purely
deliberation but purely on
but purely on emotional
purely on emotional grounds
many see microsoft operating
see microsoft operating systems
microsoft operating systems as
operating systems as the
systems as the evil
as the evil empire
out to squash every
to squash every attempt
squash every attempt at
every attempt at innovation
and working with them
working with them is
with them is seen
them is seen as
is seen as collaboration
seen as collaboration with
as collaboration with the
collaboration with the enemy
with the enemy of
the enemy of free
enemy of free academic
of free academic speech
the pros and cons
based scalable network services
pros and cons are
and cons are often
cons are often discussed
are often discussed with
often discussed with a
discussed with a righteous
with a righteous zeal
a righteous zeal that
righteous zeal that is
zeal that is frightening
our own experiences with
proceedings of the sixteenth
own experiences with microsoft
of the sixteenth acm
experiences with microsoft can
the sixteenth acm symposium
with microsoft can only
sixteenth acm symposium on
microsoft can only be
acm symposium on operating
can only be described
symposium on operating systems
only be described as
on operating systems principles
be described as extremely
described as extremely positive
never before have we
before have we had
have we had such
we had such a
had such a positive
such a positive relation
a positive relation with
positive relation with a
relation with a vendor
without any pressure from
any pressure from their
pressure from their side
we can only conclude
can only conclude that
only conclude that the
conclude that the reasons
that the reasons for
the reasons for the
reasons for the controversy
for the controversy must
the controversy must be
controversy must be found
must be found in
be found in a
tier database caching for
found in a sort
database caching for e
in a sort of
a sort of traditional
sort of traditional emotional
of traditional emotional bonding
traditional emotional bonding of
emotional bonding of academia
in international conference on
bonding of academia with
international conference on management
of academia with the
conference on management of
academia with the underdog
on management of data
with the underdog and
the underdog and that
underdog and that no
and that no real
that no real experiences
no real experiences drive
real experiences drive the
experiences drive the discussion
gaining knowledge the foremost
knowledge the foremost reasons
the foremost reasons why
foremost reasons why unix
reasons why unix was
why unix was such
unix was such a
was such a powerhouse
such a powerhouse in
a powerhouse in operating
powerhouse in operating system
in operating system research
operating system research was
system research was the
research was the great
was the great amount
the great amount of
great amount of knowledge
amount of knowledge accumulated
of knowledge accumulated over
knowledge accumulated over the
accumulated over the years
over the years about
the years about the
years about the internal
about the internal operation
the internal operation of
internal operation of the
operation of the operating
of the operating system
many of us had
of us had become
us had become gurus
had become gurus about
become gurus about some
gurus about some part
about some part of
some part of the
part of the os
of the os kernel
the os kernel and
os kernel and could
kernel and could recite
and could recite the
could recite the fields
recite the fields of
the fields of an
fields of an i
node structure at late
structure at late night
at late night meetings
late night meetings or
night meetings or discuss
meetings or discuss which
or discuss which data
discuss which data structures
which data structures to
data structures to modify
consistent and scalable cache
structures to modify to
and scalable cache replication
to modify to add
scalable cache replication for
modify to add a
cache replication for multi
to add a new
add a new protocol
a new protocol at
new protocol at runtime
protocol at runtime over
at runtime over an
runtime over an early
over an early morning
an early morning cappuccino
many of us were
of us were and
us were and still
were and still are
and still are afraid
still are afraid to
are afraid to leave
afraid to leave this
the ninja architecture for
to leave this bastion
ninja architecture for robust
architecture for robust internet
leave this bastion of
this bastion of safety
bastion of safety behind
scale systems and services
of safety behind and
safety behind and trade
behind and trade it
and trade it in
trade it in for
it in for working
in for working on
for working on an
working on an operating
on an operating system
an operating system that
operating system that at
system that at first
that at first sight
at first sight had
first sight had nothing
sight had nothing in
had nothing in common
nothing in common with
in common with our
common with our beloved
with our beloved unix
and our annotated version
our annotated version of
annotated version of the
version of the unix
of the unix version
wouldn t be of
consistent and scalable caching
t be of much
and scalable caching in
scalable caching in multitier
be of much help
caching in multitier architectures
of much help any
much help any more
help any more either
the international journal on
international journal on very
any more either it
journal on very large
on very large data
more either it took
very large data bases
either it took more
it took more then
took more then a
more then a year
then a year of
a year of immersion
year of immersion in
of immersion in the
immersion in the technology
in the technology to
the technology to get
technology to get a
to get a level
get a level where
a level where i
level where i felt
where i felt confident
i felt confident again
felt confident again to
confident again to direct
again to direct others
to direct others in
direct others in our
others in our research
in our research group
together with the overall
with the overall organizational
spatial gossip and resource
the overall organizational issues
gossip and resource location
overall organizational issues i
and resource location protocols
organizational issues i think
issues i think we
i think we lost
in proceedings of the
think we lost one
proceedings of the thirty
we lost one and
lost one and a
one and a half
and a half year
third annual acm symposium
a half year worth
annual acm symposium on
half year worth of
acm symposium on theory
year worth of research
symposium on theory of
worth of research time
on theory of computing
of research time to
research time to make
time to make the
to make the switch
make the switch in
the switch in the
switch in the most
in the most fundamental
the most fundamental way
others are making the
are making the switch
making the switch more
the switch more gradually
switch more gradually and
more gradually and are
gradually and are experiencing
and are experiencing a
are experiencing a more
experiencing a more smooth
a more smooth transition
all operation systems are
operation systems are created
systems are created equal
are created equal our
created equal our experiences
equal our experiences with
our experiences with switching
experiences with switching to
with switching to windows
switching to windows nt
to windows nt have
windows nt have made
nt have made us
have made us somewhat
made us somewhat more
us somewhat more philosophical
somewhat more philosophical about
more philosophical about the
philosophical about the nature
about the nature of
the nature of operation
nature of operation systems
the most fundamental observation
most fundamental observation is
fundamental observation is that
when stripped to their
stripped to their core
all operating systems are
improving application throughput with
operating systems are equal
application throughput with enterprise
throughput with enterprise javabeans
with enterprise javabeans caching
the functionality of the
functionality of the windows
of the windows nt
the windows nt kernel
a technique for increasing
in international conference on
technique for increasing concurrency
windows nt kernel is
for increasing concurrency in
nt kernel is just
international conference on distributed
kernel is just as
increasing concurrency in a
is just as all
conference on distributed computing
just as all other
on distributed computing systems
concurrency in a replicated
as all other kernels
in a replicated system
it abstracts the hardware
acm transactions on database
abstracts the hardware in
transactions on database systems
the hardware in the
hardware in the usual
in the usual sense
process and threads hide
and threads hide the
threads hide the cpu
hide the cpu complexity
file systems and files
systems and files hide
and files hide the
files hide the storage
hide the storage devices
protocols hide the network
shared memory and messages
memory and messages are
and messages are used
messages are used to
are used to allow
used to allow sharing
to allow sharing of
allow sharing of resources
what we often call
we often call operating
often call operating systems
call operating systems has
operating systems has nothing
systems has nothing to
has nothing to do
nothing to do with
to do with the
do with the real
with the real core
the real core of
real core of the
core of the system
currency serializability for middle
unix for most of
for most of us
tier caching and replication
most of us is
of us is a
us is a collection
is a collection of
a collection of shell
in international conference on
collection of shell commands
international conference on management
of shell commands and
conference on management of
shell commands and development
on management of data
commands and development libraries
david korn s uwin
adaptive distributed data management
distributed data management with
data management with weak
management with weak consistent
and softway s interix
with weak consistent replicated
weak consistent replicated data
in proceedings of the
both show that you
show that you can
that you can give
you can give users
can give users and
give users and developers
users and developers a
acm symposium on applied
symposium on applied computing
a ppendix we now
ppendix we now prove
we now prove theorem
unix experience including x
while running on an
running on an windows
on an windows nt
an windows nt kernel
cache with unbounded cache
with unbounded cache size
windows nt for most
unbounded cache size and
nt for most of
cache size and unbounded
for most of us
size and unbounded dependency
most of us is
and unbounded dependency lists
of us is the
unbounded dependency lists implements
us is the windows
dependency lists implements cache
is the windows explorer
the windows explorer and
windows explorer and point
since we assume that
we assume that the
assume that the transactional
that the transactional db
the transactional db is
transactional db is serializable
and according to microsoft
according to microsoft it
to microsoft it includes
microsoft it includes a
it includes a web
includes a web browser
the operations in an
operations in an execution
in an execution of
an execution of update
although i have not
execution of update transactions
i have not seen
of update transactions update
have not seen a
update transactions update can
not seen a complete
transactions update can be
seen a complete re
update can be serialized
can be serialized as
be serialized as some
serialized as some serial
as some serial execution
implementation of the explorer
of the explorer for
the explorer for unix
the next claim trivially
next claim trivially follows
claim trivially follows from
trivially follows from the
aware adaptable web services
follows from the definition
from the definition of
the definition of the
definition of the database
compatible libraries from mainsoft
of the database dependency
in proceedings of the
the database dependency list
database dependency list specification
used in the port
th international world wide
in the port of
international world wide web
the port of internet
world wide web conference
port of internet explorer
wide web conference on
of internet explorer show
web conference on alternate
if is a serialization
conference on alternate track
internet explorer show that
on alternate track papers
is a serialization of
alternate track papers and
explorer show that you
track papers and posters
a serialization of the
show that you do
serialization of the update
that you do not
of the update transactions
you do not need
the update transactions of
do not need a
update transactions of an
not need a windows
transactions of an execution
need a windows nt
of an execution update
a windows nt kernel
windows nt kernel to
nt kernel to get
kernel to get to
to get to the
get to the same
to the same user
the same user experience
at every step in
many see the rich
see the rich win
the version dependencies of
version dependencies of every
dependencies of every object
of every object match
every object match those
object match those stored
match those stored in
programming interface as the
those stored in its
interface as the native
stored in its dependency
as the native programming
in its dependency list
the native programming model
native programming model for
programming model for windows
model for windows nt
and although most windows
although most windows applications
most windows applications are
windows applications are designed
we first describe a
applications are designed using
first describe a routine
are designed using this
describe a routine for
designed using this interface
a routine for placing
routine for placing a
for placing a read
it is not the
is not the windows
not the windows nt
only transaction from a
the windows nt kernel
transaction from a cache
windows nt kernel interface
from a cache server
a cache server in
cache server in a
server in a serialization
in a serialization of
almost no applications are
a serialization of a
no applications are built
serialization of a subset
applications are built using
of a subset of
are built using the
built using the kernel
using the kernel interface
to form a serialization
form a serialization of
a serialization of both
and you would have
serialization of both the
you would have a
of both the update
would have a hard
both the update transaction
have a hard time
the update transaction and
a hard time finding
update transaction and the
hard time finding the
transaction and the read
time finding the complete
finding the complete documentation
the complete documentation for
complete documentation for all
documentation for all the
for all the system
all the system calls
describing windows nt as
windows nt as a
nt as a micro
as the kernel is
the kernel is certainly
kernel is certainly not
is certainly not small
but it is does
it is does describe
is does describe the
does describe the abstraction
describe the abstraction correctly
the abstraction correctly in
abstraction correctly in which
correctly in which the
in which the kernel
which the kernel provides
the kernel provides base
kernel provides base services
provides base services and
base services and the
services and the specific
and the specific application
the specific application context
specific application context is
application context is provided
context is provided through
is provided through subsystem
provided through subsystem servers
through subsystem servers or
subsystem servers or personalities
performing this permutation is
this permutation is one
permutation is one step
is one step of
one step of the
step of the routine
we repeat this step
repeat this step forming
this step forming a
is one of the
step forming a series
one of the personalities
forming a series of
of the personalities running
a series of permutations
profiles for the situated
the personalities running on
for the situated web
personalities running on top
running on top of
on top of windows
each permutation is a
top of windows nt
permutation is a serialization
in proceedings of the
is a serialization of
proceedings of the eleventh
a serialization of update
of the eleventh international
the eleventh international conference
eleventh international conference on
international conference on world
conference on world wide
and each permutes a
on world wide web
each permutes a range
permutes a range of
a range of the
and posix are others
range of the transactions
posix are others delivered
of the transactions with
are others delivered by
the transactions with respect
others delivered by microsoft
transactions with respect to
with respect to the
respect to the previous
to the previous step
one can run windows
can run windows nt
run windows nt without
windows nt without these
in each step the
nt without these standard
each step the right
without these standard personalities
step the right end
these standard personalities and
the right end of
standard personalities and build
right end of the
personalities and build your
end of the range
and build your own
of the range is
the range is earlier
range is earlier than
is earlier than in
what is an operating
earlier than in the
is an operating system
than in the previous
in the previous step
this question seems to
question seems to be
as one or more
seems to be on
one or more of
to be on the
or more of the
be on the mind
more of the objects
on the mind of
of the objects is
the mind of many
the objects is closer
mind of many people
objects is closer to
of many people these
is closer to the
many people these days
closer to the value
to the value read
the value read by
value read by t
infused by the microsoft
by the microsoft trial
eventually we therefore reach
we therefore reach a
academics in general have
therefore reach a permutation
in general have taken
reach a permutation where
general have taken a
a permutation where at
have taken a very
permutation where at the
taken a very narrow
where at the chosen
a very narrow view
at the chosen time
very narrow view of
the chosen time all
narrow view of what
chosen time all read
view of what an
time all read objects
of what an operating
all read objects are
what an operating system
read objects are at
an operating system is
objects are at their
are at their correct
at their correct versions
van renesse and f
david faber at microsoft
faber at microsoft trial
we place t there
at microsoft trial defined
place t there to
microsoft trial defined an
t there to obtain
trial defined an operating
there to obtain the
defined an operating system
to obtain the desired
chain replication for supporting
an operating system as
replication for supporting high
obtain the desired serialization
for supporting high throughput
operating system as the
supporting high throughput and
the desired serialization of
system as the software
desired serialization of the
as the software that
serialization of the update
high throughput and availability
of the update transactions
the software that controls
the update transactions and
software that controls the
update transactions and t
that controls the execution
controls the execution of
in sixth symposium on
the execution of programs
sixth symposium on operating
execution of programs on
symposium on operating systems
of programs on computer
on operating systems design
programs on computer systems
operating systems design and
on computer systems and
systems design and implementation
permutation routine let be
computer systems and may
routine let be an
systems and may provide
let be an execution
and may provide low
be an execution of
an execution of the
execution of the t
level services such as
services such as resource
such as resource allocation
and denote by update
denote by update the
by update the projection
update the projection of
the projection of on
output control in a
projection of on the
control in a form
of on the set
in a form which
on the set of
a form which is
the set of database
form which is sufficiently
set of database update
which is sufficiently simple
of database update transactions
is sufficiently simple and
sufficiently simple and general
simple and general so
and general so that
transaction t reads objects
general so that these
t reads objects o
so that these services
that these services are
these services are broadly
services are broadly useful
are broadly useful to
broadly useful to software
useful to software developers
in research community this
research community this strict
community this strict distinction
on with versions v
this strict distinction serves
strict distinction serves to
distinction serves to distinguish
serves to distinguish the
to distinguish the real
distinguish the real men
the real men from
real men from the
men from the boys
researchers and hackers that
and hackers that work
hackers that work in
that work in the
work in the area
in the area defined
the area defined by
area defined by this
defined by this narrow
by this narrow definition
this narrow definition of
narrow definition of operating
definition of operating systems
enabling scalable online personalization
scalable online personalization on
online personalization on the
personalization on the web
consider themselves part of
themselves part of the
take any serialization of
part of the select
any serialization of update
in proceedings of the
of the select circle
the select circle of
select circle of people
one exists according to
nd acm conference on
exists according to claim
circle of people working
acm conference on electronic
of people working on
conference on electronic commerce
people working on the
working on the core
on the core of
the core of the
core of the systems
of the systems area
and consider the first
the systems area of
systems area of computer
consider the first time
area of computer science
the first time when
first time when all
time when all the
when all the objects
once you are in
all the objects the
you are in this
the objects the transaction
objects the transaction reads
are in this circle
the transaction reads are
in this circle you
transaction reads are at
reads are at a
this circle you will
are at a version
circle you will become
at a version at
a version at least
you will become part
version at least as
at least as large
will become part of
least as large as
as large as the
become part of the
large as the versions
part of the secret
as the versions that
the versions that t
of the secret society
versions that t reads
the secret society that
secret society that practices
society that practices the
that practices the black
practices the black art
the black art of
at this time at
black art of os
this time at least
art of os research
time at least one
of os research and
at least one object
os research and will
least one object read
research and will start
one object read by
and will start to
object read by t
will start to regard
start to regard any
to regard any other
regard any other activity
the last written according
any other activity of
last written according to
other activity of systems
activity of systems development
of systems development as
systems development as irrelevant
has the correct version
development as irrelevant to
as irrelevant to the
irrelevant to the future
to the future of
the future of computer
but others might not
future of computer science
assume without loss of
for a long time
without loss of generality
a long time the
loss of generality that
long time the line
of generality that the
time the line was
generality that the last
the line was drawn
that the last version
line was drawn at
the last version written
was drawn at the
last version written is
drawn at the kernel
version written is vn
written is vn of
is vn of object
vn of object on
of object on at
object on at step
on at step t
at step t of
and one could only
one could only consider
an architecture for well
denote by t the
could only consider himself
by t the latest
only consider himself a
t the latest time
consider himself a true
the latest time at
himself a true os
latest time at which
a true os researcher
time at which a
true os researcher after
at which a wrong
os researcher after having
which a wrong version
in symposium on operating
researcher after having developed
symposium on operating systems
after having developed at
on operating systems principles
having developed at least
not the one read
developed at least two
the one read by
at least two device
one read by t
least two device drivers
two device drivers and
device drivers and hacked
drivers and hacked on
and hacked on the
hacked on the terminal
on the terminal driver
the terminal driver of
and assume wlog it
terminal driver of the
assume wlog it is
driver of the bsd
wlog it is version
it is version vn
k of object on
in modern operating systems
modern operating systems such
rather than the desired
operating systems such as
than the desired version
systems such as windows
the desired version vn
such as windows nt
the notion of where
notion of where exactly
of where exactly operating
where exactly operating systems
exactly operating systems services
operating systems services are
systems services are located
services are located is
are located is not
located is not that
we now describe a
is not that simple
now describe a single
not that simple any
that simple any more
describe a single step
a single step of
single step of the
step of the routine
fundamental services are split
services are split between
consider the transactions between
are split between kernel
the transactions between t
split between kernel and
transactions between t and
between kernel and user
between t and t
kernel and user space
and user space in
the costs and limits
user space in attempts
costs and limits of
space in attempts to
and limits of availability
in attempts to optimise
limits of availability for
attempts to optimise their
of availability for replicated
to optimise their efficiency
availability for replicated services
optimise their efficiency and
their efficiency and avoid
efficiency and avoid uncontrolled
and avoid uncontrolled growth
divide these transactions into
avoid uncontrolled growth of
these transactions into three
in proceedings of the
transactions into three sets
uncontrolled growth of kernel
proceedings of the eighteenth
growth of kernel services
of the eighteenth acm
the eighteenth acm symposium
eighteenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
the pervasiveness of distributed
transactions dependent on the
pervasiveness of distributed services
dependent on the transaction
of distributed services in
on the transaction at
distributed services in modern
the transaction at t
services in modern systems
in modern systems can
modern systems can be
systems can be considered
can be considered a
be considered a threat
considered a threat to
a threat to the
threat to the traditional
to the traditional notion
the traditional notion of
traditional notion of operating
notion of operating systems
transactions on which t
on which t is
which t is dependent
many support services are
support services are required
services are required to
are required to make
required to make distributed
to make distributed systems
make distributed systems work
distributed systems work efficiently
systems work efficiently and
work efficiently and effectively
efficiently and effectively and
and effectively and these
effectively and these services
transactions that do not
that do not belong
such as security and
do not belong to
as security and directory
not belong to either
security and directory services
belong to either group
and directory services or
directory services or distributed
services or distributed object
or distributed object support
the following lemma states
distributed object support and
following lemma states that
object support and cluster
lemma states that there
support and cluster management
states that there is
that there is no
there is no dependency
is no dependency among
no dependency among objects
are not part of
dependency among objects in
not part of a
among objects in sets
part of a traditional
of a traditional view
a traditional view of
traditional view of operating
view of operating systems
but they are essential
they are essential to
design and evaluation of
are essential to the
and hence there is
essential to the operation
hence there is no
to the operation of
and evaluation of a
the operation of modern
there is no intersection
operation of modern operating
evaluation of a conitbased
of modern operating systems
is no intersection between
of a conitbased continuous
no intersection between the
a conitbased continuous consistency
intersection between the sets
conitbased continuous consistency model
continuous consistency model for
this results in that
consistency model for replicated
results in that an
model for replicated services
in that an operating
that an operating system
an operating system no
operating system no longer
acm transactions on computer
system no longer is
transactions on computer systems
no longer is a
longer is a simple
is a simple division
a simple division between
simple division between kernel
division between kernel and
between kernel and user
kernel and user space
but consist of a
consist of a myriad
of a myriad of
if they were dependent
a myriad of services
then version vn of
of which some are
version vn of object
which some are kernilized
vn of object on
of object on depends
object on depends on
on depends on version
depends on version vn
some are local and
are local and others
local and others are
and others are remote
k of object on
operating systems that address
systems that address the
that address the needs
address the needs of
the needs of current
needs of current and
of current and future
and this dependency is
current and future clients
this dependency is reflected
and future clients and
dependency is reflected in
future clients and informatik
is reflected in their
clients and informatik informatique
reflected in their t
because they are unbounded
transaction t has read
t has read version
has read version vn
operating systems servers no
which is older than
is older than vn
systems servers no longer
servers no longer span
no longer span a
longer span a single
span a single computer
a single computer and
single computer and they
computer and they abstract
and they abstract services
the read of the
they abstract services away
read of the stale
abstract services away from
of the stale version
services away from physical
the stale version vn
away from physical nodes
from physical nodes allowing
physical nodes allowing user
nodes allowing user to
allowing user to be
user to be part
to be part of
be part of a
part of a larger
would have been detected
have been detected by
been detected by t
potential global operating environment
cache and the transaction
and the transaction would
the transaction would have
will the real dinosaur
transaction would have been
the real dinosaur please
would have been aborted
real dinosaur please come
dinosaur please come forward
therefore the assumption is
the assumption is wrong
until the spring of
and the sets are
the sets are indeed
sets are indeed independent
we were deeply committed
were deeply committed to
deeply committed to sunos
perhaps an empty set
and other bsd derivatives
is unrelated to sets
at that moment its
that moment its vendor
moment its vendor was
its vendor was discontinuing
we therefore switch sets
vendor was discontinuing the
was discontinuing the operating
discontinuing the operating system
and had designated solaris
which had its root
had its root in
its root in at
t s system v
s system v as
maintaining a serialization of
system v as the
a serialization of update
v as the successor
this event forced us
event forced us to
consider the following serialization
forced us to take
us to take a
to take a step
take a step back
a step back and
step back and evaluate
back and evaluate our
xi denotes a transaction
and evaluate our research
denotes a transaction x
evaluate our research directions
a transaction x in
our research directions and
transaction x in set
research directions and our
x in set i
directions and our expectations
and our expectations with
our expectations with respect
expectations with respect to
with respect to the
respect to the operating
to the operating systems
the operating systems to
operating systems to use
if one issue in
one issue in our
cache consistency we proceed
issue in our discussions
consistency we proceed to
in our discussions was
we proceed to prove
our discussions was dominant
proceed to prove theorem
it was the fact
was the fact that
the fact that most
fact that most of
that most of the
most of the operating
of the operating systems
let be an execution
the operating systems we
be an execution of
operating systems we were
an execution of the
systems we were looking
execution of the t
we were looking at
were looking at were
looking at were actually
at were actually very
were actually very old
actually very old fashioned
and denote by update
denote by update the
by update the projection
update the projection of
the projection of on
in structure and in
projection of on the
structure and in implementation
of on the set
on the set of
the set of database
set of database update
of database update transactions
most of these operating
of these operating systems
these operating systems had
operating systems had their
systems had their conception
had their conception in
their conception in the
s and did not
and did not change
did not change much
not change much in
change much in structure
much in structure since
in structure since then
linux could be seen
tm a set of
could be seen as
a set of readonly
be seen as an
set of readonly transactions
seen as an exception
of readonly transactions performed
as an exception since
readonly transactions performed through
an exception since it
transactions performed through a
exception since it was
performed through a single
since it was developed
through a single t
it was developed in
was developed in the
developed in the second
in the second half
the second half of
second half of the
if the read sets
the read sets of
read sets of two
sets of two transactions
of two transactions include
two transactions include the
transactions include the same
include the same object
the same object o
we say the one
say the one that
the one that read
but its structure mirrored
one that read a
its structure mirrored that
that read a larger
structure mirrored that of
read a larger version
mirrored that of the
a larger version of
that of the traditional
larger version of o
of the traditional unix
version of o depends
the traditional unix systems
of o depends on
o depends on the
depends on the other
and as such it
as such it could
all transactions access the
such it could be
transactions access the same
it could be considered
access the same cache
could be considered one
be considered one of
considered one of them
and the cache is
the cache is unbounded
the significant advances made
significant advances made in
advances made in academic
made in academic computer
in academic computer science
values are only replaced
are only replaced by
in os research and
only replaced by newer
os research and in
replaced by newer versions
research and in system
and in system software
in system software engineering
have had only minimal
so it is easy
had only minimal impact
it is easy to
only minimal impact on
is easy to see
minimal impact on the
easy to see that
impact on the design
to see that there
on the design and
see that there are
the design and implementation
that there are no
design and implementation of
there are no cycles
and implementation of commercial
are no cycles such
implementation of commercial operating
no cycles such that
of commercial operating systems
cycles such that two
such that two transactions
that two transactions depend
two transactions depend on
transactions depend on one
the design of all
depend on one another
design of all unix
of all unix systems
all unix systems violates
unix systems violates almost
the dependency graph therefore
systems violates almost all
dependency graph therefore describes
violates almost all of
graph therefore describes a
almost all of the
therefore describes a partial
all of the software
describes a partial order
of the software engineering
a partial order of
the software engineering principles
partial order of the
software engineering principles presented
order of the read
engineering principles presented to
principles presented to first
presented to first year
to first year s
first year s computer
year s computer science
s computer science students
the design is monolithic
and we choose an
design is monolithic with
we choose an arbitrary
is monolithic with almost
choose an arbitrary total
monolithic with almost no
an arbitrary total ordering
with almost no modular
arbitrary total ordering that
almost no modular structure
total ordering that respects
ordering that respects this
that respects this partial
respects this partial order
and the internal kernel
the internal kernel interfaces
internal kernel interfaces are
assume wlog the order
kernel interfaces are not
wlog the order is
interfaces are not strictly
the order is t
are not strictly enforced
not strictly enforced which
strictly enforced which introduces
enforced which introduces dependencies
which introduces dependencies on
introduces dependencies on the
dependencies on the actual
on the actual implementation
the actual implementation of
actual implementation of data
implementation of data structures
making it impossible to
it impossible to upgrade
impossible to upgrade or
to upgrade or replace
upgrade or replace modules
or replace modules without
replace modules without also
modules without also redesigning
without also redesigning several
also redesigning several other
redesigning several other modules
for example to replace
we take an initial
example to replace the
take an initial arbitrary
to replace the scheduler
an initial arbitrary serialization
replace the scheduler in
the scheduler in any
scheduler in any of
in any of the
of and permute it
any of the bsd
and permute it according
of the bsd s
permute it according to
the bsd s one
it according to the
bsd s one needs
according to the route
s one needs to
to the route above
one needs to spend
the route above to
needs to spend two
route above to place
to spend two weeks
above to place t
spend two weeks searching
two weeks searching for
weeks searching for all
searching for all dependencies
for all dependencies and
all dependencies and fixing
dependencies and fixing other
and fixing other sources
at the top of
the top of our
the result is a
top of our long
result is a permutation
of our long wish
our long wish list
long wish list for
wish list for an
list for an ideal
for an ideal research
an ideal research operating
ideal research operating system
were three important general
three important general points
we take all transactions
take all transactions that
all transactions that precede
transactions that precede t
the design and implementation
design and implementation of
and implementation of the
implementation of the operating
of the operating system
does not depend on
the operating system should
not depend on them
operating system should comply
system should comply with
should comply with modern
comply with modern software
with modern software engineering
and place them after
modern software engineering principles
place them after t
allowing researchers to introduce
researchers to introduce new
to introduce new components
we call this permutation
and replace core components
replace core components without
core components without redesigning
components without redesigning the
without redesigning the complete
live network streaming with
next we place t
redesigning the complete system
network streaming with utilities
streaming with utilities and
with utilities and cost
utilities and cost ymir
and cost ymir vigfusson
the overall structure of
overall structure of the
structure of the operating
can be placed immediately
of the operating system
be placed immediately after
placed immediately after t
user and kernel space
and kernel space components
we place it there
place it there to
should be designed towards
it there to form
be designed towards the
designed towards the future
is independent of t
then all its preceding
should be pervasive throughout
all its preceding transactions
be pervasive throughout the
freedman school of computer
pervasive throughout the whole
school of computer science
throughout the whole system
according to the dependency
to the dependency graph
are unrelated to t
iceland of computer science
the operating system vendor
and are therefore located
operating system vendor should
are therefore located after
system vendor should be
therefore located after it
vendor should be open
should be open to
be open to innovation
the permutations required are
permutations required are therefore
required are therefore after
are therefore after t
our experiences in the
experiences in the past
in the past had
the past had been
usa school of electronics
past had been that
school of electronics engineering
had been that vendors
of electronics engineering and
been that vendors always
electronics engineering and computer
that vendors always ignored
engineering and computer science
vendors always ignored important
always ignored important research
ignored important research results
important research results and
research results and only
results and only followed
and only followed very
only followed very narrow
followed very narrow paths
very narrow paths of
narrow paths of incremental
paths of incremental improvements
all relevant update transactions
relevant update transactions are
update transactions are located
transactions are located after
windows nt was the
are located after t
nt was the only
was the only operating
the only operating system
only operating system that
operating system that came
system that came close
that came close to
came close to matching
close to matching most
to matching most of
matching most of our
most of our requirements
and therefore the permutations
therefore the permutations required
the permutations required are
permutations required are all
required are all after
are all after t
with a handful of
a handful of operating
handful of operating systems
of operating systems such
operating systems such as
systems such as qnx
such as qnx and
as qnx and utah
qnx and utah s
since in all cases
and utah s os
in all cases the
all cases the permutations
cases the permutations are
the permutations are after
permutations are after t
none of the unix
of the unix based
the unix based operating
unix based operating systems
based operating systems came
operating systems came close
systems came close to
came close to fulfilling
they do not affect
close to fulfilling our
do not affect the
to fulfilling our requirements
not affect the correctness
affect the correctness of
the correctness of t
department abstract the growth
as noted before the
noted before the core
abstract the growth in
before the core of
the growth in internet
the core of those
core of those operating
growth in internet traffic
of those operating systems
we take the resulting
those operating systems is
in internet traffic associated
operating systems is based
take the resulting permutation
systems is based on
internet traffic associated with
the resulting permutation that
traffic associated with video
resulting permutation that we
permutation that we call
associated with video streaming
with video streaming and
video streaming and sharing
streaming and sharing of
and sharing of videos
sharing of videos is
of videos is so
and move all transactions
videos is so rapid
move all transactions that
is so rapid that
all transactions that neither
so rapid that it
year old designs and
rapid that it may
transactions that neither t
old designs and these
that it may soon
designs and these operating
it may soon dwarf
and these operating systems
may soon dwarf all
these operating systems still
soon dwarf all other
operating systems still treat
dwarf all other forms
systems still treat computers
all other forms of
still treat computers as
other forms of internet
treat computers as single
depend on to right
forms of internet content
computers as single entities
on to right after
as single entities without
to right after t
single entities without a
entities without a coherent
one reason for this
reason for this is
for this is that
this is that only
is that only some
that only some forms
the resulting permutation is
only some forms of
some forms of content
forms of content can
of content can be
content can be cached
we repeat this process
repeat this process until
this process until we
process until we place
until we place all
we place all read
data generated in real
generated in real time
in real time such
real time such as
time such as by
such as by live
as by live video
by live video broadcasts
this is a serialization
is a serialization of
a serialization of the
serialization of the update
of the update transactions
the update transactions in
update transactions in and
transactions in and all
in and all read
only transactions that accessed
iptv or new episodes
transactions that accessed the
or new episodes of
that accessed the same
new episodes of popular
accessed the same cache
episodes of popular tv
of popular tv shows
we have therefore shown
have therefore shown that
therefore shown that in
shown that in any
that in any execution
in any execution of
feet high windows nt
any execution of t
high windows nt looked
windows nt looked like
immersive virtual reality applications
nt looked like the
virtual reality applications and
looked like the proverbial
reality applications and games
like the proverbial dinosaur
cache the update transactions
applications and games typically
the update transactions can
and games typically can
update transactions can be
games typically can t
transactions can be serialized
typically can t be
a closer look revealed
can t be cached
can be serialized with
t be cached at
closer look revealed a
be cached at all
be serialized with readonly
look revealed a truly
serialized with readonly transactions
revealed a truly modern
a truly modern operating
with readonly transactions that
truly modern operating system
and in today s
readonly transactions that accessed
in today s systems
transactions that accessed a
that accessed a single
object oriented design is
accessed a single cache
oriented design is pervasive
each client may pull
design is pervasive through
client may pull such
is pervasive through the
may pull such information
which means that t
pervasive through the system
pull such information on
through the system including
such information on its
the system including the
information on its own
system including the kernel
on its own point
cache implements cache serializability
there is a complete
is a complete distributed
a complete distributed strategy
complete distributed strategy with
distributed strategy with at
strategy with at its
with at its core
at its core a
stream directly from the
its core a distributed
directly from the data
core a distributed object
from the data center
a distributed object technology
distributed object technology and
object technology and includes
technology and includes a
even if large numbers
and includes a complete
if large numbers of
includes a complete integration
large numbers of clients
a complete integration of
numbers of clients share
complete integration of distributed
of clients share interest
integration of distributed services
clients share interest in
of distributed services such
share interest in at
distributed services such as
interest in at least
services such as security
in at least some
at least some aspects
least some aspects of
some aspects of the
aspects of the data
we propose a new
propose a new system
a new system called
new system called g
system called g radient
called g radient aimed
and last no but
g radient aimed at
last no but least
radient aimed at reducing
aimed at reducing the
at reducing the load
reducing the load on
the load on providers
there is a real
load on providers of
is a real desire
on providers of such
a real desire by
providers of such and
real desire by the
of such and enabling
desire by the vendor
such and enabling scalable
by the vendor to
the vendor to continuously
vendor to continuously innovate
to continuously innovate its
continuously innovate its operating
bandwidthsensitive streaming service for
innovate its operating system
streaming service for heterogeneous
its operating system and
service for heterogeneous consumers
operating system and the
system and the overall
and the overall services
the core of the
core of the system
microsoft doesn t hesitate
of the system is
doesn t hesitate to
the system is an
t hesitate to incorporate
system is an overlay
hesitate to incorporate academic
is an overlay networking
to incorporate academic results
an overlay networking architecture
incorporate academic results into
overlay networking architecture intended
academic results into operating
networking architecture intended to
results into operating system
architecture intended to run
intended to run directly
to run directly on
run directly on a
directly on a content
and is open for
on a content hosting
is open for new
a content hosting platform
open for new directions
and which optimizes aggregate
innovation as a life
which optimizes aggregate bandwidth
as a life style
optimizes aggregate bandwidth use
a life style microsoft
aggregate bandwidth use by
life style microsoft is
bandwidth use by transforming
style microsoft is not
use by transforming in
microsoft is not conservative
is not conservative in
not conservative in its
conservative in its os
in its os development
flight data to match
data to match the
to match the ideal
match the ideal stream
while most vendors only
the ideal stream quality
most vendors only consider
ideal stream quality expressed
vendors only consider changes
stream quality expressed as
only consider changes to
quality expressed as an
consider changes to their
expressed as an economic
changes to their core
as an economic utility
to their core os
an economic utility of
their core os services
economic utility of the
core os services under
utility of the consuming
os services under extreme
of the consuming client
services under extreme market
under extreme market pressure
the core of windows
core of windows nt
of windows nt has
windows nt has changed
nt has changed significantly
introduction recent years have
has changed significantly over
recent years have seen
changed significantly over the
years have seen skyrocketing
significantly over the past
have seen skyrocketing demand
over the past years
seen skyrocketing demand for
the past years to
skyrocketing demand for internet
past years to accommodate
demand for internet bandwidth
years to accommodate the
to accommodate the demands
accommodate the demands of
the demands of modern
demands of modern computing
increasingly dominated by real
especially the upcoming release
time streaming of short
the upcoming release of
upcoming release of windows
but in many forms
formerly known as windows
known as windows nt
if trends continue then
trends continue then internet
makes that the microsoft
continue then internet video
that the microsoft takes
then internet video alone
the microsoft takes the
internet video alone will
microsoft takes the operating
video alone will generate
takes the operating system
alone will generate almost
the operating system functionality
operating system functionality to
system functionality to the
functionality to the next
to the next level
exabytes per month by
the advances in windows
per month by the
month by the end
by the end of
are too numerous to
too numerous to enumerate
numerous to enumerate here
they range from a
range from a file
from a file system
a file system cache
file system cache for
system cache for disconnected
cache for disconnected operation
percent of all internet
of all internet traffic
which was originally developed
was originally developed at
originally developed at cmu
developed at cmu in
at cmu in the
cmu in the coda
in the coda project
to a remote storage
a remote storage service
faced with a competitive
with a competitive landscape
remote storage service that
storage service that automatically
service that automatically moves
that automatically moves old
isps and content providers
automatically moves old data
and content providers are
moves old data from
content providers are exploring
old data from your
providers are exploring technologies
data from your hard
are exploring technologies to
from your hard disk
exploring technologies to help
your hard disk to
technologies to help satisfy
hard disk to remote
to help satisfy the
disk to remote servers
help satisfy the growing
to remote servers if
satisfy the growing demand
remote servers if you
the growing demand alongside
servers if you are
growing demand alongside the
if you are running
demand alongside the purchase
you are running out
alongside the purchase of
are running out of
the purchase of expensive
running out of disk
purchase of expensive infrastructure
out of disk space
from tight security integration
reducing the bandwidth consumption
the bandwidth consumption of
bandwidth consumption of simultaneous
consumption of simultaneous replicated
of simultaneous replicated content
simultaneous replicated content is
replicated content is a
content is a challenge
is a challenge which
a challenge which usually
challenge which usually leverages
as the dominant security
which usually leverages two
the dominant security provider
usually leverages two main
leverages two main tools
to a complete integration
caching of content and
a complete integration of
of content and multicasting
complete integration of network
integration of network quality
of network quality of
network quality of services
some forms of video
quality of services tools
forms of video content
of services tools including
services tools including data
tools including data transmission
including data transmission shapers
such as downloads of
data transmission shapers and
as downloads of unencrypted
transmission shapers and priority
downloads of unencrypted movies
shapers and priority scheduling
of unencrypted movies or
and priority scheduling and
unencrypted movies or films
priority scheduling and queuing
movies or films where
or films where many
films where many users
where many users will
many users will share
and from attributed based
users will share the
from attributed based distributed
will share the same
attributed based distributed component
share the same encryption
based distributed component programming
the same encryption key
distributed component programming to
component programming to indexing
programming to indexing support
to indexing support integrated
indexing support integrated in
support integrated in the
integrated in the file
in the file system
a wide variety of
wide variety of caching
variety of caching options
of caching options exist
we are witnesses of
are witnesses of a
witnesses of a unique
of a unique process
never before have we
before have we seen
have we seen such
we seen such a
seen such a radical
such a radical overhaul
a radical overhaul of
radical overhaul of an
overhaul of an operating
of which is the
of an operating system
which is the akamai
an operating system targeted
is the akamai content
operating system targeted for
the akamai content distribution
system targeted for the
akamai content distribution network
targeted for the enterprise
for the enterprise market
in general this market
general this market is
is arguably the most
this market is very
arguably the most famous
market is very conservative
is very conservative and
very conservative and not
conservative and not interested
and not interested in
not interested in taking
interested in taking risks
however the problems of
the problems of scale
management and distribution are
and distribution are asking
multicast techniques can reduce
distribution are asking for
techniques can reduce the
are asking for radical
can reduce the overall
asking for radical solutions
reduce the overall network
for radical solutions to
the overall network traffic
radical solutions to get
overall network traffic by
solutions to get to
network traffic by taking
to get to a
traffic by taking advantage
get to a computing
by taking advantage of
to a computing base
taking advantage of the
a computing base that
advantage of the packet
computing base that can
of the packet replication
base that can bring
the packet replication and
that can bring us
packet replication and forwarding
can bring us into
replication and forwarding within
bring us into the
and forwarding within the
us into the next
forwarding within the network
into the next century
within the network infrastructure
one of the markets
of the markets where
the markets where we
the deployment of the
markets where we will
deployment of the efficient
where we will see
of the efficient network
we will see the
will see the main
see the main competitive
the main competitive battle
main competitive battle between
competitive battle between microsoft
battle between microsoft and
between microsoft and others
microsoft and others will
and others will be
others will be that
will be that of
be that of the
that of the e
web farms with hundreds
farms with hundreds of
with hundreds of nodes
area internet has failed
with support services for
support services for load
services for load balancing
and so more expensive
so more expensive application
level overlays are generally
overlays are generally used
distributed and single image
and single image management
the devices used by
devices used by content
used by content subscribers
by content subscribers have
are really pushing the
content subscribers have become
really pushing the envelope
subscribers have become increasingly
pushing the envelope of
have become increasingly heterogeneous
the envelope of all
become increasingly heterogeneous mobile
envelope of all operating
increasingly heterogeneous mobile devices
of all operating systems
all operating systems that
operating systems that are
systems that are currently
that are currently on
are currently on the
currently on the market
are projected to consume
projected to consume over
windows nt is still
nt is still considered
ordering transactions with prediction
is still considered to
transactions with prediction in
still considered to be
with prediction in distributed
considered to be the
prediction in distributed object
to be the new
in distributed object stores
be the new kid
distributed object stores ittay
exabytes of video per
the new kid on
object stores ittay eyal
new kid on the
of video per month
kid on the block
video per month in
on the block in
the block in the
block in the internet
in the internet services
the internet services world
but it is clear
it is clear that
is clear that the
clear that the risks
that the risks that
the risks that are
risks that are taken
that are taken now
are taken now are
taken now are the
now are the right
are the right moves
the right moves to
right moves to prepare
moves to prepare the
implying that a range
to prepare the operating
that a range of
prepare the operating system
department of computer science
the operating system for
a range of subscription
operating system for operation
range of subscription rates
system for operation in
of subscription rates and
for operation in these
subscription rates and policies
operation in these emerging
rates and policies must
in these emerging massive
and policies must be
these emerging massive computing
policies must be applied
emerging massive computing environments
must be applied over
be applied over the
applied over the user
over the user base
the bugs innovation comes
bugs innovation comes at
innovation comes at a
comes at a price
department of electrical engineering
one of the costs
of the costs of
the costs of introducing
even if multiple users
costs of introducing a
if multiple users are
of introducing a significant
multiple users are streaming
introducing a significant amount
users are streaming the
a significant amount of
are streaming the same
significant amount of new
streaming the same event
amount of new code
israel abstract numbers of
of new code is
abstract numbers of storage
new code is the
numbers of storage nodes
code is the number
such as watching the
is the number of
as watching the opening
the number of software
watching the opening ceremony
number of software defects
the opening ceremony of
of software defects per
opening ceremony of the
software defects per lines
when client transactions access
ceremony of the olympics
client transactions access data
defects per lines of
transactions access data on
per lines of codes
access data on multiple
lines of codes increases
data on multiple shards
a smartphone user will
smartphone user will need
user will need a
the issue of consistency
will need a differently
issue of consistency arises
while measurements actually let
need a differently transcoded
measurements actually let us
a differently transcoded version
actually let us believe
differently transcoded version than
let us believe that
transcoded version than the
us believe that microsoft
version than the people
believe that microsoft products
than the people watching
we would use a
the people watching via
would use a system
people watching via internet
that microsoft products are
watching via internet television
use a system with
microsoft products are quite
a system with acid
products are quite reliable
system with acid transactions
are quite reliable at
quite reliable at operating
reliable at operating systems
or on their laptops
different consumer groups may
thousand lines of code
consumer groups may desire
groups may desire different
may desire different local
desire different local ads
different local ads or
local ads or sub
titles to be embedded
to be embedded into
be embedded into their
fresh code has a
embedded into their video
code has a disastrous
into their video streams
has a disastrous effect
a disastrous effect on
disastrous effect on this
effect on this number
because this model facilitates
this model facilitates reasoning
model facilitates reasoning about
the outlook becomes even
facilitates reasoning about system
avatars in a virtual
outlook becomes even more
reasoning about system properties
in a virtual world
about system properties and
becomes even more worrisome
a virtual world can
system properties and makes
even more worrisome when
virtual world can be
properties and makes possible
more worrisome when we
and makes possible a
world can be viewed
makes possible a variety
worrisome when we realize
possible a variety of
can be viewed as
a variety of highassurance
when we realize that
variety of highassurance guarantees
be viewed as subscribers
we realize that microsoft
viewed as subscribers to
realize that microsoft is
as subscribers to updates
that microsoft is not
subscribers to updates about
microsoft is not only
to updates about objects
is not only introducing
updates about objects in
not only introducing new
about objects in their
only introducing new code
objects in their vicinity
the acid model is
acid model is often
model is often avoided
is often avoided in
often avoided in today
but is also changing
and may want more
avoided in today s
may want more detailed
in today s large
is also changing all
want more detailed updates
also changing all of
more detailed updates for
changing all of its
detailed updates for objects
all of its old
updates for objects that
of its old code
scale systems due to
for objects that are
systems due to efficiency
objects that are closer
due to efficiency concerns
that are closer to
are closer to them
an automated process is
closer to them in
automated process is converting
to them in this
process is converting all
them in this world
is converting all of
converting all of the
all of the windows
of the windows nt
the windows nt code
while this growing heterogeneity
windows nt code to
this growing heterogeneity of
nt code to be
growing heterogeneity of device
heterogeneity of device types
research on cdns has
existing approaches typically run
on cdns has generally
approaches typically run transactions
cdns has generally assumed
typically run transactions speculatively
has generally assumed a
run transactions speculatively and
generally assumed a homogeneous
transactions speculatively and perform
assumed a homogeneous population
speculatively and perform certification
a homogeneous population of
and perform certification after
homogeneous population of end
perform certification after they
certification after they complete
thousand lines of code
after they complete to
lines of code per
they complete to preserve
of code per day
complete to preserve consistency
code per day and
per day and is
day and is believed
and is believed to
is believed to catch
either committing or aborting
believed to catch all
committing or aborting each
to catch all pointer
or aborting each transaction
catch all pointer arithmetic
aborting each transaction depending
all pointer arithmetic cases
each transaction depending on
transaction depending on conflicts
an important question is
important question is whether
question is whether the
is whether the introduced
whether the introduced functionality
the introduced functionality is
introduced functionality is worth
rain an architecture for
functionality is worth the
an architecture for acid
is worth the unavoidable
architecture for acid transactions
worth the unavoidable initial
for acid transactions in
the unavoidable initial instability
acid transactions in a
unavoidable initial instability that
transactions in a resilient
initial instability that is
in a resilient archive
instability that is bound
a resilient archive with
that is bound to
resilient archive with independent
is bound to occur
archive with independent nodes
thus most current systems
most current systems assume
current systems assume multiple
whenever taking risks to
the system orders transactions
systems assume multiple video
taking risks to achieve
system orders transactions before
risks to achieve major
assume multiple video streams
to achieve major improvements
orders transactions before they
multiple video streams to
transactions before they begin
video streams to be
before they begin by
streams to be sent
they begin by employing
there is always the
to be sent from
begin by employing predictors
is always the down
be sent from the
by employing predictors that
always the down side
sent from the source
employing predictors that estimate
the down side that
from the source at
predictors that estimate the
down side that there
the source at different
that estimate the set
side that there is
source at different resolutions
estimate the set of
that there is some
at different resolutions or
the set of objects
there is some change
different resolutions or that
set of objects each
resolutions or that a
of objects each transaction
is some change of
objects each transaction will
or that a single
some change of failure
each transaction will access
that a single highquality
change of failure and
a single highquality stream
of failure and it
single highquality stream is
failure and it is
highquality stream is transcoded
and it is likely
stream is transcoded by
such predictors can be
it is likely that
is transcoded by the
predictors can be implemented
transcoded by the receiver
can be implemented with
by the receiver who
is likely that we
the receiver who then
be implemented with machine
receiver who then incurs
likely that we will
who then incurs cost
implemented with machine learning
then incurs cost for
that we will see
incurs cost for last
with machine learning tools
we will see a
will see a number
see a number of
a number of components
number of components of
mile traffic owing to
of components of nt
traffic owing to unnecessarily
components of nt coming
owing to unnecessarily detailed
of nt coming under
to unnecessarily detailed video
nt coming under intense
coming under intense scrutiny
under intense scrutiny from
we pose the following
pose the following question
how can we deliver
can we deliver live
we deliver live dynamic
deliver live dynamic content
a transaction reserves a
transaction reserves a version
reserves a version of
a version of each
such as video broadcasts
version of each object
of each object it
each object it will
object it will use
or financial stock data
when later accessing the
later accessing the objects
over the internet to
the internet to large
internet to large number
to large number of
it will see these
large number of heterogeneous
will see these reserved
number of heterogeneous users
see these reserved versions
of heterogeneous users simultaneously
heterogeneous users simultaneously while
users simultaneously while balancing
simultaneously while balancing bandwidth
intense scrutiny from industry
while balancing bandwidth costs
scrutiny from industry and
from industry and academia
traffic rates and end
leases for future object
for future object versions
such as the directory
as the directory services
leases are issued for
live content refers to
are issued for a
may become a performance
issued for a predefined
content refers to content
for a predefined time
become a performance bottleneck
a predefined time period
refers to content streams
a performance bottleneck in
to content streams that
performance bottleneck in the
content streams that must
bottleneck in the overall
streams that must be
in the overall distributed
that must be transmitted
the overall distributed operation
must be transmitted to
be transmitted to multiple
not the lease holder
transmitted to multiple receivers
to multiple receivers simultaneously
or the wide spread
the wide spread security
may unilaterally decide to
wide spread security integration
unilaterally decide to ignore
such as a live
decide to ignore a
as a live broadcast
to ignore a reservation
spread security integration could
security integration could introduce
integration could introduce a
could introduce a critical
introduce a critical dependency
to run effectively at
a critical dependency on
run effectively at large
critical dependency on the
effectively at large scale
dependency on the high
ticker updates for financial
updates for financial stocks
for financial stocks or
financial stocks or object
stocks or object updates
availability of the security
or object updates in
of the security servers
object updates in a
updates in a virtual
rain must tolerate performance
in a virtual world
must tolerate performance hiccups
from a research point
a research point of
research point of view
we are not focused
these problems do not
are not focused on
problems do not really
not focused on streams
do not really bother
all of which are
not really bother us
focused on streams with
of which are common
on streams with a
which are common in
streams with a pause
are common in such
with a pause or
common in such settings
a pause or rewind
the advantage of performing
pause or rewind functions
advantage of performing research
or rewind functions or
of performing research on
rewind functions or the
performing research on a
functions or the video
research on a system
progress should never depend
should never depend on
never depend on the
depend on the responsiveness
which has distribution at
on the responsiveness of
has distribution at its
the responsiveness of any
distribution at its core
responsiveness of any single
at its core greatly
of any single machine
its core greatly outweighs
core greatly outweighs the
greatly outweighs the consequences
outweighs the consequences of
the consequences of working
consequences of working with
of working with a
the gradient cdn to
working with a cutting
gradient cdn to make
with a cutting edge
cdn to make progress
a cutting edge operating
to make progress towards
cutting edge operating system
make progress towards the
rain requires reliable entities
progress towards the research
requires reliable entities in
towards the research question
reliable entities in cloud
however i must admit
we propose a novel
i must admit that
propose a novel networked
must admit that at
it is common to
a novel networked content
is common to shard
admit that at more
novel networked content delivery
that at more then
networked content delivery system
at more then one
content delivery system called
more then one occasion
delivery system called g
system called g radient
then one occasion my
called g radient to
data across large numbers
g radient to address
across large numbers of
one occasion my students
radient to address the
large numbers of nodes
occasion my students had
to address the complex
my students had to
address the complex caching
atomic transactions are typically
the complex caching and
students had to control
transactions are typically implemented
complex caching and multicasting
are typically implemented by
had to control their
caching and multicasting issues
typically implemented by running
to control their murderous
implemented by running transactions
and multicasting issues associated
by running transactions speculatively
control their murderous intentions
multicasting issues associated with
issues associated with live
their murderous intentions towards
associated with live streaming
and then certifying them
murderous intentions towards the
with live streaming of
live streaming of dynamic
intentions towards the iis
streaming of dynamic content
of dynamic content to
aborting ones that cause
towards the iis or
ones that cause conflicts
dynamic content to a
the iis or mts
content to a heterogeneous
to a heterogeneous user
iis or mts developers
a heterogeneous user population
or mts developers or
mts developers or were
developers or were they
in high contention scenarios
or were they kept
the systems architecture consists
were they kept their
systems architecture consists of
they kept their good
architecture consists of one
this approach has drawbacks
kept their good spirits
consists of one or
their good spirits by
of one or more
good spirits by contemplating
one or more content
rather than achieving any
spirits by contemplating the
than achieving any substantial
or more content providers
achieving any substantial level
by contemplating the horrible
any substantial level of
more content providers which
contemplating the horrible tortures
substantial level of concurrency
content providers which together
the horrible tortures one
providers which together form
horrible tortures one could
which together form a
tortures one could perform
together form a cooperative
it prevents concurrency by
one could perform on
form a cooperative network
prevents concurrency by aborting
could perform on the
a cooperative network of
concurrency by aborting all
cooperative network of g
perform on the person
network of g radient
by aborting all but
of g radient cdn
on the person that
g radient cdn nodes
aborting all but one
the person that had
all but one of
person that had designed
but one of the
that had designed the
one of the contending
had designed the com
of the contending transactions
the cdn nodes form
designed the com security
cdn nodes form a
the com security architecture
nodes form a dynamic
form a dynamic overlay
our work explores a
a dynamic overlay over
work explores a new
dynamic overlay over which
explores a new option
overlay over which the
windows research there are
over which the content
research there are some
which the content is
there are some properties
the content is delivered
are some properties of
some properties of windows
properties of windows nt
of windows nt that
ordering transactions in advance
windows nt that make
and for our initial
nt that make it
transactions in advance based
that make it particularly
for our initial prototypes
make it particularly suitable
in advance based on
it particularly suitable for
our initial prototypes we
particularly suitable for research
advance based on the
suitable for research purposes
initial prototypes we will
based on the objects
prototypes we will look
on the objects they
we will look at
the objects they are
will look at spanning
objects they are likely
look at spanning trees
they are likely to
the operating system kernel
are likely to access
operating system kernel for
system kernel for example
kernel for example is
the concept of cdn
for example is designed
concept of cdn nodes
example is designed with
of cdn nodes is
providing acid transactions in
is designed with extensibility
cdn nodes is general
designed with extensibility in
acid transactions in a
with extensibility in mind
transactions in a resilient
in a resilient archive
a resilient archive with
an architecture in which
resilient archive with independent
to allow developers of
archive with independent nodes
architecture in which cdn
allow developers of hardware
in which cdn servers
developers of hardware based
which cdn servers are
of hardware based services
cdn servers are hosted
servers are hosted by
are hosted by isps
hosted by isps to
by isps to reduce
new protocols and file
isps to reduce redundant
protocols and file systems
to reduce redundant incoming
and file systems to
reduce redundant incoming bandwidth
file systems to add
redundant incoming bandwidth is
systems to add their
incoming bandwidth is a
to add their functionality
bandwidth is a logical
this preliminary ordering decreases
is a logical scenario
add their functionality to
preliminary ordering decreases abort
their functionality to the
ordering decreases abort rate
functionality to the system
to the system without
the system without much
and another example is
system without much effort
another example is that
and eliminates aborts in
example is that g
eliminates aborts in error
is that g radient
that g radient nodes
g radient nodes may
all kernel code is
radient nodes may as
kernel code is developed
nodes may as well
code is developed following
may as well be
is developed following a
as well be integrated
to allow fast recovery
well be integrated into
developed following a strict
be integrated into set
allow fast recovery from
following a strict object
fast recovery from failures
a strict object oriented
recovery from failures our
strict object oriented paradigm
from failures our scheme
object oriented paradigm and
failures our scheme does
oriented paradigm and its
our scheme does not
paradigm and its functionality
scheme does not introduce
and its functionality can
does not introduce any
its functionality can only
not introduce any locks
functionality can only be
can only be accessed
only be accessed through
be accessed through interfaces
the system consistency and
system consistency and durability
our approach to the
consistency and durability rely
approach to the problem
and durability rely on
to the problem resembles
durability rely on a
the problem resembles content
rely on a single
none of its implementation
on a single scalable
of its implementation is
a single scalable tier
its implementation is visible
single scalable tier of
scalable tier of highly
one of the designs
and in fact the
of the designs abstractions
in fact the expected
the designs abstractions of
fact the expected deployment
designs abstractions of the
simulations using the transactional
the expected deployment model
abstractions of the windows
expected deployment model would
of the windows nt
deployment model would employ
the windows nt kernel
ycsb workloads show the
model would employ a
workloads show the scalability
windows nt kernel i
would employ a geographically
show the scalability and
nt kernel i find
the scalability and benefits
kernel i find it
scalability and benefits of
i find it particularly
employ a geographically distributed
find it particularly fascinating
and benefits of acidrain
a geographically distributed set
it particularly fascinating to
geographically distributed set of
particularly fascinating to work
distributed set of isps
fascinating to work with
set of isps or
to work with is
of isps or small
work with is the
isps or small data
with is the device
or small data centers
is the device object
small data centers of
data centers of the
centers of the kind
of the kind operated
the kind operated by
a device object in
center computing systems often
device object in an
computing systems often maintain
object in an instance
systems often maintain massive
in an instance created
often maintain massive data
an instance created by
maintain massive data sets
instance created by driver
kind operated by today
created by driver objects
operated by today s
by today s cdn
today s cdn providers
sharded over large this
over large this work
large this work was
which encapsulates a unit
this work was funded
encapsulates a unit of
a unit of kernel
unit of kernel based
of kernel based software
whereas today s content
whether this is a
by grants from darpa
this is a device
is a device driver
hosting sites cache objects
a network protocol or
network protocol or a
protocol or a file
and the elkin research
or a file system
the elkin research fund
a file system filter
these objects have the
objects have the interesting
have the interesting property
only at a single
the interesting property that
at a single tier
interesting property that they
a single tier of
property that they can
single tier of the
that they can be
tier of the system
they can be attached
of the system a
can be attached to
the system a set
be attached to other
system a set of
attached to other device
a set of independent
to other device objects
our focus is on
set of independent highly
focus is on content
of independent highly available
is on content that
independent highly available logs
on content that cannot
and as such can
content that cannot be
as such can intercept
that cannot be usefully
such can intercept and
used in a novel
cannot be usefully cached
can intercept and manipulate
in a novel manner
intercept and manipulate all
and manipulate all requests
manipulate all requests flowing
all requests flowing to
the g radient project
all other entities may
g radient project aims
other entities may fail
requests flowing to and
entities may fail and
flowing to and from
may fail and can
to and from the
radient project aims to
and from the original
fail and can be
from the original device
and can be replaced
the original device object
can be replaced instantly
project aims to exploit
be replaced instantly on
aims to exploit and
replaced instantly on failure
to exploit and develop
exploit and develop two
this way it is
and develop two techniques
way it is relatively
develop two techniques that
the architecture maintains consistency
it is relatively simple
two techniques that improve
architecture maintains consistency even
is relatively simple to
techniques that improve on
maintains consistency even in
relatively simple to add
that improve on existing
consistency even in the
improve on existing cdns
even in the event
simple to add for
in the event of
the event of false
to add for example
event of false suspicion
add for example a
for example a file
example a file system
and algorithms to balance
a file system object
algorithms to balance bandwidth
file system object that
to balance bandwidth costs
system object that compresses
balance bandwidth costs with
reservations serve as suggestions
bandwidth costs with end
object that compresses or
serve as suggestions a
that compresses or encrypts
as suggestions a reservation
compresses or encrypts data
suggestions a reservation that
or encrypts data before
a reservation that is
encrypts data before the
reservation that is not
data before the data
that is not used
our design is focused
before the data reaches
is not used because
the data reaches the
design is focused on
data reaches the under
not used because of
reaches the under laying
is focused on modularity
the under laying file
used because of a
under laying file system
focused on modularity and
because of a sluggish
on modularity and incremental
of a sluggish or
modularity and incremental deployment
a sluggish or dead
sluggish or dead owner
or dead owner is
to redirect disk requests
dead owner is ignored
redirect disk requests to
disk requests to a
requests to a replication
to a replication volume
the independence of system
independence of system elements
of system elements allows
or to trace device
system elements allows for
to trace device object
elements allows for good
trace device object interaction
allows for good scalability
device object interaction during
object interaction during development
interaction during development phases
the strict object oriented
due to the interdependence
strict object oriented approach
to the interdependence of
object oriented approach is
dynamic content has substantial
oriented approach is very
content has substantial levels
approach is very well
has substantial levels of
the interdependence of the
substantial levels of redundancy
is very well done
interdependence of the log
very well done from
of the log contents
well done from a
done from a design
from a design point
even when user interests
a design point of
when user interests are
design point of view
user interests are relatively
interests are relatively heterogeneous
has to be carefully
widespread use of streaming
to be carefully coordinated
use of streaming video
be carefully coordinated to
style hacker s heart
carefully coordinated to maintain
of streaming video occurs
coordinated to maintain consistency
hacker s heart starts
streaming video occurs when
s heart starts bleeding
video occurs when internet
heart starts bleeding when
occurs when internet users
starts bleeding when he
we evaluate our architecture
bleeding when he or
when internet users watch
when he or she
internet users watch major
evaluate our architecture by
users watch major events
he or she realizes
our architecture by simulation
watch major events online
architecture by simulation with
or she realizes that
by simulation with the
she realizes that he
simulation with the transactional
realizes that he can
that he can no
such as superbowl or
he can no longer
as superbowl or the
can no longer do
superbowl or the olympics
no longer do a
longer do a quick
do a quick fix
inspect a few data
and like television users
a few data structures
few data structures and
data structures and secretly
structures and secretly swivel
such clients have little
and secretly swivel some
clients have little tolerance
secretly swivel some pointers
have little tolerance for
swivel some pointers to
little tolerance for lagged
some pointers to make
tolerance for lagged data
pointers to make things
to make things work
make things work better
we contrast the effectiveness
things work better or
contrast the effectiveness of
work better or make
the effectiveness of employing
better or make more
effectiveness of employing prediction
or make more informed
large numbers of users
make more informed decisions
of employing prediction and
numbers of users have
employing prediction and the
of users have essentially
prediction and the scalability
users have essentially the
and the scalability of
have essentially the same
the scalability of acid
essentially the same needs
the internal kernel interfaces
internal kernel interfaces are
kernel interfaces are elaborate
rain with other approaches
but since they may
since they may access
they may access the
but it appears there
may access the streams
it appears there are
access the streams from
appears there are always
the streams from a
there are always some
streams from a variety
are always some things
from a variety of
always some things one
a variety of devices
tm m om i
some things one cannot
things one cannot do
one cannot do as
cannot do as efficient
do as efficient as
with different screen sizes
as efficient as possible
different screen sizes and
screen sizes and resolutions
or different connectivity properties
in four years of
om n om i
four years of nt
years of nt kernel
of nt kernel hacking
nt kernel hacking only
the current solution is
kernel hacking only on
current solution is to
hacking only on one
solution is to provide
only on one occasion
is to provide each
on one occasion we
to provide each user
one occasion we needed
provide each user with
occasion we needed to
each user with a
we needed to break
user with a direct
needed to break through
with a direct connection
to break through the
log i log n
break through the standard
i log n figure
a direct connection to
through the standard kernel
direct connection to a
the standard kernel interface
connection to a content
server due to the
schematic structure of acid
due to the lack
we wanted to add
to the lack of
wanted to add a
the lack of robust
to add a fast
lack of robust multicast
add a fast trap
of robust multicast technologies
a fast trap into
fast trap into the
trap into the kernel
tms access multiple objects
into the kernel for
access multiple objects per
the kernel for fast
similar issues arise for
kernel for fast user
multiple objects per transaction
issues arise for newscasts
arise for newscasts of
for newscasts of fast
objects are managed by
are managed by oms
and the pages which
the pages which hold
pages which hold the
transmission of financial data
which hold the trap
of financial data and
hold the trap dispatch
financial data and virtual
the trap dispatch tables
data and virtual on
trap dispatch tables were
dispatch tables were protected
tables were protected after
were protected after the
protected after the system
after the system boot
is falsely suspected to
falsely suspected to have
suspected to have failed
our insight is that
insight is that a
is that a data
another example of what
and replaced by omi
example of what makes
rich channel can be
of what makes windows
channel can be transformed
can be transformed on
what makes windows nt
makes windows nt particular
windows nt particular suitable
nt particular suitable for
particular suitable for research
suitable for research is
network to create the
for research is the
to create the dynamic
research is the fundamental
create the dynamic content
causing them to concurrently
the dynamic content for
is the fundamental manner
dynamic content for end
them to concurrently serve
the fundamental manner in
to concurrently serve the
fundamental manner in which
concurrently serve the same
manner in which advanced
serve the same objects
in which advanced distributed
which advanced distributed services
advanced distributed services are
distributed services are integrated
oms are backed by
services are integrated into
are backed by highlyavailable
are integrated into windows
backed by highlyavailable logs
integrated into windows nt
we could add personalized
could add personalized advertisements
where they store tentative
subtitles or encryption keys
it allows us to
or encryption keys to
they store tentative transaction
allows us to rely
encryption keys to iptv
store tentative transaction entries
keys to iptv broadcasts
us to rely on
tentative transaction entries for
to rely on ubiquitous
transaction entries for serialization
rely on ubiquitous support
filters or aggregates to
on ubiquitous support services
or aggregates to financial
ubiquitous support services and
aggregates to financial stock
support services and concentrate
to financial stock updates
services and concentrate on
and concentrate on advancing
concentrate on advancing the
on advancing the state
or reduce the update
advancing the state of
reduce the update rate
the state of the
the update rate for
state of the art
update rate for distant
of the art where
rate for distant objects
the art where it
for distant objects in
art where it is
distant objects in the
where it is really
objects in the virtual
it is really needed
in the virtual world
the virtual world to
virtual world to which
world to which the
to which the user
which the user has
windows nt security provides
the user has subscribed
system structure the structure
nt security provides a
structure the structure of
security provides a complete
the structure of the
provides a complete set
structure of the system
a complete set of
of the system is
the same mechanism will
the system is illustrated
complete set of services
system is illustrated in
same mechanism will also
is illustrated in figure
set of services integrated
mechanism will also allow
of services integrated into
will also allow the
services integrated into all
also allow the system
integrated into all sections
allow the system to
into all sections of
the system to tailor
all sections of the
system to tailor to
at the base of
sections of the operating
to tailor to heterogeneous
the base of acid
tailor to heterogeneous devices
of the operating system
rain are a set
are a set of
researchers who are developing
a set of independent
who are developing an
set of independent highly
are developing an advanced
developing an advanced multi
transcoding a high definition
available logs that together
node replicated transaction server
a high definition broadcast
logs that together describe
replicated transaction server can
high definition broadcast to
transaction server can use
that together describe the
server can use off
definition broadcast to adapt
together describe the state
describe the state of
broadcast to adapt its
the state of the
state of the entire
to adapt its resolution
of the entire system
adapt its resolution to
its resolution to serve
resolution to serve a
each log is accessed
to serve a population
log is accessed through
serve a population of
is accessed through an
accessed through an object
a population of heterogeneous
through an object manager
population of heterogeneous devices
of heterogeneous devices from
heterogeneous devices from cell
devices from cell phones
from cell phones to
and encryption mechanisms into
cell phones to tablets
encryption mechanisms into their
phones to tablets to
mechanisms into their system
to tablets to iptv
into their system without
tablets to iptv lowering
their system without much
that caches the data
system without much pain
to iptv lowering overall
caches the data and
iptv lowering overall bandwidth
the data and provides
lowering overall bandwidth costs
data and provides the
overall bandwidth costs without
the use of the
bandwidth costs without affecting
and provides the data
use of the com
costs without affecting viewing
provides the data structure
without affecting viewing experience
of the com object
the data structure abstraction
the com object model
data structure abstraction exporting
com object model in
structure abstraction exporting read
object model in all
abstraction exporting read and
model in all the
exporting read and write
in all the windows
read and write operations
all the windows nt
the windows nt services
windows nt services allows
network transformations will be
nt services allows research
transformations will be applied
services allows research projects
will be applied with
allows research projects to
be applied with pluggable
research projects to import
which are managed by
projects to import these
applied with pluggable serverlets
to import these services
are managed by transaction
import these services in
managed by transaction managers
these services in a
with pluggable serverlets designed
services in a very
pluggable serverlets designed to
in a very simple
serverlets designed to execute
a very simple manner
designed to execute within
to execute within the
execute within the cdn
the existence of com
tms provide the atomic
existence of com makes
provide the atomic transaction
of com makes it
the atomic transaction abstraction
com makes it trivial
makes it trivial for
it trivial for research
trivial for research projects
they receive instructions from
for research projects to
receive instructions from clients
research projects to export
instructions from clients to
projects to export their
from clients to start
to export their interfaces
clients to start and
export their interfaces in
to start and end
their interfaces in a
start and end a
interfaces in a language
and end a transaction
in a language independent
a language independent manner
and operations to perform
operations to perform on
the ensemble project for
to perform on individual
ensemble project for example
perform on individual objects
project for example has
on individual objects within
for example has developed
individual objects within the
example has developed a
objects within the transaction
has developed a protocol
developed a protocol environment
within the cdn nodes
a protocol environment for
the cdn nodes of
protocol environment for distributed
cdn nodes of g
environment for distributed operations
nodes of g radient
for distributed operations in
distributed operations in the
the tms predict which
operations in the ml
tms predict which objects
in the ml programming
predict which objects it
the ml programming language
which objects it is
the serverlets encapsulate application
objects it is likely
it is likely to
is likely to access
and by using a
speci n ac details
by using a com
n ac details such
using a com interface
ac details such as
and reserve these object
details such as the
reserve these object versions
such as the stream
a com interface are
as the stream data
com interface are the
the stream data format
interface are the services
are the services offered
the services offered by
services offered by ensemble
offered by ensemble available
by ensemble available to
they speculatively perform each
ensemble available to c
speculatively perform each operation
and the ways to
perform each operation with
the ways to transform
each operation with the
ways to transform a
operation with the help
to transform a the
with the help of
transform a the data
the help of the
help of the appropriate
of the appropriate oms
the appropriate oms and
java and vb programmers
appropriate oms and according
rich objects into more
oms and according to
objects into more specialized
and according to the
into more specialized ones
according to the order
this allowed the researchers
to the order set
allowed the researchers to
the order set by
the researchers to side
order set by the
set by the reservations
open issues include understanding
issues include understanding what
include understanding what kinds
step the time consuming
understanding what kinds of
the time consuming development
what kinds of content
time consuming development of
kinds of content may
consuming development of native
they certify the transaction
of content may be
development of native language
certify the transaction by
of native language interfaces
content may be subject
the transaction by checking
may be subject to
transaction by checking for
be subject to such
by checking for conflicts
subject to such transformation
it helps of course
checking for conflicts in
helps of course to
to such transformation and
of course to have
for conflicts in each
course to have all
such transformation and which
to have all the
conflicts in each log
have all the tools
transformation and which dynamic
and which dynamic content
which dynamic content is
dynamic content is not
to assess the effect
assess the effect of
the effect of the
effect of the transformation
operating system versions and
of the transformation on
membership monitors are in
the transformation on quality
system versions and their
transformation on quality and
monitors are in charge
on quality and traffic
are in charge of
quality and traffic rates
versions and their source
in charge of deciding
and their source code
charge of deciding and
their source code available
of deciding and publishing
deciding and publishing which
how transformation should be
and publishing which machines
transformation should be meaningfully
publishing which machines perform
should be meaningfully expressed
which machines perform which
microsoft is very generous
machines perform which roles
be meaningfully expressed and
is very generous to
meaningfully expressed and used
very generous to academia
expressed and used by
generous to academia and
and used by content
namely which machines run
to academia and makes
used by content providers
which machines run the
academia and makes all
machines run the log
and makes all their
run the log and
makes all their tools
the log and model
all their tools from
and to learn how
their tools from operating
log and model and
tools from operating systems
to learn how computationally
from operating systems to
and model and goal
operating systems to compilers
learn how computationally intensive
model and goal we
how computationally intensive such
and goal we assume
computationally intensive such transformation
goal we assume unreliable
intensive such transformation methods
we assume unreliable servers
including tons of documentation
assume unreliable servers that
tons of documentation as
unreliable servers that may
such transformation methods can
servers that may crash
of documentation as well
that may crash or
transformation methods can be
documentation as well as
methods can be without
may crash or hang
can be without overloading
as well as subscriptions
be without overloading the
well as subscriptions to
without overloading the nodes
as subscriptions to the
subscriptions to the developer
to the developer network
balancing bandwidth costs with
bandwidth costs with end
available to the departments
to the departments free
the departments free of
departments free of charge
to accommodate reliable storage
the g radi ent
g radi ent content
source code availability turned
radi ent content delivery
code availability turned out
ent content delivery system
availability turned out to
content delivery system is
turned out to be
delivery system is currently
out to be not
system is currently designed
to be not crucial
is currently designed to
currently designed to use
designed to use a
to use a spanningtree
use a spanningtree overlay
and was only once
was only once used
as explained in section
only once used to
once used to make
used to make actual
similar to most multicast
to make actual changes
to most multicast network
make actual changes to
most multicast network architectures
actual changes to the
changes to the operating
to the operating systems
with virtual links connecting
virtual links connecting g
links connecting g radient
von eicken et al
connecting g radient cdn
g radient cdn nodes
the system exposes a
system exposes a transactional
exposes a transactional data
a transactional data store
the question is to
transactional data store supporting
question is to determine
data store supporting serializable
is to determine what
store supporting serializable transactions
to determine what nodes
determine what nodes the
what nodes the in
a client invokes a
client invokes a begin
network processing and connecting
processing and connecting to
and connecting to the
the source is extremely
connecting to the diverse
source is extremely useful
to the diverse end
is extremely useful as
extremely useful as additional
useful as additional documentation
users should be done
to examine unexpected behaviour
examine unexpected behaviour or
unexpected behaviour or to
behaviour or to provide
or to provide templates
to provide templates for
provide templates for similar
we need to optimize
templates for similar projects
need to optimize the
a field from a
to optimize the overlay
field from a table
optimize the overlay to
as one can perform
the overlay to deliver
one can perform complete
overlay to deliver the
can perform complete source
to deliver the exact
perform complete source code
deliver the exact stream
complete source code level
the exact stream quality
source code level debugging
exact stream quality demanded
code level debugging of
stream quality demanded by
level debugging of all
quality demanded by users
debugging of all parts
demanded by users while
of all parts of
by users while minimizing
all parts of the
users while minimizing bandwidth
parts of the operating
while minimizing bandwidth costs
of the operating system
the operating system including
operating system including the
setting the value of
system including the kernel
the value of a
value of a field
of a field in
a field in a
field in a table
we propose to apply
source codes helps us
propose to apply an
codes helps us to
to apply an economics
helps us to develop
apply an economics framework
us to develop experimental
to develop experimental services
finally the client invokes
develop experimental services faster
the client invokes the
experimental services faster and
client invokes the endtransaction
considering two primary inputs
invokes the endtransaction command
services faster and in
two primary inputs in
faster and in tune
primary inputs in determining
and in tune with
inputs in determining the
in tune with existing
in determining the optimal
tune with existing functionality
determining the optimal network
and the system responds
the optimal network overlay
the system responds with
system responds with either
responds with either a
with either a commit
students are free to
either a commit or
on the one hand
are free to work
a commit or an
free to work with
commit or an abort
to work with the
we consider the cost
work with the source
consider the cost for
with the source code
the cost for network
committed transactions form a
the source code and
transactions form a serializable
cost for network edges
source code and are
form a serializable execution
for network edges to
code and are not
network edges to carry
and are not prohibited
edges to carry traffic
are not prohibited in
tms are equipped with
not prohibited in any
are equipped with predictors
prohibited in any way
similar to standard bandwidth
equipped with predictors that
in any way from
to standard bandwidth pricing
any way from applying
with predictors that foresee
way from applying the
predictors that foresee which
from applying the knowledge
that foresee which objects
applying the knowledge they
foresee which objects a
the knowledge they gained
which objects a transaction
knowledge they gained in
objects a transaction is
they gained in their
a transaction is likely
we leverage the perceived
transaction is likely to
gained in their later
is likely to access
in their later careers
likely to access on
leverage the perceived utility
to access on its
the perceived utility by
access on its initiation
perceived utility by end
interactions with the evil
with the evil empire
users for receiving the
for receiving the stream
the evil empire microsoft
receiving the stream at
the stream at a
evil empire microsoft realizes
stream at a given
at a given quality
empire microsoft realizes the
microsoft realizes the potential
realizes the potential of
the potential of widespread
potential of widespread adoption
the exact solution for
exact solution for this
in an implementation of
solution for this optimization
of widespread adoption of
for this optimization problem
an implementation of the
this optimization problem is
implementation of the system
widespread adoption of windows
optimization problem is intractable
of the system one
adoption of windows nt
the system one may
problem is intractable it
system one may use
is intractable it is
of windows nt for
intractable it is np
one may use multiple
windows nt for research
may use multiple oms
use multiple oms per
nt for research purposes
multiple oms per log
for research purposes and
research purposes and there
purposes and there is
dividing the log s
and there is dedicated
the log s object
log s object set
there is dedicated academic
we have developed algorithms
is dedicated academic relations
have developed algorithms that
dedicated academic relations team
or the other way
developed algorithms that give
the other way around
algorithms that give an
academic relations team whose
that give an approximate
relations team whose single
give an approximate optimal
an approximate optimal solution
have multiple logs report
team whose single task
multiple logs report to
whose single task it
logs report to a
single task it is
report to a single
task it is to
to a single om
it is to facilitate
is to facilitate the
in the case of
to facilitate the technology
the case of video
facilitate the technology transfer
case of video streams
the choice depends on
the technology transfer between
of video streams whose
choice depends on the
technology transfer between microsoft
video streams whose quality
depends on the throughput
transfer between microsoft and
streams whose quality and
between microsoft and academia
on the throughput of
microsoft and academia and
whose quality and traffic
and academia and vice
the throughput of the
academia and vice versa
quality and traffic rates
throughput of the specific
and traffic rates can
of the specific implementations
traffic rates can be
the specific implementations chosen
rates can be downgraded
can be downgraded by
specific implementations chosen for
be downgraded by g
source licensing is very
implementations chosen for each
downgraded by g radient
chosen for each service
by g radient cdn
licensing is very liberal
g radient cdn nodes
is very liberal compared
very liberal compared to
in this paper we
liberal compared to other
this paper we use
we have derived a
paper we use a
compared to other os
have derived a primaldual
to other os vendors
derived a primaldual approximation
other os vendors and
a primaldual approximation algorithm
os vendors and several
primaldual approximation algorithm which
vendors and several institutions
approximation algorithm which produces
and several institutions are
algorithm which produces a
several institutions are involved
which produces a solution
institutions are involved in
produces a solution whose
mapping for simplicity of
a solution whose total
are involved in active
solution whose total cost
for simplicity of presentation
involved in active exchanges
in active exchanges with
active exchanges with product
exchanges with product and
the difference between total
we now describe the
with product and research
now describe the operation
difference between total network
describe the operation of
product and research groups
the operation of acid
between total network traffic
and research groups within
total network traffic costs
research groups within microsoft
network traffic costs and
traffic costs and aggregate
costs and aggregate end
joint projects are in
projects are in progress
we start with an
start with an overview
with an overview of
an overview of the
is within a factor
overview of the system
within a factor of
joint papers are starting
of the system s
papers are starting to
the system s structure
are starting to appear
system s structure in
starting to appear and
s structure in section
to appear and academics
appear and academics frequently
and academics frequently present
academics frequently present cutting
frequently present cutting edge
present cutting edge result
cutting edge result to
edge result to microsoft
result to microsoft developers
to microsoft developers and
microsoft developers and researchers
of the optimal in
the optimal in the
optimal in the worst
in the worst case
and proceed to describe
proceed to describe the
to describe the algorithm
describe the algorithm in
the algorithm in section
we see that the
see that the algorithm
that the algorithm has
om for each shard
the algorithm has lower
operating systems there is
algorithm has lower total
systems there is a
and which tms are
has lower total cost
which tms are available
there is a direct
lower total cost compared
is a direct impact
a direct impact of
total cost compared to
direct impact of academia
cost compared to a
any client can access
impact of academia on
client can access any
of academia on microsoft
can access any tm
academia on microsoft products
access any tm for
compared to a single
any tm for any
tm for any given
to a single stream
for any given transaction
a single stream source
through involvement in the
single stream source and
involvement in the strategy
stream source and a
in the strategy phases
source and a minimum
other than the logs
the strategy phases of
and a minimum spanning
strategy phases of products
a minimum spanning tree
phases of products as
minimum spanning tree streaming
of products as well
server role assignment may
spanning tree streaming protocol
role assignment may be
products as well as
assignment may be inconsistent
tree streaming protocol in
as well as through
streaming protocol in a
well as through academic
protocol in a simulation
as through academic knowledge
in a simulation based
through academic knowledge transfer
a simulation based on
academic knowledge transfer into
simulation based on a
knowledge transfer into products
based on a collection
transfer into products and
on a collection of
into products and design
a collection of as
is supposed to be
products and design groups
supposed to be managed
to be managed by
be managed by a
managed by a single
by a single om
microsoft also provides research
also provides research funding
provides research funding for
research funding for some
funding for some relevant
for some relevant groups
some relevant groups and
relevant groups and fellowship
gradient mst naive broadcast
groups and fellowship and
mst naive broadcast total
and fellowship and research
naive broadcast total cost
fellowship and research internships
and research internships for
research internships for students
at a given time
summary four years of
but this may change
four years of research
this may change due
years of research on
may change due to
of research on windows
change due to an
research on windows nt
due to an unjustified
on windows nt have
to an unjustified crash
windows nt have taught
an unjustified crash suspicion
nt have taught us
unjustified crash suspicion whereupon
have taught us that
crash suspicion whereupon an
taught us that we
suspicion whereupon an object
us that we made
that we made the
we made the right
made the right choice
the right choice in
right choice in leaving
choice in leaving the
in leaving the unix
leaving the unix behind
windows nt is an
nt is an exiting
may temporarily be managed
temporarily be managed by
be managed by two
managed by two oms
years ahead of its
ahead of its competition
that do not know
do not know of
in its implementation and
not know of one
its implementation and in
know of one another
implementation and in the
and in the actual
in the actual services
the actual services offered
it took quite some
rain uses log servers
took quite some time
uses log servers for
quite some time to
log servers for reliable
some time to reach
servers for reliable storage
time to reach the
to reach the same
reach the same level
the same level of
each log server provides
same level of knowledge
log server provides a
level of knowledge and
server provides a sequentially
of knowledge and insight
provides a sequentially consistent
knowledge and insight we
a sequentially consistent log
and insight we used
sequentially consistent log object
insight we used to
we used to have
used to have of
to have of unix
have of unix systems
but now that we
now that we have
that we have arrived
we have arrived at
have arrived at that
arrived at that same
at that same knowledge
that same knowledge point
update operations are linearizable
is it clear that
but reads may return
it clear that our
reads may return outdated
clear that our research
may return outdated results
that our research is
our research is making
research is making progress
is making progress faster
making progress faster than
progress faster than ever
faster than ever before
multiple machines may append
machines may append entries
may append entries to
append entries to a
working with windows nt
entries to a log
with windows nt requires
windows nt requires certain
nt requires certain level
requires certain level of
certain level of resilience
machines may register to
may register to the
register to the log
not because of flaws
because of flaws in
of flaws in the
the log then sends
flaws in the operating
log then sends to
in the operating system
then sends to each
sends to each all
to each all entries
but because of the
because of the zealous
from the first one
of the zealous attacks
the first one in
the zealous attacks by
first one in the
zealous attacks by colleagues
one in the log
attacks by colleagues and
by colleagues and other
colleagues and other researchers
publishing papers about research
and then new entries
then new entries as
papers about research performed
new entries as they
entries as they arrive
about research performed on
research performed on windows
performed on windows nt
on windows nt is
an om may instruct
windows nt is still
om may instruct the
nt is still quite
may instruct the log
the g radient optimization
instruct the log to
is still quite difficult
the log to truncate
g radient optimization is
log to truncate its
still quite difficult as
to truncate its prefix
radient optimization is effective
quite difficult as many
optimization is effective compared
difficult as many of
is effective compared to
as many of our
effective compared to a
many of our peer
compared to a centralized
of our peer still
to a centralized source
our peer still believe
a centralized source and
peer still believe that
centralized source and a
still believe that no
source and a minimum
believe that no good
and a minimum spanning
that no good research
a minimum spanning tree
algorithm we now describe
no good research can
we now describe the
good research can be
now describe the acid
research can be performed
can be performed on
be performed on windows
performed on windows nt
protocol even as system
even as system sizes
as system sizes scale
we explain the reservation
system sizes scale up
explain the reservation and
we hope that eventually
the reservation and certification
hope that eventually the
reservation and certification protocol
that eventually the advanced
error bars represent one
eventually the advanced technical
bars represent one standard
the advanced technical nature
represent one standard deviation
advanced technical nature of
one standard deviation over
technical nature of the
nature of the operating
of the operating system
the operating system will
operating system will prevail
system will prevail in
will prevail in the
prevail in the discussion
then discuss prediction errors
and that we can
that we can have
we can have a
can have a community
have a community where
the details are deferred
a community where research
details are deferred to
community where research results
are deferred to a
a transaction begins with
where research results can
transaction begins with the
deferred to a full
begins with the tm
to a full report
with the tm receiving
a full report on
the tm receiving a
research results can be
tm receiving a begin
full report on g
results can be shared
report on g radient
can be shared without
be shared without sarcasm
shared without sarcasm or
without sarcasm or the
transaction instruction from the
sarcasm or the risk
instruction from the client
or the risk of
the risk of igniting
risk of igniting yet
of igniting yet another
igniting yet another holy
yet another holy war
conclusion a number of
a number of interesting
the tm assigns it
number of interesting open
tm assigns it a
assigns it a unique
of interesting open questions
it a unique txnid
interesting open questions remain
open questions remain the
questions remain the focus
remain the focus of
the focus of our
and predicts which objects
focus of our continued
predicts which objects the
of our continued investigation
which objects the transaction
objects the transaction will
the transaction will access
how diverse are the
diverse are the classes
are the classes of
it interrogates the oms
the classes of content
interrogates the oms about
classes of content that
the oms about all
of content that are
oms about all these
content that are amenable
about all these objects
that are amenable to
are amenable to our
amenable to our in
and they respond with
they respond with the
respond with the latest
with the latest unreserved
the latest unreserved timestamp
latest unreserved timestamp of
how do we best
unreserved timestamp of each
do we best assess
timestamp of each object
we best assess the
best assess the effect
assess the effect of
the effect of such
the tm chooses a
effect of such transformations
tm chooses a timestamp
of such transformations on
chooses a timestamp larger
such transformations on stream
a timestamp larger than
transformations on stream quality
timestamp larger than maximum
larger than maximum among
than maximum among the
maximum among the responses
how should these transformations
should these transformations be
these transformations be expressed
and asks the oms
asks the oms to
the oms to reserve
oms to reserve the
to reserve the objects
reserve the objects with
the objects with this
and utilized by the
objects with this timestamp
utilized by the originating
with this timestamp to
by the originating content
this timestamp to txnid
the originating content providers
originating content providers to
content providers to best
providers to best balance
to best balance content
the oms confirm the
oms confirm the reservation
confirm the reservation if
the reservation if no
domain specificity with ease
reservation if no concurrent
specificity with ease of
if no concurrent tm
with ease of development
no concurrent tm has
concurrent tm has reserved
tm has reserved a
has reserved a larger
reserved a larger timestamp
how can our overlay
a larger timestamp in
can our overlay respond
larger timestamp in the
timestamp in the meantime
our overlay respond to
overlay respond to churn
respond to churn among
to churn among g
the tm then proceeds
churn among g radient
tm then proceeds to
among g radient nodes
then proceeds to serve
g radient nodes realistically
proceeds to serve transaction
radient nodes realistically low
to serve transaction operations
nodes realistically low in
serve transaction operations by
realistically low in many
transaction operations by routing
low in many common
operations by routing them
in many common cases
by routing them to
many common cases such
routing them to the
common cases such as
them to the appropriate
cases such as video
to the appropriate oms
such as video streaming
but higher in alternative
each operation is sent
higher in alternative deployment
operation is sent to
in alternative deployment scenarios
expert testimony of professor
is sent to the
testimony of professor david
sent to the om
of professor david j
to the om in
the om in charge
om in charge of
in charge of the
charge of the object
how do we ensure
do we ensure that
we ensure that the
ensure that the computational
that the computational intensity
an example flow of
example flow of the
the computational intensity of
flow of the algorithm
computational intensity of our
intensity of our transformations
of our transformations do
our transformations do not
along with the txnid
transformations do not place
do not place too
not place too much
place too much load
too much load on
the oms order accesses
much load on our
oms order accesses based
load on our g
order accesses based on
on our g radient
accesses based on timestamp
our g radient overlay
based on timestamp reservations
g radient overlay nodes
and respond only when
respond only when the
only when the correct
when the correct version
the correct version is
correct version is available
g radient contributes a
radient contributes a novel
contributes a novel platform
a novel platform for
each committed transaction is
novel platform for continued
committed transaction is assigned
platform for continued study
transaction is assigned a
for continued study and
is assigned a timestamp
continued study and progress
study and progress to
and progress to ever
progress to ever more
to ever more effective
when reading an object
ever more effective delivery
more effective delivery mechanisms
the timestamp of the
timestamp of the latest
of the latest transaction
the latest transaction that
latest transaction that wrote
transaction that wrote this
that wrote this object
wrote this object is
this object is returned
object is returned to
is returned to the
returned to the tm
the transaction s timestamp
transaction s timestamp is
s timestamp is chosen
timestamp is chosen to
is chosen to be
chosen to be larger
to be larger than
be larger than the
larger than the largest
than the largest timestamp
the largest timestamp returned
largest timestamp returned by
timestamp returned by its
returned by its operations
and not larger than
not larger than its
larger than its reserved
than its reserved timestamp
once a tm receives
a tm receives an
tm receives an end
transaction instruction from a
instruction from a client
it notifies the transaction
notifies the transaction s
the transaction s oms
bandwidth multicast in cooperative
multicast in cooperative environments
detailing the transaction s
the transaction s timestamp
transaction s timestamp and
s timestamp and log
the logs in charge
logs in charge of
in charge of the
charge of the shards
of the shards it
the shards it touched
uwin unix for windows
when it receives such
it receives such a
receives such a notification
the usenix windows nt
usenix windows nt workshop
an om appends to
om appends to its
appends to its log
to its log an
its log an entry
log an entry consisting
an entry consisting of
entry consisting of the
consisting of the txnid
approaching the zettabyte era
such logs may be
cisco visual networking index
logs may be implemented
may be implemented with
be implemented with various
implemented with various techniques
from smr to log
smr to log chains
we abstract this write
global mobile data traffic
mobile data traffic forecast
data traffic forecast update
set with the read
with the read timestamps
and assume highly available
assume highly available logs
set with written values
th edition with source
edition with source code
action should be either
should be either committed
be either committed or
either committed or aborted
committed or aborted in
or aborted in all
aborted in all its
in all its logs
and therefore cannot be
therefore cannot be removed
cannot be removed from
be removed from any
removed from any of
from any of them
any of them before
of them before the
them before the result
before the result is
the result is published
the committing tm appends
committing tm appends a
tm appends a gc
appends a gc entry
a gc entry to
gc entry to all
entry to all the
to all the transaction
all the transaction s
the transaction s logs
transaction s logs after
s logs after receiving
multicast routing in datagram
logs after receiving an
routing in datagram internetworks
after receiving an acknowledgement
in datagram internetworks and
receiving an acknowledgement that
datagram internetworks and extended
an acknowledgement that they
internetworks and extended lans
acknowledgement that they all
that they all registered
they all registered the
all registered the transaction
registered the transaction s
acm transactions on computer
the transaction s result
transactions on computer systems
an om can invoke
om can invoke log
can invoke log prefix
invoke log prefix truncation
log prefix truncation if
prefix truncation if the
truncation if the prefix
if the prefix was
the prefix was summarized
and all its transactions
all its transactions have
its transactions have corresponding
transactions have corresponding gc
have corresponding gc entries
then waits for the
waits for the entry
for the entry to
the entry to appear
entry to appear in
to appear in the
appear in the log
a transaction is committed
transaction is committed if
is committed if and
committed if and only
if and only if
and only if it
only if it is
if it is written
it is written to
is written to all
written to all logs
and it does not
it does not conflict
does not conflict with
not conflict with previous
conflict with previous transactions
with previous transactions on
previous transactions on any
transactions on any of
on any of them
conflicts are violations of
are violations of read
read or writewrite order
each om checks for
om checks for local
checks for local conflicts
the design and implementation
for local conflicts by
design and implementation of
local conflicts by checking
and implementation of the
conflicts by checking timestamps
by checking timestamps in
checking timestamps in the
timestamps in the prefix
in the prefix of
the prefix of the
prefix of the log
of the log up
the log up to
log up to the
up to the transaction
to the transaction entry
and sends its local
sends its local result
to the calling tm
if all return success
then the transaction has
the transaction has committed
otherwise it has aborted
the tm notifies the
tm notifies the client
and analysis of a
notifies the client of
analysis of a peer
the client of the
client of the transaction
of the transaction result
the transaction result and
transaction result and instructs
result and instructs the
and instructs the oms
instructs the oms to
the oms to place
oms to place this
to place this result
place this result in
this result in the
result in the logs
the oms notify the
oms notify the tm
notify the tm once
the tm once the
tm once the results
once the results are
the results are logged
robustness in case of
in case of a
case of a tm
of a tm or
a tm or om
tm or om crash
what s new in
or a missing result
s new in windows
a missing result or
missing result or gc
result or gc entry
due to message loss
another tm may read
tm may read the
may read the transaction
read the transaction entry
the transaction entry in
transaction entry in one
entry in one of
in one of the
one of the logs
and continue the certification
continue the certification and
the certification and gc
certification and gc process
if a tm places
a tm places a
tm places a transaction
places a transaction entry
a transaction entry in
transaction entry in a
entry in a strict
in a strict subset
a strict subset of
strict subset of the
subset of the transaction
of the transaction s
scaling virtual worlds with
the transaction s log
virtual worlds with a
transaction s log set
worlds with a physical
with a physical metaphor
when another tm is
another tm is instructed
tm is instructed to
is instructed to fix
instructed to fix this
it cannot tell whether
cannot tell whether the
tell whether the original
whether the original tm
the original tm is
original tm is crashed
tm is crashed or
is crashed or slow
we introduce poison entries
the fixing tm places
fixing tm places a
tm places a poison
places a poison entry
a poison entry in
poison entry in the
entry in the logs
in the logs that
the logs that miss
logs that miss the
that miss the original
miss the original entry
a poison is interpreted
poison is interpreted as
is interpreted as a
interpreted as a transaction
as a transaction entry
a transaction entry with
transaction entry with a
entry with a conflict
the original entry may
original entry may either
entry may either arrive
may either arrive eventually
either arrive eventually or
arrive eventually or not
and the following are
the following are ignored
any tm can therefore
tm can therefore observe
can therefore observe the
therefore observe the log
observe the log and
the log and consistently
log and consistently determine
and consistently determine the
consistently determine the state
determine the state of
the state of the
state of the transaction
without a race hazard
prediction errors if there
errors if there are
if there are no
there are no prediction
are no prediction errors
there are no aborts
if the transaction accesses
the transaction accesses an
nick vasilatos and werner
transaction accesses an object
vasilatos and werner vogels
accesses an object that
an object that was
object that was not
that was not predicted
do you need source
you need source with
need source with that
this object has no
object has no reserved
has no reserved version
no reserved version for
panel at the usenix
reserved version for it
at the usenix windows
the usenix windows nt
usenix windows nt workshop
accessing it can therefore
it can therefore result
can therefore result in
therefore result in a
result in a conflict
in a conflict of
a conflict of the
conflict of the transaction
of the transaction or
the transaction or of
transaction or of the
or of the following
of the following ones
no conflict would occur
but if one does
if one does it
one does it will
does it will be
it will be detected
will be detected at
be detected at certification
detected at certification time
and result in an
result in an abort
in an abort of
an abort of a
abort of a transaction
performance may be slightly
may be slightly reduced
but consistency is maintained
summary in usenix login
if a transaction does
a transaction does not
transaction does not access
does not access an
not access an object
access an object that
an object that was
object that was predicted
the tm must still
a platform for distributed
tm must still release
platform for distributed service
must still release the
for distributed service deployment
still release the reservation
distributed service deployment in
release the reservation when
service deployment in end
the reservation when the
deployment in end user
reservation when the transaction
in end user homes
when the transaction ends
this reservation might slow
reservation might slow the
might slow the processing
slow the processing of
the processing of other
processing of other transactions
of other transactions that
other transactions that wait
transactions that wait for
that wait for its
wait for its release
unix application portability to
but would not break
application portability to windows
would not break consistency
portability to windows nt
to windows nt via
windows nt via an
nt via an alternative
via an alternative environment
if a tm is
an alternative environment subsystem
a tm is suspected
tm is suspected as
is suspected as failed
the usenix windows nt
usenix windows nt workshop
its reservations are revoked
this may harm performance
but cannot break consistency
evaluation we evaluate acid
rain by comparing its
by comparing its performance
comparing its performance to
its performance to the
performance to the classical
to the classical approach
the classical approach that
classical approach that does
approach that does not
that does not use
does not use prediction
not use prediction and
use prediction and compare
prediction and compare its
and compare its certification
compare its certification protocol
its certification protocol with
certification protocol with other
protocol with other certification
with other certification schemes
we use a custom
simulating each of the
each of the agents
of the agents in
the agents in the
agents in the system
in the system clients
our workloads are an
workloads are an adaptation
are an adaptation of
an adaptation of the
adaptation of the transactional
of the transactional ycsb
the transactional ycsb specification
protect the future of
the future of computing
future of computing technology
based on the original
each transaction has a
transaction has a set
has a set of
a set of read
update operations spread along
operations spread along its
spread along its execution
object accesses follow one
accesses follow one of
follow one of two
one of two different
of two different random
two different random distributions
where each object is
each object is chosen
object is chosen uniformly
is chosen uniformly at
chosen uniformly at random
gc logs are truncated
logs are truncated to
are truncated to conserve
truncated to conserve resources
to conserve resources and
conserve resources and to
resources and to reduce
and to reduce log
to reduce log replay
reduce log replay time
log replay time on
replay time on om
time on om recovery
each om occasionally summarizes
om occasionally summarizes the
occasionally summarizes the log
summarizes the log prefix
and places this summary
places this summary in
this summary in the
summary in the log
the presence of a
presence of a summary
of a summary of
a summary of the
summary of the log
of the log up
the log up to
log up to a
up to a certain
to a certain entry
a certain entry is
certain entry is not
entry is not sufficient
is not sufficient to
not sufficient to allow
sufficient to allow truncation
to allow truncation at
allow truncation at that
truncation at that entry
this reason is that
reason is that truncation
is that truncation must
that truncation must not
truncation must not break
must not break transaction
not break transaction certification
prediction our first test
our first test scenario
first test scenario imposes
test scenario imposes a
scenario imposes a load
imposes a load substantially
a load substantially below
load substantially below the
substantially below the system
below the system s
the system s capacity
system s capacity with
rx for data center
for data center communication
data center communication scalability
each transaction reads and
transaction reads and writes
the simulation is faithful
simulation is faithful to
is faithful to the
faithful to the algorithm
with the exception of
the exception of a
exception of a small
of a small shortcut
a small shortcut oms
small shortcut oms grant
shortcut oms grant reservations
oms grant reservations by
grant reservations by arrival
reservations by arrival time
by arrival time rather
arrival time rather than
time rather than by
rather than by timestamp
this results in deadlocks
results in deadlocks in
in deadlocks in high
deadlocks in high contention
in high contention scenarios
and these are resolved
these are resolved with
are resolved with timeouts
first we vary prediction
we vary prediction accuracy
process communication primitives for
the average ratio of
communication primitives for programming
average ratio of objects
primitives for programming distributed
ratio of objects the
for programming distributed systems
of objects the predictor
programming distributed systems robbert
objects the predictor guesses
distributed systems robbert van
the predictor guesses out
systems robbert van renesse
predictor guesses out of
guesses out of the
out of the set
of the set the
the set the transaction
department of computer science
set the transaction eventually
of computer science cornell
the transaction eventually accesses
computer science cornell university
science cornell university category
representation the following position
the following position paper
is equivalent to no
following position paper describes
equivalent to no prediction
position paper describes a
to no prediction and
paper describes a new
no prediction and no
describes a new interprocess
prediction and no reservation
a new interprocess communication
primitive that is designed
that is designed to
is designed to make
and an accuracy of
designed to make it
to make it easier
live streaming with utilities
make it easier to
it easier to program
easier to program distributed
to program distributed algorithms
it is largely based
means predicting all accesses
is largely based on
largely based on my
based on my experience
on my experience in
my experience in implementing
experience in implementing algorithms
in implementing algorithms such
implementing algorithms such as
algorithms such as distributed
such as distributed consensus
subject to your evaluation
to your evaluation of
your evaluation of my
evaluation of my proposal
i would be happy
increasing contention by decreasing
would be happy to
contention by decreasing the
be happy to present
by decreasing the number
happy to present this
decreasing the number of
to present this idea
the number of objects
present this idea at
this idea at the
idea at the workshop
ipc allows processes to
allows processes to share
processes to share information
to share information and
share information and to
information and to synchronize
and to synchronize actions
load with a hot
there are two classes
are two classes of
two classes of ipc
an architecture for scalable
architecture for scalable and
for scalable and fault
mc has processes communicate
has processes communicate send
processes communicate send and
communicate send and receive
send and receive messages
while sm allows processes
sm allows processes to
allows processes to share
increasing contention by increasing
processes to share data
contention by increasing the
to share data directly
by increasing the hot
share data directly while
data directly while synchronizing
directly while synchronizing using
while synchronizing using such
synchronizing using such primitives
using such primitives as
such primitives as mutexes
primitives as mutexes and
as mutexes and condition
mutexes and condition variables
commit rate drops as
rate drops as contention
drops as contention rises
where processes are physically
accurate prediction reduces or
processes are physically separated
prediction reduces or even
reduces or even eliminates
or even eliminates this
even eliminates this drop
mc is dominant as
is dominant as e
dominant as e orts
as e orts to
e orts to support
orts to support the
in highest contention scenarios
to support the sm
support the sm paradigm
the sm paradigm have
sm paradigm have not
paradigm have not been
even with moderate prediction
have not been successful
with moderate prediction accuracy
examples of sm include
we obtain significant improvement
of sm include tcp
obtain significant improvement over
sm include tcp connections
significant improvement over the
improvement over the classical
over the classical approach
the mc and sm
mc and sm paradigms
and sm paradigms are
sm paradigms are duals
paradigms are duals in
are duals in that
we define slack to
duals in that one
define slack to be
in that one can
slack to be the
that one can be
to be the average
one can be implememted
be the average ratio
can be implememted using
the average ratio between
be implememted using the
average ratio between the
implememted using the other
ratio between the number
between the number of
the number of accesses
but they also each
number of accesses predicted
they also each have
also each have their
of accesses predicted and
each have their advantages
have their advantages and
accesses predicted and the
their advantages and disadvantages
predicted and the number
advantages and disadvantages when
and the number of
and disadvantages when compared
the number of objects
disadvantages when compared with
number of objects accessed
when compared with one
of objects accessed by
compared with one another
objects accessed by the
accessed by the transaction
it is useful to
is useful to consider
useful to consider how
if a transaction accesses
to consider how distributed
consider how distributed algorithms
how distributed algorithms such
distributed algorithms such as
algorithms such as replication
then with a slack
with a slack of
typically it has much
it has much to
has much to do
much to do with
to do with progress
in order for some
order for some process
for some process to
some process to be
process to be able
to be able to
be able to make
able to make a
to make a transition
it would reserve another
it needs to know
needs to know that
to know that one
know that one or
that one or more
one or more other
or more other processes
more other processes have
other processes have reached
processes have reached a
have reached a particular
reached a particular milestone
now with uniform random
with uniform random load
uniform random load and
and some data associated
random load and a
some data associated with
load and a variable
data associated with that
and a variable number
associated with that milestone
a variable number of
variable number of objects
the effect of using
effect of using a
of using a perfect
using a perfect predictor
a new leader in
new leader in paxos
leader in paxos needs
in paxos needs to
paxos needs to know
needs to know that
to know that a
know that a quorum
that a quorum of
a quorum of acceptors
with predictors that overpredict
quorum of acceptors have
predictors that overpredict by
of acceptors have progressed
that overpredict by factors
acceptors have progressed to
overpredict by factors of
have progressed to its
progressed to its proposed
to its proposed ballot
its proposed ballot and
proposed ballot and it
ballot and it needs
and it needs to
it needs to know
needs to know what
to know what the
know what the highest
the impact of overprediction
what the highest accepted
impact of overprediction is
the highest accepted proposals
of overprediction is surprisingly
highest accepted proposals from
transparent error correction for
accepted proposals from those
overprediction is surprisingly minor
error correction for lambda
proposals from those acceptors
correction for lambda networks
from those acceptors are
for lambda networks mahesh
lambda networks mahesh balakrishnan
a finding that should
many if not all
if not all distributed
not all distributed algorithms
all distributed algorithms can
distributed algorithms can be
algorithms can be cleanly
can be cleanly expressed
be cleanly expressed this
cleanly expressed this way
as a collection of
a collection of transition
collection of transition specifications
of transition specifications that
transition specifications that specify
specifications that specify under
that specify under which
specify under which conditions
under which conditions they
which conditions they are
conditions they are enabled
they are enabled and
are enabled and what
enabled and what state
ordering transactions in advance
and what state they
transactions in advance reduces
what state they need
in advance reduces conflicts
state they need from
advance reduces conflicts and
they need from other
reduces conflicts and increases
need from other processes
conflicts and increases commit
and increases commit ratio
note the similarity to
the similarity to knowledge
high conflict rates occur
conflict rates occur without
rates occur without with
occur without with uniform
without with uniform access
with uniform access to
uniform access to a
access to a small
while the sm paradigm
to a small number
the sm paradigm seems
a small number of
sm paradigm seems the
small number of objects
paradigm seems the best
seems the best fit
the best fit for
best fit for this
fit for this model
for this model of
this model of distributed
model of distributed algorithms
and high probability of
the paradigm is hard
high probability of accessing
paradigm is hard to
probability of accessing a
is hard to make
of accessing a hotzone
hard to make efficient
abstract the global network
the global network of
and scalable in a
global network of datacenters
scalable in a physically
network of datacenters is
even inaccurate prediction is
in a physically distributed
of datacenters is emerging
inaccurate prediction is significant
a physically distributed system
prediction is significant in
datacenters is emerging as
is significant in high
is emerging as an
significant in high contention
emerging as an important
as an important distributed
an important distributed systems
important distributed systems paradigm
compared to the the
distributed systems paradigm commodity
it is notoriously errorprone
to the the classical
is notoriously errorprone as
the the classical approach
systems paradigm commodity clusters
notoriously errorprone as programmers
paradigm commodity clusters running
errorprone as programmers are
commodity clusters running high
as programmers are having
programmers are having difficulty
are having difficulty utilizing
having difficulty utilizing the
difficulty utilizing the synchronization
utilizing the synchronization primitives
the synchronization primitives correctly
the mc paradigm can
mc paradigm can be
speed lambda networks across
paradigm can be used
lambda networks across hundreds
can be used instead
networks across hundreds of
commit ratio is affected
across hundreds of milliseconds
be used instead but
hundreds of milliseconds of
ratio is affected if
of milliseconds of network
used instead but is
milliseconds of network latency
is affected if the
instead but is awkward
affected if the predictor
but is awkward and
if the predictor reserves
is awkward and error
the predictor reserves unnecessary
packet loss on long
predictor reserves unnecessary objects
reserves unnecessary objects by
unnecessary objects by a
objects by a factor
by a factor of
haul networks can cripple
prone as well it
networks can cripple application
a factor of slack
as well it requires
can cripple application performance
cripple application performance a
well it requires the
application performance a loss
performance a loss rate
it requires the programmer
a loss rate of
requires the programmer to
the programmer to figure
programmer to figure out
to figure out which
figure out which processes
out which processes should
note that when all
which processes should send
that when all accesses
processes should send which
when all accesses are
should send which data
all accesses are to
is sufficient to reduce
accesses are to the
send which data to
are to the hot
sufficient to reduce tcp
to the hot zone
which data to which
data to which destinations
to which destinations at
ip throughput by an
which destinations at which
throughput by an order
destinations at which times
by an order of
at which times in
an order of magnitude
which times in order
order of magnitude on
times in order to
of magnitude on a
in order to ensure
order to ensure that
to ensure that recipients
ensure that recipients of
that recipients of this
recipients of this data
of this data can
this data can make
data can make progress
commit rates are lower
sometimes messages are lost
rates are lower with
messages are lost if
are lower with imperfect
maelstrom is an edge
are lost if the
lower with imperfect prediction
is an edge appliance
lost if the receiver
with imperfect prediction than
an edge appliance that
imperfect prediction than in
if the receiver starts
prediction than in the
edge appliance that masks
than in the uniform
the receiver starts execution
appliance that masks packet
in the uniform random
that masks packet loss
the uniform random case
receiver starts execution after
uniform random case with
masks packet loss transparently
starts execution after the
packet loss transparently and
execution after the sender
loss transparently and quickly
after the sender has
transparently and quickly from
the sender has started
and quickly from inter
sender has started sending
has started sending messages
started sending messages to
sending messages to it
aggregating traffic for high
speed encoding and using
encoding and using a
and using a new
using a new forward
a new forward error
pray semantics of connectionless
new forward error correction
semantics of connectionless or
forward error correction scheme
of connectionless or non
error correction scheme to
correction scheme to handle
scheme to handle bursty
to handle bursty loss
blocking messaging primitives is
messaging primitives is one
primitives is one example
introduction the emergence of
this is because all
the emergence of commodity
often needless information is
is because all accesses
emergence of commodity clusters
because all accesses to
needless information is sent
all accesses to the
of commodity clusters and
accesses to the hot
information is sent as
commodity clusters and datacenters
is sent as more
clusters and datacenters has
sent as more recent
and datacenters has enabled
zone go through a
as more recent information
datacenters has enabled a
go through a single
more recent information makes
through a single om
has enabled a new
a single om that
recent information makes old
single om that becomes
enabled a new class
om that becomes a
information makes old messages
that becomes a bottleneck
a new class of
makes old messages obsolete
new class of globally
class of globally distributed
of globally distributed highperformance
on the bright side
globally distributed highperformance applications
using paxos again as
distributed highperformance applications that
paxos again as an
highperformance applications that coordinate
again as an example
since object access conflicts
applications that coordinate over
object access conflicts occur
that coordinate over vast
access conflicts occur only
coordinate over vast geographical
conflicts occur only at
over vast geographical distances
occur only at a
in the stream of
only at a single
the stream of values
at a single shard
stream of values that
of values that acceptors
values that acceptors accept
the reservations prevent deadlocks
a financial firm s
only the most recent
reservations prevent deadlocks and
the most recent one
financial firm s new
most recent one is
prevent deadlocks and result
recent one is of
firm s new york
one is of interest
deadlocks and result in
s new york city
and result in perfect
new york city datacenter
result in perfect commit
york city datacenter may
in perfect commit ratio
city datacenter may receive
perfect commit ratio with
datacenter may receive real
commit ratio with perfect
but most mc implementations
ratio with perfect prediction
most mc implementations will
mc implementations will carefully
implementations will carefully deliver
time updates from a
will carefully deliver each
updates from a stock
carefully deliver each and
from a stock exchange
deliver each and every
a stock exchange in
each and every one
stock exchange in switzerland
where some of the
some of the objects
conduct financial transactions with
of the objects belong
financial transactions with banks
delaying delivery of the
transactions with banks in
the objects belong to
with banks in asia
delivery of the important
objects belong to a
of the important information
belong to a so
the important information until
to a so called
important information until all
cache data in london
a so called hot
data in london for
information until all obsoleted
in london for locality
until all obsoleted information
london for locality and
all obsoleted information has
for locality and mirror
obsoleted information has been
locality and mirror it
information has been delivered
and mirror it to
has been delivered as
mirror it to kansas
been delivered as well
it to kansas for
and each access is
to kansas for disaster
each access is either
access is either to
is either to the
either to the hot
this leads to wasting
leads to wasting resources
to interconnect these bandwidth
potential deadlock situations due
deadlock situations due to
or outside of it
situations due to flow
due to flow control
hungry datacenters across the
to flow control leading
datacenters across the globe
flow control leading to
chosen uniformly within each
control leading to deadly
uniformly within each zone
leading to deadly embrace
organizations are increasingly deploying
are increasingly deploying private
increasingly deploying private lambda
and also obfuscates how
deploying private lambda networks
also obfuscates how the
obfuscates how the algorithms
how the algorithms work
we set an average
set an average transaction
an average transaction per
average transaction per unit
a new class of
new class of ipc
that that tries to
that tries to combine
tries to combine the
to combine the best
combine the best features
and transactions arrivals are
the best features of
transactions arrivals are governed
best features of sm
arrivals are governed by
features of sm and
of sm and mc
are governed by a
raw bandwidth is ubiquitous
governed by a poisson
bandwidth is ubiquitous and
by a poisson process
is ubiquitous and cheaply
a poisson process with
from sm it inherits
poisson process with the
ubiquitous and cheaply available
process with the required
sm it inherits direct
with the required tput
and cheaply available in
it inherits direct access
cheaply available in the
inherits direct access to
available in the form
direct access to and
in the form of
access to and synchro
the form of existing
form of existing dark
of existing dark fiber
nization on state rather
on state rather than
state rather than providing
we are unaware of
rather than providing a
are unaware of work
than providing a stream
unaware of work that
providing a stream of
of work that uses
running and maintaining high
work that uses prediction
a stream of state
that uses prediction to
stream of state updates
uses prediction to order
prediction to order distributed
to order distributed transactions
order distributed transactions before
distributed transactions before certification
free networks over this
while from mc it
networks over this fiber
from mc it inherits
over this fiber is
mc it inherits an
this fiber is difficult
it inherits an efficient
fiber is difficult and
inherits an efficient implementation
is difficult and expensive
an efficient implementation over
efficient implementation over the
implementation over the existing
over the existing physical
the existing physical infrastructure
capacity optical links are
uses static analysis to
the concept is that
optical links are almost
concept is that processes
static analysis to allow
is that processes publish
links are almost never
that processes publish facts
are almost never congested
analysis to allow separate
to allow separate workers
allow separate workers to
separate workers to process
which are information about
workers to process independent
are information about milestones
they drop packets for
information about milestones they
to process independent transactions
about milestones they have
drop packets for numerous
milestones they have reached
process independent transactions without
packets for numerous reasons
independent transactions without synchronization
for numerous reasons dirty
and subscribe to new
subscribe to new facts
the ipc interface is
rain s suggestive prediction
ipc interface is similar
interface is similar to
is similar to topic
gargamel determines the final
determines the final transaction
the final transaction order
and does not tolerate
does not tolerate false
not tolerate false positive
tolerate false positive prediction
false positive prediction errors
but there are several
there are several important
are several important semantic
several important semantic differences
it targets a different
targets a different setting
a different setting than
different setting than acid
interface is as follows
it is a fully
is a fully replicated
a fully replicated data
fully replicated data store
it will be the
will be the publishers
be the publishers that
the publishers that actively
publishers that actively try
that actively try to
actively try to push
with a centralized scheduler
try to push new
to push new facts
push new facts to
new facts to the
facts to the subscribers
for an increasing number
an increasing number of
paxos leaders publish new
increasing number of shards
leaders publish new ballots
for example and in
publish new ballots and
example and in different
new ballots and push
and in different patterns
ballots and push these
we run multiple simulations
and push these to
run multiple simulations to
push these to acceptors
multiple simulations to find
these to acceptors as
ranging from singleton drops
simulations to find the
from singleton drops to
to acceptors as acceptors
singleton drops to extended
to find the maximal
acceptors as acceptors do
drops to extended bursts
find the maximal tput
as acceptors do not
the maximal tput the
acceptors do not necessarily
maximal tput the system
do not necessarily know
tput the system can
not necessarily know what
the system can handle
necessarily know what the
know what the set
what the set of
the set of leaders
set of leaders is
a global log forms
global log forms a
log forms a bottleneck
old ballots are automatically
ballots are automatically dropped
are automatically dropped from
automatically dropped from the
dropped from the transmission
from the transmission queue
pc with smr tms
with smr tms is
smr tms is blocked
tms is blocked by
is blocked by contention
it will be the
blocked by contention much
will be the subscribers
by contention much earlier
be the subscribers that
contention much earlier than
the subscribers that actively
much earlier than acid
subscribers that actively poll
congestion loss has been
that actively poll the
loss has been observed
actively poll the publishers
has been observed on
been observed on long
rain due to its
due to its longer
to its longer certification
its longer certification time
haul networks as well
leaders and learners both
we briefly review here
and learners both subscribe
briefly review here work
learners both subscribe to
review here work related
both subscribe to acceptors
here work related to
subscribe to acceptors accepting
work related to acidrain
to acceptors accepting pvalues
related to acidrain s
acceptors accepting pvalues and
to acidrain s certification
accepting pvalues and poll
acidrain s certification protocol
pvalues and poll for
and poll for these
poll for these facts
one approach for certification
approach for certification is
for certification is to
certification is to use
is to use a
to use a single
use a single highly
available service that orders
service that orders all
that orders all transactions
orders all transactions in
all transactions in the
transactions in the system
as subscribers that su
subscribers that su ered
that su ered communication
su ered communication loss
ered communication loss due
communication loss due to
loss due to a
due to a network
to a network partition
a network partition or
network partition or having
partition or having been
or having been temporarily
having been temporarily subscribe
a transaction commits if
transaction commits if and
commits if and only
if and only if
and only if it
only if it has
if it has no
it has no conflicts
has no conflicts with
due to a user
no conflicts with previous
to a user closing
conflicts with previous committed
a user closing a
with previous committed transactions
user closing a laptop
will the interface requires
the interface requires that
interface requires that the
requires that the fact
that the fact type
the fact type for
fact type for a
type for a par
transaction rate is high
ms w n s
w n s e
n s e figure
continue to poll publishers
such a global service
to poll publishers to
a global service becomes
poll publishers to receive
global service becomes a
publishers to receive facts
service becomes a bottleneck
to receive facts they
receive facts they have
example lambda network tional
facts they have ticular
lambda network tional lambdarail
they have ticular topic
have ticular topic is
ticular topic is totally
topic is totally ordered
our system has no
system has no such
has no such bottleneck
and those facts will
those facts will missed
all this is invisible
this is invisible to
is invisible to the
invisible to the core
to the core application
the core application be
core application be delivered
application be delivered in
be delivered in order
serialized all transactions when
all transactions when they
transactions when they enter
when they enter the
they enter the system
any data can be
enter the system to
data can be made
the system to achieve
can be made to
system to achieve a
to achieve a deterministic
achieve a deterministic order
despite nondeterministic operations the
but can be managed
nondeterministic operations the transactions
can be managed through
operations the transactions take
be managed through the
managed through the contally
through the contally ordered
the contally ordered by
as has its crippling
contally ordered by tagging
has its crippling effect
ordered by tagging it
its crippling effect on
by tagging it with
crippling effect on commodity
tagging it with a
effect on commodity protocols
it with a sequence
they consider only stored
with a sequence number
consider only stored procedures
motivating research into loss
which enable this approach
resistant data transfer protocols
the hope is that
whereas we address long
hope is that fact
we address long running
address long running transactions
long running transactions and
running transactions and use
transactions and use prediction
based ipc will simplify
and use prediction to
ipc will simplify disbut
use prediction to infer
prediction to infer an
will simplify disbut often
to infer an order
simplify disbut often times
disbut often times facts
often times facts such
times facts such as
facts such as ballots
such as ballots are
as ballots are totally
ballots are totally ortributed
are totally ortributed programming
totally ortributed programming and
ortributed programming and make
programming and make it
and make it easier
make it easier to
it easier to reason
easier to reason dered
to reason dered already
transactions are also serialized
are also serialized by
also serialized by a
serialized by a central
by a central service
given a stream of
and then scheduled according
a stream of facts
then scheduled according to
stream of facts on
scheduled according to this
of facts on some
according to this global
facts on some topic
to this global order
about safety and liveness
rain avoids a central
the argument for this
avoids a central service
argument for this is
for this is only
this is only the
is only the highest
conservative flow control mechanisms
most recent fact need
flow control mechanisms designed
recent fact need be
control mechanisms designed to
fact need be delivered
mechanisms designed to deal
need be delivered that
designed to deal with
be delivered that the
to deal with the
delivered that the paradigm
deal with the systematic
that the paradigm allows
targets a different problem
the paradigm allows the
with the systematic congestion
paradigm allows the programmer
the systematic congestion of
allows the programmer to
systematic congestion of the
the programmer to clearly
congestion of the commodity
programmer to clearly eventually
of the commodity internet
the commodity internet react
commodity internet react too
internet react too sharply
react too sharply to
while older facts can
too sharply to ephemeral
older facts can be
sharply to ephemeral loss
facts can be dropped
to ephemeral loss on
ephemeral loss on over
where it embraces non
also specify transitions and
specify transitions and under
determinism and separates execution
transitions and under which
provisioned links a single
and under which conditions
and separates execution from
links a single packet
under which conditions they
separates execution from verification
a single packet loss
which conditions they di
single packet loss in
conditions they di erent
packet loss in ten
they di erent from
loss in ten thousand
di erent from pub
in ten thousand is
the result is somewhat
ten thousand is enough
result is somewhat analogous
thousand is enough to
is somewhat analogous to
is enough to reduce
somewhat analogous to our
enough to reduce tcp
analogous to our separation
to our separation of
our separation of optimistic
if no more facts
separation of optimistic ordering
no more facts are
ip throughput to a
more facts are enabled
throughput to a third
of optimistic ordering and
to a third over
facts are enabled without
a third over a
optimistic ordering and conservative
are enabled without having
ordering and conservative certification
enabled without having to
without having to worry
having to worry much
to worry much about
worry much about how
make it easier to
much about how are
it easier to create
about how are published
easier to create a
how are published but
to create a practical
are published but some
create a practical predictor
published but some process
and one in a
but some process later
one in a thousand
some process later subscribes
in a thousand drops
a thousand drops it
certification scalability to evaluate
thousand drops it by
scalability to evaluate the
drops it by an
to evaluate the scalability
it these conditions are
it by an order
these conditions are discovered
by an order of
evaluate the scalability of
an order of magnitude
the scalability of acid
will eventually receive the
eventually receive the most
receive the most recent
rain s certification mechanism
the most recent fact
time applications are impacted
applications are impacted by
assuming both publisher and
are impacted by the
both publisher and subscriber
impacted by the reliance
publisher and subscriber are
by the reliance of
and subscriber are correct
we avoid prediction and
the reliance of reliability
avoid prediction and measure
reliance of reliability mechanisms
prediction and measure the
of reliability mechanisms on
and measure the maximal
reliability mechanisms on acknowledgments
measure the maximal commit
mechanisms on acknowledgments and
these semantics are similar
on acknowledgments and retransmissions
semantics are similar to
the maximal commit rate
are similar to the
maximal commit rate it
similar to the anti
commit rate it can
rate it can accommodate
limiting the latency of
it can accommodate with
the latency of packet
can accommodate with an
latency of packet recovery
accommodate with an increasing
entropy style of gossip
with an increasing number
of packet recovery to
an increasing number of
style of gossip protocols
increasing number of shards
packet recovery to at
recovery to at least
to at least the
at least the round
least the round trip
but the underlying implementation
the round trip time
the underlying implementation can
underlying implementation can be
implementation can be anything
writes of objects chosen
there is also a
of objects chosen uniformly
is also a control
objects chosen uniformly at
also a control interface
chosen uniformly at random
a control interface that
if delivery is sequenced
uniformly at random from
control interface that controls
at random from a
interface that controls routing
random from a small
that controls routing of
from a small set
controls routing of facts
a small set of
routing of facts for
each lost packet acts
of facts for a
lost packet acts as
facts for a particular
packet acts as a
for a particular topic
acts as a virtual
as a virtual road
block in the fifo
in the fifo channel
the fifo channel until
paxos acceptors subscribe to
fifo channel until it
channel until it is
acceptors subscribe to ballots
until it is recovered
subscribe to ballots and
to ballots and to
ballots and to new
and to new proposals
to new proposals from
new proposals from leaders
resistant protocols is not
acidrain against two approaches
protocols is not an
when the leader publishes
is not an alternative
the leader publishes one
not an alternative in
leader publishes one of
an alternative in corporate
publishes one of these
more details in section
alternative in corporate datacenters
it is transmitted to
is transmitted to all
where standardization is the
transmitted to all subscribers
standardization is the key
is the key to
the key to low
key to low and
to low and predictable
smr tms is two
and the underlying communication
low and predictable maintenance
the underlying communication layer
and predictable maintenance costs
underlying communication layer will
phase commit with reliable
communication layer will continue
commit with reliable coordinators
layer will continue retransmission
will continue retransmission until
nei this work was
continue retransmission until either
this work was supported
retransmission until either acknowledged
work was supported in
until either acknowledged or
was supported in part
either acknowledged or another
supported in part by
acknowledged or another fact
in part by grants
or another fact renders
part by grants from
another fact renders it
by grants from afosr
fact renders it obsolete
global log is an
log is an architecture
is an architecture where
an architecture where tms
architecture where tms submit
where tms submit all
ther is eliminating loss
tms submit all transactions
is eliminating loss events
submit all transactions to
eliminating loss events on
all transactions to a
loss events on a
transactions to a single
events on a network
to a single global
on a network that
a single global log
a network that could
single global log and
network that could nsf
global log and check
that could nsf and
log and check conflicts
could nsf and intel
and check conflicts on
nsf and intel corporation
check conflicts on that
conflicts on that single
on that single log
span thousands of miles
there is a need
is a need to
a need to link
need to link loss
has lower latency for
side appliance locations of
lower latency for a
appliance locations of packet
latency for a given
locations of packet loss
for a given throughput
of packet loss receive
side appliance receiver buffer
appliance receiver buffer overflow
pc since its faster
since its faster certification
its faster certification reduces
local recovery receiving end
faster certification reduces contention
it has no bottleneck
has no bottleneck as
no bottleneck as with
bottleneck as with a
as with a global
with a global log
that has less overhead
has less overhead in
kernel code no dropped
less overhead in small
code no dropped packets
overhead in small scale
no dropped packets figure
while the parameters we
maelstrom communication path mask
the parameters we choose
communication path mask loss
parameters we choose are
path mask loss on
we choose are arbitrary
mask loss on the
loss on the link
the trends are robust
choosing other parameters would
other parameters would provide
parameters would provide similar
would provide similar trends
because recovery delays for
recovery delays for lost
delays for lost packets
for lost packets translate
lost packets translate into
packets translate into dramatic
translate into dramatic reductions
into dramatic reductions in
dramatic reductions in application
because applications and os
applications and os networking
and os networking stacks
os networking stacks in
networking stacks in commodity
stacks in commodity datacenters
in commodity datacenters cannot
swift institute swift institute
commodity datacenters cannot be
institute swift institute working
datacenters cannot be rewritten
swift institute working paper
cannot be rewritten from
institute working paper no
be rewritten from scratch
is a promising solution
a promising solution for
phase commit for transaction
promising solution for reliability
commit for transaction certification
solution for reliability over
for reliability over long
the downside of these
downside of these approaches
of these approaches compared
these approaches compared to
approaches compared to acid
rain is that they
is that they require
that they require a
they require a coordinator
require a coordinator that
a coordinator that performs
coordinator that performs transactions
packet recovery latency is
that performs transactions to
recovery latency is independent
performs transactions to be
latency is independent of
transactions to be highly
is independent of the
to be highly available
independent of the rtt
of the rtt of
the rtt of the
rtt of the link
s dilemma ittay eyal
dilemma ittay eyal publication
this requires another consensus
ittay eyal publication date
while fec codes have
fec codes have been
in addition to the
codes have been used
addition to the one
have been used for
to the one at
been used for decades
the one at the
used for decades within
one at the shard
for decades within link
at the shard itself
faster commodity processors have
commodity processors have enabled
processors have enabled packet
level fec at end
related work our transaction
work our transaction ordering
our transaction ordering protocol
transaction ordering protocol is
ordering protocol is inspired
electronic copy available at
protocol is inspired by
is inspired by a
inspired by a state
machine ordering mechanism suggested
ordering mechanism suggested by
mechanism suggested by lamport
but we have generalized
we have generalized the
have generalized the protocol
generalized the protocol to
the protocol to work
protocol to work with
to work with arbitrary
work with arbitrary overlapping
end fec is very
with arbitrary overlapping par
fec is very attractive
is very attractive for
very attractive for inter
references the approaches of
the approaches of mdcc
easy to deploy and
to deploy and customize
the miner s dilemma
miner s dilemma ittay
and does not require
s dilemma ittay eyal
does not require specialized
dilemma ittay eyal cornell
not require specialized equipment
ittay eyal cornell university
require specialized equipment in
specialized equipment in the
eyal cornell university abstract
equipment in the network
in the network linking
cornell university abstract an
the network linking the
university abstract an open
network linking the datacenters
abstract an open distributed
an open distributed system
open distributed system can
distributed system can be
are close to acid
system can be secured
can be secured by
be secured by requiring
secured by requiring participants
rain s certification mechanism
by requiring participants to
host fec has two
requiring participants to present
fec has two major
participants to present proof
has two major issues
to present proof of
two major issues first
present proof of work
proof of work and
of work and rewarding
work and rewarding them
and rewarding them for
it s not transparent
rewarding them for participation
rain separates the om
separates the om abstraction
the om abstraction from
om abstraction from the
requiring modification of the
abstraction from the highly
modification of the end
the bitcoin digital currency
bitcoin digital currency introduced
digital currency introduced this
currency introduced this mechanism
which is adopted by
is adopted by almost
adopted by almost all
leasing mechanism and fast
by almost all contemporary
mechanism and fast recovery
almost all contemporary digital
all contemporary digital currencies
contemporary digital currencies and
it s not necessarily
digital currencies and related
s not necessarily rapid
we also address garbage
currencies and related services
also address garbage collection
fec works best over
works best over high
which cannot be done
a natural process leads
cannot be done independently
natural process leads participants
be done independently at
process leads participants of
done independently at the
stable traffic rates and
independently at the logs
leads participants of such
traffic rates and performs
participants of such systems
rates and performs poorly
of such systems to
and performs poorly if
such systems to form
performs poorly if the
systems to form pools
poorly if the data
if the data rate
the data rate in
data rate in the
where members aggregate their
rate in the channel
members aggregate their power
in the channel is
aggregate their power and
the channel is low
their power and share
channel is low and
power and share the
is low and sporadic
and share the rewards
experience with bitcoin shows
with bitcoin shows that
bitcoin shows that the
shows that the largest
that the largest pools
the largest pools are
largest pools are often
pools are often open
as in a single
in a single end
allowing anyone to join
it has long been
has long been known
long been known that
been known that a
known that a member
that a member can
a member can sabotage
member can sabotage an
can sabotage an open
we present the maelstrom
sabotage an open pool
present the maelstrom error
an open pool by
open pool by seemingly
the maelstrom error correction
pool by seemingly joining
maelstrom error correction appliance
by seemingly joining it
error correction appliance a
seemingly joining it but
correction appliance a rack
joining it but never
appliance a rack of
it but never sharing
a rack of proxies
but never sharing its
rack of proxies residing
never sharing its proofs
of proxies residing between
sharing its proofs of
proxies residing between a
its proofs of work
residing between a datacenter
between a datacenter and
a datacenter and its
datacenter and its wan
and its wan link
the pool shares its
a new paradigm for
pool shares its revenue
new paradigm for building
shares its revenue with
paradigm for building scalable
its revenue with the
for building scalable distributed
revenue with the attacker
building scalable distributed systems
and so each of
so each of its
each of its participants
of its participants earns
its participants earns less
maelstrom encodes fec packets
encodes fec packets over
fec packets over traffic
packets over traffic flowing
we define and analyze
over traffic flowing through
define and analyze a
traffic flowing through it
and analyze a game
flowing through it and
analyze a game where
through it and routes
a game where pools
it and routes them
game where pools use
and routes them to
where pools use some
routes them to a
pools use some of
them to a corresponding
use some of their
to a corresponding appliance
some of their participants
a corresponding appliance at
of their participants to
corresponding appliance at the
their participants to infiltrate
appliance at the destination
participants to infiltrate other
at the destination datacenter
to infiltrate other pools
infiltrate other pools and
other pools and perform
pools and perform such
and perform such an
perform such an attack
which decodes them and
uses an architecture similar
decodes them and recovers
an architecture similar to
them and recovers lost
architecture similar to our
and recovers lost data
similar to our certification
with any number of
to our certification mechanism
any number of pools
maelstrom is completely transparent
is completely transparent it
but addresses minitransactions that
completely transparent it does
addresses minitransactions that are
transparent it does not
minitransactions that are submitted
it does not require
that are submitted as
does not require modification
are submitted as a
not require modification of
submitted as a whole
require modification of end
attacks is not a
is not a nash
not a nash equilibrium
with no attempt to
host software and is
no attempt to order
software and is agnostic
attempt to order potentially
and is agnostic to
to order potentially conflicting
is agnostic to the
order potentially conflicting transactions
agnostic to the network
we study the special
to the network connecting
study the special cases
the network connecting the
the special cases where
we address full transactions
network connecting the datacenter
special cases where either
cases where either two
where either two pools
where the clients sequentially
either two pools or
the clients sequentially access
two pools or any
clients sequentially access objects
pools or any number
sequentially access objects before
or any number of
access objects before ending
it eliminates the dependence
objects before ending a
any number of identical
before ending a transaction
eliminates the dependence of
number of identical pools
the dependence of fec
of identical pools play
dependence of fec recovery
identical pools play the
of fec recovery latency
and use prediction to
fec recovery latency on
use prediction to order
pools play the game
prediction to order them
recovery latency on the
to order them in
play the game and
order them in advance
latency on the data
the game and the
on the data rate
game and the rest
the data rate in
and the rest of
data rate in any
the rest of the
rate in any single
we believe our techniques
rest of the participants
in any single node
of the participants are
believe our techniques could
the participants are uninvolved
our techniques could be
techniques could be used
could be used to
be used to reduce
used to reduce abort
in both of these
node channel by encoding
to reduce abort rates
both of these cases
reduce abort rates of
channel by encoding over
abort rates of systems
by encoding over the
of these cases there
encoding over the aggregated
rates of systems using
over the aggregated traffic
of systems using sinfonia
these cases there exists
systems using sinfonia or
the aggregated traffic leaving
using sinfonia or a
aggregated traffic leaving the
cases there exists an
sinfonia or a similar
traffic leaving the datacenter
or a similar certification
there exists an equilibrium
a similar certification mechanism
exists an equilibrium that
an equilibrium that constitutes
equilibrium that constitutes a
that constitutes a tragedy
maelstrom uses a new
constitutes a tragedy of
uses a new encoding
a tragedy of the
a new encoding scheme
tragedy of the commons
new encoding scheme called
of the commons where
encoding scheme called layered
the commons where the
scheme called layered interleaving
commons where the participating
where the participating pools
the participating pools attack
participating pools attack one
designed especially for time
pools attack one another
attack one another and
one another and earn
another and earn less
sensitive packet recovery in
and earn less than
packet recovery in the
earn less than they
recovery in the presence
less than they would
in the presence of
than they would have
the presence of bursty
they would have if
presence of bursty loss
would have if none
have if none had
if none had attacked
the contributions of this
contributions of this paper
of this paper are
this paper are as
paper are as follows
the decision whether or
decision whether or not
whether or not to
or not to attack
not to attack is
to attack is the
attack is the miner
is the miner s
the miner s dilemma
end fec for long
an instance of the
instance of the iterative
distance communication between datacenters
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
and argue that the
argue that the rate
the game is played
that the rate sensitivity
game is played daily
the rate sensitivity of
is played daily by
rate sensitivity of fec
played daily by the
sensitivity of fec codes
daily by the active
of fec codes and
by the active bitcoin
fec codes and the
the active bitcoin pools
codes and the opacity
and the opacity of
the opacity of their
opacity of their implementations
of their implementations present
which apparently choose not
their implementations present major
apparently choose not to
implementations present major obstacles
choose not to attack
present major obstacles to
major obstacles to their
obstacles to their usage
if this balance breaks
the revenue of open
revenue of open pools
of open pools might
open pools might diminish
a gateway appliance that
gateway appliance that transparently
appliance that transparently aggregates
making them unattractive to
that transparently aggregates traffic
them unattractive to participants
transparently aggregates traffic and
aggregates traffic and encodes
traffic and encodes over
and encodes over the
encodes over the resulting
over the resulting high
we describe layered interleaving
a new fec scheme
is a digital currency
new fec scheme used
a digital currency that
fec scheme used by
digital currency that is
scheme used by maelstrom
currency that is gaining
used by maelstrom where
that is gaining acceptance
by maelstrom where for
highly available storage for
maelstrom where for constant
available storage for interactive
where for constant encoding
storage for interactive services
for constant encoding overhead
constant encoding overhead the
encoding overhead the latency
overhead the latency of
the latency of packet
latency of packet recovery
of packet recovery degrades
packet recovery degrades gracefully
recovery degrades gracefully as
degrades gracefully as losses
gracefully as losses get
as losses get burstier
we discuss implementation considerations
with an estimated market
we built two versions
an estimated market capitalization
built two versions of
estimated market capitalization of
two versions of maelstrom
market capitalization of over
one runs in user
runs in user mode
while the other runs
the other runs within
other runs within the
runs within the linux
within the linux kernel
we evaluate maelstrom on
evaluate maelstrom on emulab
and show that it
show that it provides
that it provides near
it provides near lossless
provides near lossless tcp
ip throughput and latency
throughput and latency over
and latency over lossy
bitcoin s security stems
latency over lossy links
s security stems from
security stems from a
stems from a robust
from a robust incentive
a robust incentive system
a transactional record manager
and recovers packets with
transactional record manager for
recovers packets with latency
record manager for shared
packets with latency independent
participants are required to
manager for shared flash
with latency independent of
are required to provide
latency independent of the
required to provide expensive
independent of the rtt
to provide expensive proofs
of the rtt of
provide expensive proofs of
the rtt of the
expensive proofs of work
rtt of the link
of the link and
the link and the
link and the rate
and the rate in
and they are rewarded
the rate in any
they are rewarded according
rate in any single
are rewarded according to
in any single channel
rewarded according to their
according to their efforts
this architecture has proved
architecture has proved both
has proved both stable
proved both stable and
model our focus is
both stable and scalable
our focus is on
focus is on pairs
is on pairs of
on pairs of geographically
and it is used
pairs of geographically distant
it is used by
of geographically distant datacenters
is used by most
geographically distant datacenters that
used by most contemporary
distant datacenters that coordinate
by most contemporary digital
datacenters that coordinate with
most contemporary digital currencies
that coordinate with each
contemporary digital currencies and
coordinate with each other
digital currencies and related
with each other in
currencies and related services
each other in real
this has long been
has long been a
long been a critical
been a critical distributed
a critical distributed computing
critical distributed computing paradigm
distributed computing paradigm in
computing paradigm in application
paradigm in application domains
in application domains such
application domains such as
domains such as finance
such as finance and
as finance and aerospace
a middleware for highperformance
middleware for highperformance transaction
for highperformance transaction processing
similar requirements are arising
requirements are arising across
are arising across the
arising across the board
across the board as
the board as globalized
board as globalized enterprises
as globalized enterprises rely
globalized enterprises rely on
enterprises rely on networks
rely on networks for
on networks for high
speed communication and collaboration
the most general case
most general case of
general case of inter
cluster communication is one
communication is one where
is one where any
one where any node
where any node in
any node in one
node in one cluster
in one cluster can
one cluster can communicate
cluster can communicate with
can communicate with any
communicate with any node
with any node in
any node in the
node in the other
in the other cluster
our results apply to
we make no assumptions
results apply to all
make no assumptions about
apply to all such
no assumptions about the
to all such incentive
assumptions about the type
all such incentive systems
about the type of
the type of traffic
type of traffic flowing
of traffic flowing through
traffic flowing through the
flowing through the link
but we use bitcoin
we use bitcoin terminology
use bitcoin terminology and
bitcoin terminology and examples
terminology and examples since
and examples since it
boosting dbms performance by
examples since it serves
dbms performance by parallelising
since it serves as
performance by parallelising write
it serves as an
critical applications could send
serves as an active
by parallelising write transactions
as an active and
applications could send dynamically
an active and archetypal
could send dynamically generated
active and archetypal example
send dynamically generated real
bitcoin implements its incentive
time data such as
implements its incentive systems
data such as stock
its incentive systems with
such as stock quotes
incentive systems with a
systems with a data
with a data structure
a data structure called
data structure called the
financial transactions and battleground
structure called the blockchain
transactions and battleground location
and battleground location updates
the blockchain is a
blockchain is a serialization
while enterprise applications could
is a serialization of
enterprise applications could send
a serialization of all
applications could send voip
serialization of all bitcoin
could send voip streams
of all bitcoin transactions
ssh sessions and synchronous
prediction of transaction behavior
sessions and synchronous file
it is a single
of transaction behavior has
is a single global
and synchronous file updates
a single global ledger
synchronous file updates between
transaction behavior has the
file updates between offices
single global ledger maintained
behavior has the potential
global ledger maintained by
has the potential to
ledger maintained by an
the potential to significantly
maintained by an open
potential to significantly decrease
by an open distributed
to significantly decrease abort
an open distributed system
significantly decrease abort rates
packet loss typically occurs
decrease abort rates in
loss typically occurs at
abort rates in large
typically occurs at two
rates in large scale
occurs at two points
since anyone can join
in large scale transactional
anyone can join the
at two points in
can join the open
two points in an
join the open system
points in an end
large scale transactional systems
the open system and
scale transactional systems with
open system and participate
transactional systems with high
system and participate in
systems with high contention
and participate in maintaining
participate in maintaining the
in maintaining the blockchain
end communication path between
communication path between two
path between two datacenters
bitcoin uses a proof
uses a proof of
rain we employ prediction
a proof of work
as shown in figure
proof of work mechanism
we employ prediction to
of work mechanism to
work mechanism to deter
employ prediction to obtain
mechanism to deter attacks
prediction to obtain soft
to obtain soft reservations
obtain soft reservations and
soft reservations and implement
area network connecting them
participation requires exerting significant
network connecting them and
reservations and implement atomic
connecting them and at
requires exerting significant computational
and implement atomic transactions
them and at the
exerting significant computational resources
and at the receiving
implement atomic transactions while
at the receiving end
atomic transactions while requiring
transactions while requiring high
while requiring high availability
a participant who proves
requiring high availability only
participant who proves she
high availability only in
who proves she has
availability only in a
loss in the lambda
only in a single
proves she has exerted
in a single tier
in the lambda link
she has exerted enough
the lambda link can
a single tier of
lambda link can occur
single tier of independent
link can occur for
has exerted enough resources
can occur for many
tier of independent logs
occur for many reasons
exerted enough resources with
enough resources with a
resources with a proof
with a proof of
this allows for low
a proof of work
proof of work is
of work is allowed
work is allowed to
is allowed to take
allowed to take a
dirty or degraded fiber
to take a step
take a step in
a step in the
step in the protocol
in the protocol by
malfunctioning or misconfigured equipment
the protocol by generating
protocol by generating a
by generating a block
rain s operations never
s operations never depend
low receiver power and
operations never depend on
receiver power and burst
never depend on a
power and burst switching
participants are compensated for
and burst switching contention
depend on a single
burst switching contention are
are compensated for their
switching contention are some
on a single machine
contention are some reasons
a single machine by
compensated for their efforts
single machine by allowing
for their efforts with
machine by allowing fast
their efforts with newly
by allowing fast recovery
efforts with newly minted
allowing fast recovery from
with newly minted bitcoins
fast recovery from failures
recovery from failures and
from failures and performance
failures and performance hiccups
the process of creating
process of creating a
of creating a block
creating a block is
a block is called
block is called mining
and the participants miners
in order to win
order to win the
to win the reward
many miners try to
miners try to generate
try to generate blocks
the system automatically adjusts
system automatically adjusts the
automatically adjusts the difficulty
adjusts the difficulty of
the difficulty of block
difficulty of block generation
such that one block
that one block is
one block is added
block is added every
minutes to the blockchain
loss can also occur
can also occur at
also occur at receiving
this means that each
occur at receiving endhosts
means that each miner
at receiving endhosts within
that each miner seldom
receiving endhosts within the
each miner seldom generates
endhosts within the destination
miner seldom generates a
within the destination datacenter
seldom generates a block
although its revenue may
benchmarking cloud serving systems
these are usually cheap
cloud serving systems with
its revenue may be
are usually cheap commodity
revenue may be positive
serving systems with ycsb
may be positive in
usually cheap commodity machines
be positive in expectation
cheap commodity machines prone
commodity machines prone to
machines prone to temporary
prone to temporary overloads
a miner may have
to temporary overloads that
miner may have to
temporary overloads that cause
may have to wait
overloads that cause packets
have to wait for
that cause packets to
to wait for an
cause packets to be
wait for an extended
packets to be dropped
for an extended period
to be dropped by
an extended period to
be dropped by the
extended period to create
dropped by the kernel
period to create a
by the kernel in
to create a block
the kernel in bursts
create a block and
a block and earn
block and earn the
and earn the actual
earn the actual bitcoins
this loss mode occurs
miners form mining pools
loss mode occurs with
mode occurs with udp
where all members mine
based traffic but not
all members mine concurrently
traffic but not with
members mine concurrently and
but not with tcp
mine concurrently and they
concurrently and they share
and they share their
they share their revenue
share their revenue whenever
their revenue whenever one
revenue whenever one of
whenever one of them
one of them creates
which advertises receiver windows
of them creates a
advertises receiver windows to
them creates a block
receiver windows to prevent
windows to prevent end
pools are typically implemented
what are typical loss
are typically implemented as
are typical loss rates
typically implemented as a
typical loss rates on
implemented as a pool
loss rates on long
as a pool manager
a pool manager and
pool manager and a
manager and a cohort
and a cohort of
a cohort of miners
one source of information
source of information is
of information is teragrid
the pool manager joins
pool manager joins the
manager joins the bitcoin
joins the bitcoin system
the bitcoin system as
bitcoin system as a
system as a single
as a single miner
instead of generating proof
of generating proof of
generating proof of work
we plan to build
plan to build on
an optical network interconnecting
to build on our
optical network interconnecting major
build on our simulation
it outsources the work
on our simulation results
outsources the work to
our simulation results by
the work to the
network interconnecting major supercomputing
work to the miners
simulation results by implementing
interconnecting major supercomputing sites
results by implementing acid
major supercomputing sites in
supercomputing sites in the
sites in the us
in order to evaluate
order to evaluate the
rain and exploring the
to evaluate the miners
and exploring the different
evaluate the miners efforts
teragrid has a monitoring
exploring the different aspects
has a monitoring framework
the different aspects of
a monitoring framework within
different aspects of its
monitoring framework within which
aspects of its performance
framework within which ten
of its performance in
within which ten sites
the pool manager accepts
which ten sites periodically
its performance in realistic
pool manager accepts partial
performance in realistic settings
ten sites periodically send
manager accepts partial proof
sites periodically send each
accepts partial proof of
periodically send each other
partial proof of work
of particular interest are
proof of work and
of work and estimates
work and estimates each
gbps streams of udp
and estimates each miner
streams of udp packets
estimates each miner s
of udp packets and
each miner s power
udp packets and measure
miner s power according
packets and measure the
s power according to
and measure the resulting
different network topologies with
measure the resulting loss
power according to the
the resulting loss rate
network topologies with a
according to the rate
topologies with a single
to the rate with
with a single datacenter
the rate with which
a single datacenter and
rate with which it
single datacenter and with
with which it submits
datacenter and with multiple
which it submits such
and with multiple datacenters
it submits such partial
submits such partial proof
such partial proof of
partial proof of work
when a miner generates
each site measures the
a miner generates a
site measures the loss
miner generates a full
measures the loss rate
generates a full proof
the loss rate to
a full proof of
loss rate to every
full proof of work
rate to every other
behavior in face of
to every other site
in face of high
every other site once
face of high contention
other site once an
site once an hour
it sends it to
sends it to the
it to the pool
to the pool manager
resulting in a total
the pool manager which
in a total of
rain should prove efficient
pool manager which publishes
manager which publishes this
which publishes this proof
publishes this proof of
this proof of work
proof of work to
of work to the
work to the bitcoin
to the bitcoin system
where its overhead may
loss rate measurements collected
its overhead may be
rate measurements collected across
overhead may be wasteful
measurements collected across the
collected across the network
the pool manager thus
across the network every
pool manager thus receives
the network every hour
manager thus receives the
thus receives the full
receives the full revenue
the full revenue of
full revenue of the
revenue of the block
of the block and
the block and distributes
block and distributes it
and distributes it fairly
distributes it fairly according
it fairly according to
behavior in error prone
fairly according to its
in error prone scenarios
according to its members
to its members power
many of the pools
of the pools are
the pools are open
pools are open they
are open they allow
open they allow any
they allow any miner
performance with predictors of
allow any miner to
with predictors of different
any miner to join
predictors of different qualities
miner to join them
to join them using
join them using a
them using a public
using a public internet
a public internet interface
such open pools are
open pools are susceptible
pools are susceptible to
are susceptible to the
susceptible to the classical
to the classical block
the classical block withholding
classical block withholding attack
of all such measurements
all such measurements were
such measurements were over
where a miner sends
a miner sends only
miner sends only partial
sends only partial proof
only partial proof of
partial proof of work
proof of work to
of work to the
work to the pool
to the pool manager
the pool manager and
pool manager and discards
manager and discards full
and discards full proof
discards full proof of
full proof of work
lightweight elasticity in shared
due to the partial
elasticity in shared storage
to the partial proof
in shared storage databases
the partial proof of
shared storage databases for
partial proof of work
storage databases for the
proof of work it
databases for the cloud
of work it sends
for the cloud using
work it sends to
the cloud using live
it sends to the
cloud using live data
sends to the pool
of them were over
using live data migration
the miner is considered
miner is considered a
is considered a regular
considered a regular pool
a regular pool member
regular pool member and
pool member and the
member and the pool
and the pool can
the pool can estimate
pool can estimate its
can estimate its power
after eliminating a single
eliminating a single site
the attacker shares the
attacker shares the revenue
shares the revenue obtained
the revenue obtained by
revenue obtained by the
obtained by the other
that dropped incoming packets
by the other pool
dropped incoming packets steadily
the other pool members
incoming packets steadily at
packets steadily at a
steadily at a rate
at a rate of
but does not contribute
it reduces the revenue
reduces the revenue of
the revenue of the
revenue of the other
of the other members
but also its own
we provide necessary background
provide necessary background on
necessary background on the
background on the bitcoin
on the bitcoin protocol
pools and the classical
and the classical block
the classical block withholding
classical block withholding attack
block withholding attack in
withholding attack in section
of the remainder were
attack in section ii
the remainder were over
and specify our model
specify our model in
our model in section
model in section iii
live migration in shared
for a broader view
migration in shared nothing
a broader view of
in shared nothing databases
broader view of the
shared nothing databases for
view of the protocol
nothing databases for elastic
of the protocol and
databases for elastic cloud
the protocol and ecosystem
for elastic cloud platforms
protocol and ecosystem the
and ecosystem the reader
ecosystem the reader may
the reader may refer
reader may refer to
may refer to the
refer to the survey
to the survey by
the survey by bonneau
survey by bonneau et
by bonneau et al
these numbers reflect the
numbers reflect the loss
reflect the loss rate
the loss rate experienced
loss rate experienced for
rate experienced for udp
experienced for udp traffic
for udp traffic on
udp traffic on an
traffic on an end
in this work we
this work we analyze
work we analyze block
we analyze block withholding
analyze block withholding attacks
block withholding attacks among
withholding attacks among pools
end path and may
path and may not
and may not generalize
may not generalize to
not generalize to tcp
generalize to tcp packets
a pool that employs
pool that employs the
that employs the pool
employs the pool block
the pool block withholding
pool block withholding attack
block withholding attack registers
withholding attack registers with
we do not know
attack registers with the
do not know if
registers with the victim
not know if packets
with the victim pool
know if packets were
the victim pool as
if packets were dropped
victim pool as a
packets were dropped within
pool as a regular
were dropped within the
as a regular miner
dropped within the optical
within the optical network
the optical network or
optical network or at
it receives tasks from
network or at intermediate
receives tasks from the
or at intermediate devices
tasks from the victim
at intermediate devices within
from the victim pool
intermediate devices within either
the victim pool and
devices within either datacenter
victim pool and transfers
pool and transfers them
and transfers them to
transfers them to some
them to some of
though it s unlikely
to some of its
it s unlikely that
some of its own
s unlikely that they
of its own miners
unlikely that they were
that they were dropped
they were dropped at
were dropped at the
dropped at the end
we call these infiltrating
call these infiltrating miners
and the mining power
the mining power spent
many of the mea
mining power spent by
power spent by a
spent by a pool
by a pool the
a pool the infiltration
pool the infiltration rate
surements lost just one
lost just one or
just one or two
one or two packets
or two packets whereas
when electronic copy available
two packets whereas kernel
electronic copy available at
nic losses are known
losses are known to
are known to be
known to be bursty
loss occurred on paths
occurred on paths where
on paths where levels
paths where levels of
where levels of optical
levels of optical link
of optical link utilization
the dangers of replication
dangers of replication and
of replication and d
were consistently lower than
the attacking pool s
attacking pool s infiltrating
pool s infiltrating miners
s infiltrating miners deliver
infiltrating miners deliver partial
miners deliver partial proofs
deliver partial proofs of
partial proofs of work
fast distributed transactions a
distributed transactions a solution
the attacker transfers them
attacker transfers them to
transfers them to the
them to the victim
ruling out congestion as
to the victim pool
out congestion as a
congestion as a possible
as a possible cause
letting the attacked pool
the attacked pool estimate
attacked pool estimate their
a conclusion supported by
pool estimate their power
conclusion supported by dialogue
supported by dialogue with
by dialogue with the
dialogue with the network
with the network administrators
when the infiltrating miners
the infiltrating miners deliver
infiltrating miners deliver a
miners deliver a full
deliver a full proof
a full proof of
full proof of work
for partitioned database systems
the attacking pool discards
attacking pool discards it
this attack affects the
attack affects the revenues
affects the revenues of
the revenues of the
revenues of the pools
of the pools in
the pools in several
points are provided by
pools in several ways
are provided by the
provided by the back
the victim pool s
bone networks of tier
victim pool s effective
pool s effective mining
s effective mining rate
effective mining rate is
mining rate is unchanged
but its total revenue
its total revenue is
total revenue is divided
revenue is divided among
global crossing reports average
is divided among more
crossing reports average loss
divided among more miners
reports average loss rates
average loss rates between
the attacker s mining
attacker s mining power
s mining power is
mining power is reduced
since some of its
some of its miners
of its miners are
its miners are used
miners are used for
are used for block
used for block withholding
but it earns additional
it earns additional revenue
earns additional revenue through
additional revenue through its
revenue through its infiltration
through its infiltration of
its infiltration of the
infiltration of the other
of the other pool
distributed main memory transaction
main memory transaction processing
memory transaction processing system
on four of its
the total effective mining
four of its six
total effective mining power
of its six inter
effective mining power in
mining power in the
power in the system
in the system is
the system is reduced
haul links for the
causing the bitcoin protocol
links for the month
the bitcoin protocol to
for the month of
bitcoin protocol to reduce
the month of december
protocol to reduce the
to reduce the difficulty
taking all these factors
all these factors into
these factors into account
we observe that a
observe that a pool
that a pool might
a pool might be
pool might be able
might be able to
be able to increase
able to increase its
to increase its revenue
increase its revenue by
its revenue by attacking
revenue by attacking other
by attacking other pools
qwest reports loss rates
each pool therefore makes
reports loss rates of
pool therefore makes a
therefore makes a choice
makes a choice of
a choice of whether
choice of whether to
of whether to attack
whether to attack each
to attack each of
attack each of the
each of the other
of the other pools
the other pools in
other pools in the
pools in the system
and with what infiltration
with what infiltration rate
this gives rise to
gives rise to the
rise to the pool
to the pool game
we specify this game
specify this game and
this game and provide
game and provide initial
and provide initial analysis
in either direction on
provide initial analysis in
either direction on its
initial analysis in section
direction on its trans
analysis in section iv
pacific link for the
link for the same
in section v we
for the same month
section v we analyze
v we analyze the
we analyze the scenario
analyze the scenario where
the scenario where exactly
scenario where exactly two
where exactly two of
exactly two of the
two of the pools
of the pools take
the pools take part
verify replication for multi
pools take part in
take part in the
we expect privately managed
part in the game
expect privately managed lambdas
in the game and
privately managed lambdas to
the game and only
managed lambdas to exhibit
game and only one
lambdas to exhibit higher
and only one can
to exhibit higher loss
only one can attack
exhibit higher loss rates
one can attack the
higher loss rates due
can attack the other
loss rates due to
rates due to the
due to the inherent
to the inherent trade
the attacker can always
attacker can always increase
can always increase its
equipment quality and cost
always increase its revenue
increase its revenue by
its revenue by attacking
we conclude that in
conclude that in the
that in the general
in the general case
with any number of
any number of pools
as well as the
well as the difficulty
as the difficulty of
the difficulty of performing
difficulty of performing routine
of performing routine maintenance
performing routine maintenance on
attacks is not a
routine maintenance on longdistance
is not a nash
maintenance on longdistance links
not a nash equilibrium
section vi deals with
vi deals with the
deals with the case
with the case of
the case of two
case of two pools
end paths as dropping
paths as dropping packets
as dropping packets at
where each can attack
dropping packets at rates
each can attack the
packets at rates of
can attack the other
analysis becomes more complicated
becomes more complicated in
more complicated in two
complicated in two ways
the revenue of each
revenue of each pool
of each pool affects
each pool affects the
pool affects the revenue
affects the revenue of
the revenue of the
revenue of the other
of the other through
the other through the
to capture a wide
other through the infiltrating
capture a wide range
through the infiltrating miners
a wide range of
wide range of deployed
range of deployed networks
we prove that for
prove that for a
that for a static
for a static choice
a static choice of
static choice of infiltration
existing reliability options tcp
choice of infiltration rates
of infiltration rates the
infiltration rates the pool
rates the pool revenues
the pool revenues converge
ip is the default
is the default reliable
the default reliable communication
default reliable communication option
reliable communication option for
communication option for contemporary
option for contemporary networked
for contemporary networked applications
once one pool changes
one pool changes its
pool changes its infiltration
changes its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the other
exclusive embeddings in commodity
embeddings in commodity operating
in commodity operating systems
the latter may prefer
commodity operating systems and
latter may prefer to
operating systems and networking
may prefer to change
systems and networking apis
prefer to change its
to change its infiltration
change its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the former
using time instead of
time instead of timeout
most applications requiring reliable
instead of timeout for
therefore the game itself
of timeout for fault
applications requiring reliable communication
the game itself takes
requiring reliable communication over
game itself takes multiple
reliable communication over any
itself takes multiple rounds
communication over any form
takes multiple rounds to
over any form of
multiple rounds to converge
any form of network
form of network use
of network use tcp
we show analytically that
show analytically that the
analytically that the game
that the game has
the game has a
game has a single
has a single nash
a single nash equilibrium
single nash equilibrium and
nash equilibrium and numerically
equilibrium and numerically study
and numerically study the
numerically study the equilibrium
study the equilibrium points
the problem with commodity
the equilibrium points for
problem with commodity tcp
equilibrium points for different
points for different pool
for different pool sizes
for pools smaller than
ip uses positive acknowledgments
uses positive acknowledgments and
positive acknowledgments and retransmissions
at the equilibrium point
acknowledgments and retransmissions to
the equilibrium point both
and retransmissions to ensure
equilibrium point both pools
retransmissions to ensure reliability
point both pools earn
to ensure reliability the
both pools earn less
ensure reliability the sender
pools earn less than
reliability the sender buffers
earn less than they
the sender buffers packets
less than they would
sender buffers packets until
than they would have
buffers packets until their
they would have in
packets until their receipt
would have in the
until their receipt is
have in the nonequilibrium
their receipt is acknowledged
in the nonequilibrium no
receipt is acknowledged by
is acknowledged by the
acknowledged by the receiver
and resends if an
resends if an acknowledgment
if an acknowledgment is
an acknowledgment is not
acknowledgment is not received
since pools can decide
is not received within
pools can decide to
not received within some
can decide to start
received within some time
decide to start or
within some time period
to start or stop
start or stop attacking
or stop attacking at
stop attacking at any
attacking at any point
a lost packet is
this can be modeled
lost packet is received
can be modeled as
packet is received in
be modeled as the
is received in the
modeled as the miner
received in the form
as the miner s
in the form of
the miner s dilemma
the form of a
miner s dilemma an
form of a retransmission
s dilemma an instance
of a retransmission that
dilemma an instance of
a retransmission that arrives
an instance of the
retransmission that arrives no
instance of the iterative
that arrives no earlier
of the iterative prisoner
arrives no earlier than
the iterative prisoner s
iterative prisoner s dilemma
attacking is the dominant
is the dominant strategy
rtts after the original
the dominant strategy in
after the original send
dominant strategy in each
the original send event
strategy in each iteration
the sender has to
but if the pools
sender has to buffer
if the pools can
has to buffer each
the pools can agree
to buffer each packet
pools can agree not
buffer each packet until
can agree not to
each packet until it
agree not to attack
packet until it s
until it s acknowledged
both benefit in the
benefit in the long
in the long run
from paxos to corfu
rtt in lossless operation
and it has to
we address in section
it has to perform
address in section vii
has to perform additional
in section vii the
to perform additional work
section vii the case
perform additional work to
vii the case where
additional work to retransmit
the case where the
work to retransmit the
case where the participants
to retransmit the packet
where the participants are
retransmit the packet if
the participants are an
the packet if it
participants are an arbitrary
packet if it does
are an arbitrary number
if it does not
an arbitrary number of
it does not receive
arbitrary number of identical
does not receive the
number of identical pools
not receive the acknowledgment
there exists a symmetric
exists a symmetric equilibrium
a symmetric equilibrium in
symmetric equilibrium in which
any packets that arrive
equilibrium in which each
packets that arrive with
in which each participating
that arrive with higher
which each participating pool
arrive with higher sequence
each participating pool attacks
with higher sequence numbers
participating pool attacks each
higher sequence numbers than
pool attacks each of
sequence numbers than that
attacks each of the
numbers than that of
each of the other
than that of a
of the other participating
that of a lost
the other participating pools
of a lost packet
a lost packet must
lost packet must be
packet must be queued
as in the minority
must be queued while
in the minority two
be queued while the
queued while the receiver
while the receiver waits
the receiver waits for
receiver waits for the
waits for the lost
for the lost packet
the lost packet to
lost packet to arrive
here too at equilibrium
too at equilibrium all
at equilibrium all pools
equilibrium all pools earn
all pools earn less
pools earn less than
earn less than with
less than with the
than with the no
throughput financial banking application
financial banking application running
banking application running in
application running in a
running in a datacenter
in a datacenter in
a datacenter in new
datacenter in new york
in new york city
our results imply that
results imply that block
sending updates to a
imply that block withholding
updates to a sister
that block withholding by
to a sister site
block withholding by pools
a sister site in
withholding by pools leads
sister site in switzerland
by pools leads to
pools leads to an
leads to an unfavorable
to an unfavorable equilibrium
the rtt value between
rtt value between these
value between these two
between these two centers
these two centers is
two centers is typically
concurrency control and availability
control and availability in
due to the anonymity
and availability in multi
to the anonymity of
the anonymity of miners
a single pool might
single pool might be
pool might be tempted
might be tempted to
be tempted to attack
leading the other pools
the other pools to
other pools to attack
pools to attack as
to attack as well
in the case of
the implications might be
the case of a
implications might be devastating
case of a lost
might be devastating for
of a lost packet
be devastating for open
devastating for open pools
all packets received within
packets received within the
if their revenues are
their revenues are reduced
miners will prefer to
will prefer to form
prefer to form closed
to form closed pools
form closed pools that
closed pools that cannot
milliseconds between the original
pools that cannot be
between the original packet
that cannot be attacked
the original packet send
cannot be attacked in
original packet send and
be attacked in this
packet send and the
attacked in this manner
send and the a
though this may be
this may be conceived
may be conceived as
be conceived as bad
conceived as bad news
as bad news for
bad news for public
news for public mining
for public mining pools
on the whole it
the whole it may
whole it may be
it may be good
may be good news
be good news to
good news to the
h ets are generated
news to the bitcoin
on predictive modeling for
ets are generated from
to the bitcoin system
are generated from alternate
predictive modeling for optimizing
generated from alternate disjoint
modeling for optimizing transaction
from alternate disjoint sub
for optimizing transaction execution
which prefers small pools
optimizing transaction execution in
transaction execution in parallel
execution in parallel oltp
streams of data rather
in parallel oltp systems
of data rather than
we examine the practicality
data rather than from
examine the practicality of
rather than from consecutive
the practicality of the
than from consecutive packets
practicality of the attack
of the attack in
the attack in section
attack in section viii
in section viii and
section viii and discuss
viii and discuss implications
with an interleave index
and discuss implications and
an interleave index of
discuss implications and model
implications and model extensions
and model extensions in
model extensions in section
extensions in section ix
the encoder would a
our contributions are the
contributions are the following
g create correction packets
create correction packets separately
correction packets separately from
packets separately from three
separately from three disjoint
from three disjoint sub
definition of the pool
of the pool game
the pool game where
pool game where pools
game where pools in
where pools in a
pools in a proof
the first containing data
first containing data packets
containing data packets numbered
ofwork secured system attack
data packets numbered a
secured system attack one
packets numbered a c
system attack one another
numbered a c e
attack one another with
a c e g
one another with a
c e g x
another with a pool
e g x x
with a pool block
a pool block withholding
pool block withholding attack
scalable deferred update replication
in the general case
attacks is not an
is not an equilibrium
with two minority pools
two minority pools participating
the only nash equilibrium
only nash equilibrium is
nash equilibrium is when
equilibrium is when the
is when the pools
when the pools attack
the pools attack one
pools attack one another
the second with data
second with data packets
and both earn less
with data packets numb
both earn less than
data packets numb d
earn less than if
packets numb d f
less than if none
numb d f h
than if none had
d f h x
if none had attacked
f h x x
h x x bered
miners therefore face the
therefore face the miner
face the miner s
the miner s dilemma
the case for determinism
case for determinism in
for determinism in database
determinism in database systems
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
repeatedly choosing between attack
choosing between attack and
between attack and no
with multiple pools of
multiple pools of equal
pools of equal size
of equal size there
equal size there is
size there is a
there is a symmetric
is a symmetric nash
a symmetric nash equilibrium
where all pools earn
all pools earn less
pools earn less than
earn less than if
less than if none
than if none had
if none had attacked
and the third with
the third with data
third with data b
inefficient equilibria for open
equilibria for open pools
for open pools may
open pools may serve
pools may serve the
may serve the system
serve the system by
the system by reducing
system by reducing their
by reducing their attraction
reducing their attraction and
their attraction and pushing
attraction and pushing miners
and pushing miners towards
pushing miners towards smaller
miners towards smaller closed
towards smaller closed pools
the classical block withholding
classical block withholding attack
block withholding attack is
withholding attack is as
attack is as old
is as old as
as old as pools
old as pools themselves
but its use by
its use by pools
use by pools has
by pools has not
pools has not been
has not been suggested
not been suggested until
been suggested until recently
we overview related attacks
overview related attacks and
related attacks and prior
attacks and prior work
and prior work in
prior work in section
work in section x
and conclude with final
conclude with final remarks
with final remarks in
final remarks in section
remarks in section xi
p reliminaries b itcoin
interleaving adds burst tolerance
reliminaries b itcoin and
adds burst tolerance to
b itcoin and p
burst tolerance to fec
itcoin and p ooled
tolerance to fec but
and p ooled m
to fec but exacerbates
p ooled m ining
fec but exacerbates its
ooled m ining bitcoin
but exacerbates its sensitivfigure
m ining bitcoin is
ining bitcoin is a
bitcoin is a distributed
separate encoding for ity
encoding for ity to
for ity to sending
ity to sending rate
to sending rate with
sending rate with an
rate with an interleave
with an interleave index
an interleave index of
interleave index of i
index of i and
of i and an
i and an encoding
and an encoding rate
an encoding rate of
the sender would have
sender would have to
would have to wait
have to wait for
to wait for odd
wait for odd and
for odd and even
odd and even packets
and even packets i
packets before sending any
before sending any redundancy
clients use the system
sending any redundancy information
use the system by
the system by issuing
system by issuing transactions
receipt of its retransmission
of its retransmission have
and the system s
its retransmission have to
the system s only
retransmission have to be
system s only task
have to be buffered
s only task is
to be buffered at
only task is to
be buffered at the
task is to serialize
buffered at the rethese
is to serialize transactions
at the rethese two
to serialize transactions in
the rethese two obstacles
serialize transactions in a
rethese two obstacles to
transactions in a single
two obstacles to using
in a single ledger
obstacles to using fec
a single ledger and
to using fec in
single ledger and reject
using fec in time
ledger and reject transactions
and reject transactions that
reject transactions that cannot
transactions that cannot be
that cannot be serialized
cannot be serialized due
be serialized due to
serialized due to conflicts
due to conflicts with
tings rate sensitivity and
to conflicts with previous
rate sensitivity and burst
conflicts with previous transactions
sensitivity and burst susceptibility
and burst susceptibility are
burst susceptibility are innotice
susceptibility are innotice that
are innotice that for
bitcoin transactions are protected
innotice that for this
transactions are protected with
that for this commonplace
for this commonplace scenario
are protected with cryptographic
protected with cryptographic techniques
with cryptographic techniques that
cryptographic techniques that ensure
the loss of terlinked
techniques that ensure that
loss of terlinked through
that ensure that only
of terlinked through the
ensure that only the
terlinked through the tuning
that only the rightful
through the tuning knobs
only the rightful owner
the rightful owner of
rightful owner of a
owner of a bitcoin
of a bitcoin can
a bitcoin can transfer
an interleave of i
bitcoin can transfer it
interleave of i and
of i and a
i and a single
and a single packet
a single packet stops
the transaction ledger is
single packet stops all
transaction ledger is stored
packet stops all traffic
ledger is stored by
stops all traffic in
is stored by a
all traffic in the
stored by a network
traffic in the channel
by a network of
in the channel to
a network of miners
the channel to the
network of miners in
channel to the apa
of miners in a
to the apa rate
miners in a data
the apa rate of
in a data structure
a data structure caller
data structure caller the
structure caller the blockchain
revenue for proof of
provides tolerance to a
for proof of work
tolerance to a burst
proof of work the
to a burst of
of work the blockchain
a burst of up
work the blockchain records
burst of up to
the blockchain records the
of up to c
blockchain records the transactions
up to c i
records the transactions in
to c i plication
the transactions in units
c i plication for
transactions in units of
i plication for a
in units of blocks
plication for a seventh
for a seventh of
a seventh of a
seventh of a second
dubbed the genesis block
a sequence of such
sequence of such consecutive
of such consecutive packets
is defined as part
defined as part of
as part of the
part of the protocol
a valid block contains
the burst tolerance of
valid block contains the
burst tolerance of blocks
block contains the hash
tolerance of blocks can
contains the hash of
of blocks can have
the hash of the
blocks can have devastating
hash of the previous
can have devastating effect
of the previous block
have devastating effect on
devastating effect on a
effect on a high
the hash of the
hash of the transactions
of the transactions in
throughput an fec code
the transactions in the
an fec code can
transactions in the current
fec code can be
in the current block
code can be changed
can be changed by
be changed by modulating
changed by modulating either
by modulating either the
and a bitcoin address
modulating either the c
a bitcoin address which
either the c system
bitcoin address which is
the c system where
address which is to
c system where every
which is to be
system where every spare
is to be credited
where every spare cycle
to be credited with
every spare cycle counts
be credited with a
credited with a reward
with a reward for
a reward for generating
reward for generating the
for generating the block
in applior the i
applior the i parameters
any miner may add
miner may add a
may add a valid
add a valid block
a valid block to
increasing c enhances burst
valid block to the
c enhances burst tolercations
block to the chain
enhances burst tolercations with
to the chain by
burst tolercations with many
tolercations with many fine
proving that it has
a lost packet ance
that it has spent
lost packet ance at
it has spent a
packet ance at the
has spent a certain
ance at the cost
spent a certain amount
at the cost of
a certain amount of
the cost of network
certain amount of work
cost of network and
amount of work and
of network and encoding
of work and publishing
network and encoding overhead
work and publishing the
and publishing the block
publishing the block with
the block with the
block with the proof
potencan potentially trigger a
with the proof over
potentially trigger a butterfly
the proof over an
trigger a butterfly effect
proof over an overlay
a butterfly effect of
over an overlay network
butterfly effect of missed
an overlay network to
effect of missed deadtially
overlay network to all
of missed deadtially worsening
network to all other
missed deadtially worsening the
to all other miners
deadtially worsening the packet
worsening the packet loss
the packet loss experienced
packet loss experienced and
when a miner creates
loss experienced and reducing
a miner creates a
experienced and reducing lines
miner creates a block
and reducing lines along
reducing lines along a
lines along a distributed
along a distributed workflow
it is compensated for
is compensated for its
compensated for its efforts
for its efforts with
its efforts with bitcoins
this compensation includes a
compensation includes a per
transaction fee paid by
increasing i trades off
fee paid by the
i trades off recovery
paid by the users
trades off recovery periods
by the users electronic
off recovery periods market
the users electronic copy
recovery periods market crashes
users electronic copy available
periods market crashes at
electronic copy available at
market crashes at stock
crashes at stock exchanges
christmas latency for better
latency for better burst
for better burst tolerance
better burst tolerance without
burst tolerance without adding
tolerance without adding overhead
without adding overhead sales
adding overhead sales at
overhead sales at online
sales at online stores
winter storms at air
traffic control as mentioned
for higher values of
higher values of i
the encoder has to
encoder has to centers
has to centers overloaded
to centers overloaded networks
centers overloaded networks and
overloaded networks and end
hosts can exhibit wait
can exhibit wait for
exhibit wait for more
wait for more data
for more data packets
more data packets to
whose transactions are included
data packets to be
packets to be transmitted
to be transmitted before
be transmitted before it
transmitted before it can
and an amount of
before it can continuous
an amount of minted
it can continuous packet
amount of minted bitcoins
can continuous packet loss
of minted bitcoins that
minted bitcoins that are
bitcoins that are thus
that are thus introduced
are thus introduced into
with each lost packet
thus introduced into the
each lost packet driving
introduced into the system
lost packet driving the
packet driving the send
driving the send error
the send error correction
send error correction packets
the work which a
work which a miner
which a miner is
a miner is required
system further and further
miner is required to
further and further out
is required to do
and further out of
required to do is
further out of sync
to do is to
out of sync with
do is to repeatedly
of sync with respect
is to repeatedly calculate
sync with respect to
to repeatedly calculate a
with respect to its
repeatedly calculate a a
respect to its importantly
calculate a a hash
a a hash function
a hash function specifically
hash function specifically the
function specifically the sha
once the fec encoding
the fec encoding is
fec encoding is parameterized
encoding is parameterized real
with a rate and
a rate and an
rate and an interleave
and an interleave to
an interleave to tolerate
interleave to tolerate a
to tolerate a certain
tolerate a certain burst
a certain burst sensitive
certain burst sensitive flow
burst sensitive flow control
of a block header
ip is unable to
is unable to distinguish
unable to distinguish length
to distinguish length b
to indicate that he
indicate that he has
that he has performed
he has performed this
has performed this work
the miner provides a
miner provides a probabilistic
provides a probabilistic proof
a probabilistic proof as
probabilistic proof as follows
the generated block has
generated block has a
block has a nonce
has a nonce field
which can contain any
can contain any value
the miner places different
miner places different values
places different values in
different values in this
values in this field
in this field and
this field and calculates
to between ephemeral loss
field and calculates the
between ephemeral loss modes
and calculates the hash
ephemeral loss modes due
calculates the hash for
loss modes due to
the hash for each
modes due to transient
hash for each value
due to transient contolerate
to transient contolerate a
transient contolerate a burst
contolerate a burst of
a burst of length
if the result of
the result of the
result of the hash
of the hash is
the hash is smaller
hash is smaller than
is smaller than a
smaller than a target
than a target value
the nonce is considered
nonce is considered a
is considered a solution
and the block is
the block is valid
the number of attempts
all losses occurring gestion
number of attempts to
of attempts to find
attempts to find a
to find a single
find a single hash
a single hash is
single hash is therefore
hash is therefore random
is therefore random with
or dirty fiber and
therefore random with a
dirty fiber and persistent
random with a geometric
fiber and persistent in
with a geometric distribution
and persistent in bursts
persistent in bursts of
in bursts of size
bursts of size less
of size less than
as each attempt is
size less than or
each attempt is a
less than or equal
attempt is a bernoulli
than or equal to
is a bernoulli trial
or equal to b
a bernoulli trial with
equal to b are
bernoulli trial with a
to b are recovered
trial with a success
b are recovered with
with a success probability
are recovered with congestion
a success probability determined
success probability determined by
probability determined by the
determined by the target
by the target value
the loss of one
loss of one packet
of one packet out
one packet out of
packet out of ten
at the existing huge
out of ten thousand
the existing huge hashing
of ten thousand is
existing huge hashing rates
ten thousand is sufficient
huge hashing rates and
thousand is sufficient to
hashing rates and small
is sufficient to reduce
rates and small target
sufficient to reduce tcp
and small target values
ip throughput to a
the time to find
throughput to a third
time to find a
to a third of
to find a single
a third of its
find a single hash
third of its the
a single hash can
of its the same
single hash can be
its the same latency
hash can be approximated
the same latency and
can be approximated by
same latency and this
be approximated by an
latency and this latency
approximated by an exponential
and this latency depends
by an exponential distribution
this latency depends on
latency depends on the
depends on the i
on the i palossless
the i palossless maximum
the average time for
average time for a
time for a miner
for a miner to
if one packet is
a miner to find
one packet is lost
miner to find a
packet is lost out
to find a solution
is lost out of
find a solution is
lost out of a
a solution is therefore
out of a thousand
solution is therefore proportional
is therefore proportional to
therefore proportional to its
proportional to its hashing
to its hashing rate
its hashing rate or
hashing rate or mining
rate or mining power
to maintain a constant
we d like to
maintain a constant rate
d like to parameterize
a constant rate of
like to parameterize the
constant rate of bitcoin
rate of bitcoin generation
to parameterize the encoding
parameterize the encoding to
the encoding to tolerate
encoding to tolerate a
and as part of
to tolerate a maximum
as part of its
tolerate a maximum burst
part of its defense
a maximum burst length
of its defense against
maximum burst length and
its defense against denial
burst length and then
defense against denial of
length and then have
against denial of service
and then have recovthroughput
denial of service and
then have recovthroughput collapses
of service and other
have recovthroughput collapses to
service and other attacks
recovthroughput collapses to a
collapses to a thirtieth
to a thirtieth of
a thirtieth of the
thirtieth of the maximum
the system normalizes the
system normalizes the rate
normalizes the rate of
the rate of block
rate of block generation
ery latency depend on
latency depend on the
depend on the actual
on the actual burstiness
the actual burstiness of
actual burstiness of the
burstiness of the loss
the protocol deterministically defines
protocol deterministically defines the
at the same time
deterministically defines the target
defines the target value
the target value for
target value for each
we would like the
value for each block
would like the encoding
for each block according
like the encoding to
each block according to
the encoding to have
block according to the
encoding to have a
according to the time
to the time required
the time required to
time required to generate
required to generate recent
to generate recent blocks
is updated once every
fec constant rate for
constant rate for network
rate for network provisioning
for network provisioning and
network provisioning and stability
an fec scheme is
blocks such that the
fec scheme is required
such that the average
scheme is required where
that the average time
is required where latency
the average time for
required where latency of
average time for each
where latency of fec
time for each block
latency of fec encoders
for each block to
of fec encoders are
each block to be
fec encoders are typically
block to be found
encoders are typically parameterized
to be found is
are typically parameterized with
typically parameterized with an
note that the exponential
that the exponential distribution
recovery degrades gracefully as
the exponential distribution is
degrades gracefully as losses
exponential distribution is memoryless
gracefully as losses get
as losses get burstier
if all miners mine
all miners mine for
even tuple for each
miners mine for block
tuple for each outgoing
mine for block number
for each outgoing sequence
for block number b
each outgoing sequence of
outgoing sequence of r
sequence of r data
of r data packets
once the block is
the block is found
block is found at
is found at time
a as the encoding
found at time t
as the encoding overhead
the encoding overhead stays
encoding overhead stays constant
all miners switch to
miners switch to mine
switch to mine for
to mine for the
mine for the subsequent
for the subsequent block
the subsequent block b
c data and error
data and error correction
and error correction packets
error correction packets are
correction packets are sent
at t without changing
t without changing their
without changing their probability
changing their probability distribution
their probability distribution of
probability distribution of finding
distribution of finding a
of finding a block
finding a block after
redundancy information cannot be
a block after t
information cannot be generated
cannot be generated and
be generated and sent
generated and sent until
and sent until all
sent until all r
until all r data
all r data packets
r data packets are
the probability that a
data packets are available
probability that a miner
packets are available for
that a miner i
are available for sending
a miner i with
miner i with mining
i with mining power
with mining power mi
mining power mi finds
power mi finds the
mi finds the next
the latency of packet
finds the next block
latency of packet recovery
the next block is
of packet recovery is
next block is its
packet recovery is determined
block is its ratio
recovery is determined by
is its ratio out
is determined by the
its ratio out of
determined by the rate
ratio out of the
by the rate at
out of the total
the rate at which
of the total mining
rate at which the
the total mining power
at which the sender
total mining power m
which the sender transmits
mining power m in
the sender transmits data
power m in the
m in the system
generating error correction packets
miner miner miner pool
maelstrom design and implemenfrom
design and implemenfrom less
and implemenfrom less than
miner miner miner pool
implemenfrom less than r
less than r data
than r data packets
r data packets at
data packets at the
packets at the sender
at the sender is
the sender is not
sender is not a
is not a viable
not a viable tation
a viable tation option
viable tation option even
tation option even though
option even though the
even though the data
though the data rate
the data rate in
data rate in this
rate in this channel
in this channel is
this channel is low
or network could be
network could be operating
could be operating at
be operating at near
operating at near full
at near full capacity
near full capacity with
full capacity with data
capacity with data from
with data from other
data from other senders
and one miner mines
one miner mines solo
we describe the maelstrom
describe the maelstrom appliance
the maelstrom appliance as
maelstrom appliance as a
appliance as a single
as a single machine
a single machine fec
single machine fec is
pools datacenters are built
machine fec is also
datacenters are built around
fec is also very
are built around the
is also very susceptible
built around the world
also very susceptible to
very susceptible to bursty
susceptible to bursty losses
mining is only profitable
is only profitable using
only profitable using dedicated
profitable using dedicated hardware
using dedicated hardware in
dedicated hardware in cutting
hardware in cutting edge
in cutting edge mining
cutting edge mining rigs
we will show how
will show how more
show how more machines
how more machines can
otherwise the energy costs
more machines can be
the energy costs exceed
machines can be added
energy costs exceed the
can be added to
costs exceed the expected
be added to terleaving
exceed the expected revenue
although expected revenue from
expected revenue from mining
revenue from mining is
from mining is proportional
mining is proportional to
is proportional to the
proportional to the power
to the power of
the power of the
power of the mining
is a standard encoding
of the mining rigs
a standard encoding technique
the mining rigs used
standard encoding technique used
encoding technique used the
technique used the appliance
used the appliance to
a single home miner
the appliance to balance
single home miner using
appliance to balance encoding
home miner using a
to balance encoding load
miner using a small
balance encoding load and
using a small rig
encoding load and scale
a small rig is
load and scale to
small rig is unlikely
and scale to multo
rig is unlikely to
scale to multo combat
is unlikely to mine
to multo combat bursty
unlikely to mine a
multo combat bursty loss
to mine a block
mine a block for
a block for years
where error correction pack
tiple gigabits per second
gigabits per second of
per second of traffic
a b c d
b c d x
c d x x
d x x e
x x e f
x e f g
e f g h
f g h x
g h x x
h x x appliance
miners often organize themselves
often organize themselves into
organize themselves into mining
themselves into mining pools
a pool is a
pool is a group
is a group of
a group of miners
group of miners that
of miners that share
miners that share their
that share their revenues
share their revenues when
their revenues when one
revenues when one of
when one of them
one of them successfully
of them successfully mines
them successfully mines a
successfully mines a block
for each block found
the revenue is distributed
revenue is distributed among
is distributed among the
distributed among the pool
among the pool members
the pool members in
pool members in proportion
members in proportion to
in proportion to their
proportion to their mining
to their mining power
the expected revenue of
lan mtu lambda jumbo
expected revenue of a
mtu lambda jumbo mtu
revenue of a pool
lambda jumbo mtu recipe
of a pool member
jumbo mtu recipe list
a pool member is
pool member is therefore
member is therefore the
is therefore the same
therefore the same as
the same as its
same as its revenue
as its revenue had
its revenue had it
revenue had it mined
had it mined solo
due to the large
to the large power
the large power of
large power of the
power of the pool
it finds blocks at
finds blocks at a
blocks at a much
at a much higher
a much higher rate
and so the frequency
so the frequency of
the frequency of revenue
frequency of revenue collection
of revenue collection is
revenue collection is higher
allowing for a stable
for a stable daily
a stable daily or
stable daily or weekly
daily or weekly income
most pools are controlled
pools are controlled by
are controlled by a
controlled by a centralized
by a centralized pool
a centralized pool manager
miners register with the
register with the pool
with the pool manager
the pool manager and
pool manager and mine
manager and mine on
and mine on its
mine on its behalf
the pool manager generates
pool manager generates tasks
manager generates tasks and
generates tasks and the
tasks and the miners
and the miners search
the miners search for
miners search for solutions
search for solutions based
for solutions based on
solutions based on these
based on these tasks
on these tasks that
these tasks that can
tasks that can serve
that can serve as
can serve as proof
serve as proof of
as proof of work
once they find a
they find a solution
they send it to
send it to the
it to the pool
to the pool manager
the pool manager behaves
pool manager behaves as
manager behaves as a
behaves as a single
as a single miner
a single miner in
single miner in the
miner in the bitcoin
in the bitcoin system
repair packets are injected
packets are injected into
are injected into stream
injected into stream transparently
once it obtains a
it obtains a legitimate
obtains a legitimate block
a legitimate block from
legitimate block from one
block from one of
from one of its
one of its miners
basic mechanism the basic
mechanism the basic operation
the basic operation of
basic operation of maelstrom
operation of maelstrom is
the block transfers the
of maelstrom is shown
block transfers the revenue
maelstrom is shown in
transfers the revenue to
is shown in figure
the revenue to the
revenue to the control
to the control of
the control of the
control of the pool
of the pool manager
the pool manager then
pool manager then distributes
manager then distributes the
it intercepts outgoing data
then distributes the revenue
intercepts outgoing data packets
distributes the revenue among
outgoing data packets and
the revenue among the
data packets and routes
revenue among the miners
packets and routes them
among the miners according
and routes them to
the miners according to
routes them to the
miners according to their
them to the destination
according to their mining
to the destination datacenter
to their mining power
generating and injecting fec
the architecture is illustrated
and injecting fec repair
architecture is illustrated in
injecting fec repair packets
is illustrated in figure
fec repair packets into
repair packets into the
packets into the stream
into the stream in
the stream in their
in order to estimate
stream in their wake
order to estimate the
to estimate the mining
estimate the mining power
the mining power of
mining power of a
power of a miner
a repair packet consists
repair packet consists of
packet consists of a
the pool manager sets
consists of a recipe
pool manager sets a
of a recipe list
manager sets a partial
a recipe list of
sets a partial target
recipe list of data
a partial target for
list of data packet
partial target for each
of data packet identifiers
target for each member
data packet identifiers and
packet identifiers and fec
identifiers and fec information
and fec information generated
fec information generated from
information generated from these
generated from these packets
in the example in
the example in figure
this information is a
information is a simple
is a simple xor
than the target of
the target of the
target of the bitcoin
of the bitcoin system
the size of the
size of the xor
of the xor is
the xor is equal
each miner is required
xor is equal to
miner is required to
is equal to the
is required to send
equal to the mtu
required to send the
to the mtu of
to send the pool
the mtu of the
send the pool manager
mtu of the datacenter
the pool manager blocks
of the datacenter network
pool manager blocks that
manager blocks that are
blocks that are correct
that are correct according
are correct according to
and to avoid fragmentation
correct according to the
to avoid fragmentation of
according to the partial
avoid fragmentation of repair
to the partial target
fragmentation of repair packets
of repair packets we
repair packets we require
packets we require that
we require that the
require that the mtu
that the mtu of
the mtu of the
mtu of the long
the partial target is
partial target is chosen
target is chosen to
is chosen to be
chosen to be large
haul network be set
network be set to
be set to a
set to a slightly
to a slightly larger
a slightly larger value
such that partial solutions
that partial solutions arrive
partial solutions arrive frequently
solutions arrive frequently enough
this requirement is usually
arrive frequently enough for
requirement is usually satisfied
frequently enough for the
is usually satisfied in
enough for the manager
usually satisfied in practical
for the manager to
satisfied in practical deployments
the manager to accurately
manager to accurately estimate
to accurately estimate the
accurately estimate the power
estimate the power of
since gigabit links very
the power of the
gigabit links very often
power of the miner
links very often use
very often use jumbo
often use jumbo frames
use jumbo frames of
jumbo frames of up
frames of up to
to reduce management overhead
as the value of
the value of bitcoin
value of bitcoin rose
bitcoin mining has become
mining has become a
has become a rapidly
become a rapidly advancing
a rapidly advancing industry
technological advancements lead to
advancements lead to ever
lead to ever more
while lan networks have
to ever more efficient
lan networks have standard
ever more efficient hashing
networks have standard mtus
more efficient hashing asics
have standard mtus of
at the receiving datacenter
this is a simplification
is a simplification that
the appliance examines incoming
a simplification that is
appliance examines incoming repair
simplification that is sufficient
examines incoming repair packets
that is sufficient for
incoming repair packets and
is sufficient for our
repair packets and uses
sufficient for our analysis
packets and uses them
and uses them to
uses them to recover
them to recover missing
to recover missing data
recover missing data packets
the intricacies of reward
intricacies of reward systems
of reward systems are
reward systems are explained
systems are explained in
the data packet is
data packet is injected
packet is injected transparently
is injected transparently into
injected transparently into the
transparently into the stream
into the stream to
the stream to the
stream to the receiving
to the receiving end
recovered data packets will
data packets will typically
a notable exception is
packets will typically arrive
notable exception is p
will typically arrive out
but this behavior is
this behavior is expected
behavior is expected by
is expected by communication
expected by communication stacks
by communication stacks designed
communication stacks designed for
stacks designed for the
designed for the commodity
for the commodity internet
which we discuss in
we discuss in section
discuss in section ix
flow control while relaying
control while relaying tcp
forks block propagation in
block propagation in the
propagation in the overlay
in the overlay network
the overlay network takes
overlay network takes seconds
maelstrom has two flow
has two flow control
two flow control modes
therefore it is possible
it is possible for
is possible for two
possible for two distant
for two distant miners
two distant miners to
distant miners to generate
miners to generate competing
to generate competing blocks
both of which name
of which name the
which name the same
name the same block
the same block as
same block as their
block as their predecessor
the appliance routes packets
appliance routes packets through
routes packets through without
packets through without modification
are rare since the
rare since the average
since the average mining
the average mining interval
average mining interval is
control between the endhosts
the appliance acts as
appliance acts as a
acts as a tcp
and they occur on
they occur on average
occur on average once
on average once every
terminating connections and sending
connections and sending back
and sending back acks
sending back acks immediately
back acks immediately before
acks immediately before relaying
immediately before relaying data
before relaying data on
relaying data on appliance
this is particularly useful
is particularly useful for
particularly useful for applications
useful for applications with
for applications with short
the system has a
system has a mechanism
has a mechanism to
lived flows that need
a mechanism to solve
flows that need to
mechanism to solve forks
that need to ramp
to solve forks when
need to ramp up
solve forks when they
to ramp up throughput
forks when they do
ramp up throughput quickly
when they do occur
up throughput quickly and
throughput quickly and avoid
quickly and avoid the
and avoid the slow
causing one of the
one of the blocks
of the blocks to
the blocks to be
start effects of tcp
blocks to be discarded
ip on a long
we ignore bifurcations for
on a long link
ignore bifurcations for the
bifurcations for the sake
for the sake of
the sake of simplicity
the performance advantages of
performance advantages of splitting
advantages of splitting longdistance
since the choice of
of splitting longdistance connections
the choice of the
splitting longdistance connections into
choice of the discarded
longdistance connections into multiple
of the discarded block
connections into multiple hops
the discarded block on
into multiple hops are
discarded block on bifurcation
multiple hops are well
block on bifurcation is
hops are well known
on bifurcation is random
one may incorporate this
may incorporate this event
incorporate this event into
this event into the
event into the probability
into the probability of
the probability of finding
and orthogonal to this
probability of finding a
orthogonal to this work
of finding a block
we are primarily interested
and consider instead the
are primarily interested in
consider instead the probability
primarily interested in isolating
instead the probability of
interested in isolating the
the probability of finding
in isolating the impact
probability of finding a
isolating the impact of
of finding a block
the impact of rapid
finding a block that
impact of rapid and
a block that is
of rapid and transparent
block that is not
rapid and transparent recovery
that is not discarded
and transparent recovery of
transparent recovery of lost
recovery of lost packets
of lost packets by
lost packets by maelstrom
pools often charge a
packets by maelstrom on
often charge a small
by maelstrom on tcp
charge a small percentage
a small percentage of
small percentage of the
percentage of the revenue
of the revenue as
the revenue as fee
rather than the buffering
than the buffering and
we discuss in section
the buffering and slow
discuss in section ix
in section ix the
section ix the implications
ix the implications of
the implications of such
start avoidance benefits of
implications of such fees
avoidance benefits of generic
of such fees to
benefits of generic performance
such fees to our
fees to our analysis
many pools are open
pools are open and
are open and accept
in the remainder of
open and accept any
the remainder of the
and accept any interested
remainder of the paper
accept any interested miner
we describe maelstrom with
describe maelstrom with end
a pool interface is
pool interface is typically
interface is typically comprised
is typically comprised of
typically comprised of a
comprised of a web
of a web interface
a web interface for
web interface for registration
interface for registration and
for registration and a
registration and a miner
and a miner interface
a miner interface for
miner interface for the
interface for the mining
for the mining software
while maelstrom respects end
in order to mine
order to mine for
to mine for a
mine for a pool
end flow control connections
a miner registers with
miner registers with the
registers with the web
or splits them and
with the web interface
splits them and implements
them and implements its
and implements its own
implements its own proxy
supplies a bitcoin address
a bitcoin address to
bitcoin address to receive
address to receive its
to receive its future
receive its future shares
its future shares of
future shares of the
shares of the revenue
proxy flow control as
flow control as described
control as described above
and receives from the
receives from the pool
from the pool credentials
the pool credentials for
pool credentials for mining
it is not designed
is not designed for
not designed for routinely
then he feeds his
designed for routinely congested
he feeds his credentials
for routinely congested networks
feeds his credentials and
his credentials and the
credentials and the pool
and the pool s
the pool s address
the addition of fec
pool s address to
addition of fec under
s address to its
of fec under tcp
address to its mining
to its mining rig
ip flow control allows
flow control allows it
control allows it to
allows it to steal
it to steal bandwidth
the mining rig obtains
to steal bandwidth from
mining rig obtains its
steal bandwidth from other
rig obtains its tasks
bandwidth from other competing
obtains its tasks from
from other competing flows
its tasks from the
other competing flows running
tasks from the pool
competing flows running without
from the pool and
flows running without fec
the pool and sends
running without fec in
pool and sends partial
without fec in the
and sends partial and
fec in the link
sends partial and full
partial and full proof
and full proof of
full proof of work
though maintaining fairness versus
maintaining fairness versus similarly
fairness versus similarly fec
typically with the stratum
with the stratum protocol
as it finds blocks
the pool manager credits
friendliness with conventional tcp
pool manager credits the
manager credits the miner
credits the miner s
the miner s account
miner s account according
ip flows is not
s account according to
flows is not a
account according to its
is not a primary
according to its share
not a primary protocol
to its share of
a primary protocol design
its share of the
primary protocol design goal
share of the work
protocol design goal on
design goal on over
and transfers these funds
transfers these funds either
these funds either on
funds either on request
either on request or
which are often dedicated
on request or automatically
are often dedicated to
request or automatically to
often dedicated to specific
or automatically to the
dedicated to specific highvalue
automatically to the aforementioned
to specific highvalue applications
to the aforementioned bitcoin
the aforementioned bitcoin address
we see evidence for
see evidence for this
too big pools despite
evidence for this assertion
big pools despite their
for this assertion in
pools despite their important
this assertion in the
despite their important role
assertion in the routine
their important role of
in the routine use
important role of enabling
the routine use of
role of enabling small
routine use of parallel
use of parallel flows
pools can constitute a
can constitute a threat
constitute a threat to
a threat to the
threat to the bitcoin
to the bitcoin system
the bitcoin system if
bitcoin system if their
system if their size
and udp blast protocols
if their size is
their size is too
size is too large
if one pool controls
one pool controls the
pool controls the majority
controls the majority of
the majority of mining
majority of mining power
the system becomes unstable
both in commercial deployments
in commercial deployments and
commercial deployments and by
deployments and by researchers
and by researchers seeking
by researchers seeking to
researchers seeking to transfer
seeking to transfer large
to transfer large amounts
transfer large amounts of
large amounts of data
amounts of data over
of data over high
layered interleaving in layered
interleaving in layered interleaving
an fec protocol with
fec protocol with rate
warns that the system
that the system is
the system is unstable
system is unstable with
is unstable with even
unstable with even smaller
with even smaller pools
is produced by running
produced by running c
by running c multiple
running c multiple instances
c multiple instances of
multiple instances of an
in realistic scenarios of
realistic scenarios of the
scenarios of the bitcoin
of the bitcoin system
the bitcoin system no
bitcoin system no pool
system no pool controls
no pool controls a
pool controls a majority
controls a majority of
a majority of the
fec protocol simultaneously with
majority of the mining
protocol simultaneously with increasing
of the mining power
simultaneously with increasing interleave
with increasing interleave indices
increasing interleave indices i
for one day in
one day in june
a single pool called
single pool called ghash
of the blocks in
the blocks in the
blocks in the bitcoin
in the bitcoin main
the bitcoin main chain
the bitcoin community backlashed
bitcoin community backlashed at
community backlashed at the
backlashed at the pool
which has done nothing
has done nothing worse
done nothing worse than
nothing worse than being
worse than being extremely
than being extremely successful
io reduced its relative
reduced its relative mining
its relative mining power
relative mining power and
mining power and publicly
power and publicly committed
and publicly committed to
publicly committed to stay
committed to stay away
to stay away from
stay away from the
block withholding and its
withholding and its detection
and its detection classical
its detection classical block
detection classical block withholding
is an attack performed
an attack performed by
attack performed by a
performed by a pool
by a pool member
a pool member against
pool member against the
member against the other
against the other pool
the other pool members
three instances of an
the attacking miner registers
attacking miner registers with
miner registers with the
registers with the pool
with the pool and
the pool and apparently
pool and apparently starts
and apparently starts mining
apparently starts mining honestly
starts mining honestly it
mining honestly it regularly
honestly it regularly sends
it regularly sends the
regularly sends the pool
sends the pool partial
the pool partial proof
pool partial proof of
partial proof of work
the first instance with
first instance with interleave
instance with interleave i
the attacking miner sends
attacking miner sends only
miner sends only partial
sends only partial proof
only partial proof of
partial proof of work
if it finds a
the second with interleave
it finds a full
second with interleave i
finds a full solution
a full solution that
full solution that constitutes
solution that constitutes a
that constitutes a full
constitutes a full proof
a full proof of
full proof of work
proof of work it
of work it discards
work it discards the
it discards the solution
and the third with
the third with interleave
reducing the pool s
third with interleave i
the pool s total
pool s total revenue
this attack is illustrated
attack is illustrated in
is illustrated in figure
the attacker does not
attacker does not change
does not change the
not change the pool
change the pool s
the pool s effective
pool s effective mining
s effective mining power
and does not affect
does not affect directly
not affect directly the
affect directly the revenue
directly the revenue of
the revenue of other
revenue of other pools
fec encoding is simply
encoding is simply an
is simply an xor
simply an xor of
an xor of the
xor of the r
of the r data
the r data packets
r data packets hence
the attacked pool shares
attacked pool shares its
pool shares its revenue
shares its revenue with
in layered interleaving each
its revenue with the
layered interleaving each data
revenue with the attacker
interleaving each data packet
each data packet is
data packet is included
packet is included in
is included in c
therefore each miner earns
included in c xors
each miner earns less
each of which is
as the same revenue
of which is generated
the same revenue is
which is generated at
same revenue is distributed
is generated at different
revenue is distributed among
generated at different interleaves
is distributed among more
at different interleaves from
distributed among more miners
different interleaves from the
interleaves from the original
from the original data
the original data stream
recall that the proof
that the proof of
the proof of work
proof of work is
of work is only
work is only valid
is only valid for
only valid for a
valid for a specific
for a specific block
as we shall describe
we shall describe shortly
as it is the
it is the nonce
ensures that the c
is the nonce with
that the c xors
the nonce with which
the c xors containing
nonce with which the
c xors containing a
with which the block
xors containing a data
which the block s
containing a data packet
the block s hash
a data packet do
block s hash is
data packet do not
s hash is smaller
packet do not have
hash is smaller than
do not have any
is smaller than its
not have any other
smaller than its target
the attacking miner cannot
attacking miner cannot use
miner cannot use it
although the term block
the term block withholding
term block withholding has
block withholding has become
withholding has become canonical
note that the block
that the block is
the block is discarded
block is discarded and
is discarded and never
discarded and never introduced
and never introduced into
never introduced into the
introduced into the system
into the system as
the system as the
system as the name
as the name block
the name block withholding
name block withholding implies
miners miners miners pool
classical block withholding attack
a group of miners
group of miners attack
of miners attack pool
with a block withholding
a block withholding attack
denoted by a dashed
by a dashed red
a dashed red arrow
this attack reduces the
attack reduces the attacker
reduces the attacker s
the attacker s revenue
attacker s revenue compared
s revenue compared to
revenue compared to solo
compared to solo mining
to solo mining or
solo mining or honest
mining or honest pool
or honest pool participation
it suffers from the
suffers from the reduced
from the reduced revenue
the reduced revenue like
reduced revenue like the
revenue like the other
like the other pool
the other pool participants
and its revenue is
its revenue is less
revenue is less than
is less than its
less than its share
than its share of
its share of the
share of the total
of the total mining
the total mining power
total mining power in
mining power in the
power in the system
the classical block withholding
classical block withholding attack
block withholding attack can
withholding attack can therefore
attack can therefore only
can therefore only be
therefore only be used
only be used for
data packet in common
be used for sabotage
the resulting protocol effectively
resulting protocol effectively has
protocol effectively has a
effectively has a rate
at a cost to
has a rate of
a cost to the
cost to the attacker
even if a pool
if a pool detects
a pool detects that
pool detects that it
detects that it is
that it is under
with each xor generated
it is under a
each xor generated from
is under a block
xor generated from r
under a block withholding
generated from r data
a block withholding attack
from r data packets
r data packets and
data packets and each
packets and each data
and each data packet
it might not be
each data packet included
might not be able
data packet included in
not be able to
packet included in c
be able to detect
included in c xors
able to detect which
to detect which of
detect which of its
which of its registered
of its registered miners
its registered miners are
registered miners are the
miners are the perpetrators
illustrates layered interleaving for
layered interleaving for a
a pool can estimate
pool can estimate its
can estimate its expected
estimate its expected mining
its expected mining power
expected mining power and
mining power and its
power and its actual
and its actual mining
its actual mining power
actual mining power by
mining power by the
power by the rates
by the rates of
the rates of partial
rates of partial proofs
of partial proofs of
partial proofs of work
proofs of work and
of work and full
work and full proofs
and full proofs of
full proofs of work
supplied by its miners
a difference above a
difference above a set
above a set confidence
a set confidence interval
set confidence interval indicates
confidence interval indicates an
interval indicates an attack
to detect whether a
detect whether a single
whether a single miner
a single miner is
single miner is attacking
miner is attacking it
the pool must use
pool must use a
must use a similar
use a similar technique
comparing the estimated mining
the estimated mining power
estimated mining power of
standard fec schemes can
mining power of the
fec schemes can be
power of the attacker
schemes can be made
of the attacker based
can be made resistant
the attacker based on
be made resistant to
attacker based on its
made resistant to a
based on its partial
resistant to a certain
on its partial proof
to a certain loss
its partial proof of
a certain loss burst
partial proof of work
certain loss burst length
proof of work with
loss burst length at
of work with the
burst length at the
work with the fact
length at the cost
with the fact it
at the cost of
the fact it never
the cost of increased
fact it never supplies
cost of increased recovery
it never supplies a
of increased recovery latency
never supplies a full
increased recovery latency for
supplies a full proof
recovery latency for all
a full proof of
latency for all lost
full proof of work
for all lost packets
if the attacker has
including smaller bursts and
the attacker has a
smaller bursts and singleton
attacker has a small
bursts and singleton drops
has a small mining
a small mining power
it will send frequent
will send frequent partial
send frequent partial proofs
frequent partial proofs of
layered interleaving provides graceful
partial proofs of work
interleaving provides graceful degradation
provides graceful degradation in
graceful degradation in the
but the pool will
degradation in the face
the pool will only
in the face of
pool will only expect
the face of bursty
will only expect to
face of bursty loss
only expect to see
of bursty loss for
expect to see a
bursty loss for constant
to see a full
loss for constant encoding
see a full proof
for constant encoding overhead
a full proof of
constant encoding overhead singleton
full proof of work
encoding overhead singleton random
proof of work at
overhead singleton random losses
of work at very
singleton random losses are
work at very low
random losses are recovered
at very low frequency
losses are recovered as
are recovered as quickly
recovered as quickly as
as quickly as possible
it cannot obtain statistically
by xors generated with
cannot obtain statistically significant
xors generated with an
obtain statistically significant results
generated with an interleave
statistically significant results that
with an interleave of
significant results that would
results that would indicate
that would indicate an
would indicate an attack
an attacker can use
and each successive layer
attacker can use multiple
each successive layer of
can use multiple small
successive layer of xors
use multiple small block
layer of xors generated
multiple small block withholding
of xors generated at
small block withholding miners
xors generated at a
block withholding miners and
generated at a higher
withholding miners and replace
at a higher interleave
miners and replace them
a higher interleave catches
and replace them frequently
higher interleave catches larger
interleave catches larger bursts
catches larger bursts missed
larger bursts missed by
bursts missed by the
a small miner is
missed by the previous
by the previous layer
the implementation of this
implementation of this algorithm
a miner whose expected
of this algorithm is
miner whose expected full
this algorithm is simple
whose expected full proof
algorithm is simple and
expected full proof of
is simple and shown
full proof of work
simple and shown in
proof of work frequency
and shown in figure
of work frequency is
work frequency is yearly
such a miner will
a miner will see
miner will see a
will see a non
a set of repair
negligible average daily revenue
set of repair bins
of repair bins is
repair bins is maintained
bins is maintained for
is maintained for each
maintained for each layer
with i bins for
i bins for a
bins for a layer
for a layer with
a layer with interleave
layer with interleave i
a repair bin consists
repair bin consists of
bin consists of a
consists of a partially
of a partially constructed
a partially constructed repair
partially constructed repair packet
an xor and the
xor and the recipe
and the recipe list
the recipe list of
recipe list of identifiers
list of identifiers of
of identifiers of data
identifiers of data packets
of data packets that
data packets that compose
packets that compose the
that compose the xor
each intercepted data packet
intercepted data packet is
if the attacker replaces
data packet is added
the attacker replaces such
packet is added to
attacker replaces such a
is added to each
replaces such a small
added to each layer
such a small miner
to each layer where
a small miner every
each layer where adding
small miner every month
layer where adding to
where adding to a
adding to a layer
to a layer simply
he will collect about
a layer simply means
will collect about b
layer simply means choosing
simply means choosing a
means choosing a repair
choosing a repair bin
at the end of
a repair bin from
the end of each
repair bin from the
end of each month
bin from the layer
from the layer s
the layer s set
the pool must decide
pool must decide within
must decide within this
incrementally updating the xor
decide within this month
updating the xor with
within this month whether
the xor with the
this month whether the
xor with the new
month whether the miner
with the new data
whether the miner is
the new data packet
the miner is an
miner is an attacker
and adding the data
and revoke its earnings
adding the data packet
the data packet s
data packet s header
packet s header to
s header to the
header to the recipe
to the recipe list
or just an unlucky
just an unlucky honest
an unlucky honest miner
a counter is incremented
counter is incremented as
is incremented as each
incremented as each data
since an honest miner
as each data packet
an honest miner of
each data packet arrives
honest miner of this
data packet arrives at
miner of this power
packet arrives at the
of this power is
arrives at the appliance
this power is unlikely
power is unlikely to
is unlikely to find
unlikely to find a
to find a full
and choosing the repair
find a full proof
choosing the repair bin
a full proof of
full proof of work
the repair bin from
proof of work within
of work within a
repair bin from the
work within a month
bin from the layer
from the layer s
the layer s set
layer s set is
s set is done
set is done by
is done by taking
done by taking the
by taking the modulo
taking the modulo of
according to the exponential
the modulo of the
to the exponential distribution
modulo of the counter
of the counter with
the counter with the
counter with the number
with the number of
a pool that rejects
the number of bins
pool that rejects miners
number of bins in
that rejects miners based
of bins in each
rejects miners based on
bins in each layer
miners based on this
based on this criterion
on this criterion would
this criterion would reject
criterion would reject the
for a layer with
would reject the majority
a layer with interleave
reject the majority of
the majority of its
majority of its honest
of its honest miners
the alternative of rejecting
alternative of rejecting small
the xth intercepted packet
of rejecting small miners
xth intercepted packet is
rejecting small miners in
intercepted packet is added
small miners in general
packet is added to
miners in general or
is added to the
in general or distributing
general or distributing revenue
or distributing revenue on
distributing revenue on a
revenue on a yearly
on a yearly basis
a yearly basis contradicts
yearly basis contradicts the
basis contradicts the goal
contradicts the goal of
the goal of pooled
goal of pooled mining
when a repair bin
m odel and s
a repair bin fills
odel and s tandard
repair bin fills up
and s tandard o
bin fills up its
s tandard o peration
fills up its recipe
tandard o peration we
up its recipe list
o peration we specify
its recipe list contains
peration we specify the
recipe list contains r
we specify the basic
list contains r data
specify the basic model
contains r data packets
the basic model in
r data packets it
basic model in which
data packets it fires
model in which participants
in which participants operate
which participants operate in
participants operate in section
operate in section iii
a repair packet is
repair packet is generated
packet is generated consisting
is generated consisting of
generated consisting of the
consisting of the xor
of the xor and
proceed to describe how
the xor and the
to describe how honest
xor and the recipe
describe how honest miners
and the recipe list
how honest miners operate
the recipe list and
honest miners operate in
recipe list and is
miners operate in this
list and is scheduled
operate in this environment
and is scheduled for
in this environment in
is scheduled for sending
this environment in sections
environment in sections iii
while the repair bin
the repair bin is
repair bin is re
initialized with an empty
with an empty recipe
an empty recipe list
and how the classical
empty recipe list and
how the classical block
recipe list and blank
the classical block withholding
list and blank xor
classical block withholding attack
block withholding attack is
withholding attack is implemented
attack is implemented with
is implemented with our
implemented with our model
with our model in
our model in section
model in section iii
incoming repair packets are
repair packets are processed
packets are processed as
are processed as follows
if all the data
model the system is
all the data packets
the system is comprised
the data packets contained
system is comprised of
data packets contained in
is comprised of the
packets contained in the
comprised of the bitcoin
contained in the repair
of the bitcoin network
in the repair s
the bitcoin network and
the repair s recipe
bitcoin network and nodes
repair s recipe list
network and nodes with
s recipe list have
and nodes with unique
recipe list have been
nodes with unique ids
list have been received
have been received successfully
and progresses in steps
the repair packet is
repair packet is discarded
a node i generates
node i generates tasks
if the repair s
i generates tasks which
the repair s recipe
generates tasks which are
repair s recipe list
tasks which are associated
s recipe list contains
which are associated with
recipe list contains a
are associated with its
list contains a single
associated with its id
contains a single missing
with its id i
a single missing data
single missing data packet
a node can work
node can work on
recovery can occur immediately
can work on a
can occur immediately by
work on a task
occur immediately by combining
on a task for
immediately by combining the
a task for the
by combining the xor
task for the duration
combining the xor in
for the duration of
the xor in the
the duration of a
xor in the repair
duration of a step
in the repair with
the repair with layer
the result of this
result of this work
of this work is
this work is a
work is a set
is a set of
a set of partial
set of partial proofs
of partial proofs of
partial proofs of work
proofs of work and
of work and a
work and a set
and a set of
a set of full
set of full proofs
of full proofs of
full proofs of work
the number of proofs
number of proofs in
of proofs in each
proofs in each set
in each set has
each set has a
set has a poisson
has a poisson distribution
partial proofs with a
proofs with a large
with a large mean
a large mean and
large mean and full
mean and full proofs
and full proofs with
full proofs with a
proofs with a small
with a small mean
nodes that work on
that work on tasks
work on tasks are
on tasks are called
tasks are called a
are called a miners
miners have identical power
and hence identical probabilities
hence identical probabilities to
identical probabilities to generate
probabilities to generate proofs
to generate proofs of
generate proofs of work
the bitcoin network pays
bitcoin network pays for
network pays for full
pays for full proofs
for full proofs of
full proofs of work
to acquire this payoff
acquire this payoff an
this payoff an entity
payoff an entity publishes
an entity publishes a
entity publishes a task
publishes a task task
a task task and
task task and its
task and its corresponding
and its corresponding proof
its corresponding proof of
corresponding proof of work
proof of work to
of work to the
work to the network
the payoff goes to
payoff goes to the
goes to the id
to the id associated
the id associated with
id associated with task
the bitcoin protocol normalizes
bitcoin protocol normalizes revenue
protocol normalizes revenue such
normalizes revenue such that
revenue such that the
such that the average
that the average total
the average total revenue
average total revenue distributed
total revenue distributed in
revenue distributed in each
distributed in each step
in each step is
each step is a
step is a constant
is a constant throughout
a constant throughout the
constant throughout the execution
throughout the execution of
the execution of the
layer with interleave of
execution of the system
any node can transact
node can transact bitcoins
can transact bitcoins to
transact bitcoins to another
bitcoins to another node
to another node by
another node by issuing
node by issuing a
by issuing a bitcoin
issuing a bitcoin transaction
nodes that generate tasks
that generate tasks but
generate tasks but outsource
tasks but outsource the
but outsource the work
outsource the work are
the work are called
work are called pools
pools send tasks to
send tasks to miners
tasks to miners over
to miners over the
miners over the network
the miners receive the
miners receive the tasks
and send the partial
send the partial and
the partial and full
partial and full proofs
and full proofs of
full proofs of work
proofs of work to
of work to the
work to the pool
apart from working on
from working on tasks
and receipt are instantaneous
we assume that the
assume that the number
that the number of
the number of miners
number of miners is
of miners is large
miners is large enough
is large enough such
large enough such that
enough such that mining
such that mining power
that mining power can
mining power can be
power can be split
can be split arbitrarily
be split arbitrarily without
split arbitrarily without resolution
arbitrarily without resolution constraints
denote the number of
the number of pools
number of pools with
of pools with p
the total number of
total number of mining
number of mining power
of mining power in
mining power in the
power in the system
in the system with
the system with m
system with m and
with m and the
m and the miners
and the miners participating
the miners participating in
miners participating in pool
participating in pool i
we use a quasistatic
use a quasistatic analysis
a quasistatic analysis where
quasistatic analysis where miner
analysis where miner participation
the other successfully received
where miner participation in
other successfully received data
miner participation in a
successfully received data packets
participation in a pool
in a pool does
a pool does not
pool does not change
does not change over
not change over time
if the repair contains
the repair contains multiple
repair contains multiple missing
contains multiple missing data
multiple missing data packets
solo mining a solo
it cannot be used
mining a solo miner
cannot be used immediately
a solo miner is
be used immediately for
solo miner is a
used immediately for recovery
miner is a node
immediately for recovery it
is a node that
for recovery it is
a node that generates
recovery it is instead
node that generates its
it is instead stored
that generates its own
is instead stored in
generates its own tasks
instead stored in a
stored in a table
in a table that
a table that maps
table that maps missing
in every step it
that maps missing data
every step it generates
maps missing data packets
step it generates a
missing data packets to
it generates a task
data packets to repair
packets to repair packets
works on it for
on it for the
whenever a data packet
it for the duration
a data packet is
for the duration of
data packet is subsequently
the duration of the
packet is subsequently received
duration of the step
is subsequently received or
of the step and
subsequently received or recovered
the step and if
step and if it
and if it finds
if it finds a
it finds a full
finds a full proof
a full proof of
this table is checked
full proof of work
table is checked to
is checked to see
checked to see if
it publishes this proof
to see if any
publishes this proof of
see if any xors
this proof of work
if any xors now
proof of work to
any xors now have
of work to earn
xors now have singleton
work to earn the
now have singleton losses
to earn the payoff
have singleton losses due
singleton losses due to
losses due to the
due to the presence
to the presence of
the presence of the
presence of the new
of the new packet
pools a pool is
the new packet and
a pool is a
new packet and can
pool is a node
packet and can be
is a node that
and can be used
a node that serves
can be used for
node that serves as
be used for recovering
that serves as a
used for recovering other
serves as a coordinator
for recovering other missing
as a coordinator and
recovering other missing packets
a coordinator and multiple
coordinator and multiple miners
and multiple miners can
multiple miners can register
miners can register to
can register to a
register to a pool
to a pool and
a pool and work
pool and work for
xors received from different
and work for it
received from different layers
from different layers interact
different layers interact to
layers interact to recover
interact to recover missing
in every step it
to recover missing data
every step it generates
recover missing data packets
step it generates a
it generates a task
generates a task for
a task for each
task for each registered
since an xor received
for each registered miner
an xor received at
each registered miner and
xor received at a
registered miner and sends
received at a higher
miner and sends it
at a higher interleave
and sends it over
a higher interleave can
sends it over the
higher interleave can recover
it over the network
interleave can recover a
can recover a packet
recover a packet that
a packet that makes
each miner receives its
packet that makes an
miner receives its task
that makes an earlier
receives its task and
makes an earlier xor
its task and works
an earlier xor at
task and works on
earlier xor at a
and works on it
xor at a lower
works on it for
at a lower interleave
on it for the
a lower interleave usable
it for the duration
lower interleave usable hence
for the duration of
the duration of the
duration of the step
at the end of
though layered interleaving is
the end of the
layered interleaving is equivalent
end of the step
interleaving is equivalent to
is equivalent to c
equivalent to c different
the miner sends the
miner sends the pool
sends the pool the
the pool the full
pool the full and
the full and the
full and the partial
and the partial proofs
the partial proofs of
partial proofs of work
proofs of work it
of work it has
work it has found
instances in terms of
in terms of overhead
terms of overhead and
of overhead and design
the pool receives the
pool receives the proofs
receives the proofs of
its recovery power is
the proofs of work
recovery power is much
proofs of work of
power is much higher
of work of all
is much higher and
work of all its
much higher and comes
of all its miners
higher and comes close
and comes close to
comes close to standard
registers the partial proofs
the partial proofs of
partial proofs of work
proofs of work and
of work and publishes
work and publishes the
and publishes the full
publishes the full proofs
it calculates its overall
calculates its overall revenue
and proceeds to distribute
proceeds to distribute it
to distribute it among
distribute it among its
it among its miners
each miner receives revenue
miner receives revenue proportional
receives revenue proportional to
revenue proportional to its
proportional to its success
to its success in
its success in the
success in the current
in the current step
namely the ratio of
the ratio of its
ratio of its partial
of its partial proofs
its partial proofs of
partial proofs of work
proofs of work out
of work out of
work out of all
out of all partial
of all partial proofs
all partial proofs of
partial proofs of work
proofs of work the
of work the pool
work the pool received
we assume that pools
assume that pools do
that pools do not
pools do not collect
do not collect fees
not collect fees of
collect fees of the
fees of the revenue
pool fees and their
fees and their implications
and their implications on
their implications on our
implications on our analysis
on our analysis are
our analysis are discussed
analysis are discussed in
are discussed in section
discussed in section ix
block withholding miner a
withholding miner a miner
miner a miner registered
a miner registered at
miner registered at a
registered at a pool
at a pool can
a pool can perform
pool can perform the
can perform the classical
perform the classical block
the classical block withholding
classical block withholding attack
an attacker miner operates
attacker miner operates as
miner operates as if
operates as if it
as if it worked
if it worked for
it worked for the
worked for the pool
second set of rsized
set of rsized xors
of rsized xors staggered
rsized xors staggered start
xors staggered start xors
it receives its tasks
receives its tasks and
its tasks and works
tasks and works on
and works on them
only at the end
at the end of
the end of each
end of each round
of each round it
each round it sends
round it sends only
it sends only its
sends only its partial
only its partial proofs
its partial proofs of
partial proofs of work
and omits full proofs
omits full proofs of
full proofs of work
proofs of work if
of work if it
work if it had
if it had found
it had found any
the pool registers the
pool registers the miner
registers the miner s
the miner s partial
miner s partial proofs
but cannot distinguish between
cannot distinguish between miners
distinguish between miners running
between miners running honestly
miners running honestly and
running honestly and block
honestly and block withholding
and block withholding miners
the implications are that
implications are that a
are that a miner
that a miner that
a miner that engages
miner that engages in
that engages in block
engages in block withholding
in block withholding does
block withholding does not
withholding does not contribute
does not contribute to
not contribute to the
contribute to the pool
to the pool s
the pool s overall
pool s overall mining
s overall mining power
but still shares the
still shares the pool
shares the pool s
the pool s revenue
pool s revenue according
s revenue according to
revenue according to its
according to its sent
to its sent partial
its sent partial proofs
sent partial proofs of
partial proofs of work
to reason about a
reason about a pool
about a pool s
a pool s efficiency
pool s efficiency we
s efficiency we define
efficiency we define its
we define its per
miner revenue as follows
the revenue density of
revenue density of a
density of a pool
of a pool is
a pool is the
pool is the ratio
is the ratio between
the ratio between the
ratio between the average
between the average revenue
the average revenue a
average revenue a pool
revenue a pool member
a pool member earns
pool member earns and
member earns and the
earns and the average
and the average revenue
the average revenue it
average revenue it would
revenue it would have
it would have earned
would have earned as
have earned as a
earned as a solo
as a solo miner
the revenue density of
revenue density of a
density of a solo
of a solo miner
and that of a
that of a miner
of a miner working
a miner working with
miner working with an
working with an unattacked
with an unattacked pool
an unattacked pool are
unattacked pool are one
if a pool is
a pool is attacked
pool is attacked with
is attacked with block
attacked with block withholding
its revenue density decreases
continuous analysis because our
analysis because our analysis
because our analysis will
our analysis will be
analysis will be of
will be of the
be of the average
of the average revenue
we will consider proofs
will consider proofs of
consider proofs of work
both full and partial
as continuous deterministic sizes
according to their probability
work on a task
on a task therefore
a task therefore results
task therefore results in
therefore results in a
results in a deterministic
in a deterministic fraction
a deterministic fraction of
deterministic fraction of proof
fraction of proof of
of proof of work
t he p ool
he p ool g
p ool g ame
ool g ame a
the pool block withholding
pool block withholding attack
block withholding attack just
withholding attack just as
attack just as a
just as a miner
as a miner can
a miner can perform
miner can perform block
can perform block withholding
perform block withholding on
block withholding on a
withholding on a pool
on a pool j
a pool i can
pool i can use
i can use some
can use some of
use some of its
some of its mining
of its mining power
its mining power to
mining power to infiltrate
power to infiltrate a
to infiltrate a pool
infiltrate a pool j
a pool j and
pool j and perform
j and perform a
and perform a block
perform a block withholding
a block withholding attack
block withholding attack on
withholding attack on j
denote the amount of
the amount of such
amount of such infiltrating
of such infiltrating mining
such infiltrating mining power
infiltrating mining power at
mining power at step
power at step t
at step t by
step t by xi
miners working for pool
working for pool i
either mining honestly or
mining honestly or used
honestly or used for
or used for infiltrating
used for infiltrating pool
for infiltrating pool j
are loyal to pool
loyal to pool i
at the end of
the end of a
end of a round
pool i aggregates its
i aggregates its revenue
aggregates its revenue from
its revenue from mining
revenue from mining in
from mining in the
mining in the current
in the current round
the current round and
current round and from
round and from its
and from its infiltration
from its infiltration in
its infiltration in the
infiltration in the previous
in the previous round
it distributes the revenue
distributes the revenue evenly
the revenue evenly among
revenue evenly among all
evenly among all its
among all its loyal
all its loyal miners
its loyal miners according
loyal miners according to
miners according to their
according to their partial
to their partial proofs
their partial proofs of
partial proofs of work
the pool s miners
pool s miners are
s miners are oblivious
miners are oblivious to
are oblivious to their
oblivious to their role
to their role and
their role and they
role and they operate
and they operate as
they operate as regular
operate as regular honest
as regular honest miners
revenue convergence note that
convergence note that pool
note that pool j
that pool j sends
pool j sends its
j sends its revenue
sends its revenue to
its revenue to infiltrators
revenue to infiltrators from
to infiltrators from pool
infiltrators from pool i
from pool i at
pool i at the
i at the end
at the end of
the end of the
end of the step
and this revenue is
this revenue is calculated
revenue is calculated in
is calculated in pool
calculated in pool i
in pool i at
pool i at the
i at the beginning
at the beginning of
the beginning of the
beginning of the subsequent
of the subsequent step
if there is a
there is a chain
is a chain of
a chain of pools
where each pool infiltrates
each pool infiltrates the
pool infiltrates the previous
infiltrates the previous one
the pool revenue will
pool revenue will not
revenue will not be
will not be static
since the revenue from
the revenue from infiltration
revenue from infiltration takes
from infiltration takes one
infiltration takes one step
takes one step to
one step to take
step to take each
to take each hop
from the first step
the revenue of pool
since it is only
it is only infiltrated
is only infiltrated and
only infiltrated and loses
infiltrated and loses some
and loses some of
loses some of its
some of its revenue
of its revenue for
its revenue for pool
starting from the second
from the second step
the revenue of pool
comprised of its own
of its own mining
its own mining and
own mining and its
mining and its revenue
and its revenue from
its revenue from the
revenue from the infiltration
from the infiltration of
the infiltration of pool
with some revenue lost
some revenue lost due
revenue lost due to
lost due to its
due to its infiltration
to its infiltration by
its infiltration by pool
starting from the third
from the third step
the revenue of pool
max is the longest
is the longest chain
the longest chain in
longest chain in the
chain in the system
the revenue stabilizes after
if there are loops
there are loops in
are loops in the
loops in the infiltration
in the infiltration graph
the system will converge
system will converge to
will converge to a
converge to a certain
to a certain revenue
as stated in the
stated in the following
in the following lemma
if infiltration rates are
infiltration rates are constant
the pool revenues converge
pool revenues converge to
revenues converge to a
converge to a limit
comparison of packet recovery
to a limit as
of packet recovery probability
a limit as time
limit as time progresses
denote the revenue density
the revenue density of
revenue density of pool
density of pool i
of pool i at
pool i at the
i at the end
at the end of
the end of step
end of step t
of step t by
step t by ri
and define the revenue
define the revenue density
the revenue density vector
revenue density vector r
optimizations staggered start for
staggered start for rate
limiting in the naive
in the naive implementation
the naive implementation of
naive implementation of the
implementation of the layered
of the layered interleaving
the layered interleaving algorithm
repair packets are transmitted
packets are transmitted as
are transmitted as soon
transmitted as soon as
as soon as repair
soon as repair bins
as repair bins fill
repair bins fill and
bins fill and allow
fill and allow them
and allow them to
allow them to be
them to be constructed
all the repair bins
the repair bins in
repair bins in a
bins in a layer
in a layer fill
a layer fill in
layer fill in quick
fill in quick succession
the revenues at all
revenues at all pools
at all pools converge
all pools converge as
the arrival of packets
pools converge as follows
will successively fill the
successively fill the four
fill the four repair
the four repair bins
four repair bins in
repair bins in layer
this behavior leads to
behavior leads to a
leads to a large
to a large number
a large number of
large number of repair
number of repair packets
of repair packets being
repair packets being generated
packets being generated and
being generated and sent
generated and sent within
and sent within a
sent within a short
within a short period
a short period of
short period of time
which results in undesirable
p in every round
results in undesirable overhead
in undesirable overhead and
undesirable overhead and traffic
overhead and traffic spikes
pool i uses its
i uses its mining
uses its mining power
its mining power of
mining power of m
we would like to
would like to rate
limit transmissions of repair
transmissions of repair packets
of repair packets to
j used for direct
repair packets to one
used for direct mining
packets to one for
for direct mining p
to one for every
one for every r
for every r data
every r data packets
this problem is fixed
problem is fixed by
is fixed by staggering
fixed by staggering the
and shares it among
by staggering the starting
shares it among its
staggering the starting sizes
it among its m
the starting sizes of
starting sizes of the
sizes of the bins
analogous to the starting
to the starting positions
the starting positions of
starting positions of runners
positions of runners in
of runners in a
runners in a sprint
the very first time
very first time bin
first time bin number
time bin number x
bin number x in
all sums are over
number x in a
sums are over the
x in a layer
are over the range
in a layer of
a layer of interleave
layer of interleave i
of interleave i fires
it does so at
does so at size
so at size x
at size x mod
size x mod r
the first repair bin
first repair bin in
repair bin in the
bin in the second
denote the direct mining
in the second layer
the direct mining revenue
the second layer with
direct mining revenue density
second layer with interleave
mining revenue density of
revenue density of each
density of each pool
would fire at size
which is a constant
is a constant factor
the second would fire
second would fire at
would fire at size
for the first i
the first i data
first i data packets
i data packets added
data packets added to
packets added to a
added to a layer
to a layer with
a layer with interleave
layer with interleave i
r fire immediately with
fire immediately with just
immediately with just one
with just one packet
just one packet in
one packet in them
for the next i
the next i data
next i data packets
i data packets added
r fire immediately with
fire immediately with two
immediately with two data
with two data packets
two data packets in
data packets in them
and so on until
so on until r
on until r i
until r i data
r i data packets
i data packets have
data packets have been
the pool game in
packets have been added
pool game in the
have been added to
game in the pool
been added to the
in the pool game
added to the layer
the pool game pools
to the layer and
pool game pools try
the layer and all
game pools try to
layer and all bins
pools try to optimize
and all bins have
try to optimize their
all bins have fired
to optimize their infiltration
bins have fired exactly
optimize their infiltration rates
have fired exactly once
their infiltration rates of
infiltration rates of other
rates of other pools
of other pools to
other pools to maximize
pools to maximize their
to maximize their revenue
all bins fire at
bins fire at size
fire at size r
the overall number of
overall number of miners
number of miners and
of miners and the
miners and the number
and the number of
the number of miners
now that they have
number of miners loyal
that they have been
of miners loyal to
they have been staggered
miners loyal to each
have been staggered at
loyal to each pool
been staggered at the
to each pool remain
staggered at the start
each pool remain constant
pool remain constant throughout
remain constant throughout the
constant throughout the game
time progresses in rounds
r fire for any
fire for any i
for any i data
any i data packets
let s be a
s be a constant
be a constant integer
the outlined scheme works
a constant integer large
outlined scheme works when
constant integer large enough
scheme works when i
integer large enough that
works when i is
large enough that revenue
when i is greater
enough that revenue can
i is greater than
that revenue can be
is greater than or
revenue can be approximated
greater than or equal
can be approximated as
than or equal to
be approximated as its
or equal to r
approximated as its convergence
as its convergence limit
as is usually the
is usually the case
in each round the
each round the system
round the system takes
the system takes s
if i is smaller
system takes s steps
i is smaller than
takes s steps and
is smaller than r
s steps and then
steps and then a
and then a single
then a single pool
the bin with index
bin with index x
with index x fires
index x fires at
picked with a round
may change its infiltration
change its infiltration rates
its infiltration rates of
infiltration rates of all
rates of all other
of all other pools
the total revenue of
total revenue of each
revenue of each step
of each step is
each step is normalized
step is normalized to
so the revenue per
the revenue per round
revenue per round is
per round is one
the initial firing sizes
initial firing sizes would
the pool taking a
firing sizes would be
pool taking a step
taking a step knows
a step knows the
step knows the rate
knows the rate of
for the first bin
the rate of infiltrators
the first bin and
rate of infiltrators attacking
of infiltrators attacking it
for the second bin
though not their identity
if r and i
r and i are
and the revenue rates
and i are not
the revenue rates of
i are not integral
revenue rates of each
are not integral multiples
rates of each of
not integral multiples of
of each of the
integral multiples of each
each of the other
multiples of each other
of the other pools
this knowledge is required
knowledge is required to
is required to optimize
required to optimize a
limiting still works but
to optimize a pool
still works but is
optimize a pool s
works but is slightly
a pool s revenue
but is slightly less
is slightly less effective
slightly less effective due
less effective due to
effective due to rounding
as we see next
due to rounding errors
we explain in section
delaying xors in the
explain in section viii
xors in the naive
in section viii how
in the naive implementation
section viii how a
viii how a pool
how a pool can
a pool can technically
pool can technically obtain
repair packets are transmitted
can technically obtain this
packets are transmitted as
technically obtain this knowledge
are transmitted as soon
transmitted as soon as
as soon as they
soon as they are
as they are generated
general analysis recall that
this results in the
analysis recall that mi
results in the repair
recall that mi is
in the repair packet
that mi is the
the repair packet leaving
mi is the number
repair packet leaving immediately
is the number of
packet leaving immediately after
the number of miners
leaving immediately after the
number of miners loyal
immediately after the last
of miners loyal to
after the last data
miners loyal to pool
the last data packet
loyal to pool i
last data packet that
data packet that was
packet that was added
that was added to
was added to it
which lowers burst tolerance
lowers burst tolerance if
burst tolerance if the
tolerance if the repair
if the repair packet
the repair packet was
repair packet was generated
is the number of
packet was generated at
the number of miners
was generated at interleave
number of miners used
generated at interleave i
of miners used by
miners used by pool
used by pool i
by pool i to
pool i to infiltrate
the resulting protocol can
i to infiltrate pool
resulting protocol can tolerate
to infiltrate pool j
protocol can tolerate a
infiltrate pool j at
can tolerate a burst
pool j at step
tolerate a burst of
j at step t
a burst of i
burst of i lost
of i lost data
i lost data packets
lost data packets excluding
data packets excluding the
the mining rate of
packets excluding the repair
mining rate of pool
rate of pool i
of pool i is
pool i is therefore
i is therefore the
but the burst could
is therefore the number
the burst could swallow
therefore the number of
burst could swallow both
the number of its
could swallow both the
number of its loyal
swallow both the repair
of its loyal miners
both the repair and
its loyal miners minus
the repair and the
loyal miners minus the
repair and the last
miners minus the miners
and the last data
minus the miners it
the last data packet
the miners it uses
last data packet in
miners it uses for
data packet in it
it uses for infiltration
packet in it as
in it as they
it as they are
as they are not
they are not separated
are not separated by
not separated by the
separated by the requisite
this effective mining rate
by the requisite interleave
effective mining rate is
mining rate is divided
rate is divided by
is divided by the
divided by the total
by the total mining
the solution to this
the total mining rate
solution to this is
total mining rate in
mining rate in the
to this is simple
rate in the system
this is simple delay
is simple delay sending
simple delay sending the
namely the number of
delay sending the repair
the number of all
sending the repair packet
number of all miners
the repair packet generated
of all miners that
repair packet generated by
all miners that do
packet generated by a
miners that do not
generated by a repair
that do not engage
by a repair bin
do not engage in
a repair bin until
not engage in block
repair bin until the
engage in block withholding
bin until the next
until the next time
the next time a
next time a data
time a data packet
a data packet is
data packet is added
packet is added to
denote the direct mining
is added to the
the direct mining rate
added to the now
direct mining rate of
to the now empty
mining rate of pool
the now empty bin
rate of pool i
of pool i at
pool i at step
i at step t
at step t by
step t by pp
t by pp mi
by pp mi j
which happens i packets
happens i packets later
i packets later and
packets later and introduces
later and introduces the
and introduces the required
introduces the required interleave
the required interleave between
required interleave between the
interleave between the repair
between the repair packet
the repair packet and
repair packet and the
packet and the last
and the last data
the last data packet
last data packet included
data packet included in
packet included in it
notice that although transmitting
that although transmitting the
although transmitting the xor
transmitting the xor immediately
the xor immediately results
xor immediately results in
immediately results in faster
results in faster recovery
doing so also reduces
so also reduces the
also reduces the probability
reduces the probability of
the probability of a
probability of a lost
k the revenue of
of a lost packet
the revenue of pool
a lost packet being
revenue of pool i
lost packet being recovered
of pool i in
pool i in step
i in step t
in step t taken
step t taken through
t taken through infiltration
taken through infiltration from
through infiltration from pool
off results in a
infiltration from pool j
results in a minor
from pool j s
in a minor control
pool j s revenue
a minor control knob
j s revenue in
minor control knob permitting
s revenue in step
control knob permitting us
revenue in step t
knob permitting us to
permitting us to balance
us to balance speed
to balance speed against
balance speed against burst
speed against burst tolerance
our default configuration is
default configuration is to
configuration is to transmit
is to transmit the
to transmit the xor
transmit the xor immediately
pool i distributes this
i distributes this revenue
distributes this revenue among
this revenue among its
revenue among its mi
i members loyal and
members loyal and infiltrators
define the p p
envelope analysis to start
the p p infiltration
analysis to start with
p p infiltration matrix
p infiltration matrix by
infiltration matrix by its
matrix by its i
we note that no
note that no two
that no two repair
no two repair packets
two repair packets generated
repair packets generated at
packets generated at different
generated at different interleaves
at different interleaves i
i ij the revenue
ij the revenue density
the revenue density of
revenue density of pool
density of pool i
of pool i at
pool i at the
i at the end
at the end of
the end of step
will have more than
end of step t
have more than one
of step t is
more than one data
step t is its
than one data packet
t is its revenue
one data packet in
is its revenue from
data packet in common
its revenue from direct
packet in common as
revenue from direct mining
in common as long
from direct mining together
common as long as
direct mining together with
as long as the
mining together with its
long as the least
together with its revenue
as the least common
with its revenue from
the least common multiple
its revenue from infiltrated
revenue from infiltrated pools
divided by the number
by the number of
the number of its
of the interleaves is
number of its loyal
the interleaves is greater
of its loyal miners
interleaves is greater than
its loyal miners together
is greater than r
loyal miners together with
greater than r i
miners together with block
withholding infiltrators that attack
infiltrators that attack it
pairings of repair bins
of repair bins in
repair bins in two
bins in two different
in two different layers
two different layers with
different layers with interleaves
layers with interleaves i
a good rule of
good rule of thumb
rule of thumb is
of thumb is to
thumb is to select
is to select interleaves
to select interleaves that
select interleaves that are
interleaves that are relatively
that are relatively prime
are relatively prime to
relatively prime to maximize
prime to maximize their
to maximize their lcm
and also ensure that
also ensure that the
ensure that the larger
that the larger interleave
the larger interleave is
larger interleave is greater
interleave is greater than
is greater than r
let us assume that
us assume that packets
assume that packets are
that packets are dropped
packets are dropped with
are dropped with uniform
given a lost data
a lost data packet
and the revenue vector
the revenue vector at
revenue vector at step
what is the probability
vector at step t
is the probability that
at step t is
the probability that we
step t is hereinafter
probability that we can
t is hereinafter we
that we can recover
is hereinafter we move
we can recover it
hereinafter we move to
we move to a
move to a static
to a static state
a static state analysis
we can recover a
static state analysis and
can recover a data
state analysis and omit
recover a data packet
analysis and omit the
a data packet if
and omit the t
data packet if at
omit the t argument
packet if at least
the t argument in
if at least one
t argument in the
at least one of
argument in the expressions
least one of the
one of the c
of the c xors
the c xors containing
c xors containing it
xors containing it is
containing it is re
local recovery for receiver
recovery for receiver loss
for receiver loss ceived
receiver loss ceived correctly
loss ceived correctly and
ceived correctly and usable
all the other data
the other data packets
other data packets in
data packets in it
packets in it have
in it have also
it have also been
since the row sums
have also been received
the row sums of
also been received correctly
row sums of the
sums of the infiltration
of the infiltration matrix
the infiltration matrix are
infiltration matrix are smaller
the probability of in
matrix are smaller than
probability of in the
are smaller than one
of in the absence
in the absence of
the absence of intelligent
absence of intelligent flow
of intelligent flow control
its largest eigenvalue is
intelligent flow control mechanisms
largest eigenvalue is smaller
flow control mechanisms like
eigenvalue is smaller than
control mechanisms like which
mechanisms like which is
like which is simply
recall that difficulty is
that difficulty is only
difficulty is only adjusted
is only adjusted periodically
and there are transient
there are transient effects
are transient effects that
transient effects that are
effects that are not
that are not covered
the probability of a
are not covered by
probability of a received
not covered by this
of a received tcp
covered by this stable
we discuss this in
discuss this in section
this in section viii
inexpensive xor being unusable
xor being unusable is
being unusable is the
unusable is the complement
miners miners miners the
miners miners the revenue
miners the revenue its
the revenue its infiltrators
revenue its infiltrators obtained
its infiltrators obtained from
infiltrators obtained from pool
the revenue per loyal
revenue per loyal pool
hosts can be easily
can be easily overwhelmed
miner is therefore r
be easily overwhelmed and
easily overwhelmed and drop
overwhelmed and drop packets
and drop packets during
drop packets during traffic
packets during traffic spikes
during traffic spikes or
traffic spikes or cpu
the probability x of
probability x of a
x of a sent
of a sent xor
a sent xor being
sent xor being nance
xor being nance tasks
being nance tasks like
nance tasks like garbage
tasks like garbage collection
controls its infiltration rate
reliable applicationdropped or unusable
its infiltration rate of
infiltration rate of pool
applicationdropped or unusable is
or unusable is the
unusable is the sum
is the sum of
the sum of the
sum of the probability
of the probability that
the probability that it
probability that it level
that it level protocols
it level protocols layered
level protocols layered over
protocols layered over udp
layered over udp for
over udp for reliable
udp for reliable multiwas
for reliable multiwas dropped
and will choose the
reliable multiwas dropped and
will choose the value
multiwas dropped and the
choose the value that
dropped and the probability
the value that maximizes
and the probability that
value that maximizes the
the probability that it
that maximizes the revenue
probability that it was
maximizes the revenue density
that it was received
it was received and
was received and cast
on the first round
or high speed data
the first round of
high speed data transfer
first round of the
round of the pool
of the pool game
the value of r
is maximized at a
maximized at a single
at a single point
a single point in
single point in the
point in the feasible
in the feasible range
cannot not react to
not react to pool
this point is the
point is the stable
is the stable state
the stable state of
stable state of the
state of the system
and we denote the
we denote the value
denote the value of
the value of x
would ordinarily go back
ordinarily go back to
go back to the
back to the sender
to the sender to
the sender to retrieve
sender to retrieve the
to retrieve the lost
retrieve the lost packet
even though it was
though it was dropped
and the values of
it was dropped at
the values of the
was dropped at the
values of the corresponding
dropped at the receiver
of the corresponding revenues
at the receiver after
the corresponding revenues of
the receiver after since
corresponding revenues of the
receiver after since it
revenues of the pools
after since it is
of the pools with
since it is easy
the pools with r
it is easy to
is easy to ensure
easy to ensure that
to ensure that no
ensure that no two
that no two xors
no two xors share
two xors share covering
xors share covering the
share covering the entire
covering the entire geographical
the entire geographical distance
substituting the stable value
the stable value x
more than one data
than one data packet
the usability probabilities of
usability probabilities of the
probabilities of the maelstrom
we obtain the revenues
of the maelstrom proxy
obtain the revenues of
the maelstrom proxy acts
the revenues of the
maelstrom proxy acts as
revenues of the two
proxy acts as a
of the two pools
acts as a local
as a local packet
a local packet cache
all are given in
are given in figure
stordifferent xors are independent
the probability of all
probability of all ing
of all ing incoming
all ing incoming packets
ing incoming packets for
incoming packets for a
packets for a short
for a short period
to simplify the expressions
a short period of
short period of time
period of time and
of time and prothe
time and prothe c
and prothe c xors
prothe c xors being
c xors being dropped
xors being dropped or
being dropped or unusable
dropped or unusable is
or unusable is xc
viding hooks that allow
hooks that allow protocols
no attack if no
attack if no pool
that allow protocols to
if no pool engages
no pool engages in
allow protocols to first
pool engages in block
engages in block withholding
protocols to first query
to first query the
first query the cache
query the cache the
the cache the probability
cache the probability of
the probability of correctly
probability of correctly receiving
of correctly receiving at
correctly receiving at least
receiving at least one
at least one usable
least one usable to
one usable to locate
usable to locate missing
to locate missing packets
locate missing packets before
missing packets before sending
packets before sending retransmission
before sending retransmission xor
sending retransmission xor is
and we have i
the probability of recovrequests
probability of recovrequests back
of recovrequests back to
recovrequests back to the
back to the sender
future versions of maelstrom
versions of maelstrom ering
of maelstrom ering the
maelstrom ering the lost
ering the lost data
each miner s revenue
the lost data packet
miner s revenue is
lost data packet is
s revenue is proportional
revenue is proportional to
is proportional to its
proportional to its power
be it in a
which expands to could
it in a pool
expands to could potentially
in a pool or
to could potentially use
a pool or working
could potentially use knowledge
pool or working solo
potentially use knowledge of
use knowledge of protocol
knowledge of protocol internals
of protocol internals to
o ne attacker we
ne attacker we begin
attacker we begin our
we begin our analysis
begin our analysis with
our analysis with a
analysis with a simplified
with a simplified game
a simplified game of
simplified game of two
game of two pools
by intercepting and this
intercepting and this closed
form formula only gives
formula only gives us
only gives us a
gives us a lower
us a lower bound
a lower bound satisfying
lower bound satisfying retransmission
bound satisfying retransmission requests
satisfying retransmission requests sent
retransmission requests sent by
requests sent by the
sent by the receiver
by the receiver in
the receiver in on
miners outside both pools
receiver in on the
outside both pools mine
in on the recovery
both pools mine solo
on the recovery probability
or with closed pools
since the xor usability
with closed pools that
the xor usability for
closed pools that do
pools that do not
that do not attack
do not attack and
not attack and cannot
attack and cannot be
and cannot be attacked
or by resending packets
this scenario is illustrated
by resending packets when
scenario is illustrated in
is illustrated in figure
resending packets when acmula
packets when acmula does
when acmula does not
acmula does not factor
does not factor in
not factor in the
the dashed red arrow
factor in the probability
dashed red arrow indicates
in the probability of
red arrow indicates that
the probability of the
arrow indicates that x
probability of the other
of the other data
the other data knowledgments
other data knowledgments are
data knowledgments are not
knowledgments are not observed
are not observed within
not observed within a
observed within a certain
within a certain time
a certain time period
certain time period in
time period in an
period in an ack
s mining power infiltrates
mining power infiltrates pool
with a block withholding
a block withholding attack
packets in the xor
in the xor being
the xor being dropped
xor being dropped and
being dropped and recovered
does not engage in
not engage in block
engage in block withholding
we extend the analysis
all of its m
extend the analysis to
the analysis to bursty
analysis to bursty losses
loyal miners work on
miners work on its
work on its behalf
if the lost data
the lost data packet
lost data packet was
data packet was part
packet was part of
was part of a
part of a loss
of a loss burst
a loss burst of
loss burst of size
burst of size b
on the other hand
the other hand does
other hand does not
hand does not employ
does not employ x
repair packets generated at
packets generated at interleaves
generated at interleaves less
at interleaves less than
interleaves less than b
less than b are
than b are dropped
b are dropped or
are dropped or useless
dropped or useless with
or useless with high
of its loyal miners
useless with high probability
and its direct mining
and we can discount
its direct mining power
we can discount them
direct mining power is
mining power is only
power is only m
probability of recovering the
of recovering the data
recovering the data packet
the data packet is
data packet is then
the bitcoin system normalizes
bitcoin system normalizes these
system normalizes these rates
is the number of
normalizes these rates by
the number of xors
these rates by the
number of xors generated
rates by the total
of xors generated at
by the total number
xors generated at interleaves
the total number of
generated at interleaves greater
total number of miners
at interleaves greater than
number of miners that
interleaves greater than b
of miners that publish
miners that publish full
that publish full proofs
the formulae derived for
formulae derived for xor
derived for xor usability
for xor usability still
xor usability still hold
namely all miners but
all miners but x
since packet losses with
packet losses with more
losses with more than
with more than b
more than b intervening
than b intervening packets
b intervening packets between
intervening packets between them
packets between them have
between them have independent
them have independent probability
the pools direct revenues
pools direct revenues are
direct revenues are therefore
revenues are therefore m
there is only correlation
is only correlation within
only correlation within the
correlation within the bursts
how does this compare
does this compare to
this compare to traditional
codes such as reed
c repair packets are
repair packets are generated
packets are generated and
are generated and sent
generated and sent for
and sent for every
sent for every r
for every r data
every r data packets
and the correct delivery
the correct delivery of
correct delivery of any
delivery of any r
of any r of
any r of the
r of the r
divides its revenue among
its revenue among its
revenue among its loyal
among its loyal miners
its loyal miners and
c packets transmitted is
loyal miners and the
packets transmitted is sufficient
miners and the miners
transmitted is sufficient to
and the miners that
is sufficient to reconstruct
the miners that infiltrated
sufficient to reconstruct the
miners that infiltrated it
to reconstruct the original
reconstruct the original r
the original r data
original r data packets
its revenue density is
revenue density is therefore
density is therefore r
given a lost data
a lost data packet
we can recover it
can recover it if
recover it if at
it if at least
if at least r
at least r packets
least r packets are
r packets are received
packets are received correctly
are received correctly in
received correctly in the
correctly in the encoding
in the encoding set
the encoding set of
encoding set of r
c data and repair
data and repair packets
and repair packets that
repair packets that the
packets that the lost
that the lost packet
the lost packet belongs
lost packet belongs to
the probability of recovering
probability of recovering a
of recovering a lost
recovering a lost packet
a lost packet is
lost packet is equivalent
packet is equivalent to
is equivalent to the
equivalent to the probability
to the probability of
the probability of losing
probability of losing c
or less packets from
less packets from the
packets from the total
from the total r
since the number of
the number of other
number of other lost
of other lost packets
other lost packets in
lost packets in the
packets in the xor
in the xor is
the xor is a
xor is a random
is a random variable
a random variable y
random variable y and
variable y and has
y and has a
and has a binomial
has a binomial distribution
a binomial distribution with
binomial distribution with parameters
is the summation z
the summation z c
game progress bitcoin network
progress bitcoin network figure
we obtain the expression
obtain the expression for
the expression for r
we plot the recovery
plot the recovery probability
the recovery probability curves
recovery probability curves for
probability curves for layered
curves for layered interleaving
for layered interleaving and
layered interleaving and reed
solomon against uniformly random
against uniformly random loss
uniformly random loss rate
note that the curves
that the curves are
the curves are very
curves are very close
are very close to
very close to each
close to each other
especially in the loss
in the loss range
the loss range of
loss range of interest
range of interest between
divides its revenue among
its revenue among its
revenue among its registered
among its registered miners
the revenue includes both
revenue includes both its
includes both its direct
both its direct mining
its direct mining revenue
direct mining revenue and
implementation details we initially
mining revenue and b
details we initially implemented
we initially implemented and
initially implemented and evaluated
implemented and evaluated maelstrom
and evaluated maelstrom as
numerical analysis we analyze
evaluated maelstrom as a
analysis we analyze this
maelstrom as a user
we analyze this game
analyze this game numerically
this game numerically by
game numerically by finding
numerically by finding the
by finding the x
performance turned out to
turned out to be
out to be limited
to be limited by
be limited by copying
limited by copying and
by copying and context
and substituting this value
substituting this value for
this value for r
and we subsequently reimplemented
we subsequently reimplemented the
subsequently reimplemented the system
reimplemented the system as
the system as a
system as a module
as a module that
a module that runs
module that runs within
that runs within the
runs within the linux
we vary the sizes
vary the sizes of
the sizes of the
sizes of the pools
of the pools through
the pools through the
pools through the entire
through the entire feasible
the entire feasible range
entire feasible range and
feasible range and depict
range and depict the
and depict the optimal
depict the optimal x
at an encoding rate
and the corresponding revenues
an encoding rate of
the corresponding revenues in
corresponding revenues in figure
each point in each
point in each graph
in each graph represents
each graph represents the
graph represents the equilibrium
represents the equilibrium point
the equilibrium point of
equilibrium point of a
point of a game
of a game with
a game with the
game with the corresponding
with the corresponding m
the experimental prototype of
experimental prototype of the
prototype of the kernel
of the kernel version
the kernel version reaches
kernel version reaches output
version reaches output speeds
reaches output speeds close
output speeds close to
where we normalize m
gigabit per second of
per second of combined
second of combined data
of combined data and
combined data and fec
data and fec traffic
limited only by the
only by the capacity
the top right half
by the capacity of
top right half of
the capacity of the
right half of the
capacity of the outbound
half of the range
of the outbound network
of the range in
the outbound network card
the range in all
range in all graphs
in all graphs is
all graphs is not
graphs is not feasible
lambda networks are already
as the sum of
networks are already reaching
the sum of m
are already reaching speeds
already reaching speeds of
and higher speeds are
higher speeds are a
speeds are a certainty
we use this range
are a certainty down
use this range as
a certainty down the
this range as a
certainty down the road
range as a reference
as a reference color
and we use a
we use a dashed
use a dashed line
a dashed line to
dashed line to show
line to show the
we envision maelstrom as
to show the bound
envision maelstrom as a
show the bound between
maelstrom as a small
the bound between this
as a small rack
bound between this value
between this value within
this value within the
value within the feasible
within the feasible range
style cluster of blade
a shows the optimal
each acting as an
shows the optimal infiltration
acting as an individual
the optimal infiltration rate
as an individual proxy
in the entire feasible
traffic would be distributed
the entire feasible range
entire feasible range we
would be distributed over
feasible range we see
range we see that
be distributed over such
we see that pool
distributed over such a
over such a rack
such a rack by
chooses a strictly positive
a rack by partitioning
a strictly positive value
strictly positive value for
rack by partitioning the
positive value for x
by partitioning the address
partitioning the address space
the address space of
address space of the
space of the remote
of the remote datacenter
the remote datacenter and
remote datacenter and routing
datacenter and routing different
and routing different segments
routing different segments of
different segments of the
segments of the space
of the space through
the space through distinct
the revenue of pool
space through distinct maelstrom
through distinct maelstrom appliance
distinct maelstrom appliance pairs
is depicted in figure
b and in the
and in the entire
in the entire feasible
the entire feasible region
we plan to experiment
entire feasible region it
plan to experiment with
feasible region it is
to experiment with such
region it is strictly
experiment with such configurations
it is strictly larger
is strictly larger than
which would also permit
would also permit us
also permit us to
permit us to explore
us to explore faulttolerance
to explore faulttolerance issues
which the pool would
the pool would have
pool would have gotten
would have gotten without
have gotten without attacking
if a maelstrom blade
a maelstrom blade fails
and to support load
balancing schemes that might
schemes that might vary
that might vary the
might vary the ip
vary the ip address
the ip address space
ip address space partitioning
address space partitioning dynamically
space partitioning dynamically to
partitioning dynamically to spread
dynamically to spread the
to spread the encoding
spread the encoding load
c depicts the revenue
the encoding load over
depicts the revenue of
encoding load over multiple
the revenue of pool
load over multiple machines
which is strictly smaller
is strictly smaller than
we present the implementation
in the entire range
present the implementation and
the implementation and performance
implementation and performance of
and performance of a
performance of a single
note that the total
that the total system
the total system mining
total system mining power
the kernel implementation is
system mining power is
kernel implementation is a
mining power is reduced
implementation is a module
power is reduced when
is a module for
is reduced when pool
a module for linux
chooses to infiltrate pool
the revenue of third
revenue of third parties
miners not in either
with hooks into the
not in either pool
hooks into the kernel
into the kernel packet
the kernel packet filter
maelstrom proxies work in
proxies work in pairs
one on each side
on each side of
each side of the
side of the long
of the long haul
the long haul link
each proxy acts both
proxy acts both as
acts both as an
both as an ingress
as an ingress and
an ingress and egress
ingress and egress temporarily
in case all but
therefore pays for the
case all but one
pays for the increased
all but one of
for the increased revenue
but one of the
the increased revenue of
one of the missing
increased revenue of its
of the missing packets
revenue of its attacker
the missing packets are
of its attacker and
missing packets are router
its attacker and everyone
packets are router at
attacker and everyone else
are router at the
and everyone else in
router at the same
everyone else in the
at the same time
else in the system
the same time since
same time since they
time since they handle
since they handle duplex
they handle duplex traffic
handle duplex traffic in
duplex traffic in received
traffic in received later
implications to the general
in received later or
to the general case
received later or recovered
the general case consider
later or recovered through
general case consider the
or recovered through other
case consider the case
recovered through other xors
consider the case of
the case of p
case of p pools
allowing the following manner
for any choice of
any choice of the
choice of the pools
of the pools sizes
the pools sizes m
the recovery of the
recovery of the remaining
of the remaining missing
the remaining missing packet
remaining missing packet from
missing packet from this
packet from this xor
in practice we stored
practice we stored data
we stored data and
stored data and xor
data and xor packets
and xor packets in
xor packets in dou
packets in dou the
in dou the egress
dou the egress router
the egress router captures
egress router captures ip
router captures ip packets
captures ip packets and
ip packets and creates
at least one pool
packets and creates re
least one pool will
one pool will choose
pool will choose to
will choose to perform
choose to perform block
ble buffered red black
to perform block withholding
buffered red black trees
red black trees for
byte packets and dundant
packets and dundant fec
and dundant fec packets
the original ip packets
original ip packets are
entries this occupies around
routed through unaltered as
through unaltered as they
unaltered as they would
as they would have
they would have been
would have been at
have been at the
been at the send
the repair bins in
repair bins in the
bins in the layered
in the layered interoriginally
the redundant packets are
redundant packets are then
packets are then forwarded
are then forwarded leaving
then forwarded leaving scheme
forwarded leaving scheme store
leaving scheme store incrementally
scheme store incrementally computed
store incrementally computed xors
incrementally computed xors and
computed xors and to
xors and to the
and to the remote
to the remote ingress
the remote ingress router
remote ingress router via
ingress router via a
router via a udp
via a udp channel
lists of data packet
of data packet headers
without the data packet
the data packet payloads
resulting in low storage
in low storage overheads
low storage overheads for
storage overheads for each
overheads for each layer
for each layer the
each layer the ingress
layer the ingress router
the ingress router captures
ingress router captures and
router captures and stores
captures and stores ip
and stores ip packets
stores ip packets that
ip packets that rise
packets that rise linearly
that rise linearly with
rise linearly with the
linearly with the value
with the value of
the value of the
value of the interleave
the coming from the
coming from the direction
from the direction of
the direction of the
direction of the egress
of the egress router
upon memory footprint for
memory footprint for a
footprint for a long
running proxy was around
proxy was around receipt
was around receipt of
around receipt of a
receipt of a redundant
of a redundant packet
an ip packet is
ip packet is recov
mb in our experiments
ered if there is
if there is an
there is an opportunity
is an opportunity to
an opportunity to do
opportunity to do so
redundant packets that can
packets that can be
that can be used
can be used at
be used at a
used at a later
at a later time
a later time are
later time are stored
if the redundant packet
the redundant packet is
redundant packet is useless
packet is useless it
is useless it is
useless it is immediately
it is immediately dis
other performance enhancing roles
performance enhancing roles carded
upon recovery the ip
recovery the ip packet
the ip packet is
ip packet is sent
packet is sent through
is sent through maelstrom
sent through maelstrom appliances
through maelstrom appliances can
maelstrom appliances can optionally
appliances can optionally aggregate
can optionally aggregate small
optionally aggregate small suba
aggregate small suba raw
small suba raw socket
suba raw socket to
raw socket to its
socket to its intended
to its intended destination
kilobyte packets from different
packets from different flows
from different flows into
different flows into larger
flows into larger ones
into larger ones for
larger ones for using
ones for using fec
for using fec requires
using fec requires that
fec requires that each
requires that each data
that each data packet
each data packet have
data packet have a
packet have a unique
have a unique better
a unique better communication
unique better communication efficiency
better communication efficiency over
communication efficiency over the
efficiency over the long
distance identifier that the
identifier that the receiver
that the receiver can
the receiver can use
receiver can use to
can use to keep
use to keep track
to keep track of
keep track of re
in split flow control
split flow control mode
flow control mode they
control mode they can
mode they can ceived
they can ceived data
can ceived data packets
ceived data packets and
data packets and to
packets and to identify
and to identify missing
to identify missing data
identify missing data packets
missing data packets perform
data packets perform send
side buffering of in
flight data for multiin
data for multiin a
for multiin a repair
multiin a repair packet
if we had access
we had access to
had access to end
we gigabyte flows that
stable state where only
gigabyte flows that exceed
state where only pool
flows that exceed the
that exceed the sending
exceed the sending end
host s buffercould have
s buffercould have added
buffercould have added a
have added a header
added a header to
a header to each
header to each packet
to each packet with
each packet with a
packet with a unique
with a unique ing
a unique ing capacity
maelstrom appliances can act
appliances can act as
can act as mulsequence
act as mulsequence number
we intercept traffic trans
two pools where one
pools where one infiltrates
appliances send multicast packparently
where one infiltrates the
send multicast packparently and
one infiltrates the other
multicast packparently and need
packparently and need to
and need to route
need to route it
to route it without
optimal infiltration rate x
route it without modification
it without modification or
without modification or addi
ets to each other
to each other across
each other across the
other across the long
as a function of
a function of pool
function of pool sizes
we identify ip multicast
to spread them within
spread them within their
them within their datacenters
ip packets by a
packets by a tuple
by a tuple consisting
a tuple consisting of
tuple consisting of the
consisting of the source
of the source and
and the lines in
the source and des
appliances can take on
can take on other
take on other existing
on other existing roles
other existing roles in
existing roles in the
roles in the tination
show the revenue density
in the tination ip
the revenue density of
the tination ip address
size of the ip
of the ip datacenter
acting as security and
in a system with
as security and vpn
a system with p
security and vpn gateways
system with p pools
and vpn gateways and
vpn gateways and as
gateways and as header
and as header plus
as header plus data
and a checksum over
a checksum over the
checksum over the ip
over the ip data
the ip data pay
conventional performance enhancing proxies
is not an equilibrium
assume towards negation this
towards negation this is
negation this is not
this is not the
is not the case
the checksum over the
checksum over the payload
over the payload is
the payload is necessary
payload is necessary since
is necessary since the
necessary since the ip
is an equilibrium point
since the ip identification
the ip identification field
ip identification field is
identification field is only
now consider a setting
consider a setting with
a setting with only
setting with only pools
bits long and a
long and a single
and a single pair
a single pair of
single pair of end
and treat the other
hosts communicating at high
treat the other pools
communicating at high speeds
the other pools as
at high speeds will
other pools as independent
pools as independent miners
evaluation use the same
this is the setting
use the same identifier
is the setting analyzed
the setting analyzed above
the same identifier for
setting analyzed above and
same identifier for different
analyzed above and we
above and we have
identifier for different data
and we have seen
we have seen there
for different data packets
have seen there that
seen there that pool
different data packets within
data packets within a
packets within a fairly
within a fairly short
can increase its revenue
a fairly short interval
increase its revenue by
fairly short interval unless
its revenue by performing
short interval unless the
revenue by performing a
interval unless the checksum
by performing a block
unless the checksum is
performing a block withholding
the checksum is added
a block withholding attack
checksum is added to
block withholding attack on
is added to we
withholding attack on pool
added to we evaluated
to we evaluated maelstrom
we evaluated maelstrom on
evaluated maelstrom on the
maelstrom on the emulab
on the emulab testbed
the emulab testbed at
emulab testbed at utah
testbed at utah differentiate
at utah differentiate between
utah differentiate between them
s infiltration rate by
infiltration rate by x
take this values back
this values back to
values back to the
for all the experiments
back to the setting
to the setting at
the setting at hand
setting at hand with
at hand with p
hand with p pools
we used a dumbbell
used a dumbbell topoltifiers
a dumbbell topoltifiers result
dumbbell topoltifiers result in
topoltifiers result in garbled
the revenue of pool
result in garbled recovery
in garbled recovery by
garbled recovery by maelstrom
is better when x
an event ogy of
event ogy of two
ogy of two clusters
of two clusters of
two clusters of nodes
clusters of nodes connected
of nodes connected via
nodes connected via routing
connected via routing nodes
via routing nodes which
routing nodes which will
nodes which will be
which will be caught
will be caught by
be caught by higher
caught by higher level
by higher level checksums
higher level checksums designed
level checksums designed with
checksums designed with a
designed with a high
latency link in between
link in between them
designed to emto deal
to emto deal with
emto deal with tranmission
deal with tranmission errors
with tranmission errors on
tranmission errors on commodity
errors on commodity networks
on commodity networks ulate
commodity networks ulate the
networks ulate the setup
ulate the setup in
the setup in figure
and ran the proxy
ran the proxy code
the proxy code on
proxy code on and
code on and hence
on and hence does
and hence does not
hence does not have
does not have significant
not have significant consequences
have significant consequences unless
significant consequences unless the
consequences unless the routers
shows the performance of
name size discusfish antpool
the performance of the
size discusfish antpool ghash
performance of the kernel
of the kernel version
the kernel version at
kernel version at gigabit
version at gigabit speeds
io btchine btcguild eligius
btchine btcguild eligius others
the remainder of the
remainder of the graphs
of the graphs it
the graphs it occurs
graphs it occurs frequently
the kernel version of
kernel version of maelstrom
version of maelstrom can
of maelstrom can generate
maelstrom can generate up
can generate up to
generate up to a
up to a show
to a show the
a show the performance
show the performance of
the performance of the
performance of the user
space version at slower
version at slower gigabit
at slower gigabit per
slower gigabit per second
gigabit per second of
per second of data
second of data and
of data and fec
data and fec traffic
to emulate the mtu
emulate the mtu difference
the mtu difference between
mtu difference between the
difference between the longput
between the longput data
the longput data rate
longput data rate depending
data rate depending on
rate depending on the
depending on the encoding
on the encoding rate
haul link and the
link and the datacenter
and the datacenter network
we were able to
were able to saturate
able to saturate the
to saturate the outgoing
saturate the outgoing card
the outgoing card at
outgoing card at set
card at set an
at set an mtu
set an mtu of
bytes on the network
on the network connecting
the network connecting the
network connecting the rates
connecting the rates as
the rates as high
rates as high as
with cpu overload occurring
cpu overload occurring at
overload occurring at end
hosts to the proxy
to the proxy and
the proxy and an
proxy and an mtu
and an mtu of
where each incoming data
each incoming data packet
incoming data packet had
data packet had to
packet had to be
had to be xored
to be xored long
haul link between proxies
the only exception is
only exception is figure
where we maintained equal
we maintained equal mtus
maintained equal mtus of
throughput metrics at the
metrics at the receive
the six largest open
six largest open pool
largest open pool sizes
open pool sizes as
pool sizes as of
sizes as of january
incoming data packets are
data packets are buffered
packets are buffered so
are buffered so that
buffered so that they
so that they can
that they can be
they can be used
can be used in
be used in conjunction
used in conjunction with
in conjunction with figures
show that commodity tcp
ip throughxors to recover
throughxors to recover missing
to recover missing data
recover missing data packets
any received put collapses
received put collapses in
put collapses in the
collapses in the presence
their optimal infiltration rates
in the presence of
the presence of non
of each pool as
each pool as a
pool as a fraction
as a fraction of
a fraction of its
fraction of its size
and xor that is
xor that is missing
that is missing more
is missing more than
if it attacked all
missing more than one
it attacked all others
more than one data
attacked all others without
than one data packet
all others without reciprocation
one data packet is
data packet is stored
packet is stored that
is stored that maelstrom
stored that maelstrom successfully
that maelstrom successfully masks
maelstrom successfully masks loss
successfully masks loss and
and their revenue density
masks loss and prevents
their revenue density when
loss and prevents this
revenue density when attacking
can improve its revenue
improve its revenue by
its revenue by attacking
revenue by attacking pool
attacks is not an
is not an equilibrium
not an equilibrium point
case as a test
as a test case
we take the pool
take the pool distribution
the pool distribution in
pool distribution in january
we analyze the cases
analyze the cases where
the cases where each
cases where each of
where each of the
each of the pools
of the pools attacks
the pools attacks all
pools attacks all other
attacks all other open
all other open pools
all of which behave
of which behave honestly
ip no loss maelstrom
no loss maelstrom no
loss maelstrom no loss
maelstrom no loss maelstrom
note that attacking all
that attacking all pools
attacking all pools with
all pools with force
pools with force proportional
with force proportional to
force proportional to their
proportional to their size
to their size yields
their size yields the
size yields the same
yields the same results
the same results as
same results as attacking
results as attacking a
as attacking a single
attacking a single pool
a single pool of
single pool of their
pool of their aggregate
of their aggregate size
plugging in the numbers
in the numbers into
the numbers into the
numbers into the analysis
into the analysis above
the analysis above shows
analysis above shows that
above shows that a
shows that a larger
that a larger pool
a larger pool needs
larger pool needs to
pool needs to use
needs to use a
to use a smaller
use a smaller ratio
a smaller ratio of
smaller ratio of its
ratio of its mining
of its mining power
its mining power for
mining power for infiltration
power for infiltration and
for infiltration and can
infiltration and can increase
and can increase its
can increase its revenue
increase its revenue density
its revenue density more
revenue density more than
density more than a
more than a small
than a small pool
achieves its optimum attack
its optimum attack rate
optimum attack rate at
of the pool s
the pool s mining
pool s mining power
increasing its revenue by
its revenue by almost
this amounts to a
amounts to a daily
to a daily revenue
a daily revenue increase
daily revenue increase of
revenue increase of b
usd at the exchange
at the exchange rate
the exchange rate on
exchange rate on that
rate on that date
this represents a considerable
represents a considerable increase
a considerable increase of
considerable increase of the
increase of the pools
of the pools net
the pools net revenue
for the smallest pool
the attack is much
attack is much less
is much less profitable
to reach the optimum
reach the optimum it
the optimum it needs
optimum it needs almost
it needs almost a
needs almost a third
almost a third of
a third of its
third of its power
of its power for
its power for attacking
power for attacking but
for attacking but increases
attacking but increases its
but increases its revenue
increases its revenue density
its revenue density by
revenue density by merely
two attacking pools system
as a function of
a function of pool
function of pool sizes
tcp no loss maelstrom
no loss maelstrom no
loss maelstrom no loss
maelstrom no loss maelstrom
t wo p ools
wo p ools we
p ools we proceed
ools we proceed to
we proceed to analyze
proceed to analyze the
to analyze the case
analyze the case where
the case where two
case where two pools
where two pools may
two pools may attack
pools may attack each
may attack each other
attack each other and
each other and the
other and the other
and the other miners
the other miners mine
other miners mine solo
again we have pool
controls its infiltration rate
its infiltration rate x
also controls its infiltration
controls its infiltration rate
its infiltration rate x
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
the total mining power
total mining power in
mining power in the
power in the system
in the system is
the system is m
system is m x
one way link latency
the direct revenues r
of the pools from
the pools from mining
pools from mining are
from mining are their
mining are their effective
are their effective mining
their effective mining rates
without infiltrating mining power
divided by the total
by the total mining
the total mining rate
way latency collapse from
latency collapse from occurring
shows the performance of
the performance of the
performance of the user
space version on a
mbps link and figure
shows the kernel version
the kernel version on
kernel version on a
the experiment in each
experiment in each case
in each case involves
each case involves running
case involves running iperf
flows from one node
from one node to
one node to another
node to another across
to another across the
another across the long
distance link with and
link with and without
with and without intermediary
and without intermediary maelstrom
without intermediary maelstrom proxies
intermediary maelstrom proxies and
maelstrom proxies and measuring
proxies and measuring obtained
and measuring obtained throughput
measuring obtained throughput while
obtained throughput while varying
throughput while varying loss
while varying loss rate
left graph on each
graph on each figure
the total revenue of
total revenue of each
revenue of each pool
of each pool is
each pool is its
pool is its direct
is its direct mining
its direct mining revenue
the error bars on
error bars on the
bars on the graphs
on the graphs to
the graphs to the
graphs to the left
to the left are
the left are standard
left are standard errors
are standard errors of
standard errors of the
errors of the throughput
of the throughput over
the throughput over ten
throughput over ten runs
ip s cache of
s cache of tuning
cache of tuning parameters
of tuning parameters to
tuning parameters to allow
parameters to allow for
to allow for repeatable
allow for repeatable results
two pools infiltrating each
pools infiltrating each other
the clients in the
clients in the experiment
in the experiment are
the experiment are running
experiment are running tcp
and the infiltration revenue
the infiltration revenue from
ip reno on a
infiltration revenue from the
reno on a linux
revenue from the previous
from the previous round
which is the attacked
is the attacked pool
the attacked pool s
attacked pool s total
pool s total revenue
s total revenue multiplied
total revenue multiplied by
revenue multiplied by its
multiplied by its infiltration
by its infiltration rate
the pool s total
pool s total revenue
s total revenue is
total revenue is divided
revenue is divided among
the maelstrom parameters used
is divided among its
maelstrom parameters used are
divided among its loyal
parameters used are r
among its loyal miners
its loyal miners and
loyal miners and miners
miners and miners that
and miners that infiltrated
miners that infiltrated it
at stable state this
stable state this is
state this is r
space version involved running
version involved running a
involved running a single
second iperf flow from
iperf flow from one
flow from one node
from one node to
one node to another
node to another with
to another with and
another with and without
with and without maelstrom
and without maelstrom running
without maelstrom running on
maelstrom running on the
running on the routers
on the routers and
the routers and measuring
routers and measuring throughput
and measuring throughput while
measuring throughput while varying
throughput while varying the
while varying the random
varying the random loss
the random loss rate
random loss rate on
loss rate on the
rate on the link
on the link and
the link and the
link and the one
to test the kernel
test the kernel version
the kernel version at
kernel version at gigabit
version at gigabit speeds
we ran eight parallel
ran eight parallel iperf
eight parallel iperf flows
parallel iperf flows from
we obtain the following
iperf flows from one
obtain the following closed
flows from one node
the following closed expressions
from one node to
following closed expressions for
one node to another
closed expressions for each
node to another for
we express the revenues
express the revenues as
the revenues as functions
revenues as functions of
as functions of x
the curves obtained from
curves obtained from the
obtained from the two
from the two versions
the two versions are
two versions are almost
versions are almost identical
we present both to
present both to show
both to show that
to show that the
show that the kernel
that the kernel version
the kernel version successfully
kernel version successfully scales
version successfully scales up
successfully scales up the
scales up the performance
up the performance of
the performance of the
performance of the user
space version to hundreds
version to hundreds of
to hundreds of megabits
hundreds of megabits of
of megabits of traffic
megabits of traffic per
of traffic per second
we show how tcp
ip performance degrades on
performance degrades on a
ms link as the
link as the loss
as the loss rate
the loss rate is
loss rate is increased
rate is increased from
maelstrom masks loss up
masks loss up to
without significant throughput degradation
with the kernel version
the kernel version achieving
kernel version achieving two
version achieving two orders
achieving two orders of
two orders of magnitude
orders of magnitude higher
of magnitude higher throughput
magnitude higher throughput that
higher throughput that conventional
throughput that conventional tcp
the graphs on the
graphs on the right
on the right side
the right side of
right side of figures
ip throughput declining on
throughput declining on a
declining on a link
on a link of
a link of increasing
link of increasing length
of increasing length when
increasing length when subjected
length when subjected to
when subjected to uniform
subjected to uniform loss
to uniform loss rates
uniform loss rates of
the top line in
top line in the
line in the graphs
in the graphs is
the graphs is the
graphs is the performance
is the performance of
the performance of tcp
ip without loss and
without loss and provides
loss and provides an
and provides an upper
provides an upper bound
an upper bound for
upper bound for performance
bound for performance on
each pool controls only
for performance on the
pool controls only its
performance on the link
controls only its own
only its own infiltration
its own infiltration rate
in each round of
each round of the
space and kernel versions
round of the pool
of the pool game
maelstrom masks packet loss
masks packet loss and
each pool will optimize
packet loss and tracks
pool will optimize its
loss and tracks the
will optimize its infiltration
and tracks the lossless
optimize its infiltration rate
tracks the lossless line
its infiltration rate of
the lossless line closely
infiltration rate of the
rate of the other
lagging only when the
only when the link
when the link latency
the link latency is
link latency is low
latency is low and
acts at step t
is low and tcp
it optimizes its revenue
ip s throughput is
optimizes its revenue with
s throughput is very
its revenue with r
throughput is very high
ip to attain very
to attain very high
attain very high speeds
very high speeds on
high speeds on the
speeds on the gi
acts at step t
it optimizes its revenue
optimizes its revenue with
its revenue with x
an equilibrium exists where
equilibrium exists where neither
exists where neither pool
can improve its revenue
improve its revenue by
its revenue by changing
revenue by changing its
by changing its infiltration
changing its infiltration rate
any pair of values
pair of values x
such that arg maxx
way delivery latency against
delivery latency against loss
latency against loss rate
the feasible region for
feasible region for the
region for the pool
for the pool sizes
the pool sizes is
pool sizes is m
the revenue function for
revenue function for ri
function for ri is
for ri is concave
ri is concave in
is concave in xi
concave in xi for
in xi for all
xi for all feasible
for all feasible values
all feasible values of
feasible values of the
values of the variables
therefore the solutions for
the solutions for equations
are unique and are
unique and are either
and are either at
are either at the
either at the borders
at the borders of
the borders of the
borders of the feasible
of the feasible region
the feasible region or
feasible region or where
region or where ri
from section v we
section v we know
v we know that
we know that no
attack is not an
is not an equilibrium
not an equilibrium point
since each pool can
each pool can increase
pool can increase its
can increase its revenue
increase its revenue by
its revenue by choosing
revenue by choosing a
by choosing a strictly
choosing a strictly positive
a strictly positive infiltration
strictly positive infiltration rate
is not a solution
not a solution to
a solution to equations
nash equilibrium therefore exists
equilibrium therefore exists with
therefore exists with x
packet delivery latencies gabit
delivery latencies gabit link
we had to set
had to set the
to set the mtu
set the mtu of
the mtu of the
mtu of the entire
of the entire path
the entire path to
entire path to be
path to be the
to be the maximum
which meant that the
meant that the longhaul
that the longhaul link
the longhaul link had
longhaul link had the
link had the same
had the same mtu
the same mtu as
same mtu as the
mtu as the inter
this resulted in the
resulted in the fragmentation
in the fragmentation of
the fragmentation of repair
using symbolic computation tools
fragmentation of repair packets
of repair packets sent
repair packets sent over
packets sent over udp
sent over udp on
over udp on the
we see that there
udp on the long
see that there is
that there is a
there is a single
is a single pair
a single pair of
haul link into two
single pair of values
link into two ip
pair of values for
into two ip packet
of values for which
two ip packet fragments
values for which equation
since the loss of
the loss of a
loss of a single
of a single fragment
holds for any feasible
a single fragment resulted
for any feasible choice
single fragment resulted in
any feasible choice of
fragment resulted in the
feasible choice of m
resulted in the loss
in the loss of
the loss of the
loss of the repair
we observed a higher
observed a higher loss
a higher loss rate
higher loss rate for
loss rate for repairs
rate for repairs than
for repairs than for
repairs than for data
than for data packets
numerical analysis a numerical
analysis a numerical analysis
a numerical analysis confirms
numerical analysis confirms these
analysis confirms these observations
we expect performance to
we simulate the pool
expect performance to be
simulate the pool game
performance to be better
the pool game for
to be better on
pool game for a
be better on a
game for a range
better on a network
for a range of
on a network where
a range of pool
a network where the
range of pool sizes
network where the mtu
where the mtu of
the mtu of the
mtu of the long
for each choice of
each choice of pool
choice of pool sizes
haul link is truly
link is truly larger
is truly larger than
truly larger than the
we start the simulation
larger than the mtu
start the simulation when
than the mtu within
the simulation when both
the mtu within each
simulation when both pools
mtu within each cluster
when both pools do
both pools do not
pools do not infiltrate
do not infiltrate each
not infiltrate each other
latency metrics to measure
metrics to measure the
to measure the latency
measure the latency effects
the latency effects of
latency effects of tcp
mbps stream between two
stream between two nodes
between two nodes over
two nodes over a
and the revenue densities
the revenue densities are
revenue densities are r
and simultaneously ran a
at each round one
each round one pool
round one pool chooses
one pool chooses its
pool chooses its optimal
chooses its optimal infiltration
mbps flow alongside on
its optimal infiltration rate
flow alongside on the
optimal infiltration rate based
alongside on the same
infiltration rate based on
on the same link
rate based on the
the same link to
based on the pool
same link to simulate
on the pool sizes
link to simulate a
the pool sizes and
to simulate a real
pool sizes and the
sizes and the rate
and the rate with
the rate with which
rate with which it
time stream combined with
with which it is
stream combined with other
which it is infiltrated
combined with other intercluster
with other intercluster traffic
and we calculate the
we calculate the revenue
calculate the revenue after
the revenue after convergence
revenue after convergence with
after convergence with equation
shows the average delivery
the average delivery latency
average delivery latency of
recall the players in
the players in the
players in the pool
in the pool game
the pool game are
pool game are chosen
game are chosen with
are chosen with the
chosen with the round
level packets in the
with the round robin
the round robin policy
so the pools take
the pools take turns
and we let the
we let the game
let the game run
the game run until
as loss rates go
game run until convergence
loss rates go up
the results are illustrated
results are illustrated in
are illustrated in figure
each run with some
run with some m
shows the same scenario
the same scenario with
same scenario with a
scenario with a constant
with a constant uniformly
a constant uniformly random
constant uniformly random loss
uniformly random loss rate
random loss rate of
values results in a
results in a single
in a single point
a single point in
single point in each
point in each graph
in each graph in
each graph in figure
and varying oneway latency
we depict the infiltration
depict the infiltration rates
the infiltration rates of
infiltration rates of both
rates of both pools
maelstrom s delivery latency
of both pools x
s delivery latency is
delivery latency is almost
latency is almost exactly
is almost exactly equal
almost exactly equal to
exactly equal to the
equal to the one
way latency on the
latency on the link
ip takes more than
takes more than twice
more than twice as
than twice as long
twice as long once
as long once one
way latencies go past
b and the pools
and the pools revenue
the pools revenue densities
pools revenue densities r
plots delivery latency against
delivery latency against message
latency against message identifier
the spikes in latency
spikes in latency are
in latency are triggered
for each choice of
latency are triggered by
each choice of m
are triggered by losses
triggered by losses that
by losses that lead
losses that lead to
that lead to packets
lead to packets piling
to packets piling up
packets piling up at
piling up at the
up at the receiver
the values of x
a key point is
key point is that
point is that we
is that we are
that we are plotting
we are plotting the
are plotting the delivery
plotting the delivery latency
the delivery latency of
delivery latency of all
latency of all packets
not just lost ones
ip delays correctly received
delays correctly received packets
correctly received packets while
received packets while waiting
packets while waiting for
while waiting for missing
waiting for missing packets
for missing packets sequenced
are the points in
missing packets sequenced earlier
the points in each
packets sequenced earlier by
points in each of
sequenced earlier by the
in each of the
earlier by the sender
each of the graphs
by the sender the
of the graphs with
the sender the effect
the graphs with the
sender the effect of
graphs with the respective
the effect of this
with the respective coordinates
effect of this is
of this is shown
this is shown in
is shown in figure
j graphs we draw
graphs we draw a
we draw a border
draw a border around
a border around the
border around the region
around the region where
the region where there
where single packet losses
region where there is
single packet losses cause
where there is no
packet losses cause spikes
losses cause spikes in
cause spikes in delivery
spikes in delivery latency
in delivery latency that
delivery latency that last
attack by i in
latency that last for
by i in equilibrium
that last for hundreds
last for hundreds of
for hundreds of packets
for the ri graphs
the ri graphs we
the low data rate
ri graphs we draw
low data rate in
graphs we draw a
data rate in the
we draw a line
rate in the flow
draw a line around
in the flow of
a line around the
the flow of roughly
line around the region
around the region where
the region where the
region where the revenue
where the revenue is
the revenue is the
revenue is the same
is the same as
the same as in
same as in the
as in the no
kb packets per rtt
packets per rtt makes
per rtt makes tcp
ip flow control delays
flow control delays at
control delays at the
delays at the sender
at the sender unlikely
we first observe that
given that the congestion
first observe that only
that the congestion control
observe that only in
the congestion control algorithm
that only in extreme
congestion control algorithm is
only in extreme cases
control algorithm is reno
in extreme cases a
extreme cases a pool
cases a pool does
a pool does not
pool does not attack
which implements fast recovery
does not attack its
implements fast recovery and
not attack its counterpart
fast recovery and halves
recovery and halves the
and halves the congestion
halves the congestion window
the congestion window on
congestion window on packet
window on packet loss
on packet loss rather
packet loss rather than
at equilibrium a pool
loss rather than resetting
equilibrium a pool will
rather than resetting it
a pool will refrain
than resetting it completely
pool will refrain from
will refrain from attacking
refrain from attacking only
from attacking only if
attacking only if the
only if the other
if the other pool
the other pool is
other pool is larger
pool is larger than
is larger than about
the maelstrom configuration used
maelstrom configuration used is
of the total mining
the total mining power
we observe that a
observe that a pool
that a pool improves
a pool improves its
pool improves its revenue
improves its revenue compared
its revenue compared to
revenue compared to the
compared to the no
attacks scenario only when
scenario only when it
only when it controls
when it controls a
it controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the total
of the total mining
the total mining power
these are the small
are the small triangular
the small triangular regions
small triangular regions in
triangular regions in figures
in the rest of
the rest of the
rest of the space
the trapezoids in the
trapezoids in the figures
the revenue of the
revenue of the pool
of the pool is
the pool is inferior
pool is inferior compared
is inferior compared to
inferior compared to the
compared to the no
the prisoner s dilemma
prisoner s dilemma in
s dilemma in a
dilemma in a healthy
in a healthy bitcoin
a healthy bitcoin environment
where neither pool controls
neither pool controls a
pool controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the mining
of the mining power
both pools will earn
pools will earn less
will earn less at
earn less at equilibrium
less at equilibrium than
at equilibrium than if
equilibrium than if both
than if both pools
if both pools ran
both pools ran without
pools ran without attacking
we can analyze in
can analyze in this
analyze in this case
in this case a
this case a game
case a game where
a game where each
game where each pool
where each pool chooses
each pool chooses either
pool chooses either to
chooses either to attack
either to attack and
to attack and optimize
attack and optimize its
and optimize its revenue
or to refrain from
to refrain from attacking
without loss of generality
as we have seen
we have seen in
have seen in section
seen in section v
can increase its revenue
increase its revenue above
does attack but pool
we denote the revenue
denote the revenue of
the revenue of pool
the exact value of
exact value of r
depends on the values
on the values of
the values of m
but it is always
it is always smaller
is always smaller than
always smaller than one
as we have seen
we have seen above
relatively prime interleaves offer
prime interleaves offer better
interleaves offer better performance
offer better performance r
does choose to attack
but does not surpass
does not surpass one
the game is summarized
game is summarized in
is summarized in figure
this is the classical
is the classical prisoner
the classical prisoner s
classical prisoner s dilemma
attack is the dominant
is the dominant strategy
chooses to attack or
to attack or not
the revenue of pool
is larger when attacking
larger when attacking than
when attacking than when
attacking than when refraining
layered interleaving and bursty
than when refraining from
interleaving and bursty loss
when refraining from attack
and bursty loss thus
bursty loss thus far
loss thus far we
thus far we have
and the same for
far we have shown
the same for xxx
we have shown how
same for xxx xxx
have shown how maelstrom
for xxx xxx pool
shown how maelstrom effectively
how maelstrom effectively hides
maelstrom effectively hides loss
effectively hides loss from
hides loss from tcp
no attack xxx pool
ip for packets dropped
for packets dropped with
packets dropped with uniform
dropped with uniform randomness
we examine the performance
examine the performance of
the performance of the
performance of the layered
of the layered interleaving
the layered interleaving algorithm
showing how different parameterizations
how different parameterizations handle
different parameterizations handle bursty
parameterizations handle bursty loss
handle bursty loss patterns
we use a loss
use a loss model
a loss model where
loss model where packets
model where packets are
where packets are dropped
packets are dropped in
are dropped in bursts
dropped in bursts of
in bursts of fixed
bursts of fixed length
allowing us to study
us to study the
to study the impact
study the impact of
the impact of burst
impact of burst length
of burst length on
burst length on performance
the link has a
link has a one
ms and a loss
and a loss rate
a loss rate of
where it is varied
mbps flow of udp
flow of udp packets
of udp packets is
udp packets is sent
packets is sent over
is sent over it
we show that our
show that our observation
that our observation in
our observation in section
is correct for high
correct for high loss
for high loss rates
high loss rates if
loss rates if the
rates if the interleaves
if the interleaves are
the interleaves are relatively
interleaves are relatively prime
performance improves substantially when
improves substantially when loss
prisoner s dilemma for
substantially when loss rates
s dilemma for two
when loss rates are
dilemma for two pools
loss rates are high
rates are high and
are high and losses
high and losses are
and losses are bursty
the revenue density of
revenue density of each
density of each pool
of each pool is
the graph plots the
each pool is determined
graph plots the percentage
pool is determined by
plots the percentage of
is determined by the
the percentage of lost
determined by the decision
percentage of lost packets
by the decision of
of lost packets successfully
the decision of both
lost packets successfully recovered
decision of both pools
packets successfully recovered on
of both pools whether
successfully recovered on the
both pools whether to
recovered on the y
pools whether to attack
whether to attack or
to attack or not
axis against an x
the dominant strategy of
dominant strategy of each
strategy of each player
axis of loss rates
of each player is
of loss rates on
each player is to
loss rates on a
player is to attack
rates on a log
on a log scale
however the payoff of
the payoff of both
the maelstrom configuration used
payoff of both would
maelstrom configuration used is
of both would be
configuration used is r
both would be larger
would be larger if
be larger if they
larger if they both
if they both refrain
they both refrain from
both refrain from attacking
at equilibrium of this
equilibrium of this attack
when both pools attack
the revenue of each
revenue of each pool
of each pool is
each pool is smaller
pool is smaller than
is smaller than its
smaller than its revenue
than its revenue if
its revenue if neither
revenue if neither pool
if neither pool attacked
the game is not
game is not played
is not played once
where each pool can
each pool can change
pool can change its
can change its strategy
change its strategy between
its strategy between attack
strategy between attack and
between attack and no
the pools can agree
to refrain from attacking
we show the ability
show the ability of
the ability of layered
ability of layered interleaving
and in each round
of layered interleaving to
in each round a
layered interleaving to provide
each round a pool
interleaving to provide gracefully
round a pool can
to provide gracefully degrading
a pool can detect
provide gracefully degrading performance
pool can detect whether
gracefully degrading performance in
can detect whether it
degrading performance in the
detect whether it is
performance in the face
whether it is being
in the face of
it is being attacked
the face of bursty
is being attacked and
face of bursty loss
being attacked and deduce
attacked and deduce that
and deduce that the
deduce that the other
that the other pool
the other pool is
other pool is violating
pool is violating the
is violating the agreement
we plot the percentage
plot the percentage of
the percentage of lost
percentage of lost packets
of lost packets successfully
lost packets successfully recovered
cooperation where neither pool
packets successfully recovered against
where neither pool attacks
successfully recovered against the
neither pool attacks is
recovered against the length
pool attacks is a
against the length of
attacks is a possible
the length of loss
is a possible stable
length of loss bursts
a possible stable state
of loss bursts for
loss bursts for two
bursts for two different
for two different sets
two different sets of
different sets of interleaves
and in the bottom
in the bottom graph
the bottom graph we
bottom graph we plot
graph we plot the
we plot the average
plot the average latency
the average latency at
average latency at which
latency at which the
at which the packets
which the packets were
the packets were recovered
recovery latency is defined
latency is defined as
is defined as the
despite the fact that
defined as the difference
the fact that the
as the difference between
fact that the single
the difference between the
that the single nash
difference between the eventual
the single nash equilibrium
between the eventual delivery
single nash equilibrium in
the eventual delivery time
nash equilibrium in every
eventual delivery time of
equilibrium in every round
delivery time of the
in every round is
time of the recovered
every round is to
of the recovered packet
round is to attack
the recovered packet and
recovered packet and the
packet and the one
way latency of the
latency of the link
case as an example
we confirmed that the
as an example we
confirmed that the emulab
an example we take
that the emulab link
example we take again
the emulab link had
we take again the
emulab link had almost
take again the pool
link had almost no
again the pool sizes
had almost no jitter
the pool sizes shown
almost no jitter on
pool sizes shown in
no jitter on correctly
sizes shown in figure
jitter on correctly delivered
on correctly delivered packets
and study the case
study the case where
way latency an accurate
the case where the
latency an accurate estimate
case where the two
an accurate estimate of
where the two largest
accurate estimate of expected
the two largest pools
estimate of expected lossless
of expected lossless delivery
expected lossless delivery time
the optimal infiltration rates
increasing the interleaves results
the interleaves results in
out of the total
interleaves results in much
of the total system
results in much higher
the total system mining
in much higher recovery
total system mining power
much higher recovery percentages
higher recovery percentages at
recovery percentages at large
percentages at large burst
at large burst sizes
but percentage of packets
percentage of packets recovered
and the pools would
the pools would lose
percentage of packets recovered
compared to the no
q i dentical p
i dentical p ools
dentical p ools let
p ools let there
ools let there be
let there be q
there be q pools
be q pools of
q pools of identical
pools of identical size
of identical size that
identical size that engage
size that engage in
that engage in block
engage in block withholding
in block withholding against
block withholding against one
withholding against one another
other miners neither attack
miners neither attack nor
neither attack nor are
attack nor are being
nor are being attacked
in this case there
this case there exists
case there exists a
there exists a symmetric
exists a symmetric equilibrium
without loss of generality
a step of pool
it controls its attack
controls its attack rates
its attack rates each
attack rates each of
rates each of the
each of the other
of the other pools
and due to symmetry
due to symmetry they
to symmetry they are
symmetry they are all
they are all the
are all the same
the attack rate of
attack rate of pool
against any other pool
each of the other
of the other pools
the other pools can
other pools can attack
pools can attack its
can attack its peers
attack its peers as
its peers as well
all attack rates by
attack rates by all
rates by all attackers
by all attackers are
all attackers are identical
the attack rate of
attack rate of any
rate of any pool
of any pool other
any pool other than
against any other pool
the direct revenue of
direct revenue of each
revenue of each of
of each of the
each of the other
of the other pools
similarly denote by r
the revenue densities of
revenue densities of pool
are instantiated to mi
layered interleaving recovery percentage
interleaving recovery percentage and
recovery percentage and latency
percentage and latency comes
and latency comes at
latency comes at the
comes at the cost
at the cost of
the cost of higher
cost of higher recovery
of higher recovery latency
set of interleaves catches
of interleaves catches almost
interleaves catches almost all
catches almost all packets
almost all packets in
all packets in an
packets in an extended
in an extended burst
an extended burst of
packets at an average
at an average latency
an average latency of
average latency of around
while repairing all random
repairing all random singleton
all random singleton losses
random singleton losses within
the graphs also show
graphs also show recovery
also show recovery latency
show recovery latency rising
recovery latency rising gracefully
latency rising gracefully with
rising gracefully with the
gracefully with the increase
with the increase in
the increase in loss
increase in loss burst
in loss burst length
the longer the burst
the longer it takes
longer it takes to
it takes to recover
takes to recover the
to recover the lost
recover the lost packets
the maelstrom configuration used
maelstrom configuration used is
configuration used is r
we show histograms of
show histograms of recovery
histograms of recovery latencies
and solving we obtain
of recovery latencies for
solving we obtain a
recovery latencies for the
we obtain a single
latencies for the two
obtain a single expression
for the two interleave
a single expression for
the two interleave configurations
single expression for any
two interleave configurations under
expression for any ri
interleave configurations under different
configurations under different burst
under different burst lengths
since in the symmetric
in the symmetric case
the symmetric case we
the histograms confirm the
symmetric case we have
histograms confirm the trends
case we have r
confirm the trends described
the trends described above
packet recoveries take longer
recoveries take longer from
take longer from left
longer from left to
from left to right
left to right as
to right as we
right as we increase
as we increase loss
we increase loss burst
the expression is shown
increase loss burst length
expression is shown in
is shown in equation
and from top to
from top to bottom
top to bottom as
to bottom as we
bottom as we increase
as we increase the
we increase the interleave
increase the interleave values
illustrates the difference between
the difference between a
difference between a traditional
given any value of
between a traditional fec
any value of q
a traditional fec code
value of q and
traditional fec code and
of q and mi
fec code and layered
code and layered interleaving
and layered interleaving by
layered interleaving by plotting
interleaving by plotting a
element moving average of
moving average of recovery
the feasible range of
average of recovery latencies
feasible range of the
of recovery latencies for
range of the infiltration
recovery latencies for both
of the infiltration rates
latencies for both codes
the infiltration rates is
the channel is configured
channel is configured to
is configured to lose
configured to lose singleton
to lose singleton packets
lose singleton packets randomly
singleton packets randomly at
packets randomly at a
randomly at a loss
at a loss rate
a loss rate of
within this range ri
this range ri is
range ri is continuous
and concave in x
and additionally lose long
additionally lose long bursts
lose long bursts of
packets at occasional intervals
the optimal point for
both codes recovery latency
optimal point for pool
reed solomon layered interleaving
since the function is
the function is concave
function is concave the
is concave the equation
concave the equation yields
the equation yields a
equation yields a single
yields a single feasible
a single feasible solution
which is a function
is a function of
a function of the
function of the attack
of the attack rates
the attack rates of
attack rates of the
rates of the other
of the other pools
to find a symmetric
find a symmetric equilibrium
and obtain a single
obtain a single feasible
a single feasible solution
solomon versus layered interleaving
versus layered interleaving are
the equilibrium infiltration rate
layered interleaving are configured
equilibrium infiltration rate and
interleaving are configured with
infiltration rate and the
are configured with r
rate and the matching
and the matching revenues
the matching revenues are
matching revenues are shown
revenues are shown in
are shown in equation
and recover all lost
recover all lost packets
all lost packets reed
solomon uses an interleave
uses an interleave of
as in the two
and layered interleaving uses
layered interleaving uses interleaves
interleaving uses interleaves of
the revenue at the
revenue at the symmetric
at the symmetric equilibrium
the symmetric equilibrium is
symmetric equilibrium is inferior
equilibrium is inferior to
is inferior to the
inferior to the no
and consequently both have
consequently both have a
both have a maximum
have a maximum tolerable
a maximum tolerable burst
maximum tolerable burst length
tolerable burst length of
up our analysis addresses
our analysis addresses the
analysis addresses the eventual
addresses the eventual revenue
we use a publicly
the eventual revenue of
use a publicly available
eventual revenue of the
a publicly available implementation
revenue of the pools
publicly available implementation of
available implementation of a
implementation of a reed
assuming the mining difficulty
the mining difficulty is
solomon code based on
mining difficulty is set
code based on vandermonde
difficulty is set based
based on vandermonde matrices
is set based on
set based on the
based on the effective
on the effective mining
the effective mining power
not including mining power
including mining power used
mining power used for
power used for withholding
difficulty is updated only
is updated only periodically
the code is plugged
updated only periodically every
code is plugged into
is plugged into maelstrom
plugged into maelstrom instead
into maelstrom instead of
maelstrom instead of layered
instead of layered interleaving
showing that we can
that we can use
we can use new
can use new encodings
use new encodings within
new encodings within the
encodings within the same
within the same framework
the same framework seamlessly
when mining power in
mining power in the
power in the system
in the system is
the system is regularly
system is regularly increasing
solomon code recovers all
which has been true
code recovers all lost
has been true for
recovers all lost packets
been true for the
true for the majority
all lost packets with
for the majority of
the majority of bitcoin
lost packets with roughly
majority of bitcoin s
of bitcoin s history
packets with roughly the
with roughly the same
roughly the same latency
the same latency whereas
same latency whereas layered
latency whereas layered interleaving
whereas layered interleaving recovers
layered interleaving recovers singleton
interleaving recovers singleton losses
recovers singleton losses almost
singleton losses almost immediately
losses almost immediately and
almost immediately and exhibits
immediately and exhibits latency
no adjustment may be
and exhibits latency spikes
adjustment may be necessary
exhibits latency spikes whenever
latency spikes whenever the
spikes whenever the longer
whenever the longer loss
the longer loss burst
longer loss burst occurs
if an attacker purchases
an attacker purchases new
attacker purchases new mining
purchases new mining hardware
new mining hardware and
mining hardware and employs
related work a significant
hardware and employs it
work a significant body
and employs it directly
a significant body of
employs it directly for
significant body of work
it directly for block
body of work on
directly for block withholding
of work on application
work on application and
on application and tcp
this mining power is
mining power is never
ip performance over high
power is never included
is never included in
never included in the
included in the difficulty
in the difficulty calculation
the difficulty calculation the
difficulty calculation the system
distance networks exists in
calculation the system is
networks exists in the
the system is never
exists in the context
system is never aware
in the context of
is never aware of
the context of high
never aware of it
the difficulty is therefore
difficulty is therefore already
is therefore already correctly
therefore already correctly calculated
already correctly calculated and
correctly calculated and the
calculated and the attack
and the attack is
the attack is profitable
the use of parallel
attack is profitable immediately
use of parallel sockets
of parallel sockets for
parallel sockets for higher
sockets for higher throughput
for higher throughput in
higher throughput in the
throughput in the face
in the face of
the face of non
if the mining power
the mining power is
mining power is static
congestion loss was proposed
loss was proposed in
was proposed in psockets
the attack becomes profitable
attack becomes profitable only
becomes profitable only after
profitable only after the
only after the bitcoin
after the bitcoin system
the bitcoin system has
bitcoin system has normalized
system has normalized the
has normalized the revenues
normalized the revenues by
the revenues by adjusting
revenues by adjusting difficulty
a number of protocols
number of protocols have
of protocols have been
protocols have been suggested
the revenue of an
have been suggested as
revenue of an attacking
been suggested as replacements
of an attacking pool
suggested as replacements for
an attacking pool is
as replacements for tcp
attacking pool is reduced
pool is reduced due
is reduced due to
reduced due to the
ip in such settings
due to the reduction
in such settings xcp
to the reduction in
the reduction in block
reduction in block generation
in block generation of
block generation of both
generation of both the
of both the attacking
both the attacking and
the attacking and attacked
attacking and attacked pools
are a few but
a few but all
few but all require
but all require modifications
all require modifications to
require modifications to end
or the intervening network
some approaches seek to
approaches seek to differentiate
seek to differentiate between
to differentiate between congestion
differentiate between congestion and
between congestion and non
maelstrom is a transparent
is a transparent performance
a transparent performance enhancing
transparent performance enhancing proxy
as defined in rfc
numerous implementations of peps
implementations of peps exist
of peps exist for
peps exist for improving
exist for improving tcp
for improving tcp performance
improving tcp performance on
tcp performance on satellite
but we are not
we are not aware
are not aware of
not aware of any
aware of any peps
of any peps that
any peps that use
peps that use fec
that use fec to
use fec to mask
fec to mask errors
to mask errors on
mask errors on long
based fec for reliable
fec for reliable communication
for reliable communication was
reliable communication was first
communication was first explored
was first explored by
first explored by rizzo
expression for ri in
for ri in a
ri in a system
in a system with
a system with pools
system with pools of
suggested the use of
with pools of equal
the use of fec
pools of equal size
use of fec for
of fec for tcp
ip retransmissions over aggregated
retransmissions over aggregated traffic
over aggregated traffic within
aggregated traffic within an
traffic within an overlay
within an overlay network
an overlay network in
overlay network in the
network in the commodity
in the commodity internet
uses fec for real
modulating the rate of
the rate of encoding
rate of encoding adaptively
the use of end
host fec under tcp
ip has been explored
has been explored in
a multitude of different
multitude of different fec
of different fec encodings
different fec encodings exist
fec encodings exist in
q mi q mi
encodings exist in literature
they can broadly be
can broadly be categorized
broadly be categorized into
be categorized into optimal
categorized into optimal erasure
into optimal erasure codes
optimal erasure codes and
erasure codes and near
known optimal code is
optimal code is reed
which we described previously
we described previously as
described previously as generating
previously as generating c
as generating c repair
generating c repair packets
c repair packets from
repair packets from r
packets from r source
from r source packets
any r of the
r of the resulting
of the resulting r
c packets can be
packets can be used
can be used to
be used to reconstruct
used to reconstruct the
to reconstruct the r
reconstruct the r source
the r source packets
optimal codes such as
codes such as tornado
such as tornado and
as tornado and lt
off encoding speed for
encoding speed for large
speed for large data
for large data sizes
large data sizes against
data sizes against a
sizes against a loss
against a loss of
a loss of optimality
loss of optimality the
of optimality the receiver
optimality the receiver needs
the receiver needs to
receiver needs to receive
needs to receive slightly
to receive slightly more
receive slightly more than
slightly more than r
more than r source
than r source or
r source or repair
source or repair packets
or repair packets to
repair packets to regenerate
packets to regenerate the
to regenerate the original
regenerate the original r
the original r data
original r data packets
q symmetric equilibrium values
symmetric equilibrium values for
equilibrium values for a
values for a system
for a system of
a system of q
system of q pools
of q pools of
q pools of equal
pools of equal sizes
optimal codes are extremely
codes are extremely fast
are extremely fast for
extremely fast for encoding
fast for encoding over
for encoding over large
encoding over large sets
over large sets of
large sets of data
sets of data but
of data but not
countermeasures in order to
data but not of
in order to choose
but not of significant
order to choose its
not of significant importance
to choose its optimal
of significant importance for
choose its optimal infiltration
significant importance for real
its optimal infiltration rate
a pool has to
pool has to know
has to know the
to know the rate
since optimal codes perform
know the rate at
optimal codes perform equally
the rate at which
codes perform equally well
rate at which it
perform equally well with
at which it is
equally well with small
which it is attacked
well with small data
with small data sizes
and the revenue density
of particular relevance are
the revenue density of
particular relevance are growth
revenue density of potential
relevance are growth codes
density of potential victim
of potential victim pools
a pool can estimate
pool can estimate the
can estimate the rate
estimate the rate with
the rate with which
rate with which it
with which it is
which it is attacked
it is attacked by
which use multiple encoding
is attacked by comparing
use multiple encoding rates
attacked by comparing the
multiple encoding rates for
by comparing the rates
encoding rates for different
comparing the rates of
rates for different overhead
the rates of partial
for different overhead levels
rates of partial and
of partial and full
partial and full proofs
and full proofs of
full proofs of work
proofs of work it
of work it receives
work it receives from
it receives from its
layered interleaving uses multiple
receives from its miners
interleaving uses multiple interleaves
uses multiple interleaves for
multiple interleaves for different
interleaves for different burst
for different burst resilience
as explained in section
different burst resilience levels
explained in section ii
burst resilience levels without
resilience levels without modulating
levels without modulating the
without modulating the encoding
modulating the encoding rate
in order to estimate
the effect of random
order to estimate the
effect of random losses
to estimate the revenue
of random losses on
estimate the revenue densities
random losses on tcp
the revenue densities of
revenue densities of the
densities of the other
of the other pools
ip has been studied
has been studied in
been studied in depth
studied in depth by
a pool can use
in depth by lakshman
pool can use one
can use one of
use one of two
one of two methods
pools often publish this
often publish this data
publish this data to
this data to demonstrate
data to demonstrate their
to demonstrate their honesty
demonstrate their honesty to
padhye s analytical model
their honesty to their
honesty to their miners
provides a means to
a means to gauge
means to gauge the
to gauge the impact
gauge the impact of
the impact of packet
impact of packet loss
of packet loss on
packet loss on tcp
while most published studies
most published studies of
published studies of packet
studies of packet loss
of packet loss are
packet loss are based
loss are based on
are based on the
based on the commodity
on the commodity internet
the commodity internet rather
commodity internet rather than
internet rather than highspeed
rather than highspeed lambda
than highspeed lambda links
a pool can infiltrate
pool can infiltrate each
can infiltrate each of
infiltrate each of the
each of the other
of the other pools
the other pools with
study the sprint backbone
other pools with some
the sprint backbone and
pools with some nominal
sprint backbone and make
with some nominal probing
backbone and make two
some nominal probing mining
and make two observations
nominal probing mining power
make two observations that
probing mining power and
two observations that could
mining power and measure
observations that could be
power and measure the
that could be explained
and measure the revenue
could be explained by
measure the revenue density
be explained by non
the revenue density directly
revenue density directly by
density directly by monitoring
directly by monitoring the
by monitoring the probe
monitoring the probe s
the probe s rewards
probe s rewards from
s rewards from the
rewards from the pool
links are rarely loaded
are rarely loaded at
rarely loaded at more
as in the case
loaded at more than
in the case of
the case of classical
case of classical block
of classical block withholding
classical block withholding explained
block withholding explained in
withholding explained in section
explained in section ii
of capacity and b
a pool might detect
packet reordering events occur
pool might detect that
reordering events occur for
might detect that it
events occur for some
detect that it is
occur for some flows
that it is being
it is being attacked
possibly indicating packet loss
indicating packet loss followed
but cannot detect which
packet loss followed by
cannot detect which of
loss followed by retransmissions
detect which of its
which of its miners
of its miners is
its miners is the
miners is the attacker
future work scaling maelstrom
therefore a pool cannot
work scaling maelstrom to
a pool cannot block
scaling maelstrom to multiple
pool cannot block or
maelstrom to multiple gigabits
cannot block or punish
to multiple gigabits per
block or punish withholding
multiple gigabits per second
or punish withholding miners
gigabits per second of
per second of traffic
second of traffic will
of traffic will require
traffic will require small
will require small rack
various techniques can be
techniques can be used
style clusters of tens
can be used to
clusters of tens of
be used to encourage
of tens of machines
used to encourage miners
tens of machines to
to encourage miners to
of machines to distribute
encourage miners to submit
machines to distribute encoding
miners to submit full
to distribute encoding load
to submit full blocks
distribute encoding load over
a pool can pay
we need to design
pool can pay a
need to design intelligent
can pay a bonus
to design intelligent load
pay a bonus for
a bonus for submitting
bonus for submitting a
for submitting a full
submitting a full proof
a full proof of
full proof of work
over mechanisms for such
mechanisms for such a
for such a scheme
this would increase the
would increase the revenue
increase the revenue of
the revenue of the
revenue of the miner
of the miner that
we have described layered
the miner that found
have described layered interleaving
miner that found a
described layered interleaving with
that found a block
layered interleaving with fixed
found a block while
a block while reducing
block while reducing the
while reducing the revenue
reducing the revenue of
the revenue of the
revenue of the other
of the other miners
the other miners from
other miners from this
miners from this block
and the next step
the next step in
next step in extending
step in extending this
in extending this protocol
while the average revenue
extending this protocol is
the average revenue of
this protocol is to
average revenue of each
protocol is to make
revenue of each miner
is to make it
of each miner would
to make it adaptive
each miner would stay
miner would stay the
would stay the same
changing interleaves and rate
interleaves and rate as
small miners will suffer
and rate as loss
miners will suffer from
rate as loss patterns
will suffer from higher
as loss patterns in
suffer from higher variance
loss patterns in the
from higher variance in
patterns in the link
higher variance in revenue
in the link change
another approach is to
approach is to introduce
is to introduce a
conclusion modern distributed systems
to introduce a joining
modern distributed systems are
introduce a joining fee
distributed systems are compelled
a joining fee by
systems are compelled by
joining fee by paying
are compelled by real
fee by paying new
by paying new miners
paying new miners less
new miners less for
world imperatives to coordinate
miners less for their
imperatives to coordinate across
less for their work
to coordinate across datacenters
for their work until
coordinate across datacenters separated
their work until they
across datacenters separated by
work until they have
until they have established
they have established a
have established a reputation
established a reputation with
a reputation with the
reputation with the pool
miners that seek flexibility
that seek flexibility may
seek flexibility may not
flexibility may not accept
may not accept this
not accept this policy
accept this policy and
this policy and choose
policy and choose another
and choose another pool
the pool can use
pool can use a
can use a honeypot
use a honeypot trap
a honeypot trap by
honeypot trap by sending
trap by sending the
by sending the miners
sending the miners tasks
the miners tasks which
miners tasks which it
tasks which it knows
which it knows will
it knows will result
knows will result in
will result in a
result in a full
in a full proof
a full proof of
full proof of work
if a miner fails
a miner fails to
miner fails to submit
fails to submit the
to submit the full
submit the full proof
the full proof of
full proof of work
proof of work it
of work it is
work it is tagged
it is tagged as
is tagged as an
tagged as an attacker
to prevent the attacker
prevent the attacker from
the attacker from learning
attacker from learning them
the honeypot tasks have
honeypot tasks have to
tasks have to be
have to be regularly
to be regularly refreshed
pools can also incorporate
can also incorporate out
also incorporate out of
incorporate out of band
out of band mechanisms
of band mechanisms to
band mechanisms to deter
mechanisms to deter attacks
such as verifying the
as verifying the identity
verifying the identity of
the identity of miners
identity of miners or
of miners or using
miners or using trusted
or using trusted computing
using trusted computing technologies
that assure no block
assure no block withholding
no block withholding is
block withholding is taking
withholding is taking place
this would require miners
would require miners to
require miners to use
miners to use specialized
to use specialized hardware
use specialized hardware and
specialized hardware and software
an overhead miners may
overhead miners may not
miners may not accept
there is no known
is no known silver
no known silver bullet
all these techniques reduce
these techniques reduce the
techniques reduce the pool
reduce the pool s
the pool s attractiveness
pool s attractiveness and
s attractiveness and deter
attractiveness and deter miners
block withholding recycling we
withholding recycling we assume
recycling we assume that
we assume that the
assume that the infiltrating
that the infiltrating miners
the infiltrating miners are
infiltrating miners are loyal
miners are loyal to
are loyal to the
loyal to the attacker
some of the pool
of the pool s
the pool s members
pool s members may
s members may be
members may be disloyal
may be disloyal infiltrators
when sending disloyal miners
sending disloyal miners to
disloyal miners to perform
miners to perform block
to perform block withholding
perform block withholding at
block withholding at other
withholding at other pools
an attacker takes a
attacker takes a significant
takes a significant risk
can use a loyal
use a loyal miner
a loyal miner w
loyal miner w to
miner w to infiltrate
w to infiltrate pool
thinking the miner is
the miner is loyal
miner is loyal to
is loyal to it
might use it to
use it to attack
it to attack pool
the miner m can
miner m can perform
m can perform honest
can perform honest mining
perform honest mining for
honest mining for pool
rather than withhold its
than withhold its blocks
and not return any
not return any revenue
return any revenue to
any revenue to pool
it will take its
will take its share
take its share of
its share of pool
which thinks the miner
thinks the miner is
the miner is loyal
miner is loyal to
is loyal to it
and deliver it back
deliver it back to
it back to pool
to avoid such a
avoid such a risk
a pool needs a
pool needs a sufficient
needs a sufficient number
a sufficient number of
sufficient number of verified
number of verified miners
of verified miners miners
verified miners miners that
miners miners that it
miners that it knows
that it knows to
it knows to be
knows to be loyal
the optimal infiltration rate
optimal infiltration rate may
infiltration rate may be
rate may be as
may be as high
be as high as
of the pool size
but this is only
this is only in
is only in extreme
only in extreme cases
in extreme cases when
extreme cases when pools
cases when pools are
when pools are large
for practical pool sizes
a pool may need
pool may need up
may need up to
of its mining power
its mining power for
mining power for infiltration
latency histograms for i
pools typically have loyal
typically have loyal mining
have loyal mining power
loyal mining power either
mining power either run
power either run directly
either run directly by
run directly by the
directly by the pool
by the pool owners
the pool owners or
pool owners or sold
owners or sold as
or sold as a
sold as a service
as a service but
a service but run
service but run on
but run on the
run on the pool
on the pool owners
the pool owners hardware
however the size of
the size of this
size of this mining
of this mining power
this mining power is
mining power is considered
power is considered a
is considered a trade
considered a trade secret
a trade secret and
trade secret and is
secret and is not
and is not published
block withholding in practice
withholding in practice long
in practice long term
practice long term block
long term block withholding
term block withholding attacks
block withholding attacks are
withholding attacks are difficult
attacks are difficult to
are difficult to hide
since miners using an
miners using an attacked
using an attacked pool
an attacked pool would
attacked pool would notice
pool would notice the
would notice the reduced
notice the reduced revenue
the reduced revenue density
such attacks are rarely
attacks are rarely reported
and we can therefore
we can therefore conclude
can therefore conclude that
therefore conclude that they
conclude that they are
that they are indeed
they are indeed rare
a recent exception is
recent exception is an
exception is an attack
is an attack on
an attack on the
attack on the eligius
on the eligius pool
the eligius pool performed
eligius pool performed in
pool performed in may
performed in may and
in may and june
bitcoin before detecting the
before detecting the attack
at which point payouts
which point payouts to
point payouts to the
payouts to the attackers
to the attackers were
the attackers were blocked
the attackers continued the
attackers continued the attack
more bitcoin before realizing
bitcoin before realizing they
latency histograms for i
before realizing they were
realizing they were not
they were not receiving
were not receiving their
not receiving their payout
the reasons the attack
reasons the attack was
the attack was so
attack was so easily
was so easily subverted
so easily subverted is
easily subverted is the
subverted is the limited
is the limited efforts
the limited efforts of
limited efforts of the
efforts of the attackers
of the attackers to
the attackers to hide
attackers to hide themselves
they have only used
have only used two
only used two payout
used two payout addresses
two payout addresses to
payout addresses to collect
addresses to collect their
to collect their payouts
and so it was
so it was possible
it was possible for
was possible for the
possible for the alert
for the alert pool
the alert pool manager
alert pool manager to
pool manager to cluster
manager to cluster the
to cluster the attacking
cluster the attacking miners
the attacking miners and
attacking miners and obtain
miners and obtain a
and obtain a statistically
obtain a statistically significant
a statistically significant proof
statistically significant proof of
significant proof of their
proof of their wrongdoing
it is unknown whether
is unknown whether this
unknown whether this was
whether this was a
this was a classical
was a classical block
a classical block withholding
classical block withholding attack
packet loss cripples the
loss cripples the performance
with the goal of
cripples the performance notes
the goal of sabotage
the performance notes of
performance notes of such
notes of such systems
or a more elaborate
a more elaborate scheme
and reliability and flow
to verify the effectiveness
verify the effectiveness of
the effectiveness of block
effectiveness of block withholding
of block withholding for
block withholding for profit
implemented an experimental bitcoin
an experimental bitcoin test
experimental bitcoin test network
bitcoin test network and
test network and demonstrated
are increasingly popular and
network and demonstrated the
increasingly popular and designed
and demonstrated the practicality
popular and designed for
demonstrated the practicality of
and designed for lans
the practicality of the
designed for lans and
practicality of the attack
or the commodity internet
the commodity internet fail
commodity internet fail to
internet fail to used
fail to used for
to used for applications
used for applications such
bitcoin s health large
for applications such as
s health large pools
applications such as efficiently
health large pools hinder
such as efficiently distributing
large pools hinder bitcoin
as efficiently distributing bulk
pools hinder bitcoin s
efficiently distributing bulk data
hinder bitcoin s distributed
bitcoin s distributed nature
s distributed nature as
distributed nature as they
nature as they put
as they put a
they put a lot
put a lot of
a lot of mining
lot of mining power
of mining power in
mining power in the
power in the hands
in the hands of
achieve optimal performance on
the hands of a
optimal performance on the
hands of a few
performance on the high
of a few pool
a few pool managers
this has been mostly
has been mostly addressed
been mostly addressed by
mostly addressed by community
addressed by community pressure
it is not obvious
by community pressure on
is not obvious that
community pressure on miners
not obvious that these
pressure on miners to
obvious that these have
on miners to avoid
that these have utility
miners to avoid forming
these have utility in
to avoid forming large
have utility in real
avoid forming large pools
time communi lambda networks
communi lambda networks linking
lambda networks linking datacenters
protocols is not an
is not an option
not an option for
an option for commodity
however such recommendations had
option for commodity clusters
such recommendations had only
for commodity clusters where
recommendations had only had
commodity clusters where standardization
had only had limited
clusters where standardization is
only had limited success
where standardization is critical
standardization is critical for
is critical for cost
critical for cost mitigation
and mining is still
mining is still dominated
is still dominated by
still dominated by a
maelstrom is an edge
dominated by a small
is an edge appliance
by a small number
an edge appliance that
a small number of
edge appliance that uses
small number of large
appliance that uses forward
number of large pools
that uses forward error
uses forward error correction
forward error correction references
error correction references to
as a characteristic example
correction references to mask
references to mask packet
to mask packet loss
mask packet loss from
packet loss from end
in the period of
the period of november
global crossing current network
crossing current network performance
three pools generated over
of the proofs of
the proofs of work
ip throughput and latency
throughput and latency by
the fact that block
and latency by orders
latency by orders of
fact that block withholding
by orders of magninetwork
that block withholding attacks
block withholding attacks are
withholding attacks are rarely
attacks are rarely observed
are rarely observed may
rarely observed may indicate
observed may indicate that
may indicate that the
indicate that the active
that the active pools
the active pools have
last tude when loss
active pools have reached
tude when loss occurs
pools have reached an
have reached an implicit
reached an implicit or
an implicit or explicit
maelstrom is easy to
implicit or explicit agreement
is easy to install
or explicit agreement not
easy to install and
explicit agreement not to
to install and accessed
agreement not to attack
install and accessed feb
not to attack one
to attack one another
an attacked pool cannot
attacked pool cannot detect
pool cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners are
its miners are attacking
miners are attacking it
let alone which pool
alone which pool controls
which pool controls the
pool controls the miners
and is completely transparent
is completely transparent to
completely transparent to applications
transparent to applications and
at some point a
some point a pool
point a pool might
a pool might miscalculate
pool might miscalculate and
might miscalculate and decide
miscalculate and decide to
and decide to try
decide to try to
to try to increase
qwest ip network statistics
try to increase its
to increase its revenue
one pool might be
pool might be enough
might be enough to
be enough to break
enough to break the
to break the agreement
possibly leading to a
leading to a constant
to a constant rate
a constant rate of
constant rate of attacks
rate of attacks among
of attacks among pools
protocols literally providing reliability
attacks among pools and
literally providing reliability in
among pools and a
providing reliability in an
pools and a reduced
reliability in an inexpennet
and a reduced revenue
if open pools reach
open pools reach a
pools reach a state
reach a state where
a state where their
state where their revenue
where their revenue density
their revenue density is
revenue density is reduced
density is reduced due
is reduced due to
reduced due to attacks
miners will leave them
will leave them in
leave them in favor
them in favor of
in favor of other
favor of other available
of other available options
miners of sufficient size
of sufficient size can
sufficient size can mine
size can mine solo
smaller miners can form
miners can form private
can form private pools
form private pools with
private pools with closed
pools with closed access
acknowledgments we would like
we would like to
would like to thank
limited to trusted participants
like to thank our
to thank our shepherd
thank our shepherd robert
our shepherd robert morris
such a change may
shepherd robert morris and
a change may be
robert morris and the
change may be in
morris and the other
may be in favor
and the other reviewers
be in favor of
the other reviewers for
in favor of bitcoin
other reviewers for extensive
favor of bitcoin as
reviewers for extensive comments
of bitcoin as a
for extensive comments that
bitcoin as a whole
extensive comments that significantly
comments that significantly shaped
that significantly shaped the
significantly shaped the final
since they require such
shaped the final version
they require such intimate
the final version of
require such intimate trust
final version of the
version of the paper
private pools are likely
pools are likely to
are likely to be
likely to be smaller
and form a fine
form a fine grained
a fine grained distribution
fine grained distribution of
grained distribution of mining
distribution of mining power
of mining power with
mining power with many
power with many small
with many small pools
many small pools and
small pools and solo
pools and solo miners
vidhyashankar venkataraman and vivek
venkataraman and vivek vishnumurthy
and vivek vishnumurthy provided
vivek vishnumurthy provided useful
vishnumurthy provided useful comments
tom boures provided valuable
boures provided valuable insight
provided valuable insight into
valuable insight into the
insight into the quality
a pool may engage
into the quality of
pool may engage in
the quality of existing
may engage in an
quality of existing fiber
engage in an attack
of existing fiber links
in an attack against
an attack against another
attack against another pool
against another pool not
another pool not to
stanislav shalunov provided information
pool not to increase
shalunov provided information on
not to increase its
provided information on loss
to increase its absolute
information on loss rates
increase its absolute revenue
on loss rates on
loss rates on internet
but rather to attract
rather to attract miners
to attract miners by
attract miners by temporarily
and paul wefel gave
miners by temporarily increasing
paul wefel gave us
by temporarily increasing its
wefel gave us access
temporarily increasing its revenue
gave us access to
increasing its revenue relative
us access to teragrid
its revenue relative to
access to teragrid loss
revenue relative to a
to teragrid loss measurements
relative to a competing
to a competing pool
recent work has investigated
work has investigated the
has investigated the motivation
investigated the motivation of
the motivation of pools
motivation of pools to
of pools to utilize
pools to utilize part
to utilize part of
utilize part of their
part of their resources
of their resources towards
their resources towards sabotage
resources towards sabotage attacks
towards sabotage attacks against
sabotage attacks against each
attacks against each other
the model of those
model of those works
of those works is
those works is different
works is different from
is different from the
different from the pool
from the pool game
the pool game model
pool game model in
game model in two
model in two major
nat and packet mangling
in two major ways
and packet mangling for
two major ways a
packet mangling for linux
major ways a sabotage
ways a sabotage attack
a sabotage attack does
sabotage attack does not
attack does not transfer
does not transfer revenue
not transfer revenue from
transfer revenue from victim
revenue from victim to
from victim to attacker
and migrating miners switch
migrating miners switch to
miners switch to less
switch to less attacked
to less attacked pools
changing pool sizes and
pool sizes and hence
sizes and hence revenues
and hence revenues until
hence revenues until convergence
the model is parametrized
model is parametrized by
is parametrized by the
parametrized by the cost
by the cost of
the cost of the
cost of the attack
of the attack and
the attack and by
attack and by the
and by the mobility
by the mobility of
the mobility of the
mobility of the miners
and the analysis demonstrates
the analysis demonstrates that
analysis demonstrates that when
demonstrates that when considering
that when considering only
when considering only sabotage
considering only sabotage attacks
only sabotage attacks there
sabotage attacks there are
attacks there are regions
there are regions where
are regions where no
attack is the best
is the best strategy
the miner s dilemma
miner s dilemma is
s dilemma is therefore
dilemma is therefore not
is therefore not manifested
therefore not manifested in
not manifested in that
manifested in that model
pool competition for miners
competition for miners is
for miners is an
miners is an incentive
is an incentive in
an incentive in and
incentive in and of
in and of its
and of its own
of its own for
its own for mutual
own for mutual attacks
and a pool may
a pool may therefore
pool may therefore choose
may therefore choose to
therefore choose to perform
choose to perform block
to perform block withholding
perform block withholding even
block withholding even if
withholding even if its
even if its revenue
if its revenue would
its revenue would increase
revenue would increase only
would increase only after
increase only after the
only after the next
after the next difficult
the next difficult adjustment
the two models are
two models are therefore
models are therefore complementary
lateral error correction for
error correction for timecritical
correction for timecritical multicast
the analysis of their
analysis of their combination
of their combination is
their combination is left
combination is left for
is left for future
left for future work
fourth usenix symposium on
we assumed in our
usenix symposium on networked
assumed in our analysis
symposium on networked systems
in our analysis that
on networked systems design
our analysis that pools
networked systems design and
analysis that pools do
systems design and implementation
that pools do not
pools do not charge
do not charge fees
not charge fees from
charge fees from their
fees from their members
from their members since
their members since such
members since such fees
since such fees are
such fees are typically
fees are typically nominal
of a pool s
a pool s revenue
the model can be
model can be extended
can be extended to
be extended to include
extended to include pools
to include pools fees
fees would add a
would add a friction
add a friction element
a friction element to
friction element to the
element to the flow
to the flow of
performance enhancing proxies intended
the flow of revenue
enhancing proxies intended to
flow of revenue among
proxies intended to mitigate
of revenue among infiltrated
intended to mitigate link
revenue among infiltrated and
among infiltrated and infiltrating
infiltrated and infiltrating pools
would change to take
change to take into
to take into account
take into account a
into account a pool
account a pool fee
a pool fee of
pool fee of f
fee of f pp
of f pp ri
enhanced loss differentiation algorithms
loss differentiation algorithms for
differentiation algorithms for use
algorithms for use in
for use in tcp
use in tcp sources
in tcp sources over
tcp sources over heterogeneous
sources over heterogeneous wireless
over heterogeneous wireless networks
ieee global telecommunications conference
a pool with a
pool with a fee
with a fee of
a fee of f
fee of f is
of f is a
f is a less
is a less attractive
a less attractive target
less attractive target for
attractive target for block
target for block withholding
since the attacker s
the attacker s revenue
attacker s revenue is
s revenue is reduced
revenue is reduced by
is reduced by f
however it is also
it is also less
is also less attractive
also less attractive for
less attractive for miners
attractive for miners in
for miners in general
trading off the two
off the two for
the two for best
two for best protection
for best protection is
best protection is left
protection is left for
is left for future
left for future work
as part of the
part of the treatment
of the treatment of
the treatment of the
treatment of the miner
flow aggregation for enhanced
aggregation for enhanced tcp
for enhanced tcp over
enhanced tcp over wide
tcp over wide area
over wide area wireless
r elated w ork
elated w ork a
the block withholding attack
block withholding attack the
withholding attack the danger
attack the danger of
the danger of a
danger of a block
of a block withholding
a block withholding attack
block withholding attack is
withholding attack is as
attack is as old
is as old as
as old as bitcoin
old as bitcoin pools
the attack was described
attack was described by
was described by rosenfeld
vice president of research
president of research and
of research and t
as pools were becoming
pools were becoming a
were becoming a dominant
becoming a dominant player
a dominant player in
dominant player in the
player in the bitcoin
in the bitcoin world
the paper described the
paper described the standard
described the standard attack
used by a miner
by a miner to
a miner to sabotage
miner to sabotage a
to sabotage a pool
sabotage a pool at
a pool at the
pool at the cost
at the cost of
the cost of reducing
cost of reducing its
of reducing its own
reducing its own revenue
a more general view
more general view of
general view of fairness
view of fairness in
of fairness in proof
fairness in proof of
in proof of work
proof of work schemes
of work schemes was
work schemes was discussed
schemes was discussed in
multicast routing in datagram
routing in datagram internetworks
in datagram internetworks and
datagram internetworks and extended
internetworks and extended lans
in the context of
the context of the
context of the hashcash
of the hashcash system
early work did not
work did not address
did not address the
not address the possibility
address the possibility of
the possibility of pools
possibility of pools infiltrating
of pools infiltrating other
pools infiltrating other pools
infiltrating other pools for
other pools for block
pools for block withholding
experimentally demonstrate that block
demonstrate that block withholding
that block withholding can
block withholding can increase
withholding can increase the
can increase the attacker
increase the attacker s
the attacker s revenue
they do not address
do not address the
not address the question
address the question of
the question of mutual
question of mutual attacks
have recently noted that
recently noted that a
noted that a pool
that a pool can
a pool can increase
pool can increase its
can increase its overall
increase its overall revenue
its overall revenue with
overall revenue with block
revenue with block withholding
with block withholding if
block withholding if all
withholding if all other
if all other mining
all other mining is
other mining is performed
mining is performed by
is performed by honest
performed by honest pools
we consider the general
consider the general case
the general case where
general case where not
case where not all
where not all mining
not all mining is
all mining is performed
mining is performed through
is performed through public
performed through public pools
and analyze situations where
analyze situations where pools
situations where pools can
where pools can attack
level traffic measurements from
pools can attack one
traffic measurements from the
can attack one another
measurements from the sprint
from the sprint ip
the sprint ip backbone
the discrepancy between the
discrepancy between the calculations
between the calculations of
for the special case
the special case analyzed
special case analyzed there
case analyzed there and
analyzed there and our
there and our results
and our results can
our results can be
results can be explained
can be explained by
be explained by the
explained by the strong
by the strong approximations
the strong approximations in
strong approximations in that
approximations in that work
we calculate exactly how
calculate exactly how infiltrating
exactly how infiltrating miners
how infiltrating miners reduce
infiltrating miners reduce the
miners reduce the revenue
reduce the revenue density
the revenue density of
revenue density of the
density of the infiltrated
of the infiltrated pool
temporary block withholding in
block withholding in the
withholding in the block
in the block withholding
the block withholding attack
block withholding attack discussed
withholding attack discussed in
attack discussed in this
discussed in this work
in this work the
this work the withheld
work the withheld blocks
the withheld blocks are
withheld blocks are never
blocks are never published
blocks can be withheld
a transport protocol for
can be withheld temporarily
transport protocol for grid
protocol for grid computing
not following the bitcoin
following the bitcoin protocol
journal of grid computing
to improve an attacker
improve an attacker s
an attacker s revenue
a miner or a
miner or a pool
or a pool can
a pool can perform
pool can perform a
can perform a selfish
perform a selfish mining
a selfish mining attack
with selfish mining the
selfish mining the attacker
mining the attacker increases
the attacker increases its
attacker increases its revenue
increases its revenue by
its revenue by temporarily
revenue by temporarily withholding
by temporarily withholding its
temporarily withholding its blocks
withholding its blocks and
its blocks and publishing
blocks and publishing them
and publishing them in
publishing them in response
them in response to
in response to block
response to block publication
to block publication by
block publication by other
publication by other pools
by other pools and
other pools and miners
this attack is independent
attack is independent of
is independent of the
independent of the block
of the block withholding
the block withholding attack
block withholding attack we
withholding attack we discuss
attack we discuss here
we discuss here and
discuss here and the
here and the two
and the two can
the two can be
two can be performed
can be performed in
be performed in concert
an attacker can also
attacker can also perform
can also perform a
also perform a double
perform a double spending
a double spending attack
double spending attack as
spending attack as follows
optical domain performance monitoring
optical fiber communication conference
he intentionally generates two
intentionally generates two conflicting
generates two conflicting transactions
places one in a
one in a block
in a block it
a block it withholds
and publishes the other
publishes the other transaction
after the recipient sees
the recipient sees the
recipient sees the published
sees the published transaction
the attacker publishes the
attacker publishes the withheld
publishes the withheld block
the withheld block to
withheld block to revoke
block to revoke the
to revoke the former
revoke the former transaction
this attack is performed
attack is performed by
is performed by miners
performed by miners or
by miners or pools
miners or pools against
or pools against service
pools against service providers
against service providers that
service providers that accept
providers that accept bitcoin
and it not directly
it not directly related
end performance effects of
not directly related to
performance effects of parallel
directly related to this
effects of parallel tcp
related to this work
of parallel tcp sockets
parallel tcp sockets on
tcp sockets on a
sockets on a lossy
on a lossy wide
block withholding defense most
withholding defense most crypto
currencies use a proof
work architecture similar to
architecture similar to bitcoin
where finding proof of
finding proof of work
proof of work is
of work is the
work is the result
is the result of
the result of solution
result of solution guessing
of solution guessing and
solution guessing and checking
all of the algorithms
of the algorithms we
the algorithms we are
algorithms we are aware
we are aware of
are aware of are
aware of are susceptible
of are susceptible to
are susceptible to the
susceptible to the block
to the block withholding
the block withholding attack
as in all of
in all of them
all of them the
of them the miner
them the miner can
the miner can check
miner can check whether
can check whether she
check whether she found
whether she found a
she found a full
found a full or
a full or a
full or a partial
or a partial proof
a partial proof of
partial proof of work
the effects of systemic
effects of systemic packet
prominent examples are litecoin
of systemic packet loss
systemic packet loss on
packet loss on aggregate
loss on aggregate tcp
on aggregate tcp flows
ieee conference on supercomputing
it is possible to
is possible to use
possible to use an
to use an alternative
use an alternative proof
an alternative proof of
alternative proof of work
proof of work mechanism
of work mechanism in
work mechanism in which
mechanism in which miners
in which miners would
which miners would not
miners would not be
would not be able
not be able to
be able to distinguish
able to distinguish partial
to distinguish partial from
distinguish partial from full
partial from full proofs
from full proofs of
full proofs of work
predictable high performance bulk
high performance bulk data
performance bulk data transfer
ieee international conference on
international conference on cluster
conference on cluster computing
such a solution could
a solution could reduce
solution could reduce or
could reduce or remove
reduce or remove the
or remove the danger
remove the danger of
the danger of block
danger of block withholding
making such a change
such a change may
a change may not
change may not be
may not be in
not be in the
be in the interest
in the interest of
the interest of the
interest of the community
or even its potential
the case for packet
case for packet level
for packet level fec
could lead to a
lead to a reduction
to a reduction of
a reduction of pool
reduction of pool sizes
as explained in section
explained in section ix
proceedings of the tc
decentralized pools although most
pools although most pools
although most pools use
most pools use a
pools use a centralized
use a centralized manager
a prominent exception is
prominent exception is p
pool a distributed pool
a distributed pool architecture
distributed pool architecture with
pool architecture with no
architecture with no central
with no central manager
fifth international workshop on
international workshop on protocols
workshop on protocols for
on protocols for high
but the question of
the question of whether
question of whether a
of whether a pool
whether a pool is
a pool is run
pool is run by
is run by a
run by a centralized
by a centralized manager
a centralized manager or
centralized manager or with
manager or with a
or with a decentralized
with a decentralized architecture
a decentralized architecture is
decentralized architecture is almost
architecture is almost immaterial
is almost immaterial for
almost immaterial for the
immaterial for the attack
for the attack we
the attack we describe
pool group can be
group can be infiltrated
can be infiltrated and
be infiltrated and attacked
pool code can be
code can be changed
can be changed to
be changed to support
changed to support attacks
to support attacks against
support attacks against other
attacks against other pools
on the other hand
pool can be used
can be used by
be used by groups
used by groups of
by groups of miners
groups of miners to
of miners to easily
miners to easily form
to easily form closed
easily form closed pools
these do not accept
do not accept untrusted
not accept untrusted miners
and are therefore protected
are therefore protected against
therefore protected against block
protected against block withholding
gigabit ethernet on commodity
ethernet on commodity systems
c onclusion we explored
onclusion we explored a
we explored a block
explored a block withholding
a block withholding attack
block withholding attack among
withholding attack among bitcoin
attack among bitcoin mining
among bitcoin mining pools
bitcoin mining pools an
mining pools an attack
pools an attack that
an attack that is
attack that is possible
that is possible in
is possible in any
possible in any similar
in any similar system
any similar system that
similar system that rewards
system that rewards for
that rewards for proof
rewards for proof of
for proof of work
such systems are gaining
systems are gaining popularity
running most digital currencies
most digital currencies and
digital currencies and related
currencies and related services
we observe that no
attacks is not a
is not a nash
not a nash equilibrium
if none of the
none of the other
of the other pools
the other pools attack
a pool can increase
pool can increase its
can increase its revenue
increase its revenue by
its revenue by attacking
revenue by attacking the
by attacking the others
when two pools can
two pools can attack
pools can attack each
can attack each other
they face a version
face a version of
a version of the
version of the prisoner
of the prisoner s
the prisoner s dilemma
if one pool chooses
one pool chooses to
pool chooses to attack
where did my performance
did my performance go
the victim s revenue
victim s revenue is
s revenue is reduced
rate limiting rears its
and it can retaliate
limiting rears its ugly
it can retaliate by
rears its ugly head
can retaliate by attacking
retaliate by attacking and
by attacking and increase
attacking and increase its
and increase its revenue
at nash equilibrium both
nash equilibrium both earn
equilibrium both earn less
both earn less than
earn less than they
less than they would
than they would have
they would have if
would have if neither
have if neither attacked
with multiple pools of
multiple pools of equal
pools of equal size
of equal size a
equal size a similar
size a similar situation
a similar situation arises
similar situation arises with
situation arises with a
arises with a symmetric
with a symmetric equilibrium
the fact that block
fact that block withholding
that block withholding is
block withholding is not
withholding is not common
is not common may
not common may be
common may be explained
may be explained by
be explained by modeling
explained by modeling the
by modeling the attack
modeling the attack decisions
the attack decisions as
attack decisions as an
decisions as an iterative
as an iterative prisoner
an iterative prisoner s
iterative prisoner s dilemma
we argue that the
argue that the situation
that the situation is
the situation is unstable
situation is unstable since
is unstable since the
unstable since the attack
since the attack can
the attack can be
attack can be done
can be done anonymously
isn t quite enough
one pool may decide
pool may decide to
may decide to increase
decide to increase its
to increase its revenue
increase its revenue and
its revenue and drag
revenue and drag the
and drag the others
drag the others to
the others to attack
others to attack as
to attack as well
ending with a reduced
with a reduced revenue
a reduced revenue for
reduced revenue for all
the inferior revenue would
inferior revenue would push
revenue would push miners
would push miners to
push miners to join
miners to join private
to join private pools
which can verify that
can verify that their
verify that their registered
that their registered miners
their registered miners do
registered miners do not
miners do not withhold
do not withhold blocks
this would lead to
would lead to smaller
lead to smaller pools
and so ultimately to
so ultimately to a
ultimately to a better
to a better environment
a better environment for
better environment for bitcoin
environment for bitcoin as
for bitcoin as a
bitcoin as a whole
modified tcp congestion avoidance
for their valuable advice
tcp congestion avoidance algorithm
the author is grateful
author is grateful to
is grateful to ken
grateful to ken birman
emin gu n sirer
and the paper shepherd
the paper shepherd joseph
paper shepherd joseph bonneau
peer electronic cash system
physical layer impact upon
layer impact upon packet
impact upon packet errors
passive and active measurement
and active measurement workshop
ebay s paypal unit
s paypal unit to
paypal unit to start
unit to start accepting
to start accepting bitcoin
start accepting bitcoin payments
google adds bitcoin currency
adds bitcoin currency conversion
bitcoin currency conversion to
currency conversion to search
maximizing sensor network data
sensor network data persistence
in proceedings of acm
proceedings of acm sigcomm
congestion control for high
control for high bandwidth
and protocols for computer
protocols for computer communications
journal of lightwave technology
repurposing bitcoin work for
bitcoin work for data
work for data preservation
in proceedings of the
proceedings of the ieee
of the ieee symposium
the ieee symposium on
ieee symposium on security
symposium on security and
on security and privacy
namecoin dns dotbit project
a cross layer study
cross layer study of
layer study of packet
study of packet loss
of packet loss in
packet loss in all
a next generation smart
next generation smart contract
the performance of tcp
ip for networks with
for networks with high
networks with high bandwidth
delay products and random
products and random loss
acm transactions on networking
analysis of bitcoin pooled
of bitcoin pooled mining
bitcoin pooled mining reward
pooled mining reward systems
rd annual ieee symposium
annual ieee symposium on
ieee symposium on foundations
symposium on foundations of
on foundations of computer
foundations of computer science
end forward error correction
international zurich seminar on
research perspectives on bitcoin
zurich seminar on communications
perspectives on bitcoin and
on bitcoin and secondgeneration
bitcoin and secondgeneration cryptocurrencies
in ieee symposium on
ieee symposium on security
symposium on security and
on security and privacy
rateless codes and big
codes and big downloads
paritybased loss recovery for
loss recovery for reliable
recovery for reliable multicast
for reliable multicast transmission
in proceedings of the
proceedings of the acm
of the acm sigcomm
a simple model and
simple model and its
model and its empirical
and its empirical validation
information propagation in the
propagation in the bitcoin
in the bitcoin network
th ieee international conference
ieee international conference on
international conference on peer
bitcoin and the age
and the age of
the age of bespoke
age of bespoke silicon
in proceedings of the
international conference on compilers
architectures and synthesis for
and synthesis for embedded
synthesis for embedded systems
an adaptive forward error
adaptive forward error correction
forward error correction protocol
error correction protocol for
correction protocol for end
computer communications and networks
into the bitcoin mines
th international conference on
businesses see the light
effective erasure codes for
erasure codes for reliable
codes for reliable computer
for reliable computer communication
reliable computer communication protocols
on the feasibility of
the feasibility of software
feasibility of software fec
how a mining monopoly
a mining monopoly can
mining monopoly can attack
monopoly can attack bitcoin
the case for application
level network striping for
network striping for data
striping for data intensive
for data intensive applications
data intensive applications using
intensive applications using high
applications using high speed
using high speed wide
high speed wide area
speed wide area networks
ieee conference on supercomputing
google s secret plans
s secret plans for
secret plans for all
plans for all that
for all that dark
all that dark fiber
majority is not enough
bitcoin mining is vulnerable
in financial cryptography and
financial cryptography and data
cryptography and data security
cooperative equilibrium for supergames
the review of economic
review of economic studies
an overlay based architecture
overlay based architecture for
based architecture for enhancing
architecture for enhancing internet
for enhancing internet qos
first usenix symposium on
usenix symposium on networked
symposium on networked systems
on networked systems design
networked systems design and
systems design and implementation
term competition a game
udp bandwidth measurement tool
a tcp performance enhancing
tcp performance enhancing proxy
performance enhancing proxy for
enhancing proxy for satellite
proxy for satellite links
proceedings of the second
of the second international
the second international ifip
networking conference on networking
conference on networking technologies
performance of computer and
of computer and communication
computer and communication networks
and mobile and wireless
mobile and wireless communications
io bitcoin mining pool
tsunami file transfer protocol
workshop on protocols for
on protocols for fast
protocols for fast longdistance
for fast longdistance networks
the university of illinois
university of illinois national
of illinois national center
illinois national center for
national center for supercomputing
center for supercomputing applications
an integrated experimental environment
integrated experimental environment for
experimental environment for distributed
environment for distributed systems
for distributed systems and
distributed systems and networks
of the fifth symposium
the fifth symposium on
fifth symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
kncminer bitcoin mining cloud
bitcoin mining cloud mining
solomon codes and their
codes and their applications
an authorization architecture for
authorization architecture for trustworthy
architecture for trustworthy computing
in proceedings of the
proceedings of the twenty
third acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
on power splitting games
power splitting games in
splitting games in distributed
games in distributed computation
the case of bitcoin
case of bitcoin pooled
of bitcoin pooled mining
weekly bitcoin network statistics
theoretic analysis of ddos
analysis of ddos attacks
of ddos attacks against
ddos attacks against bitcoin
attacks against bitcoin mining
against bitcoin mining pools
in workshop on bitcoin
workshop on bitcoin research
when bitcoin mining pools
bitcoin mining pools run
mining pools run dry
in workshop on bitcoin
workshop on bitcoin research
comparison of mining pools
comparison of mining pools
hashcash amortizable publicly auditable
amortizable publicly auditable cost
hashcash a denial of
a denial of service
denial of service counter
on subversive miner strategies
subversive miner strategies and
miner strategies and block
strategies and block withholding
and block withholding attack
block withholding attack in
withholding attack in bitcoin
attack in bitcoin digital
in bitcoin digital currency
how to disincentivize large
to disincentivize large bitcoin
disincentivize large bitcoin mining
large bitcoin mining pools
the: 7744
of: 4121
a: 3489
to: 3267
and: 3193
in: 2417
is: 1914
for: 1353
that: 1296
with: 990
on: 965
are: 940
we: 925
as: 917
it: 771
by: 745
be: 695
this: 681
data: 659
pool: 659
s: 654
an: 631
at: 630
can: 574
system: 559
its: 497
from: 483
not: 466
or: 452
r: 429
which: 418
each: 404
file: 401
all: 377
systems: 372
m: 368
if: 362
figure: 357
x: 343
one: 338
time: 335
nodes: 332
pools: 325
revenue: 325
t: 325
packets: 320
rate: 320
other: 317
cache: 310
but: 309
our: 291
have: 289
work: 287
i: 282
performance: 281
such: 271
when: 268
loss: 258
p: 258
miners: 257
has: 252
bandwidth: 251
packet: 244
c: 243
network: 242
their: 236
will: 232
attack: 230
block: 230
mining: 230
j: 228
these: 223
than: 222
only: 221
end: 220
use: 220
they: 218
more: 216
node: 209
bitcoin: 204
no: 204
high: 203
number: 202
services: 200
latency: 197
b: 196
may: 193
transactions: 192
would: 192
server: 190
two: 188
where: 188
update: 187
power: 182
between: 180
used: 177
based: 174
d: 173
over: 171
any: 170
different: 169
distributed: 166
miner: 164
new: 164
single: 164
also: 162
client: 161
some: 161
large: 159
tcp: 159
was: 157
web: 157
since: 153
objects: 152
application: 150
ip: 150
service: 150
using: 149
updates: 146
e: 144
protocol: 144
them: 144
set: 140
read: 139
access: 138
applications: 137
process: 137
files: 134
transaction: 133
maelstrom: 132
traffic: 132
there: 131
operating: 130
gossip: 129
however: 129
into: 129
section: 129
withholding: 129
rates: 128
example: 127
mfs: 127
so: 127
communication: 124
consistency: 124
both: 122
same: 122
size: 122
object: 121
priorities: 120
repair: 120
even: 119
peer: 119
throughput: 119
chain: 118
g: 116
control: 114
failure: 114
information: 113
while: 113
first: 112
recovery: 112
were: 112
results: 111
database: 110
protocols: 110
case: 109
acm: 106
link: 106
low: 106
therefore: 106
then: 105
without: 105
rpcs: 104
small: 104
clients: 103
writes: 103
networks: 102
could: 101
second: 101
ms: 100
rpc: 99
do: 98
many: 98
asynchronous: 97
writeback: 97
log: 96
model: 96
within: 96
group: 95
send: 95
does: 94
proof: 94
most: 93
up: 93
memory: 92
state: 91
user: 91
average: 90
content: 90
version: 90
level: 89
order: 89
back: 87
been: 87
support: 87
less: 86
through: 85
windows: 85
available: 84
groups: 84
long: 84
out: 84
see: 84
after: 83
another: 83
approach: 83
fec: 83
full: 83
how: 83
against: 82
architecture: 82
infiltration: 82
message: 82
o: 82
disk: 81
k: 81
messages: 81
need: 81
qsm: 81
about: 80
kb: 80
multicast: 80
sender: 80
uses: 80
management: 79
n: 79
q: 79
way: 79
delivery: 78
total: 78
disks: 77
experiments: 77
possible: 77
write: 77
design: 76
higher: 76
delay: 75
increase: 75
layer: 75
local: 75
research: 75
scale: 75
upload: 75
computer: 74
f: 74
implementation: 74
might: 74
source: 74
analysis: 73
burst: 73
live: 73
probability: 73
workloads: 73
accesses: 72
because: 72
every: 72
lost: 72
solution: 71
cost: 70
due: 70
step: 70
v: 70
value: 70
equilibrium: 69
like: 69
multiple: 69
manager: 68
per: 68
priority: 68
well: 68
list: 67
overhead: 67
computing: 66
load: 66
running: 66
cornell: 65
http: 65
mechanism: 65
opportunistic: 65
run: 65
should: 65
under: 65
attacking: 64
cluster: 64
operations: 64
proceedings: 64
servers: 64
show: 64
shown: 64
test: 64
attacks: 63
layered: 63
much: 63
paper: 63
partial: 63
received: 63
stream: 63
attacker: 62
dependency: 62
kernel: 62
point: 62
solutions: 62
event: 61
l: 61
maximum: 61
must: 61
scheme: 61
shows: 61
sizes: 61
code: 60
game: 60
interleave: 60
prefetching: 60
proofs: 60
replication: 60
result: 60
round: 60
storage: 60
us: 60
perform: 59
sending: 59
very: 59
inconsistency: 58
once: 58
provide: 58
threshold: 58
users: 58
workload: 58
flow: 57
scalable: 57
sent: 57
similar: 57
streaming: 57
being: 56
conference: 56
symposium: 56
download: 55
nt: 55
problem: 55
random: 55
receiver: 55
reduce: 55
requests: 55
until: 55
before: 54
correct: 54
factor: 54
global: 54
graph: 54
interleaving: 54
larger: 54
open: 54
processes: 54
range: 54
retrieved: 54
among: 53
auditing: 53
caching: 53
cannot: 53
h: 53
scenario: 53
center: 52
fetch: 52
mode: 52
real: 52
synchronous: 52
take: 52
transactional: 52
according: 51
form: 51
ieee: 51
increasing: 51
internet: 51
make: 51
present: 51
reads: 51
xor: 51
able: 50
algorithm: 50
current: 50
had: 50
inconsistencies: 50
mobile: 50
store: 50
components: 49
contention: 49
either: 49
existing: 49
hence: 49
mechanisms: 49
mi: 49
now: 49
three: 49
whether: 49
encoding: 48
general: 48
host: 48
implemented: 48
own: 48
prefetch: 48
recovered: 48
reliable: 48
values: 48
although: 47
important: 47
pp: 47
side: 47
w: 47
behavior: 46
execution: 46
fixed: 46
function: 46
generated: 46
graphs: 46
operation: 46
platform: 46
request: 46
speed: 46
th: 46
consider: 45
designed: 45
shared: 45
significant: 45
university: 45
victim: 45
window: 45
attacked: 44
blocks: 44
com: 44
community: 44
delays: 44
density: 44
error: 44
future: 44
hosted: 44
kbps: 44
left: 44
pages: 44
smaller: 44
standard: 44
wide: 44
appliance: 43
changes: 43
component: 43
costs: 43
events: 43
fig: 43
here: 43
makes: 43
ratio: 43
required: 43
right: 43
thus: 43
y: 43
allows: 42
amount: 42
change: 42
developers: 42
distribution: 42
experiment: 42
just: 42
often: 42
rather: 42
scalability: 42
seen: 42
start: 42
tasks: 42
uniform: 42
what: 42
cloud: 41
effect: 41
mafs: 41
missing: 41
numbers: 41
optimal: 41
reduced: 41
simple: 41
ssa: 41
strategy: 41
across: 40
address: 40
detection: 40
down: 40
further: 40
given: 40
hosts: 40
lower: 40
next: 40
non: 40
receive: 40
sends: 40
software: 40
token: 40
typically: 40
allow: 39
caches: 39
cases: 39
congestion: 39
directly: 39
entire: 39
increases: 39
independent: 39
interface: 39
length: 39
original: 39
overheads: 39
part: 39
structure: 39
times: 39
compared: 38
described: 38
direct: 38
during: 38
microsoft: 38
region: 38
require: 38
revenues: 38
world: 38
accessed: 37
al: 37
birman: 37
centers: 37
codes: 37
effective: 37
enough: 37
et: 37
improve: 37
losses: 37
membership: 37
provides: 37
xors: 37
better: 36
clusters: 36
consistent: 36
describe: 36
expected: 36
fact: 36
fast: 36
loyal: 36
previous: 36
related: 36
relative: 36
techniques: 36
today: 36
types: 36
adaptation: 35
additional: 35
almost: 35
commodity: 35
environment: 35
https: 35
international: 35
last: 35
links: 35
longer: 35
minimum: 35
needs: 35
org: 35
performed: 35
proxy: 35
reliability: 35
still: 35
though: 35
above: 34
acid: 34
earlier: 34
evaluation: 34
factors: 34
injection: 34
interleaves: 34
ken: 34
levels: 34
managed: 34
percentage: 34
remote: 34
sets: 34
several: 34
virtual: 34
www: 34
constant: 33
denote: 33
limited: 33
note: 33
overall: 33
particular: 33
receiving: 33
top: 33
working: 33
assume: 32
become: 32
clustered: 32
detect: 32
find: 32
including: 32
period: 32
replicated: 32
scenarios: 32
seconds: 32
space: 32
stable: 32
table: 32
technologies: 32
technology: 32
those: 32
trace: 32
versions: 32
added: 31
ensure: 31
evaluate: 31
finally: 31
follows: 31
immediately: 31
invalidations: 31
least: 31
mb: 31
overlay: 31
prediction: 31
principles: 31
receivers: 31
requires: 31
runs: 31
sirp: 31
target: 31
udp: 31
achieve: 30
adaptive: 30
amazon: 30
auditors: 30
collaboration: 30
correction: 30
dropped: 30
good: 30
incoming: 30
lists: 30
members: 30
performs: 30
policy: 30
recent: 30
ri: 30
schemes: 30
security: 30
share: 30
third: 30
usenix: 30
z: 30
associated: 29
availability: 29
close: 29
commit: 29
complete: 29
delivered: 29
edu: 29
head: 29
key: 29
later: 29
platforms: 29
pull: 29
receives: 29
recover: 29
reducing: 29
science: 29
settings: 29
task: 29
varying: 29
xi: 29
best: 28
configuration: 28
core: 28
dilemma: 28
feasible: 28
implements: 28
issues: 28
making: 28
never: 28
obtain: 28
occur: 28
others: 28
repository: 28
resulting: 28
style: 28
tools: 28
transport: 28
type: 28
area: 27
async: 27
build: 27
building: 27
cached: 27
capacity: 27
collection: 27
failures: 27
following: 27
forward: 27
framework: 27
increased: 27
instance: 27
major: 27
mbps: 27
needed: 27
neighbors: 27
nov: 27
participants: 27
reader: 27
resources: 27
solo: 27
speedup: 27
stored: 27
tm: 27
vn: 27
writer: 27
abort: 26
basic: 26
becomes: 26
benefit: 26
bin: 26
bins: 26
certain: 26
channel: 26
classical: 26
common: 26
consumption: 26
controls: 26
discuss: 26
entry: 26
fault: 26
haul: 26
instead: 26
means: 26
mostly: 26
online: 26
os: 26
solomon: 26
sources: 26
tolerance: 26
vol: 26
allowing: 25
backend: 25
bursts: 25
bursty: 25
choice: 25
conditions: 25
considered: 25
contribution: 25
copy: 25
cs: 25
difficulty: 25
distance: 25
estimate: 25
figures: 25
flows: 25
found: 25
goal: 25
hardware: 25
invalidation: 25
machines: 25
observed: 25
properties: 25
queue: 25
rain: 25
reduces: 25
report: 25
spent: 25
split: 25
takes: 25
transmission: 25
abstract: 24
algorithms: 24
around: 24
blockchain: 24
cause: 24
closed: 24
committed: 24
contrast: 24
correctly: 24
corresponding: 24
critical: 24
datacenters: 24
demand: 24
developed: 24
done: 24
equal: 24
experimental: 24
front: 24
having: 24
idea: 24
individual: 24
infiltrating: 24
knowledge: 24
limit: 24
lock: 24
logs: 24
ny: 24
observe: 24
oriented: 24
peers: 24
place: 24
processing: 24
strategies: 24
streams: 24
structured: 24
too: 24
view: 24
again: 23
approaches: 23
called: 23
choose: 23
create: 23
datacenter: 23
detected: 23
duration: 23
include: 23
layers: 23
likely: 23
majority: 23
member: 23
monitoring: 23
ones: 23
powered: 23
product: 23
reed: 23
sufficient: 23
sync: 23
traditional: 23
unix: 23
ways: 23
workshop: 23
york: 23
alternative: 22
always: 22
avoid: 22
built: 22
certification: 22
connected: 22
consequently: 22
context: 22
defined: 22
dependencies: 22
development: 22
efficient: 22
generate: 22
handle: 22
he: 22
made: 22
maintain: 22
mtu: 22
net: 22
occurs: 22
off: 22
optical: 22
parameters: 22
patterns: 22
popular: 22
problems: 22
revision: 22
starts: 22
via: 22
who: 22
wireless: 22
bandwidths: 21
buffers: 21
centralized: 21
configurations: 21
contains: 21
dynamic: 21
easily: 21
easy: 21
equation: 21
etc: 21
garbage: 21
hand: 21
hash: 21
identical: 21
iii: 21
index: 21
let: 21
life: 21
line: 21
mashup: 21
milliseconds: 21
old: 21
path: 21
private: 21
project: 21
proxies: 21
reasons: 21
response: 21
short: 21
significantly: 21
social: 21
staleness: 21
video: 21
vogels: 21
wait: 21
writing: 21
aggregate: 20
analyze: 20
architectures: 20
benefits: 20
buffering: 20
changing: 20
choosing: 20
consists: 20
four: 20
generates: 20
google: 20
grep: 20
honest: 20
inter: 20
interest: 20
interfaces: 20
library: 20
machine: 20
manner: 20
minibrowser: 20
multi: 20
none: 20
potentially: 20
presence: 20
proc: 20
quality: 20
queued: 20
racs: 20
rapidly: 20
references: 20
respectively: 20
simply: 20
site: 20
stale: 20
together: 20
traces: 20
updated: 20
usa: 20
usage: 20
yet: 20
actually: 19
adding: 19
appropriate: 19
clear: 19
convergence: 19
course: 19
currently: 19
digital: 19
expect: 19
explained: 19
extended: 19
extremely: 19
faster: 19
features: 19
inconsistent: 19
investigation: 19
issue: 19
kind: 19
know: 19
mine: 19
month: 19
natural: 19
networking: 19
om: 19
partition: 19
periods: 19
potential: 19
propagation: 19
proposed: 19
query: 19
quickly: 19
re: 19
recipe: 19
reply: 19
sequence: 19
serializability: 19
soc: 19
speeds: 19
subscribers: 19
taken: 19
towards: 19
transfer: 19
transient: 19
upon: 19
whereas: 19
works: 19
active: 18
aggregation: 18
aware: 18
background: 18
bad: 18
chooses: 18
cpu: 18
databases: 18
difficult: 18
divided: 18
drop: 18
earn: 18
effectiveness: 18
employ: 18
eventually: 18
exchange: 18
failed: 18
feb: 18
fiber: 18
foreground: 18
generation: 18
get: 18
gigabit: 18
heavy: 18
history: 18
identify: 18
includes: 18
initial: 18
itself: 18
known: 18
lambda: 18
latencies: 18
logging: 18
moreover: 18
nash: 18
neither: 18
noted: 18
participating: 18
propose: 18
publish: 18
queries: 18
repositories: 18
roundtrip: 18
sigcomm: 18
specific: 18
study: 18
subversion: 18
summary: 18
switching: 18
synthetic: 18
tokens: 18
topics: 18
unique: 18
varied: 18
various: 18
vary: 18
actual: 17
automatically: 17
chosen: 17
coda: 17
communications: 17
developer: 17
device: 17
devices: 17
don: 17
early: 17
enabled: 17
environments: 17
errors: 17
experience: 17
focus: 17
fraction: 17
functionality: 17
grows: 17
highest: 17
highly: 17
hosting: 17
ii: 17
impact: 17
implement: 17
infrastructure: 17
lines: 17
maintains: 17
modified: 17
module: 17
necessary: 17
offer: 17
partitioning: 17
periodically: 17
products: 17
progress: 17
projects: 17
ran: 17
raps: 17
reach: 17
remain: 17
setting: 17
sharing: 17
simultaneous: 17
specifically: 17
standards: 17
subservice: 17
successfully: 17
supported: 17
switch: 17
symmetric: 17
term: 17
transmitted: 17
van: 17
variety: 17
years: 17
acts: 16
already: 16
axis: 16
believe: 16
buffer: 16
bytes: 16
call: 16
chainsaw: 16
clustering: 16
compare: 16
configured: 16
conflicts: 16
connectivity: 16
contents: 16
conventional: 16
created: 16
define: 16
demonstrate: 16
difference: 16
efficacy: 16
examples: 16
fees: 16
few: 16
ghash: 16
go: 16
hard: 16
illustrated: 16
implications: 16
indeed: 16
infiltrate: 16
integration: 16
io: 16
kinds: 16
lead: 16
limiting: 16
linux: 16
little: 16
main: 16
market: 16
measurements: 16
modes: 16
operate: 16
options: 16
page: 16
parallel: 16
physical: 16
points: 16
prisoner: 16
publishes: 16
registered: 16
requirements: 16
serialization: 16
simulation: 16
simultaneously: 16
status: 16
strong: 16
sub: 16
subsystem: 16
themselves: 16
timestamp: 16
topic: 16
transparently: 16
typical: 16
accessing: 15
adapt: 15
applied: 15
arrive: 15
atp: 15
attempt: 15
bar: 15
bc: 15
comparison: 15
containing: 15
contribute: 15
corba: 15
department: 15
describes: 15
diff: 15
edge: 15
effects: 15
exists: 15
fire: 15
gc: 15
greater: 15
idle: 15
included: 15
infiltrated: 15
info: 15
june: 15
latter: 15
linear: 15
maintaining: 15
namely: 15
november: 15
oms: 15
optimize: 15
outgoing: 15
paths: 15
performing: 15
practice: 15
predictable: 15
programming: 15
regions: 15
regular: 15
renesse: 15
represents: 15
respond: 15
sense: 15
sirer: 15
slightly: 15
slow: 15
statistics: 15
stores: 15
supercomputing: 15
teragrid: 15
thousands: 15
tier: 15
underlying: 15
uniformly: 15
whole: 15
accept: 14
addition: 14
arise: 14
balancing: 14
bounded: 14
channels: 14
class: 14
combined: 14
commits: 14
conclusion: 14
concurrency: 14
currency: 14
decrease: 14
deliver: 14
destination: 14
detects: 14
differentiated: 14
directory: 14
dissemination: 14
distinct: 14
drops: 14
engineering: 14
entries: 14
exactly: 14
explore: 14
fail: 14
fifo: 14
financial: 14
finding: 14
growing: 14
guarantees: 14
handling: 14
help: 14
improves: 14
infiltrators: 14
integrated: 14
interested: 14
involves: 14
malicious: 14
modern: 14
option: 14
perfect: 14
policies: 14
prevent: 14
previously: 14
prior: 14
program: 14
providing: 14
published: 14
question: 14
relatively: 14
sabotage: 14
search: 14
singleton: 14
soon: 14
spread: 14
starting: 14
temporarily: 14
thread: 14
tolerate: 14
turn: 14
useful: 14
xj: 14
zookeeper: 14
achieved: 13
add: 13
afs: 13
annual: 13
avg: 13
balance: 13
bound: 13
collaborative: 13
collect: 13
compile: 13
completely: 13
computation: 13
concurrent: 13
consisting: 13
constraints: 13
decreases: 13
depends: 13
determine: 13
determined: 13
did: 13
digests: 13
discarded: 13
dominant: 13
dynamically: 13
embedded: 13
epidemic: 13
exception: 13
eyal: 13
face: 13
far: 13
field: 13
free: 13
frequently: 13
fundamental: 13
generating: 13
gives: 13
grained: 13
growth: 13
his: 13
hit: 13
instances: 13
intended: 13
interactive: 13
interval: 13
intervals: 13
introduction: 13
join: 13
lack: 13
location: 13
magnitude: 13
measure: 13
mentioned: 13
missed: 13
modeless: 13
nfm: 13
normal: 13
notice: 13
ntfs: 13
overview: 13
paradigm: 13
positive: 13
proportional: 13
provided: 13
public: 13
radient: 13
receipt: 13
registers: 13
relevant: 13
remains: 13
researchers: 13
robust: 13
rtt: 13
semantics: 13
setup: 13
shares: 13
situations: 13
special: 13
static: 13
structures: 13
subscribe: 13
thousand: 13
tool: 13
track: 13
trade: 13
tree: 13
unbounded: 13
written: 13
aborted: 12
academic: 12
acceptable: 12
account: 12
accurate: 12
balakrishnan: 12
base: 12
below: 12
ca: 12
capable: 12
caused: 12
challenges: 12
classes: 12
conclude: 12
copies: 12
creating: 12
cumulative: 12
date: 12
decentralized: 12
decide: 12
dedicated: 12
definition: 12
delayed: 12
despite: 12
efficiency: 12
element: 12
enterprise: 12
facts: 12
fairly: 12
footprint: 12
generally: 12
half: 12
hashcash: 12
html: 12
ing: 12
interactions: 12
introduced: 12
iv: 12
ix: 12
jan: 12
java: 12
keep: 12
leads: 12
lfs: 12
li: 12
limitations: 12
locking: 12
maintained: 12
near: 12
obtained: 12
opportunity: 12
oracle: 12
ordering: 12
orders: 12
otherwise: 12
overlap: 12
particularly: 12
past: 12
practical: 12
primary: 12
purposes: 12
push: 12
reason: 12
recently: 12
redundant: 12
rescue: 12
review: 12
roles: 12
roughly: 12
sort: 12
specify: 12
spikes: 12
stack: 12
subset: 12
taking: 12
technique: 12
ten: 12
tms: 12
unif: 12
whenever: 12
you: 12
achieving: 11
acknowledgments: 11
activity: 11
advance: 11
aggregated: 11
argue: 11
authors: 11
automated: 11
basis: 11
begin: 11
callback: 11
complex: 11
converge: 11
crash: 11
deal: 11
deployed: 11
detail: 11
details: 11
detecting: 11
discussion: 11
energy: 11
ensures: 11
equivalent: 11
evict: 11
fa: 11
fee: 11
fetches: 11
fetching: 11
finds: 11
flexible: 11
focused: 11
heterogeneous: 11
hot: 11
hundreds: 11
identifiers: 11
illustrates: 11
implementing: 11
improvements: 11
incorporates: 11
increasingly: 11
indicate: 11
insufficient: 11
interact: 11
introduce: 11
involved: 11
ithaca: 11
largest: 11
layout: 11
linearly: 11
logged: 11
maintenance: 11
measurement: 11
metadata: 11
modal: 11
moving: 11
name: 11
orkut: 11
osdi: 11
pair: 11
parameter: 11
partitioned: 11
prefetches: 11
privacy: 11
processed: 11
prove: 11
providers: 11
randomly: 11
readers: 11
realistic: 11
recovers: 11
replace: 11
replicas: 11
requiring: 11
responsible: 11
retransmission: 11
role: 11
routine: 11
sample: 11
scheduling: 11
sensitive: 11
sep: 11
separate: 11
serve: 11
simplicity: 11
stock: 11
strictly: 11
subsequent: 11
supporting: 11
supports: 11
true: 11
trusted: 11
try: 11
unlikely: 11
unshared: 11
valid: 11
ve: 11
white: 11
whose: 11
xml: 11
accuracy: 10
ack: 10
additionally: 10
along: 10
appear: 10
arg: 10
assumption: 10
asynchronously: 10
becoming: 10
bitcoins: 10
bottleneck: 10
cc: 10
cdn: 10
check: 10
checks: 10
compares: 10
conflict: 10
constructed: 10
continuous: 10
dec: 10
decision: 10
decisions: 10
degenerate: 10
degree: 10
depend: 10
desired: 10
detailed: 10
discussed: 10
distinguish: 10
distributes: 10
effectively: 10
efforts: 10
elements: 10
enable: 10
enhancing: 10
epidemics: 10
especially: 10
evaluated: 10
eventual: 10
examine: 10
expensive: 10
experienced: 10
fairness: 10
false: 10
final: 10
fine: 10
forms: 10
give: 10
gracefully: 10
ideal: 10
improving: 10
infiltrates: 10
injected: 10
ipc: 10
isn: 10
journal: 10
language: 10
leverage: 10
map: 10
maps: 10
mesh: 10
methods: 10
microbenchmarks: 10
minutes: 10
miss: 10
networked: 10
nevertheless: 10
news: 10
novel: 10
overlapping: 10
paxos: 10
pending: 10
possibility: 10
presented: 10
presents: 10
proceed: 10
pushing: 10
rapid: 10
really: 10
recall: 10
remainder: 10
reported: 10
reports: 10
representing: 10
rest: 10
return: 10
rise: 10
robbert: 10
router: 10
routes: 10
routing: 10
runtime: 10
sampling: 10
scales: 10
segment: 10
situation: 10
studies: 10
subject: 10
success: 10
synchrony: 10
tail: 10
team: 10
technical: 10
tests: 10
theorem: 10
think: 10
thresholds: 10
throughout: 10
tion: 10
transparent: 10
unlike: 10
unstable: 10
usually: 10
utility: 10
variant: 10
visible: 10
volume: 10
widely: 10
zone: 10
achieves: 9
advantages: 9
alarm: 9
allowed: 9
appliances: 9
apply: 9
assigned: 9
assigns: 9
assumed: 9
attackers: 9
august: 9
behave: 9
beneficial: 9
break: 9
causing: 9
central: 9
changed: 9
co: 9
commercial: 9
companies: 9
comparing: 9
competing: 9
compute: 9
computers: 9
confidence: 9
connections: 9
continue: 9
curves: 9
daily: 9
default: 9
degradation: 9
depending: 9
deterministic: 9
developing: 9
dirty: 9
discards: 9
disconnected: 9
domain: 9
ec: 9
ee: 9
efficiently: 9
eliminate: 9
en: 9
entirely: 9
execute: 9
explicit: 9
explored: 9
expression: 9
fails: 9
fashion: 9
fd: 9
force: 9
forming: 9
forwarding: 9
frequency: 9
fully: 9
functions: 9
grant: 9
grow: 9
gw: 9
hide: 9
hierarchy: 9
hold: 9
id: 9
ideally: 9
identifier: 9
importance: 9
incentive: 9
inexpensive: 9
infocom: 9
initially: 9
intel: 9
investigate: 9
iperf: 9
iterative: 9
john: 9
kept: 9
knows: 9
leaving: 9
loads: 9
lose: 9
lossless: 9
lowest: 9
maximize: 9
media: 9
merlin: 9
middle: 9
middleware: 9
minor: 9
modifications: 9
modify: 9
modules: 9
nsdi: 9
owner: 9
pattern: 9
permutation: 9
places: 9
plan: 9
profitable: 9
programmer: 9
prone: 9
proportion: 9
quite: 9
reached: 9
reading: 9
records: 9
reflect: 9
respect: 9
retry: 9
ricochet: 9
rings: 9
risk: 9
rounds: 9
rw: 9
sampled: 9
sd: 9
sec: 9
segments: 9
selected: 9
self: 9
session: 9
shall: 9
showing: 9
sigmod: 9
sosp: 9
specialized: 9
steps: 9
susceptible: 9
terms: 9
threads: 9
tolerant: 9
topology: 9
transfers: 9
transformation: 9
transitions: 9
transmitting: 9
trip: 9
ttl: 9
unacknowledged: 9
unless: 9
upcall: 9
vi: 9
viii: 9
want: 9
werner: 9
academia: 8
accordingly: 8
activities: 8
adds: 8
advantage: 8
affect: 8
affects: 8
afrl: 8
aggregates: 8
allocation: 8
amounts: 8
api: 8
arbitrary: 8
arrays: 8
arxiv: 8
aspects: 8
attributes: 8
auditor: 8
automatic: 8
away: 8
backup: 8
behind: 8
beyond: 8
breaks: 8
buffered: 8
byte: 8
cbcb: 8
challenge: 8
charge: 8
checking: 8
clock: 8
collected: 8
combine: 8
come: 8
competition: 8
compromised: 8
concurrently: 8
confirm: 8
congested: 8
connecting: 8
consecutive: 8
contributing: 8
coordinator: 8
corresponds: 8
creates: 8
currencies: 8
dark: 8
david: 8
de: 8
degrades: 8
densities: 8
deploy: 8
deployment: 8
detectors: 8
differs: 8
dogecoin: 8
drag: 8
driven: 8
earns: 8
eligius: 8
employed: 8
engage: 8
equations: 8
equipment: 8
essentially: 8
ever: 8
exact: 8
executed: 8
exist: 8
extensions: 8
external: 8
extreme: 8
favor: 8
filesystem: 8
gib: 8
greatly: 8
header: 8
histograms: 8
honestly: 8
ideas: 8
improvement: 8
input: 8
insight: 8
interaction: 8
jgroups: 8
largely: 8
leader: 8
leading: 8
leave: 8
lemma: 8
light: 8
limits: 8
litecoin: 8
look: 8
mashups: 8
masks: 8
massive: 8
match: 8
max: 8
mc: 8
measuring: 8
method: 8
minimize: 8
misbehaving: 8
mixed: 8
modeled: 8
models: 8
modification: 8
move: 8
neighbor: 8
nominal: 8
nor: 8
notification: 8
notifications: 8
oct: 8
offers: 8
ordered: 8
papers: 8
participation: 8
payoff: 8
perhaps: 8
perturbed: 8
placed: 8
played: 8
plot: 8
portion: 8
prioritised: 8
purpose: 8
put: 8
react: 8
recovering: 8
refer: 8
refrain: 8
replaced: 8
reservation: 8
reservations: 8
retransmissions: 8
returned: 8
reward: 8
robin: 8
sdn: 8
sections: 8
senders: 8
september: 8
series: 8
serves: 8
similarly: 8
simulate: 8
sink: 8
sm: 8
solve: 8
sometimes: 8
span: 8
specification: 8
specified: 8
stacks: 8
staggered: 8
stepwise: 8
strict: 8
subsequently: 8
substituting: 8
suitable: 8
surprisingly: 8
timer: 8
turns: 8
twice: 8
unusable: 8
verify: 8
views: 8
wang: 8
weak: 8
weather: 8
weekly: 8
wiki: 8
ws: 8
xc: 8
aborting: 7
abstraction: 7
acceptors: 7
acknowledged: 7
air: 7
apache: 7
applying: 7
architectural: 7
arises: 7
array: 7
attractive: 7
belongs: 7
big: 7
broadcast: 7
bsd: 7
byzantine: 7
calculate: 7
card: 7
causes: 7
cb: 7
characteristics: 7
cisco: 7
claim: 7
cleaning: 7
cleanup: 7
clearly: 7
closer: 7
collapse: 7
communities: 7
completion: 7
complexity: 7
concept: 7
conflicting: 7
connection: 7
considering: 7
consistently: 7
construct: 7
contemporary: 7
contributions: 7
cooperative: 7
counter: 7
creation: 7
dashed: 7
december: 7
decoupling: 7
degraded: 7
delaying: 7
demers: 7
deploying: 7
dept: 7
derived: 7
designs: 7
deter: 7
determining: 7
display: 7
disrupt: 7
doesn: 7
doing: 7
dolev: 7
downstream: 7
easier: 7
elapsed: 7
electronic: 7
eliminated: 7
eliminates: 7
employs: 7
empty: 7
emulab: 7
enabling: 7
equally: 7
everything: 7
exchanges: 7
experiences: 7
exploit: 7
exponential: 7
extend: 7
feature: 7
feedback: 7
feeds: 7
fires: 7
fit: 7
follow: 7
furthermore: 7
gaining: 7
gray: 7
guarantee: 7
handles: 7
hour: 7
huge: 7
ignored: 7
image: 7
implementations: 7
importantly: 7
incoherent: 7
incorporate: 7
inferior: 7
introduces: 7
inventory: 7
isis: 7
isolation: 7
january: 7
joseph: 7
keys: 7
latest: 7
lbfs: 7
located: 7
locations: 7
ma: 7
mahesh: 7
mapping: 7
mica: 7
mines: 7
ml: 7
mod: 7
modeling: 7
modifying: 7
motivation: 7
multicasts: 7
nature: 7
negligible: 7
nothing: 7
nsf: 7
oblivious: 7
observation: 7
obvious: 7
october: 7
operator: 7
optimistic: 7
overloaded: 7
partitions: 7
percentile: 7
persistent: 7
plus: 7
poorly: 7
population: 7
pre: 7
prefer: 7
press: 7
prime: 7
programs: 7
propagated: 7
prototype: 7
publishing: 7
rack: 7
rarely: 7
rc: 7
reaches: 7
record: 7
reflects: 7
regarding: 7
register: 7
regularly: 7
relaying: 7
rely: 7
repeated: 7
represent: 7
represented: 7
requesting: 7
resistant: 7
restart: 7
retailer: 7
retrieve: 7
rich: 7
route: 7
routers: 7
san: 7
savings: 7
scaling: 7
seamlessly: 7
seek: 7
sharply: 7
she: 7
simplify: 7
simulations: 7
simulator: 7
sites: 7
socket: 7
sockets: 7
springer: 7
stop: 7
storing: 7
subservices: 7
substantially: 7
successful: 7
timeout: 7
tradeoff: 7
trans: 7
transition: 7
transmit: 7
treat: 7
treated: 7
trees: 7
trust: 7
twenty: 7
u: 7
ubiquitous: 7
unaware: 7
unchanged: 7
useless: 7
utilization: 7
validation: 7
variation: 7
vendor: 7
vendors: 7
versus: 7
vii: 7
violating: 7
wan: 7
year: 7
yield: 7
yields: 7
yu: 7
accommodate: 6
achievable: 6
acknowledgement: 6
act: 6
acting: 6
addressed: 6
addresses: 6
adjustment: 6
administrators: 6
affected: 6
afosr: 6
agreement: 6
alternatives: 6
analyzed: 6
apparently: 6
appropriately: 6
argument: 6
arrives: 6
assumptions: 6
atomic: 6
averages: 6
avoids: 6
bars: 6
begins: 6
berkeley: 6
bonneau: 6
bottom: 6
boundaries: 6
broadly: 6
bullet: 6
california: 6
calls: 6
catch: 6
checkpoint: 6
checksum: 6
chen: 6
closely: 6
clouds: 6
clr: 6
coherent: 6
combination: 6
combines: 6
comes: 6
command: 6
comprised: 6
comput: 6
concave: 6
conducted: 6
conjunction: 6
consensus: 6
conservative: 6
considerable: 6
contain: 6
controlled: 6
coordinate: 6
copying: 6
corporation: 6
costly: 6
coupled: 6
crashed: 6
cross: 6
curve: 6
customize: 6
darpa: 6
dates: 6
db: 6
debian: 6
denotes: 6
dependent: 6
deployments: 6
description: 6
detector: 6
determines: 6
develop: 6
digest: 6
discusfish: 6
disjoint: 6
disseminate: 6
divides: 6
document: 6
draw: 6
druschel: 6
durability: 6
earth: 6
ed: 6
effort: 6
egress: 6
eliminating: 6
email: 6
erasure: 6
established: 6
expressions: 6
facebook: 6
feasibility: 6
feed: 6
fifth: 6
fill: 6
focuses: 6
forced: 6
forks: 6
former: 6
foundation: 6
frame: 6
france: 6
gbps: 6
generic: 6
hashing: 6
heartbeat: 6
hidden: 6
histories: 6
hop: 6
huang: 6
imposed: 6
improved: 6
inc: 6
indicates: 6
industry: 6
ingress: 6
intensive: 6
intercepted: 6
intermediate: 6
issued: 6
issuing: 6
kncminer: 6
krzysztof: 6
lacking: 6
lamport: 6
lan: 6
lans: 6
lcm: 6
ledger: 6
loaded: 6
locally: 6
logical: 6
lt: 6
luu: 6
manage: 6
master: 6
matching: 6
maxx: 6
mean: 6
measured: 6
min: 6
mission: 6
modifies: 6
moment: 6
moves: 6
mp: 6
multicasting: 6
my: 6
naturally: 6
nd: 6
nearly: 6
necessarily: 6
noble: 6
nonce: 6
normalizes: 6
notion: 6
numbered: 6
numerical: 6
numerous: 6
occurring: 6
older: 6
operators: 6
optimized: 6
oscillatory: 6
ostrowski: 6
outlined: 6
outperforms: 6
output: 6
overload: 6
pareto: 6
parties: 6
passive: 6
pdf: 6
perfectly: 6
permit: 6
perspective: 6
phase: 6
play: 6
pooled: 6
possibly: 6
powerful: 6
predict: 6
prefix: 6
price: 6
primarily: 6
procedure: 6
produced: 6
publicly: 6
publisher: 6
pulls: 6
punish: 6
questions: 6
queuing: 6
qwest: 6
reachable: 6
red: 6
reduction: 6
redundancy: 6
reject: 6
repeatedly: 6
replay: 6
replicate: 6
resource: 6
resulted: 6
returns: 6
reveals: 6
rewards: 6
rig: 6
ring: 6
rj: 6
rules: 6
samples: 6
satyanarayanan: 6
say: 6
seattle: 6
seems: 6
select: 6
sensitivity: 6
serialized: 6
six: 6
slowly: 6
snapshot: 6
solving: 6
somewhat: 6
sorts: 6
standardized: 6
states: 6
straightforward: 6
stratum: 6
suggested: 6
summarize: 6
sun: 6
super: 6
supplies: 6
switzerland: 6
synchronization: 6
targeted: 6
tat: 6
thank: 6
theory: 6
timeouts: 6
tit: 6
toolkit: 6
tracking: 6
transmits: 6
trigger: 6
trying: 6
txnid: 6
ultimately: 6
understand: 6
unfortunately: 6
unreliable: 6
usability: 6
usable: 6
validate: 6
variability: 6
variations: 6
vast: 6
vector: 6
vldb: 6
welsh: 6
why: 6
withheld: 6
won: 6
workers: 6
worse: 6
xxx: 6
yahoo: 6
zhang: 6
zhu: 6
ability: 5
absence: 5
absolute: 5
acknowledgements: 5
acknowledgment: 5
acl: 5
adapting: 5
adjusting: 5
ago: 5
agree: 5
ahead: 5
allocated: 5
anyone: 5
append: 5
approximate: 5
arbitrarily: 5
arguably: 5
arrival: 5
assuming: 5
atkin: 5
atomicity: 5
attempts: 5
author: 5
avoiding: 5
award: 5
backed: 5
band: 5
behalf: 5
behaves: 5
belong: 5
bit: 5
bits: 5
blocking: 5
brevity: 5
brewer: 5
broken: 5
broker: 5
buildings: 5
bus: 5
calculated: 5
calculates: 5
capture: 5
carry: 5
catches: 5
caught: 5
chains: 5
cheap: 5
cheriton: 5
classified: 5
cloned: 5
collapses: 5
comments: 5
communicate: 5
communicates: 5
compose: 5
concern: 5
concerns: 5
consequence: 5
considerations: 5
constitutes: 5
constrained: 5
consume: 5
consuming: 5
contact: 5
continuously: 5
coolstreaming: 5
cope: 5
count: 5
counts: 5
crashes: 5
credentials: 5
crossing: 5
customers: 5
danny: 5
datagram: 5
day: 5
dealing: 5
defense: 5
demands: 5
demonstrated: 5
denial: 5
denoted: 5
depict: 5
describing: 5
df: 5
dialog: 5
direction: 5
division: 5
dramatic: 5
dsn: 5
edition: 5
eferences: 5
eight: 5
elaborate: 5
elated: 5
embedding: 5
emerging: 5
employing: 5
encourage: 5
encryption: 5
enforce: 5
ephemeral: 5
estimated: 5
ethernet: 5
exceed: 5
except: 5
exhibit: 5
explain: 5
explicitly: 5
exploiting: 5
exploring: 5
expressed: 5
falls: 5
faults: 5
faulty: 5
filtering: 5
firing: 5
flexibility: 5
forces: 5
forwarded: 5
frames: 5
freebsd: 5
frequent: 5
gap: 5
generality: 5
geo: 5
geographical: 5
gigabits: 5
gribble: 5
grid: 5
ground: 5
gu: 5
hacker: 5
health: 5
hierarchical: 5
highperformance: 5
hints: 5
hooks: 5
human: 5
identification: 5
illustrate: 5
imagine: 5
implicit: 5
implies: 5
inaccurate: 5
incorrect: 5
incrementally: 5
incurs: 5
independently: 5
informatik: 5
informatique: 5
innovation: 5
instantly: 5
integrating: 5
interesting: 5
interference: 5
internal: 5
interoperability: 5
invalidate: 5
investigated: 5
investigator: 5
iptv: 5
isps: 5
ittay: 5
johnson: 5
joining: 5
joins: 5
katz: 5
kleinberg: 5
lakshmi: 5
languages: 5
layouts: 5
learn: 5
leases: 5
lengths: 5
lightweight: 5
linking: 5
liu: 5
locality: 5
locks: 5
logic: 5
looking: 5
lossy: 5
mar: 5
marketing: 5
mask: 5
messaging: 5
metrics: 5
minibrowsers: 5
minority: 5
monitors: 5
monthly: 5
moved: 5
mutual: 5
national: 5
normally: 5
ntroduction: 5
observations: 5
obtains: 5
occasional: 5
occurred: 5
offered: 5
omit: 5
omitted: 5
onclusion: 5
onon: 5
optimization: 5
optimizations: 5
optimizes: 5
organization: 5
organizations: 5
organized: 5
originally: 5
orthogonal: 5
outside: 5
overcome: 5
pairs: 5
partially: 5
passed: 5
pause: 5
pay: 5
pays: 5
peerto: 5
people: 5
percentages: 5
permitting: 5
personal: 5
pf: 5
phenomenon: 5
placement: 5
plots: 5
poison: 5
positives: 5
precisely: 5
predictor: 5
predictors: 5
probabilistic: 5
proceeds: 5
progresses: 5
property: 5
proprietary: 5
protected: 5
proved: 5
punished: 5
quick: 5
raise: 5
rare: 5
raw: 5
rd: 5
reaching: 5
regardless: 5
release: 5
reliance: 5
remaining: 5
remove: 5
repairs: 5
repeat: 5
requested: 5
requirement: 5
resilience: 5
resolve: 5
respects: 5
responsiveness: 5
restrictions: 5
reveal: 5
rizzo: 5
road: 5
robustness: 5
satisfactory: 5
satisfied: 5
save: 5
saving: 5
scheduled: 5
schneider: 5
seem: 5
sees: 5
selecting: 5
sensors: 5
separated: 5
separately: 5
sequenced: 5
serializable: 5
sessions: 5
shard: 5
shards: 5
signal: 5
simulated: 5
sized: 5
slack: 5
slower: 5
sophisticated: 5
soule: 5
speculative: 5
sprint: 5
stated: 5
stay: 5
studied: 5
submit: 5
substantial: 5
subsystems: 5
suffer: 5
sum: 5
summarized: 5
suspicion: 5
switched: 5
switches: 5
tech: 5
tell: 5
temporary: 5
texture: 5
thinking: 5
tightly: 5
timely: 5
timestamps: 5
tocs: 5
topologies: 5
tracks: 5
transform: 5
transformations: 5
trap: 5
treating: 5
trend: 5
trends: 5
triggers: 5
tune: 5
tuning: 5
turned: 5
unable: 5
unexpected: 5
unit: 5
unpredictable: 5
untrusted: 5
updating: 5
upper: 5
ut: 5
utilisation: 5
verifying: 5
viewed: 5
volatile: 5
vs: 5
waiting: 5
walk: 5
wall: 5
wants: 5
win: 5
wired: 5
writers: 5
ycsb: 5
yx: 5
ab: 4
abbadi: 4
ac: 4
accepted: 4
acks: 4
action: 4
actions: 4
adopted: 4
advanced: 4
advances: 4
agrawal: 4
alone: 4
alongside: 4
alternate: 4
alvisi: 4
amir: 4
amortizable: 4
analogous: 4
andrew: 4
answer: 4
antpool: 4
applicable: 4
approximated: 4
april: 4
archive: 4
arrow: 4
aspect: 4
assign: 4
assumes: 4
athey: 4
awkward: 4
bahack: 4
ballots: 4
banking: 4
behaviour: 4
benchmark: 4
bernstein: 4
biersack: 4
bifurcations: 4
bitcointalk: 4
blade: 4
blast: 4
blend: 4
blocked: 4
blogspot: 4
border: 4
boxes: 4
brief: 4
briefly: 4
broadcasts: 4
broader: 4
bulk: 4
burstier: 4
calculator: 4
callbacks: 4
caller: 4
capitalization: 4
captures: 4
carefully: 4
certainly: 4
charts: 4
chat: 4
city: 4
clean: 4
clones: 4
closes: 4
cms: 4
collecting: 4
collector: 4
combining: 4
coming: 4
comparable: 4
compensated: 4
compiles: 4
completed: 4
complicated: 4
componentized: 4
composition: 4
comprehensive: 4
compromise: 4
conduct: 4
confirms: 4
consequences: 4
consist: 4
contained: 4
continued: 4
converges: 4
cooperation: 4
correlated: 4
correlation: 4
courtois: 4
crucial: 4
cryptography: 4
cutting: 4
cycle: 4
danger: 4
das: 4
debugging: 4
decades: 4
decided: 4
declining: 4
deep: 4
deferred: 4
defines: 4
demonstrates: 4
desktop: 4
devastating: 4
di: 4
differences: 4
differentiate: 4
differently: 4
directed: 4
directions: 4
directories: 4
disaster: 4
discovery: 4
discussions: 4
disloyal: 4
disrupted: 4
disruption: 4
distant: 4
distribute: 4
distributions: 4
double: 4
ease: 4
ebay: 4
economic: 4
editor: 4
educause: 4
elsewhere: 4
emin: 4
emulate: 4
encoder: 4
encodes: 4
endhosts: 4
enforcing: 4
engages: 4
engineer: 4
enhanced: 4
enormous: 4
enter: 4
envelope: 4
epi: 4
eprint: 4
esb: 4
evenly: 4
evicting: 4
evidence: 4
evil: 4
ex: 4
examines: 4
exchanged: 4
exclusive: 4
executing: 4
existence: 4
export: 4
exposed: 4
extensive: 4
faber: 4
faced: 4
familiar: 4
february: 4
filter: 4
firewalls: 4
five: 4
fixing: 4
flowing: 4
flush: 4
flushes: 4
focusing: 4
followed: 4
formula: 4
foster: 4
fourth: 4
fragmentation: 4
francis: 4
francisco: 4
freedman: 4
friendly: 4
gain: 4
games: 4
gateways: 4
gathered: 4
gets: 4
globally: 4
goes: 4
going: 4
graceful: 4
grants: 4
grateful: 4
grossklags: 4
hackingdistributed: 4
hakim: 4
heartbeats: 4
heavily: 4
helps: 4
hint: 4
holds: 4
home: 4
honeypot: 4
hope: 4
horus: 4
hweather: 4
identified: 4
identifying: 4
identity: 4
ids: 4
ignore: 4
images: 4
impacted: 4
impossible: 4
inaccessible: 4
incorporating: 4
incurred: 4
incurring: 4
inform: 4
initiated: 4
initiative: 4
inquiry: 4
integral: 4
integrate: 4
intelligent: 4
intend: 4
interacts: 4
interrupted: 4
intervening: 4
intrinsically: 4
introducing: 4
invalidated: 4
invalidating: 4
isbn: 4
javascript: 4
jboss: 4
jelasity: 4
joint: 4
jose: 4
july: 4
jumbo: 4
jxta: 4
kaashoek: 4
keeping: 4
keidar: 4
kermarrec: 4
kj: 4
korn: 4
lacks: 4
lakshman: 4
laszka: 4
leaders: 4
learning: 4
leaves: 4
letting: 4
leveraging: 4
libraries: 4
lies: 4
listed: 4
lived: 4
ll: 4
logsim: 4
longdistance: 4
looked: 4
lru: 4
maid: 4
malfunctioning: 4
managing: 4
marked: 4
matched: 4
matrix: 4
maximizes: 4
measures: 4
merely: 4
methodology: 4
miles: 4
military: 4
miller: 4
mind: 4
minimal: 4
minted: 4
minute: 4
misconfigured: 4
misses: 4
mix: 4
mixture: 4
mobility: 4
modulating: 4
monitor: 4
monopoly: 4
moore: 4
msg: 4
mtus: 4
naive: 4
nak: 4
namecoin: 4
narrow: 4
netfilter: 4
normalized: 4
notable: 4
notify: 4
numerically: 4
obstacles: 4
obtaining: 4
offering: 4
ools: 4
operates: 4
optimum: 4
organofcorti: 4
ork: 4
outstanding: 4
owners: 4
ownership: 4
packages: 4
parameterized: 4
participate: 4
parts: 4
patient: 4
paul: 4
payments: 4
payout: 4
payouts: 4
peak: 4
penalty: 4
peps: 4
periodic: 4
permacoin: 4
permutations: 4
person: 4
perspectives: 4
pfldnet: 4
phenomena: 4
php: 4
pi: 4
picked: 4
pictures: 4
placing: 4
player: 4
plotting: 4
podc: 4
poll: 4
polling: 4
positions: 4
practicality: 4
predicted: 4
preferred: 4
preprint: 4
pressure: 4
prevents: 4
pricing: 4
primitives: 4
principle: 4
probabilities: 4
probably: 4
prominent: 4
promising: 4
protect: 4
provisioned: 4
provisioning: 4
pub: 4
publication: 4
pulled: 4
purely: 4
qi: 4
qp: 4
quantities: 4
quantum: 4
querying: 4
readset: 4
reality: 4
realize: 4
reasonable: 4
reference: 4
reflected: 4
regional: 4
rejoin: 4
relation: 4
relations: 4
reliably: 4
removed: 4
reno: 4
repairing: 4
replacement: 4
replicating: 4
repo: 4
reserved: 4
residing: 4
resilient: 4
resolution: 4
resolved: 4
responding: 4
responses: 4
retailers: 4
retransmit: 4
rev: 4
revoke: 4
rigs: 4
rk: 4
robert: 4
root: 4
rosenfeld: 4
routed: 4
rover: 4
rowstron: 4
rule: 4
safety: 4
saturate: 4
saw: 4
scan: 4
secondary: 4
secret: 4
secure: 4
secured: 4
seeks: 4
selective: 4
selfish: 4
separates: 4
sequences: 4
sequentially: 4
sha: 4
shasha: 4
shenker: 4
shift: 4
shut: 4
silver: 4
situational: 4
sixteenth: 4
smalltalk: 4
smart: 4
smr: 4
sold: 4
spanning: 4
spun: 4
srm: 4
standardization: 4
statistically: 4
steadily: 4
steady: 4
stress: 4
stronger: 4
strongly: 4
students: 4
subjected: 4
subsection: 4
successes: 4
suffers: 4
sums: 4
suspected: 4
symmetry: 4
synchronized: 4
tackle: 4
tailored: 4
technological: 4
tens: 4
terminology: 4
terrain: 4
terry: 4
tested: 4
theoretic: 4
things: 4
threaded: 4
took: 4
tornado: 4
touched: 4
towsley: 4
traced: 4
tradeoffs: 4
trading: 4
translate: 4
travel: 4
treats: 4
tremendous: 4
trial: 4
truly: 4
tuple: 4
understanding: 4
undesirable: 4
units: 4
unknown: 4
unusual: 4
upstream: 4
usd: 4
usual: 4
utilities: 4
vahdat: 4
valuable: 4
variable: 4
variants: 4
varies: 4
vfs: 4
viable: 4
vice: 4
visual: 4
von: 4
vulnerable: 4
waits: 4
walsh: 4
washington: 4
weakly: 4
weatherspoon: 4
weight: 4
wish: 4
withhold: 4
worked: 4
worst: 4
worth: 4
writeset: 4
wrong: 4
xk: 4
xkj: 4
yearly: 4
your: 4
abadi: 3
aborts: 3
accepting: 3
accepts: 3
accountable: 3
accumulated: 3
accusations: 3
acidrain: 3
acknowledge: 3
acquire: 3
actively: 3
adapts: 3
adequate: 3
adjust: 3
advancing: 3
advantageous: 3
advertisements: 3
afec: 3
affecting: 3
aggregating: 3
agnostic: 3
aguilera: 3
aimed: 3
aircraft: 3
alan: 3
albeit: 3
alberta: 3
album: 3
alert: 3
alerts: 3
alleviate: 3
amenable: 3
analytical: 3
analytically: 3
anomaly: 3
anything: 3
app: 3
apparent: 3
appears: 3
ar: 3
areas: 3
aren: 3
argued: 3
arising: 3
arla: 3
assertion: 3
assess: 3
assigning: 3
assignment: 3
association: 3
assure: 3
attribute: 3
auditable: 3
aug: 3
authorization: 3
avatars: 3
avoided: 3
backbone: 3
balancer: 3
baltimore: 3
banks: 3
bases: 3
basically: 3
batch: 3
bayou: 3
beginning: 3
bianchini: 3
black: 3
boards: 3
bone: 3
boston: 3
boures: 3
breaking: 3
bring: 3
browser: 3
builds: 3
busy: 3
calling: 3
cambridge: 3
camera: 3
cap: 3
care: 3
carries: 3
categories: 3
chandra: 3
characteristic: 3
checked: 3
children: 3
chronous: 3
chubby: 3
churn: 3
circumvent: 3
claims: 3
clement: 3
closing: 3
colleagues: 3
colorado: 3
column: 3
combinations: 3
commands: 3
commerce: 3
commonly: 3
commun: 3
communicating: 3
company: 3
compatible: 3
compete: 3
competitive: 3
compilers: 3
compiling: 3
completes: 3
composed: 3
compound: 3
comprises: 3
compulsory: 3
computational: 3
computed: 3
con: 3
conceived: 3
concentrate: 3
concluded: 3
conclusions: 3
condition: 3
configurable: 3
confirmed: 3
conservation: 3
conserve: 3
consideration: 3
constructing: 3
construction: 3
consumed: 3
consumes: 3
continues: 3
convinced: 3
convoy: 3
cooperate: 3
coordinates: 3
coordination: 3
copper: 3
corbett: 3
corfu: 3
corporate: 3
correcting: 3
correctness: 3
correlate: 3
criterion: 3
culler: 3
culprit: 3
cumulus: 3
curious: 3
custer: 3
custom: 3
customer: 3
customized: 3
cycles: 3
dahlin: 3
dangers: 3
davis: 3
ddos: 3
deadline: 3
deadlines: 3
deals: 3
decade: 3
deciding: 3
decker: 3
decreasing: 3
deering: 3
degrade: 3
demonstrating: 3
dependable: 3
designers: 3
desire: 3
determinism: 3
deviation: 3
dialogue: 3
differentiation: 3
dis: 3
discover: 3
discrepancy: 3
disruptions: 3
disruptive: 3
disseminated: 3
distributing: 3
dns: 3
documentation: 3
documents: 3
dollars: 3
dominated: 3
dos: 3
drawn: 3
driver: 3
dropping: 3
drpm: 3
dying: 3
economics: 3
eded: 3
edward: 3
eicken: 3
el: 3
elastic: 3
elastras: 3
election: 3
electrical: 3
elegant: 3
else: 3
emergence: 3
emotional: 3
empire: 3
encodings: 3
encouraging: 3
ending: 3
endpoint: 3
endto: 3
enhances: 3
ensuring: 3
enterprises: 3
entities: 3
entity: 3
essay: 3
essential: 3
evaluates: 3
evaluating: 3
eventing: 3
evident: 3
evolution: 3
evolved: 3
exacerbates: 3
excellent: 3
excluding: 3
executes: 3
expands: 3
expelled: 3
experimentally: 3
experimented: 3
expires: 3
explorer: 3
exposes: 3
extends: 3
extension: 3
extent: 3
extra: 3
extracted: 3
fascinating: 3
fewer: 3
fg: 3
fields: 3
fifteenth: 3
finite: 3
firm: 3
flash: 3
flat: 3
fledged: 3
flight: 3
folder: 3
folders: 3
forest: 3
format: 3
formation: 3
franklin: 3
freeloaders: 3
french: 3
friend: 3
fs: 3
ganesh: 3
gargamel: 3
gather: 3
geographically: 3
gf: 3
gfgf: 3
goals: 3
gossiped: 3
government: 3
gps: 3
graphically: 3
great: 3
greatest: 3
grids: 3
grossman: 3
gt: 3
guaranteed: 3
gui: 3
gummadi: 3
guo: 3
gurumurthi: 3
hall: 3
handlers: 3
handley: 3
happen: 3
happy: 3
hauser: 3
haven: 3
heap: 3
helland: 3
helping: 3
hibernator: 3
hierarchically: 3
hierarchies: 3
highspeed: 3
homogeneous: 3
howard: 3
hypothesis: 3
ibm: 3
icdcs: 3
ics: 3
ignores: 3
ignoring: 3
il: 3
immersed: 3
implicitly: 3
impose: 3
imposes: 3
incentives: 3
income: 3
incorporated: 3
incorrectly: 3
incremental: 3
incremented: 3
incur: 3
indiana: 3
indicating: 3
informed: 3
inherits: 3
initiate: 3
innovations: 3
inside: 3
insights: 3
instability: 3
instantaneous: 3
institute: 3
intent: 3
interacting: 3
intercept: 3
intercepting: 3
intercepts: 3
interconnect: 3
interconnected: 3
internals: 3
internetworks: 3
interplay: 3
intervene: 3
inversion: 3
irregular: 3
iteration: 3
jbosscache: 3
jim: 3
jitter: 3
keeps: 3
kenneth: 3
knowing: 3
kuenning: 3
landscape: 3
laptops: 3
larson: 3
late: 3
lateral: 3
lesson: 3
linkage: 3
linked: 3
lions: 3
lloyd: 3
logically: 3
london: 3
looks: 3
loop: 3
losing: 3
lot: 3
luby: 3
mainframe: 3
mainsoft: 3
mainwin: 3
malkhi: 3
malo: 3
managers: 3
marian: 3
markets: 3
marks: 3
mashed: 3
matter: 3
mazie: 3
mckusick: 3
meanwhile: 3
memcached: 3
michael: 3
microbenchmark: 3
mid: 3
migration: 3
minimizing: 3
mirror: 3
mitigate: 3
modular: 3
montresor: 3
motivated: 3
motivates: 3
mountain: 3
movies: 3
multithreaded: 3
nat: 3
native: 3
neighborhood: 3
ninja: 3
nonetheless: 3
noticeable: 3
null: 3
observing: 3
obstruction: 3
occasionally: 3
odel: 3
oneway: 3
onto: 3
opened: 3
operational: 3
opposed: 3
optimizing: 3
optionally: 3
organize: 3
orientation: 3
ousterhout: 3
outbound: 3
outdated: 3
overflows: 3
overlapped: 3
overloads: 3
overwhelmed: 3
pacific: 3
padhye: 3
pai: 3
paid: 3
parameterize: 3
participant: 3
passing: 3
paying: 3
payload: 3
pc: 3
pedone: 3
penalties: 3
perceived: 3
percent: 3
perez: 3
personalities: 3
personalization: 3
pervasive: 3
peter: 3
phone: 3
pinheiro: 3
pisa: 3
players: 3
pleisch: 3
poisson: 3
polls: 3
poor: 3
popek: 3
popularity: 3
portions: 3
pose: 3
posed: 3
positioning: 3
prabhakaran: 3
prebuilt: 3
precedence: 3
predominate: 3
preferentially: 3
prefetched: 3
presentation: 3
preserved: 3
president: 3
preventing: 3
principal: 3
probing: 3
processor: 3
produce: 3
productivity: 3
programmers: 3
promise: 3
propagate: 3
properly: 3
protection: 3
proves: 3
provider: 3
psockets: 3
publishers: 3
punishment: 3
purchases: 3
pushed: 3
putting: 3
qpqp: 3
quanta: 3
queueing: 3
queues: 3
raises: 3
ramp: 3
ranging: 3
rao: 3
raptor: 3
reacting: 3
readonly: 3
realizing: 3
reasoning: 3
recipient: 3
recognize: 3
recommendations: 3
reconstruct: 3
recoveries: 3
reflecting: 3
rejoins: 3
relate: 3
relates: 3
released: 3
releases: 3
remarkably: 3
removing: 3
replaces: 3
replacing: 3
replayed: 3
replica: 3
replies: 3
representation: 3
representative: 3
res: 3
reserve: 3
resort: 3
resp: 3
respective: 3
responds: 3
restarting: 3
restored: 3
restricted: 3
retain: 3
retransmitted: 3
retrieves: 3
revisions: 3
rewarding: 3
rfc: 3
rises: 3
risks: 3
safely: 3
saint: 3
satisfies: 3
satisfy: 3
satisfying: 3
scaled: 3
scene: 3
school: 3
scope: 3
script: 3
semantic: 3
sensor: 3
separation: 3
sequential: 3
served: 3
seventeenth: 3
seventh: 3
severe: 3
sharded: 3
shepherd: 3
showed: 3
sight: 3
simpler: 3
simplest: 3
sinfonia: 3
situated: 3
sixth: 3
sleep: 3
slight: 3
smallest: 3
soft: 3
song: 3
sorrosal: 3
sound: 3
spanner: 3
spare: 3
spatial: 3
specifications: 3
speculatively: 3
splitstream: 3
splitting: 3
sporadic: 3
spot: 3
sprite: 3
sr: 3
ssrn: 3
stability: 3
standardize: 3
started: 3
stays: 3
stems: 3
streamed: 3
struggled: 3
subnet: 3
subscriber: 3
substrate: 3
successive: 3
suddenly: 3
sufficiently: 3
suggests: 3
suite: 3
supplied: 3
surprising: 3
suspicions: 3
symbolic: 3
symbols: 3
synchronously: 3
sys: 3
syst: 3
tables: 3
tacc: 3
tagging: 3
talk: 3
tape: 3
targets: 3
taylor: 3
teams: 3
television: 3
tends: 3
terminating: 3
testing: 3
text: 3
thin: 3
thinks: 3
thirty: 3
thomson: 3
threat: 3
tight: 3
tiled: 3
tolerable: 3
ton: 3
tput: 3
tr: 3
traditionally: 3
train: 3
transferred: 3
transferring: 3
transmissions: 3
triggered: 3
triggering: 3
trivial: 3
trouble: 3
truncation: 3
tsunami: 3
tudor: 3
tudorm: 3
turning: 3
uk: 3
unacceptable: 3
unavailable: 3
unblocks: 3
uncommittable: 3
undetected: 3
unexpectedly: 3
unfairly: 3
unmanaged: 3
unperturbed: 3
unrelated: 3
utah: 3
utilize: 3
uwin: 3
validated: 3
valuation: 3
variables: 3
variance: 3
verified: 3
verlag: 3
viewing: 3
vigfusson: 3
visualization: 3
vt: 3
wake: 3
walli: 3
wanted: 3
warns: 3
watch: 3
wefel: 3
wei: 3
whatever: 3
widespread: 3
winner: 3
wisdom: 3
wobber: 3
worlds: 3
worry: 3
wv: 3
yxyx: 3
zero: 3
zhao: 3
zurich: 3
abandon: 2
abc: 2
abilene: 2
abstractions: 2
academics: 2
acceptance: 2
accessible: 2
accomplished: 2
accordance: 2
accounting: 2
accumulating: 2
accurately: 2
accusation: 2
accused: 2
acquisition: 2
adam: 2
addison: 2
addressing: 2
adjusted: 2
adjusts: 2
administrative: 2
adopt: 2
advancements: 2
advent: 2
adversary: 2
advertises: 2
advice: 2
advocated: 2
aegis: 2
affinity: 2
aforementioned: 2
age: 2
agents: 2
aggregator: 2
aggressive: 2
aict: 2
aim: 2
ajax: 2
akamai: 2
alaska: 2
alberto: 2
albums: 2
alive: 2
alleviating: 2
allocates: 2
allocating: 2
alloscomp: 2
alternatively: 2
altruistic: 2
ame: 2
amortizes: 2
amounting: 2
analyzes: 2
anchorage: 2
anderson: 2
andresen: 2
anomalies: 2
anonymity: 2
anonymously: 2
anti: 2
anticipate: 2
antony: 2
apart: 2
apis: 2
appealing: 2
appeared: 2
appends: 2
applicationindependent: 2
approximately: 2
approximation: 2
approximations: 2
apr: 2
archetypal: 2
argues: 2
arguing: 2
arithmetic: 2
arose: 2
arraystructured: 2
arrived: 2
art: 2
article: 2
articles: 2
asia: 2
asics: 2
asks: 2
asp: 2
aspx: 2
assists: 2
assurance: 2
astonishingly: 2
asynch: 2
atm: 2
attach: 2
attached: 2
attain: 2
attempted: 2
attempting: 2
attestation: 2
attract: 2
attraction: 2
attractiveness: 2
audio: 2
aumann: 2
authentication: 2
automate: 2
autonomous: 2
autotuning: 2
avoidance: 2
ba: 2
baa: 2
babaoglu: 2
bach: 2
backlashed: 2
bailey: 2
baker: 2
ban: 2
barb: 2
barr: 2
barrier: 2
bast: 2
basu: 2
began: 2
behaved: 2
behaving: 2
belonging: 2
benjamin: 2
berlin: 2
bernoulli: 2
besides: 2
bespoke: 2
bhargava: 2
bifurcation: 2
billion: 2
binary: 2
binomial: 2
birrell: 2
bitcoinfoundation: 2
bjornstad: 2
blank: 2
bloomberg: 2
blow: 2
blumenthal: 2
boils: 2
bolton: 2
bonus: 2
borders: 2
box: 2
boycott: 2
bridge: 2
brings: 2
brokerage: 2
bronson: 2
browsers: 2
bruijn: 2
btcguild: 2
btchine: 2
buf: 2
bulpin: 2
burden: 2
burstiness: 2
business: 2
businesses: 2
buterin: 2
butterfly: 2
bypass: 2
caja: 2
calculation: 2
calculations: 2
calvin: 2
came: 2
canada: 2
candidates: 2
canonical: 2
capabilities: 2
carey: 2
carolina: 2
carrera: 2
cash: 2
castro: 2
casual: 2
casually: 2
category: 2
cation: 2
cdns: 2
cease: 2
ceases: 2
ceived: 2
census: 2
centralization: 2
century: 2
certainty: 2
cfm: 2
challenging: 2
chance: 2
characterise: 2
cheaply: 2
checkout: 2
checksums: 2
chemical: 2
chicago: 2
chief: 2
china: 2
chowdhry: 2
cidr: 2
circle: 2
circulate: 2
circulates: 2
circumstances: 2
cited: 2
clark: 2
click: 2
cloudviews: 2
coarse: 2
coexist: 2
coherence: 2
cohort: 2
colarelli: 2
colocated: 2
color: 2
combat: 2
comer: 2
committing: 2
commons: 2
communicated: 2
compelled: 2
compensate: 2
compensation: 2
complement: 2
composing: 2
computes: 2
concentrated: 2
concert: 2
conclusive: 2
confident: 2
confined: 2
connect: 2
cons: 2
considerably: 2
considers: 2
constitute: 2
constraint: 2
contacted: 2
contexts: 2
contract: 2
contradicts: 2
controlling: 2
conversion: 2
converted: 2
converting: 2
cooling: 2
cooper: 2
cording: 2
corner: 2
correspond: 2
countermeasures: 2
counterpart: 2
covered: 2
covering: 2
cox: 2
cpus: 2
credited: 2
credits: 2
cripple: 2
cripples: 2
criticism: 2
croquet: 2
crypto: 2
cryptocurrencies: 2
cryptographic: 2
cryptology: 2
ct: 2
cubic: 2
cypherspace: 2
cz: 2
damage: 2
dan: 2
dangerous: 2
daniel: 2
dast: 2
datasets: 2
datta: 2
days: 2
dbms: 2
dce: 2
dd: 2
deadlocks: 2
dealbook: 2
deceased: 2
decodes: 2
deduce: 2
deeper: 2
deeply: 2
defanti: 2
defects: 2
defer: 2
degradations: 2
degrading: 2
deleting: 2
deliberately: 2
deliberation: 2
delivering: 2
delta: 2
demanding: 2
dentical: 2
dependence: 2
depicted: 2
depicts: 2
deplist: 2
deplistcurr: 2
derive: 2
descriptor: 2
designing: 2
deterministically: 2
deviate: 2
devise: 2
dfreedman: 2
didn: 2
differentiable: 2
diminish: 2
dinosaur: 2
diot: 2
disabled: 2
disadvantage: 2
disadvantages: 2
discount: 2
disincentivize: 2
disrupting: 2
disseminates: 2
dissertation: 2
distances: 2
distinction: 2
diverse: 2
divide: 2
dividing: 2
doi: 2
dok: 2
dominate: 2
dot: 2
dotbit: 2
doubt: 2
downloaded: 2
downloads: 2
downside: 2
drives: 2
driving: 2
dry: 2
ds: 2
dubbed: 2
dugan: 2
dumbbell: 2
duplex: 2
duplicating: 2
dutta: 2
eagerly: 2
earned: 2
earnings: 2
ebling: 2
echo: 2
ecoop: 2
ecosystem: 2
eigenvalue: 2
eighteenth: 2
einar: 2
einstein: 2
elmore: 2
embeddings: 2
emphasis: 2
empirical: 2
enables: 2
encapsulate: 2
encapsulated: 2
encoders: 2
encounter: 2
encountered: 2
encrypted: 2
endhost: 2
ends: 2
ensemble: 2
ent: 2
enters: 2
envision: 2
equate: 2
equilibria: 2
era: 2
ered: 2
esbs: 2
escriva: 2
esign: 2
establishing: 2
estimates: 2
ethereum: 2
ethereumwhitepaper: 2
ets: 2
european: 2
eurosys: 2
ev: 2
eva: 2
eve: 2
eventbased: 2
everyone: 2
eviction: 2
evictions: 2
evolve: 2
exabytes: 2
exceeds: 2
exceptionally: 2
excessively: 2
executions: 2
exerted: 2
exerting: 2
exhibits: 2
expectation: 2
expectations: 2
expedite: 2
explains: 2
explores: 2
exponentially: 2
exports: 2
express: 2
expurging: 2
extensibility: 2
extremes: 2
eyes: 2
facilitate: 2
facto: 2
fair: 2
fall: 2
falling: 2
farms: 2
faulttolerance: 2
featuring: 2
fekete: 2
felser: 2
felten: 2
feng: 2
ferguson: 2
fetched: 2
fills: 2
finer: 2
finished: 2
finishes: 2
fired: 2
firewalling: 2
firoiu: 2
fits: 2
fix: 2
fl: 2
flag: 2
flexibly: 2
fluctuations: 2
fluid: 2
flushed: 2
fold: 2
forbes: 2
forcing: 2
forgo: 2
formats: 2
formulae: 2
forrestv: 2
forth: 2
foundations: 2
fox: 2
fragment: 2
fragments: 2
fraleigh: 2
frameworks: 2
fred: 2
fresh: 2
friction: 2
friedman: 2
friendliness: 2
frobenius: 2
fundamentally: 2
funded: 2
funds: 2
furman: 2
gained: 2
gaps: 2
garbled: 2
gateway: 2
gehrke: 2
generalize: 2
generations: 2
genesis: 2
geometric: 2
ghz: 2
gibbs: 2
gibson: 2
gigabyte: 2
github: 2
glick: 2
globalcrossing: 2
globe: 2
gossiper: 2
gossips: 2
gotten: 2
gr: 2
gradient: 2
gradually: 2
granted: 2
grapevine: 2
grasp: 2
greene: 2
griner: 2
guerraoui: 2
guesses: 2
guessing: 2
gupta: 2
guruprasad: 2
habel: 2
hackers: 2
halfway: 2
halted: 2
handful: 2
hands: 2
happens: 2
harder: 2
harley: 2
harm: 2
hashrate: 2
headers: 2
healthy: 2
heidelberg: 2
height: 2
held: 2
helpful: 2
hereinafter: 2
heterogenous: 2
hey: 2
hibler: 2
hiccups: 2
hides: 2
highlight: 2
highvalue: 2
hinder: 2
histogram: 2
hits: 2
hoarding: 2
hobor: 2
holy: 2
homepage: 2
honesty: 2
honeyman: 2
hops: 2
hotcloud: 2
huitema: 2
hundred: 2
hungry: 2
hurdle: 2
hurwitz: 2
huston: 2
iacr: 2
ic: 2
iciw: 2
icmp: 2
identities: 2
idit: 2
ie: 2
ifip: 2
ih: 2
ij: 2
ill: 2
illinois: 2
im: 2
imagined: 2
immaterial: 2
immediate: 2
immersion: 2
imperatives: 2
imperfect: 2
imply: 2
imposing: 2
impractical: 2
impulse: 2
incorporation: 2
indices: 2
indirection: 2
inefficiency: 2
inefficient: 2
infer: 2
influence: 2
influenced: 2
infrastructures: 2
ingrid: 2
ings: 2
inherent: 2
ining: 2
initialized: 2
initiates: 2
injecting: 2
insertion: 2
inspect: 2
install: 2
installed: 2
instantiated: 2
institutions: 2
instruction: 2
instructs: 2
integer: 2
intentionally: 2
interconnecting: 2
interconnection: 2
interconnects: 2
interix: 2
intermediary: 2
interpret: 2
intersection: 2
intervention: 2
intimate: 2
intricacies: 2
invalid: 2
investment: 2
invoke: 2
invokes: 2
ipdps: 2
iptps: 2
irish: 2
iscussion: 2
island: 2
italy: 2
itcoin: 2
ith: 2
ity: 2
izs: 2
james: 2
javabeans: 2
jimenez: 2
joglekar: 2
jonsson: 2
jsp: 2
juels: 2
justify: 2
kandemir: 2
kansas: 2
kapritsos: 2
karlsson: 2
katabi: 2
kazar: 2
kemme: 2
keycurr: 2
kharif: 2
kiawah: 2
kilper: 2
kim: 2
kimsas: 2
kjkj: 2
knob: 2
knobs: 2
kojo: 2
kroll: 2
krzys: 2
kurose: 2
labelled: 2
labs: 2
lagged: 2
lagging: 2
lake: 2
lambdarail: 2
lambdas: 2
landing: 2
landolsi: 2
laptop: 2
lastly: 2
lastop: 2
launching: 2
laying: 2
le: 2
lease: 2
legitimate: 2
leigh: 2
lepreau: 2
leskovec: 2
leslie: 2
leverages: 2
levy: 2
lightly: 2
lightwave: 2
likewise: 2
lin: 2
liskov: 2
literally: 2
literature: 2
lm: 2
locate: 2
lockstep: 2
longest: 2
longhaul: 2
loops: 2
loosely: 2
louise: 2
lowering: 2
lowers: 2
lows: 2
ltd: 2
luck: 2
lundqvist: 2
lynch: 2
lyon: 2
madden: 2
madhow: 2
magharei: 2
mance: 2
mandatory: 2
mangling: 2
manifested: 2
manipulate: 2
manually: 2
march: 2
marshaling: 2
martinez: 2
matrices: 2
matthews: 2
mature: 2
maximal: 2
maximized: 2
maya: 2
md: 2
mdcc: 2
meant: 2
megabits: 2
memoryless: 2
menees: 2
metacdn: 2
micro: 2
microsystems: 2
migrating: 2
milestone: 2
mined: 2
minimising: 2
minimizes: 2
minus: 2
mirroring: 2
miscalculate: 2
mismatched: 2
mistakenly: 2
mit: 2
mitigated: 2
mitigation: 2
mlml: 2
modem: 2
moderately: 2
modest: 2
modulo: 2
mohr: 2
montenegro: 2
monterey: 2
moshe: 2
mrc: 2
mst: 2
multigrep: 2
multiples: 2
multiplied: 2
multithreading: 2
muri: 2
muthitacharoen: 2
myriad: 2
nakamoto: 2
named: 2
names: 2
naming: 2
nandi: 2
narayanan: 2
naughton: 2
navathe: 2
ncsa: 2
ne: 2
nec: 2
needham: 2
negation: 2
neil: 2
nejdl: 2
newbold: 2
newer: 2
newly: 2
ngan: 2
nic: 2
nichols: 2
nishtala: 2
nity: 2
nlanr: 2
nonequilibrium: 2
nonnenmacher: 2
nontransactional: 2
normalization: 2
normalize: 2
normalizing: 2
normed: 2
notably: 2
notes: 2
notifies: 2
notifying: 2
noting: 2
nutshell: 2
nytimes: 2
obsolete: 2
obviously: 2
occasion: 2
occupies: 2
odd: 2
offices: 2
ofwork: 2
ole: 2
olympics: 2
omi: 2
omits: 2
ool: 2
ooled: 2
op: 2
opacity: 2
opening: 2
operated: 2
opportunities: 2
opt: 2
opted: 2
ordinarily: 2
organizational: 2
organizing: 2
originate: 2
orities: 2
oscillates: 2
ostar: 2
ourselves: 2
outages: 2
outs: 2
outsource: 2
outsources: 2
overcast: 2
overflow: 2
overlays: 2
overqos: 2
pairings: 2
pam: 2
panacea: 2
par: 2
paradigms: 2
parameshwaran: 2
parameterizations: 2
parametrized: 2
parity: 2
park: 2
parno: 2
pass: 2
pathway: 2
patterson: 2
payloads: 2
paypal: 2
pcb: 2
pdcs: 2
pdfs: 2
penalised: 2
pentium: 2
peration: 2
perfor: 2
peris: 2
permits: 2
permitted: 2
perpetrators: 2
perron: 2
petersen: 2
ph: 2
phanishayee: 2
phases: 2
physically: 2
picture: 2
piggybacked: 2
piling: 2
pipeline: 2
pipelines: 2
pitfalls: 2
plague: 2
plays: 2
plication: 2
plugged: 2
plugging: 2
poolattacks: 2
popper: 2
port: 2
porto: 2
ports: 2
poses: 2
position: 2
powersaving: 2
pplive: 2
practically: 2
preceding: 2
precise: 2
precludes: 2
predecessor: 2
predefined: 2
predetermined: 2
predictive: 2
predicts: 2
preferable: 2
prefers: 2
preiss: 2
preliminary: 2
premise: 2
presenting: 2
preservation: 2
preserve: 2
preserving: 2
prevail: 2
prevention: 2
primitive: 2
prioritising: 2
prioritization: 2
prioritize: 2
prioritizing: 2
privately: 2
probabilistically: 2
probe: 2
problematic: 2
processors: 2
produces: 2
professor: 2
profile: 2
profiler: 2
profit: 2
projection: 2
promote: 2
proper: 2
proposals: 2
pros: 2
proving: 2
pseudo: 2
pullbased: 2
pulling: 2
pulse: 2
purchase: 2
purchasing: 2
pure: 2
pursue: 2
pushes: 2
pvldb: 2
qhuang: 2
qin: 2
qmi: 2
qos: 2
quasistatic: 2
quicksilver: 2
quote: 2
race: 2
racticalities: 2
radc: 2
radical: 2
radio: 2
raised: 2
ramakrishnan: 2
ramamritham: 2
randomness: 2
ranges: 2
rank: 2
rateless: 2
rational: 2
ratios: 2
reacts: 2
readily: 2
ready: 2
realizes: 2
rears: 2
reasonably: 2
reception: 2
reciprocation: 2
recognition: 2
recompute: 2
reconciliation: 2
recycling: 2
redesigned: 2
redesigning: 2
reductions: 2
referred: 2
refraining: 2
refreshed: 2
regard: 2
registration: 2
reimplemented: 2
reissue: 2
reissued: 2
rejaie: 2
rejected: 2
rejecting: 2
rejects: 2
relaxed: 2
relay: 2
relevance: 2
relied: 2
relies: 2
reliminaries: 2
relying: 2
remarks: 2
remotely: 2
removes: 2
rendering: 2
rep: 2
repaired: 2
repeatable: 2
repetitions: 2
reporting: 2
repurposing: 2
reputation: 2
requisite: 2
resending: 2
resends: 2
reserves: 2
resident: 2
resolutions: 2
respecting: 2
responsive: 2
restarted: 2
retaliate: 2
retried: 2
retries: 2
reverse: 2
reviewers: 2
revisiting: 2
rewarded: 2
rewritten: 2
reykjavik: 2
reynolds: 2
ricci: 2
rightful: 2
rigid: 2
rigorous: 2
rigorously: 2
rimon: 2
rising: 2
rivalry: 2
roberts: 2
rohrs: 2
rome: 2
roots: 2
rose: 2
rosenblum: 2
ross: 2
rounding: 2
routinely: 2
row: 2
rp: 2
rsized: 2
rt: 2
rtts: 2
ruling: 2
runners: 2
rvr: 2
sabul: 2
safe: 2
saha: 2
said: 2
sake: 2
sales: 2
satellite: 2
saxena: 2
scans: 2
scatter: 2
scattered: 2
scheduler: 2
schedules: 2
sci: 2
scientist: 2
scratch: 2
scsi: 2
seamless: 2
secondgeneration: 2
seda: 2
seeking: 2
seemingly: 2
seldom: 2
seltzer: 2
seminar: 2
senior: 2
sensible: 2
sept: 2
serial: 2
serialize: 2
serially: 2
serious: 2
serverlets: 2
serverpull: 2
settle: 2
shape: 2
shapley: 2
sharp: 2
sheds: 2
shelby: 2
shell: 2
shi: 2
shieh: 2
shifts: 2
shokrollahi: 2
shortcut: 2
shortly: 2
sidebotham: 2
sigact: 2
signs: 2
sigops: 2
sigurbjornsson: 2
silicon: 2
silverlight: 2
simplification: 2
simplified: 2
simulating: 2
singh: 2
sinks: 2
sister: 2
sivakumar: 2
slashdot: 2
slashes: 2
slows: 2
slush: 2
smooth: 2
soar: 2
soars: 2
soas: 2
societies: 2
society: 2
solaris: 2
solely: 2
solheim: 2
solid: 2
solved: 2
something: 2
son: 2
sonic: 2
sons: 2
soper: 2
sourceforge: 2
south: 2
sovran: 2
specialists: 2
speedups: 2
spend: 2
spending: 2
splits: 2
spreads: 2
spreitzer: 2
srs: 2
st: 2
stabilizes: 2
staggering: 2
standalone: 2
stands: 2
stat: 2
statement: 2
station: 2
statqwest: 2
stats: 2
steal: 2
stefan: 2
stephen: 2
stocks: 2
stoller: 2
stops: 2
stories: 2
storms: 2
story: 2
stripe: 2
striping: 2
sturgis: 2
styles: 2
su: 2
subgroup: 2
submits: 2
submitted: 2
submitting: 2
subscribed: 2
subversive: 2
subverted: 2
succession: 2
successively: 2
sudden: 2
suffice: 2
suggest: 2
suggestions: 2
suited: 2
summation: 2
sundr: 2
supergame: 2
supergames: 2
supervisors: 2
supply: 2
suppose: 2
sure: 2
surpass: 2
surprise: 2
survey: 2
susceptibility: 2
suspect: 2
sustain: 2
swallow: 2
swanson: 2
swapping: 2
swift: 2
swinehart: 2
swiss: 2
sybil: 2
synchronize: 2
synthesis: 2
systematic: 2
systemic: 2
tablets: 2
tagged: 2
tailer: 2
tandard: 2
tango: 2
tardos: 2
tation: 2
tauber: 2
tc: 2
technically: 2
tempted: 2
tend: 2
termed: 2
testbed: 2
tgperf: 2
theimer: 2
thick: 2
thing: 2
thirtieth: 2
thumb: 2
tiered: 2
ties: 2
tional: 2
tions: 2
tirumala: 2
toappliance: 2
tock: 2
tods: 2
tolerates: 2
tolerating: 2
topeer: 2
topologically: 2
totally: 2
touch: 2
touches: 2
toueg: 2
tough: 2
toy: 2
tp: 2
tracing: 2
tracked: 2
trades: 2
tragedy: 2
tranmission: 2
transact: 2
transcoded: 2
transforming: 2
trapezoids: 2
treatment: 2
tremel: 2
triangular: 2
tricky: 2
tries: 2
trivially: 2
trol: 2
trsu: 2
trustworthy: 2
tuft: 2
tuned: 2
tv: 2
twentieth: 2
twofold: 2
ugly: 2
umich: 2
un: 2
unaltered: 2
unattacked: 2
unattractive: 2
uncommitable: 2
uncommitted: 2
unexplored: 2
unfavorable: 2
uninvolved: 2
uniquely: 2
united: 2
unlucky: 2
unnecessarily: 2
unnecessary: 2
unreachable: 2
unresponsive: 2
uploading: 2
urgent: 2
userspace: 2
validating: 2
vancouver: 2
vandermeer: 2
vandermonde: 2
vasek: 2
vcurr: 2
vein: 2
venkataramani: 2
ver: 2
verby: 2
versioned: 2
vicinity: 2
viewers: 2
violations: 2
virtualized: 2
visibility: 2
visited: 2
vko: 2
volumes: 2
vpn: 2
wakeup: 2
walks: 2
wallace: 2
war: 2
warehouse: 2
warship: 2
watching: 2
wattenhofer: 2
weakens: 2
weaker: 2
weaknesses: 2
websphere: 2
welch: 2
wesley: 2
west: 2
whereby: 2
whom: 2
wicker: 2
wider: 2
width: 2
wiley: 2
williams: 2
willing: 2
willner: 2
winter: 2
withholds: 2
witnessed: 2
wizkid: 2
wlog: 2
wo: 2
wolfgang: 2
wong: 2
words: 2
workflow: 2
worsening: 2
wrapping: 2
wrongdoing: 2
wvwv: 2
xie: 2
xored: 2
xp: 2
xth: 2
yang: 2
ymir: 2
yxxy: 2
zoom: 2
aaron: 1
abbreviations: 1
abilalso: 1
absorbs: 1
abstracts: 1
abu: 1
accompanied: 1
accomplish: 1
accomplishing: 1
accounted: 1
accumulate: 1
aceves: 1
acheive: 1
acheived: 1
acls: 1
acmula: 1
acomplish: 1
acquires: 1
acquiring: 1
acthe: 1
activated: 1
actuators: 1
acwe: 1
adamic: 1
adaptable: 1
adapted: 1
adaptively: 1
adaptivity: 1
addi: 1
addiserver: 1
additive: 1
addressable: 1
adelaide: 1
adhere: 1
adjacent: 1
administers: 1
admit: 1
admits: 1
adoption: 1
ads: 1
advertise: 1
advertised: 1
adya: 1
aelstrom: 1
aerospace: 1
af: 1
affirmative: 1
afford: 1
afforded: 1
afraid: 1
afterward: 1
agenda: 1
agent: 1
ager: 1
aggregat: 1
aggregrate: 1
aggressively: 1
aggressiveness: 1
agreements: 1
ahnn: 1
aid: 1
aims: 1
airplane: 1
ak: 1
akkus: 1
alarms: 1
albatross: 1
albrecht: 1
alegre: 1
alexander: 1
alfetching: 1
allavena: 1
allegedly: 1
alleviated: 1
alleviates: 1
allo: 1
alloc: 1
allocations: 1
allthingsdistributed: 1
alof: 1
alpha: 1
altogether: 1
altrustic: 1
am: 1
amar: 1
ambitious: 1
america: 1
amortized: 1
ample: 1
amplify: 1
amsden: 1
analogy: 1
analyse: 1
analyst: 1
analytics: 1
ance: 1
anceaume: 1
anddrop: 1
andersen: 1
andre: 1
andreas: 1
ann: 1
anne: 1
annie: 1
annotated: 1
announce: 1
announcement: 1
announces: 1
annoyingly: 1
annually: 1
anonymous: 1
answered: 1
answers: 1
anticipated: 1
antipolis: 1
antonio: 1
anytime: 1
anyway: 1
anywhere: 1
ap: 1
apa: 1
appeal: 1
appendix: 1
applaud: 1
appleton: 1
appli: 1
applicationdropped: 1
appliit: 1
applior: 1
applithe: 1
approaching: 1
approximates: 1
apps: 1
apthe: 1
arbor: 1
architects: 1
archival: 1
archives: 1
argus: 1
arisen: 1
armies: 1
arranging: 1
arrivals: 1
artifact: 1
artificial: 1
ase: 1
aside: 1
ask: 1
asking: 1
assembling: 1
assist: 1
assisted: 1
associates: 1
associating: 1
astrolabe: 1
aswhen: 1
asynbandwidth: 1
asynchrony: 1
asynmicrobenchmarks: 1
asynmobile: 1
asynqueue: 1
ata: 1
atomically: 1
atr: 1
att: 1
attaches: 1
attaching: 1
attar: 1
attention: 1
attr: 1
attracted: 1
attributable: 1
attributed: 1
atypical: 1
audit: 1
audits: 1
australia: 1
authoritative: 1
authorized: 1
autodesk: 1
automation: 1
autotion: 1
autowriteback: 1
autumn: 1
ava: 1
availto: 1
avatar: 1
awaiting: 1
awareness: 1
axes: 1
azim: 1
backgound: 1
backgrounds: 1
backlog: 1
backlogs: 1
backnt: 1
backups: 1
bakalova: 1
balancers: 1
ballance: 1
ballot: 1
banaei: 1
bandcontain: 1
bandhowever: 1
bandwhile: 1
bandwidthdelay: 1
bandwidthsensitive: 1
banff: 1
barcelona: 1
bare: 1
barracuda: 1
barriers: 1
baseline: 1
bastion: 1
batched: 1
batches: 1
batching: 1
batkin: 1
battle: 1
battlefield: 1
battleground: 1
bayeux: 1
bcc: 1
bcq: 1
became: 1
befriended: 1
behren: 1
beijing: 1
belief: 1
believed: 1
beloved: 1
benchmarking: 1
benchmarks: 1
benenational: 1
benoit: 1
bered: 1
berkeleydb: 1
bernd: 1
bershad: 1
bership: 1
bert: 1
bertier: 1
bhattacharjee: 1
biggest: 1
bile: 1
bill: 1
billed: 1
billing: 1
bills: 1
bindel: 1
binds: 1
bio: 1
bitcoinmines: 1
bk: 1
blades: 1
blame: 1
ble: 1
bleeding: 1
blending: 1
blogs: 1
boa: 1
board: 1
body: 1
bold: 1
bologna: 1
bond: 1
bonding: 1
bonn: 1
book: 1
boosting: 1
boot: 1
borisov: 1
bortnikov: 1
boss: 1
bostic: 1
bother: 1
bottlenecks: 1
bought: 1
boundary: 1
bounds: 1
boys: 1
bq: 1
br: 1
brahms: 1
brazil: 1
breakthrough: 1
bregni: 1
breslau: 1
brian: 1
bridging: 1
bright: 1
british: 1
broad: 1
broberg: 1
brokers: 1
brought: 1
bruno: 1
budget: 1
budgets: 1
buffercould: 1
bug: 1
buggy: 1
bugs: 1
builders: 1
burdens: 1
bureau: 1
burgess: 1
buried: 1
burrows: 1
busnel: 1
button: 1
buyer: 1
buying: 1
buys: 1
cabrera: 1
cacheable: 1
cacheserializability: 1
caise: 1
cal: 1
calability: 1
camargos: 1
cameras: 1
cancelled: 1
candidate: 1
cannes: 1
cantwell: 1
capability: 1
cappuccino: 1
captured: 1
caratti: 1
carded: 1
cardinality: 1
cardoso: 1
career: 1
careers: 1
careful: 1
caribbean: 1
carl: 1
carried: 1
carrier: 1
carrying: 1
cart: 1
carzaniga: 1
cas: 1
cascades: 1
cast: 1
castor: 1
catalog: 1
catastrophe: 1
catastrophic: 1
cated: 1
categorized: 1
cations: 1
causal: 1
cbb: 1
cbbc: 1
cbqpcb: 1
ccb: 1
ccdf: 1
cdf: 1
cdrom: 1
ceives: 1
cell: 1
centered: 1
ceremony: 1
certify: 1
certifying: 1
cess: 1
chained: 1
chainlink: 1
chair: 1
chakka: 1
chakravorty: 1
challenger: 1
chang: 1
changtao: 1
chapman: 1
characterised: 1
chawathe: 1
cheat: 1
checkouts: 1
chenchu: 1
cheslack: 1
chicken: 1
chiefly: 1
chien: 1
chinese: 1
ching: 1
chockler: 1
choke: 1
chose: 1
chow: 1
christened: 1
christmas: 1
chronously: 1
chrony: 1
chu: 1
chuck: 1
chunk: 1
chunks: 1
cincilla: 1
circuitous: 1
circulation: 1
circumvented: 1
circumvents: 1
citation: 1
cites: 1
cities: 1
clara: 1
clarity: 1
cleaned: 1
cleanly: 1
clearer: 1
clements: 1
clientserver: 1
clocks: 1
clone: 1
closest: 1
cloudifying: 1
clutter: 1
cmu: 1
codaniques: 1
coded: 1
coding: 1
coexistence: 1
coexists: 1
coherency: 1
coincide: 1
collaborate: 1
collaborating: 1
collapsing: 1
collateral: 1
collects: 1
collusions: 1
columbia: 1
comings: 1
comitting: 1
comm: 1
commatic: 1
commence: 1
commences: 1
commentary: 1
commenting: 1
commercially: 1
commonplace: 1
communal: 1
communi: 1
commutative: 1
comp: 1
compact: 1
comparably: 1
comparaour: 1
comparative: 1
comparisons: 1
compelling: 1
compensating: 1
competitors: 1
compiler: 1
complementary: 1
complementing: 1
complexities: 1
complimentary: 1
comply: 1
compositional: 1
compressed: 1
compresses: 1
comprising: 1
compromises: 1
compromising: 1
computationally: 1
computfits: 1
comsium: 1
concentrates: 1
concentration: 1
conception: 1
conceptually: 1
concludes: 1
concrete: 1
concurby: 1
concuruses: 1
conditioned: 1
conext: 1
configure: 1
conform: 1
conios: 1
conitbased: 1
conjecture: 1
connec: 1
connectionless: 1
conner: 1
consequent: 1
conserving: 1
consisted: 1
consisupdate: 1
consortium: 1
constantly: 1
constituent: 1
constrain: 1
constructs: 1
consulting: 1
consumer: 1
consumers: 1
contacting: 1
contally: 1
contemplate: 1
contemplated: 1
contemplating: 1
contending: 1
conthe: 1
contingencies: 1
contolerate: 1
contractors: 1
contravention: 1
contributes: 1
controller: 1
controversy: 1
convenience: 1
convention: 1
converged: 1
converging: 1
conversely: 1
converts: 1
conveyed: 1
convoys: 1
cooperating: 1
coordinated: 1
coordinating: 1
coordinators: 1
copied: 1
coping: 1
cops: 1
cornelldeveloped: 1
corr: 1
corrected: 1
corrections: 1
correspondingly: 1
corroborated: 1
corrupted: 1
cotton: 1
counters: 1
counting: 1
couple: 1
crashing: 1
crawl: 1
credit: 1
credo: 1
crete: 1
crippling: 1
criteria: 1
critically: 1
crossroads: 1
crowcroft: 1
csd: 1
cstr: 1
culled: 1
cumulatively: 1
customised: 1
customizability: 1
customizable: 1
customization: 1
customizing: 1
customuserserviceapp: 1
cutler: 1
cuts: 1
cybercaf: 1
cyrus: 1
czerwinski: 1
dallas: 1
danielsson: 1
danilov: 1
dantzig: 1
dat: 1
datagrams: 1
dataset: 1
datastores: 1
daunting: 1
dave: 1
davoli: 1
dazzling: 1
dc: 1
dead: 1
deadlock: 1
deadly: 1
deadtially: 1
dean: 1
debatable: 1
debate: 1
debated: 1
debilitating: 1
debris: 1
debugger: 1
declare: 1
declaring: 1
declines: 1
decode: 1
decoder: 1
decoding: 1
decoupled: 1
decouples: 1
decreased: 1
defend: 1
deferplications: 1
deferrable: 1
defers: 1
defgh: 1
defining: 1
definitions: 1
degrees: 1
deit: 1
delegation: 1
delete: 1
deleted: 1
delivers: 1
demanded: 1
demise: 1
demonstration: 1
denning: 1
dennis: 1
denoting: 1
dep: 1
depart: 1
departments: 1
dependalso: 1
dependenrate: 1
depsa: 1
depth: 1
dequeued: 1
der: 1
dered: 1
deregistered: 1
derivative: 1
derivatives: 1
derives: 1
deriving: 1
des: 1
descending: 1
deserver: 1
deshow: 1
designated: 1
designating: 1
designer: 1
desirability: 1
desirable: 1
desktops: 1
destabilize: 1
destinations: 1
detailing: 1
deterioration: 1
determinants: 1
detrimental: 1
dev: 1
developerhours: 1
deviations: 1
devised: 1
devlin: 1
devoted: 1
devoting: 1
dewitt: 1
dexa: 1
dhs: 1
dht: 1
diamond: 1
dictionaries: 1
diego: 1
dies: 1
differany: 1
differential: 1
differentiates: 1
differentiating: 1
differenwith: 1
differing: 1
diffs: 1
dimensions: 1
dimov: 1
ding: 1
directing: 1
directs: 1
disable: 1
disables: 1
disappearance: 1
disappeared: 1
disastrous: 1
disbut: 1
discard: 1
disconnections: 1
disconnects: 1
discontinuing: 1
discotheque: 1
discounts: 1
discovered: 1
discusses: 1
discussing: 1
disguise: 1
disinclined: 1
disjoing: 1
dislike: 1
dismiss: 1
dispatch: 1
dispatcher: 1
dispatching: 1
displayed: 1
displaying: 1
displays: 1
dispools: 1
disregarded: 1
dissatisfied: 1
disseminating: 1
distill: 1
distorted: 1
diverges: 1
diversion: 1
diversity: 1
dll: 1
dlls: 1
documented: 1
dol: 1
domains: 1
dominating: 1
donet: 1
door: 1
dou: 1
doubled: 1
douceur: 1
doug: 1
downgraded: 1
downtime: 1
dozen: 1
dr: 1
drain: 1
drained: 1
drawbacks: 1
drawing: 1
draws: 1
drift: 1
drifting: 1
drive: 1
drivers: 1
drone: 1
duals: 1
ducing: 1
dummynet: 1
dundant: 1
dunn: 1
duplicates: 1
dur: 1
durably: 1
durations: 1
dwarf: 1
dx: 1
dynamics: 1
ear: 1
eastham: 1
economies: 1
ecution: 1
edd: 1
edges: 1
edit: 1
editors: 1
edits: 1
eds: 1
eduardo: 1
educational: 1
edutella: 1
eed: 1
efficacies: 1
eg: 1
egemen: 1
egg: 1
ekin: 1
elasticity: 1
elect: 1
electric: 1
electricity: 1
electronics: 1
eleventh: 1
eliability: 1
elicit: 1
eliciting: 1
elkin: 1
embark: 1
embody: 1
embrace: 1
embraces: 1
emerged: 1
emerges: 1
emitting: 1
emmanuelle: 1
empted: 1
emto: 1
emulating: 1
encapsulates: 1
encod: 1
encode: 1
encompass: 1
encourages: 1
encrypt: 1
encrypts: 1
endeavor: 1
endowment: 1
endpoints: 1
endtransaction: 1
endtransport: 1
enemy: 1
enforced: 1
engine: 1
engineers: 1
enlarge: 1
enlarges: 1
enlarging: 1
enputing: 1
entail: 1
entering: 1
entitled: 1
entropy: 1
enumerate: 1
episodes: 1
epositories: 1
epstein: 1
equeation: 1
equipped: 1
erally: 1
erates: 1
erent: 1
ering: 1
erodes: 1
erred: 1
errorprone: 1
ery: 1
eschewing: 1
esprit: 1
establish: 1
establishes: 1
etup: 1
eugster: 1
evalappended: 1
eventoriented: 1
everyday: 1
everywhere: 1
evocative: 1
evolves: 1
evolving: 1
exacerbating: 1
exaggerated: 1
examined: 1
excellently: 1
excess: 1
exchanging: 1
excitement: 1
exclusively: 1
exec: 1
execusystem: 1
executable: 1
exemplifies: 1
exercise: 1
exhibitthe: 1
existed: 1
exited: 1
exiting: 1
expects: 1
expedited: 1
expense: 1
experiencing: 1
expert: 1
expire: 1
explanation: 1
explanatory: 1
exploits: 1
exponentiated: 1
exporting: 1
expose: 1
exposition: 1
expunged: 1
expurge: 1
exsmart: 1
exspecified: 1
extending: 1
extensible: 1
extensively: 1
extracting: 1
extracts: 1
facilitates: 1
facilitating: 1
facing: 1
factory: 1
failing: 1
failuredetectio: 1
failwhen: 1
faithful: 1
faloutsos: 1
falsely: 1
faltered: 1
famous: 1
farber: 1
farewell: 1
farm: 1
farnoush: 1
farther: 1
fascination: 1
fashioned: 1
fastest: 1
featured: 1
federal: 1
federica: 1
feel: 1
feels: 1
feet: 1
feldman: 1
fell: 1
fellow: 1
fellowship: 1
felt: 1
ferred: 1
ferris: 1
ffs: 1
fic: 1
fidelity: 1
fifteen: 1
figured: 1
fikes: 1
filing: 1
filled: 1
films: 1
filtered: 1
filters: 1
finance: 1
findings: 1
finegrained: 1
finergrained: 1
finish: 1
fiorano: 1
firewall: 1
firms: 1
fisher: 1
fitted: 1
fitting: 1
fixes: 1
flavors: 1
flaws: 1
flickr: 1
flood: 1
flooding: 1
fluctuating: 1
fluke: 1
flushing: 1
fly: 1
focs: 1
football: 1
forcibly: 1
forecast: 1
foregoing: 1
foremost: 1
foresee: 1
forgoing: 1
fork: 1
forked: 1
formal: 1
formally: 1
formed: 1
formerly: 1
fort: 1
fortune: 1
forwards: 1
founder: 1
fractions: 1
franke: 1
frans: 1
freed: 1
freenix: 1
freeze: 1
freshness: 1
fricano: 1
friends: 1
friendship: 1
frightening: 1
frontend: 1
frost: 1
ftcs: 1
fugal: 1
fulfilling: 1
fulfillment: 1
functional: 1
fund: 1
funding: 1
furniture: 1
furthest: 1
gabit: 1
gabriel: 1
gallager: 1
garbinato: 1
garcia: 1
gates: 1
gathering: 1
gauge: 1
gauthier: 1
gave: 1
gb: 1
gbit: 1
gcheap: 1
geambasu: 1
generalized: 1
genercache: 1
generous: 1
geneva: 1
genit: 1
genuinely: 1
geodistributed: 1
geoff: 1
geoffrey: 1
gershinsky: 1
gestion: 1
getting: 1
ghemawat: 1
gi: 1
gian: 1
giardullo: 1
gifford: 1
gilbert: 1
ginting: 1
ginza: 1
gis: 1
gist: 1
giving: 1
glade: 1
glance: 1
glitches: 1
globalized: 1
globecom: 1
goel: 1
gold: 1
goldberg: 1
googles: 1
gov: 1
governed: 1
governmental: 1
grade: 1
gradual: 1
grande: 1
granting: 1
granularity: 1
graphical: 1
grc: 1
gree: 1
greece: 1
grepwe: 1
griffioen: 1
grimm: 1
grips: 1
grochowski: 1
grounds: 1
groundwork: 1
grove: 1
gruber: 1
grunwald: 1
guadelope: 1
gubarev: 1
guha: 1
guis: 1
gunnar: 1
gunnars: 1
gurevich: 1
gurus: 1
guy: 1
guyadec: 1
hacked: 1
hacking: 1
hadoop: 1
haifa: 1
halem: 1
halt: 1
halts: 1
halves: 1
hampering: 1
hanan: 1
handing: 1
handled: 1
handler: 1
handoff: 1
handurukande: 1
hang: 1
hansell: 1
happened: 1
haridasan: 1
haridasana: 1
harmful: 1
harnessing: 1
harpaz: 1
hartman: 1
harwood: 1
hasn: 1
hawaii: 1
hazard: 1
hazards: 1
headquarters: 1
heard: 1
heart: 1
heartbeatmonitor: 1
heat: 1
heavyweight: 1
hegde: 1
hegedu: 1
heidemann: 1
heiser: 1
helen: 1
hellerstein: 1
helped: 1
henceforth: 1
her: 1
herein: 1
hersonissos: 1
hesitate: 1
heterogeneity: 1
heuristic: 1
heuristics: 1
hiding: 1
highassurance: 1
highbandwidth: 1
highbut: 1
highlights: 1
highlyavailable: 1
highpower: 1
highquality: 1
hik: 1
hill: 1
him: 1
himself: 1
hisgen: 1
hjelm: 1
hochschild: 1
holbrook: 1
holder: 1
holding: 1
holte: 1
homes: 1
homomorphic: 1
honolulu: 1
honored: 1
hoon: 1
hopcroft: 1
hoping: 1
horizontal: 1
horn: 1
horrible: 1
hospital: 1
hotice: 1
hotly: 1
hotnets: 1
hotzone: 1
hours: 1
howa: 1
hpca: 1
hreshold: 1
hrs: 1
hsieh: 1
htm: 1
hu: 1
huazhong: 1
huberman: 1
hungary: 1
hurricane: 1
hurting: 1
hyder: 1
hyper: 1
ically: 1
icccn: 1
iceland: 1
icomp: 1
icons: 1
icpads: 1
icsoc: 1
idempotence: 1
iden: 1
idenhigh: 1
identically: 1
idigest: 1
ied: 1
igniting: 1
ignorance: 1
ihkj: 1
iis: 1
ilability: 1
illegal: 1
illusion: 1
imaginable: 1
imation: 1
imc: 1
imlocal: 1
immature: 1
immersive: 1
impacts: 1
implememted: 1
implemenfrom: 1
implemenshared: 1
implementapackages: 1
implosion: 1
implying: 1
import: 1
imported: 1
imporwriteback: 1
imposition: 1
impossibility: 1
imprecise: 1
impressive: 1
improv: 1
inadequacy: 1
inadequate: 1
inadequately: 1
inapplicable: 1
inappropriate: 1
inbound: 1
incentivize: 1
inception: 1
inclusive: 1
incompatible: 1
incomplete: 1
incon: 1
inconsisto: 1
incorpoas: 1
increasess: 1
incredibly: 1
incrementing: 1
indefinitely: 1
independence: 1
indexing: 1
indicators: 1
indictment: 1
indirect: 1
indirectly: 1
indispensable: 1
individinterference: 1
individuals: 1
indranil: 1
induced: 1
industrystandard: 1
inefficiencies: 1
inevitable: 1
inexpennet: 1
inf: 1
infect: 1
infected: 1
infection: 1
infectious: 1
inference: 1
inferred: 1
inflate: 1
inflexibility: 1
inflight: 1
informa: 1
informatics: 1
informing: 1
informs: 1
infrequent: 1
infused: 1
inherited: 1
inhibit: 1
inhibiting: 1
inicontention: 1
initialised: 1
initialize: 1
initiating: 1
initiation: 1
inject: 1
injects: 1
inner: 1
innetwork: 1
innotice: 1
innovate: 1
inprocess: 1
inputs: 1
insecure: 1
insensitive: 1
inseparable: 1
inserted: 1
inserts: 1
inspection: 1
inspired: 1
instruct: 1
instructed: 1
instructing: 1
instructions: 1
instrument: 1
instrumented: 1
instrumenting: 1
int: 1
integers: 1
integrity: 1
intellection: 1
intellectual: 1
intelligence: 1
intem: 1
intense: 1
intensity: 1
intention: 1
intentions: 1
interadditional: 1
intercluster: 1
interdependence: 1
interests: 1
interfere: 1
interferes: 1
interject: 1
interlinked: 1
intermittent: 1
intermittently: 1
internally: 1
internships: 1
interoriginally: 1
interpreted: 1
interpreting: 1
interprocess: 1
interrogates: 1
interrupt: 1
interrupts: 1
interspersed: 1
intervenallows: 1
intra: 1
intractable: 1
intrapartition: 1
intrusion: 1
intrusions: 1
intuitively: 1
invaluable: 1
invariant: 1
invest: 1
investigations: 1
invisible: 1
invocation: 1
invocations: 1
involve: 1
involvement: 1
involving: 1
iperfthe: 1
ipto: 1
irections: 1
irregularity: 1
irregularly: 1
irrelevant: 1
irrespectively: 1
isca: 1
isola: 1
isolate: 1
isolated: 1
isolating: 1
israel: 1
istemi: 1
istva: 1
itcc: 1
items: 1
iterators: 1
ities: 1
itors: 1
iyengar: 1
jacobson: 1
jade: 1
jain: 1
janne: 1
jannotti: 1
jansch: 1
jared: 1
jari: 1
je: 1
jerian: 1
jesi: 1
jian: 1
jiang: 1
jin: 1
jini: 1
jit: 1
jiun: 1
jk: 1
jmc: 1
jms: 1
job: 1
jobs: 1
joined: 1
jones: 1
jong: 1
jorge: 1
jostling: 1
jr: 1
judicious: 1
julkunen: 1
jump: 1
jumpy: 1
juni: 1
junqueira: 1
justice: 1
justification: 1
kallman: 1
kalogeras: 1
kamilmani: 1
kaminsky: 1
kamra: 1
kanthak: 1
karamanolis: 1
karels: 1
karp: 1
kashani: 1
katti: 1
kay: 1
kde: 1
keidl: 1
keith: 1
keller: 1
kempe: 1
kent: 1
kerberos: 1
kernels: 1
kernilized: 1
kevin: 1
keyboard: 1
khan: 1
khorlin: 1
kib: 1
kick: 1
kicking: 1
kicks: 1
kid: 1
kilobyte: 1
kilobytes: 1
kirk: 1
kistler: 1
kit: 1
kk: 1
kleiman: 1
kliot: 1
kloc: 1
knights: 1
knowledgments: 1
kodali: 1
kogan: 1
korhonen: 1
koskela: 1
kostic: 1
kouznetsov: 1
kr: 1
kramer: 1
kraska: 1
krishnakumar: 1
krishnamurthy: 1
kristjan: 1
kristjanvj: 1
krohn: 1
kubiatowicz: 1
kulkarni: 1
kumar: 1
kupfer: 1
kwiatkowski: 1
la: 1
laboratories: 1
laboratory: 1
lacked: 1
ladis: 1
lafayette: 1
lag: 1
lags: 1
laid: 1
laing: 1
lamb: 1
land: 1
landlord: 1
lands: 1
landscapes: 1
lapping: 1
larry: 1
lasting: 1
lauderdale: 1
launch: 1
law: 1
lay: 1
layed: 1
layering: 1
lazy: 1
leaks: 1
learned: 1
learners: 1
leasing: 1
lecture: 1
led: 1
lee: 1
leff: 1
legends: 1
lenient: 1
lenz: 1
lesser: 1
lets: 1
lever: 1
levin: 1
libdeh: 1
liberal: 1
licensing: 1
lie: 1
lied: 1
lieu: 1
lighter: 1
likelihood: 1
limitation: 1
linden: 1
lindsay: 1
linearizable: 1
linger: 1
linkages: 1
lion: 1
listen: 1
listening: 1
littered: 1
liveness: 1
lives: 1
livestreaming: 1
livny: 1
lkjj: 1
ln: 1
lo: 1
localized: 1
localizes: 1
lockfree: 1
logarithmic: 1
logarithmically: 1
logics: 1
login: 1
logstructured: 1
lombard: 1
longput: 1
longrunning: 1
lookup: 1
loose: 1
loses: 1
loudifying: 1
louisiana: 1
lowand: 1
lowbandwidth: 1
lowerfile: 1
lowmfs: 1
lowney: 1
lowpower: 1
lpdc: 1
lr: 1
lugano: 1
luna: 1
luo: 1
lying: 1
lyles: 1
maarten: 1
mach: 1
macrobenchmarks: 1
maffeis: 1
magazine: 1
maglaris: 1
magnetic: 1
magnified: 1
magninetwork: 1
mahajan: 1
maheshwari: 1
mailing: 1
mailoth: 1
mainly: 1
mainteconsequently: 1
mak: 1
maki: 1
malloth: 1
man: 1
mandated: 1
mandreoli: 1
manipulates: 1
manm: 1
mann: 1
mao: 1
marandi: 1
marchukov: 1
marcon: 1
margo: 1
marie: 1
marin: 1
mario: 1
markoff: 1
markus: 1
marrying: 1
marshal: 1
martignon: 1
maryland: 1
marzullo: 1
mash: 1
mashing: 1
masking: 1
mass: 1
massachussetts: 1
matches: 1
materials: 1
matically: 1
matskin: 1
matt: 1
maxcontiguous: 1
maxim: 1
maximizing: 1
maymounkov: 1
mazieres: 1
mazon: 1
mbit: 1
mcauliffe: 1
mcelroy: 1
mckenney: 1
mea: 1
meaning: 1
meaningfully: 1
meantime: 1
mechacies: 1
medians: 1
mediarich: 1
mediately: 1
medical: 1
meet: 1
meetings: 1
megabytes: 1
megastore: 1
meirong: 1
melnik: 1
mem: 1
memcache: 1
memcopy: 1
memoryrelated: 1
men: 1
mendel: 1
menus: 1
mer: 1
merchant: 1
merging: 1
meta: 1
metaphor: 1
miami: 1
miao: 1
mib: 1
migrate: 1
mika: 1
mike: 1
mikhail: 1
mile: 1
milestones: 1
millions: 1
mimic: 1
mindset: 1
minh: 1
minimise: 1
minimised: 1
minimized: 1
minitransactions: 1
minjun: 1
minneapolis: 1
minnesota: 1
minobrowser: 1
mirrored: 1
mirrors: 1
misbehavior: 1
misfinally: 1
miskin: 1
mislove: 1
misra: 1
mistakes: 1
mitigates: 1
mitigating: 1
mitzenmacher: 1
mixes: 1
mmcn: 1
moderate: 1
modewell: 1
modularity: 1
mofavouring: 1
mohan: 1
moll: 1
moments: 1
monetary: 1
monin: 1
monnet: 1
mono: 1
monolithic: 1
monotonically: 1
moon: 1
morning: 1
morris: 1
mostlyreads: 1
motes: 1
motivating: 1
motivations: 1
mounted: 1
mouse: 1
movement: 1
mpi: 1
mplementation: 1
mscorwks: 1
msgs: 1
msiegen: 1
msn: 1
mts: 1
mulsequence: 1
multiframed: 1
multigigabit: 1
multiin: 1
multimedia: 1
multiplexing: 1
multispeed: 1
multitier: 1
multitude: 1
multiversioning: 1
multiwas: 1
multo: 1
mummert: 1
murderous: 1
music: 1
mutexes: 1
mvs: 1
mwaura: 1
na: 1
naaman: 1
nagle: 1
nahrstedt: 1
naively: 1
naks: 1
namespace: 1
nance: 1
napper: 1
narada: 1
nary: 1
nate: 1
nats: 1
naval: 1
navigate: 1
navy: 1
nawab: 1
nca: 1
ndi: 1
neatly: 1
necessity: 1
needing: 1
needless: 1
needlessly: 1
negative: 1
negatively: 1
negligibly: 1
negotiate: 1
nei: 1
neighboring: 1
nelson: 1
ness: 1
netecon: 1
neting: 1
neufeld: 1
newarr: 1
newscasts: 1
nextgeneration: 1
nfs: 1
ngas: 1
nicely: 1
niche: 1
nick: 1
night: 1
nikolov: 1
nimble: 1
ninth: 1
nishimura: 1
nishita: 1
nism: 1
nization: 1
noisy: 1
nomad: 1
nonblockingtransport: 1
noncongestion: 1
nondeterministic: 1
nonempty: 1
nossdav: 1
noteworthy: 1
notified: 1
notoriously: 1
nowadays: 1
np: 1
npapers: 1
nsfc: 1
ntserver: 1
num: 1
numb: 1
numeric: 1
nutanong: 1
nygren: 1
obeyed: 1
obeys: 1
obfuscates: 1
objective: 1
objectivity: 1
objectoriented: 1
obligation: 1
obliging: 1
observable: 1
observes: 1
obsessively: 1
obsoleted: 1
obstacle: 1
obstructs: 1
occurrence: 1
ofc: 1
offenders: 1
offerings: 1
officially: 1
offline: 1
offset: 1
oforder: 1
ogy: 1
oltp: 1
omitting: 1
oneanother: 1
ongoing: 1
ontology: 1
onwards: 1
opearting: 1
openafs: 1
opennt: 1
opens: 1
opensketch: 1
operafrom: 1
operamfs: 1
operat: 1
operatencies: 1
opposing: 1
opposition: 1
optimality: 1
optimally: 1
optimisation: 1
optimisations: 1
optimise: 1
optimised: 1
optimistically: 1
optional: 1
orchestrating: 1
orderings: 1
organised: 1
origin: 1
originated: 1
originating: 1
originator: 1
ority: 1
orks: 1
orleans: 1
orma: 1
ormance: 1
ortributed: 1
orts: 1
oscillate: 1
oscillating: 1
ost: 1
otivation: 1
ource: 1
ous: 1
outcontent: 1
outlook: 1
outof: 1
outperform: 1
outperformed: 1
outright: 1
outweighs: 1
overcomes: 1
overhaul: 1
overlaid: 1
overlayed: 1
overloading: 1
overpredict: 1
overprediction: 1
overreach: 1
overrequest: 1
overrequesting: 1
oversight: 1
oversold: 1
overweigh: 1
overwritten: 1
owing: 1
owned: 1
ozalp: 1
ozsu: 1
pa: 1
pack: 1
package: 1
packparently: 1
packs: 1
pain: 1
pairing: 1
paleczny: 1
pallickara: 1
palossless: 1
pan: 1
panel: 1
pang: 1
panning: 1
pans: 1
paolo: 1
papazoglou: 1
parallelising: 1
parallelism: 1
parallelized: 1
parallelizing: 1
parameterizing: 1
parent: 1
parents: 1
paritybased: 1
parliament: 1
parsa: 1
partitionable: 1
partners: 1
party: 1
passes: 1
pastry: 1
pat: 1
paterson: 1
patin: 1
patino: 1
pavlo: 1
pdc: 1
peculiar: 1
peek: 1
peep: 1
peking: 1
penalized: 1
pennsylvania: 1
penzo: 1
perceive: 1
perceiving: 1
percentiles: 1
perception: 1
perdichizzi: 1
perf: 1
performances: 1
perience: 1
periments: 1
permission: 1
permute: 1
permutes: 1
permuting: 1
perobject: 1
persisted: 1
persistence: 1
persisting: 1
personalize: 1
personalized: 1
personally: 1
pertaining: 1
perturbances: 1
perturbation: 1
perturbations: 1
perv: 1
pervasively: 1
pervasiveness: 1
petko: 1
petrov: 1
pfhsn: 1
phani: 1
philadelphia: 1
philosophical: 1
phones: 1
phpmyadmin: 1
physician: 1
pianese: 1
picconi: 1
picking: 1
picks: 1
piece: 1
pieces: 1
piles: 1
pirahesh: 1
pittsburgh: 1
pivotal: 1
plain: 1
planes: 1
planned: 1
planning: 1
plans: 1
plants: 1
plasma: 1
plat: 1
plausible: 1
please: 1
plentiful: 1
plotted: 1
pluggable: 1
plugins: 1
pn: 1
podcasts: 1
pointer: 1
pointers: 1
poirier: 1
police: 1
political: 1
portability: 1
portal: 1
porting: 1
portob: 1
portray: 1
posix: 1
post: 1
postava: 1
posted: 1
posters: 1
postponed: 1
postponing: 1
potencan: 1
potholes: 1
powell: 1
powerhouse: 1
powering: 1
powers: 1
powersavings: 1
ppendix: 1
practices: 1
pratt: 1
pray: 1
preallocating: 1
precede: 1
precious: 1
precision: 1
preclude: 1
predetermining: 1
predictability: 1
predicting: 1
predictions: 1
predominant: 1
predominantly: 1
preempted: 1
preexisting: 1
preferences: 1
prefetchthe: 1
preguica: 1
preparation: 1
prepare: 1
prepared: 1
prepares: 1
preprocessing: 1
pressing: 1
presume: 1
pretend: 1
pretending: 1
pretends: 1
prevailing: 1
prevalent: 1
previewer: 1
previwhen: 1
prices: 1
prifetched: 1
priin: 1
primaldual: 1
princehouse: 1
priorispeedup: 1
prioritized: 1
priortwo: 1
prito: 1
priviledges: 1
privileged: 1
pro: 1
probed: 1
probes: 1
procedures: 1
proceedin: 1
professional: 1
profiled: 1
profiles: 1
profiling: 1
programmed: 1
progressed: 1
prohibited: 1
prohibitive: 1
prohibitively: 1
prohibits: 1
projected: 1
proliferating: 1
prometheus: 1
prominently: 1
promised: 1
promotional: 1
promptly: 1
pronounced: 1
propagates: 1
propagating: 1
propel: 1
propgated: 1
proportionally: 1
proposal: 1
proposes: 1
prothe: 1
prototypes: 1
protruding: 1
proverbial: 1
provers: 1
provisions: 1
provoke: 1
proximity: 1
prudently: 1
pruned: 1
ptions: 1
publications: 1
publishsubscribe: 1
pubsub: 1
punishing: 1
purchased: 1
purdue: 1
putation: 1
puter: 1
puts: 1
puzar: 1
pvalues: 1
pvm: 1
pvt: 1
qnx: 1
qppq: 1
qu: 1
quadrant: 1
quadrants: 1
qualities: 1
quantified: 1
quantity: 1
quarterman: 1
quarters: 1
quasi: 1
quema: 1
questionable: 1
quinlan: 1
quired: 1
quorum: 1
quotes: 1
raab: 1
races: 1
rachid: 1
racing: 1
radar: 1
radi: 1
rago: 1
raid: 1
rails: 1
raincloud: 1
raisepriority: 1
raising: 1
rameter: 1
ramifications: 1
randomised: 1
ranks: 1
ratnasamy: 1
ratner: 1
rayfield: 1
rbudp: 1
rchitecture: 1
reaction: 1
reactive: 1
readiness: 1
readwrite: 1
realistically: 1
realities: 1
realization: 1
realtime: 1
reardon: 1
reboot: 1
rebuilt: 1
recast: 1
rechecks: 1
recipients: 1
recite: 1
reclamation: 1
recode: 1
recommendation: 1
recommended: 1
recommends: 1
reconfigurable: 1
reconfiguration: 1
reconfigure: 1
reconfiguring: 1
reconnect: 1
reconstruction: 1
recorded: 1
recov: 1
recovrequests: 1
recovthroughput: 1
recurrence: 1
recursive: 1
recursively: 1
redesign: 1
redirect: 1
redirected: 1
redirecting: 1
redisplaying: 1
reedsolomon: 1
referenced: 1
referring: 1
refers: 1
refines: 1
reflectsan: 1
refuse: 1
reg: 1
regenerate: 1
registering: 1
registry: 1
regularity: 1
reid: 1
reiher: 1
reimplementing: 1
relational: 1
relationship: 1
relationships: 1
relayed: 1
religion: 1
relinked: 1
remained: 1
removal: 1
ren: 1
rename: 1
rency: 1
render: 1
renderers: 1
renders: 1
rendezvous: 1
renessea: 1
renewed: 1
rently: 1
reordering: 1
replacements: 1
replicates: 1
reportedly: 1
repre: 1
reprefetch: 1
representa: 1
reproduced: 1
rescuer: 1
researcher: 1
resembles: 1
resend: 1
resetting: 1
reside: 1
resides: 1
resiliency: 1
resolves: 1
resolving: 1
resorting: 1
respected: 1
restarts: 1
restrict: 1
restructured: 1
resumed: 1
retained: 1
retaining: 1
retains: 1
rethese: 1
rethink: 1
retriev: 1
retrieving: 1
reusability: 1
reusable: 1
reuse: 1
reused: 1
revalidate: 1
revealed: 1
revealing: 1
reverts: 1
revisited: 1
revived: 1
revoked: 1
revolution: 1
rewind: 1
rexford: 1
rhee: 1
ricardo: 1
ride: 1
righteous: 1
rio: 1
rive: 1
rlogin: 1
ro: 1
roads: 1
rockell: 1
rocky: 1
rodrigues: 1
rodriguez: 1
rolig: 1
roll: 1
rollback: 1
rolled: 1
rollout: 1
room: 1
rooted: 1
roselli: 1
rotating: 1
rotations: 1
rough: 1
roundrobin: 1
roussel: 1
roy: 1
rss: 1
ru: 1
rubenstein: 1
ruichuan: 1
rush: 1
rushed: 1
rx: 1
saab: 1
sacrificing: 1
saikat: 1
saito: 1
sakoda: 1
salt: 1
sambamurthy: 1
samet: 1
sandber: 1
sankaran: 1
santa: 1
sarana: 1
sarcasm: 1
saroiu: 1
sata: 1
satpep: 1
saturated: 1
saturates: 1
saturating: 1
saturation: 1
savage: 1
saying: 1
says: 1
scaleable: 1
scarce: 1
scenarmobile: 1
scenes: 1
schedule: 1
schematic: 1
schiper: 1
schizophrenic: 1
schlosser: 1
schmidt: 1
schroeder: 1
schuh: 1
schultz: 1
sciascia: 1
scott: 1
screen: 1
screenshots: 1
scripting: 1
scripts: 1
scrutiny: 1
sdns: 1
seagate: 1
searchers: 1
searching: 1
searing: 1
sears: 1
secretly: 1
seeing: 1
seely: 1
seemed: 1
selec: 1
selection: 1
selectively: 1
selfinterested: 1
selforganizing: 1
semanticweb: 1
senses: 1
sensitivfigure: 1
sentative: 1
separating: 1
sequencing: 1
ser: 1
serialised: 1
sericola: 1
serverless: 1
servicing: 1
serving: 1
setceiver: 1
setups: 1
seven: 1
severely: 1
shacham: 1
shaded: 1
shah: 1
shahabi: 1
shalunov: 1
shao: 1
shaped: 1
shapers: 1
shapiro: 1
sharding: 1
shayee: 1
shed: 1
shelf: 1
shenghua: 1
shielding: 1
shim: 1
shipping: 1
shirriff: 1
shop: 1
shopping: 1
shoring: 1
shortcomings: 1
shorter: 1
shouldn: 1
shraer: 1
shrideep: 1
shtml: 1
shupp: 1
shutdown: 1
si: 1
sidebar: 1
siegenthaler: 1
siena: 1
sig: 1
sigkdd: 1
sigmetrics: 1
signature: 1
signed: 1
signers: 1
significance: 1
signing: 1
silberstein: 1
silently: 1
similarities: 1
similarity: 1
simon: 1
simulaneous: 1
simulates: 1
singhai: 1
sintek: 1
sishim: 1
sistencies: 1
sitaraman: 1
sits: 1
sivasubramaniam: 1
sive: 1
sjsu: 1
skepticism: 1
sky: 1
skyrocketing: 1
slash: 1
slay: 1
sleeps: 1
slide: 1
slip: 1
slowdowns: 1
sluggish: 1
smartphone: 1
smith: 1
smoothly: 1
snapshots: 1
snooping: 1
soa: 1
socc: 1
sock: 1
softway: 1
solicited: 1
solves: 1
somefound: 1
sonicmq: 1
sonicsoftware: 1
sooner: 1
sophia: 1
sorted: 1
sought: 1
spain: 1
spanningtree: 1
spans: 1
spared: 1
spawned: 1
speaking: 1
speaks: 1
speci: 1
specializes: 1
specificity: 1
specifies: 1
specifying: 1
spectrum: 1
speech: 1
spends: 1
spielman: 1
spiked: 1
spinning: 1
spirits: 1
spix: 1
splay: 1
splitx: 1
sponse: 1
sporting: 1
sports: 1
sprays: 1
spring: 1
squash: 1
squirrelmail: 1
sridharan: 1
srrs: 1
srsr: 1
ssh: 1
stabilizing: 1
stadrops: 1
stafford: 1
stand: 1
standardizing: 1
stanford: 1
stanislav: 1
stanton: 1
startup: 1
starved: 1
starving: 1
statemachine: 1
statems: 1
stationary: 1
statistic: 1
stead: 1
steen: 1
steep: 1
steer: 1
steere: 1
stepping: 1
stipulating: 1
sto: 1
stochastic: 1
stocking: 1
stodolsky: 1
stoica: 1
stor: 1
stordifferent: 1
straight: 1
street: 1
strengths: 1
stretagy: 1
strike: 1
strikes: 1
strikingly: 1
strings: 1
stripped: 1
strongest: 1
stronglytraces: 1
structuring: 1
studying: 1
stumbled: 1
stylistic: 1
suba: 1
subing: 1
subintervals: 1
subj: 1
subkilobyte: 1
submission: 1
subnetworks: 1
subordinate: 1
subramanian: 1
subscribes: 1
subscription: 1
subscriptions: 1
subsections: 1
subsequence: 1
subservicecontrol: 1
subserviceprocess: 1
substandard: 1
substitute: 1
substreams: 1
subtitles: 1
subtransactions: 1
succeeds: 1
successor: 1
sue: 1
suffix: 1
suggestive: 1
sul: 1
summarise: 1
summarised: 1
summarizes: 1
summarizing: 1
summer: 1
sunos: 1
sup: 1
superbowl: 1
superceded: 1
superfluous: 1
superimpose: 1
superior: 1
superlinearly: 1
supersede: 1
superseded: 1
supervisory: 1
supplementing: 1
supposed: 1
suppressing: 1
surely: 1
surements: 1
surge: 1
surplus: 1
surrounding: 1
surtani: 1
survivors: 1
suryanarayana: 1
suspended: 1
sussman: 1
sw: 1
swart: 1
swivel: 1
swws: 1
sympo: 1
syn: 1
synchro: 1
synchronise: 1
synchronizing: 1
systraditional: 1
szeged: 1
szymaniak: 1
tablet: 1
tag: 1
tags: 1
tailor: 1
tains: 1
talking: 1
talks: 1
tam: 1
tamma: 1
tan: 1
tance: 1
tanin: 1
tao: 1
tapped: 1
tapping: 1
tari: 1
taught: 1
tdi: 1
te: 1
technetwork: 1
technicalsessions: 1
technion: 1
technologists: 1
telecommunications: 1
telemetry: 1
templates: 1
tempt: 1
tems: 1
tency: 1
tended: 1
tension: 1
tent: 1
tentative: 1
tention: 1
terleaving: 1
terlinked: 1
terminal: 1
terminate: 1
terminated: 1
testimony: 1
textures: 1
thanks: 1
thefly: 1
ther: 1
thereafter: 1
thereby: 1
thorsten: 1
thrashing: 1
threading: 1
threetier: 1
throughputs: 1
throughxors: 1
tial: 1
tiate: 1
tib: 1
ticast: 1
ticipant: 1
ticker: 1
ticular: 1
tied: 1
tightrope: 1
timecritical: 1
timeframe: 1
timeline: 1
timers: 1
timescales: 1
timesharing: 1
timo: 1
tination: 1
tings: 1
tiple: 1
titles: 1
tity: 1
tively: 1
tivity: 1
todd: 1
todisincentivize: 1
toend: 1
toknow: 1
tokyo: 1
tolercations: 1
tom: 1
tone: 1
tons: 1
toplas: 1
topoltifiers: 1
tortures: 1
touted: 1
traceroute: 1
traf: 1
trafficshaping: 1
trailing: 1
tranasctions: 1
transactionally: 1
transactypes: 1
transcoding: 1
transformed: 1
transis: 1
transit: 1
transitional: 1
translated: 1
translates: 1
translation: 1
translators: 1
translucence: 1
transportation: 1
transporting: 1
travels: 1
treatments: 1
tri: 1
trials: 1
tricks: 1
tried: 1
trillion: 1
trim: 1
trips: 1
truncate: 1
truncated: 1
truong: 1
tsatalos: 1
ttls: 1
tude: 1
tudy: 1
tunable: 1
tung: 1
tuples: 1
turing: 1
tus: 1
tweb: 1
twelth: 1
twin: 1
twitter: 1
twotier: 1
tx: 1
txcache: 1
txn: 1
typed: 1
typwrite: 1
ual: 1
ubicomm: 1
ubiquitously: 1
ublcs: 1
uc: 1
ucb: 1
ufrgs: 1
ular: 1
ulate: 1
ultrareliable: 1
unacceptably: 1
unavoidable: 1
unbe: 1
uncertain: 1
unclustered: 1
unconstrained: 1
uncontrolled: 1
uncorrelated: 1
underdog: 1
undergo: 1
underlies: 1
underneath: 1
underperform: 1
understandable: 1
understanddevices: 1
understands: 1
understood: 1
undertake: 1
undertaken: 1
underutilisation: 1
underway: 1
undesired: 1
undisturbed: 1
unencrypted: 1
unflattering: 1
unfortunate: 1
unidirectional: 1
unifies: 1
uniformally: 1
unilaterally: 1
unintended: 1
uninterference: 1
unites: 1
univ: 1
univerisity: 1
universal: 1
universe: 1
universita: 1
unjustified: 1
unlink: 1
unlinking: 1
unmodified: 1
unnoticed: 1
unparalleled: 1
unrealistic: 1
unreasonable: 1
unrecoverable: 1
unreserved: 1
unresilient: 1
unresolved: 1
unresponsiveness: 1
unrpcs: 1
unspecified: 1
unsuitable: 1
untouched: 1
unusually: 1
unwilling: 1
upare: 1
upcalls: 1
upcan: 1
upcations: 1
upcoming: 1
upgrade: 1
upgrades: 1
upisting: 1
uploads: 1
upreader: 1
upson: 1
upstudies: 1
upthe: 1
upwidth: 1
ures: 1
urgently: 1
url: 1
urls: 1
usages: 1
usdoj: 1
usefully: 1
usermakes: 1
uservisible: 1
utilising: 1
utilized: 1
utilizes: 1
utilizing: 1
utrsut: 1
utt: 1
uture: 1
uut: 1
uutt: 1
validations: 1
vanilla: 1
vanishes: 1
var: 1
variances: 1
vasilatos: 1
vb: 1
vectored: 1
vehicles: 1
veitch: 1
velenis: 1
venkataraman: 1
vercurr: 1
verification: 1
versa: 1
vertical: 1
victims: 1
videos: 1
vidhyashankar: 1
viding: 1
viewer: 1
viewsynchronous: 1
violated: 1
violates: 1
viral: 1
vironment: 1
virtually: 1
virtue: 1
vishnumurthy: 1
visibly: 1
vision: 1
visit: 1
visiting: 1
vista: 1
visualize: 1
visualizing: 1
vital: 1
vivek: 1
vlo: 1
vmm: 1
vms: 1
voelker: 1
vogel: 1
voip: 1
vollset: 1
voluntary: 1
vrable: 1
wa: 1
waived: 1
wallach: 1
wans: 1
warp: 1
wasn: 1
wasteful: 1
wastes: 1
wasting: 1
watches: 1
wave: 1
wcnc: 1
weaken: 1
weakness: 1
webfs: 1
weblogs: 1
webtier: 1
weeks: 1
weighed: 1
welldefined: 1
weng: 1
wes: 1
westerlund: 1
wg: 1
whatsnew: 1
whatsoever: 1
wheeler: 1
whereupon: 1
whiteboard: 1
whitepaper: 1
whithout: 1
wholefile: 1
wicom: 1
widens: 1
wieloch: 1
wilma: 1
windowsnt: 1
winnie: 1
wires: 1
withuated: 1
witnesses: 1
wolf: 1
wonder: 1
woo: 1
woodford: 1
worker: 1
worries: 1
worrisome: 1
worthwhile: 1
wouldn: 1
wrapped: 1
wraps: 1
writclassification: 1
writeaccesses: 1
writeinvalidations: 1
writequirement: 1
writeserver: 1
writetive: 1
writewrite: 1
wrote: 1
wscompatible: 1
wsdl: 1
wspds: 1
wstransactions: 1
wu: 1
xaxis: 1
xcp: 1
xiao: 1
xisting: 1
xperimental: 1
xu: 1
xyx: 1
yaghmazadeh: 1
yann: 1
yaxes: 1
yee: 1
yielded: 1
yin: 1
ylianttila: 1
youtube: 1
yuanchao: 1
yuanyuan: 1
yum: 1
yushprakh: 1
zahorjan: 1
zdonik: 1
zeal: 1
zealous: 1
zelenka: 1
zephyr: 1
zettabyte: 1
zhen: 1
zhenqi: 1
zhou: 1
zhuang: 1
zoomed: 1
zooming: 1
zooms: 1
zou: 1
zuck: 1
zwilling: 1
